{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we first do the classification using the transformer This is our first classification task.\n",
    "\n",
    "The output classification vector from the transformer is saved to be used by the FCNN This is our second classification task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing necessary libraries\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import sklearn\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from simpletransformers.classification import ClassificationModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the dataset\n",
    "\n",
    "Some pre-processing to the dataset has already been done in preparation for various tests, so this processing is not from scratch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# procedure for getting the data sets and formatting them for the transformer\n",
    " \n",
    "\n",
    "def prepareDataset( filename):\n",
    "     \n",
    "    ReadSet=pd.read_excel(filename )\n",
    "\n",
    "    ReadSet['text']=ReadSet['Statement']\n",
    "    ReadSet['labels']=ReadSet['Label']\n",
    "    \n",
    "    ReadSet=ReadSet.drop(['ID','Label','Statement','Subject','Speaker','Job','From','Affiliation','PantsTotal','NotRealTotal','BarelyTotal','HalfTotal','MostlyTotal','Truths','Context'\n",
    "],axis=1)\n",
    "     \n",
    "    return ReadSet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The attorney general requires that rape victim...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>President Clinton reduced the scale of our mil...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I used tax cuts to help create over 80,000 job...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>New Mexico moved \"up to\" sixth in the nation i...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Corporate profits are up, CEO pay is up, but a...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10264</th>\n",
       "      <td>Under Obamacare, premiums have doubled and tri...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10265</th>\n",
       "      <td>We adopted the modern Social Security system a...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10266</th>\n",
       "      <td>More than two months ago President Barack Obam...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10267</th>\n",
       "      <td>We had a massive landslide victory, as you kno...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10268</th>\n",
       "      <td>Says U.S. Rep. Nancy Pelosi said, Employers cu...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10269 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  labels\n",
       "0      The attorney general requires that rape victim...       0\n",
       "1      President Clinton reduced the scale of our mil...       3\n",
       "2      I used tax cuts to help create over 80,000 job...       4\n",
       "3      New Mexico moved \"up to\" sixth in the nation i...       4\n",
       "4      Corporate profits are up, CEO pay is up, but a...       5\n",
       "...                                                  ...     ...\n",
       "10264  Under Obamacare, premiums have doubled and tri...       4\n",
       "10265  We adopted the modern Social Security system a...       5\n",
       "10266  More than two months ago President Barack Obam...       3\n",
       "10267  We had a massive landslide victory, as you kno...       1\n",
       "10268  Says U.S. Rep. Nancy Pelosi said, Employers cu...       1\n",
       "\n",
       "[10269 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# preparing the training dataset\n",
    "train=prepareDataset( 'train.xlsx')\n",
    "# and display for inspecting\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The president is brain-dead.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Barack Obama supported keeping troops in Iraq,...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>He's leading by example, refusing contribution...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I'm the first person who really took up the is...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I built that border fence in San Diego...and i...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1279</th>\n",
       "      <td>CNN accidentally aired 30 minutes of pornograp...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1280</th>\n",
       "      <td>President Obamas American Recovery and Reinves...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1281</th>\n",
       "      <td>We (in Illinois) have the fifth-highest tax bu...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1282</th>\n",
       "      <td>Says Donald Trump won more counties than any c...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1283</th>\n",
       "      <td>A recent study found that cities where Uber op...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1284 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  labels\n",
       "0                          The president is brain-dead.       0\n",
       "1     Barack Obama supported keeping troops in Iraq,...       3\n",
       "2     He's leading by example, refusing contribution...       3\n",
       "3     I'm the first person who really took up the is...       4\n",
       "4     I built that border fence in San Diego...and i...       4\n",
       "...                                                 ...     ...\n",
       "1279  CNN accidentally aired 30 minutes of pornograp...       1\n",
       "1280  President Obamas American Recovery and Reinves...       2\n",
       "1281  We (in Illinois) have the fifth-highest tax bu...       4\n",
       "1282  Says Donald Trump won more counties than any c...       4\n",
       "1283  A recent study found that cities where Uber op...       3\n",
       "\n",
       "[1284 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# preparing the evaluation/validation dataset\n",
    "Eval=prepareDataset('valid.xlsx')\n",
    "# and display for inspecting\n",
    "Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>New Mexico was 46th in teacher pay (when he wa...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Barack Obama and Hillary Clinton have changed ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I'll tell you what I can tell this country: If...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tommy Thompson created the first school choice...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fifty-six percent decline in overall crime. A ...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1278</th>\n",
       "      <td>We have trade agreements with 20 countries, an...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1279</th>\n",
       "      <td>On Donald Trumps plan to cut federal funding t...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1280</th>\n",
       "      <td>Black Lives Matter, who are attacking law enfo...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1281</th>\n",
       "      <td>Latina who enthusiastically supported Donald T...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1282</th>\n",
       "      <td>Theres been no conclusive or specific report t...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1283 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  labels\n",
       "0     New Mexico was 46th in teacher pay (when he wa...       4\n",
       "1     Barack Obama and Hillary Clinton have changed ...       3\n",
       "2     I'll tell you what I can tell this country: If...       1\n",
       "3     Tommy Thompson created the first school choice...       5\n",
       "4     Fifty-six percent decline in overall crime. A ...       5\n",
       "...                                                 ...     ...\n",
       "1278  We have trade agreements with 20 countries, an...       1\n",
       "1279  On Donald Trumps plan to cut federal funding t...       4\n",
       "1280  Black Lives Matter, who are attacking law enfo...       2\n",
       "1281  Latina who enthusiastically supported Donald T...       0\n",
       "1282  Theres been no conclusive or specific report t...       1\n",
       "\n",
       "[1283 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# preparing the test set dataset\n",
    "test=prepareDataset('test.xlsx')\n",
    "test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up the transformer for fine tuning\n",
    "\n",
    "This is where changes are done to optimise the model\n",
    "\n",
    "The simpletransformers library is the quickest way to do this at the time of writing. \n",
    "For more information on the settings and their default value go here:\n",
    "https://github.com/ThilinaRajapakse/simpletransformers#default-settings \n",
    "\n",
    "###### Please do read that reference before changing any parameters. Don't try to be a hero!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model variables were set up: \n"
     ]
    }
   ],
   "source": [
    "#Set the model being used here\n",
    "model_class='roberta'  # bert or roberta or albert\n",
    "model_version='roberta-large' #bert-base-cased, roberta-base, roberta-large, albert-base-v2 OR albert-large-v2\n",
    "\n",
    "\n",
    "output_folder='./TunedModels/'+model_class+'/'+model_version+\"/\"\n",
    "cache_directory= \"./TunedModels/\"+model_class+\"/\"+model_version+\"/\"+\"/cache/\"\n",
    "labels_count=6  # the number of classification classes\n",
    "\n",
    "print('model variables were set up: ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G:\\0 finalThesis\\LIAR_Text\n",
      "./TunedModels/roberta/roberta-large/\n",
      "./TunedModels/roberta/roberta-large//cache/\n"
     ]
    }
   ],
   "source": [
    "# use this to test if writing to the directories is working\n",
    "\n",
    "import os\n",
    "print(os.getcwd())\n",
    "print(output_folder)\n",
    "print(cache_directory)\n",
    "\n",
    "testWrite=train.head(30)\n",
    " \n",
    "testWrite.to_csv(output_folder+'DeleteThisToo.tsv', sep='\\t')\n",
    "testWrite.to_csv(cache_directory+'DeleteThisToo.tsv', sep='\\t')\n",
    "\n",
    "del(testWrite)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "save_every_steps=1285\n",
    "# assuming training batch size of 8\n",
    "# any number above 1284 saves the model only at every epoch\n",
    "# Saving the model mid training very often will consume disk space fast\n",
    "\n",
    "train_args={\n",
    "    \"output_dir\":output_folder,\n",
    "    \"cache_dir\":cache_directory,\n",
    "    'reprocess_input_data': True,\n",
    "    'overwrite_output_dir': True,\n",
    "    'num_train_epochs': 2,\n",
    "    \"save_steps\": save_every_steps, \n",
    "    \"learning_rate\": 2.2e-5,\n",
    "    \"train_batch_size\": 64,\n",
    "    \"eval_batch_size\": 16,\n",
    "    \"adam_epsilon\": 1e-7,\n",
    "    \"evaluate_during_training_steps\": 5,\n",
    "    \"max_seq_length\": 100,\n",
    "    \"n_gpu\": 1,\n",
    "}\n",
    "\n",
    "# Create a ClassificationModel\n",
    "model = ClassificationModel(model_class, model_version, num_labels=labels_count, args=train_args) \n",
    "\n",
    "# You can set class weights by using the optional weight argument"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading a saved model (based on above args{})\n",
    "\n",
    "If you stopped training you can continue training from a previously saved check point.\n",
    "The next cell allows you to load a model from any checkpoint.\n",
    "The number of epochs in the train_args{} will be done and continue tuning from your checkpoint.\n",
    "\n",
    "###### HOWEVER\n",
    "It will overwrite previous checkpoints!\n",
    "Example:  If you load an epoch-3 checkpoint, the epoch-1 checkpoint will be overwritten by the 4th epoch and it will be equivalent to a 4th epoch even if you have epoch-1 in the name.\n",
    "###### SO BE CAREFUL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model, please wait...\n",
      "model in use is : ./TunedModels/roberta/roberta-large/checkpoint-161-epoch-2\n"
     ]
    }
   ],
   "source": [
    "# loading a previously saved model based on this particular Transformer Class and model_name\n",
    "\n",
    "# loading the checkpoint that gave the best result\n",
    "CheckPoint='checkpoint-161-epoch-2'  \n",
    "\n",
    "\n",
    "preSavedCheckpoint=output_folder+CheckPoint\n",
    "\n",
    "print('Loading model, please wait...')\n",
    "model = ClassificationModel( model_class, preSavedCheckpoint, num_labels=labels_count, args=train_args) \n",
    "print('model in use is :', preSavedCheckpoint )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the Transformer\n",
    "\n",
    "Skip the next cell if you want to skip the training and go directly to the evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting to features started. Cache is not used.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f0c2b5518a14ed18106d52b6dc76b53",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=10269.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.\n",
      "\n",
      "Defaults for this optimization level are:\n",
      "enabled                : True\n",
      "opt_level              : O1\n",
      "cast_model_type        : None\n",
      "patch_torch_functions  : True\n",
      "keep_batchnorm_fp32    : None\n",
      "master_weights         : None\n",
      "loss_scale             : dynamic\n",
      "Processing user overrides (additional kwargs that are not None)...\n",
      "After processing overrides, optimization options are:\n",
      "enabled                : True\n",
      "opt_level              : O1\n",
      "cast_model_type        : None\n",
      "patch_torch_functions  : True\n",
      "keep_batchnorm_fp32    : None\n",
      "master_weights         : None\n",
      "loss_scale             : dynamic\n",
      "Warning:  multi_tensor_applier fused unscale kernel is unavailable, possibly because apex was installed without --cuda_ext --cpp_ext. Using Python fallback.  Original ImportError was: ModuleNotFoundError(\"No module named 'amp_C'\")\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3efee13344eb467099c5087e919c2ab2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch', max=2.0, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b28dad575f254bd1a82bb8a8f85696be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Current iteration', max=161.0, style=ProgressStyle(descri…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "Running loss: 1.887999"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mark\\Anaconda3\\envs\\thesis\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:110: UserWarning: Seems like `optimizer.step()` has been overridden after learning rate scheduler initialization. Please, make sure to call `optimizer.step()` before `lr_scheduler.step()`. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\"Seems like `optimizer.step()` has been overridden after learning rate scheduler \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running loss: 1.849229Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n",
      "Running loss: 1.703963Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 16384.0\n",
      "Running loss: 1.803489"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mark\\Anaconda3\\envs\\thesis\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:224: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running loss: 1.803763Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8192.0\n",
      "Running loss: 1.722979\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75011fdc0e67482d971c19a3779e2cee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Current iteration', max=161.0, style=ProgressStyle(descri…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running loss: 1.703236Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4096.0\n",
      "\n",
      "\n",
      "Training of roberta model complete. Saved to ./TunedModels/roberta/roberta-large/.\n",
      "Training time:  0:12:25.826038\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "start_time = datetime.now()\n",
    "model.train_model(train)\n",
    "print(\"Training time: \", datetime.now() - start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating the training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting to features started. Cache is not used.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35615b7dc5d54dc5aac96de84b39a730",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=10269.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4eab9e3ebc084169935b9760763655be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=642.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{'mcc': 0.22271499230748143, 'acc': 0.3658584088031941, 'eval_loss': 1.541503066585814}\n",
      "Converting to features started. Cache is not used.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25a0e10991e0426598de1a678f4372f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1284.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8332f0bb4be47d79dd45d3803ab6212",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=81.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{'mcc': 0.12517664675137755, 'acc': 0.2842679127725857, 'eval_loss': 1.6382164130976171}\n",
      "Training Result: 0.3658584088031941\n",
      "Eval Result: 0.2842679127725857\n",
      "Training & Evaluation time taken:  0:16:38.946984\n"
     ]
    }
   ],
   "source": [
    "TrainResult, TrainModel_outputs, wrong_predictions = model.eval_model(train, acc=sklearn.metrics.accuracy_score)\n",
    "\n",
    "EvalResult, EvalModel_outputs, wrong_predictions = model.eval_model(Eval, acc=sklearn.metrics.accuracy_score)\n",
    "\n",
    "\n",
    "print('Training Result:', TrainResult['acc'])\n",
    "#print('Model Out:', TrainModel_outputs)\n",
    "\n",
    "print('Eval Result:', EvalResult['acc'])\n",
    "#print('Model Out:', EvalModel_outputs)\n",
    "\n",
    "print(\"Training & Evaluation time taken: \", datetime.now() - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting to features started. Cache is not used.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31c55f5362a64b3a90d6c6d98488dd66",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1283.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21b0b457963043fbba5ca58246696338",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=81.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{'mcc': 0.10461072020967066, 'acc': 0.2727981293842556, 'eval_loss': 1.63450613728276}\n",
      "Test Set Result: 0.2727981293842556\n"
     ]
    }
   ],
   "source": [
    "TestResult, TestModel_outputs, wrong_predictions = model.eval_model(test, acc=sklearn.metrics.accuracy_score)\n",
    "\n",
    "print('Test Set Result:', TestResult['acc'])\n",
    "#print('Model Out:', TestModel_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-2.5820312  -0.9086914   0.08953857  1.1494141   1.3085938   0.32763672] 4   4 Match 1\n",
      "\n",
      "[-1.0683594  -0.12902832  0.13452148  0.39819336  0.01693726 -0.1652832 ] 3   3 Match 2\n",
      "\n",
      "[-0.3725586   0.17175293 -0.08422852  0.00453186 -0.25708008 -0.20959473] 1   1 Match 3\n",
      "\n",
      "[-1.5673828  -0.33276367  0.5341797   1.1835938   0.56591797 -0.36499023] 3   5 \n",
      "[-2.4023438  -0.6591797  -0.4663086   0.8261719   1.1064453   0.57128906] 4   5 \n",
      "[-2.0253906  -0.29858398 -0.28710938  0.80322266  0.65966797  0.22766113] 3   2 \n",
      "[-2.5742188  -0.19689941 -0.41186523  0.9501953   1.2851562   0.7241211 ] 4   4 Match 4\n",
      "\n",
      "[-0.67871094  0.35791016  0.30322266  0.79248047 -0.13330078 -0.46069336] 3   5 \n",
      "[-2.0585938  -0.43408203 -0.43945312  0.34301758  0.84814453  0.9980469 ] 5   4 \n",
      "[-1.9697266  -0.0147171   0.21386719  0.9267578   0.7158203   0.13220215] 3   5 \n",
      "[-0.8510742   0.09527588  0.5727539   1.046875    0.45214844 -0.93115234] 3   5 \n",
      "[-1.5361328   0.2783203   0.1973877   0.76123047 -0.07617188 -0.52685547] 3   3 Match 5\n",
      "\n",
      "[-0.5307617   0.57470703 -0.19470215  0.25341797 -0.6635742  -0.04498291] 1   2 \n",
      "[-0.09820557  0.46533203 -0.11877441  0.20178223 -0.61083984 -0.21057129] 1   1 Match 6\n",
      "\n",
      "[-1.2333984  -0.3408203  -0.5107422   0.14025879  0.86865234  0.81933594] 4   4 Match 7\n",
      "\n",
      "[-1.2744141  -0.12329102  0.19506836  0.24597168 -0.07080078 -0.28710938] 3   4 \n",
      "[-1.7646484  -0.05099487 -0.35766602  0.39282227  0.6816406   0.80029297] 5   4 \n",
      "[-1.3330078   0.23583984  0.26538086  0.7578125   0.05221558  0.07666016] 3   3 Match 8\n",
      "\n",
      "[-0.86816406  0.2685547  -0.41870117  0.07427979 -0.05267334  0.14489746] 1   1 Match 9\n",
      "\n",
      "[-1.5898438  -0.3659668  -0.12054443  0.47387695  0.5991211   0.14282227] 4   1 \n",
      "[-2.1582031  -0.6455078  -0.21240234  0.7026367   0.83496094  0.74609375] 4   1 \n",
      "[-2.5019531  -0.4621582  -0.37109375  0.58154297  1.3300781   1.0136719 ] 4   3 \n",
      "[-1.0488281   0.14477539 -0.6376953   0.01380157 -0.06671143  0.24853516] 5   1 \n",
      "[-1.5605469   0.24279785  0.64746094  0.93408203 -0.05615234 -0.7529297 ] 3   5 \n",
      "[-1.3798828   0.02832031 -0.06021118  0.11663818  0.3227539   0.4543457 ] 5   5 Match 10\n",
      "\n",
      "[-1.3134766  -0.09832764 -0.41333008  0.25097656  0.2130127   0.5332031 ] 5   5 Match 11\n",
      "\n",
      "[-0.51708984  0.33032227 -0.40698242  0.07409668 -0.02900696  0.12109375] 1   5 \n",
      "[-0.5019531   0.52197266  0.33984375  0.14831543 -0.00655746 -0.6855469 ] 1   4 \n",
      "[-1.5224609  -0.2166748   0.18737793  0.7314453   0.3083496   0.17102051] 3   5 \n",
      "[-1.4794922  -0.10882568  0.25512695  0.19311523  0.01878357  0.03640747] 2   3 \n",
      "[-1.2177734   0.01631165  0.02809143  0.8276367   0.4267578   0.09179688] 3   5 \n",
      "[-1.7402344  -0.03955078 -0.6333008  -0.19799805  0.2993164   0.5600586 ] 5   2 \n",
      "[ 0.01132202  0.2878418  -0.04257202  0.20397949 -0.6098633  -0.47070312] 1   0 \n",
      "[-2.2265625  -0.3894043   0.00872803  1.7451172   0.8022461  -0.55322266] 3   5 \n",
      "[-1.5371094  -0.23291016 -0.16271973  0.19445801  0.5678711   0.67089844] 5   5 Match 12\n",
      "\n",
      "[-1.7763672  -0.31567383  0.1776123   0.97314453  0.5864258   0.42382812] 3   5 \n",
      "[-1.0537109   0.02629089 -0.36010742  0.17333984 -0.02531433  0.20751953] 5   4 \n",
      "[-0.36669922  0.05102539  0.0770874   0.3696289  -0.01317596 -0.24682617] 3   3 Match 13\n",
      "\n",
      "[-1.4150391  -0.14538574 -0.32226562  0.47070312  0.5654297   0.7421875 ] 5   3 \n",
      "[-1.3671875  -0.03771973 -0.15026855  0.1772461   0.3581543   0.2849121 ] 4   5 \n",
      "[-0.69433594  0.06433105 -0.09332275  0.26391602 -0.21313477 -0.01835632] 3   5 \n",
      "[-1.6777344  -0.21325684 -0.09490967  0.35229492  0.69970703  0.8574219 ] 5   4 \n",
      "[-1.6337891  -0.35058594 -0.01377869  0.79345703  0.5410156  -0.00450134] 3   3 Match 14\n",
      "\n",
      "[ 0.06341553  0.11407471  0.07611084  0.2006836  -0.16687012 -0.6425781 ] 3   2 \n",
      "[-0.7373047   0.21508789 -0.5185547  -0.01230621 -0.28442383  0.22607422] 5   1 \n",
      "[-0.38354492  0.5854492   0.51708984  0.8154297  -0.24914551 -1.2822266 ] 3   2 \n",
      "[-2.1308594  -0.45166016 -0.17700195  0.6225586   0.8173828   0.75      ] 4   3 \n",
      "[-0.77734375  0.17626953  0.703125    0.26586914 -0.03045654 -0.94433594] 2   2 Match 15\n",
      "\n",
      "[-1.0097656   0.31933594  0.42138672  1.0986328   0.43823242 -0.9638672 ] 3   2 \n",
      "[-1.6650391   0.07281494 -0.45581055  0.27978516  0.38256836  0.80126953] 5   5 Match 16\n",
      "\n",
      "[-1.9599609  -0.46069336 -0.41357422  0.5625      1.1650391   1.0517578 ] 4   5 \n",
      "[-1.7041016  -0.30810547 -0.3581543   0.8442383   0.82910156  0.35620117] 3   2 \n",
      "[-1.6259766  -0.421875    0.03091431  1.1494141   0.48388672 -0.41088867] 3   4 \n",
      "[-1.125      -0.10247803 -0.16491699  0.33691406 -0.11151123  0.4416504 ] 5   2 \n",
      "[-1.3222656   0.2084961  -0.52978516 -0.04260254  0.05172729  0.74902344] 5   1 \n",
      "[-1.7578125  -0.18395996  0.10119629  0.5317383   0.5961914   0.3857422 ] 4   5 \n",
      "[-1.7041016  -0.54833984 -0.22839355  0.28173828  0.8256836   1.1142578 ] 5   5 Match 17\n",
      "\n",
      "[-1.4580078  -0.22741699  0.51220703  0.5415039   0.36938477  0.02848816] 3   2 \n",
      "[-1.4580078   0.12548828 -0.09918213  0.07452393 -0.15356445  0.19604492] 5   5 Match 18\n",
      "\n",
      "[-0.8457031   0.49389648 -0.40356445  0.22607422  0.15539551  0.203125  ] 1   2 \n",
      "[-1.1503906   1.6474609  -0.59521484  1.1777344  -0.9711914  -0.5600586 ] 1   1 Match 19\n",
      "\n",
      "[-1.3134766   0.09130859  0.66845703  0.6401367   0.14978027 -0.16394043] 2   1 \n",
      "[-1.0439453   1.7773438  -0.79248047  1.1152344  -1.0371094  -0.2319336 ] 1   3 \n",
      "[-0.51708984  0.19970703 -0.18261719  0.25585938 -0.39941406  0.04174805] 3   5 \n",
      "[ 1.0634766   0.9033203   0.14135742  0.0680542  -0.5073242  -0.9897461 ] 0   0 Match 20\n",
      "\n",
      "[-1.2089844  -0.2697754   0.05575562  0.49682617  0.26635742  0.43115234] 3   5 \n",
      "[-1.8457031  -0.36376953 -0.34179688  0.37939453  1.0048828   0.96533203] 4   3 \n",
      "[-1.8564453  -0.30395508 -0.41723633  0.11035156  1.03125     1.0693359 ] 5   4 \n",
      "[ 0.46557617  1.1455078   0.1697998   0.36621094 -1.0380859  -1.265625  ] 1   3 \n",
      "[-1.3896484  -0.12200928 -0.07391357  0.56103516  0.11108398  0.03115845] 3   1 \n",
      "[-1.5830078  -0.21643066 -0.54589844  0.56689453  0.88378906  0.98876953] 5   5 Match 21\n",
      "\n",
      "[-1.0146484  -0.22839355  0.14819336  0.3869629  -0.12988281  0.2175293 ] 3   1 \n",
      "[-0.58447266  0.41210938  0.04736328  0.43896484 -0.09338379 -0.40893555] 3   3 Match 22\n",
      "\n",
      "[-0.44189453  0.41088867 -0.31518555  0.13427734 -0.59228516  0.28881836] 1   5 \n",
      "[ 0.0607605   0.37353516 -0.14331055  0.05273438 -0.54833984 -0.10900879] 1   4 \n",
      "[-0.48461914  1.9863281  -0.8066406   0.9667969  -1.2646484  -0.52246094] 1   1 Match 23\n",
      "\n",
      "[-2.0800781  -0.29370117 -0.21984863  0.40551758  0.85009766  1.3203125 ] 5   4 \n",
      "[-0.94873047  1.8496094  -0.6098633   0.97998047 -1.3115234  -0.34350586] 1   3 \n",
      "[-1.4033203   0.29101562 -0.34472656  0.09796143 -0.07830811  0.6582031 ] 5   1 \n",
      "[-0.8964844  -0.02131653 -0.37329102  0.00648499 -0.1418457   0.35302734] 5   3 \n",
      "[-1.8994141  -0.40893555  0.6298828   0.6616211   0.23522949  0.20690918] 3   3 Match 24\n",
      "\n",
      "[-1.6933594  -0.23449707 -0.4296875   0.38720703  0.6870117   0.6586914 ] 4   5 \n",
      "[-1.8369141  -0.18798828  0.02627563  0.25878906  0.28857422  0.6635742 ] 5   2 \n",
      "[-1.9628906  -0.41796875 -0.08312988  0.50341797  1.1240234   0.7001953 ] 4   1 \n",
      "[-1.00195312e+00  2.15332031e-01 -2.25782394e-04  4.21630859e-01\n",
      "  1.07421875e-01 -1.00250244e-02] 3   4 \n",
      "[-1.3222656  -0.13049316  0.07806396  0.20178223  0.12512207  0.01731873] 3   3 Match 25\n",
      "\n",
      "[-0.70703125  1.5371094   0.02191162  0.5053711  -1.1904297  -0.70214844] 1   3 \n",
      "[-1.1357422   0.0282135   0.27783203  0.31079102 -0.1673584   0.20336914] 3   3 Match 26\n",
      "\n",
      "[-1.1367188   0.04376221  0.10430908  0.4140625   0.12719727  0.16369629] 3   4 \n",
      "[-1.7792969  -0.5546875  -0.02323914  0.38623047  0.9472656   0.36987305] 4   5 \n",
      "[-0.7651367   0.28515625  0.0243988   0.44213867 -0.10559082 -0.09124756] 3   4 \n",
      "[-0.40600586  1.8388672  -0.71777344  0.7182617  -1.109375   -0.69384766] 1   3 \n",
      "[ 1.4091797   0.8691406   0.3395996  -0.13354492 -0.9423828  -1.2558594 ] 0   0 Match 27\n",
      "\n",
      "[-2.3105469  -0.16271973  0.02345276  0.57666016  1.0244141   0.44458008] 4   1 \n",
      "[-1.4765625  -0.08843994 -0.01319122  0.5263672   0.23059082 -0.4099121 ] 3   1 \n",
      "[-1.5878906   0.58447266  0.22375488  0.7163086  -0.13769531 -0.19262695] 3   1 \n",
      "[-1.578125   -0.10375977 -0.32470703  0.45922852  0.69384766  0.14465332] 4   5 \n",
      "[-1.1953125  -0.17529297  0.04391479  0.44091797  0.44360352  0.42993164] 4   5 \n",
      "[-0.6430664   0.03924561 -0.14379883  0.01506805 -0.24645996 -0.01024628] 1   3 \n",
      "[-0.05062866  0.22680664  0.05633545 -0.01223755 -0.2956543  -0.38500977] 1   1 Match 28\n",
      "\n",
      "[-1.6689453  -0.39111328 -0.4326172   0.28759766  1.0859375   0.53564453] 4   4 Match 29\n",
      "\n",
      "[ 1.4638672   0.75390625  0.9404297   0.19641113 -0.8071289  -1.71875   ] 0   0 Match 30\n",
      "\n",
      "[-1.9404297   0.04928589  0.5263672   1.2763672   0.33618164 -0.20129395] 3   3 Match 31\n",
      "\n",
      "[-0.8100586   0.3395996  -0.37890625 -0.25097656 -0.08673096  0.24487305] 1   1 Match 32\n",
      "\n",
      "[-1.0712891e+00  1.0404587e-03 -1.2878418e-01  1.2609863e-01\n",
      " -1.5853882e-02  1.4978027e-01] 5   2 \n",
      "[-0.75390625  0.24914551  0.66259766  0.7753906  -0.08728027 -0.61328125] 3   1 \n",
      "[-0.0980835   0.61376953  0.24169922  0.14770508 -0.5776367  -0.93408203] 1   2 \n",
      "[-0.01950073  0.5751953   0.36816406  0.13024902 -0.57177734 -0.8027344 ] 1   5 \n",
      "[ 0.90185547  0.74072266  0.27246094 -0.01806641 -0.47436523 -0.92089844] 0   5 \n",
      "[-1.7373047  -0.01118469 -0.3474121   0.25024414  0.60839844  0.40966797] 4   2 \n",
      "[ 0.61035156  0.51123047  0.45581055  0.06951904 -0.81103516 -1.2587891 ] 0   0 Match 33\n",
      "\n",
      "[-1.5039062  -0.55029297  0.55810547  0.8959961   0.36938477 -0.3935547 ] 3   2 \n",
      "[-1.5097656  -0.03305054 -0.26904297  0.25878906  0.66259766  0.5239258 ] 4   5 \n",
      "[-2.0683594  -0.47485352 -0.16589355  0.7373047   0.81103516  0.35107422] 4   4 Match 34\n",
      "\n",
      "[-0.8720703   2.0234375  -0.51660156  1.0224609  -1.2412109  -0.6665039 ] 1   1 Match 35\n",
      "\n",
      "[ 0.4428711   0.40966797  0.3005371   0.21020508 -0.5415039  -0.96191406] 0   0 Match 36\n",
      "\n",
      "[-0.70751953  0.3149414   0.09234619  0.3491211  -0.49951172 -0.11535645] 3   5 \n",
      "[-1.8710938e+00  9.9301338e-05  4.3457031e-02  6.6357422e-01\n",
      "  4.6972656e-01  3.1274414e-01] 3   1 \n",
      "[ 0.3642578   0.8754883   0.5942383   0.43408203 -0.7338867  -1.5458984 ] 1   1 Match 37\n",
      "\n",
      "[-2.0761719  -0.3515625  -0.23205566  0.65283203  0.83496094  0.18395996] 4   3 \n",
      "[-1.3261719  -0.01325226 -0.05963135  0.43652344 -0.15588379 -0.08898926] 3   2 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.07275391  0.9692383   0.41308594  0.06634521 -0.6904297  -1.5107422 ] 1   2 \n",
      "[-2.3457031  -0.6015625  -0.2331543   0.8598633   1.1728516   0.75439453] 4   4 Match 38\n",
      "\n",
      "[-1.5527344   0.14758301 -0.05941772  0.42016602  0.49536133  0.38793945] 4   4 Match 39\n",
      "\n",
      "[-1.265625    0.12866211 -0.02493286  0.40649414  0.1517334   0.10675049] 3   5 \n",
      "[-1.0859375   0.04574585  0.30029297  0.55029297  0.28930664 -0.39013672] 3   1 \n",
      "[-1.2421875   0.05041504 -0.4230957   0.4765625   0.23046875  0.11743164] 3   1 \n",
      "[-2.421875   -0.23754883  0.09454346  1.1201172   0.7338867   0.14477539] 3   4 \n",
      "[-2.1679688  -0.5136719  -0.2368164   0.7910156   0.92041016  0.6801758 ] 4   5 \n",
      "[-1.3505859  -0.33203125  0.04882812  0.38745117  0.49365234 -0.22607422] 4   1 \n",
      "[-2.4765625  -0.45166016  0.06750488  1.0478516   0.86865234 -0.12780762] 3   2 \n",
      "[-1.1777344   0.27026367 -0.64501953  0.12225342  0.05993652  1.0605469 ] 5   2 \n",
      "[ 0.32714844  0.79248047 -0.04220581  0.22265625 -0.9316406  -0.65625   ] 1   1 Match 40\n",
      "\n",
      "[-1.0576172   0.3408203   0.2467041   0.6298828   0.10742188  0.03741455] 3   2 \n",
      "[-1.7197266  -0.20227051  0.03552246  0.9589844   0.52978516  0.23669434] 3   1 \n",
      "[-1.3378906   0.32958984 -0.3088379   0.31982422  0.10858154  0.63134766] 5   2 \n",
      "[-2.2675781  -0.64404297 -0.60791016  0.71484375  1.2861328   1.4208984 ] 5   5 Match 41\n",
      "\n",
      "[-0.99316406  0.19311523 -0.2220459   0.00666428  0.01444244  0.21203613] 5   5 Match 42\n",
      "\n",
      "[-1.6923828  -0.08752441 -0.4873047   0.46533203  0.6723633   0.38623047] 4   2 \n",
      "[-1.2216797  -0.21765137  0.41723633  0.9970703   0.11810303 -0.8359375 ] 3   3 Match 43\n",
      "\n",
      "[-0.58496094 -0.39746094  0.7319336   1.0595703   0.06219482 -1.1220703 ] 3   1 \n",
      "[-2.1289062  -0.7446289  -0.36328125  0.8041992   1.296875    0.98583984] 4   2 \n",
      "[-0.60546875  0.9814453   0.22998047  0.3881836  -0.5102539  -0.45996094] 1   1 Match 44\n",
      "\n",
      "[-1.2285156   0.23522949 -0.11187744  0.28466797 -0.28320312 -0.02731323] 3   4 \n",
      "[-1.7763672  -0.52734375  0.32495117  1.5439453   0.58935547 -0.6196289 ] 3   3 Match 45\n",
      "\n",
      "[-1.8613281  -0.30444336  0.31982422  1.6533203   0.6328125  -0.83496094] 3   4 \n",
      "[-2.2421875  -0.2944336   0.19848633  1.0742188   0.9433594  -0.23095703] 3   3 Match 46\n",
      "\n",
      "[-0.6333008   0.02687073  0.3791504   0.2866211  -0.13000488 -0.2800293 ] 2   3 \n",
      "[-2.5625     -0.6323242  -0.25610352  0.85595703  1.4580078   1.0507812 ] 4   5 \n",
      "[ 0.33276367  0.40063477  0.34643555  0.45703125 -0.5239258  -1.1220703 ] 3   4 \n",
      "[ 0.28027344  1.0146484  -0.54833984  0.13244629 -0.9248047  -0.1348877 ] 1   1 Match 47\n",
      "\n",
      "[-1.9736328  -0.22631836 -0.03302002  0.8276367   0.6430664   0.32348633] 3   2 \n",
      "[-1.4423828  -0.03753662 -0.03375244  0.30493164  0.17321777  0.06835938] 3   1 \n",
      "[-1.7548828  -0.16931152 -0.40673828 -0.02464294  0.66796875  0.78222656] 5   3 \n",
      "[-0.54248047  0.23718262  0.6635742   0.27124023 -0.40893555 -0.64697266] 2   2 Match 48\n",
      "\n",
      "[-0.80615234 -0.06988525  0.68896484  0.47973633 -0.12359619 -0.59716797] 2   3 \n",
      "[-2.1914062  -0.45458984 -0.4638672   0.74658203  0.85302734  0.73095703] 4   5 \n",
      "[-1.8886719  -0.5229492  -0.25048828  0.6308594   1.0410156   0.5966797 ] 4   4 Match 49\n",
      "\n",
      "[-1.7939453   0.05218506  0.22705078  0.73779297  0.2607422  -0.18359375] 3   4 \n",
      "[-2.0878906  -0.1159668  -0.4584961   0.3173828   0.97802734  0.91552734] 4   5 \n",
      "[-1.9404297  -0.29858398  0.08520508  0.7470703   0.86816406  0.5214844 ] 4   5 \n",
      "[ 0.9213867   0.8613281   0.2088623  -0.12597656 -0.99658203 -1.2519531 ] 0   1 \n",
      "[-0.94140625  0.3557129  -0.09649658  0.22644043 -0.27368164 -0.21911621] 1   4 \n",
      "[-1.0712891   1.8466797  -0.8173828   1.0302734  -1.0839844  -0.27001953] 1   3 \n",
      "[-1.9052734  -0.35888672 -0.22753906  0.19299316  0.5439453   0.7553711 ] 5   3 \n",
      "[-2.3925781  -0.32592773 -0.12780762  1.0039062   0.85595703  0.39575195] 3   5 \n",
      "[-0.9814453   0.3630371  -0.10266113  0.36157227 -0.08599854  0.10791016] 1   3 \n",
      "[-2.4199219  -0.57421875 -0.4020996   0.71875     1.1416016   1.0791016 ] 4   2 \n",
      "[-0.66503906  0.50341797 -0.2705078  -0.08215332 -0.08685303  0.22546387] 1   3 \n",
      "[-0.25        0.61865234 -0.41333008  0.02589417 -0.47973633  0.11859131] 1   1 Match 50\n",
      "\n",
      "[-0.68652344  0.6533203   0.22180176  0.14440918 -0.20324707 -0.8491211 ] 1   3 \n",
      "[-2.8046875  -0.9057617  -0.02983093  1.3310547   1.2421875   0.02079773] 3   2 \n",
      "[-0.79248047  0.16186523  0.0221405  -0.03262329 -0.1149292   0.02145386] 1   5 \n",
      "[-2.5136719  -0.5834961  -0.22192383  0.60546875  1.5175781   1.0927734 ] 4   5 \n",
      "[-0.89746094  1.9013672  -0.8745117   0.7944336  -1.1289062  -0.1998291 ] 1   3 \n",
      "[-1.125      -0.37402344  0.20593262  0.6035156   0.24719238 -0.14465332] 3   5 \n",
      "[-2.3046875  -0.56152344 -0.7573242   0.5786133   1.3808594   1.0371094 ] 4   3 \n",
      "[-1.28125    -0.2043457   0.79589844  1.0205078   0.14331055 -0.73535156] 3   4 \n",
      "[-1.9482422  -0.48364258 -0.2849121   0.66503906  1.1708984   0.9140625 ] 4   1 \n",
      "[-1.6103516  -0.35351562 -0.39526367  0.55078125  0.88183594  0.5703125 ] 4   2 \n",
      "[-1.84375    -0.27392578 -0.6333008   0.00690079  0.53759766  1.0507812 ] 5   5 Match 51\n",
      "\n",
      "[-0.89941406 -0.16809082 -0.2861328   0.15014648  0.32421875  0.07983398] 4   3 \n",
      "[-1.2255859  -0.01657104  0.03475952  0.50390625 -0.13183594 -0.16833496] 3   3 Match 52\n",
      "\n",
      "[ 0.10437012  0.95703125 -0.0859375  -0.22619629 -0.6508789  -0.45458984] 1   1 Match 53\n",
      "\n",
      "[-1.3232422  -0.28442383 -0.04473877  0.70458984  0.47631836  0.17895508] 3   1 \n",
      "[-1.1015625   0.32617188 -0.12658691  0.02201843 -0.36279297  0.1907959 ] 1   0 \n",
      "[ 0.06262207  0.296875    0.26098633  0.02581787 -0.79541016 -0.43701172] 1   0 \n",
      "[-0.88183594 -0.02822876 -0.23071289  0.09552002  0.081604    0.0670166 ] 3   4 \n",
      "[-2.0078125   0.14831543 -0.3557129   0.44018555  0.6948242   1.0302734 ] 5   1 \n",
      "[-1.5419922   0.07940674 -0.44213867 -0.03561401  0.2668457   0.6557617 ] 5   5 Match 54\n",
      "\n",
      "[-1.3261719   0.21655273  0.6333008   1.0966797   0.07678223 -0.8330078 ] 3   2 \n",
      "[-1.9003906  -0.24255371 -0.79345703  0.24304199  0.86816406  0.71777344] 4   5 \n",
      "[-1.0800781   0.60058594 -0.32910156  0.15734863  0.00113583  0.21386719] 1   5 \n",
      "[-1.6757812  -0.09606934 -0.3618164   0.4580078   0.77734375  0.3701172 ] 4   0 \n",
      "[-0.5366211   0.37475586  0.27319336  0.32177734 -0.2775879  -0.54296875] 1   1 Match 55\n",
      "\n",
      "[-0.7949219   1.5976562  -0.84033203  0.7597656  -1.0966797  -0.33984375] 1   1 Match 56\n",
      "\n",
      "[-0.5751953   0.43798828 -0.40185547 -0.14672852 -0.1940918   0.23022461] 1   2 \n",
      "[-0.54541016 -0.09381104 -0.18322754  0.12121582  0.02282715 -0.06140137] 3   3 Match 57\n",
      "\n",
      "[-1.2851562   0.19714355  0.99902344  0.39404297 -0.074646   -0.2788086 ] 2   3 \n",
      "[-0.05895996  0.5625     -0.17932129 -0.20385742 -0.83251953 -0.13146973] 1   1 Match 58\n",
      "\n",
      "[-0.04257202  1.0712891   0.01641846  0.21691895 -0.72558594 -0.4567871 ] 1   1 Match 59\n",
      "\n",
      "[-1.6308594  -0.47460938  0.01956177  0.9472656   0.44580078  0.1616211 ] 3   2 \n",
      "[-0.41381836  0.0006156   0.20336914  0.26171875 -0.34570312 -0.0692749 ] 3   3 Match 60\n",
      "\n",
      "[-2.2558594  -0.5292969  -0.02192688  0.92041016  1.1074219   0.46923828] 4   3 \n",
      "[-2.3691406  -0.6074219  -0.28955078  0.5966797   1.2880859   0.9589844 ] 4   1 \n",
      "[ 0.07019043  0.51123047  0.24731445  0.13623047 -0.5004883  -0.6479492 ] 1   1 Match 61\n",
      "\n",
      "[-2.2714844  -0.08184814  0.12078857  0.91015625  0.6411133   0.10888672] 3   4 \n",
      "[-2.2246094  -0.58935547 -0.4650879   0.7036133   1.3505859   1.3173828 ] 4   5 \n",
      "[-1.9980469  -0.17810059  0.3227539   1.0966797   0.7910156   0.06298828] 3   3 Match 62\n",
      "\n",
      "[-1.2626953  -0.17028809  0.16418457  0.60498047  0.21252441 -0.08276367] 3   3 Match 63\n",
      "\n",
      "[ 0.04110718  0.38378906  0.42773438  0.22265625 -0.7060547  -0.8442383 ] 2   1 \n",
      "[-1.4355469   0.11791992  0.7524414   0.43188477  0.0541687  -0.44604492] 2   3 \n",
      "[-0.7753906   1.6796875  -0.6401367   0.96533203 -1.0742188  -0.60058594] 1   3 \n",
      "[ 1.1767578   1.2011719   0.21875    -0.35742188 -1.2304688  -1.3955078 ] 1   0 \n",
      "[-1.5263672  -0.15539551  0.10693359  0.00365067  0.58935547  0.3737793 ] 4   2 \n",
      "[ 0.3881836   0.5576172   0.24511719  0.14489746 -0.78125    -1.2392578 ] 1   5 \n",
      "[-0.5463867   0.59033203  0.93408203  0.6635742  -0.55566406 -1.0683594 ] 2   2 Match 64\n",
      "\n",
      "[-2.3652344  -0.6459961  -0.29785156  0.77490234  1.3271484   0.8432617 ] 4   4 Match 65\n",
      "\n",
      "[ 0.07415771  0.6767578   0.28320312  0.01516724 -0.5698242  -0.60253906] 1   3 \n",
      "[-0.09326172  0.77246094  0.5942383  -0.34375    -0.7636719  -1.0683594 ] 1   4 \n",
      "[-1.3271484   0.25073242  0.07788086  0.52490234  0.55078125  0.1586914 ] 4   4 Match 66\n",
      "\n",
      "[ 0.734375    1.3271484   0.32910156 -0.00431442 -1.0390625  -0.9604492 ] 1   1 Match 67\n",
      "\n",
      "[-1.7724609  -0.37939453  0.20800781  1.0087891   0.5708008  -0.2211914 ] 3   4 \n",
      "[ 0.2298584   0.47729492 -0.06188965 -0.08459473 -0.8100586  -0.72021484] 1   2 \n",
      "[-1.7431641   0.19885254  0.5571289   0.6611328   0.10162354 -0.5229492 ] 3   1 \n",
      "[-2.0703125  -0.42895508  0.33764648  1.03125     0.86572266 -0.70751953] 3   2 \n",
      "[ 0.24841309  0.5048828   0.20007324  0.31274414 -0.3359375  -0.6640625 ] 1   3 \n",
      "[-1.1660156   0.38989258  1.0263672   0.18041992 -0.18676758 -0.7680664 ] 2   1 \n",
      "[-1.5634766  -0.25097656  0.5209961   1.7138672   0.50097656 -0.8486328 ] 3   3 Match 68\n",
      "\n",
      "[ 0.24035645  0.49389648  0.22705078 -0.07470703 -0.6845703  -0.82177734] 1   0 \n",
      "[-1.6875     -0.18103027 -0.49438477  0.1842041   0.69384766  0.6669922 ] 4   3 \n",
      "[-1.0244141   0.08343506 -0.11798096  0.5883789   0.14013672 -0.33666992] 3   1 \n",
      "[ 0.31469727  0.7495117   1.0107422   0.26782227 -0.69091797 -1.5996094 ] 2   0 \n",
      "[-1.3691406  -0.07287598 -0.08605957  0.1151123   0.5083008   0.1772461 ] 4   0 \n",
      "[-2.515625   -0.5644531  -0.33496094  0.8588867   0.7163086   0.50683594] 3   1 \n",
      "[-0.20935059  0.34155273  0.3461914   0.14733887 -0.46728516 -0.69091797] 2   3 \n",
      "[-0.52978516  0.2927246  -0.08673096 -0.08886719 -0.3864746  -0.11053467] 1   5 \n",
      "[ 1.0654297   0.59716797 -0.19458008 -0.39624023 -0.88916016 -0.6538086 ] 0   0 Match 69\n",
      "\n",
      "[-2.4785156  -0.58691406 -0.41235352  0.8725586   1.1376953   0.98046875] 4   4 Match 70\n",
      "\n",
      "[-0.90234375  0.24316406  1.2841797   0.8432617  -0.35668945 -1.34375   ] 2   2 Match 71\n",
      "\n",
      "[ 0.5185547   0.49658203  0.19042969 -0.01126862 -0.80615234 -0.57177734] 0   2 \n",
      "[-0.4248047   0.55078125 -0.23937988  0.06286621 -0.22497559 -0.01426697] 1   1 Match 72\n",
      "\n",
      "[-0.8486328   0.5703125   0.6533203   0.74560547 -0.3581543  -0.60595703] 3   3 Match 73\n",
      "\n",
      "[-0.8364258   0.40283203  0.6982422   0.37963867 -0.5834961  -0.7807617 ] 2   5 \n",
      "[-0.8305664  -0.3552246   0.88916016  0.6088867   0.21374512 -0.6176758 ] 2   4 \n",
      "[-0.58203125  0.11425781 -0.31762695 -0.02731323 -0.24829102  0.13220215] 5   1 \n",
      "[-0.92578125  0.00238991  0.8828125   0.41235352 -0.35180664 -0.8051758 ] 2   0 \n",
      "[-0.89697266  2.0351562  -0.7109375   1.0732422  -1.1679688  -0.4440918 ] 1   1 Match 74\n",
      "\n",
      "[-1.5664062   0.23864746  0.74902344  1.3232422   0.03509521 -1.1904297 ] 3   3 Match 75\n",
      "\n",
      "[-0.42773438  0.2993164   0.07226562  0.10241699 -0.34960938 -0.25390625] 1   2 \n",
      "[ 0.11260986  0.4909668   0.20776367 -0.0243988  -0.4025879  -0.5957031 ] 1   2 \n",
      "[-0.11230469  0.2685547  -0.13378906 -0.32226562 -0.08905029 -0.17590332] 1   5 \n",
      "[-0.4423828   0.38476562  0.24768066 -0.037323   -0.07751465 -0.25854492] 1   3 \n",
      "[-1.3671875  -0.42626953  0.00846863  0.4267578   0.24267578  0.2368164 ] 3   4 \n",
      "[-1.9765625  -0.36987305 -0.01252747  0.4116211   0.87646484  0.54833984] 4   1 \n",
      "[-1.1298828   0.11920166 -0.11254883  0.12768555  0.13989258  0.09710693] 4   1 \n",
      "[-2.1269531  -0.44677734 -0.04721069  1.3466797   0.6459961   0.02394104] 3   1 \n",
      "[-0.72558594  0.20471191 -0.3798828  -0.30419922 -0.2298584   0.1665039 ] 1   0 \n",
      "[-1.3583984  -0.52783203  0.32104492  0.59228516  0.6435547   0.29125977] 4   4 Match 76\n",
      "\n",
      "[-0.67822266  0.4321289   0.77685547  0.9501953  -0.22717285 -1.3056641 ] 3   1 \n",
      "[ 0.00772095  0.54248047  1.0458984   0.48632812 -0.75097656 -1.2460938 ] 2   3 \n",
      "[-0.15637207  0.01452637  0.15795898  0.0124054  -0.32348633  0.0826416 ] 2   1 \n",
      "[-0.8574219   0.7675781  -0.22851562  0.2763672  -0.23303223 -0.26831055] 1   1 Match 77\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.9208984  -0.5239258  -0.18481445  0.71240234  0.74072266  0.29785156] 4   3 \n",
      "[-0.6821289  -0.17749023  0.15856934  0.32739258 -0.01053619 -0.27563477] 3   0 \n",
      "[-2.0078125  -0.40527344 -0.21350098  0.5463867   0.7890625   0.83203125] 5   5 Match 78\n",
      "\n",
      "[-0.70410156  0.5209961  -0.2175293   0.05517578 -0.12493896  0.14111328] 1   0 \n",
      "[-1.90625    -0.19042969 -0.38208008  0.7285156   0.6098633   0.57470703] 3   3 Match 79\n",
      "\n",
      "[-1.8193359  -0.18762207  0.18188477  0.69384766  0.5371094  -0.16638184] 3   2 \n",
      "[-1.4824219  -0.0586853   0.12493896  0.34204102  0.03970337  0.39868164] 5   0 \n",
      "[-0.11993408  0.2824707   0.92871094  0.1875     -0.55908203 -1.0097656 ] 2   0 \n",
      "[-1.9677734  -0.67822266  0.02638245  1.2431641   0.60791016 -0.05941772] 3   4 \n",
      "[-0.61865234 -0.02648926  0.4086914   0.25708008 -0.17675781 -0.37719727] 2   1 \n",
      "[-1.0917969   0.18676758  1.0380859   0.98046875  0.01512909 -1.1376953 ] 2   2 Match 80\n",
      "\n",
      "[-1.1542969  -0.05111694 -0.32128906  0.10931396  0.11352539  0.8466797 ] 5   3 \n",
      "[-1.8564453  -0.49169922  0.1116333   0.48046875  0.5415039   0.4873047 ] 4   2 \n",
      "[-2.4140625  -0.65478516 -0.5961914   0.6386719   1.4082031   1.2382812 ] 4   5 \n",
      "[-1.0771484   1.8671875  -0.67529297  1.0039062  -1.0429688  -0.22387695] 1   3 \n",
      "[-1.6191406   0.24291992 -0.00917053  0.66308594  0.41796875 -0.06500244] 3   5 \n",
      "[-1.7822266  -0.6665039  -0.1027832   1.2998047   0.63427734 -0.20202637] 3   4 \n",
      "[-2.0800781  -0.5576172  -0.38867188  0.45825195  0.76220703  0.92626953] 5   4 \n",
      "[-1.640625   -0.00617218 -0.44213867  0.41210938  0.3942871   0.6855469 ] 5   1 \n",
      "[-2.5078125 -0.3322754  0.1652832  1.125      0.8989258 -0.0123291] 3   4 \n",
      "[-1.4121094  -0.22460938  0.06427002  0.59277344  0.6123047   0.01464081] 4   3 \n",
      "[-0.79296875  0.06262207  0.47436523  0.6713867  -0.07794189 -0.9975586 ] 3   0 \n",
      "[-2.3066406  -0.16381836  0.11676025  0.60791016  0.5961914   0.29003906] 3   3 Match 81\n",
      "\n",
      "[-1.7919922  -0.3869629  -0.3161621   0.4675293   0.48388672  0.49243164] 5   3 \n",
      "[-1.1005859   1.6943359  -0.61328125  0.98583984 -0.87597656 -0.5239258 ] 1   3 \n",
      "[-1.8535156   0.26733398  0.19799805  1.25        0.37841797 -0.6323242 ] 3   4 \n",
      "[-1.9833984  -0.12597656 -0.02461243  1.0039062   0.5463867  -0.2775879 ] 3   0 \n",
      "[-1.5039062   0.7026367  -0.19055176  0.21716309  0.32250977  0.39257812] 1   1 Match 82\n",
      "\n",
      "[-2.7695312  -0.6298828  -0.36889648  0.9301758   1.4238281   1.0527344 ] 4   4 Match 83\n",
      "\n",
      "[-0.13928223  1.3398438  -0.3540039  -0.16064453 -0.86279297 -0.55126953] 1   1 Match 84\n",
      "\n",
      "[-0.89501953  1.7421875  -0.74121094  1.0654297  -1.0849609  -0.5019531 ] 1   1 Match 85\n",
      "\n",
      "[-0.17016602  0.45263672 -0.37158203 -0.2208252  -0.41748047 -0.01364899] 1   0 \n",
      "[-1.7275391  -0.040802    0.2536621   0.5151367   0.27416992 -0.32373047] 3   2 \n",
      "[-2.2695312  -0.30029297  0.08947754  1.1367188   0.72314453 -0.19580078] 3   4 \n",
      "[-1.2880859   0.4650879   0.6948242   1.0996094   0.05731201 -0.7661133 ] 3   1 \n",
      "[-1.5195312  -0.34033203 -0.02812195  0.70214844  0.34106445  0.16784668] 3   2 \n",
      "[-2.0800781  -0.01395416 -0.3371582   0.43139648  0.81591797  0.66748047] 4   4 Match 86\n",
      "\n",
      "[-2.171875   -0.35107422 -0.59277344  0.34814453  0.94189453  1.1220703 ] 5   1 \n",
      "[-1.6542969   0.02783203  0.375       0.9248047   0.32421875 -0.6660156 ] 3   1 \n",
      "[-2.6289062  -0.6010742  -0.11889648  0.921875    1.0410156   0.53466797] 4   3 \n",
      "[-1.6816406  -0.15637207 -0.4489746   0.26513672  0.578125    0.77978516] 5   5 Match 87\n",
      "\n",
      "[-0.8652344   0.7548828  -0.01779175  0.19848633 -0.40014648 -0.42700195] 1   5 \n",
      "[-1.7646484  -0.27001953 -0.30859375  0.50146484  0.53808594  0.47216797] 4   4 Match 88\n",
      "\n",
      "[-1.1308594  -0.11791992  0.42333984  0.41552734 -0.04663086 -0.71972656] 2   2 Match 89\n",
      "\n",
      "[-1.4316406   0.31469727  0.00289154  0.48876953  0.05648804  0.31640625] 3   5 \n",
      "[-1.9941406  -0.26513672 -0.51171875  0.24768066  0.7788086   0.5576172 ] 4   3 \n",
      "[-1.68261719e+00 -1.16882324e-01  1.46508217e-04  5.18066406e-01\n",
      "  3.31787109e-01  2.97119141e-01] 3   4 \n",
      "[-0.79541016  0.57421875  0.16015625  0.39672852 -0.19958496 -0.5131836 ] 1   1 Match 90\n",
      "\n",
      "[-1.6386719  -0.28686523  0.08575439  1.0615234   1.1269531   0.36816406] 4   3 \n",
      "[ 0.13293457  0.8027344   0.7128906   0.08166504 -0.74316406 -1.2529297 ] 1   1 Match 91\n",
      "\n",
      "[-2.046875    0.19628906  0.02496338  0.39160156  0.32543945  0.22265625] 3   4 \n",
      "[-1.875      -0.02578735  0.19714355  0.61279297  0.10003662  0.04919434] 3   0 \n",
      "[-2.1914062  -0.22888184  0.22717285  0.8652344   0.6411133   0.43481445] 3   5 \n",
      "[-1.9072266  -0.09411621 -0.67871094  0.54833984  0.5136719   1.078125  ] 5   5 Match 92\n",
      "\n",
      "[-1.7734375  -0.3227539  -0.15820312  0.38476562  0.6845703   0.5336914 ] 4   3 \n",
      "[-1.9511719  -0.28955078 -0.31152344  0.5175781   0.59375     0.44726562] 4   3 \n",
      "[-1.8994141  -0.19006348 -0.06622314  0.9975586   0.63134766  0.11315918] 3   3 Match 93\n",
      "\n",
      "[-1.7607422  -0.19946289 -0.14562988  0.33935547  0.39013672  0.35205078] 4   4 Match 94\n",
      "\n",
      "[-2.6660156  -0.93066406 -0.26293945  0.9589844   1.2939453   0.6640625 ] 4   4 Match 95\n",
      "\n",
      "[-1.8173828  -0.38598633  0.07641602  0.6274414   0.5727539  -0.20056152] 3   2 \n",
      "[-1.6123047  -0.08215332 -0.18188477  0.34057617  0.21276855  0.5913086 ] 5   1 \n",
      "[ 0.4807129   1.421875    0.17102051 -0.00788879 -0.90234375 -1.4296875 ] 1   1 Match 96\n",
      "\n",
      "[ 0.11779785  0.8720703   0.5253906   0.0881958  -0.75878906 -1.53125   ] 1   0 \n",
      "[-1.5332031  -0.30859375 -0.22949219  0.10534668  0.72509766  0.9941406 ] 5   5 Match 97\n",
      "\n",
      "[-2.453125   -0.56933594 -0.67626953  0.44335938  1.2490234   1.0585938 ] 4   3 \n",
      "[-1.3613281  -0.0993042  -0.38916016 -0.10192871  0.34521484  1.0498047 ] 5   5 Match 98\n",
      "\n",
      "[-2.0039062  -0.04901123 -0.09942627  0.6035156   0.5263672  -0.0736084 ] 3   1 \n",
      "[-0.9033203   0.18884277  0.4255371   0.4296875   0.2529297  -0.7446289 ] 3   5 \n",
      "[-1.3017578   0.05505371  0.77978516  1.4755859   0.2097168  -1.0205078 ] 3   4 \n",
      "[-1.5400391   0.0836792   0.22570801  0.5732422   0.36035156  0.11218262] 3   3 Match 99\n",
      "\n",
      "[-0.8198242   1.0263672  -0.00592804  0.3317871  -0.59033203 -0.48242188] 1   2 \n",
      "[-0.5644531   0.12042236 -0.38330078 -0.12915039 -0.53564453  0.07183838] 1   0 \n",
      "[ 0.27685547  0.5209961   0.0222168  -0.13769531 -0.66015625 -0.48388672] 1   1 Match 100\n",
      "\n",
      "[-1.2470703  -0.05215454 -0.27197266  0.17053223  0.05484009  0.47875977] 5   5 Match 101\n",
      "\n",
      "[-1.3876953   0.12512207 -0.4794922   0.515625   -0.1038208   0.04397583] 3   3 Match 102\n",
      "\n",
      "[-1.6923828  -0.18640137 -0.00685883  0.60791016  0.44555664  0.01509094] 3   4 \n",
      "[-0.94921875  0.32495117  0.09143066  0.4477539  -0.16625977 -0.17321777] 3   1 \n",
      "[-2.2460938  -0.18444824 -0.39648438  0.49267578  1.4492188   1.0419922 ] 4   1 \n",
      "[-1.6152344   0.37963867  0.5180664   1.2001953  -0.00357819 -0.65722656] 3   3 Match 103\n",
      "\n",
      "[-1.7714844  -0.07348633 -0.31176758  0.52441406  0.27294922  0.18469238] 3   4 \n",
      "[-1.0517578   0.00455093  0.19799805  0.17004395 -0.1171875   0.11993408] 2   1 \n",
      "[-0.60546875  0.80908203  0.53027344  0.7998047  -0.47338867 -1.0390625 ] 1   3 \n",
      "[-0.12646484  0.6357422   0.21887207  0.4868164  -0.24511719 -0.5107422 ] 1   5 \n",
      "[-0.2866211   0.27148438 -0.09313965  0.11169434 -0.04779053 -0.37231445] 1   2 \n",
      "[-1.5751953  -0.31152344  0.35913086  0.86865234  0.35913086 -0.45043945] 3   3 Match 104\n",
      "\n",
      "[-1.4677734   1.4521484  -0.55615234  1.1484375  -0.8310547  -0.23815918] 1   3 \n",
      "[-0.59033203  0.31884766  0.2241211   0.05383301 -0.32543945 -0.38305664] 1   2 \n",
      "[ 0.61279297  0.90966797  0.40771484  0.02818298 -0.5058594  -1.0732422 ] 1   3 \n",
      "[-0.2770996   0.58935547  0.14672852  0.02388    -0.6035156  -0.59033203] 1   0 \n",
      "[-2.3515625  -0.41723633 -0.2055664   0.9892578   0.94628906  0.8564453 ] 3   4 \n",
      "[-0.8901367   0.39868164 -0.11407471  0.30810547 -0.04736328 -0.53564453] 1   1 Match 105\n",
      "\n",
      "[-1.9853516  -0.5917969  -0.41601562  0.5239258   1.2705078   0.8852539 ] 4   3 \n",
      "[-1.9003906  -0.23461914  0.27612305  0.76660156  0.4387207  -0.49560547] 3   3 Match 106\n",
      "\n",
      "[-0.9501953   2.0039062  -0.38916016  1.2333984  -1.0039062  -0.6645508 ] 1   5 \n",
      "[-0.6533203   0.09692383  0.0541687   0.31689453  0.07025146  0.16589355] 3   4 \n",
      "[ 0.48876953  1.2480469   0.07220459 -0.34936523 -1.0644531  -0.796875  ] 1   1 Match 107\n",
      "\n",
      "[-1.1943359  -0.05239868 -0.3046875   0.34643555  0.13671875  0.38867188] 5   2 \n",
      "[-1.6279297  -0.39501953 -0.56884766  0.4177246   0.8149414   0.7338867 ] 4   4 Match 108\n",
      "\n",
      "[-1.5097656   0.00965881 -0.2409668   0.29907227  0.33666992  0.10009766] 4   1 \n",
      "[-0.94628906  0.06945801 -0.09222412  0.12207031 -0.06665039  0.13269043] 5   1 \n",
      "[-0.95410156  1.9013672  -0.82470703  0.9970703  -1.1201172  -0.35766602] 1   1 Match 109\n",
      "\n",
      "[-0.08447266  0.01335907  0.26391602  0.08685303 -0.16357422 -0.578125  ] 2   2 Match 110\n",
      "\n",
      "[-1.3925781  -0.05145264 -0.12963867  0.03686523  0.3642578   0.2866211 ] 4   0 \n",
      "[ 0.2902832   0.56640625 -0.05154419 -0.0486145  -0.57714844 -0.7011719 ] 1   4 \n",
      "[-1.3994141   0.14367676 -0.22290039  0.17626953  0.35839844  0.24291992] 4   1 \n",
      "[-2.1660156  -0.51953125 -0.5698242   0.73046875  1.0429688   1.1337891 ] 5   4 \n",
      "[-0.8076172   0.20739746 -0.01785278  0.10296631  0.14038086  0.23144531] 5   1 \n",
      "[-1.3066406  -0.35327148 -0.34057617  0.31567383  0.65625     0.05187988] 4   0 \n",
      "[-0.7470703   0.1887207  -0.25830078  0.00832367 -0.07318115  0.46142578] 5   1 \n",
      "[-2.0019531  -0.29711914 -0.85498047  0.47387695  0.9770508   1.2490234 ] 5   5 Match 111\n",
      "\n",
      "[-1.6230469  -0.13049316 -0.27246094  0.0082016   0.7397461   0.6640625 ] 4   4 Match 112\n",
      "\n",
      "[-2.0332031  -0.6621094  -0.35717773  0.58740234  1.1660156   0.81591797] 4   5 \n",
      "[-2.2011719  -0.1036377  -0.16101074  1.0078125   0.421875    0.39013672] 3   1 \n",
      "[-2.7226562  -0.875      -0.31933594  1.1474609   1.5546875   0.7939453 ] 4   3 \n",
      "[-2.2070312  -0.39892578 -0.50146484  0.6113281   1.2548828   0.97265625] 4   2 \n",
      "[-1.5332031  -0.00437164 -0.33520508  0.15930176  0.6616211   0.20373535] 4   2 \n",
      "[-0.7050781   0.31982422 -0.48583984 -0.18774414 -0.06860352  0.44580078] 5   1 \n",
      "[-2.0820312  -0.45996094 -0.40307617  0.4621582   0.94628906  0.9736328 ] 5   4 \n",
      "[-1.5371094   0.15368652 -0.30200195  0.2019043   0.734375    0.6899414 ] 4   1 \n",
      "[-1.0625      0.45092773  0.45751953  1.2626953   0.14660645 -1.0507812 ] 3   4 \n",
      "[-1.8662109  -0.03189087  0.09094238  0.43945312  0.5239258   0.02615356] 4   3 \n",
      "[ 0.17456055  0.859375    0.19812012 -0.15441895 -0.91503906 -0.84716797] 1   3 \n",
      "[-1.7900391  -0.02949524 -0.34204102  0.3137207   0.6191406   0.59228516] 4   3 \n",
      "[-2.3964844  -0.5263672  -0.22705078  1.3291016   0.9663086  -0.36987305] 3   3 Match 113\n",
      "\n",
      "[ 0.17443848  0.27368164  0.07720947 -0.14648438 -0.3388672  -0.3190918 ] 1   2 \n",
      "[-2.09375     0.12915039  0.30322266  0.6220703   0.6142578   0.5395508 ] 3   1 \n",
      "[-1.5664062  -0.04492188 -0.14147949  0.2479248   0.09637451  0.08392334] 3   3 Match 114\n",
      "\n",
      "[-0.9145508   0.20874023 -0.26904297  0.19238281 -0.13366699  0.04092407] 1   3 \n",
      "[ 0.7578125   0.8256836   0.84375     0.19543457 -0.7246094  -2.        ] 2   1 \n",
      "[-0.99316406  1.9990234  -0.80126953  0.99316406 -1.1054688  -0.4206543 ] 1   1 Match 115\n",
      "\n",
      "[-0.52197266  0.19848633  0.14831543  0.58984375 -0.08135986 -0.6772461 ] 3   1 \n",
      "[-0.5644531  -0.04428101  0.6088867   0.4621582  -0.31445312 -0.3798828 ] 2   4 \n",
      "[-1.6894531  -0.22766113  0.5756836   1.1699219   0.3984375  -0.7363281 ] 3   3 Match 116\n",
      "\n",
      "[-1.5625      0.0519104  -0.00783539  0.88134766  0.31225586 -0.15197754] 3   3 Match 117\n",
      "\n",
      "[ 0.12646484  2.0136719  -0.29125977  0.61621094 -1.2060547  -0.6352539 ] 1   1 Match 118\n",
      "\n",
      "[-0.70214844  0.03390503 -0.1730957   0.02249146  0.34643555  0.17077637] 4   4 Match 119\n",
      "\n",
      "[-2.5839844  -0.33764648 -0.40673828  0.83496094  1.2392578   1.1835938 ] 4   4 Match 120\n",
      "\n",
      "[-2.0585938   0.26391602  0.4567871   1.2167969   0.21960449 -0.3071289 ] 3   4 \n",
      "[ 0.06488037  0.73535156 -0.09338379  0.21862793 -0.53808594 -0.82958984] 1   4 \n",
      "[ 0.47314453  0.61279297  0.71191406 -0.01989746 -0.69873047 -1.4404297 ] 2   0 \n",
      "[ 0.0635376  0.8178711  0.734375   0.4831543 -0.8051758 -1.7539062] 1   1 Match 121\n",
      "\n",
      "[-2.2402344  -0.48535156 -0.24536133  0.4025879   1.2373047   0.95703125] 4   4 Match 122\n",
      "\n",
      "[-2.0664062  -0.51464844 -0.44995117  0.3647461   0.5527344   0.96435547] 5   5 Match 123\n",
      "\n",
      "[-0.17346191  0.5810547  -0.14050293 -0.2010498  -0.48461914 -0.33447266] 1   1 Match 124\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[-1.6884766  -0.10510254 -0.10614014  0.39501953  0.5913086   0.7988281 ] 5   3 \n",
      "[-1.2666016  -0.21252441 -0.4189453   0.14648438  0.53515625  0.5136719 ] 4   3 \n",
      "[-1.6396484  -0.5576172  -0.5991211   0.47827148  0.87890625  0.92089844] 5   4 \n",
      "[-1.5195312   0.38891602  0.2211914   0.8911133   0.18408203  0.05734253] 3   3 Match 125\n",
      "\n",
      "[ 0.1739502   0.6455078   0.78564453  0.49194336 -0.5551758  -1.4453125 ] 2   1 \n",
      "[-0.8208008   0.36645508 -0.22314453  0.12017822 -0.1953125   0.1784668 ] 1   4 \n",
      "[-1.9208984  -0.40356445 -0.4169922   0.68310547  1.125       0.25512695] 4   2 \n",
      "[-0.03860474  0.6533203   0.35058594  0.1352539  -0.3942871  -0.7680664 ] 1   0 \n",
      "[ 0.00460815  0.7363281   0.42773438 -0.02037048 -0.56640625 -0.9433594 ] 1   1 Match 126\n",
      "\n",
      "[-1.7460938   0.20361328 -0.5703125   0.34423828  0.5732422   0.6767578 ] 5   1 \n",
      "[-1.8798828  -0.42260742 -0.38867188  0.73779297  0.5600586   0.43481445] 3   5 \n",
      "[-2.5136719  -0.33642578 -0.12182617  1.2529297   0.7636719  -0.03475952] 3   4 \n",
      "[-1.1494141   0.09191895 -0.65185547 -0.23535156  0.8051758   1.2392578 ] 5   4 \n",
      "[-0.35473633  0.15942383  0.5605469   0.04074097 -0.48828125 -0.54785156] 2   0 \n",
      "[-1.7695312  -0.18273926 -0.44140625  0.45507812  0.8330078   0.7602539 ] 4   5 \n",
      "[-2.5097656  -0.7675781  -0.48901367  0.9091797   1.4541016   1.0351562 ] 4   5 \n",
      "[-0.43041992  0.3137207  -0.47583008 -0.14587402 -0.13830566  0.08551025] 1   1 Match 127\n",
      "\n",
      "[-0.25830078  0.22216797  0.26586914 -0.01428986 -0.17321777 -0.48608398] 2   3 \n",
      "[-1.8955078  -0.23815918 -0.4074707   0.42089844  0.56933594  0.4873047 ] 4   3 \n",
      "[-0.98535156  0.22387695  0.34350586  0.77490234 -0.12188721 -0.7685547 ] 3   1 \n",
      "[-2.2714844  -0.2746582  -0.02438354  0.95947266  0.5341797   0.24938965] 3   3 Match 128\n",
      "\n",
      "[-1.8408203  -0.17773438 -0.2133789   0.9511719   0.6035156   0.4489746 ] 3   4 \n",
      "[-2.2929688  -0.77001953 -0.05737305  1.1923828   1.4912109   0.50390625] 4   3 \n",
      "[-0.10595703  0.6772461  -0.11291504  0.00508881 -0.67333984 -0.36743164] 1   5 \n",
      "[-1.7470703  -0.22143555 -0.2783203   0.16381836  0.7167969   0.765625  ] 5   1 \n",
      "[-1.1650391  -0.07519531 -0.03979492  0.38671875  0.6484375   0.1854248 ] 4   2 \n",
      "[-2.0175781  -0.16247559 -0.3330078   0.91796875  0.39819336  0.11462402] 3   4 \n",
      "[-9.5800781e-01  8.4045410e-02  9.1992188e-01  7.1679688e-01\n",
      "  1.4662743e-04 -7.5048828e-01] 2   3 \n",
      "[-2.4160156  -0.73535156 -0.33911133  0.84472656  1.2412109   0.52685547] 4   2 \n",
      "[-1.5654297   0.03857422  0.31860352  0.58984375  0.17504883 -0.25317383] 3   4 \n",
      "[-1.0107422   0.19421387  0.38671875  1.0693359  -0.12347412 -1.0136719 ] 3   3 Match 129\n",
      "\n",
      "[-0.14794922 -0.09387207 -0.15258789 -0.06396484 -0.17260742  0.25878906] 5   4 \n",
      "[-0.9682617   0.02322388 -0.27368164  0.6855469   0.74609375  0.11175537] 4   0 \n",
      "[-2.7578125  -0.73876953 -0.25146484  0.9135742   1.5097656   0.9555664 ] 4   5 \n",
      "[-0.2878418   0.44677734  0.62109375  0.2626953  -0.65283203 -0.6826172 ] 2   5 \n",
      "[-0.41723633  0.69970703  0.39770508  0.2241211  -0.41357422 -0.58691406] 1   2 \n",
      "[-2.1308594  -0.26904297 -0.10888672  0.5073242   0.63623047  0.09979248] 4   1 \n",
      "[-2.0527344  -0.16577148 -0.3725586   0.7871094   0.59814453  0.19396973] 3   4 \n",
      "[-0.8232422  -0.12988281 -0.24182129 -0.25073242  0.24987793  0.4350586 ] 5   2 \n",
      "[-2.0117188  -0.45581055  0.3166504   1.1142578   0.36328125 -0.50439453] 3   3 Match 130\n",
      "\n",
      "[-1.6757812  -0.3317871   0.45581055  0.2084961   0.4819336  -0.17712402] 4   2 \n",
      "[-0.3383789   0.35058594  0.49414062  0.5732422   0.04150391 -0.8305664 ] 3   1 \n",
      "[-1.2753906   0.13989258 -0.41357422  0.20031738  0.49194336  0.66015625] 5   5 Match 131\n",
      "\n",
      "[-0.22546387 -0.02955627  0.75146484  0.8652344  -0.27563477 -1.3876953 ] 3   1 \n",
      "[-1.2333984  -0.00146866  0.05221558  0.25708008  0.4248047   0.40112305] 4   1 \n",
      "[-1.3105469   0.08197021  0.9140625   0.97314453 -0.03833008 -1.4902344 ] 3   3 Match 132\n",
      "\n",
      "[-1.9248047  -0.7788086   0.12011719  1.2099609   0.73535156 -0.39624023] 3   3 Match 133\n",
      "\n",
      "[-2.0253906  -0.38208008 -0.36035156  0.34033203  0.76904297  0.60546875] 4   4 Match 134\n",
      "\n",
      "[-2.5839844  -0.75341797 -0.11560059  1.28125     1.3642578   0.22314453] 4   4 Match 135\n",
      "\n",
      "[-2.3164062  -0.5415039   0.3840332   1.1005859   1.0693359  -0.41064453] 3   5 \n",
      "[-2.7109375  -1.1083984  -0.36767578  1.5712891   1.1503906  -0.03533936] 3   3 Match 136\n",
      "\n",
      "[-2.625     -0.7055664 -0.2861328  0.9477539  1.0957031  0.6928711] 4   1 \n",
      "[-0.6201172   0.6791992   0.9819336   0.33862305 -0.58691406 -1.5839844 ] 2   1 \n",
      "[-2.0410156  -0.20910645 -0.18615723  1.1494141   0.4074707  -0.02023315] 3   5 \n",
      "[-0.36865234  0.38427734  0.9863281   0.59277344 -0.4326172  -1.6962891 ] 2   2 Match 137\n",
      "\n",
      "[-1.9423828  -0.15161133 -0.6303711   0.2529297   0.7832031   0.9794922 ] 5   3 \n",
      "[-2.1816406  -0.4609375  -0.27490234  0.5522461   1.0478516   0.7709961 ] 4   4 Match 138\n",
      "\n",
      "[-1.7773438  -0.4284668  -0.1451416   0.47875977  0.69677734  0.07086182] 4   1 \n",
      "[-0.62890625  0.7602539   0.94091797  0.875      -0.10784912 -0.88134766] 2   3 \n",
      "[-1.6552734   0.01437378  0.34545898  0.45483398  0.2705078  -0.2376709 ] 3   1 \n",
      "[-0.1496582   0.6640625   0.1038208  -0.21203613 -0.47045898 -0.30664062] 1   3 \n",
      "[-0.08288574  1.0644531   0.63134766  0.41259766 -0.609375   -1.6435547 ] 1   1 Match 139\n",
      "\n",
      "[-1.3310547   0.15588379  0.2705078   0.42895508  0.08673096 -0.06311035] 3   3 Match 140\n",
      "\n",
      "[-0.19604492  0.21325684  0.54003906  0.47851562 -0.11383057 -1.3398438 ] 2   2 Match 141\n",
      "\n",
      "[-2.2597656  -0.36621094  0.14538574  0.859375    0.8100586   0.67041016] 3   5 \n",
      "[-0.97998047  0.34765625 -0.11956787  0.06878662  0.05023193  0.3630371 ] 5   1 \n",
      "[-1.7490234  -0.68847656 -0.55126953  0.4572754   1.3271484   1.1513672 ] 4   3 \n",
      "[-1.4111328   0.4633789   0.21740723  0.36499023  0.11914062 -0.29370117] 1   3 \n",
      "[ 0.00770569  0.48364258  0.27001953 -0.04324341 -0.5209961  -0.71533203] 1   3 \n",
      "[-1.4355469  -0.09411621  0.24072266  0.66308594  0.18530273 -0.1538086 ] 3   3 Match 142\n",
      "\n",
      "[-1.9287109  -0.42260742  0.69140625  1.0996094   0.42358398 -0.25219727] 3   4 \n",
      "[-1.5742188  -0.27539062  0.04568481  0.42749023  0.35083008  0.46411133] 5   3 \n",
      "[-0.22265625  0.44213867  0.921875    1.2509766  -0.21362305 -1.8769531 ] 3   3 Match 143\n",
      "\n",
      "[-1.1611328  -0.03161621  0.26757812  0.5419922   0.40551758 -0.07397461] 3   5 \n",
      "[-1.8779297  -0.55615234 -0.34570312  0.9458008   1.03125     0.6201172 ] 4   4 Match 144\n",
      "\n",
      "[-2.3867188  -0.66064453 -0.09649658  1.1484375   1.2988281   0.5488281 ] 4   5 \n",
      "[-0.85498047  0.4645996   0.04104614  0.03686523 -0.39086914 -0.2388916 ] 1   1 Match 145\n",
      "\n",
      "[-1.0253906  -0.3293457   0.5253906   0.5292969   0.36621094 -0.44995117] 3   2 \n",
      "[-1.8134766  -0.3720703  -0.12524414  0.26953125  0.78027344  0.8359375 ] 5   4 \n",
      "[-1.5878906  -0.18579102  0.05984497  0.7553711   0.40795898  0.06201172] 3   2 \n",
      "[ 0.5932617   0.4873047  -0.04824829 -0.22949219 -0.70458984 -0.41723633] 0   2 \n",
      "[-1.1240234   0.11254883 -0.13476562  0.02468872 -0.10699463  0.59375   ] 5   3 \n",
      "[-1.3808594   0.01187897 -0.5864258   0.24780273  0.35961914  0.7675781 ] 5   5 Match 146\n",
      "\n",
      "[-1.3154297   0.8251953   0.26611328  0.40551758 -0.32495117 -0.03302002] 1   2 \n",
      "[-1.25       -0.01522827 -0.07171631  0.42895508  0.30078125 -0.04611206] 3   0 \n",
      "[-2.5859375  -0.47924805 -0.40307617  1.4257812   1.3408203   0.36254883] 3   4 \n",
      "[-1.2607422   0.5830078   0.5629883   0.8676758  -0.15136719 -1.1962891 ] 3   1 \n",
      "[-0.17565918  1.0761719   0.9316406   0.40405273 -0.6821289  -1.0126953 ] 1   1 Match 147\n",
      "\n",
      "[ 1.9257812   1.2792969   0.2052002  -0.37573242 -1.09375    -1.7080078 ] 0   0 Match 148\n",
      "\n",
      "[-0.6113281   0.45947266  0.69628906  1.0302734  -0.23303223 -1.8837891 ] 3   3 Match 149\n",
      "\n",
      "[-1.6621094  -0.3486328  -0.6743164   0.07165527  0.7480469   0.96240234] 5   4 \n",
      "[-0.51708984  0.04602051  0.24169922  0.22277832 -0.02075195 -0.77246094] 2   0 \n",
      "[-2.3183594  -0.4580078  -0.51171875  0.49926758  1.0634766   1.0322266 ] 4   4 Match 150\n",
      "\n",
      "[ 1.2246094  1.0927734  0.5678711  0.1694336 -0.6401367 -1.4492188] 0   3 \n",
      "[-2.0976562  -0.8022461   0.16516113  0.8647461   1.0068359  -0.14172363] 4   5 \n",
      "[-0.16540527  0.26660156  0.47045898  0.47485352 -0.30908203 -0.7626953 ] 3   1 \n",
      "[-0.28930664  0.5942383   1.3359375   0.3256836  -0.5366211  -1.3544922 ] 2   3 \n",
      "[-2.2226562  -0.4140625  -0.3725586   0.7338867   0.98095703  0.96728516] 4   5 \n",
      "[-1.1845703  -0.18774414 -0.03030396  0.01683044  0.8022461   0.46704102] 4   3 \n",
      "[-0.73535156  0.49194336  0.83154297  0.7578125  -0.24560547 -1.2148438 ] 2   1 \n",
      "[-2.421875   -0.8833008  -0.36791992  0.65283203  1.2636719   0.81347656] 4   4 Match 151\n",
      "\n",
      "[-1.6113281   0.10308838 -0.47021484 -0.12573242  1.0058594   1.0673828 ] 5   3 \n",
      "[-2.2617188  -0.14111328 -0.00486374  0.55810547  0.5756836   0.13513184] 4   3 \n",
      "[ 0.17028809  0.7988281   0.55371094  0.8491211  -0.4189453  -1.6679688 ] 3   3 Match 152\n",
      "\n",
      "[-2.0234375  -0.39038086 -0.5859375   0.47607422  1.1113281   0.73535156] 4   5 \n",
      "[ 1.1123047   1.4003906   0.7402344   0.04855347 -1.1953125  -1.9208984 ] 1   1 Match 153\n",
      "\n",
      "[-1.0771484   0.01448059  0.17114258  0.12329102  0.36328125  0.04721069] 4   1 \n",
      "[-1.7509766  -0.4658203  -0.3203125   0.48168945  0.58935547  0.9980469 ] 5   4 \n",
      "[-2.0234375  -0.06152344 -0.37353516  0.37280273  1.1708984   0.8300781 ] 4   5 \n",
      "[-0.83154297  0.2668457  -0.09552002  0.06915283  0.49267578  0.15356445] 4   3 \n",
      "[-1.2197266  -0.16699219  0.26367188  1.1298828   0.5620117  -0.49072266] 3   5 \n",
      "[ 1.3505859   0.8618164   0.10546875 -0.4013672  -0.9658203  -1.0039062 ] 0   1 \n",
      "[-2.7109375  -0.81640625 -0.35546875  1.0537109   1.3789062   0.9765625 ] 4   5 \n",
      "[-1.6953125   0.00565338  0.2644043   1.2021484   0.3395996  -0.5678711 ] 3   1 \n",
      "[ 0.13220215  0.57910156  0.4165039   0.20825195 -0.6040039  -0.8979492 ] 1   3 \n",
      "[-0.9291992   0.21899414  1.1347656   0.8300781   0.16125488 -0.7265625 ] 2   5 \n",
      "[-2.6015625  -0.7036133  -0.45410156  0.6044922   1.1962891   1.0566406 ] 4   4 Match 154\n",
      "\n",
      "[-1.6005859   0.0826416  -0.28930664  0.5932617   0.15710449  0.29785156] 3   1 \n",
      "[-1.1748047  -0.02058411 -0.2536621   0.00118065  0.47460938  0.20788574] 4   5 \n",
      "[-1.3613281   0.14904785 -0.42382812 -0.10015869  0.22692871  0.36669922] 5   2 \n",
      "[-1.3789062   0.20690918  0.4753418   0.4309082   0.25       -0.45092773] 2   3 \n",
      "[-2.2089844  -0.19873047 -0.11437988  0.67529297  0.51953125  0.25610352] 3   3 Match 155\n",
      "\n",
      "[-2.1660156  -0.24621582 -0.11120605  0.90771484  0.68652344  0.18603516] 3   5 \n",
      "[-1.7119141  -0.31152344 -0.14611816  0.9379883   0.67089844  0.17297363] 3   5 \n",
      "[ 1.4121094   0.90771484 -0.27783203 -0.27929688 -1.1054688  -0.84033203] 0   2 \n",
      "[ 0.15515137  0.40283203  0.2578125   0.3840332  -0.39013672 -0.7939453 ] 1   0 \n",
      "[-1.5664062  -0.0121994  -0.5761719   0.00517273  0.5786133   0.49951172] 4   1 \n",
      "[-0.42919922  0.5527344   0.6245117   0.2109375  -0.24682617 -0.95947266] 2   1 \n",
      "[-2.3847656  -0.41601562  0.03607178  0.8964844   0.703125    0.08752441] 3   3 Match 156\n",
      "\n",
      "[-1.0644531   0.46289062 -0.50341797  0.3088379  -0.22937012 -0.06695557] 1   1 Match 157\n",
      "\n",
      "[ 0.09942627  0.6303711   0.15026855 -0.4128418  -0.22802734 -0.8496094 ] 1   0 \n",
      "[-0.4206543   0.48876953  0.20874023  1.0234375   0.13720703 -0.7636719 ] 3   2 \n",
      "[-1.1611328  -0.07147217 -0.49023438 -0.18017578  0.2927246   0.9013672 ] 5   5 Match 158\n",
      "\n",
      "[-1.2402344   0.03735352 -0.13146973  0.6435547   0.1505127  -0.20263672] 3   3 Match 159\n",
      "\n",
      "[-1.8857422  -0.50390625 -0.5493164   0.5004883   0.7363281   0.6689453 ] 4   5 \n",
      "[-2.5839844 -0.6743164 -0.5292969  0.7993164  1.4384766  0.9248047] 4   3 \n",
      "[-0.8642578   0.25634766  0.4165039   0.39672852 -0.32250977 -0.61279297] 2   2 Match 160\n",
      "\n",
      "[-2.3222656   0.03137207 -0.18457031  0.49804688  0.7216797   0.74365234] 5   1 \n",
      "[-1.5107422   0.11499023 -0.36206055  0.28125     0.68066406  0.54052734] 4   3 \n",
      "[-1.1845703   0.42382812  0.15185547  0.22058105 -0.01029968 -0.17016602] 1   0 \n",
      "[-1.796875    0.6040039   0.26000977  0.6147461   0.28076172 -0.12841797] 3   5 \n",
      "[-2.1269531  -0.16223145 -0.20471191  0.40185547  0.69677734  0.71435547] 5   4 \n",
      "[-1.6787109  -0.28173828  0.20410156  0.41308594  0.3630371   0.08355713] 3   2 \n",
      "[-0.03390503  0.28100586  0.13134766 -0.2446289  -0.3491211  -0.20275879] 1   1 Match 161\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.9243164  -0.16845703 -0.16430664 -0.03933716  0.29296875  0.44433594] 5   3 \n",
      "[-0.3371582   0.42993164  0.68310547  0.6591797  -0.35839844 -1.6787109 ] 2   1 \n",
      "[ 0.64501953  0.98291016  0.3552246   0.04360962 -0.79833984 -1.3544922 ] 1   1 Match 162\n",
      "\n",
      "[-0.34399414  0.4663086  -0.00399017 -0.03549194 -0.56689453  0.05715942] 1   2 \n",
      "[-1.8027344   0.27807617  0.26953125  0.48046875 -0.09857178 -0.14807129] 3   3 Match 163\n",
      "\n",
      "[-0.95166016  0.17541504  0.51660156  0.53125    -0.08648682 -1.0976562 ] 3   3 Match 164\n",
      "\n",
      "[-0.3017578   0.22094727  0.5395508   0.61865234 -0.5229492  -0.71728516] 3   2 \n",
      "[-1.7949219   0.21691895 -0.22827148  0.21887207  0.35107422  0.7402344 ] 5   2 \n",
      "[-0.68115234 -0.0914917  -0.16564941  0.06652832  0.21716309 -0.15307617] 4   1 \n",
      "[-0.6826172   1.8964844  -0.34594727  0.6376953  -1.3828125  -0.28857422] 1   5 \n",
      "[-2.5410156  -0.51904297 -0.3803711   0.6748047   1.0419922   1.1044922 ] 5   5 Match 165\n",
      "\n",
      "[-0.62060547  0.76171875  0.59228516  1.0234375  -0.28808594 -1.3945312 ] 3   1 \n",
      "[-1.5126953  -0.49365234 -0.3569336   0.6303711   0.56884766  0.6142578 ] 3   1 \n",
      "[-0.23376465  0.26245117  1.2744141   0.65527344 -0.19262695 -1.5146484 ] 2   0 \n",
      "[-2.0488281  -0.13183594 -0.46264648  0.5888672   0.91552734  0.49609375] 4   1 \n",
      "[-1.859375   -0.38378906 -0.12164307  0.6113281   0.88671875  0.7651367 ] 4   3 \n",
      "[-1.2705078  -0.11505127  0.44213867  1.5117188   0.39575195 -0.8881836 ] 3   4 \n",
      "[-0.94091797  0.3984375   0.20227051  0.6503906  -0.06994629 -0.8051758 ] 3   1 \n",
      "[-1.4755859   0.02420044  0.16711426  0.72216797  0.22607422 -0.30297852] 3   3 Match 166\n",
      "\n",
      "[-0.24267578  0.1821289   0.21557617  0.2097168  -0.07824707 -0.60009766] 2   5 \n",
      "[-1.8701172  -0.6064453  -0.04516602  1.4355469   0.7626953  -0.12249756] 3   3 Match 167\n",
      "\n",
      "[-1.9619141  -0.39526367 -0.6230469   0.17895508  0.88671875  1.0722656 ] 5   3 \n",
      "[ 1.4863281   0.66748047  0.06036377 -0.0430603  -0.83496094 -1.2021484 ] 0   0 Match 168\n",
      "\n",
      "[-0.42822266  0.3774414  -0.21862793 -0.31469727 -0.31420898  0.11395264] 1   1 Match 169\n",
      "\n",
      "[-2.609375   -0.5058594  -0.3779297   0.51220703  1.1240234   0.9794922 ] 4   2 \n",
      "[-2.171875   -0.2548828  -0.45288086  0.45898438  1.0078125   1.0273438 ] 5   2 \n",
      "[-0.5073242   0.38110352 -0.20959473 -0.16796875 -0.39819336  0.19543457] 1   4 \n",
      "[ 1.0029297   0.65185547  0.8803711   0.5546875  -0.65771484 -1.6708984 ] 0   3 \n",
      "[-2.3730469  -0.76660156 -0.44091797  0.53808594  1.6396484   1.0742188 ] 4   4 Match 170\n",
      "\n",
      "[ 0.7895508   1.1787109   0.4699707   0.12005615 -0.6230469  -1.5576172 ] 1   2 \n",
      "[-0.9399414   0.13659668  0.5566406   0.28979492 -0.33032227 -0.9160156 ] 2   2 Match 171\n",
      "\n",
      "[-1.5673828  -0.04644775  0.24377441  1.0869141   0.4580078  -0.34277344] 3   1 \n",
      "[ 0.73779297  1.4296875   0.36914062 -0.09033203 -1.1669922  -1.4560547 ] 1   0 \n",
      "[-1.3222656   0.09906006 -0.29541016  0.12194824 -0.11273193  0.05279541] 3   1 \n",
      "[-1.9208984  -0.14929199 -0.66796875  0.28857422  0.61279297  0.8413086 ] 5   1 \n",
      "[ 0.05758667  0.65966797  1.0175781   0.66308594 -0.63183594 -1.6523438 ] 2   2 Match 172\n",
      "\n",
      "[-0.8149414   0.16430664 -0.06976318  0.45239258  0.19458008 -0.10821533] 3   5 \n",
      "[-2.7265625  -0.63964844 -0.4165039   1.0576172   1.5810547   0.86279297] 4   3 \n",
      "[-2.0878906  -0.7949219  -0.21118164  0.9980469   1.3261719   0.6069336 ] 4   2 \n",
      "[-2.2050781  -0.43920898  0.11950684  1.2109375   0.78759766 -0.40063477] 3   2 \n",
      "[ 0.72509766  0.46044922  0.44384766 -0.25219727 -0.6152344  -1.0332031 ] 0   0 Match 173\n",
      "\n",
      "[-2.0527344 -0.2290039 -0.6533203  0.5097656  0.7026367  0.5654297] 4   3 \n",
      "[-0.48461914  0.77734375  0.35620117  0.2939453  -0.6459961  -0.95410156] 1   2 \n",
      "[-0.11901855  0.40820312  0.9472656   0.4338379  -0.28686523 -1.3789062 ] 2   3 \n",
      "[ 0.48828125  1.2919922   0.3425293   0.0486145  -0.84716797 -1.5976562 ] 1   0 \n",
      "[-2.1816406  -0.1116333   0.0994873   0.43676758  0.7705078   0.15686035] 4   1 \n",
      "[-1.6416016  -0.6225586   0.4074707   0.62841797  0.5991211  -0.3720703 ] 3   4 \n",
      "[-1.7919922e+00 -5.1269531e-01  1.6717911e-03  7.1923828e-01\n",
      "  9.0283203e-01  5.8496094e-01] 4   3 \n",
      "[-2.2265625  -0.2956543  -0.2097168   1.2099609   0.7426758   0.05828857] 3   1 \n",
      "[-0.58740234  0.4128418   0.8876953   0.66503906 -0.3713379  -1.4775391 ] 2   2 Match 174\n",
      "\n",
      "[-1.8808594  -0.36206055 -0.1829834   0.8564453   0.66748047  0.3166504 ] 3   5 \n",
      "[-0.10198975  0.46899414  0.9379883   0.36132812 -0.2919922  -1.2753906 ] 2   2 Match 175\n",
      "\n",
      "[-0.66015625  0.27661133 -0.09997559 -0.12573242 -0.23022461 -0.16955566] 1   4 \n",
      "[-0.9560547  -0.05551147  0.55566406  0.37939453 -0.0479126  -0.9169922 ] 2   3 \n",
      "[-0.9921875   0.28857422 -0.39379883  0.04855347 -0.06402588  0.22644043] 1   3 \n",
      "[-1.9882812  -0.46801758  0.06033325  0.6147461   0.9042969   0.5761719 ] 4   1 \n",
      "[-0.24609375  0.3046875   0.24389648  0.29736328 -0.37963867 -0.7294922 ] 1   3 \n",
      "[-0.28295898  0.09191895  0.30688477  0.10717773 -0.02087402 -0.80908203] 2   3 \n",
      "[-1.8730469  -0.24389648 -0.421875    0.7363281   0.8413086   0.53125   ] 4   4 Match 176\n",
      "\n",
      "[-0.6616211   0.44848633  0.25097656  0.6098633  -0.19433594 -0.5649414 ] 3   1 \n",
      "[-1.4365234  -0.31689453  0.46264648  0.6796875   0.51220703 -0.36376953] 3   5 \n",
      "[-1.0615234  -0.32910156 -0.0395813   0.14318848  0.5097656   0.26782227] 4   3 \n",
      "[-0.43286133  0.5888672   0.28979492  0.44384766 -0.31347656 -0.5361328 ] 1   1 Match 177\n",
      "\n",
      "[-1.8613281  -0.734375    0.09942627  0.59033203  0.97753906  0.36914062] 4   4 Match 178\n",
      "\n",
      "[-1.6728516  -0.31835938 -0.39135742  0.10223389  0.8408203   0.92285156] 5   5 Match 179\n",
      "\n",
      "[-1.3095703   0.06347656 -0.2232666   0.6040039   0.07836914 -0.22546387] 3   5 \n",
      "[-2.4277344  -0.14123535  0.47094727  1.0664062   0.61376953 -0.06860352] 3   3 Match 180\n",
      "\n",
      "[-2.1191406  -0.43847656 -0.5546875   0.73876953  0.86621094  0.69140625] 4   3 \n",
      "[-0.46875     0.1138916   0.10852051  0.31396484 -0.11810303 -0.48413086] 3   3 Match 181\n",
      "\n",
      "[-1.4570312  -0.05871582  0.6894531   1.0849609   0.20800781 -0.59765625] 3   2 \n",
      "[-2.3359375  -0.4494629  -0.4243164   0.8417969   0.9194336   0.67285156] 4   4 Match 182\n",
      "\n",
      "[-1.3056641  -0.21569824  0.01773071  0.36767578  0.515625    0.38061523] 4   5 \n",
      "[-1.1230469  -0.33496094  0.29125977  0.8251953   0.20690918 -0.01676941] 3   1 \n",
      "[-0.56152344  0.45776367 -0.38134766  0.1776123  -0.10113525  0.13623047] 1   2 \n",
      "[-1.1582031   0.07946777 -0.2626953  -0.14758301  0.23010254  0.45385742] 5   4 \n",
      "[-1.5195312  -0.31274414 -0.0748291   0.26733398  0.45703125  0.6591797 ] 5   3 \n",
      "[-1.4960938  -0.00959015 -0.47338867 -0.12890625  0.17785645  0.5517578 ] 5   5 Match 183\n",
      "\n",
      "[-0.7548828   0.47998047 -0.5336914  -0.19592285 -0.2548828   0.21643066] 1   0 \n",
      "[-0.85546875 -0.00122261  0.8491211   0.5205078  -0.02810669 -0.60546875] 2   0 \n",
      "[-1.0947266  -0.03111267  0.55029297  0.5703125   0.17565918 -0.5644531 ] 3   1 \n",
      "[-0.93408203  0.63183594  0.41235352  0.5205078  -0.45166016 -0.67285156] 1   1 Match 184\n",
      "\n",
      "[-0.06298828  0.6123047   0.36108398  0.28930664  0.00794983 -0.640625  ] 1   4 \n",
      "[-1.8662109  -0.16540527 -0.7104492   0.15930176  0.7705078   1.1328125 ] 5   5 Match 185\n",
      "\n",
      "[-1.8808594  -0.23352051 -0.3071289   0.23156738  0.61083984  0.5756836 ] 4   0 \n",
      "[-0.87646484  0.23730469  0.30126953  0.35961914  0.19299316 -0.14819336] 3   4 \n",
      "[-2.0449219   0.04669189 -0.20471191  0.7573242   0.3947754   0.09564209] 3   2 \n",
      "[-0.7036133   0.09973145  0.6982422   1.2626953  -0.20629883 -1.5136719 ] 3   4 \n",
      "[-0.26782227  0.53125     0.72802734  0.7763672  -0.28466797 -1.9003906 ] 3   2 \n",
      "[ 0.065979    0.5786133   0.7963867   0.37475586 -0.51171875 -1.6210938 ] 2   2 Match 186\n",
      "\n",
      "[ 0.46679688  1.1992188   0.80322266  0.6621094  -0.79345703 -1.9121094 ] 1   2 \n",
      "[-0.85839844  0.20812988  0.5136719   0.70410156  0.31054688 -0.67626953] 3   0 \n",
      "[ 0.23095703  0.6850586   0.52783203  0.48388672 -0.5097656  -1.1845703 ] 1   2 \n",
      "[-1.1923828   0.01204681 -0.27392578  0.08337402  0.0637207   0.60498047] 5   2 \n",
      "[-0.9658203   0.27392578  0.81884766  1.3623047  -0.02856445 -1.0576172 ] 3   1 \n",
      "[-0.3684082   0.57470703 -0.12902832  0.22460938 -0.42041016 -0.4909668 ] 1   4 \n",
      "[-1.2294922   0.25048828  0.4074707   0.76171875 -0.02630615 -0.47216797] 3   2 \n",
      "[-2.0292969  -0.41967773  0.10223389  0.47851562  0.5341797   0.52734375] 4   3 \n",
      "[-0.28857422  0.87158203  0.17089844  0.21899414 -0.26391602 -0.6958008 ] 1   3 \n",
      "[-2.5546875 -0.5805664 -0.3034668  0.6923828  1.5068359  0.6821289] 4   4 Match 187\n",
      "\n",
      "[-2.203125   -0.4868164   0.19262695  1.1611328   0.90234375  0.17236328] 3   2 \n",
      "[-1.4609375  -0.40673828  0.9921875   1.2089844   0.36401367 -1.0449219 ] 3   2 \n",
      "[-1.8193359  -0.4958496  -0.37841797  0.57373047  0.87841797  0.48388672] 4   3 \n",
      "[ 0.27001953  0.8383789   1.1455078   0.6538086  -0.34204102 -1.5996094 ] 2   2 Match 188\n",
      "\n",
      "[-1.4892578  -0.11956787  0.08447266  0.26733398  0.5498047   0.3251953 ] 4   4 Match 189\n",
      "\n",
      "[-0.7163086   0.42578125  0.6484375   0.60302734 -0.36279297 -1.2373047 ] 2   3 \n",
      "[-0.11169434  0.33325195  0.56347656  0.14770508 -0.40454102 -1.0693359 ] 2   1 \n",
      "[-2.2441406  -0.47998047 -0.4621582   1.0205078   1.3535156   0.87158203] 4   5 \n",
      "[-1.0058594   0.11450195 -0.01701355  0.06414795 -0.01212311  0.22192383] 5   3 \n",
      "[-2.0175781  -0.11010742 -0.07623291  0.79296875  0.7241211   0.46020508] 3   4 \n",
      "[-1.6748047  -0.01163483 -0.26391602  0.76660156  0.48632812 -0.10406494] 3   5 \n",
      "[-0.96484375 -0.04577637 -0.35229492 -0.22216797  0.30541992  0.5361328 ] 5   2 \n",
      "[-1.7763672  -0.11395264  0.8676758   1.0498047   0.19494629 -0.7475586 ] 3   3 Match 190\n",
      "\n",
      "[-1.6367188  -0.3244629  -0.11712646  0.29516602  0.32910156  0.8022461 ] 5   5 Match 191\n",
      "\n",
      "[-1.1259766  -0.35327148  0.38964844  0.61816406  0.34814453 -0.42260742] 3   2 \n",
      "[-2.2753906  -0.44750977 -0.4555664   0.70214844  1.2158203   0.6933594 ] 4   5 \n",
      "[-2.6972656 -0.2277832 -0.2578125  0.9584961  1.1650391  0.7260742] 4   4 Match 192\n",
      "\n",
      "[-1.7158203   0.01269531 -0.32226562  0.13916016  0.66064453  0.66015625] 4   2 \n",
      "[-1.9414062  -0.16040039 -0.35302734  0.47827148  0.8496094   1.0136719 ] 5   3 \n",
      "[ 0.11639404  0.60009766  1.          0.45629883 -0.58691406 -1.4960938 ] 2   0 \n",
      "[-2.1699219  -0.23034668 -0.0214386   0.3425293   0.81640625  0.5551758 ] 4   2 \n",
      "[-2.4980469  -0.58935547 -0.46606445  0.84472656  1.2890625   0.7324219 ] 4   5 \n",
      "[-1.6064453  -0.02696228 -0.3076172   0.41210938  0.5073242   0.63183594] 5   5 Match 193\n",
      "\n",
      "[-2.359375  -0.4013672 -0.6010742  0.3720703  1.0683594  1.3027344] 5   3 \n",
      "[-0.9145508  -0.08203125  0.29345703  0.4645996   0.28100586 -0.08892822] 3   2 \n",
      "[-1.1943359   0.30078125  0.03945923  0.23950195 -0.29077148 -0.09124756] 1   4 \n",
      "[-1.8574219  -0.31713867  0.00834656  0.6586914   0.6201172   0.04412842] 3   1 \n",
      "[-2.1679688  -0.66259766 -0.8276367   0.28930664  1.2646484   1.4199219 ] 5   4 \n",
      "[-1.8105469   0.31323242 -0.17089844  0.5078125   0.24633789  0.28051758] 3   3 Match 194\n",
      "\n",
      "[-2.8125     -0.859375   -0.1472168   1.0839844   1.1259766   0.48876953] 4   3 \n",
      "[-1.6611328  -0.15612793 -0.7104492  -0.03222656  0.7036133   1.0068359 ] 5   1 \n",
      "[-2.0429688  -0.56689453 -0.7675781   0.28344727  1.2675781   1.3310547 ] 5   4 \n",
      "[-2.4824219 -0.640625  -0.2232666  0.6386719  1.2275391  0.8173828] 4   5 \n",
      "[-0.74365234  0.66015625  0.3088379  -0.01641846 -0.6308594  -0.51123047] 1   2 \n",
      "[-1.4912109  -0.16674805  0.5517578   0.6425781   0.6274414  -0.60546875] 3   0 \n",
      "[-0.78027344  0.21704102 -0.0340271  -0.10699463 -0.20007324 -0.25317383] 1   1 Match 195\n",
      "\n",
      "[-2.2597656  -0.7001953  -0.26831055  0.6459961   1.1347656   0.94140625] 4   3 \n",
      "[-2.3632812  -0.31152344 -0.08648682  0.6191406   0.72216797  0.4790039 ] 4   3 \n",
      "[-0.5522461   0.23278809 -0.11090088  0.11480713 -0.01635742 -0.52246094] 1   2 \n",
      "[-2.0019531  -0.7636719  -0.11517334  0.70654297  1.2431641   0.6010742 ] 4   5 \n",
      "[-2.7773438  -0.5234375  -0.19213867  0.70751953  1.3603516   1.1914062 ] 4   2 \n",
      "[-2.4296875  -0.6694336  -0.3701172   0.50683594  1.6826172   1.3242188 ] 4   5 \n",
      "[-0.34277344  0.67089844  0.7807617   0.60253906 -0.4489746  -1.1972656 ] 2   3 \n",
      "[-2.3515625  -0.77734375 -0.0604248   0.57128906  1.4335938   0.69433594] 4   4 Match 196\n",
      "\n",
      "[-1.5517578   0.13146973 -0.33496094  0.1083374   0.3930664   0.5786133 ] 5   2 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.9511719  -0.2401123  -0.2232666   0.5083008   1.1650391   0.95703125] 4   4 Match 197\n",
      "\n",
      "[-1.2060547   0.13256836  0.06451416  0.5551758   0.38354492 -0.14050293] 3   2 \n",
      "[-1.2675781   0.28515625  0.21972656  0.74365234  0.01625061 -0.14404297] 3   4 \n",
      "[-1.8125      0.18334961  0.1505127   0.68847656  0.3408203   0.31323242] 3   4 \n",
      "[-1.5283203  -0.06604004 -0.5366211   0.3161621   0.49658203  0.5449219 ] 5   0 \n",
      "[-1.2519531   0.5996094   0.30566406  0.62597656 -0.46020508 -0.59814453] 3   2 \n",
      "[-1.2050781   0.18334961  0.10198975  0.5161133   0.484375    0.15270996] 3   5 \n",
      "[-1.8388672  -0.30200195 -0.56884766  0.2331543   0.78125     0.8652344 ] 5   5 Match 198\n",
      "\n",
      "[-0.8129883   0.3486328   0.08190918  0.00503159 -0.28515625 -0.46020508] 1   2 \n",
      "[-1.3974609   0.23706055 -0.03314209  0.3256836  -0.07025146  0.06082153] 3   3 Match 199\n",
      "\n",
      "[-0.8989258   0.4152832  -0.20214844  0.3203125  -0.01902771 -0.09155273] 1   1 Match 200\n",
      "\n",
      "[-1.84375    -0.6010742  -0.40161133  0.42529297  0.97021484  0.8808594 ] 4   3 \n",
      "[-1.8066406  -0.05935669  0.20568848  0.98339844  0.3149414  -0.3815918 ] 3   3 Match 201\n",
      "\n",
      "[-0.68359375  0.84521484  0.08496094  0.3010254  -0.1652832  -0.39282227] 1   0 \n",
      "[-0.9765625   0.16809082 -0.0690918   0.40673828 -0.09020996 -0.15441895] 3   2 \n",
      "[-1.4189453  -0.03594971 -0.10314941  0.75390625  0.16174316  0.1640625 ] 3   4 \n",
      "[-1.5097656  -0.17504883 -0.4423828   0.1517334   0.48095703  0.8286133 ] 5   4 \n",
      "[-0.68896484  0.9038086   0.8408203   0.9633789  -0.4416504  -1.2236328 ] 3   4 \n",
      "[-1.7089844  -0.09448242  0.19348145  0.64746094  0.31420898 -0.04937744] 3   4 \n",
      "[-1.1230469   0.0670166   0.16809082  0.5058594  -0.03421021 -0.12121582] 3   3 Match 202\n",
      "\n",
      "[-2.3828125   0.01527405  0.17358398  0.8208008   0.64941406  0.02757263] 3   0 \n",
      "[-2.2753906  -0.6923828   0.00910187  0.70654297  1.2626953   0.6669922 ] 4   5 \n",
      "[-0.95947266  0.02111816  0.3154297   0.38427734 -0.06890869  0.17150879] 3   2 \n",
      "[-0.71972656  0.19055176 -0.07305908  0.3347168  -0.18701172  0.1541748 ] 3   2 \n",
      "[-0.6230469   0.62646484 -0.12646484  0.42626953 -0.25341797 -0.19104004] 1   4 \n",
      "[-1.9589844  -0.01882935 -0.40454102  0.46142578  0.8544922   0.65625   ] 4   1 \n",
      "[-1.8056641  -0.39208984 -0.41918945  0.47583008  1.1005859   0.6796875 ] 4   4 Match 203\n",
      "\n",
      "[-1.1796875  -0.16027832 -0.51416016 -0.10046387  0.35473633  1.0507812 ] 5   3 \n",
      "[-1.7890625  -0.46533203  0.14404297  0.98046875  0.60546875 -0.40576172] 3   4 \n",
      "[-1.1894531   1.359375   -0.32104492  0.9765625  -0.640625   -0.33032227] 1   5 \n",
      "[-1.8632812   0.18164062  0.07183838  0.6064453   0.38623047 -0.06204224] 3   2 \n",
      "[-1.9326172  -0.15136719 -0.26586914  1.0244141   0.69091797  0.50390625] 3   5 \n",
      "[-1.4755859   0.03265381 -0.5751953   0.52783203  0.41503906  0.3798828 ] 3   3 Match 204\n",
      "\n",
      "[-0.7963867   0.03561401  0.35302734  0.9790039  -0.08398438 -0.9291992 ] 3   3 Match 205\n",
      "\n",
      "[-1.3457031   0.09777832  0.10919189  0.39746094  0.4951172   0.09649658] 4   1 \n",
      "[-2.1660156   0.12976074 -0.07641602  0.3088379   0.66748047  0.29760742] 4   4 Match 206\n",
      "\n",
      "[-0.29345703  0.10852051  0.69140625  0.3959961  -0.23278809 -0.90185547] 2   2 Match 207\n",
      "\n",
      "[-0.9013672   1.296875   -0.52001953  0.56884766 -0.6879883  -0.04852295] 1   1 Match 208\n",
      "\n",
      "[ 0.44580078  0.61035156 -0.17102051 -0.07055664 -0.5541992  -0.5629883 ] 1   4 \n",
      "[-2.0351562  -0.5444336  -0.17700195  0.5698242   1.1699219   0.73339844] 4   4 Match 209\n",
      "\n",
      "[-1.7119141  -0.15405273 -0.34570312  0.10687256  0.55126953  0.6635742 ] 5   3 \n",
      "[-2.4433594  -0.78564453 -0.46533203  0.9345703   1.5185547   0.9536133 ] 4   3 \n",
      "[-1.1503906   0.0748291   0.08752441  0.46923828  0.10266113  0.10437012] 3   2 \n",
      "[ 0.3774414   0.6411133  -0.34887695 -0.3984375  -0.8701172  -0.46826172] 1   0 \n",
      "[-0.9038086   0.8623047   0.08703613  0.31298828 -0.05535889 -0.31225586] 1   1 Match 210\n",
      "\n",
      "[-2.2753906  -0.13952637 -0.45507812  0.42114258  0.9814453   1.0029297 ] 5   4 \n",
      "[-2.6484375  -0.6328125  -0.02728271  1.0292969   0.84033203  0.14685059] 3   4 \n",
      "[-1.7402344  -0.14001465 -0.49389648  0.29077148  0.8955078   0.7817383 ] 4   4 Match 211\n",
      "\n",
      "[-1.5253906  -0.15795898 -0.6279297   0.12060547  0.6738281   0.9238281 ] 5   5 Match 212\n",
      "\n",
      "[-1.0742188   0.30688477  0.48657227  0.92529297 -0.34570312 -1.1748047 ] 3   3 Match 213\n",
      "\n",
      "[-1.7519531  -0.14025879 -0.26220703  0.4658203   0.7636719   0.890625  ] 5   2 \n",
      "[-0.77441406  0.39404297 -0.44604492 -0.14208984  0.2298584   0.7885742 ] 5   5 Match 214\n",
      "\n",
      "[ 0.79541016  1.0849609   0.05917358 -0.14807129 -0.76708984 -0.95410156] 1   0 \n",
      "[-1.5361328  -0.15356445  0.62060547  0.9584961   0.33325195 -0.7729492 ] 3   3 Match 215\n",
      "\n",
      "[-0.57666016  0.3022461   0.2409668   0.27416992 -0.31713867 -0.69189453] 1   0 \n",
      "[-2.1171875 -0.5673828 -0.7290039  0.7158203  1.3300781  1.1210938] 4   4 Match 216\n",
      "\n",
      "[-1.1484375   0.03152466 -0.2890625   0.50634766  0.23022461  0.18859863] 3   4 \n",
      "[-0.72558594  0.54345703 -0.42895508 -0.34399414 -0.1953125   0.23986816] 1   4 \n",
      "[-1.7695312   0.24987793 -0.00347519  0.85546875  0.08544922 -0.01462555] 3   3 Match 217\n",
      "\n",
      "[-2.0039062  -0.30981445  0.24414062  1.3642578   0.43896484 -0.6689453 ] 3   2 \n",
      "[-0.59472656 -0.01986694 -0.3984375  -0.0539856  -0.16833496  0.1887207 ] 5   5 Match 218\n",
      "\n",
      "[-1.8427734 -0.5126953 -0.1776123  0.3762207  0.9316406  0.5595703] 4   5 \n",
      "[-1.1464844   0.19873047  0.1616211   0.33569336 -0.01442719  0.03610229] 3   1 \n",
      "[-2.0332031   0.12011719 -0.07305908  0.69628906  0.4482422   0.29223633] 3   1 \n",
      "[-1.2509766  -0.15429688 -0.61621094 -0.03967285  0.80566406  0.9604492 ] 5   3 \n",
      "[-1.2041016  -0.15551758  0.3100586   0.54296875  0.49951172 -0.5527344 ] 3   2 \n",
      "[-1.4921875  -0.01795959 -0.8144531  -0.14782715  0.42578125  0.71240234] 5   5 Match 219\n",
      "\n",
      "[-1.2060547  -0.1451416  -0.27734375  0.50927734  0.49047852  0.40429688] 3   2 \n",
      "[-1.6630859  -0.29077148 -0.44213867  0.04959106  0.7338867   0.9316406 ] 5   1 \n",
      "[-0.91796875  1.9892578  -0.64697266  0.66503906 -0.9189453  -0.02172852] 1   3 \n",
      "[-2.5332031  -0.6850586  -0.41918945  0.7211914   1.3212891   0.8930664 ] 4   3 \n",
      "[-1.1308594   0.1661377  -0.48657227 -0.34692383 -0.04211426  0.54541016] 5   1 \n",
      "[-1.9248047  -0.14929199 -0.02661133  1.0068359   0.7919922   0.21923828] 3   3 Match 220\n",
      "\n",
      "[-2.3964844  -0.77978516 -0.09997559  1.0556641   1.4013672   0.64208984] 4   4 Match 221\n",
      "\n",
      "[-1.3964844   0.11029053  0.6303711   1.0722656  -0.04473877 -0.7631836 ] 3   5 \n",
      "[-1.3232422  -0.35473633 -0.50390625  0.55566406  0.75683594  0.5986328 ] 4   4 Match 222\n",
      "\n",
      "[-2.4179688  -0.63623047 -0.30493164  0.7348633   1.2685547   0.9086914 ] 4   1 \n",
      "[-1.7275391  -0.20666504 -0.10003662  0.7241211   1.046875    0.35375977] 4   3 \n",
      "[-1.4892578  -0.32958984 -0.37329102  0.20483398  0.8691406   0.65283203] 4   4 Match 223\n",
      "\n",
      "[ 0.75683594  0.96875     0.7285156   0.2421875  -0.79785156 -1.4335938 ] 1   0 \n",
      "[-1.7207031  -0.14550781 -0.30810547  0.43725586  0.5371094   0.6357422 ] 5   2 \n",
      "[-0.9501953   0.4892578  -0.50097656  0.02520752  0.14782715  0.4111328 ] 1   1 Match 224\n",
      "\n",
      "[-1.0947266   0.02433777 -0.33496094  0.20288086  0.18664551  0.35180664] 5   5 Match 225\n",
      "\n",
      "[-2.0410156  -0.33032227 -0.26953125  0.8198242   0.5878906   0.29956055] 3   2 \n",
      "[-2.7167969  -0.6166992  -0.18652344  1.0234375   1.2822266   0.9145508 ] 4   4 Match 226\n",
      "\n",
      "[-1.4775391  -0.15820312  0.50390625  1.0595703  -0.05773926 -0.80371094] 3   3 Match 227\n",
      "\n",
      "[-1.53125    -0.05633545  0.15625     0.8203125   0.44189453 -0.17138672] 3   4 \n",
      "[-0.4580078   0.9638672  -0.39941406  0.11901855 -0.74072266 -0.29541016] 1   5 \n",
      "[-1.4746094  -0.30004883  0.0586853   0.22949219  0.62158203  0.09179688] 4   1 \n",
      "[ 0.9951172   0.86279297  0.00723267 -0.32666016 -0.85546875 -0.82470703] 0   0 Match 228\n",
      "\n",
      "[-1.4453125  -0.3618164  -0.14904785  0.23461914  0.22607422  0.41308594] 5   2 \n",
      "[ 0.65966797  1.1533203   0.5205078   0.14904785 -0.53125    -1.1904297 ] 1   2 \n",
      "[-0.8666992   0.32080078 -0.05426025  0.5732422  -0.30517578 -0.44482422] 3   1 \n",
      "[-0.17089844  0.7060547   0.4519043   0.35180664 -0.6772461  -1.5722656 ] 1   1 Match 229\n",
      "\n",
      "[-1.4111328   0.07775879  0.52978516  0.8935547  -0.00159168 -0.8833008 ] 3   4 \n",
      "[-1.4296875  -0.39086914  0.20483398  0.6640625   0.21044922 -0.16186523] 3   2 \n",
      "[-2.1914062  -0.36621094 -0.60302734  0.5053711   0.98876953  0.91552734] 4   1 \n",
      "[-0.94628906  0.35668945  0.24157715  0.6074219  -0.19726562 -0.98876953] 3   5 \n",
      "[-2.1542969  -0.39135742 -0.7265625   0.34887695  1.0253906   1.0898438 ] 5   4 \n",
      "[-2.1621094  -0.45581055 -0.1928711   0.9355469   0.8730469   0.47485352] 3   5 \n",
      "[-1.9433594  -0.00975037 -0.20532227  0.4194336   0.42041016  0.53027344] 5   3 \n",
      "[-0.7104492   0.05371094  0.9848633   0.6220703  -0.1899414  -0.9453125 ] 2   1 \n",
      "[-0.875       0.19592285 -0.33081055 -0.00206757  0.07202148  0.39257812] 5   2 \n",
      "[-1.4384766   0.28637695 -0.36450195  0.14990234  0.5488281   0.6386719 ] 5   2 \n",
      "[ 0.58496094  1.0986328   0.4387207  -0.32592773 -0.98339844 -1.1875    ] 1   3 \n",
      "[-2.1816406  -0.46728516 -0.46679688  0.6772461   1.2490234   0.6738281 ] 4   5 \n",
      "[-1.4697266   0.18652344 -0.61816406  0.05505371  0.54589844  0.89697266] 5   1 \n",
      "[-0.13867188  0.7133789   0.0484314   0.07702637 -0.61328125 -0.03244019] 1   3 \n",
      "[-0.4580078   0.35229492  1.234375    0.78222656 -0.28442383 -1.5234375 ] 2   3 \n",
      "[-1.625      -0.27929688 -0.77490234  0.13061523  1.0654297   1.2451172 ] 5   5 Match 230\n",
      "\n",
      "[-0.609375    0.45581055  0.9458008   0.30908203 -0.27490234 -0.95751953] 2   2 Match 231\n",
      "\n",
      "[-0.9350586   0.72753906  0.10528564  0.35546875 -0.28955078 -0.3696289 ] 1   1 Match 232\n",
      "\n",
      "[-1.7783203  -0.3840332  -0.05496216  0.70751953  0.6088867   0.22241211] 3   3 Match 233\n",
      "\n",
      "[-0.7519531  1.7861328 -0.4152832  1.2412109 -1.0410156 -0.7890625] 1   3 \n",
      "[-1.1513672  -0.1706543  -0.4230957   0.44018555  0.65234375  0.4958496 ] 4   5 \n",
      "[-1.1025391   0.13500977 -0.15698242  0.1706543   0.24450684  0.68847656] 5   5 Match 234\n",
      "\n",
      "[-0.9892578  -0.1005249   0.16271973  0.6069336  -0.09857178 -0.31298828] 3   2 \n",
      "[-2.3828125  -0.52197266 -0.34838867  0.85791016  0.86816406  0.6904297 ] 4   5 \n",
      "[-2.5996094  -0.8544922  -0.42358398  1.0527344   1.5146484   0.93847656] 4   5 \n",
      "[-0.5620117   0.35791016 -0.22509766 -0.18371582 -0.37646484 -0.05075073] 1   3 \n",
      "[-0.16357422  0.35107422  0.18835449  0.0602417  -0.35961914 -0.8256836 ] 1   1 Match 235\n",
      "\n",
      "[-2.0527344  -0.21472168 -0.68896484  0.24951172  0.81152344  1.015625  ] 5   4 \n",
      "[-2.5878906  -0.8354492  -0.16064453  1.0546875   1.4501953   0.66845703] 4   3 \n",
      "[-0.77734375  0.5288086  -0.21557617  0.3161621  -0.24511719  0.3383789 ] 1   1 Match 236\n",
      "\n",
      "[-2.3027344  -0.12261963 -0.02023315  0.5493164   0.56591797  0.8183594 ] 5   4 \n",
      "[-2.4667969  -0.46069336 -0.6611328   0.47460938  1.          1.0693359 ] 5   1 \n",
      "[-2.4785156  -0.56640625 -0.33862305  0.671875    1.1621094   1.0644531 ] 4   5 \n",
      "[-2.4179688  -0.3984375  -0.10858154  1.0263672   0.6645508   0.30541992] 3   3 Match 237\n",
      "\n",
      "[-2.3574219  -0.50341797 -0.09088135  0.58740234  1.3916016   0.8652344 ] 4   4 Match 238\n",
      "\n",
      "[-0.95166016  0.09741211 -0.4963379  -0.23815918 -0.29248047  0.3671875 ] 5   3 \n",
      "[ 1.0302734   0.98779297  0.79833984  0.2800293  -0.9536133  -2.0917969 ] 0   1 \n",
      "[-2.421875   -0.05218506 -0.6069336   0.90185547  1.0048828   0.7607422 ] 4   3 \n",
      "[-1.0908203   0.25048828 -0.29858398  0.15344238 -0.00420761  0.1854248 ] 1   4 \n",
      "[-1.8349609  -0.44067383 -0.6015625   0.11535645  0.89453125  1.0410156 ] 5   4 \n",
      "[-1.1308594   0.35424805  0.06976318  0.56347656  0.34228516 -0.7519531 ] 3   5 \n",
      "[-0.38623047  0.23120117 -0.46899414 -0.00460434 -0.18566895 -0.23095703] 1   4 \n",
      "[-2.4023438  -0.8198242  -0.14660645  1.4111328   0.9291992   0.13330078] 3   4 \n",
      "[-1.1298828   0.54248047 -0.2866211   0.49975586  0.08880615 -0.23815918] 1   5 \n",
      "[ 0.8144531   0.73828125 -0.29418945 -0.49145508 -0.6098633  -0.4482422 ] 0   5 \n",
      "[-0.9511719  -0.23132324  0.20129395  0.3022461   0.03433228 -0.36328125] 3   4 \n",
      "[-1.4394531   0.20898438  0.08361816  0.69433594  0.13623047  0.08972168] 3   5 \n",
      "[-1.9638672  -0.33374023 -0.42407227  0.5058594   1.0097656   0.9370117 ] 4   4 Match 239\n",
      "\n",
      "[-2.1894531   0.06161499  0.14855957  1.0380859   0.55322266 -0.2442627 ] 3   3 Match 240\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[-0.6567383   0.3395996   1.0830078   0.70166016 -0.26513672 -1.0351562 ] 2   0 \n",
      "[-0.7519531   0.22436523  1.0917969   0.69677734 -0.10412598 -1.2314453 ] 2   2 Match 241\n",
      "\n",
      "[-2.0507812  -0.41455078 -0.3383789   0.95703125  1.0322266   0.57470703] 4   4 Match 242\n",
      "\n",
      "[-0.32666016  0.4794922  -0.14367676  0.36743164  0.00372124 -0.1809082 ] 1   4 \n",
      "[-2.3886719  -0.6274414  -0.17675781  0.6020508   1.0244141   0.84033203] 4   2 \n",
      "[-2.3359375  -0.27148438 -0.33374023  0.55322266  0.8383789   0.91748047] 5   3 \n",
      "[-2.8671875  -0.71435547 -0.34936523  0.8457031   1.6660156   1.1650391 ] 4   5 \n",
      "[-1.0429688  -0.19348145  0.69091797  0.59472656  0.3293457  -0.44360352] 2   4 \n",
      "[-0.94970703 -0.03421021 -0.0723877   0.9433594   0.44799805 -0.4169922 ] 3   4 \n",
      "[-0.20422363 -0.16040039  0.20288086  0.6538086  -0.07232666 -0.39624023] 3   0 \n",
      "[-1.5087891  -0.49951172  0.23205566  0.7114258   0.43164062 -0.09112549] 3   4 \n",
      "[-0.2854004   0.13500977 -0.27075195 -0.11230469 -0.15258789  0.13916016] 5   5 Match 243\n",
      "\n",
      "[-1.4042969  -0.11676025  0.20129395  1.3085938   0.6269531  -0.5053711 ] 3   1 \n",
      "[-0.58984375  0.5703125   0.28222656  0.5463867  -0.51464844 -0.92041016] 1   2 \n",
      "[ 0.86328125  1.0683594   0.859375    0.37597656 -0.9067383  -2.1738281 ] 1   2 \n",
      "[-0.32983398  0.24731445 -0.3623047   0.15783691 -0.03570557 -0.31884766] 1   0 \n",
      "[-1.8164062  -0.5810547  -0.21740723  1.0097656   0.9951172   0.35742188] 3   4 \n",
      "[-1.8066406  -0.48876953 -0.2376709   0.6723633   1.1142578   0.58154297] 4   3 \n",
      "[-1.3320312  -0.07348633 -0.07794189  0.17932129  0.44995117  0.29418945] 4   5 \n",
      "[-0.9946289   0.18615723  0.6196289   1.0175781  -0.19226074 -1.4785156 ] 3   2 \n",
      "[-1.2060547  -0.01882935 -0.30322266  0.65771484  0.15856934  0.04458618] 3   1 \n",
      "[-1.0380859   0.01330566 -0.02262878  0.35302734 -0.0949707  -0.12988281] 3   2 \n",
      "[-2.1484375  -0.5214844  -0.5029297   0.46533203  1.1113281   0.859375  ] 4   4 Match 244\n",
      "\n",
      "[-0.80615234  0.4038086  -0.15454102  0.02474976 -0.08416748  0.07171631] 1   5 \n",
      "[-1.2929688   0.01541138  0.61572266  1.0097656   0.4025879  -0.8041992 ] 3   5 \n",
      "[-1.9658203  -0.37817383  0.22619629  0.78125     0.7866211   0.2722168 ] 4   1 \n",
      "[-1.8828125  -0.36987305 -0.06549072  0.67529297  0.8544922   0.05197144] 4   3 \n",
      "[-1.0517578   0.0725708   0.26831055  0.17077637  0.15563965 -0.06878662] 2   1 \n",
      "[-1.2109375   0.18359375 -0.17578125  0.15856934 -0.01067352  0.07025146] 1   2 \n",
      "[-1.9082031  -0.23046875 -0.26049805  0.17919922  0.47485352  0.37060547] 4   3 \n",
      "[-1.96875    -0.6435547  -0.5317383   0.6542969   0.79541016  0.88427734] 5   1 \n",
      "[ 1.15625     0.98339844  0.7915039   0.19824219 -1.0234375  -1.8564453 ] 0   0 Match 245\n",
      "\n",
      "[-1.4804688   0.2368164  -0.33813477 -0.15722656  0.12255859  0.7709961 ] 5   5 Match 246\n",
      "\n",
      "[-2.5214844  -0.79785156 -0.19274902  1.0996094   1.2636719   0.5546875 ] 4   5 \n",
      "[-1.6855469  -0.10925293 -0.51220703  0.5390625   1.0087891   0.5371094 ] 4   1 \n",
      "[-0.7348633   0.10101318 -0.38330078 -0.12475586  0.4482422   0.7705078 ] 5   1 \n",
      "[-1.3085938  -0.05255127  1.1240234   0.9921875  -0.10742188 -0.9243164 ] 2   0 \n",
      "[ 0.7548828   0.65478516  0.00538635 -0.12756348 -0.7089844  -0.81689453] 0   1 \n",
      "[-1.9550781  -0.3935547   0.2697754   1.5859375   0.71435547 -0.6479492 ] 3   3 Match 247\n",
      "\n",
      "[ 1.0048828   0.6826172   0.51708984  0.24145508 -0.63671875 -1.4677734 ] 0   0 Match 248\n",
      "\n",
      "[-1.9082031  -0.1005249   0.6220703   1.0087891   0.4440918  -0.64160156] 3   4 \n",
      "[-1.5605469  -0.15515137 -0.50927734  0.06604004  0.4892578   0.96777344] 5   4 \n",
      "[-0.37939453 -0.07440186  0.5883789   0.43676758 -0.09094238 -0.25463867] 2   5 \n",
      "[-0.08251953  0.7104492  -0.27905273 -0.04672241 -0.5283203   0.03857422] 1   3 \n",
      "[-0.56347656  0.19360352  0.36743164  0.29663086 -0.20349121 -0.14111328] 2   2 Match 249\n",
      "\n",
      "[ 1.1201172   0.6303711   0.64501953  0.10253906 -0.84375    -1.6113281 ] 0   0 Match 250\n",
      "\n",
      "[-1.7382812  -0.31201172 -0.0993042   0.15124512  0.7529297   0.66796875] 4   4 Match 251\n",
      "\n",
      "[-2.2675781  -0.16882324  0.30273438  1.1552734   0.1776123  -0.46166992] 3   2 \n",
      "[-1.0859375   0.15661621  0.47021484  0.22875977 -0.18469238 -0.26611328] 2   2 Match 252\n",
      "\n",
      "[-1.8144531   0.11846924  0.02403259  0.0446167   0.31030273  0.6767578 ] 5   2 \n",
      "[-1.7773438  -0.40649414  0.9926758   1.1748047   0.5205078  -0.8388672 ] 3   4 \n",
      "[-0.6982422   0.16137695 -0.44335938  0.16821289 -0.16174316 -0.43896484] 3   5 \n",
      "[-0.9238281   0.60839844  0.2709961   0.42871094 -0.28149414 -0.6669922 ] 1   4 \n",
      "[ 0.69921875  0.8173828   0.3178711  -0.2208252  -0.98828125 -0.88623047] 1   2 \n",
      "[-1.3496094  -0.41455078  0.20532227  0.19189453  0.34350586  0.48535156] 5   4 \n",
      "[-2.5       -0.7783203  0.0276947  1.3378906  1.2255859  0.4350586] 3   4 \n",
      "[-1.5410156  -0.01488495  0.2376709   1.2119141   0.40527344 -0.4494629 ] 3   2 \n",
      "[-0.46533203  0.7763672   0.04244995  0.0147934  -0.47631836 -0.01693726] 1   3 \n",
      "[-0.81689453  0.60498047  0.4260254   0.9008789  -0.41088867 -1.3828125 ] 3   2 \n",
      "[-1.4863281  -0.11523438 -0.04815674  0.47729492  0.18701172  0.30688477] 3   4 \n",
      "[-2.4277344  -0.62597656 -0.46704102  0.5839844   1.2314453   0.97802734] 4   3 \n",
      "[-1.6132812   0.00535965 -0.15283203  0.2734375   0.8330078   0.6533203 ] 4   2 \n",
      "[-0.6191406   0.45336914 -0.01157379 -0.07183838 -0.0758667  -0.06060791] 1   1 Match 253\n",
      "\n",
      "[-2.2246094 -0.5439453 -0.390625   0.4963379  1.5507812  1.0732422] 4   4 Match 254\n",
      "\n",
      "[ 0.53271484  0.9086914   0.0151825   0.1595459  -0.74121094 -0.9116211 ] 1   0 \n",
      "[ 0.7548828   0.9433594   0.22961426 -0.30004883 -1.0039062  -0.5703125 ] 1   2 \n",
      "[-1.0498047  -0.28271484 -0.04168701  0.3479004   0.33764648 -0.2052002 ] 3   3 Match 255\n",
      "\n",
      "[ 0.07635498  0.7524414   0.45776367 -0.04931641 -0.76123047 -0.69433594] 1   0 \n",
      "[-0.31396484  0.21948242  0.08782959  0.01905823 -0.2265625  -0.21508789] 1   2 \n",
      "[ 1.1210938   0.94433594  0.51708984  0.16577148 -1.0029297  -1.8896484 ] 0   1 \n",
      "[-2.65625    -0.6621094  -0.47802734  0.9506836   1.4707031   0.80859375] 4   4 Match 256\n",
      "\n",
      "[-1.0517578  -0.34643555  0.10076904  0.50341797  0.3647461  -0.05487061] 3   1 \n",
      "[-0.92871094  0.14770508  0.22766113  0.3400879  -0.17565918 -0.16540527] 3   3 Match 257\n",
      "\n",
      "[-0.60595703 -0.00898743 -0.00510788  0.2956543  -0.0713501  -0.00820923] 3   0 \n",
      "[-1.3476562  -0.14013672 -0.4560547   0.01734924  0.3239746   0.89208984] 5   1 \n",
      "[-1.8320312  -0.17346191  0.34033203  0.38232422  0.51123047  0.15344238] 4   3 \n",
      "[-2.2832031  -0.67822266 -0.48266602  0.9902344   1.3779297   0.5961914 ] 4   5 \n",
      "[-1.6054688   0.00849915  0.1352539   0.7783203   0.32543945 -0.15808105] 3   4 \n",
      "[-1.3837891  -0.2602539  -0.33032227  0.3803711   0.59228516  0.34545898] 4   4 Match 258\n",
      "\n",
      "[-0.31152344  0.7895508   0.0814209   0.5332031  -0.16540527 -0.34692383] 1   0 \n",
      "[-0.35888672  0.41625977 -0.5136719  -0.20275879 -0.55859375 -0.12573242] 1   0 \n",
      "[-0.48901367  0.26245117  0.20617676  0.24206543 -0.08666992 -0.40112305] 1   2 \n",
      "[-1.9013672  -0.26879883 -0.25634766  0.8544922   0.56347656  0.55859375] 3   0 \n",
      "[-0.87060547  0.4519043   0.08374023  0.25195312 -0.13647461 -0.03083801] 1   2 \n",
      "[-1.2675781  -0.08374023 -0.4741211   0.46850586  0.57470703  0.43408203] 4   1 \n",
      "[-2.1601562  -0.49902344 -0.6113281   0.7285156   1.2324219   0.9741211 ] 4   3 \n",
      "[-1.8359375  -0.47631836  0.02693176  0.39453125  0.66015625  0.56103516] 4   3 \n",
      "[-0.99902344  0.4489746   0.20593262  0.7421875  -0.36791992 -0.6020508 ] 3   5 \n",
      "[-1.5488281  -0.32666016  0.19238281  0.69091797  0.5551758  -0.01849365] 3   3 Match 259\n",
      "\n",
      "[ 0.14343262  0.5551758   1.3105469   0.7631836  -0.2512207  -1.3857422 ] 2   1 \n",
      "[-0.6323242  -0.2286377   1.1074219   0.74365234 -0.04241943 -1.1259766 ] 2   0 \n",
      "[-1.2431641  -0.09997559 -0.34521484 -0.16833496  0.16894531  0.2052002 ] 5   2 \n",
      "[-1.0849609   0.10253906 -0.16308594  0.14929199 -0.16015625  0.2578125 ] 5   2 \n",
      "[-0.87939453  0.28442383  0.25805664  0.36035156 -0.33276367 -0.08929443] 3   1 \n",
      "[-1.9121094  -0.28173828 -0.21594238  0.6196289   0.5053711   0.4951172 ] 3   5 \n",
      "[-0.5229492   0.71240234 -0.21313477 -0.02555847 -0.04946899 -0.0647583 ] 1   2 \n",
      "[-0.8964844  -0.19567871  0.73535156  0.82421875  0.26245117 -0.5131836 ] 3   1 \n",
      "[-2.1679688  -0.6225586  -0.42041016  0.5888672   1.3066406   1.0136719 ] 4   4 Match 260\n",
      "\n",
      "[-1.1210938  -0.30419922 -0.45874023  0.24536133  0.61279297  0.4104004 ] 4   1 \n",
      "[-0.52978516  0.7084961  -0.20056152  0.14331055 -0.02050781  0.36547852] 1   1 Match 261\n",
      "\n",
      "[-1.921875   -0.1986084   0.41137695  1.0087891   0.78125    -0.46362305] 3   4 \n",
      "[-0.71875     0.30908203  0.09863281  0.06988525 -0.20239258 -0.12646484] 1   3 \n",
      "[-2.4082031  -0.6401367   0.2668457   1.03125     0.88427734 -0.14990234] 3   4 \n",
      "[-0.7783203   0.12420654 -0.10455322  0.0027256  -0.02658081  0.07067871] 1   4 \n",
      "[-0.07519531  0.3857422   0.8979492   0.91845703 -0.4609375  -1.4804688 ] 3   2 \n",
      "[-1.1298828   0.10516357 -0.2709961   0.05001831  0.31933594  0.57421875] 5   4 \n",
      "[-1.15625     0.05157471  0.17578125  0.7128906   0.05603027 -0.12457275] 3   4 \n",
      "[-2.15625    -0.5449219  -0.18200684  0.49853516  1.2617188   1.0214844 ] 4   4 Match 262\n",
      "\n",
      "[-1.5410156   0.07830811 -0.59033203  0.32202148  0.41674805  0.39038086] 4   5 \n",
      "[-0.89941406  0.27685547 -0.57910156 -0.28564453  0.7392578   1.2177734 ] 5   5 Match 263\n",
      "\n",
      "[-1.7705078  -0.6298828  -0.22485352  0.52246094  0.5986328   0.56152344] 4   0 \n",
      "[-2.2597656  -0.33007812 -0.11938477  0.90625     0.7182617   0.2232666 ] 3   5 \n",
      "[-1.4726562  -0.5131836  -0.15441895  0.7270508   0.8520508   0.28442383] 4   3 \n",
      "[-2.1425781  -0.4140625  -0.34301758  0.5288086   0.8881836   0.8774414 ] 4   4 Match 264\n",
      "\n",
      "[-0.44726562  0.44604492 -0.25952148 -0.04003906 -0.17883301  0.00139713] 1   3 \n",
      "[-1.0820312  -0.17797852  0.7470703   0.47753906  0.1817627  -0.45336914] 2   3 \n",
      "[-0.5419922  -0.2548828   0.21008301  0.33129883 -0.24438477 -0.49804688] 3   4 \n",
      "[-1.0498047   0.4868164   1.0683594   0.6635742  -0.07904053 -1.2753906 ] 2   3 \n",
      "[-0.06896973  0.48486328  0.5776367   0.44580078 -0.4987793  -0.68896484] 2   1 \n",
      "[-0.5810547   0.62158203  0.16027832  0.24353027 -0.30908203 -0.01480865] 1   1 Match 265\n",
      "\n",
      "[-0.9790039   0.22399902 -0.52246094 -0.01025391  0.25610352  0.6147461 ] 5   1 \n",
      "[-1.6816406  -0.3786621  -0.47607422  0.32958984  0.7841797   0.84228516] 5   5 Match 266\n",
      "\n",
      "[ 1.0019531   0.9682617   0.32617188 -0.25219727 -1.1064453  -1.2890625 ] 0   0 Match 267\n",
      "\n",
      "[-2.4394531  -0.7788086   0.4506836   1.46875     0.83251953 -0.46777344] 3   1 \n",
      "[-1.859375   -0.4975586   0.25        0.7583008   0.6801758   0.27612305] 3   3 Match 268\n",
      "\n",
      "[-0.73339844  0.05764771 -0.4116211  -0.1295166  -0.11413574  0.46533203] 5   1 \n",
      "[-1.0498047   1.8691406  -0.43896484  0.8330078  -0.7548828  -0.3395996 ] 1   1 Match 269\n",
      "\n",
      "[-1.1855469   0.08746338 -0.5209961  -0.10925293  0.6542969   0.7416992 ] 5   5 Match 270\n",
      "\n",
      "[-1.9755859  -0.2524414  -0.09777832  0.97998047  0.8803711   0.15515137] 3   4 \n",
      "[ 0.07788086  1.0898438   0.5673828   0.44018555 -0.6074219  -1.5068359 ] 1   2 \n",
      "[-1.7265625  -0.34448242 -0.08233643  0.7363281   0.78222656 -0.00210571] 4   3 \n",
      "[-0.8535156   0.6635742   0.14916992  0.49609375 -0.03857422 -0.7504883 ] 1   1 Match 271\n",
      "\n",
      "[-0.03945923  1.0107422   0.2541504   0.22631836 -0.64501953 -1.1035156 ] 1   2 \n",
      "[-2.0722656  -0.5732422  -0.11834717  1.2675781   0.87939453  0.29467773] 3   1 \n",
      "[-0.11676025  0.83203125 -0.43139648 -0.11376953 -0.13537598  0.3623047 ] 1   2 \n",
      "[-0.7470703   0.07751465 -0.17871094  0.16320801 -0.1307373   0.14453125] 3   4 \n",
      "[ 1.4960938   1.0273438  -0.00211334 -0.5151367  -1.1679688  -0.87353516] 0   0 Match 272\n",
      "\n",
      "[-2.7207031  -0.83251953 -0.2998047   1.1708984   1.5654297   0.9526367 ] 4   4 Match 273\n",
      "\n",
      "[-1.2724609  -0.18408203  1.078125    1.0830078   0.09655762 -0.9921875 ] 3   4 \n",
      "[-1.0048828   0.01567078  0.26538086  0.6640625   0.12225342  0.04266357] 3   4 \n",
      "[-1.9560547  -0.31079102 -0.6591797   0.1328125   0.7167969   1.1650391 ] 5   4 \n",
      "[-2.59375    -0.98583984  0.00840759  1.3017578   1.2841797   0.05889893] 3   5 \n",
      "[-2.2128906  -0.76708984 -0.41967773  0.66064453  1.2841797   1.1816406 ] 4   5 \n",
      "[-0.6323242  -0.02801514  0.18847656  0.35302734  0.00714111 -0.33251953] 3   2 \n",
      "[-1.7871094   0.14880371 -0.38012695  0.19250488  0.6816406   0.9423828 ] 5   1 \n",
      "[-2.2460938 -0.0390625 -0.2956543  0.7709961  0.7753906  0.2524414] 4   4 Match 274\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.7353516  -0.18127441 -0.5751953   0.4321289   0.69628906  0.6074219 ] 4   4 Match 275\n",
      "\n",
      "[-2.3769531  -0.4326172   0.07299805  0.70947266  0.95214844  0.87109375] 4   3 \n",
      "[-1.5507812   0.2919922   0.05947876  0.62841797  0.2331543  -0.15625   ] 3   3 Match 276\n",
      "\n",
      "[ 0.04092407  0.42578125  0.61621094  0.46826172 -0.8466797  -1.4501953 ] 2   3 \n",
      "[-1.1289062   0.30371094 -0.10656738  0.04394531  0.07116699  0.28564453] 1   2 \n",
      "[-2.0722656  -0.41064453 -0.25976562  0.67089844  0.87646484  0.67578125] 4   3 \n",
      "[-1.6982422  -0.43115234  0.04052734  0.44360352  1.0947266   0.04522705] 4   3 \n",
      "[-0.64208984  0.3930664   0.25        0.26904297 -0.0838623  -0.31079102] 1   4 \n",
      "[-2.6699219  -1.0976562  -0.14526367  1.0048828   1.5214844   0.52246094] 4   1 \n",
      "[-1.7333984  -0.14733887 -0.5410156   0.10510254  0.45532227  0.92089844] 5   4 \n",
      "[-2.6035156  -0.63378906 -0.54541016  0.9135742   1.1962891   0.96875   ] 4   3 \n",
      "[-1.6210938  -0.00211525 -0.47216797  0.03353882  0.52197266  0.8691406 ] 5   5 Match 277\n",
      "\n",
      "[-0.6713867  1.8398438 -0.2397461  1.0556641 -0.9379883 -0.53125  ] 1   1 Match 278\n",
      "\n",
      "[-0.43676758  0.31298828  0.16394043  0.39990234 -0.29101562 -0.37109375] 3   1 \n",
      "[-2.1132812  -0.11157227 -0.29174805  0.6411133   0.7558594   0.7441406 ] 4   5 \n",
      "[ 0.19799805  1.0136719   0.8183594   0.65478516 -0.453125   -1.6025391 ] 1   3 \n",
      "[-0.16442871  0.26342773  0.11529541  0.12634277 -0.06884766 -0.70458984] 1   1 Match 279\n",
      "\n",
      "[-1.6914062  -0.33911133  0.07623291  1.1904297   0.33618164 -0.5966797 ] 3   2 \n",
      "[-2.2539062   0.00865936 -0.42016602  0.7373047   0.92626953  0.4560547 ] 4   4 Match 280\n",
      "\n",
      "[ 0.6591797   0.76220703 -0.10906982 -0.22558594 -0.33618164 -0.3552246 ] 1   1 Match 281\n",
      "\n",
      "[-0.86035156 -0.1005249   0.19665527  0.6455078   0.13024902 -0.2529297 ] 3   1 \n",
      "[-0.7192383   0.0269165   0.16259766  0.37475586 -0.25732422 -0.5654297 ] 3   3 Match 282\n",
      "\n",
      "[-1.1015625   0.17272949 -0.11749268  0.40698242  0.08856201  0.23083496] 3   0 \n",
      "[-1.7666016  -0.19580078 -0.41479492  0.29785156  0.62353516  0.765625  ] 5   1 \n",
      "[-2.3105469  -0.7163086  -0.515625    0.32739258  1.5810547   1.2607422 ] 4   5 \n",
      "[-8.4082031e-01  1.6494751e-02  2.0068359e-01  1.1077881e-01\n",
      "  4.4465065e-04  2.1484375e-01] 5   2 \n",
      "[-1.1152344   1.6835938  -0.6386719   1.1123047  -0.95947266 -0.44580078] 1   3 \n",
      "[-0.75146484  0.3491211   0.04974365 -0.05130005 -0.3527832  -0.08251953] 1   4 \n",
      "[-1.8310547  -0.29663086 -0.35791016  0.13684082  1.1171875   0.8208008 ] 4   2 \n",
      "[-0.37280273  1.0839844   0.80029297  0.4465332  -0.6376953  -1.2099609 ] 1   1 Match 283\n",
      "\n",
      "[-0.8779297  -0.06842041  0.04330444  0.52441406  0.25024414  0.065979  ] 3   3 Match 284\n",
      "\n",
      "[-2.3085938  -0.36450195  0.1361084   0.74121094  0.7114258   0.62890625] 3   4 \n",
      "[-1.3544922   0.2866211   0.49243164  0.5654297  -0.0567627  -0.59765625] 3   1 \n",
      "[-1.2724609  -0.42895508  0.18566895  0.67626953  0.20056152 -0.22338867] 3   3 Match 285\n",
      "\n",
      "[-2.2070312  -0.3696289  -0.5595703   0.54296875  0.85302734  1.0322266 ] 5   5 Match 286\n",
      "\n",
      "[-0.35791016  0.88671875 -0.3203125  -0.0402832  -0.21948242  0.67333984] 1   1 Match 287\n",
      "\n",
      "[-1.9316406  -0.6098633  -0.4086914   0.18139648  1.0976562   0.9111328 ] 4   1 \n",
      "[-1.4287109  -0.21960449  0.24804688  1.4208984   0.69384766 -0.5053711 ] 3   0 \n",
      "[-1.6337891  -0.40942383 -0.640625    0.26513672  1.0673828   0.82666016] 4   5 \n",
      "[-2.4160156  -0.45043945 -0.39160156  0.34570312  1.09375     1.1035156 ] 5   3 \n",
      "[-0.98291016  0.11761475 -0.2052002   0.41748047  0.20983887 -0.33862305] 3   4 \n",
      "[-1.5302734  -0.31274414 -0.22973633  0.6323242   0.94921875  0.39697266] 4   1 \n",
      "[-2.546875   -0.6928711  -0.12225342  1.2138672   1.0146484   0.2697754 ] 3   4 \n",
      "[-1.8447266  -0.37109375 -0.60302734  0.4741211   1.2363281   1.171875  ] 4   5 \n",
      "[-0.31811523  0.24829102  0.41430664  0.0647583  -0.36938477 -0.74316406] 2   2 Match 288\n",
      "\n",
      "[ 0.01018524  0.49316406 -0.2915039   0.16210938 -0.5751953  -0.3557129 ] 1   0 \n",
      "[-0.93896484  1.8164062  -0.6225586   0.8417969  -1.1269531  -0.40942383] 1   1 Match 289\n",
      "\n",
      "[-2.1464844  -0.49829102 -0.08996582  0.7338867   1.0664062   0.6772461 ] 4   4 Match 290\n",
      "\n",
      "[-0.82714844  0.31640625  0.01957703  0.29760742 -0.12902832 -0.6376953 ] 1   5 \n",
      "[-0.9741211   0.03643799 -0.06860352 -0.06185913  0.09472656  0.11669922] 5   1 \n",
      "[-1.5107422e+00 -1.0290146e-03 -3.8427734e-01  2.4291992e-01\n",
      "  6.2939453e-01  6.4013672e-01] 5   5 Match 291\n",
      "\n",
      "[ 0.76416016  0.58447266  0.6303711   0.30517578 -0.77685547 -1.1533203 ] 0   3 \n",
      "[-1.8847656  -0.17456055 -0.5913086   0.71972656  0.9379883   0.5839844 ] 4   5 \n",
      "[-0.6508789   0.80859375  0.26782227  0.08184814 -0.36914062 -0.52783203] 1   1 Match 292\n",
      "\n",
      "[-1.4355469  -0.31347656 -0.19226074  0.15039062  0.4099121   0.79345703] 5   5 Match 293\n",
      "\n",
      "[-2.4941406  -0.77197266 -0.4099121   0.97802734  1.4765625   0.6376953 ] 4   1 \n",
      "[-1.4462891  -0.30859375  0.62353516  0.5263672   0.49658203  0.20678711] 2   4 \n",
      "[-2.5664062  -0.95751953 -0.28027344  1.1748047   1.3398438   0.5488281 ] 4   2 \n",
      "[-0.14257812  0.15673828 -0.12939453 -0.05105591 -0.09020996 -0.29101562] 1   5 \n",
      "[-0.80566406  0.20947266  0.46850586  0.19873047 -0.19274902 -0.27368164] 2   1 \n",
      "[-1.9511719  -0.5102539  -0.4567871   0.07293701  1.0654297   1.4267578 ] 5   5 Match 294\n",
      "\n",
      "[-2.1699219 -0.5917969 -0.4645996  0.7109375  1.2207031  0.7089844] 4   4 Match 295\n",
      "\n",
      "[-0.20581055  0.3623047   0.05496216  0.09332275 -0.52685547 -0.02708435] 1   5 \n",
      "[-7.3925781e-01 -4.5847893e-04  3.3683777e-03  1.0803223e-01\n",
      "  3.4521484e-01  3.8909912e-03] 4   4 Match 296\n",
      "\n",
      "[-0.7397461  -0.00944519 -0.0269165   0.21008301  0.10247803 -0.28955078] 3   1 \n",
      "[ 0.17834473  0.64160156  0.9008789   0.61083984 -0.7246094  -1.9130859 ] 2   2 Match 297\n",
      "\n",
      "[-0.39208984  0.09484863 -0.16003418  0.03646851 -0.1340332  -0.15637207] 1   5 \n",
      "[-2.2011719  -0.4790039  -0.31103516  0.4580078   1.0800781   0.84716797] 4   1 \n",
      "[-1.9550781  -0.20080566 -0.47924805  0.39794922  0.6411133   0.6542969 ] 5   4 \n",
      "[-2.1386719  -0.3005371  -0.31152344  0.94677734  0.5546875   0.18103027] 3   4 \n",
      "[-1.0615234   0.21069336 -0.5390625  -0.16918945  0.42822266  0.7651367 ] 5   4 \n",
      "[-2.015625   -0.33569336 -0.4572754   0.78222656  0.71972656  0.42822266] 3   5 \n",
      "[ 0.3786621   0.71435547  0.7348633   0.30615234 -0.41870117 -1.609375  ] 2   3 \n",
      "[-1.6796875  -0.35766602 -0.4807129   0.41064453  0.54296875  0.6928711 ] 5   5 Match 298\n",
      "\n",
      "[-1.6054688  -0.17578125 -0.12164307  0.5385742   0.7475586   0.41308594] 4   4 Match 299\n",
      "\n",
      "[-1.6152344  -0.22241211  0.6508789   0.98339844  0.5908203  -0.5126953 ] 3   4 \n",
      "[-2.1855469  -0.49975586 -0.2364502   1.2558594   0.97753906  0.3232422 ] 3   1 \n",
      "[ 0.1003418   0.81396484 -0.3161621  -0.19970703 -0.17175293 -0.06964111] 1   0 \n",
      "[-0.7426758   0.33911133 -0.6567383  -0.26000977  0.0692749   0.45629883] 5   4 \n",
      "[-2.2773438  -0.89453125 -0.34936523  1.3232422   1.1894531   0.43774414] 3   3 Match 300\n",
      "\n",
      "[-0.13671875  0.40893555  0.5805664   0.44140625 -0.34814453 -1.1201172 ] 2   3 \n",
      "[-0.09112549  0.2548828   0.09033203  0.2763672  -0.546875   -0.63720703] 3   1 \n",
      "[-2.5703125  -0.7446289  -0.39331055  0.96972656  1.2783203   0.9189453 ] 4   4 Match 301\n",
      "\n",
      "[-0.13171387  0.78564453  0.6455078   0.54052734 -0.3544922  -0.91503906] 1   2 \n",
      "[-0.46972656  0.68310547 -0.28295898  0.16394043 -0.24450684 -0.21472168] 1   3 \n",
      "[-1.6708984  -0.05230713 -0.5209961   0.3347168   0.6191406   0.7519531 ] 5   4 \n",
      "[-1.2304688   0.08581543 -0.16711426 -0.09301758 -0.01312256 -0.05181885] 1   4 \n",
      "[ 0.19726562  1.3378906   0.39697266  0.5336914  -0.92041016 -1.3330078 ] 1   4 \n",
      "[-1.3554688  -0.33862305  0.02310181  0.3540039   0.71240234  0.26782227] 4   3 \n",
      "[-1.8916016  -0.5888672   0.12133789  0.8696289   0.59765625  0.08618164] 3   4 \n",
      "[-1.3632812   0.2088623  -0.5883789   0.12261963  0.15429688  0.546875  ] 5   4 \n",
      "[-0.8852539  -0.12207031  0.06774902  0.24719238  0.34423828 -0.19396973] 4   2 \n",
      "[-1.5927734  -0.20288086 -0.1005249   0.37329102  0.57666016  0.22131348] 4   5 \n",
      "[-1.5771484  -0.24682617  0.41015625  0.65722656  0.42822266 -0.22546387] 3   4 \n",
      "[-0.25805664  0.21777344  0.59033203 -0.00710678 -0.36523438 -0.82666016] 2   1 \n",
      "[-1.0136719   0.1262207  -0.0489502  -0.09692383 -0.19018555  0.24230957] 5   1 \n",
      "[-2.2988281  -0.19213867 -0.3786621   0.52001953  1.1513672   0.7861328 ] 4   2 \n",
      "[-2.0097656  -0.4074707  -0.41992188  0.4519043   0.9711914   0.88378906] 4   5 \n",
      "[ 0.24487305  1.2109375   0.38793945  0.30981445 -1.1425781  -1.5390625 ] 1   3 \n",
      "[-1.9980469  -0.36010742 -0.29077148  0.4909668   1.3310547   0.45410156] 4   4 Match 302\n",
      "\n",
      "[-2.1640625  -0.1381836  -0.45288086  0.3696289   0.89697266  0.81933594] 4   3 \n",
      "[-1.0742188  -0.12548828  0.8154297   0.9746094   0.15441895 -1.3125    ] 3   4 \n",
      "[ 0.02876282  0.8442383   0.40307617  0.2541504  -1.0253906  -1.3896484 ] 1   0 \n",
      "[-2.21875    -0.5185547  -0.47387695  0.10449219  1.0957031   0.66552734] 4   3 \n",
      "[-0.68359375  0.35083008  0.07904053  0.1508789   0.05990601 -0.17443848] 1   1 Match 303\n",
      "\n",
      "[-2.5292969  -0.38232422 -0.3503418   0.84472656  0.96435547  0.5546875 ] 4   4 Match 304\n",
      "\n",
      "[-0.6430664   0.4260254  -0.03076172  0.12451172 -0.40600586  0.02630615] 1   4 \n",
      "[-2.4824219  -0.63916016 -0.61865234  0.6035156   1.3916016   1.1992188 ] 4   4 Match 305\n",
      "\n",
      "[-1.7011719  -0.33862305 -0.61865234  0.2602539   0.9321289   0.85839844] 4   4 Match 306\n",
      "\n",
      "[-0.99658203  0.02215576 -0.08966064  0.2626953   0.07952881  0.16040039] 3   1 \n",
      "[-2.3222656  -0.7402344  -0.07794189  1.3037109   0.88623047 -0.09326172] 3   2 \n",
      "[-1.8310547   0.51416016 -0.19677734  0.86865234  0.2524414  -0.28393555] 3   1 \n",
      "[-1.1904297  -0.39331055 -0.01256561  0.30493164  0.5205078   0.25561523] 4   4 Match 307\n",
      "\n",
      "[-0.12817383  1.0966797   0.51904297  0.32592773 -0.79785156 -1.4228516 ] 1   1 Match 308\n",
      "\n",
      "[-0.8066406   0.12335205  0.16101074  0.68847656 -0.2109375  -0.49072266] 3   2 \n",
      "[-0.8828125  -0.02378845 -0.16577148  0.46899414  0.58496094 -0.14978027] 4   5 \n",
      "[-2.4980469e+00 -6.5917969e-01 -6.4514160e-02  1.4990234e+00\n",
      "  1.0957031e+00  1.5697479e-03] 3   2 \n",
      "[-2.1777344  -0.6694336   0.10449219  1.1015625   0.7558594   0.1817627 ] 3   3 Match 309\n",
      "\n",
      "[-1.8134766   0.16479492 -0.5415039   0.73095703  0.5078125   0.3317871 ] 3   4 \n",
      "[-1.5703125  -0.5385742   0.5053711   0.32788086  0.5361328   0.17700195] 4   5 \n",
      "[-2.6523438  -0.69677734 -0.41845703  1.0800781   1.2900391   0.85546875] 4   0 \n",
      "[-1.4365234  -0.29711914 -0.3552246   0.5878906   1.2353516   0.57958984] 4   3 \n",
      "[-2.3769531  -0.46777344 -0.40722656  0.70751953  1.3603516   0.8066406 ] 4   5 \n",
      "[-4.16015625e-01  3.28125000e-01 -3.35937500e-01 -2.49624252e-04\n",
      " -5.27038574e-02 -1.16882324e-01] 1   2 \n",
      "[ 0.7192383   0.32421875 -0.01194    -0.25634766 -0.99365234 -0.77246094] 0   3 \n",
      "[-0.69921875  0.49121094  0.16381836  0.60595703  0.1227417  -0.45629883] 3   4 \n",
      "[-1.5654297  -0.26635742 -0.62939453  0.32055664  0.6489258   1.0751953 ] 5   5 Match 310\n",
      "\n",
      "[-0.7519531  -0.20031738  0.30200195  0.43896484  0.03433228 -0.18701172] 3   3 Match 311\n",
      "\n",
      "[ 0.61035156  0.8833008  -0.20092773 -0.30639648 -1.1074219  -0.7446289 ] 1   0 \n",
      "[-0.56347656  0.18469238  0.75634766  0.32177734 -0.36743164 -0.8022461 ] 2   2 Match 312\n",
      "\n",
      "[-0.1899414   0.43603516  0.04846191  0.3334961  -0.27368164 -0.43017578] 1   1 Match 313\n",
      "\n",
      "[-1.375      -0.22875977 -0.04608154  0.39135742  0.19165039  0.35180664] 3   2 \n",
      "[-0.0682373   0.11230469  0.23608398 -0.19665527 -0.38134766 -0.37841797] 2   1 \n",
      "[-0.08337402  0.2841797  -0.12011719 -0.03967285 -0.3005371   0.0345459 ] 1   5 \n",
      "[-1.3916016   0.61328125  0.33129883  0.5644531  -0.16149902 -0.34960938] 1   2 \n",
      "[ 0.5415039   1.078125    0.22521973  0.21862793 -0.6044922  -0.7705078 ] 1   0 \n",
      "[-1.7109375  -0.16052246 -0.7055664  -0.00601196  0.6333008   1.1376953 ] 5   2 \n",
      "[-0.4970703   0.7294922  -0.33154297  0.05337524 -0.07281494 -0.02131653] 1   5 \n",
      "[-1.9990234   0.15563965  0.4375      0.8354492   0.86816406 -0.07354736] 4   3 \n",
      "[-1.5019531   0.09277344 -0.6010742   0.29077148  0.55810547  0.43310547] 4   5 \n",
      "[-0.1274414   0.5444336   0.47460938  0.11932373 -0.27490234 -0.9291992 ] 1   1 Match 314\n",
      "\n",
      "[-1.5478516  -0.10723877 -0.7104492   0.13391113  0.65966797  1.1054688 ] 5   1 \n",
      "[-1.0166016   0.43945312 -0.17810059  0.50390625  0.07073975 -0.25390625] 3   5 \n",
      "[-1.2402344   0.06872559 -0.30297852  0.1875      0.4013672   0.78515625] 5   1 \n",
      "[-0.86572266  1.34375    -0.5332031   1.1435547  -0.62353516 -0.22753906] 1   1 Match 315\n",
      "\n",
      "[-9.7070312e-01  1.7651367e-01 -6.2011719e-01  9.8632812e-02\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -6.1082840e-04  4.0722656e-01] 5   3 \n",
      "[-1.6904297  -0.27978516 -0.29541016  0.29248047  0.5864258   0.8105469 ] 5   4 \n",
      "[-0.72265625  2.0371094  -0.51708984  1.0488281  -1.0722656  -0.35546875] 1   3 \n",
      "[ 1.0224609   0.8432617   0.23925781 -0.14282227 -0.80566406 -1.1640625 ] 0   3 \n",
      "[-1.4326172   0.39086914  0.24645996  0.6333008   0.01599121  0.05102539] 3   4 \n",
      "[-1.9169922  -0.3618164  -0.5126953   0.24194336  1.1054688   1.2089844 ] 5   5 Match 316\n",
      "\n",
      "[-0.31274414  0.64453125 -0.4111328  -0.26416016 -0.36767578 -0.10626221] 1   5 \n",
      "[ 1.5117188   0.6333008  -0.00377655 -0.36206055 -0.8520508  -0.79296875] 0   5 \n",
      "[-1.1484375   0.04470825 -0.10083008  0.2685547   0.21166992  0.08422852] 3   2 \n",
      "[-2.4375     -0.44018555 -0.11669922  0.5957031   1.1796875   0.7792969 ] 4   4 Match 317\n",
      "\n",
      "[-1.3730469   0.03289795 -0.6772461   0.18652344  0.6894531   1.2207031 ] 5   2 \n",
      "[-0.47827148 -0.0244751  -0.01940918  0.10028076 -0.01705933 -0.37841797] 3   4 \n",
      "[-0.68066406  0.31835938 -0.24780273  0.14868164  0.16418457 -0.08575439] 1   4 \n",
      "[-0.04840088  0.9042969   0.84472656  0.9580078  -0.6352539  -1.859375  ] 3   2 \n",
      "[-2.2617188  -0.24902344 -0.10003662  0.81591797  0.7919922   0.65625   ] 3   2 \n",
      "[-0.43359375 -0.01219177 -0.25854492  0.22595215 -0.32641602  0.09069824] 3   2 \n",
      "[-1.2011719   0.12805176  0.4777832   0.47216797  0.01841736 -0.42871094] 2   2 Match 318\n",
      "\n",
      "[-1.1455078   0.34936523  0.35083008  0.7402344   0.04229736 -0.40014648] 3   3 Match 319\n",
      "\n",
      "[-0.82666016 -0.20874023 -0.48388672  0.1907959  -0.14880371  0.0015049 ] 3   4 \n",
      "[-0.03555298  0.515625   -0.17687988  0.2631836  -0.87109375 -0.51904297] 1   0 \n",
      "[-0.6586914  -0.08905029  1.0224609   1.0625      0.2130127  -1.0351562 ] 3   3 Match 320\n",
      "\n",
      "[-1.3525391  -0.20397949 -0.6669922   0.12683105  0.7416992   0.6982422 ] 4   5 \n",
      "[-1.3066406   0.5620117   0.2824707   0.4753418  -0.25708008 -0.53271484] 1   3 \n",
      "[ 0.24304199  0.9057617  -0.14135742 -0.03479004 -0.66552734 -0.61035156] 1   1 Match 321\n",
      "\n",
      "[-2.1425781  -0.46264648 -0.03979492  0.4736328   0.4560547   0.27563477] 3   4 \n",
      "[-1.5693359  -0.6220703   0.4580078   0.9301758   0.47973633 -0.47607422] 3   4 \n",
      "[-1.8320312  -0.32861328 -0.37646484  0.4013672   1.0410156   0.92578125] 4   3 \n",
      "[-1.4023438   0.03198242 -0.5727539  -0.15063477  0.30981445  0.43603516] 5   5 Match 322\n",
      "\n",
      "[-1.2558594  -0.07293701  0.12658691  0.42895508  0.34179688  0.03161621] 3   4 \n",
      "[-0.89404297 -0.06408691  0.20031738  0.14770508  0.24694824 -0.35107422] 4   4 Match 323\n",
      "\n",
      "[-1.3486328   0.01733398 -0.06237793  0.48046875  0.80371094  0.24816895] 4   4 Match 324\n",
      "\n",
      "[ 0.02558899 -0.0869751  -0.06866455 -0.2019043   0.05496216 -0.13720703] 4   2 \n",
      "[-0.8457031   0.18444824  0.23779297  0.27368164 -0.17199707  0.03805542] 3   4 \n",
      "[-0.6220703   0.58935547  0.2697754   0.47314453 -0.32055664 -0.6689453 ] 1   2 \n",
      "[-2.7539062  -0.5541992  -0.48779297  0.9770508   1.3144531   0.65185547] 4   5 \n",
      "[-1.0107422   0.35766602  0.8383789   0.86035156 -0.01042175 -1.4550781 ] 3   2 \n",
      "[-1.8144531  -0.3256836  -0.42114258  0.15319824  0.8671875   0.75927734] 4   4 Match 325\n",
      "\n",
      "[ 0.13586426  0.9379883   0.45483398  0.37841797 -0.80859375 -1.0947266 ] 1   2 \n",
      "[-1.5546875  -0.16687012 -0.5698242   0.08435059  0.66064453  0.72802734] 5   5 Match 326\n",
      "\n",
      "[-1.7226562  -0.18054199 -0.49194336  0.7319336   0.94921875  0.46069336] 4   5 \n",
      "[-0.8120117   0.18066406  0.28125     0.55029297 -0.28051758 -0.33813477] 3   2 \n",
      "[-0.25830078 -0.16906738 -0.0440979   0.17053223 -0.1105957  -0.24682617] 3   0 \n",
      "[-0.6621094   0.38110352  0.12347412  0.44604492 -0.29492188 -0.3552246 ] 3   1 \n",
      "[-1.4443359  -0.07006836 -0.41357422  0.08410645  0.47192383  0.33569336] 4   4 Match 327\n",
      "\n",
      "[-0.55078125  0.6894531  -0.05209351  0.2524414  -0.28881836 -0.57470703] 1   2 \n",
      "[-1.484375   -0.17199707 -0.03887939  0.39770508  0.5605469   0.11633301] 4   4 Match 328\n",
      "\n",
      "[-0.83496094  0.10882568 -0.10717773  0.17382812  0.1381836  -0.17565918] 3   2 \n",
      "[ 0.28808594  0.43139648 -0.34326172 -0.28344727 -0.76708984 -0.25561523] 1   5 \n",
      "[-2.1386719  -0.6411133  -0.08331299  0.48583984  0.7270508   0.6069336 ] 4   2 \n",
      "[-2.0488281  -0.44799805 -0.23828125  0.6816406   1.0400391   0.79345703] 4   2 \n",
      "[-0.5600586   0.64697266 -0.03683472  0.08520508 -0.33081055 -0.03302002] 1   1 Match 329\n",
      "\n",
      "[-1.0585938  -0.09185791  0.4621582   1.3183594   0.5810547  -1.1904297 ] 3   5 \n",
      "[-0.24804688  0.52783203  0.18530273  0.0803833  -0.30615234 -0.37890625] 1   4 \n",
      "[-1.0292969e+00 -7.6675415e-04 -2.2375488e-01  3.4497070e-01\n",
      "  4.7070312e-01  3.5949707e-02] 4   1 \n",
      "[-0.37841797  0.39868164  0.05310059 -0.14978027 -0.02816772 -0.2368164 ] 1   2 \n",
      "[-1.078125   -0.34814453 -0.20861816  0.42504883  0.20715332  0.28271484] 3   3 Match 330\n",
      "\n",
      "[ 0.57421875  0.58203125  0.39794922  0.2524414  -0.6347656  -0.9941406 ] 1   1 Match 331\n",
      "\n",
      "[-0.54785156  0.4345703  -0.4140625   0.296875    0.14697266  0.5209961 ] 5   4 \n",
      "[-0.6694336   0.57421875  0.45483398  0.45629883 -0.19946289 -1.0566406 ] 1   2 \n",
      "[-2.7382812  -0.5908203  -0.21105957  0.7861328   1.4355469   1.0195312 ] 4   5 \n",
      "[-1.265625   -0.04122925  0.25146484  0.5864258   0.25439453 -0.56347656] 3   5 \n",
      "[-0.8647461  -0.20446777  0.5991211   0.59228516 -0.12072754 -0.6166992 ] 2   2 Match 332\n",
      "\n",
      "[-0.6010742   0.26293945 -0.19165039  0.3251953  -0.08251953  0.04495239] 3   2 \n",
      "[-1.8349609   0.07733154  0.39208984  1.2617188   0.21203613 -0.78808594] 3   4 \n",
      "[-1.5341797  -0.16992188 -0.44091797  0.15527344  0.7783203   0.9555664 ] 5   4 \n",
      "[-1.0292969   0.26513672 -0.05535889  0.72509766  0.09344482 -0.17785645] 3   1 \n",
      "[-0.1862793   0.90478516 -0.06427002  0.12060547 -0.26904297 -0.05633545] 1   0 \n",
      "[-1.2617188  -0.4423828  -0.38842773  0.66845703  0.67822266  0.48901367] 4   4 Match 333\n",
      "\n",
      "[-1.4052734  -0.0369873   0.074646    0.34838867  0.4453125   0.4753418 ] 5   3 \n",
      "[-1.2558594   0.55615234 -0.10095215  0.74560547 -0.13110352 -0.02677917] 3   1 \n",
      "[-0.19360352  0.57470703  0.5678711   0.6611328  -0.60839844 -1.0146484 ] 3   2 \n",
      "[-1.6523438  -0.4909668  -0.07110596  1.0595703   1.2958984   0.1361084 ] 4   3 \n",
      "[-2.2285156  -0.5488281  -0.5336914   0.95751953  1.1757812   0.5541992 ] 4   3 \n",
      "[-2.2246094  -0.21289062 -0.5258789   0.3076172   1.2841797   1.1230469 ] 4   4 Match 334\n",
      "\n",
      "[-0.46850586  0.4206543  -0.4650879   0.02099609  0.0463562  -0.11199951] 1   5 \n",
      "[ 0.09381104  0.36914062 -0.3173828  -0.30419922 -0.59375    -0.47265625] 1   3 \n",
      "[-1.4277344  -0.5048828   0.2775879   0.63964844  0.5878906  -0.16503906] 3   2 \n",
      "[ 0.06445312  0.28808594  0.68652344  0.71533203 -0.26708984 -1.1054688 ] 3   2 \n",
      "[-2.3242188  -0.61865234 -0.36865234  0.62646484  1.3740234   0.8027344 ] 4   4 Match 335\n",
      "\n",
      "[-0.46069336  0.41625977  0.10198975 -0.04464722 -0.03744507 -0.15014648] 1   1 Match 336\n",
      "\n",
      "[-0.8520508   1.3945312  -0.6245117   0.9013672  -0.9765625  -0.41015625] 1   1 Match 337\n",
      "\n",
      "[-0.6816406  -0.05804443  0.41357422  0.86279297  0.47753906 -0.35961914] 3   5 \n",
      "[-2.765625   -0.3869629  -0.2758789   0.96484375  1.0800781   0.94873047] 4   5 \n",
      "[-1.5117188   0.26245117  0.30981445  1.2929688  -0.08648682 -0.7709961 ] 3   3 Match 338\n",
      "\n",
      "[-0.78515625  0.2614746   0.1595459   0.46728516  0.04586792 -0.40942383] 3   2 \n",
      "[-1.9101562  -0.52001953 -0.6386719   0.54003906  0.9765625   0.82177734] 4   0 \n",
      "[-0.4501953   0.22839355  0.3737793   0.17407227 -0.3959961  -0.54248047] 2   3 \n",
      "[-1.9013672  -0.4248047  -0.2064209   0.30981445  1.2451172   0.859375  ] 4   5 \n",
      "[ 0.2709961   0.32788086 -0.15246582 -0.15905762 -0.51416016 -0.39013672] 1   4 \n",
      "[-2.3808594  -0.49389648 -0.26342773  1.3759766   0.76416016 -0.13342285] 3   5 \n",
      "[-0.25341797  0.5371094   0.5644531   0.39819336 -0.4621582  -1.1503906 ] 2   3 \n",
      "[-1.1884766   0.15881348  0.45214844  0.80810547  0.10119629 -0.4494629 ] 3   2 \n",
      "[-0.4453125   0.02816772  0.38085938  0.25048828  0.01759338 -0.33154297] 2   2 Match 339\n",
      "\n",
      "[-1.6757812  -0.3840332  -0.03997803  0.60058594  0.5488281  -0.081604  ] 3   1 \n",
      "[-1.1621094  -0.3251953  -0.18249512  0.23486328  0.21740723  0.08776855] 3   1 \n",
      "[ 0.31079102  0.71533203  0.05853271  0.0368042  -0.4416504  -0.5073242 ] 1   3 \n",
      "[-1.0029297  -0.04406738 -0.04891968  0.34301758  0.6464844   0.16442871] 4   5 \n",
      "[-0.5239258   0.14208984  0.01476288  0.12805176 -0.18066406 -0.2841797 ] 1   4 \n",
      "[-1.0371094   0.38598633 -0.0536499   0.44970703  0.30029297 -0.2915039 ] 3   0 \n",
      "[-2.0371094  -0.27978516  0.8408203   1.2753906   0.40405273 -0.91064453] 3   2 \n",
      "[-2.0351562  -0.5102539  -0.2915039   0.6352539   1.0859375   0.61083984] 4   5 \n",
      "[-1.7675781  -0.5966797   0.20471191  0.47998047  0.6455078   0.21533203] 4   4 Match 340\n",
      "\n",
      "[-0.36889648  0.41357422  0.10766602 -0.23034668 -0.25268555 -0.15856934] 1   2 \n",
      "[-1.1298828  -0.11566162  0.67822266  0.57666016  0.32910156 -0.41503906] 2   3 \n",
      "[-1.2001953   0.36450195  0.7324219   0.86816406 -0.08642578 -0.6743164 ] 3   2 \n",
      "[ 0.08428955  0.9707031   1.0527344   0.9082031  -0.35498047 -1.5673828 ] 2   3 \n",
      "[-0.8569336   0.04867554  0.15112305  0.34643555  0.33276367 -0.31396484] 3   1 \n",
      "[-0.75341797  0.3232422  -0.04971313  0.10144043 -0.01568604  0.10986328] 1   2 \n",
      "[-0.83496094  0.11328125  0.8261719   0.5756836  -0.39819336 -1.0263672 ] 2   5 \n",
      "[-0.20263672 -0.2088623   0.18432617  0.29833984 -0.09436035 -0.36914062] 3   5 \n",
      "[-1.2724609  -0.79589844  0.859375    1.2705078   0.39208984 -0.5341797 ] 3   3 Match 341\n",
      "\n",
      "[-1.0136719   0.57470703  0.73095703  0.7294922  -0.10369873 -0.9135742 ] 2   3 \n",
      "[ 0.22912598  0.9238281  -0.19299316 -0.2578125  -0.7626953  -0.39575195] 1   2 \n",
      "[-1.5566406  -0.15625    -0.15734863  0.0871582   0.54003906  0.671875  ] 5   4 \n",
      "[-1.5488281  -0.02915955  0.06335449  0.56396484  0.44262695 -0.05877686] 3   4 \n",
      "[-0.00747681  0.02122498  0.08178711  0.13671875 -0.4345703  -0.05795288] 3   3 Match 342\n",
      "\n",
      "[-1.0322266  -0.07720947  1.0849609   1.0683594   0.1184082  -1.2001953 ] 2   1 \n",
      "[-1.6152344   0.25634766  0.23254395  1.1113281   0.24194336 -0.32055664] 3   3 Match 343\n",
      "\n",
      "[-1.4326172  -0.32348633  0.7060547   0.72265625  0.4987793  -0.4975586 ] 3   4 \n",
      "[-1.1552734  -0.58935547  0.5078125   0.9658203   0.5449219  -0.63183594] 3   3 Match 344\n",
      "\n",
      "[ 0.54296875  1.0576172   0.8383789   0.36279297 -0.92822266 -1.7587891 ] 1   2 \n",
      "[-0.9628906  -0.41308594  0.49682617  0.6381836   0.41186523 -0.43408203] 3   1 \n",
      "[-1.3818359  -0.03016663 -0.00937653  0.1772461   0.06188965  0.6767578 ] 5   4 \n",
      "[-0.51904297  0.29174805 -0.0513916  -0.25610352 -0.2565918  -0.10089111] 1   3 \n",
      "[-2.0292969  -0.45092773 -0.9248047   0.30688477  1.3730469   1.1679688 ] 4   4 Match 345\n",
      "\n",
      "[-0.27807617  0.7207031   0.6948242   0.5473633  -0.37597656 -1.0751953 ] 1   1 Match 346\n",
      "\n",
      "[-0.82421875  0.47607422  0.14953613  0.15881348 -0.43920898 -0.06365967] 1   2 \n",
      "[-0.7446289   0.11651611  0.3840332   0.8051758  -0.2824707  -0.61328125] 3   2 \n",
      "[-1.0947266  -0.09667969  0.16723633  0.81152344  0.74560547 -0.43286133] 3   0 \n",
      "[-0.93847656 -0.09429932 -0.01226044  0.0869751   0.3330078   0.16564941] 4   2 \n",
      "[-0.27270508  0.32788086  0.27416992  0.06842041 -0.11566162 -0.3930664 ] 1   2 \n",
      "[-0.82910156 -0.05389404  0.4802246   0.08227539 -0.10174561 -0.30444336] 2   3 \n",
      "[-0.38549805  0.5488281   0.0010252   0.05337524 -0.58496094 -0.10113525] 1   5 \n",
      "[-0.72998047  0.51123047 -0.17053223  0.38378906 -0.07519531 -0.5234375 ] 1   4 \n",
      "[-0.16772461  0.02351379  0.7128906   0.80078125  0.04437256 -1.2236328 ] 3   2 \n",
      "[-2.4277344  -0.26538086 -0.12866211  0.56347656  0.4020996   0.19055176] 3   3 Match 347\n",
      "\n",
      "[-0.35424805  0.25610352 -0.21679688 -0.06530762 -0.20336914  0.11584473] 1   3 \n",
      "[-1.2304688   0.1496582   0.8334961   0.6479492  -0.08325195 -0.8198242 ] 2   4 \n",
      "[-0.7026367   0.30078125 -0.32763672  0.55322266  0.33203125 -0.07659912] 3   4 \n",
      "[-1.3798828  -0.34350586  0.13256836  0.40551758  0.1661377   0.07672119] 3   2 \n",
      "[-2.40625    -0.64208984 -0.5336914   0.62939453  1.2744141   0.74560547] 4   3 \n",
      "[-2.2910156  -0.4868164  -0.49365234  0.6479492   1.359375    1.0234375 ] 4   2 \n",
      "[-0.4716797   0.11151123  0.46875     0.5288086   0.22265625 -0.55615234] 3   5 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.36621094  0.5991211  -0.30444336 -0.34228516 -0.68408203 -0.59765625] 1   1 Match 348\n",
      "\n",
      "[-2.03125    -0.22937012  0.55322266  0.7265625   0.5361328  -0.11694336] 3   2 \n",
      "[ 0.6816406   0.33544922 -0.14892578 -0.25830078 -0.73779297 -0.7866211 ] 0   0 Match 349\n",
      "\n",
      "[-1.0615234   0.06201172 -0.20715332  0.11572266  0.38867188  0.07757568] 4   0 \n",
      "[-0.7314453   0.4494629  -0.1472168   0.11578369  0.10473633  0.32470703] 1   3 \n",
      "[-1.3193359  -0.1619873  -0.03546143  0.50683594  0.05413818 -0.29711914] 3   2 \n",
      "[-2.6699219  -0.69140625 -0.6220703   0.78515625  1.3730469   1.3105469 ] 4   1 \n",
      "[-0.9321289   0.6411133   0.25976562  0.68066406 -0.25610352 -0.39990234] 3   4 \n",
      "[ 1.1464844   0.4790039   0.33276367  0.33984375 -0.5029297  -1.25      ] 0   2 \n",
      "[-0.09283447  0.27392578 -0.16467285 -0.03109741 -0.2541504  -0.14770508] 1   0 \n",
      "[-0.52001953  0.11218262 -0.23120117 -0.1381836  -0.18054199 -0.0736084 ] 1   1 Match 350\n",
      "\n",
      "350\n"
     ]
    }
   ],
   "source": [
    " Pred=[]\n",
    "\n",
    "countCorrect=0\n",
    "\n",
    "for row in range(TestModel_outputs.shape[0]):\n",
    "    outputs=TestModel_outputs[row]\n",
    "    #print(test.iloc[row,0])\n",
    "    print(outputs, end=' ')\n",
    "    \n",
    "    result=0\n",
    "    if outputs[0]<outputs[1]:result=1\n",
    "    if outputs[result]<outputs[2]:result=2\n",
    "    if outputs[result]<outputs[3]:result=3\n",
    "    if outputs[result]<outputs[4]:result=4\n",
    "    if outputs[result]<outputs[5]:result=5\n",
    "    Pred.append(result)\n",
    "    print(result, ' ',test.iloc[row,1], end=' ')\n",
    "    if result==test.iloc[row,1]:\n",
    "        countCorrect+=1\n",
    "        print('Match',countCorrect)\n",
    "    print('')\n",
    "\n",
    "print(countCorrect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[16 36 12 16 10  2]\n",
      " [ 5 83 21 68 39 34]\n",
      " [ 4 51 27 78 29 25]\n",
      " [ 5 49 29 90 68 26]\n",
      " [ 0 30  5 91 83 40]\n",
      " [ 3 27  6 55 69 51]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "print(metrics.confusion_matrix(test['labels'],Pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Pants       0.48      0.17      0.26        92\n",
      "       False       0.30      0.33      0.32       250\n",
      " Barely-True       0.27      0.13      0.17       214\n",
      "   Half-True       0.23      0.34      0.27       267\n",
      " Mostly-True       0.28      0.33      0.30       249\n",
      "        True       0.29      0.24      0.26       211\n",
      "\n",
      "    accuracy                           0.27      1283\n",
      "   macro avg       0.31      0.26      0.26      1283\n",
      "weighted avg       0.29      0.27      0.27      1283\n",
      "\n"
     ]
    }
   ],
   "source": [
    "target_names = ['Pants', 'False', 'Barely-True','Half-True','Mostly-True','True']\n",
    "\n",
    "print(metrics.classification_report(test['labels'], Pred,target_names =target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving...\n",
      "Saving Complete on 2020-05-01 08:32:11.747996 in: ./TunedModels/roberta/roberta-large/Saves/\n"
     ]
    }
   ],
   "source": [
    "# saving the output of the models to CSVs\n",
    "#these are 1X6 classification vectors\n",
    "\n",
    "SavesDirectory='./TunedModels/'+model_class+'/'+model_version+\"/Saves/\"\n",
    "print('Saving...')\n",
    "trainOut = pd.DataFrame(data= TrainModel_outputs )\n",
    "trainOut.to_csv(SavesDirectory+'trainOut.tsv', sep='\\t',  index=False)\n",
    "\n",
    "evalOut = pd.DataFrame(data= EvalModel_outputs )\n",
    "evalOut.to_csv(SavesDirectory+'evalOut.tsv', sep='\\t',  index=False)\n",
    "\n",
    "testOut = pd.DataFrame(data= TestModel_outputs )\n",
    "testOut.to_csv(SavesDirectory+'testOut.tsv', sep='\\t',  index=False)\n",
    "\n",
    "print('Saving Complete on',datetime.now() ,'in:', SavesDirectory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "del(model)\n",
    "#del(train,Eval,test)\n",
    "del(trainOut,evalOut,testOut)\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Adding the reputation vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section takes the output results from the transformer used above and uses it together with the speaker's reputation to enhance the classification.\n",
    "\n",
    "Before running this section it is suggested that you halt the program and start running it again from this cell. The neural net will likely have an error caused by some unreleased variable used by thr simple transformers library. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PantsTotal</th>\n",
       "      <th>NotRealTotal</th>\n",
       "      <th>BarelyTotal</th>\n",
       "      <th>HalfTotal</th>\n",
       "      <th>MostlyTotal</th>\n",
       "      <th>Truths</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.005</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.875000</td>\n",
       "      <td>-0.035553</td>\n",
       "      <td>-0.036926</td>\n",
       "      <td>0.124512</td>\n",
       "      <td>0.091125</td>\n",
       "      <td>0.248901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.095</td>\n",
       "      <td>0.160</td>\n",
       "      <td>0.170</td>\n",
       "      <td>0.290</td>\n",
       "      <td>0.165</td>\n",
       "      <td>0.165</td>\n",
       "      <td>-1.904297</td>\n",
       "      <td>-0.231323</td>\n",
       "      <td>0.364746</td>\n",
       "      <td>1.080078</td>\n",
       "      <td>0.403564</td>\n",
       "      <td>-0.042603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.005</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.040</td>\n",
       "      <td>0.010</td>\n",
       "      <td>-2.021484</td>\n",
       "      <td>-0.625000</td>\n",
       "      <td>0.489990</td>\n",
       "      <td>1.277344</td>\n",
       "      <td>0.593262</td>\n",
       "      <td>-0.539062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.005</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.040</td>\n",
       "      <td>0.010</td>\n",
       "      <td>-2.273438</td>\n",
       "      <td>-0.583496</td>\n",
       "      <td>-0.375000</td>\n",
       "      <td>1.092773</td>\n",
       "      <td>0.999512</td>\n",
       "      <td>0.554688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.035</td>\n",
       "      <td>0.145</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.345</td>\n",
       "      <td>0.380</td>\n",
       "      <td>0.365</td>\n",
       "      <td>-2.255859</td>\n",
       "      <td>-0.787598</td>\n",
       "      <td>0.012428</td>\n",
       "      <td>1.327148</td>\n",
       "      <td>0.995117</td>\n",
       "      <td>-0.192749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10264</th>\n",
       "      <td>0.005</td>\n",
       "      <td>0.030</td>\n",
       "      <td>0.070</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.020</td>\n",
       "      <td>-0.273926</td>\n",
       "      <td>0.841309</td>\n",
       "      <td>0.604980</td>\n",
       "      <td>0.637695</td>\n",
       "      <td>-0.615723</td>\n",
       "      <td>-1.586914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10265</th>\n",
       "      <td>0.055</td>\n",
       "      <td>0.075</td>\n",
       "      <td>0.080</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.035</td>\n",
       "      <td>-2.171875</td>\n",
       "      <td>-0.200439</td>\n",
       "      <td>-0.195557</td>\n",
       "      <td>0.686523</td>\n",
       "      <td>1.147461</td>\n",
       "      <td>1.179688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10266</th>\n",
       "      <td>0.035</td>\n",
       "      <td>0.115</td>\n",
       "      <td>0.140</td>\n",
       "      <td>0.190</td>\n",
       "      <td>0.170</td>\n",
       "      <td>0.075</td>\n",
       "      <td>-1.827148</td>\n",
       "      <td>-0.359619</td>\n",
       "      <td>-0.008209</td>\n",
       "      <td>0.834473</td>\n",
       "      <td>0.503418</td>\n",
       "      <td>0.132935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10267</th>\n",
       "      <td>0.305</td>\n",
       "      <td>0.570</td>\n",
       "      <td>0.315</td>\n",
       "      <td>0.255</td>\n",
       "      <td>0.185</td>\n",
       "      <td>0.070</td>\n",
       "      <td>-0.827637</td>\n",
       "      <td>0.247314</td>\n",
       "      <td>-0.009705</td>\n",
       "      <td>0.440430</td>\n",
       "      <td>0.225342</td>\n",
       "      <td>-0.443848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10268</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.365723</td>\n",
       "      <td>0.539062</td>\n",
       "      <td>0.328369</td>\n",
       "      <td>0.183594</td>\n",
       "      <td>-0.918945</td>\n",
       "      <td>-0.920898</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10269 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       PantsTotal  NotRealTotal  BarelyTotal  HalfTotal  MostlyTotal  Truths  \\\n",
       "0           0.005         0.000        0.000      0.000        0.000   0.000   \n",
       "1           0.095         0.160        0.170      0.290        0.165   0.165   \n",
       "2           0.005         0.010        0.005      0.015        0.040   0.010   \n",
       "3           0.005         0.010        0.005      0.015        0.040   0.010   \n",
       "4           0.035         0.145        0.200      0.345        0.380   0.365   \n",
       "...           ...           ...          ...        ...          ...     ...   \n",
       "10264       0.005         0.030        0.070      0.050        0.050   0.020   \n",
       "10265       0.055         0.075        0.080      0.100        0.050   0.035   \n",
       "10266       0.035         0.115        0.140      0.190        0.170   0.075   \n",
       "10267       0.305         0.570        0.315      0.255        0.185   0.070   \n",
       "10268       0.000         0.005        0.000      0.000        0.000   0.000   \n",
       "\n",
       "              0         1         2         3         4         5  \n",
       "0     -0.875000 -0.035553 -0.036926  0.124512  0.091125  0.248901  \n",
       "1     -1.904297 -0.231323  0.364746  1.080078  0.403564 -0.042603  \n",
       "2     -2.021484 -0.625000  0.489990  1.277344  0.593262 -0.539062  \n",
       "3     -2.273438 -0.583496 -0.375000  1.092773  0.999512  0.554688  \n",
       "4     -2.255859 -0.787598  0.012428  1.327148  0.995117 -0.192749  \n",
       "...         ...       ...       ...       ...       ...       ...  \n",
       "10264 -0.273926  0.841309  0.604980  0.637695 -0.615723 -1.586914  \n",
       "10265 -2.171875 -0.200439 -0.195557  0.686523  1.147461  1.179688  \n",
       "10266 -1.827148 -0.359619 -0.008209  0.834473  0.503418  0.132935  \n",
       "10267 -0.827637  0.247314 -0.009705  0.440430  0.225342 -0.443848  \n",
       "10268 -0.365723  0.539062  0.328369  0.183594 -0.918945 -0.920898  \n",
       "\n",
       "[10269 rows x 12 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "train=pd.read_excel('trainReputation.xlsx' )\n",
    "train=train.iloc[:,:-2].astype(float)\n",
    "train=train/200  #for scaling\n",
    "#train\n",
    "\n",
    "model_class='roberta'  # bert or roberta or albert\n",
    "model_version='roberta-large' #bert-base-cased, roberta-base, roberta-large, albert-base-v2 OR albert-large-v2\n",
    "SavesDirectory='./TunedModels/'+model_class+'/'+model_version+\"/Saves/\"\n",
    "TF_Output=pd.read_csv( SavesDirectory+'trainOut.tsv', sep='\\t')\n",
    "\n",
    "train=pd.concat([train,TF_Output], axis=1)\n",
    "\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10264</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10265</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10266</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10267</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10268</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10269 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0  1  2  3  4  5\n",
       "0      1  0  0  0  0  0\n",
       "1      0  0  0  1  0  0\n",
       "2      0  0  0  0  1  0\n",
       "3      0  0  0  0  1  0\n",
       "4      0  0  0  0  0  1\n",
       "...   .. .. .. .. .. ..\n",
       "10264  0  0  0  0  1  0\n",
       "10265  0  0  0  0  0  1\n",
       "10266  0  0  0  1  0  0\n",
       "10267  0  1  0  0  0  0\n",
       "10268  0  1  0  0  0  0\n",
       "\n",
       "[10269 rows x 6 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TrainLables=pd.read_excel('trainReputation.xlsx' )\n",
    "TrainLables=TrainLables.iloc[:,-1] \n",
    "\n",
    "TrainLables=pd.get_dummies(TrainLables)\n",
    "TrainLables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0050,  0.0000,  0.0000,  ...,  0.1245,  0.0911,  0.2489],\n",
       "        [ 0.0950,  0.1600,  0.1700,  ...,  1.0801,  0.4036, -0.0426],\n",
       "        [ 0.0050,  0.0100,  0.0050,  ...,  1.2773,  0.5933, -0.5391],\n",
       "        ...,\n",
       "        [ 0.0350,  0.1150,  0.1400,  ...,  0.8345,  0.5034,  0.1329],\n",
       "        [ 0.3050,  0.5700,  0.3150,  ...,  0.4404,  0.2253, -0.4438],\n",
       "        [ 0.0000,  0.0050,  0.0000,  ...,  0.1836, -0.9189, -0.9209]],\n",
       "       dtype=torch.float64)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input=torch.tensor(train.values)\n",
    " \n",
    "input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 1., 0., 0.],\n",
       "        [0., 0., 0., 0., 1., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0., 0., 0.],\n",
       "        [0., 1., 0., 0., 0., 0.]], dtype=torch.float64)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets=torch.tensor(TrainLables.astype(float).values)\n",
    " \n",
    "targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input size: 12\n",
      "output size: 6\n"
     ]
    }
   ],
   "source": [
    " \n",
    "size= torch.tensor(input[0].size())\n",
    "InputSize=size.item()\n",
    "\n",
    "OutputSize=torch.tensor(targets[0].size()).item()\n",
    "\n",
    "print('input size:', InputSize)\n",
    "print('output size:', OutputSize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Net(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "         \n",
    "        # an affine operation: y = Wx + b\n",
    "        self.fc1 = nn.Linear(InputSize, 24)  # input size 32\n",
    "        self.fc2 = nn.Linear(24, 12)\n",
    "        self.fc3 = nn.Linear(12, OutputSize)  #classifies 'outputsize' different classes\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.tanh(self.fc1(x))\n",
    "        x = torch.tanh(self.fc2(x)) \n",
    "        x = torch.tanh(self.fc3(x)).double()\n",
    "        return x\n",
    "\n",
    "    \n",
    "\n",
    "#now we use it\n",
    "\n",
    "net = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here we  setup the neural network parameters\n",
    "# pick an optimizer (Simple Gradient Descent)\n",
    "\n",
    "learning_rate = 1e-4\n",
    "criterion = nn.MSELoss()  #computes the loss Function\n",
    "\n",
    "import torch.optim as optim\n",
    "\n",
    "# creating optimizer\n",
    "#optimizer = optim.SGD(net.parameters(), lr=learning_rate)\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor(0.0931, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 0\n",
      "Loss: tensor(0.0931, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1\n",
      "Loss: tensor(0.0931, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2\n",
      "Loss: tensor(0.0931, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3\n",
      "Loss: tensor(0.0931, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4\n",
      "Loss: tensor(0.0931, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5\n",
      "Loss: tensor(0.0931, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6\n",
      "Loss: tensor(0.0931, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7\n",
      "Loss: tensor(0.0931, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8\n",
      "Loss: tensor(0.0931, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 9\n",
      "Loss: tensor(0.0931, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 10\n",
      "Loss: tensor(0.0931, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 11\n",
      "Loss: tensor(0.0931, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 12\n",
      "Loss: tensor(0.0931, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 13\n",
      "Loss: tensor(0.0931, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 14\n",
      "Loss: tensor(0.0931, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 15\n",
      "Loss: tensor(0.0931, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 16\n",
      "Loss: tensor(0.0931, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 17\n",
      "Loss: tensor(0.0931, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 18\n",
      "Loss: tensor(0.0931, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 19\n",
      "Loss: tensor(0.0931, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 20\n",
      "Loss: tensor(0.0931, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 21\n",
      "Loss: tensor(0.0931, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 22\n",
      "Loss: tensor(0.0931, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 23\n",
      "Loss: tensor(0.0931, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 24\n",
      "Loss: tensor(0.0931, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 25\n",
      "Loss: tensor(0.0931, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 26\n",
      "Loss: tensor(0.0931, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 27\n",
      "Loss: tensor(0.0931, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 28\n",
      "Loss: tensor(0.0931, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 29\n",
      "Loss: tensor(0.0931, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 30\n",
      "Loss: tensor(0.0931, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 31\n",
      "Loss: tensor(0.0931, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 32\n",
      "Loss: tensor(0.0931, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 33\n",
      "Loss: tensor(0.0931, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 34\n",
      "Loss: tensor(0.0931, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 35\n",
      "Loss: tensor(0.0931, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 36\n",
      "Loss: tensor(0.0931, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 37\n",
      "Loss: tensor(0.0931, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 38\n",
      "Loss: tensor(0.0931, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 39\n",
      "Loss: tensor(0.0931, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 40\n",
      "Loss: tensor(0.0931, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 41\n",
      "Loss: tensor(0.0931, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 42\n",
      "Loss: tensor(0.0931, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 43\n",
      "Loss: tensor(0.0931, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 44\n",
      "Loss: tensor(0.0931, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 45\n",
      "Loss: tensor(0.0931, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 46\n",
      "Loss: tensor(0.0931, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 47\n",
      "Loss: tensor(0.0931, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 48\n",
      "Loss: tensor(0.0931, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 49\n",
      "Loss: tensor(0.0931, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 50\n",
      "Loss: tensor(0.0931, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 51\n",
      "Loss: tensor(0.0931, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 52\n",
      "Loss: tensor(0.0931, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 53\n",
      "Loss: tensor(0.0931, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 54\n",
      "Loss: tensor(0.0931, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 55\n",
      "Loss: tensor(0.0931, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 56\n",
      "Loss: tensor(0.0931, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 57\n",
      "Loss: tensor(0.0931, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 58\n",
      "Loss: tensor(0.0931, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 59\n",
      "Loss: tensor(0.0931, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 60\n",
      "Loss: tensor(0.0931, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 61\n",
      "Loss: tensor(0.0931, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 62\n",
      "Loss: tensor(0.0931, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 63\n",
      "Loss: tensor(0.0931, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 64\n",
      "Loss: tensor(0.0931, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 65\n",
      "Loss: tensor(0.0931, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 66\n",
      "Loss: tensor(0.0931, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 67\n",
      "Loss: tensor(0.0931, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 68\n",
      "Loss: tensor(0.0931, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 69\n",
      "Loss: tensor(0.0931, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 70\n",
      "Loss: tensor(0.0931, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 71\n",
      "Loss: tensor(0.0931, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 72\n",
      "Loss: tensor(0.0931, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 73\n",
      "Loss: tensor(0.0931, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 74\n",
      "Loss: tensor(0.0931, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 75\n",
      "Loss: tensor(0.0931, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 76\n",
      "Loss: tensor(0.0931, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 77\n",
      "Loss: tensor(0.0931, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 78\n",
      "Loss: tensor(0.0931, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 79\n",
      "Loss: tensor(0.0931, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 80\n",
      "Loss: tensor(0.0931, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 81\n",
      "Loss: tensor(0.0931, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 82\n",
      "Loss: tensor(0.0931, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 83\n",
      "Loss: tensor(0.0931, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 84\n",
      "Loss: tensor(0.0931, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 85\n",
      "Loss: tensor(0.0931, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 86\n",
      "Loss: tensor(0.0931, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 87\n",
      "Loss: tensor(0.0931, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 88\n",
      "Loss: tensor(0.0931, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 89\n",
      "Loss: tensor(0.0931, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 90\n",
      "Loss: tensor(0.0931, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 91\n",
      "Loss: tensor(0.0931, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 92\n",
      "Loss: tensor(0.0931, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 93\n",
      "Loss: tensor(0.0931, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 94\n",
      "Loss: tensor(0.0931, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 95\n",
      "Loss: tensor(0.0931, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 96\n",
      "Loss: tensor(0.0931, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 97\n",
      "Loss: tensor(0.0931, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 98\n",
      "Loss: tensor(0.0931, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 99\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(100):  \n",
    "        \n",
    "    optimizer.zero_grad()   # zero the gradient buffers\n",
    "    output = net(input.float())\n",
    "\n",
    "    loss = criterion(output, targets)\n",
    "    print('Loss:', loss, ' at epoch:', epoch)\n",
    "\n",
    "    loss.backward()  #backprop\n",
    "    optimizer.step()    # Does the update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the FCNN model\n",
    "\n",
    "stage='NNetwork/'\n",
    "SavesDirectory='./TunedModels/'+model_class+'/'+model_version+\"/\"+stage\n",
    "#PATH = SavesDirectory+'Tanh_MSE_adam4793.pth'\n",
    "\n",
    "torch.save(net.state_dict(), PATH)\n",
    "\n",
    "# more on saving pytorch networks: https://pytorch.org/docs/stable/notes/serialization.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load previously saved FCNN model \n",
    "\n",
    "stage='NNetwork/'\n",
    "SavesDirectory='./TunedModels/'+model_class+'/'+model_version+\"/\"+stage\n",
    "#PATH = SavesDirectory+'Tanh_MSE_adam4731.pth'\n",
    "\n",
    "net = Net()\n",
    "net.load_state_dict(torch.load(PATH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 3 3 4 3 1 4 5 5 5 4 3 4 5 3 5 4 5 3 3 3 2 5 1 3 3 3 1 1 1 4 4 5 3 5 3 5 5 5 5 3 4 3 4 1 5 2 3 5 5 5 5 3 1 5 3 3 3 1 3 3 4 5 1 3 3 4 5 5 3 4 3 5 4 5 4 4 3 4 4 3 3 4 1 2 4 3 1 1 5 3 3 3 0 0 5 5 2 2 5 5 1 4 4 3 5 3 3 5 4 4 3 4 5 4 3 3 3 3 1 4 2 5 5 0 3 4 3 1 4 3 3 5 5 4 2 1 5 4 1 4 3 3 3 3 3 5 4 4 5 1 3 1 5 3 4 4 3 5 3 5 1 3 5 1 0 3 5 3 3 3 5 5 3 3 5 4 5 0 2 4 5 3 5 5 2 5 5 3 5 3 5 1 3 5 4 5 4 4 1 1 3 0 5 1 1 5 1 5 3 2 0 0 0 1 3 5 4 4 5 5 3 5 1 1 1 0 3 0 4 3 4 2 3 5 3 5 4 4 2 5 5 5 5 4 3 3 5 4 4 3 3 5 3 3 5 2 5 4 4 5 0 5 4 5 3 4 3 5 3 5 3 3 3 5 0 0 0 3 5 3 0 3 5 5 3 3 3 3 3 4 2 5 3 2 3 3 4 1 3 4 2 3 2 1 5 3 4 4 1 0 0 0 1 4 5 5 5 3 0 3 1 3 1 5 5 5 4 1 5 3 1 1 3 1 5 1 5 1 3 3 5 5 4 3 4 4 3 3 3 3 3 3 5 1 0 1 1 5 4 0 5 3 5 4 5 3 4 4 3 4 4 5 4 5 1 1 5 3 5 3 5 3 3 5 1 5 5 5 1 5 5 0 0 5 1 1 4 5 4 5 5 5 1 3 3 3 2 5 5 5 3 1 3 3 2 3 5 4 3 5 1 5 4 3 0 4 1 5 4 3 3 1 0 1 1 2 0 3 2 5 5 5 5 5 3 5 5 2 4 5 5 3 3 3 1 1 1 1 1 0 5 0 5 1 1 3 4 1 1 1 1 3 4 1 3 3 3 2 4 3 1 3 1 5 5 2 0 5 1 4 1 1 5 5 1 3 1 5 4 3 3 4 4 3 4 4 3 4 2 1 0 3 4 5 3 5 3 5 5 4 5 5 2 5 1 5 1 3 3 4 2 4 1 5 4 5 1 1 5 5 5 4 1 1 0 5 0 3 5 0 1 3 1 5 3 1 5 1 1 2 4 3 3 3 3 3 5 1 4 5 5 5 5 4 5 5 4 1 4 3 4 5 4 4 4 1 5 1 5 3 1 5 3 5 1 1 3 3 1 5 5 4 4 5 4 5 4 5 1 3 3 1 1 5 3 1 3 3 1 5 3 4 3 1 2 2 1 2 0 1 5 1 4 1 0 5 4 5 5 1 3 3 1 3 2 3 1 5 5 1 1 3 1 2 3 1 3 4 2 1 1 5 3 3 4 4 5 0 0 1 1 3 5 1 4 3 1 1 3 3 1 4 1 5 4 3 5 5 1 5 5 5 0 4 4 2 3 3 1 0 3 4 4 5 5 1 5 1 1 0 1 1 5 1 3 5 1 4 1 5 5 5 5 1 1 2 0 5 0 2 4 2 5 5 1 1 3 1 1 5 5 5 3 4 3 3 3 1 3 5 1 3 2 2 1 1 1 5 4 1 1 5 3 4 1 1 1 5 1 3 1 1 5 0 0 0 3 5 4 4 2 1 3 1 4 1 4 1 1 3 3 1 1 4 3 0 4 4 4 4 0 1 0 3 3 3 1 1 1 4 3 5 0 5 1 3 5 1 3 1 1 3 1 4 5 3 4 1 5 1 2 3 0 4 2 3 1 2 5 3 1 1 3 3 2 3 2 4 0 1 1 1 1 1 1 5 5 5 3 1 1 3 1 5 0 1 4 2 5 4 3 3 2 1 5 3 4 5 1 1 1 3 1 3 1 1 5 3 3 3 3 5 1 2 2 4 4 4 4 4 2 4 1 5 1 3 2 1 5 5 1 1 0 0 3 4 3 5 1 3 1 0 2 3 3 1 5 4 1 5 1 1 1 4 0 3 1 3 0 4 2 1 1 3 1 1 3 1 3 3 3 2 3 1 3 5 1 5 1 1 5 3 0 1 5 4 3 2 3 5 0 0 1 0 2 4 4 4 1 1 3 1 5 4 5 1 3 3 4 1 3 3 1 3 3 4 3 5 1 4 2 1 2 3 5 3 3 3 2 4 4 3 4 5 1 1 5 4 0 4 1 3 4 2 3 3 4 1 1 1 5 5 4 1 1 5 0 3 5 5 5 1 5 3 3 4 1 4 1 3 3 4 5 3 4 3 0 1 5 5 3 1 1 1 4 3 4 4 3 1 3 5 1 3 3 3 5 1 5 1 1 1 2 3 4 5 5 3 1 1 5 1 3 1 2 3 3 3 1 1 4 2 1 1 4 1 1 5 1 4 3 3 1 2 3 5 4 4 4 2 3 1 1 5 0 3 3 4 5 4 3 3 3 3 4 4 4 4 3 3 2 3 1 1 4 5 3 5 5 5 4 5 2 2 5 3 1 0 2 4 2 2 3 4 1 0 2 0 2 5 3 1 3 3 1 3 5 0 3 3 3 5 3 4 2 1 5 3 3 1 1 1 2 3 5 3 2 3 1 5 3 1 1 2 5 1 1 1 5 3 3 3 4 5 2 2 3 5 3 2 3 1 5 5 4 3 5 3 5 3 4 1 1 4 4 4 4 2 1 5 5 1 0 1 4 5 5 5 1 3 1 5 2 1 4 4 1 3 5 3 1 4 3 1 1 3 1 3 3 1 1 3 5 3 5 2 1 5 4 4 3 3 1 5 5 0 5 5 5 4 4 3 5 1 4 1 3 4 4 5 1 1 3 4 5 1 1 1 2 5 1 3 4 5 1 0 5 1 1 3 1 5 4 2 4 1 1 5 5 1 5 1 5 3 4 3 4 3 3 4 0 4 4 5 2 3 3 3 5 3 1 2 3 3 3 5 3 4 1 5 1 3 5 3 4 4 5 1 2 2 2 2 4 5 5 5 3 4 3 4 0 3 3 3 0 3 0 3 3 3 1 3 3 5 3 2 1 5 3 4 4 0 3 5 2 5 3 0 1 0 3 5 1 1 4 3 3 5 3 4 1 3 5 3 0 2 3 4 5 3 4 5 5 3 1 0 1 3 3 1 2 2 5 4 1 2 3 3 3 4 0 4 4 1 1 1 3 3 1 4 3 1 3 5 1 5 5 1 2 3 5 3 3 2 5 4 3 4 4 2 1 4 0 0 0 3 2 5 3 3 2 2 3 1 5 5 5 1 0 1 0 4 4 2 3 2 4 0 5 2 5 5 5 4 2 2 3 3 5 3 5 0 1 2 1 3 3 4 3 5 2 1 0 1 4 3 5 5 1 3 2 1 3 3 1 2 3 2 3 3 4 1 1 4 5 2 1 5 5 2 5 5 1 3 1 4 4 3 2 4 5 2 1 5 5 2 3 4 3 2 3 3 5 3 5 5 5 4 1 0 3 3 3 2 2 3 3 5 3 1 2 4 1 5 3 1 3 1 4 3 1 5 0 5 1 2 3 3 1 5 2 0 2 1 5 4 2 3 5 3 3 2 3 3 3 1 0 1 3 0 4 3 0 3 1 2 3 2 3 3 5 0 4 1 2 5 3 3 1 1 3 5 5 3 1 0 0 4 3 3 5 1 4 4 2 5 4 4 3 4 3 4 1 4 5 4 4 3 4 5 3 3 2 3 3 4 3 3 4 2 2 1 4 1 1 1 4 0 1 3 2 3 2 2 4 1 1 1 2 2 0 2 1 4 4 3 1 5 4 1 5 4 3 4 4 5 2 3 3 5 5 2 2 1 2 5 2 3 5 2 0 1 2 3 3 4 3 3 1 3 2 1 3 5 5 3 0 4 1 3 1 2 4 2 3 2 3 2 3 5 1 3 1 4 3 3 2 3 5 3 5 5 4 3 3 1 4 2 1 4 5 1 5 4 3 2 1 2 3 2 2 3 2 1 2 2 2 3 2 3 3 3 3 2 1 2 1 0 2 2 2 3 3 4 3 3 4 5 4 3 1 3 3 2 3 5 2 3 2 1 3 3 1 5 3 1 5 1 2 3 1 3 1 1 4 3 3 1 3 3 4 1 1 2 2 4 2 3 5 3 0 2 4 4 5 3 2 3 0 4 0 3 1 5 1 1 2 1 1 1 1 1 2 5 5 2 2 4 0 5 2 4 1 2 2 2 4 2 1 1 1 0 2 1 4 2 1 5 2 2 5 3 3 1 1 1 1 1 3 3 3 3 1 3 1 3 0 2 5 4 4 3 3 1 5 2 0 3 5 1 0 5 2 3 1 2 2 1 2 3 5 2 1 2 2 2 2 1 2 1 5 2 0 2 1 2 1 4 2 2 0 4 5 3 3 3 3 1 4 4 3 2 0 3 1 5 0 1 2 2 1 1 2 2 1 2 1 5 3 4 1 3 4 3 3 3 3 1 1 3 2 3 5 3 5 2 5 2 2 2 5 0 1 2 2 0 1 3 1 4 4 2 2 3 3 3 1 0 3 0 5 3 4 3 1 0 1 3 3 2 2 2 5 3 2 1 5 3 3 1 3 0 2 3 4 1 3 1 4 1 3 3 5 5 5 3 4 3 3 2 5 4 5 4 0 5 3 3 1 0 4 2 4 1 1 1 4 2 5 1 1 4 4 0 5 5 0 5 1 0 1 3 4 4 1 5 5 5 1 5 4 5 5 2 5 5 3 2 1 3 5 4 5 1 5 3 3 1 1 4 3 2 2 5 3 3 2 4 3 1 5 3 3 4 1 4 2 1 5 5 5 1 5 4 5 3 1 3 3 1 1 0 1 3 3 2 3 5 5 0 3 4 1 4 2 2 5 5 3 5 5 3 1 5 4 3 4 0 0 3 4 2 1 4 4 4 2 4 2 3 1 5 4 1 4 1 1 3 1 4 4 3 5 0 4 4 5 5 5 1 4 2 3 0 1 5 1 1 5 1 4 2 4 5 1 2 5 1 3 5 3 5 4 4 5 5 3 1 4 2 5 5 1 5 1 4 0 5 1 5 5 1 5 5 3 4 5 4 1 2 1 5 4 2 1 4 3 4 3 1 5 4 4 1 1 4 1 0 1 1 5 1 1 4 1 2 1 0 5 3 1 4 5 5 1 4 1 4 5 3 1 5 1 2 0 3 4 4 1 3 1 1 5 3 3 5 3 4 5 2 3 1 3 4 1 4 2 5 3 1 1 1 5 3 5 4 4 1 3 4 2 1 1 3 3 5 1 4 0 4 4 0 1 1 3 3 1 1 5 4 1 5 2 1 3 0 4 3 4 5 4 2 5 1 1 5 3 2 1 1 4 5 5 5 4 5 5 4 1 1 5 1 3 3 3 3 1 3 2 4 1 3 1 1 3 1 3 4 4 4 2 3 3 3 4 1 5 3 1 1 3 2 5 0 1 1 1 1 3 3 0 5 1 5 2 1 0 1 3 1 5 1 4 4 3 3 3 1 1 4 4 1 5 5 4 1 1 4 0 5 5 2 3 5 2 1 0 1 2 3 4 3 5 1 4 1 1 3 1 4 1 4 0 4 4 1 5 1 3 4 5 1 5 1 4 4 3 5 3 4 1 3 4 1 1 3 4 5 0 4 1 3 0 3 1 1 2 2 0 4 0 1 5 4 0 3 3 4 1 3 4 2 1 0 4 4 4 1 3 1 5 5 5 1 5 4 4 5 1 3 3 4 4 3 5 2 1 5 4 3 4 4 5 3 1 1 2 5 1 5 4 4 4 3 4 2 5 1 4 5 3 3 4 3 2 3 3 3 4 3 1 5 1 3 5 1 5 1 5 1 1 5 5 1 4 0 4 1 5 1 5 4 2 3 1 3 1 4 3 1 2 1 4 4 5 1 5 5 1 5 3 4 3 4 1 4 5 3 4 0 5 2 4 5 3 5 3 1 3 3 3 5 4 3 3 5 5 4 3 1 4 1 1 1 5 5 5 5 4 4 4 3 2 3 0 1 4 0 3 1 4 5 1 4 3 1 4 0 1 1 3 5 2 4 3 0 3 3 2 4 4 5 1 5 5 2 1 2 3 3 5 5 4 1 1 4 5 3 5 3 2 1 3 4 5 1 1 5 0 1 2 5 1 5 1 5 1 3 4 5 4 5 3 5 1 4 1 2 1 3 1 5 0 1 2 4 3 3 1 5 3 2 4 3 4 4 1 4 4 4 3 3 3 1 1 2 1 5 5 5 4 2 5 2 3 4 2 4 4 4 4 3 4 5 2 4 3 1 5 4 4 1 4 1 3 3 5 0 3 4 4 3 1 5 3 5 4 5 1 1 5 2 5 5 3 3 4 4 5 3 2 2 2 3 1 1 1 4 3 4 4 1 3 0 0 4 5 3 1 2 4 4 3 5 4 1 2 4 3 1 0 5 4 0 5 4 5 1 1 3 3 3 3 2 3 5 4 3 5 5 3 3 1 3 4 0 3 4 4 2 2 4 4 5 1 3 5 3 0 1 1 2 4 1 1 3 2 2 1 5 4 2 2 2 0 5 1 4 4 1 1 2 4 4 1 0 1 1 1 3 4 3 5 1 5 0 4 3 3 4 5 1 1 5 3 5 4 3 5 4 1 1 3 4 1 3 3 4 4 5 5 5 5 4 4 3 3 4 3 1 3 1 4 1 4 2 1 3 1 3 5 4 3 3 1 4 5 1 4 5 4 1 4 0 4 1 5 2 1 3 3 4 1 4 3 4 1 4 2 1 2 3 5 0 1 5 1 2 3 2 3 3 4 3 4 4 2 1 4 5 1 1 4 2 2 1 1 4 2 1 1 5 4 1 5 4 5 1 0 5 3 4 3 4 3 3 2 1 1 1 3 3 4 5 2 3 0 4 5 1 5 3 2 3 4 3 5 1 1 4 3 4 4 3 3 1 2 4 1 4 5 5 3 3 1 5 1 5 4 2 5 3 5 1 3 3 1 1 3 5 5 4 0 4 3 0 5 5 2 2 4 3 1 2 4 4 4 3 5 1 1 5 5 2 5 1 2 5 3 2 2 5 3 0 1 1 5 4 0 4 3 5 5 2 1 5 5 4 1 5 4 5 0 5 5 1 5 3 4 2 5 5 2 3 2 1 3 3 4 4 4 5 4 3 2 1 4 5 1 2 2 2 4 3 1 4 1 4 3 1 3 1 4 3 4 1 1 1 2 1 1 3 5 2 5 5 3 3 5 3 3 2 2 3 2 3 1 4 1 3 2 2 4 1 1 1 2 5 0 5 3 1 1 3 4 1 1 1 2 4 2 2 1 5 5 3 3 1 3 2 1 1 0 3 4 4 5 1 5 4 2 3 1 1 5 4 2 1 1 4 3 5 1 1 3 4 3 1 4 5 2 5 3 1 1 1 3 4 4 2 1 4 3 4 0 5 2 1 5 3 1 1 1 0 3 4 5 5 1 3 1 0 0 1 5 1 0 0 3 3 0 5 1 4 5 2 2 3 3 5 2 3 4 4 3 1 1 3 1 1 5 3 3 3 2 2 0 5 5 1 3 4 2 5 4 5 2 4 3 4 3 1 1 4 4 2 1 3 4 2 5 1 2 2 1 3 2 0 5 4 1 1 3 1 2 2 3 3 4 5 3 5 3 4 2 5 1 3 2 3 2 3 5 4 0 4 5 2 1 1 1 5 2 5 5 4 2 4 5 1 1 4 4 4 1 4 1 3 5 4 3 3 3 1 3 0 3 3 1 5 3 3 3 3 2 4 2 4 5 1 1 2 3 1 4 3 4 5 1 3 3 2 1 0 3 4 4 4 3 1 5 4 2 3 1 2 3 1 2 1 3 4 5 3 1 3 4 3 1 1 4 4 3 2 1 5 1 1 3 2 5 4 4 2 3 2 4 4 3 1 0 1 5 1 3 3 1 5 3 3 1 1 4 5 3 1 1 1 2 1 5 5 1 3 4 1 4 1 1 1 3 3 3 3 3 3 5 1 3 1 1 1 3 5 3 4 3 1 5 4 3 1 5 0 1 3 2 2 3 5 5 3 3 1 3 4 5 1 4 5 1 3 3 4 1 5 1 1 4 1 2 3 4 3 3 5 5 2 1 3 3 5 4 4 3 0 5 5 4 4 3 3 2 5 1 1 3 2 3 2 3 1 3 5 3 1 2 3 4 2 4 3 1 3 3 2 4 2 4 4 1 4 1 1 1 1 5 1 5 1 2 5 4 2 2 1 2 4 1 2 3 4 1 1 3 1 1 2 1 4 1 4 2 5 3 3 5 3 4 1 5 1 5 3 5 0 1 4 1 3 3 1 3 2 3 5 4 4 5 1 5 5 1 1 5 3 3 5 3 2 5 4 4 1 3 2 1 1 3 1 0 1 5 2 5 4 5 5 5 3 5 2 2 1 0 4 5 5 1 5 1 5 5 4 1 1 5 5 1 4 3 4 3 4 3 2 5 4 3 3 1 3 5 3 1 5 2 5 4 3 1 1 1 3 4 3 2 1 2 1 0 4 4 3 4 2 2 5 5 2 5 3 5 3 3 4 5 5 3 1 3 0 4 1 3 3 3 1 5 5 1 4 3 5 5 3 4 2 4 2 4 2 2 3 3 3 5 4 3 1 4 1 3 3 1 5 2 1 1 3 1 1 3 5 3 2 3 3 3 4 2 3 4 5 1 4 4 4 3 3 1 4 4 3 3 1 3 3 1 5 4 4 2 3 5 1 5 3 5 4 2 1 1 1 3 2 4 1 3 0 1 3 3 5 4 1 5 5 1 2 4 1 2 4 3 3 2 5 3 1 1 2 4 3 2 5 2 3 1 4 5 5 1 5 2 3 4 1 5 4 2 3 4 1 4 5 5 3 5 4 1 4 1 5 3 3 4 3 3 3 1 1 2 5 5 5 5 2 1 5 4 0 4 4 1 3 3 1 0 3 2 0 3 4 5 5 3 2 3 5 1 5 4 4 5 3 3 1 4 4 1 2 0 0 3 1 3 1 1 3 3 4 1 4 2 5 5 1 2 4 4 3 1 2 3 3 3 3 2 1 2 3 4 1 4 1 5 4 5 5 0 5 3 1 0 2 5 4 1 2 2 5 5 1 1 0 2 5 1 5 2 3 1 3 3 1 1 4 3 4 3 3 3 3 5 4 1 3"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 4 0 4 3 5 3 5 3 1 3 3 0 5 5 3 1 5 0 1 1 1 5 1 3 1 1 3 1 2 1 4 5 3 1 3 2 3 2 1 3 1 1 4 5 4 4 3 4 5 4 1 3 3 1 5 1 3 3 4 5 1 3 1 4 2 1 4 3 1 4 5 1 5 5 4 1 5 1 4 3 1 3 2 4 4 4 2 3 1 4 4 4 5 3 3 5 1 1 0 4 1 2 1 5 3 0 4 1 2 4 0 3 3 4 4 3 3 1 4 3 1 3 5 3 4 1 4 0 3 3 4 5 4 5 1 4 5 5 5 4 4 2 1 4 3 5 4 5 4 1 3 5 3 3 1 3 2 2 3 2 3 0 0 2 5 1 1 1 5 1 1 3 1 0 3 4 4 4 1 2 3 2 4 2 5 4 5 3 2 5 5 3 1 1 0 5 1 1 4 3 3 1 4 2 2 3 1 2 5 3 3 5 1 3 3 5 3 3 5 2 3 0 2 5 2 1 4 4 1 1 1 1 2 1 1 1 3 1 3 1 2 5 2 5 4 5 4 5 1 3 1 1 1 4 5 1 0 4 1 4 5 3 2 5 3 5 5 3 4 2 1 3 1 2 5 3 3 3 4 3 5 1 3 1 5 4 2 5 1 1 1 0 4 5 4 3 2 0 5 4 0 5 3 3 2 0 3 4 4 3 5 1 5 5 5 2 1 1 1 3 4 4 2 4 2 3 1 1 5 1 5 4 1 1 5 4 5 3 3 4 4 5 5 5 4 3 5 1 2 3 5 2 4 1 1 4 3 2 4 1 2 1 1 3 2 4 3 2 5 4 2 4 1 1 1 2 2 1 1 0 4 2 1 3 1 5 3 4 1 5 1 0 5 4 2 2 3 2 5 3 2 1 3 2 1 2 2 4 2 3 1 1 3 2 3 1 1 4 1 2 3 3 4 1 2 1 1 2 2 2 5 4 3 5 0 5 1 3 4 5 1 5 4 3 3 3 4 2 5 5 5 3 5 3 1 2 4 1 4 2 1 3 1 4 4 3 4 3 0 3 1 4 2 4 1 4 1 3 5 1 2 5 3 1 4 4 5 5 3 1 5 5 2 3 3 3 3 5 3 4 1 1 1 5 4 2 3 2 4 4 1 2 1 2 2 3 1 4 2 5 1 4 3 5 3 4 4 2 1 4 2 1 4 2 3 2 3 5 4 4 4 4 1 2 3 2 3 3 0 3 4 5 4 5 3 3 3 1 1 0 5 4 5 2 3 1 1 5 3 1 4 1 4 1 1 1 1 4 4 1 3 4 1 5 1 3 5 2 4 1 1 3 4 4 3 1 1 2 5 2 3 5 5 1 2 4 5 3 1 1 1 3 3 2 5 4 0 3 3 3 1 5 1 1 2 3 2 1 5 2 2 5 3 4 5 3 1 2 1 1 2 2 4 5 3 3 0 3 4 3 4 4 4 3 2 2 3 3 2 3 1 5 0 1 3 3 4 4 1 2 4 3 5 5 4 5 1 1 5 1 4 3 0 2 2 0 2 2 5 5 0 5 4 3 5 2 4 3 1 2 3 3 2 1 2 1 5 1 2 1 3 4 2 1 4 0 2 5 4 1 1 1 5 2 3 2 2 1 4 5 3 4 2 3 4 5 3 5 3 5 4 4 1 4 4 1 1 2 4 4 3 5 1 1 4 2 1 4 4 1 0 3 2 5 1 1 5 3 3 1 2 5 1 5 1 1 0 3 5 1 1 2 1 4 4 2 5 4 4 3 4 2 3 4 2 2 3 1 3 5 3 2 5 4 4 5 5 1 1 5 4 3 1 1 4 2 2 5 1 2 5 4 4 5 2 2 5 3 2 4 2 3 4 5 5 5 4 3 2 3 2 0 3 5 3 5 2 3 1 3 4 4 2 3 3 1 5 1 1 4 1 3 1 4 4 0 1 2 2 3 2 2 2 4 1 4 1 1 5 3 3 1 3 3 5 5 3 3 2 4 3 3 3 5 3 2 5 3 5 5 3 3 1 4 3 3 3 4 3 1 4 5 3 4 3 3 4 3 4 3 4 2 1 5 4 4 4 1 4 0 2 2 5 3 3 3 2 2 3 4 3 3 3 3 3 4 5 4 5 4 1 4 1 1 1 1 2 3 2 4 4 4 3 3 1 4 3 4 5 0 1 2 2 3 1 5 2 1 3 1 2 3 3 2 3 2 4 2 3 1 2 3 1 3 2 1 1 1 0 0 0 5 0 1 5 4 3 4 4 0 2 4 3 3 4 2 4 3 2 5 2 3 3 3 2 5 1 4 2 3 1 1 5 2 5 2 5 2 2 4 2 4 4 4 1 3 2 4 4 2 0 3 4 2 3 3 2 2 3 5 2 5 1 1 5 4 3 3 4 3 1 3 4 2 3 4 4 4 2 3 3 2 1 2 2 4 2 2 2 2 3 2 3 1 1 1 1 4 2 3 5 1 2 5 2 1 1 4 2 3 3 4 2 3 1 3 1 4 5 4 3 1 4 3 4 2 1 3 4 3 2 2 4 2 1 2 3 1 4 4 3 2 2 2 4 4 4 3 3 5 5 3 3 5 4 0 2 4 3 3 4 3 4 1 4 4 2 4 2 2 5 5 3 3 5 1 2 5 3 5 3 4 4 3 0 2 1 2 3 4 4 3 3 5 5 1 4 3 3 1 2 2 2 3 0 3 3 4 1 1 1 2 1 4 4 3 2 2 1 2 3 4 4 2 1 3 4 3 2 3 2 4 5 5 3 3 5 4 4 5 5 2 1 4 1 4 1 4 5 3 3 3 3 1 5 4 5 0 4 0 5 1 1 2 2 3 5 4 3 1 5 4 1 5 5 3 5 5 4 5 3 2 4 4 5 3 5 4 4 5 5 3 2 5 4 5 3 4 0 3 4 2 1 2 5 4 3 5 3 3 4 3 5 3 4 4 1 4 4 5 1 3 5 4 5 4 1 5 4 4 5 5 3 5 4 1 5 5 4 5 5 3 4 2 3 2 4 3 1 4 3 4 2 1 1 4 5 4 3 3 5 3 5 3 5 1 5 1 3 3 0 4 1 1 1 4 5 5 3 5 5 4 5 1 3 3 5 1 5 5 4 4 4 4 4 4 3 1 4 4 4 0 1 4 1 3 4 1 3 2 1 4 5 3 1 5 5 4 4 5 4 2 5 3 3 3 4 4 2 0 4 3 0 5 5 4 3 3 3 1 5 3 4 3 1 4 4 4 4 4 4 5 5 4 4 5 5 5 1 2 4 3 4 4 1 3 3 3 5 5 4 5 5 4 3 5 5 1 5 5 4 2 5 2 4 1 1 5 1 4 5 4 1 1 1 1 2 5 1 4 4 3 3 3 3 1 3 4 1 2 3 3 3 4 2 2 1 4 5 2 3 5 4 4 3 3 4 3 4 1 5 4 3 5 3 2 4 3 4 1 4 4 4 3 3 4 1 3 1 3 5 1 5 3 1 3 2 5 4 5 5 4 1 3 4 2 2 4 3 4 4 5 3 2 1 1 5 3 0 1 4 5 3 5 5 4 5 4 0 1 3 3 4 1 5 1 2 3 2 5 2 3 1 1 5 5 4 4 5 5 3 5 1 5 3 4 3 2 1 3 3 1 3 5 5 2 5 1 4 4 2 4 4 4 3 3 3 1 1 4 4 2 3 4 3 4 3 3 2 3 4 4 1 2 2 0 3 4 3 5 3 5 5 4 1 4 3 1 1 4 5 1 3 3 1 4 5 1 3 3 4 3 2 1 4 4 5 5 3 3 0 5 4 4 1 5 1 3 4 4 3 3 1 4 4 3 0 5 5 2 0 4 4 1 1 1 3 4 3 3 1 3 4 4 1 3 2 4 2 3 3 3 4 5 2 2 0 3 3 5 3 4 2 4 3 4 3 2 3 1 1 4 5 4 3 2 3 2 3 2 4 4 1 3 5 3 4 3 3 3 3 3 4 4 4 3 1 5 5 1 1 1 5 1 3 5 4 5 5 1 5 4 2 2 5 5 5 4 5 2 3 2 3 3 2 3 3 4 1 4 0 4 4 3 2 5 1 1 2 4 4 2 4 1 5 5 4 3 2 1 4 0 3 4 4 5 0 4 1 5 5 2 3 2 5 5 1 5 3 1 5 1 4 2 4 2 2 3 1 4 3 4 5 3 1 5 5 2 1 5 3 4 1 4 4 3 4 4 3 4 1 3 0 4 3 0 5 5 4 3 3 3 5 5 4 4 1 4 3 4 1 5 1 3 4 3 4 1 4 5 4 1 1 4 3 1 4 0 0 2 3 1 5 2 4 1 4 1 1 2 1 4 1 3 2 4 0 4 4 1 5 4 4 3 5 0 4 4 4 3 3 3 2 2 4 4 1 3 3 1 0 1 3 2 4 2 4 1 3 3 1 0 2 1 1 3 5 4 5 1 3 1 3 1 4 5 4 3 1 3 2 3 1 5 1 4 3 2 3 1 5 5 4 4 1 5 3 0 1 2 5 3 3 1 1 5 2 3 1 2 3 5 4 1 3 0 3 1 3 4 4 4 3 3 5 5 4 2 4 1 4 4 2 3 3 3 5 1 4 3 3 3 5 5 1 4 4 1 2 2 2 1 3 1 3 4 4 4 4 5 3 4 1 2 2 4 4 5 2 1 4 1 5 4 1 4 4 3 3 1 3 4 5 1 0 4 3 4 5 4 3 4 3 4 4 4 3 2 4 1 2 4 1 4 3 1 4 4 3 1 1 1 4 3 0 3 3 3 4 4 1 3 2 3 0 1 5 1 1 4 5 2 2 2 4 5 5 3 4 3 3 3 5 5 1 5 2 4 2 2 3 1 4 1 4 5 1 5 5 2 4 2 5 5 1 2 4 1 2 3 5 3 1 4 4 3 2 4 4 3 5 4 3 1 1 1 5 3 2 1 2 5 5 1 1 1 1 5 5 2 2 2 5 5 3 2 0 2 2 5 4 1 1 3 5 4 0 3 1 4 2 3 4 1 1 1 5 2 1 1 3 1 2 1 0 1 1 3 1 1 1 4 3 4 1 2 1 5 0 2 4 0 2 1 3 1 4 5 3 4 3 4 1 4 5 1 4 0 2 4 5 1 5 3 4 1 1 0 2 1 3 4 1 2 5 3 1 3 1 1 5 4 1 4 3 1 3 4 5 1 4 3 2 3 3 4 3 5 2 4 3 3 4 5 3 3 2 1 5 2 0 3 1 3 1 3 3 4 3 2 1 5 3 2 4 1 3 4 3 4 1 2 2 2 3 5 1 3 3 4 4 2 3 1 2 4 1 3 1 1 1 4 4 5 4 4 3 4 2 4 2 1 1 3 3 3 1 5 3 4 4 1 1 5 3 4 2 2 3 3 1 4 4 3 4 1 5 3 4 4 3 1 1 3 3 1 4 3 1 3 3 0 4 5 0 3 5 1 1 1 3 3 0 1 4 5 5 4 2 0 3 3 1 2 3 4 4 2 3 3 2 1 3 3 1 1 5 3 1 4 1 4 1 2 4 3 5 4 4 4 2 3 0 4 3 5 1 2 1 4 4 4 4 3 4 5 1 5 1 3 1 1 4 2 4 4 5 5 4 5 1 1 5 5 1 3 2 1 4 5 4 4 2 5 5 4 0 0 4 4 4 2 5 1 4 2 5 1 2 5 5 3 3 5 2 2 2 3 5 3 3 4 3 4 4 5 2 2 3 1 1 1 1 1 3 5 5 2 4 4 1 2 2 4 5 1 5 5 1 0 4 5 3 1 5 5 4 1 4 1 5 3 1 1 2 4 5 3 4 3 2 5 1 5 2 5 1 1 1 3 1 1 5 5 2 5 4 4 5 3 4 1 3 1 1 1 3 3 4 1 1 1 1 3 1 1 1 3 4 2 5 2 1 1 2 2 1 5 3 4 5 3 3 4 4 2 5 1 1 5 4 3 3 5 3 4 5 3 4 2 1 5 3 0 2 4 4 1 1 0 2 1 4 5 4 4 5 4 3 4 5 1 3 4 4 3 1 5 4 2 4 3 1 4 3 4 3 3 3 4 5 5 1 1 4 2 5 1 4 3 1 5 4 5 5 1 3 1 2 3 2 5 5 5 1 3 2 3 3 1 1 5 0 2 4 5 4 2 1 1 4 5 4 1 1 5 4 2 5 2 3 3 4 4 3 4 2 3 4 4 5 5 2 2 1 3 5 4 3 2 4 2 1 4 1 5 3 3 4 4 3 4 3 5 2 1 3 1 3 2 0 0 4 2 1 3 4 4 3 2 1 2 3 5 3 1 3 2 3 4 3 5 1 1 2 3 3 4 2 3 5 5 4 2 4 5 5 2 2 5 4 4 4 1 2 5 3 2 2 4 1 3 3 3 1 5 2 5 4 2 4 3 3 4 1 5 4 4 4 3 1 0 2 4 0 0 3 3 1 2 1 2 4 0 2 4 0 2 4 4 1 5 2 3 2 1 4 3 1 2 2 1 1 4 0 1 2 1 4 2 3 4 1 5 4 0 3 3 2 0 4 4 4 3 5 4 2 1 3 3 1 2 1 4 3 1 2 1 4 4 3 4 0 5 4 2 2 1 3 1 2 3 1 4 2 1 1 4 4 3 3 1 5 1 1 0 4 3 4 0 4 3 2 4 1 3 1 2 1 3 1 3 2 3 4 0 1 3 3 4 1 4 0 2 4 3 3 2 4 1 1 4 4 3 5 2 2 5 2 3 0 1 5 2 4 3 1 4 1 5 1 2 0 5 3 3 5 5 3 5 4 1 1 2 3 5 4 3 0 1 3 4 3 0 1 4 4 2 1 3 4 2 1 3 4 5 1 1 3 1 0 1 3 5 1 1 3 3 5 3 3 5 3 4 1 4 0 3 1 4 3 1 3 5 4 4 1 2 1 1 2 5 2 1 1 1 5 5 1 3 4 2 0 5 1 3 3 3 1 4 4 2 4 3 1 2 1 5 3 5 3 2 2 2 0 2 4 2 2 5 3 2 1 4 2 3 1 1 0 1 1 3 1 1 2 1 4 3 3 1 4 2 3 5 4 1 5 0 3 0 1 1 4 2 1 3 3 1 5 2 1 1 1 4 3 2 3 1 2 4 4 3 1 1 4 2 3 1 4 3 4 4 1 3 3 2 4 1 1 3 1 1 1 5 3 2 5 4 4 3 4 1 2 1 4 2 4 5 1 2 2 5 0 5 1 2 3 3 4 1 2 1 2 3 5 5 1 0 5 3 3 2 5 1 1 1 1 3 1 2 3 4 3 0 2 2 4 4 4 3 5 3 1 0 4 4 2 1 4 4 3 2 2 1 2 1 3 3 3 0 5 2 2 5 0 1 1 3 1 4 1 1 0 4 5 5 2 1 2 1 5 3 5 3 3 3 1 3 1 1 3 3 4 4 2 1 3 3 5 4 1 2 2 1 5 1 3 2 2 3 4 4 3 3 4 2 1 2 3 3 5 3 5 1 1 2 4 1 4 1 5 4 1 1 4 2 1 5 2 3 2 2 3 1 2 1 3 4 3 1 2 1 3 1 4 5 1 5 5 3 3 2 2 5 1 5 2 2 1 3 1 4 3 3 5 4 1 3 0 2 2 5 1 5 0 3 1 3 2 3 4 1 1 2 1 1 3 2 2 0 1 3 5 5 1 4 2 3 2 1 3 4 4 5 4 1 3 3 4 1 2 2 3 1 1 3 4 2 0 2 1 4 2 3 3 2 1 2 4 2 2 1 3 3 3 4 1 3 4 3 2 1 5 2 3 3 5 4 3 5 1 1 3 2 4 3 3 3 0 4 1 1 4 2 4 1 1 3 4 0 4 5 3 1 3 5 5 4 1 3 2 1 2 5 4 3 1 2 3 2 5 0 4 1 3 1 4 2 2 1 1 2 5 4 3 2 3 1 2 1 1 1 3 4 1 1 4 3 4 2 1 1 1 1 5 1 4 3 3 2 2 5 4 1 1 1 5 3 1 0 2 4 1 1 3 3 5 2 2 1 2 1 3 2 3 4 2 1 3 1 2 4 3 3 4 4 2 5 5 1 1 1 2 1 0 4 3 4 1 4 5 3 4 1 0 4 0 5 3 5 4 1 1 2 1 4 5 4 2 5 3 4 0 5 4 3 5 5 1 0 5 2 4 3 2 3 5 1 2 4 1 3 5 4 5 3 3 3 1 4 5 5 1 4 3 5 2 5 5 4 4 3 0 3 5 3 3 5 5 4 1 3 5 3 4 5 1 1 4 4 4 5 3 1 1 1 4 4 3 3 2 4 4 4 0 2 3 4 0 3 2 3 4 4 5 5 5 5 4 3 4 2 3 3 3 4 5 0 1 0 2 3 1 3 2 3 4 3 1 1 5 4 5 1 3 2 5 4 3 3 2 4 4 3 5 1 5 0 5 1 1 5 3 3 1 3 3 4 4 2 1 5 4 3 1 4 4 3 3 5 4 4 4 4 3 4 5 3 3 3 3 5 5 4 3 4 5 3 0 4 3 1 1 5 1 3 1 4 4 5 4 5 4 2 3 1 4 3 3 4 4 0 2 1 5 1 5 3 2 3 2 3 4 4 0 5 1 5 4 1 0 4 0 4 0 4 3 1 1 4 1 3 4 4 3 4 1 1 2 1 1 1 1 1 4 3 1 3 2 5 5 1 2 5 3 4 0 3 1 4 2 3 1 5 5 3 2 3 4 2 5 1 5 4 5 1 4 1 2 1 3 5 4 4 4 5 2 2 4 1 3 1 2 4 3 3 4 5 3 1 5 3 4 1 4 3 2 1 4 5 4 2 1 1 5 4 2 4 4 2 3 4 5 4 2 1 5 4 2 3 2 4 2 2 3 2 1 1 0 5 4 4 2 5 1 4 1 4 5 4 2 4 5 4 4 4 3 3 4 3 5 1 3 5 3 1 3 1 4 4 1 5 1 4 0 5 1 1 5 3 3 2 4 4 1 3 5 2 4 5 5 2 2 1 4 3 2 4 4 1 5 5 1 5 5 4 3 4 5 2 1 3 1 4 4 3 3 5 5 4 2 5 5 3 4 3 2 3 5 1 4 3 5 5 2 5 5 4 1 2 2 3 0 3 4 4 3 3 3 1 3 4 2 5 0 3 3 3 3 4 1 1 4 3 4 4 1 4 1 5 5 1 2 5 3 2 5 1 5 5 4 4 5 4 3 3 4 3 3 1 1 5 4 5 1 4 3 3 3 2 5 3 4 4 2 4 2 0 5 3 3 3 1 5 2 5 5 2 4 3 1 3 5 3 5 3 3 5 3 3 4 1 2 0 4 5 5 4 2 2 4 3 5 1 4 4 5 3 5 3 3 5 0 1 1 1 3 3 4 3 4"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 4 4 2 4 4 3 5 1 5 4 1 2 1 1 1 4 0 1 4 4 3 2 4 2 4 1 4 3 2 3 3 3 4 5 4 5 4 1 2 1 1 3 4 3 2 2 3 4 1 1 0 2 4 1 3 4 3 5 1 4 3 2 4 1 3 3 1 1 4 1 5 5 2 4 0 3 3 4 5 4 5 4 5 4 1 0 4 4 2 4 2 4 3 2 1 3 2 5 1 1 5 4 3 4 3 4 5 1 4 5 1 2 0 0 2 5 1 3 3 1 2 2 1 3 4 5 2 1 4 1 0 1 1 3 2 1 0 3 2 1 3 4 1 4 4 1 3 3 5 1 4 1 4 1 1 5 4 4 3 1 1 2 3 4 4 1 1 1 3 4 5 3 3 3 4 3 3 1 4 2 3 4 1 1 5 1 1 4 0 2 5 1 5 4 1 0 3 4 3 2 2 4 1 4 1 1 1 4 1 5 5 1 4 3 4 3 3 2 5 5 5 3 1 5 1 1 4 1 1 3 4 5 3 2 3 3 2 2 4 2 1 4 4 1 2 1 2 4 5 5 2 1 4 1 1 1 1 4 1 4 5 4 3 2 4 1 1 4 4 1 2 3 3 5 5 1 5 2 5 2 2 2 3 1 4 1 3 1 2 1 5 1 2 2 4 1 5 3 1 0 4 4 5 1 5 4 5 4 1 4 1 4 3 5 4 2 1 1 5 3 1 5 5 1 4 5 5 5 1 4 3 2 3 1 2 4 1 1 1 2 4 0 5 1 3 1 4 3 5 1 5 1 5 4 1 3 4 5 1 3 3 5 1 3 1 5 5 1 4 1 1 3 5 3 4 4 1 4 2 5 5 5 4 4 2 4 5 3 1 4 2 5 0 4 4 2 1 1 1 3 1 4 1 3 4 3 5 2 1 3 5 4 4 5 1 4 1 4 1 4 2 0 3 5 1 3 4 1 5 1 4 1 1 2 2 4 3 2 1 5 4 5 4 3 2 1 1 3 2 1 4 3 4 1 1 5 3 4 4 1 1 3 1 1 3 3 3 2 3 2 4 1 1 1 3 1 2 4 0 2 1 1 4 3 1 1 1 2 4 5 3 4 4 4 4 5 2 3 4 5 4 1 2 1 4 4 1 2 2 1 4 4 1 2 5 3 2 3 1 4 1 0 4 3 1 1 3 1 3 2 4 1 3 3 4 2 1 1 4 5 2 1 1 2 4 5 1 4 4 1 5 4 4 2 3 2 4 5 1 2 5 4 4 1 1 4 5 2 3 2 4 3 4 5 1 4 2 3 2 4 1 1 3 3 3 4 1 1 4 2 1 3 3 4 3 2 2 3 4 2 4 4 2 4 0 4 2 1 4 3 1 1 5 5 1 1 2 1 1 1 3 1 2 3 4 5 3 3 3 4 3 2 2 1 4 2 2 1 2 5 5 4 4 4 4 3 4 1 5 3 3 4 3 4 4 1 5 4 3 3 1 1 1 3 4 2 3 3 3 3 2 5 1 5 1 1 1 1 3 1 5 4 3 2 4 2 3 2 3 0 0 1 5 3 4 4 2 5 2 3 4 1 4 3 4 2 3 2 2 1 1 4 4 1 3 0 2 4 4 2 4 4 5 1 5 3 4 2 1 4 4 4 5 4 2 2 0 4 3 1 3 5 1 4 2 4 5 4 2 5 2 1 3 4 5 4 4 4 4 4 3 5 3 4 1 4 4 1 0 4 1 3 1 1 3 2 4 4 5 1 1 3 2 2 2 1 2 2 4 1 4 1 4 3 3 2 1 5 2 1 2 4 1 5 1 1 2 2 3 1 4 1 2 4 3 1 5 4 4 2 5 2 3 4 1 4 4 3 2 1 4 3 1 4 3 2 5 4 2 1 5 4 1 2 4 1 1 5 4 1 1 4 5 4 2 2 2 4 3 3 5 4 5 2 4 1 1 4 5 4 1 3 4 3 4 1 0 4 2 1 5 2 4 4 3 1 3 4 2 4 4 4 2 1 4 5 2 4 4 4 1 4 4 4 5 3 3 2 1 1 1 1 1 2 3 5 3 4 5 4 5 3 1 1 1 1 3 5 2 3 4 1 2 1 2 4 5 4 1 1 4 1 3 4 4 4 5 3 4 3 4 3 1 3 0 3 1 2 4 4 0 3 2 3 2 5 1 1 4 2 0 3 5 4 4 2 5 2 1 3 4 5 3 1 3 5 4 4 4 4 2 0 3 5 3 3 1 5 4 3 3 4 3 4 1 4 1 4 2 1 3 1 1 4 4 1 3 3 2 1 4 3 3 4 4 4 3 2 4 4 5 1 1 1 5 0 1 1 4 1 1 4 4 4 4 5 4 3 4 1 3 2 5 3 1 4 2 1 5 4 1 1 1 4 4 2 4 2 4 3 4 1 4 5 3 1 2 1 1 5 4 2 2 3 2 5 2 1 5 2 1 1 1 4 1 4 3 4 2 4 4 4 3 3 3 0 4 3 2 1 2 3 1 2 3 3 5 5 5 4 1 5 3 4 5 5 5 4 3 4 3 4 1 3 1 1 5 4 4 4 5 4 4 1 4 4 3 4 2 3 4 5 1 1 4 3 5 4 5 1 3 0 1 1 2 5 3 5 1 4 5 2 1 5 4 3 2 3 1 4 2 3 5 3 1 2 4 4 2 0 3 4 3 5 1 5 1 1 3 4 4 3 5 5 3 1 4 5 2 5 1 1 3 3 2 5 4 4 3 3 3 2 3 4 4 5 1 1 3 5 1 0 4 4 2 3 1 5 1 3 4 1 5 1 5 1 2 5 4 4 2 1 4 5 1 5 2 4 1 3 4 4 3 1 2 3 2 3 5 0 4 1 2 4 2 2 5 5 2 3 5 3 3 0 4 5 1 4 2 0 3 4 2 5 4 4 2 2 5 2 2 2 2 0 3 3 3 3 4 5 1 5 1 3 4 3 3 4 3 5 1 4 2 4 3 5 3 1 4 4 3 4 3 1 2 0 4 1 4 4 1 4 2 1 1 1 2 1 1 2 1 4 2 3 3 2 2 4 1 4 2 1 4 1 1 4 1 3 4 1 1 4 1 4 3 4 1 2 4 4 4 1 3 4 2 4 4 3 4 4 4 5 3 3 1 3 4 1 1 3 1 2 3 5 3 3 4 4 4 3 0 2 2 4 1 5 5 5 3 4 4 5 3 4 3 1 3 2 1 4 1 4 1 2 1 1 5 2 3 4 3 3 1 0 1 4 1 5 4 2 1 2 1 2 5 4 1 2 4 3 3 3 3 1 4 3 2 4 1 4 3 4 3 2 1 4 4 2 5 1 1 5 2 3 2 4 2 1 5 3 3 1 4 2 2 1 2 1 5 3 1 1 3 2 3 1 2 1 4 1 3 2 4 3 5 1 2 2 1 4 4 5 1 3 5 4 2 1 1 4 1 3 1 0 2 3 3 1 1 4 3 1 3 4 1 2 1 3 2 1 4 2 1 1 1 1 3 1 2 5 5 2 3 5 2 5 4 5 3 2 5 2 5 4 3 3 1 4 1 4 2 2 1 1 1 3 1 5 2 1 1 5 2 2 3 3 1 1 2 2 5 4 3 2 0 3 3 5 0 1 1 4 1 4 3 2 3 4 3 1 3 1 2 4 1 3 1 1 1 1 5 1 2 4 3 5 1 1 2 3 2 3 5 1 1 4 4 1 2 4 3 1 3 5 1 2 1 5 5 4 1 1 4 5 1 1 5 4 3 1 1 4 2 1 1 2 2 1 2 1 1 2 0 3 3 2 2 3 2 2 3 2 3 3 1 3 5 2 5 1 0 1 3 3 3 2 2 3 3 4 3 3 1 5 2 3 5 2 1 3 1 5 3 3 4 2 2 2 4 2 2 2 4 2 1 1 2 3 3 3 2 1 2 4 1 3 2 1 3 1 4 1 1 5 1 1 3 2 1 1 3 1 1 1 5 2 2 0 2 1 1 1 4 3 3 4 5 3 3 1 3 1 1 4 3 3 3 1 4 5 2 3 3 2 0 3 2 3 3 1 2 0 3 1 1 4 4 3 1 2 1 4 5 1 4 3 3 3 3 3 1 3 3 4 4 5 3 1 3 2 2 4 2 5 2 3 3 0 5 5 4 1 2 1 5 2 2 2 4 3 1 3 2 2 3 1 4 2 2 3 3 1 5 0 4 4 2 1 0 1 3 2 3 3 3 1 3 2 1 5 0 2 2 3 1 1 4 4 4 2 5 3 1 3 2 3 3 3 0 1 1 4 2 2 5 3 1 3 3 0 2 2 4 1 4 2 1 2 4 1 3 3 0 5 1 0 2 0 5 0 1 4 1 1 5 5 4 4 1 1 3 0 0 1 4 1 4 5 1 3 1 1 4 1 1 0 1 4 5 2 2 3 2 2 3 3 1 5 1 1 2 3 4 1 1 3 3 1 1 Correct: 5742 out of: 10269\n",
      "Accuracy of the network :  55.91586327782647\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "countCorrect0=0\n",
    "countCorrect1=0\n",
    "count0=0\n",
    "count1=0\n",
    "labels=pd.read_excel('trainReputation.xlsx' )\n",
    "\n",
    "Y=[]  #target\n",
    "Pred=[]  #predicted\n",
    "\n",
    "with torch.no_grad():\n",
    "    for row in range(len(input)):\n",
    "        outputs = net(input[row,:].float())\n",
    "        result=0\n",
    "        total+=1\n",
    "        if outputs[0]<outputs[1]:result=1\n",
    "        if outputs[result]<outputs[2]:result=2\n",
    "        if outputs[result]<outputs[3]:result=3\n",
    "        if outputs[result]<outputs[4]:result=4\n",
    "        if outputs[result]<outputs[5]:result=5\n",
    "        \n",
    "        if TrainLables.iloc[row,result]==1: correct+=1\n",
    "        \n",
    "        Y.append(labels.iloc[row])\n",
    "        Pred.append(result)\n",
    "        \n",
    "        print(result, end=' ')\n",
    "        \n",
    "    \n",
    "print('Correct:', correct, 'out of:', total )\n",
    "print('Accuracy of the network : ',( 100 * correct / total))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0200,  0.0500,  0.0550,  ..., -0.3562, -1.0098, -0.8691],\n",
       "        [ 0.0100,  0.0300,  0.0300,  ...,  1.0410,  0.2646, -0.4180],\n",
       "        [ 0.0450,  0.3550,  0.3500,  ...,  0.5498,  0.1101,  0.2856],\n",
       "        ...,\n",
       "        [ 0.0000,  0.0000,  0.0000,  ...,  0.4402,  1.1455,  1.0537],\n",
       "        [ 0.0000,  0.0500,  0.0400,  ...,  0.4883,  1.1436,  0.5972],\n",
       "        [ 0.0000,  0.0000,  0.0000,  ...,  1.3447,  1.0322,  0.3281]],\n",
       "       dtype=torch.float64)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the validation data\n",
    "\n",
    "ValidData=pd.read_excel('validReputation.xlsx' )\n",
    "ValidData=ValidData.iloc[:,:-2].astype(float)\n",
    "ValidData=ValidData/200\n",
    "\n",
    "SavesDirectory='./TunedModels/'+model_class+'/'+model_version+\"/Saves/\"\n",
    "TF_Output=pd.read_csv( SavesDirectory+'evalOut.tsv', sep='\\t')\n",
    "\n",
    "ValidData=pd.concat([ValidData,TF_Output], axis=1)\n",
    "\n",
    "\n",
    "ValidData=torch.tensor(ValidData.values)\n",
    "ValidData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1279</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1280</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1281</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1282</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1283</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1284 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0  1  2  3  4  5\n",
       "0     1  0  0  0  0  0\n",
       "1     0  0  0  1  0  0\n",
       "2     0  0  0  1  0  0\n",
       "3     0  0  0  0  1  0\n",
       "4     0  0  0  0  1  0\n",
       "...  .. .. .. .. .. ..\n",
       "1279  0  1  0  0  0  0\n",
       "1280  0  0  1  0  0  0\n",
       "1281  0  0  0  0  1  0\n",
       "1282  0  0  0  0  1  0\n",
       "1283  0  0  0  1  0  0\n",
       "\n",
       "[1284 rows x 6 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels=pd.read_excel('validReputation.xlsx' )\n",
    "\n",
    "labels=labels.iloc[:,-1] \n",
    "labelsOneHot=pd.get_dummies(labels)\n",
    "labelsOneHot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 1, 0, 0],\n",
       "        [0, 0, 0, 1, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, 0, 1, 0],\n",
       "        [0, 0, 0, 0, 1, 0],\n",
       "        [0, 0, 0, 1, 0, 0]], dtype=torch.uint8)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ValidLables =torch.tensor(labelsOneHot.values)\n",
    "ValidLables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 3 5 5 4 3 5 5 5 4 5 3 1 1 5 3 3 5 0 2 3 3 1 2 3 3 2 5 3 3 4 4 4 1 0 0 3 4 1 0 0 2 1 0 5 3 5 3 4 3 5 1 0 5 5 1 5 1 3 5 3 5 1 3 1 3 0 1 1 5 3 2 4 0 5 3 3 1 3 1 1 2 1 1 3 3 1 4 1 1 1 2 5 3 3 1 3 1 0 1 0 1 1 4 1 1 0 0 1 1 1 1 4 1 1 1 1 2 1 1 4 2 3 0 3 3 5 4 1 1 1 3 2 4 4 2 3 2 5 3 3 3 3 3 5 3 1 5 3 4 1 4 1 1 5 2 5 1 3 2 4 5 2 4 5 4 2 1 1 3 3 3 3 2 1 4 5 4 2 5 1 5 5 2 2 5 4 5 4 4 0 2 3 3 4 5 2 1 4 5 2 4 3 1 5 2 4 4 4 2 2 1 1 1 1 3 3 5 2 4 4 2 1 3 3 2 2 1 2 3 3 2 2 2 1 2 3 2 1 1 3 5 2 5 3 4 3 4 1 3 2 3 1 1 2 5 4 3 3 3 4 5 3 2 5 2 1 3 3 1 2 1 4 2 4 1 5 1 5 5 4 1 1 4 3 1 2 0 3 1 4 1 1 4 4 1 3 1 1 3 5 3 3 5 0 3 4 5 3 1 5 2 4 2 4 3 5 1 5 2 5 2 1 3 1 1 4 5 1 4 4 2 3 5 5 2 4 3 1 5 1 1 1 1 4 0 1 3 2 3 1 4 3 5 2 1 3 1 2 1 2 4 3 2 2 4 1 2 3 1 4 3 1 1 2 1 5 5 2 1 5 1 1 1 4 3 5 3 5 4 1 1 5 0 4 3 5 1 1 3 4 4 3 4 5 5 4 1 4 3 2 1 3 3 3 5 4 3 4 4 4 2 4 4 1 3 2 1 1 1 3 0 5 3 1 1 1 5 5 1 3 4 4 5 4 3 1 1 3 5 5 2 3 1 3 5 1 5 1 1 3 5 3 1 1 4 5 4 5 3 3 4 4 5 4 3 5 1 3 4 1 0 1 3 3 3 2 3 1 3 1 3 4 1 2 2 5 1 1 2 3 4 4 3 5 5 3 1 1 3 4 0 5 4 3 4 1 1 5 3 1 3 3 5 0 3 3 1 1 2 3 5 5 4 4 3 2 1 0 2 4 2 0 4 0 1 5 5 3 4 1 3 4 2 3 2 4 3 1 4 2 1 2 1 1 5 2 2 1 1 3 3 0 1 1 3 3 3 0 1 2 4 3 2 1 5 3 5 1 1 1 1 5 4 2 5 4 2 5 3 1 2 3 4 1 0 3 3 5 3 2 3 1 1 2 5 2 1 3 3 4 5 1 0 4 2 1 3 2 4 2 2 3 1 3 5 1 5 2 3 2 1 1 1 2 2 1 4 4 2 1 3 2 3 0 3 4 4 5 5 1 1 3 4 5 3 1 5 4 3 1 4 5 3 3 4 4 3 2 5 4 3 5 5 2 3 4 5 4 4 3 5 2 3 5 5 3 5 3 4 4 5 4 1 4 1 2 1 4 1 2 0 1 4 1 5 3 4 3 1 3 4 3 5 3 0 5 1 5 5 5 3 1 3 2 2 4 5 5 5 3 3 1 5 5 0 1 1 4 1 1 1 5 2 0 0 4 2 1 5 4 2 5 4 4 3 1 4 3 2 2 1 2 3 4 2 3 3 2 2 3 3 4 0 3 4 3 2 4 3 1 3 1 1 2 1 5 2 4 4 2 3 1 3 3 1 2 5 4 1 2 3 2 0 1 3 4 1 5 1 3 1 1 3 3 5 1 4 5 5 3 4 1 3 5 3 0 2 4 2 2 3 0 1 4 1 1 1 4 4 3 5 3 5 1 5 0 2 3 4 1 4 1 4 4 0 1 1 2 1 4 2 3 2 4 5 3 3 2 0 4 3 1 1 2 3 3 4 4 5 1 1 5 2 1 1 1 4 4 2 3 3 2 1 1 3 1 3 2 5 4 5 4 3 2 0 0 3 5 3 2 5 4 0 3 3 3 1 4 3 3 4 1 2 3 1 5 3 4 3 2 4 3 0 0 5 3 4 3 3 0 4 0 2 4 2 3 4 1 2 2 3 5 1 3 2 4 2 1 1 2 2 2 4 4 5 5 5 3 3 4 3 0 3 5 2 5 2 3 1 4 5 3 1 1 1 3 4 4 5 3 4 1 1 4 5 1 1 4 5 5 3 3 3 5 3 5 3 2 5 1 1 3 4 2 4 3 4 2 3 3 2 5 2 4 1 1 3 0 1 2 2 4 5 3 3 4 2 5 5 5 3 2 2 5 2 4 4 1 4 2 3 5 1 2 3 4 5 0 2 5 3 2 3 4 3 2 4 5 4 2 4 1 4 0 1 4 3 3 1 1 5 2 4 4 2 1 4 1 1 4 4 3 4 0 4 0 1 1 4 5 1 2 3 3 5 1 4 3 5 2 2 0 5 1 4 3 4 3 1 1 1 4 5 4 4 4 4 5 1 5 2 4 3 4 4 1 3 3 1 4 3 4 3 4 1 5 1 3 1 5 1 5 5 3 4 1 4 1 2 3 1 5 1 1 2 1 3 4 5 1 2 4 3 4 1 3 3 3 1 4 1 1 4 5 4 1 4 3 2 1 0 5 1 1 3 4 4 1 3 1 0 4 5 3 3 2 3 2 3 4 3 3 1 3 1 4 3 1 4 4 3 3 5 0 3 5 1 1 3 3 4 3 1 1 5 4 3 2 4 1 5 1 3 2 4 5 3 5 5 2 2 1 4 4 2 1 2 1 1 1 3 1 0 0 4 2 1 1 0 2 4 4 3 Correct: 619 out of: 1284\n",
      "Accuracy of the network :  48.20872274143302\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "countCorrect0=0\n",
    "countCorrect1=0\n",
    "count0=0\n",
    "count1=0\n",
    "\n",
    "Y=[]  #target\n",
    "Pred=[]  #predicted\n",
    "\n",
    "with torch.no_grad():\n",
    "    for row in range(len(ValidData)):\n",
    "        outputs = net(ValidData[row,:].float())\n",
    "        result=0\n",
    "        total+=1\n",
    "        if outputs[0]<outputs[1]:result=1\n",
    "        if outputs[result]<outputs[2]:result=2\n",
    "        if outputs[result]<outputs[3]:result=3\n",
    "        if outputs[result]<outputs[4]:result=4\n",
    "        if outputs[result]<outputs[5]:result=5\n",
    "        \n",
    "        if labelsOneHot.iloc[row,result]==1: correct+=1\n",
    "        \n",
    "        Y.append(labels.iloc[row])\n",
    "        Pred.append(result)\n",
    "        \n",
    "        print(result, end=' ')\n",
    "        \n",
    "    \n",
    "print('Correct:', correct, 'out of:', total )\n",
    "print('Accuracy of the network : ',( 100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0050,  0.0100,  0.0050,  ...,  1.1494,  1.3086,  0.3276],\n",
       "        [ 0.0000,  0.0000,  0.0000,  ...,  0.3982,  0.0169, -0.1653],\n",
       "        [ 0.0200,  0.0250,  0.0600,  ...,  0.0045, -0.2571, -0.2096],\n",
       "        ...,\n",
       "        [ 0.0100,  0.0050,  0.0250,  ...,  0.3398, -0.5029, -1.2500],\n",
       "        [ 0.2200,  0.0950,  0.0350,  ..., -0.0311, -0.2542, -0.1477],\n",
       "        [ 0.0050,  0.0600,  0.0100,  ..., -0.1382, -0.1805, -0.0736]],\n",
       "       dtype=torch.float64)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the test data\n",
    "\n",
    "TestData=pd.read_excel('testReputation.xlsx' )\n",
    "TestData=TestData.iloc[:,:-2].astype(float)\n",
    "TestData=TestData/200\n",
    "\n",
    "SavesDirectory='./TunedModels/'+model_class+'/'+model_version+\"/Saves/\"\n",
    "TF_Output=pd.read_csv( SavesDirectory+'testOut.tsv', sep='\\t')\n",
    "\n",
    "TestData=pd.concat([TestData,TF_Output], axis=1)\n",
    "\n",
    "\n",
    "TestData=torch.tensor(TestData.values)\n",
    "TestData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1278</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1279</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1280</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1281</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1282</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1283 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0  1  2  3  4  5\n",
       "0     0  0  0  0  1  0\n",
       "1     0  0  0  1  0  0\n",
       "2     0  1  0  0  0  0\n",
       "3     0  0  0  0  0  1\n",
       "4     0  0  0  0  0  1\n",
       "...  .. .. .. .. .. ..\n",
       "1278  0  1  0  0  0  0\n",
       "1279  0  0  0  0  1  0\n",
       "1280  0  0  1  0  0  0\n",
       "1281  1  0  0  0  0  0\n",
       "1282  0  1  0  0  0  0\n",
       "\n",
       "[1283 rows x 6 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels=pd.read_excel('testReputation.xlsx' )\n",
    "\n",
    "labels=labels.iloc[:,-1] \n",
    "labelsOneHot=pd.get_dummies(labels)\n",
    "labelsOneHot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0, 0, 0, 1, 0],\n",
       "        [0, 0, 0, 1, 0, 0],\n",
       "        [0, 1, 0, 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 1, 0, 0, 0],\n",
       "        [1, 0, 0, 0, 0, 0],\n",
       "        [0, 1, 0, 0, 0, 0]], dtype=torch.uint8)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TestLables =torch.tensor(labelsOneHot.values)\n",
    "TestLables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 3 2 3 4 3 4 3 5 3 3 3 3 1 4 3 1 3 1 4 5 4 5 3 5 5 1 4 3 5 4 1 0 3 5 3 5 3 5 4 5 5 3 1 5 3 5 2 3 5 4 3 3 5 1 4 5 2 5 1 1 2 1 5 1 5 5 5 1 3 5 5 1 5 5 1 5 1 5 5 2 5 5 4 1 2 1 5 5 4 3 1 1 1 2 1 4 5 3 1 4 0 3 1 1 1 1 1 1 5 1 3 4 3 1 1 0 3 1 2 3 2 4 3 1 4 1 4 5 3 3 3 1 3 3 2 5 1 2 3 4 4 1 3 3 3 3 3 4 3 0 3 1 4 5 3 5 5 3 3 4 1 1 1 3 5 4 5 3 1 1 3 5 5 1 3 5 3 3 2 5 4 3 1 1 0 2 4 4 5 2 5 5 0 1 1 2 2 3 1 1 3 5 4 4 1 3 5 3 3 2 2 3 1 4 1 2 4 2 1 1 1 3 1 1 4 3 2 3 0 4 1 0 1 3 2 2 0 5 2 2 1 2 2 4 1 2 1 3 3 0 4 4 5 3 3 3 0 4 1 2 1 1 2 0 5 1 3 4 2 2 3 1 2 5 2 5 1 1 3 5 1 3 4 3 5 5 1 3 0 1 4 1 3 1 1 3 3 3 4 1 4 4 5 5 3 2 5 3 3 1 4 1 3 3 4 5 3 3 3 5 4 4 3 1 0 5 4 5 3 2 3 3 1 5 1 1 3 3 2 4 3 3 3 3 5 2 3 1 1 1 0 4 1 4 1 1 3 1 2 4 1 1 1 2 0 1 4 5 1 0 1 5 5 4 3 4 5 3 1 5 1 3 4 1 3 3 2 1 5 3 2 1 1 2 3 3 1 1 4 3 1 0 1 4 5 2 5 3 5 3 2 1 4 2 1 1 5 3 5 2 4 4 1 2 3 3 3 4 3 5 1 3 3 2 4 3 3 5 1 4 5 1 1 3 4 3 2 3 5 1 5 1 3 4 4 4 3 1 1 5 2 3 4 4 3 1 3 1 3 3 4 1 4 1 2 3 1 5 3 2 3 3 1 2 1 2 0 5 5 1 3 4 3 2 1 3 4 3 4 3 4 2 2 5 4 1 4 4 4 1 5 1 2 4 5 4 3 1 5 1 3 2 5 1 4 5 3 1 5 3 0 3 1 1 3 1 1 3 5 3 5 4 2 1 3 0 5 3 1 1 5 1 2 3 2 3 2 2 4 1 5 1 1 0 1 5 4 3 3 4 3 5 0 1 4 4 4 2 4 1 2 3 1 1 3 3 3 4 3 4 2 3 1 2 1 1 4 4 3 2 3 2 4 3 3 4 1 4 4 1 4 4 1 4 5 3 3 4 4 2 3 3 1 2 5 5 5 0 0 1 1 1 5 3 2 3 3 2 2 1 3 3 5 3 4 3 3 3 4 3 2 4 2 4 3 1 5 5 3 4 2 3 5 3 4 4 4 3 0 4 4 5 3 3 3 5 5 1 4 5 4 4 2 4 2 3 3 2 4 4 5 2 4 4 4 4 2 1 0 1 2 5 1 5 3 3 3 1 2 4 5 3 4 3 4 4 2 5 4 1 4 4 3 1 4 3 5 3 4 1 2 1 4 4 3 3 5 1 1 4 4 4 5 3 2 5 0 3 0 3 4 4 3 3 5 4 3 1 3 2 5 4 5 1 4 1 1 4 3 3 4 4 4 2 2 1 5 3 4 3 3 5 2 0 5 1 1 1 4 4 4 5 5 5 3 2 2 5 3 4 5 1 2 5 1 0 3 1 5 5 3 5 4 3 1 5 4 1 2 1 5 3 4 3 1 3 3 4 3 4 3 1 5 4 3 4 3 1 2 4 1 4 5 5 2 4 0 3 5 3 1 1 1 4 4 4 3 3 3 4 5 2 4 4 1 3 3 5 0 4 5 1 4 0 1 3 0 2 5 5 1 2 0 4 3 2 2 3 4 1 2 5 4 3 1 3 3 3 2 1 4 1 2 2 1 5 2 4 5 2 3 5 2 4 3 4 0 0 2 3 1 1 3 4 0 3 2 3 2 2 1 5 2 3 4 4 1 3 2 4 4 3 5 4 4 5 5 3 3 3 3 1 2 3 2 2 1 5 5 0 3 3 1 1 5 3 2 3 1 1 1 1 4 0 4 3 2 4 4 5 2 5 3 4 4 1 1 5 3 4 2 5 4 5 5 1 3 5 3 1 3 4 1 3 3 0 3 4 2 1 1 2 1 3 4 1 3 5 1 4 3 5 4 5 1 4 5 2 1 1 4 1 1 5 3 4 1 5 4 4 4 1 1 5 4 5 4 2 1 1 3 4 3 5 5 3 5 4 3 3 1 4 4 0 2 4 1 2 4 2 3 4 4 4 2 4 5 2 1 4 5 3 4 3 3 1 4 1 3 3 5 4 1 2 2 4 1 3 1 3 3 3 2 4 4 4 1 1 4 5 3 0 2 1 2 2 5 2 1 5 1 4 4 1 2 1 5 1 1 4 1 2 1 4 1 1 4 4 5 4 3 1 3 2 4 3 4 0 3 5 3 1 4 2 4 5 4 4 4 2 5 3 4 2 4 1 5 5 3 3 1 4 1 4 2 0 5 4 1 3 4 1 1 3 0 3 3 4 4 3 1 3 4 3 0 4 5 3 3 4 4 4 4 1 2 2 4 1 1 5 5 3 2 4 1 4 5 3 1 2 1 3 5 1 4 4 1 3 4 4 2 3 2 1 2 2 2 3 3 3 1 5 1 5 3 3 3 3 1 2 2 3 4 1 5 3 1 3 2 3 1 1 2 3 5 2 1 3 4 4 4 1 4 0 1 1 2 4 2 3 0 1 Correct: 607 out of: 1283\n",
      "Accuracy of the network :  47.31098986749805\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "countCorrect0=0\n",
    "countCorrect1=0\n",
    "count0=0\n",
    "count1=0\n",
    "\n",
    "Y=[]  #target\n",
    "Pred=[]  #predicted\n",
    "\n",
    "with torch.no_grad():\n",
    "    for row in range(len(TestData)):\n",
    "        outputs = net(TestData[row,:].float())\n",
    "        result=0\n",
    "        total+=1\n",
    "        if outputs[0]<outputs[1]:result=1\n",
    "        if outputs[result]<outputs[2]:result=2\n",
    "        if outputs[result]<outputs[3]:result=3\n",
    "        if outputs[result]<outputs[4]:result=4\n",
    "        if outputs[result]<outputs[5]:result=5\n",
    "        \n",
    "        if labelsOneHot.iloc[row,result]==1: correct+=1\n",
    "        \n",
    "        Y.append(labels.iloc[row])\n",
    "        Pred.append(result)\n",
    "        \n",
    "        print(result, end=' ')\n",
    "        \n",
    "       \n",
    "print('Correct:', correct, 'out of:', total )\n",
    "print('Accuracy of the network : ',( 100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 40  26   8  13   4   1]\n",
      " [  3 143  27  38  21  18]\n",
      " [  3  35  79  52  27  18]\n",
      " [  1  40  27 125  47  27]\n",
      " [  0  21  13  64 117  34]\n",
      " [  3  21   9  25  51 102]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    " \n",
    "print(metrics.confusion_matrix(Y,Pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Pants       0.80      0.43      0.56        92\n",
      "       False       0.50      0.57      0.53       250\n",
      " Barely-True       0.48      0.37      0.42       214\n",
      "   Hlaf-True       0.39      0.47      0.43       267\n",
      " Mostly-True       0.44      0.47      0.45       249\n",
      "        True       0.51      0.48      0.50       211\n",
      "\n",
      "    accuracy                           0.47      1283\n",
      "   macro avg       0.52      0.47      0.48      1283\n",
      "weighted avg       0.49      0.47      0.47      1283\n",
      "\n"
     ]
    }
   ],
   "source": [
    "target_names = ['Pants', 'False', 'Barely-True','Hlaf-True','Mostly-True','True']\n",
    "\n",
    "print(metrics.classification_report(Y, Pred,target_names =target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the FCNN model\n",
    "\n",
    "stage='NNetwork/'\n",
    "SavesDirectory='./TunedModels/'+model_class+'/'+model_version+\"/\"+stage\n",
    "#PATH = SavesDirectory+'Tanh_MSE_adam4731.pth'\n",
    "\n",
    "torch.save(net.state_dict(), PATH)\n",
    "\n",
    "# more on saving pytorch networks: https://pytorch.org/docs/stable/notes/serialization.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
