{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we first do the classification using the BERT transformer\n",
    "This is our first classification task.\n",
    "\n",
    "The output classification vector from the transformer is saved to be used by the FCNN\n",
    "This is our second classification task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing necessary libraries\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import sklearn\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from simpletransformers.classification import ClassificationModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the dataset\n",
    "\n",
    "Some pre-processing to the dataset has already been done in preparation for various tests, so this processing is not from scratch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# procedure for getting the data sets and formatting them for the transformer\n",
    " \n",
    "\n",
    "def prepareDataset( filename):\n",
    "     \n",
    "    ReadSet=pd.read_excel(filename )\n",
    "\n",
    "    ReadSet['text']=ReadSet['Statement']\n",
    "    ReadSet['labels']=ReadSet['Label']\n",
    "    \n",
    "    ReadSet=ReadSet.drop(['ID','Label','Statement','Subject','Speaker','Job','From','Affiliation','PantsTotal','NotRealTotal','BarelyTotal','HalfTotal','MostlyTotal','Truths','Context'\n",
    "],axis=1)\n",
    "     \n",
    "    return ReadSet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The attorney general requires that rape victim...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>President Clinton reduced the scale of our mil...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I used tax cuts to help create over 80,000 job...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>New Mexico moved \"up to\" sixth in the nation i...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Corporate profits are up, CEO pay is up, but a...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10264</th>\n",
       "      <td>Under Obamacare, premiums have doubled and tri...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10265</th>\n",
       "      <td>We adopted the modern Social Security system a...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10266</th>\n",
       "      <td>More than two months ago President Barack Obam...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10267</th>\n",
       "      <td>We had a massive landslide victory, as you kno...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10268</th>\n",
       "      <td>Says U.S. Rep. Nancy Pelosi said, Employers cu...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10269 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  labels\n",
       "0      The attorney general requires that rape victim...       0\n",
       "1      President Clinton reduced the scale of our mil...       3\n",
       "2      I used tax cuts to help create over 80,000 job...       4\n",
       "3      New Mexico moved \"up to\" sixth in the nation i...       4\n",
       "4      Corporate profits are up, CEO pay is up, but a...       5\n",
       "...                                                  ...     ...\n",
       "10264  Under Obamacare, premiums have doubled and tri...       4\n",
       "10265  We adopted the modern Social Security system a...       5\n",
       "10266  More than two months ago President Barack Obam...       3\n",
       "10267  We had a massive landslide victory, as you kno...       1\n",
       "10268  Says U.S. Rep. Nancy Pelosi said, Employers cu...       1\n",
       "\n",
       "[10269 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# preparing the training dataset\n",
    "train=prepareDataset( 'train.xlsx')\n",
    "# and display for inspecting\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The president is brain-dead.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Barack Obama supported keeping troops in Iraq,...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>He's leading by example, refusing contribution...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I'm the first person who really took up the is...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I built that border fence in San Diego...and i...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1279</th>\n",
       "      <td>CNN accidentally aired 30 minutes of pornograp...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1280</th>\n",
       "      <td>President Obamas American Recovery and Reinves...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1281</th>\n",
       "      <td>We (in Illinois) have the fifth-highest tax bu...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1282</th>\n",
       "      <td>Says Donald Trump won more counties than any c...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1283</th>\n",
       "      <td>A recent study found that cities where Uber op...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1284 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  labels\n",
       "0                          The president is brain-dead.       0\n",
       "1     Barack Obama supported keeping troops in Iraq,...       3\n",
       "2     He's leading by example, refusing contribution...       3\n",
       "3     I'm the first person who really took up the is...       4\n",
       "4     I built that border fence in San Diego...and i...       4\n",
       "...                                                 ...     ...\n",
       "1279  CNN accidentally aired 30 minutes of pornograp...       1\n",
       "1280  President Obamas American Recovery and Reinves...       2\n",
       "1281  We (in Illinois) have the fifth-highest tax bu...       4\n",
       "1282  Says Donald Trump won more counties than any c...       4\n",
       "1283  A recent study found that cities where Uber op...       3\n",
       "\n",
       "[1284 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# preparing the evaluation/validation dataset\n",
    "Eval=prepareDataset('valid.xlsx')\n",
    "# and display for inspecting\n",
    "Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>New Mexico was 46th in teacher pay (when he wa...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Barack Obama and Hillary Clinton have changed ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I'll tell you what I can tell this country: If...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tommy Thompson created the first school choice...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fifty-six percent decline in overall crime. A ...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1278</th>\n",
       "      <td>We have trade agreements with 20 countries, an...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1279</th>\n",
       "      <td>On Donald Trumps plan to cut federal funding t...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1280</th>\n",
       "      <td>Black Lives Matter, who are attacking law enfo...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1281</th>\n",
       "      <td>Latina who enthusiastically supported Donald T...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1282</th>\n",
       "      <td>Theres been no conclusive or specific report t...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1283 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  labels\n",
       "0     New Mexico was 46th in teacher pay (when he wa...       4\n",
       "1     Barack Obama and Hillary Clinton have changed ...       3\n",
       "2     I'll tell you what I can tell this country: If...       1\n",
       "3     Tommy Thompson created the first school choice...       5\n",
       "4     Fifty-six percent decline in overall crime. A ...       5\n",
       "...                                                 ...     ...\n",
       "1278  We have trade agreements with 20 countries, an...       1\n",
       "1279  On Donald Trumps plan to cut federal funding t...       4\n",
       "1280  Black Lives Matter, who are attacking law enfo...       2\n",
       "1281  Latina who enthusiastically supported Donald T...       0\n",
       "1282  Theres been no conclusive or specific report t...       1\n",
       "\n",
       "[1283 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# preparing the test set dataset\n",
    "test=prepareDataset('test.xlsx')\n",
    "test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up the transformer for fine tuning\n",
    "\n",
    "This is where changes are done to optimise the model\n",
    "\n",
    "The simpletransformers library is the quickest way to do this at the time of writing. \n",
    "For more information on the settings and their default value go here:\n",
    "https://github.com/ThilinaRajapakse/simpletransformers#default-settings \n",
    "\n",
    "###### Please do read that reference before changing any parameters. Don't try to be a hero!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model variables were set up: \n"
     ]
    }
   ],
   "source": [
    "#Set the model being used here\n",
    "model_class='bert'  # bert or roberta or albert\n",
    "model_version='bert-base-cased' #bert-base-cased, roberta-base, roberta-large, albert-base-v2 OR albert-large-v2\n",
    "\n",
    "\n",
    "output_folder='./TunedModels/'+model_class+'/'+model_version+\"/\"\n",
    "cache_directory= \"./TunedModels/\"+model_class+\"/\"+model_version+\"/\"+\"/cache/\"\n",
    "labels_count=6  # the number of classification classes\n",
    "\n",
    "print('model variables were set up: ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G:\\0 finalThesis\\LIAR_Text\n",
      "./TunedModels/bert/bert-base-cased/\n",
      "./TunedModels/bert/bert-base-cased//cache/\n"
     ]
    }
   ],
   "source": [
    "# use this to test if writing to the directories is working\n",
    "\n",
    "import os\n",
    "print(os.getcwd())\n",
    "print(output_folder)\n",
    "print(cache_directory)\n",
    "\n",
    "testWrite=train.head(30)\n",
    " \n",
    "testWrite.to_csv(output_folder+'DeleteThisToo.tsv', sep='\\t')\n",
    "testWrite.to_csv(cache_directory+'DeleteThisToo.tsv', sep='\\t')\n",
    "\n",
    "del(testWrite)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "save_every_steps=1285\n",
    "# assuming training batch size of 8\n",
    "# any number above 1284 saves the model only at every epoch\n",
    "# Saving the model mid training very often will consume disk space fast\n",
    "\n",
    "train_args={\n",
    "    \"output_dir\":output_folder,\n",
    "    \"cache_dir\":cache_directory,\n",
    "    'reprocess_input_data': True,\n",
    "    'overwrite_output_dir': True,\n",
    "    'num_train_epochs': 2,\n",
    "    \"save_steps\": save_every_steps, \n",
    "    \"learning_rate\": 1.8e-5,\n",
    "    \"train_batch_size\": 64,\n",
    "    \"eval_batch_size\": 16,\n",
    "    \"evaluate_during_training_steps\": 312,\n",
    "    \"max_seq_length\": 100,\n",
    "    \"n_gpu\": 1,\n",
    "}\n",
    "\n",
    "# Create a ClassificationModel\n",
    "model = ClassificationModel(model_class, model_version, num_labels=labels_count, args=train_args) \n",
    "\n",
    "# You can set class weights by using the optional weight argument"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading a saved model (based on above args{})\n",
    "\n",
    "If you stopped training you can continue training from a previously saved check point.\n",
    "The next cell allows you to load a model from any checkpoint.\n",
    "The number of epochs in the train_args{} will be done and continue tuning from your checkpoint.\n",
    "\n",
    "###### HOWEVER\n",
    "It will overwrite previous checkpoints!\n",
    "Example:  If you load an epoch-3 checkpoint, the epoch-1 checkpoint will be overwritten by the 4th epoch and it will be equivalent to a 4th epoch even if you have epoch-1 in the name.\n",
    "###### SO BE CAREFUL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model, please wait...\n",
      "model in use is : ./TunedModels/bert/bert-base-cased/checkpoint-322-epoch-2\n"
     ]
    }
   ],
   "source": [
    "# loading a previously saved model based on this particular Transformer Class and model_name\n",
    "\n",
    "# loading the checkpoint that gave the best result\n",
    "CheckPoint='checkpoint-322-epoch-2'  #epoch 2\n",
    "\n",
    "\n",
    "preSavedCheckpoint=output_folder+CheckPoint\n",
    "\n",
    "print('Loading model, please wait...')\n",
    "model = ClassificationModel( model_class, preSavedCheckpoint, num_labels=labels_count, args=train_args) \n",
    "print('model in use is :', preSavedCheckpoint )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the Transformer\n",
    "\n",
    "Skip the next cell if you want to skip the training and go directly to the evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting to features started. Cache is not used.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d7632000111464a8085fa7f42c7bf61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=10269.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.\n",
      "\n",
      "Defaults for this optimization level are:\n",
      "enabled                : True\n",
      "opt_level              : O1\n",
      "cast_model_type        : None\n",
      "patch_torch_functions  : True\n",
      "keep_batchnorm_fp32    : None\n",
      "master_weights         : None\n",
      "loss_scale             : dynamic\n",
      "Processing user overrides (additional kwargs that are not None)...\n",
      "After processing overrides, optimization options are:\n",
      "enabled                : True\n",
      "opt_level              : O1\n",
      "cast_model_type        : None\n",
      "patch_torch_functions  : True\n",
      "keep_batchnorm_fp32    : None\n",
      "master_weights         : None\n",
      "loss_scale             : dynamic\n",
      "Warning:  multi_tensor_applier fused unscale kernel is unavailable, possibly because apex was installed without --cuda_ext --cpp_ext. Using Python fallback.  Original ImportError was: ModuleNotFoundError(\"No module named 'amp_C'\")\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb22fdcb98684988944602b00e317e6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch', max=2.0, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8e864ce219740f89698e6e7279ab6f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Current iteration', max=161.0, style=ProgressStyle(descri…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "Running loss: 1.845521"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mark\\Anaconda3\\envs\\thesis\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:110: UserWarning: Seems like `optimizer.step()` has been overridden after learning rate scheduler initialization. Please, make sure to call `optimizer.step()` before `lr_scheduler.step()`. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\"Seems like `optimizer.step()` has been overridden after learning rate scheduler \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running loss: 1.764381"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mark\\Anaconda3\\envs\\thesis\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:224: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running loss: 1.747870\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff84a7a280fb4215a3c3a0a902a56142",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Current iteration', max=161.0, style=ProgressStyle(descri…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running loss: 1.591926\n",
      "\n",
      "Training of bert model complete. Saved to ./TunedModels/bert/bert-base-cased/.\n",
      "Training time:  0:06:27.380125\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "start_time = datetime.now()\n",
    "model.train_model(train)\n",
    "print(\"Training time: \", datetime.now() - start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating the training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting to features started. Cache is not used.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "669611d6fc564e8d84e4722364aa087d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=10269.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ed2a55ffc1e400f9677c160a6380d50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=642.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{'mcc': 0.16271697234721857, 'acc': 0.3192131658389327, 'eval_loss': 1.6220376242729733}\n",
      "Converting to features started. Cache is not used.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da96c95ce5bb415cb5fdc2c540485095",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1284.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6e443d21818409588fa666762867525",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=81.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{'mcc': 0.08116052192534284, 'acc': 0.2562305295950156, 'eval_loss': 1.687631521695926}\n",
      "Training Result: 0.3192131658389327\n",
      "Eval Result: 0.2562305295950156\n",
      "Training & Evaluation time taken:  0:08:35.250750\n"
     ]
    }
   ],
   "source": [
    "TrainResult, TrainModel_outputs, wrong_predictions = model.eval_model(train, acc=sklearn.metrics.accuracy_score)\n",
    "\n",
    "EvalResult, EvalModel_outputs, wrong_predictions = model.eval_model(Eval, acc=sklearn.metrics.accuracy_score)\n",
    "\n",
    "\n",
    "print('Training Result:', TrainResult['acc'])\n",
    "#print('Model Out:', TrainModel_outputs)\n",
    "\n",
    "print('Eval Result:', EvalResult['acc'])\n",
    "#print('Model Out:', EvalModel_outputs)\n",
    "\n",
    "print(\"Training & Evaluation time taken: \", datetime.now() - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting to features started. Cache is not used.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28d11098d3a3438d9eef662e9934b324",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1283.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2267c1d931e74ad7b65b4fc1c332ebce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=81.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{'mcc': 0.10674957436746564, 'acc': 0.2766952455183164, 'eval_loss': 1.6706138746238048}\n",
      "Test Set Result: 0.2766952455183164\n"
     ]
    }
   ],
   "source": [
    "TestResult, TestModel_outputs, wrong_predictions = model.eval_model(test, acc=sklearn.metrics.accuracy_score)\n",
    "\n",
    "print('Test Set Result:', TestResult['acc'])\n",
    "#print('Model Out:', TestModel_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.5859375  -0.17675781 -0.6533203   0.28076172  1.0107422   1.0078125 ] 4   4 Match 1\n",
      "\n",
      "[-0.42333984  0.30200195  0.27197266  0.11785889 -0.3774414  -0.5854492 ] 1   3 \n",
      "[-0.67822266  0.28149414 -0.13684082 -0.04931641 -0.28320312  0.02845764] 1   1 Match 2\n",
      "\n",
      "[-1.1582031  -0.05422974  0.22033691  0.6225586   0.04275513 -0.2541504 ] 3   5 \n",
      "[-1.5605469  -0.1184082  -0.30859375  0.6230469   0.99560547  0.46679688] 4   5 \n",
      "[-1.4960938   0.23535156 -0.20532227  0.42089844  0.40698242  0.29785156] 3   2 \n",
      "[-1.8173828  -0.08123779 -0.27124023  0.71533203  1.0253906   0.3005371 ] 4   4 Match 3\n",
      "\n",
      "[-1.2617188  -0.0289917   0.15429688  0.31982422  0.27148438 -0.0657959 ] 3   5 \n",
      "[-1.4570312   0.06799316 -0.31713867  0.44067383  0.7050781   0.71875   ] 5   4 \n",
      "[-1.6611328   0.05957031 -0.19628906  0.6015625   0.8798828   0.4099121 ] 4   5 \n",
      "[-1.1210938   0.12176514  0.22509766  0.6645508  -0.01420593 -0.45922852] 3   5 \n",
      "[-1.1708984   0.27539062 -0.09887695  0.22485352  0.07519531  0.03710938] 1   3 \n",
      "[-0.09204102  0.87060547 -0.18737793 -0.34448242 -0.8720703  -0.43725586] 1   2 \n",
      "[-0.05429077  0.23352051  0.15686035 -0.28027344 -0.44848633 -0.40185547] 1   1 Match 4\n",
      "\n",
      "[-1.0136719   0.04562378  0.10351562  0.36791992  0.17248535 -0.03512573] 3   4 \n",
      "[-0.4111328   0.28857422 -0.12731934 -0.0682373  -0.44677734 -0.11907959] 1   4 \n",
      "[-1.3125      0.02984619 -0.31518555  0.40283203  0.39453125  0.27954102] 3   4 \n",
      "[-1.03125     0.4572754   0.13391113  0.4777832   0.15026855 -0.15795898] 3   3 Match 5\n",
      "\n",
      "[-0.5864258   0.33154297  0.14465332 -0.07702637 -0.3227539  -0.2668457 ] 1   1 Match 6\n",
      "\n",
      "[-1.3525391   0.04385376  0.09429932  0.4819336   0.2590332  -0.00785065] 3   1 \n",
      "[-1.0800781   0.3034668  -0.22583008  0.22351074  0.10174561  0.15808105] 1   1 Match 7\n",
      "\n",
      "[-1.6337891  -0.14404297 -0.32861328  0.4790039   1.1533203   0.7084961 ] 4   3 \n",
      "[-1.4501953   0.14013672 -0.30908203  0.42871094  0.5800781   0.4008789 ] 4   1 \n",
      "[-1.2255859   0.056427    0.29736328  0.63623047 -0.07495117 -0.29223633] 3   5 \n",
      "[-0.63720703  0.27783203  0.01800537  0.14648438 -0.3959961  -0.2265625 ] 1   5 \n",
      "[-0.34326172  0.29541016  0.04153442 -0.2758789  -0.4580078  -0.06512451] 1   5 \n",
      "[-0.7763672  -0.01145935 -0.01763916  0.32177734  0.08483887  0.0513916 ] 3   5 \n",
      "[-0.88378906  0.28881836 -0.06225586  0.12756348  0.06298828  0.03335571] 1   4 \n",
      "[-0.75097656  0.2199707   0.31933594  0.36083984 -0.02191162 -0.33007812] 3   5 \n",
      "[-0.8876953   0.3959961   0.034729    0.15454102 -0.08374023 -0.09539795] 1   3 \n",
      "[-0.68896484  0.37182617  0.02308655 -0.07366943 -0.4489746  -0.29077148] 1   5 \n",
      "[-1.265625    0.1060791  -0.4038086   0.15441895  0.33984375  0.4543457 ] 5   2 \n",
      "[ 0.3869629   0.34228516  0.13964844 -0.5151367  -0.77490234 -0.30200195] 0   0 Match 8\n",
      "\n",
      "[-1.3115234  -0.11486816 -0.08886719  0.6640625   0.59716797  0.14123535] 3   5 \n",
      "[-0.95410156  0.37768555 -0.18579102 -0.10681152  0.20715332  0.25976562] 1   5 \n",
      "[-1.2900391   0.07867432  0.1149292   0.58251953  0.49121094 -0.03616333] 3   5 \n",
      "[-1.2402344   0.12109375 -0.20947266  0.10675049  0.15014648  0.35107422] 5   4 \n",
      "[-0.2290039   0.20385742  0.15002441 -0.17541504 -0.38671875 -0.2668457 ] 1   3 \n",
      "[-0.9399414   0.18713379  0.03050232  0.1505127  -0.13879395 -0.06585693] 1   3 \n",
      "[-1.3808594   0.0141449   0.12817383  0.54296875  0.19030762 -0.0188446 ] 3   5 \n",
      "[-0.11547852  0.37695312  0.2475586  -0.22473145 -0.5698242  -0.3881836 ] 1   5 \n",
      "[-0.8330078   0.2607422   0.00205231  0.17236328 -0.08300781 -0.01516724] 1   4 \n",
      "[-1.0683594   0.22888184  0.00529861  0.23254395 -0.07843018  0.01181793] 3   3 Match 9\n",
      "\n",
      "[-0.9038086   0.19445801  0.1842041   0.30322266 -0.25976562 -0.36791992] 3   2 \n",
      "[-0.69433594  0.3330078  -0.4267578  -0.27294922 -0.09259033  0.31982422] 1   1 Match 10\n",
      "\n",
      "[-0.94433594  0.03634644  0.30004883  0.48779297 -0.1821289  -0.48266602] 3   2 \n",
      "[-1.6552734  -0.02352905 -0.33398438  0.34545898  0.60302734  0.71191406] 5   3 \n",
      "[-0.5332031   0.23962402  0.24279785  0.20007324 -0.22595215 -0.41357422] 2   2 Match 11\n",
      "\n",
      "[-1.0488281   0.57177734 -0.18664551  0.23791504  0.00355148  0.09570312] 1   2 \n",
      "[-1.4306641   0.20788574 -0.11138916  0.3671875   0.13378906  0.23706055] 3   5 \n",
      "[-1.4316406  -0.03961182  0.05862427  0.5649414   0.4892578   0.1282959 ] 3   5 \n",
      "[-1.7519531  -0.05264282 -0.4140625   0.44921875  0.8276367   0.8125    ] 4   2 \n",
      "[-1.8212891  -0.23864746 -0.19934082  0.8232422   0.8105469   0.39233398] 3   4 \n",
      "[-0.6401367   0.42041016  0.02804565  0.14123535 -0.56591797 -0.38256836] 1   2 \n",
      "[-0.7446289   0.3984375  -0.16931152 -0.05859375 -0.39819336  0.03289795] 1   1 Match 12\n",
      "\n",
      "[-0.32202148  0.03912354  0.41235352  0.03387451 -0.56152344 -0.5986328 ] 2   5 \n",
      "[-1.5908203  -0.04507446 -0.11242676  0.6196289   0.61816406  0.25170898] 3   5 \n",
      "[-0.5288086   0.1472168   0.15270996  0.33374023 -0.17675781 -0.4013672 ] 3   2 \n",
      "[-1.1328125  -0.01184845 -0.2244873   0.04821777  0.19189453  0.46899414] 5   5 Match 13\n",
      "\n",
      "[-0.97558594  0.38452148  0.00201607  0.2154541  -0.14782715 -0.08905029] 1   2 \n",
      "[-0.44018555  1.0820312  -0.47070312 -0.06500244 -0.6352539  -0.22094727] 1   1 Match 14\n",
      "\n",
      "[-1.5205078   0.01209259 -0.10467529  0.40185547  0.5527344   0.4345703 ] 4   1 \n",
      "[-0.28027344  0.9951172  -0.5234375  -0.1538086  -0.7338867  -0.0087738 ] 1   3 \n",
      "[-0.10742188  0.21240234  0.10577393 -0.06027222 -0.24841309 -0.30688477] 1   5 \n",
      "[-0.52685547  0.24206543  0.14282227  0.02452087 -0.42089844 -0.2866211 ] 1   0 \n",
      "[-1.109375    0.10412598  0.24206543  0.49243164 -0.00269318 -0.1685791 ] 3   5 \n",
      "[-1.3193359   0.01739502 -0.01707458  0.5136719   0.5727539   0.14953613] 4   3 \n",
      "[-1.6572266   0.00259018 -0.37304688  0.28320312  0.98535156  0.7211914 ] 4   4 Match 15\n",
      "\n",
      "[-0.36035156  0.23339844 -0.00208282 -0.15075684 -0.51171875 -0.33740234] 1   3 \n",
      "[-1.1601562   0.23364258  0.05953979  0.33764648 -0.07269287 -0.05834961] 3   1 \n",
      "[-1.5947266  -0.1138916  -0.12634277  0.5961914   0.5839844   0.25439453] 3   5 \n",
      "[-0.28564453  0.23095703 -0.04272461 -0.22753906 -0.40551758 -0.21887207] 1   1 Match 16\n",
      "\n",
      "[-0.5493164   0.3010254   0.3256836   0.23986816 -0.37719727 -0.4326172 ] 2   3 \n",
      "[-0.53808594  0.2854004  -0.05413818 -0.0960083  -0.27929688  0.12219238] 1   5 \n",
      "[ 0.09844971  0.41552734  0.03744507 -0.53466797 -0.6411133  -0.30688477] 1   4 \n",
      "[-0.25048828  1.0917969  -0.57714844 -0.21972656 -0.8383789  -0.26513672] 1   1 Match 17\n",
      "\n",
      "[-1.5341797  -0.18469238 -0.42211914  0.42822266  0.93603516  0.59375   ] 4   4 Match 18\n",
      "\n",
      "[-0.3852539   1.2226562  -0.44604492 -0.1262207  -0.8413086  -0.33325195] 1   3 \n",
      "[-0.953125    0.25927734 -0.07196045  0.14770508 -0.24987793 -0.01247406] 1   1 Match 19\n",
      "\n",
      "[-0.25219727  0.12097168  0.22460938 -0.05682373 -0.5439453  -0.4453125 ] 2   3 \n",
      "[-0.98095703 -0.01014709  0.42358398  0.67529297  0.14550781 -0.4501953 ] 3   3 Match 20\n",
      "\n",
      "[-1.2753906   0.30981445 -0.3305664   0.16064453  0.4482422   0.5361328 ] 5   5 Match 21\n",
      "\n",
      "[-1.0878906   0.27441406  0.05789185  0.22290039  0.02410889  0.05007935] 1   2 \n",
      "[-1.3388672   0.10894775 -0.17138672  0.30810547  0.33740234  0.21484375] 4   1 \n",
      "[-0.49072266  0.41870117 -0.01855469 -0.21679688 -0.6225586  -0.17492676] 1   4 \n",
      "[-1.0058594   0.04074097  0.22155762  0.37475586  0.12457275 -0.13964844] 3   3 Match 22\n",
      "\n",
      "[-1.1445312   0.44726562 -0.01599121  0.2475586  -0.19812012 -0.16699219] 1   3 \n",
      "[-0.44995117  0.23547363  0.07537842 -0.14147949 -0.25561523 -0.01733398] 1   3 \n",
      "[-0.3894043   0.28637695 -0.01589966 -0.07452393 -0.42089844 -0.34472656] 1   4 \n",
      "[-1.6103516  -0.11022949 -0.1459961   0.55126953  0.81640625  0.24731445] 4   5 \n",
      "[-0.9433594   0.30200195 -0.04412842  0.30786133 -0.15234375 -0.14709473] 3   4 \n",
      "[-0.0271759   0.7084961  -0.64453125 -0.47509766 -0.7841797  -0.13928223] 1   3 \n",
      "[ 0.23693848  0.4555664   0.1182251  -0.47924805 -0.78564453 -0.49267578] 1   0 \n",
      "[-1.8369141  -0.32055664 -0.37060547  0.59033203  0.89160156  0.61816406] 4   1 \n",
      "[-1.6328125   0.11218262 -0.08532715  0.53759766  0.7011719   0.06842041] 4   1 \n",
      "[-0.9501953   0.36035156  0.08258057  0.27612305 -0.10894775 -0.06787109] 1   1 Match 23\n",
      "\n",
      "[-1.1787109   0.20019531 -0.06384277  0.46240234  0.03799438  0.08148193] 3   5 \n",
      "[-0.78027344  0.22888184 -0.0553894   0.10125732 -0.4387207  -0.11987305] 1   5 \n",
      "[-0.38183594  0.09338379 -0.13342285 -0.07409668 -0.14868164  0.02677917] 1   3 \n",
      "[-0.68896484  0.1850586   0.42993164  0.19311523 -0.07611084 -0.35473633] 2   1 \n",
      "[-1.5849609  -0.09399414 -0.6689453   0.30371094  1.0810547   0.89990234] 4   4 Match 24\n",
      "\n",
      "[-0.07763672  0.11236572  0.17871094 -0.24829102 -0.46435547 -0.54052734] 2   0 \n",
      "[-1.0068359   0.3154297   0.1237793   0.51464844 -0.08703613 -0.23937988] 3   3 Match 25\n",
      "\n",
      "[-0.7294922   0.2319336  -0.27319336 -0.26391602 -0.16918945  0.13134766] 1   1 Match 26\n",
      "\n",
      "[-1.6669922   0.03860474 -0.1628418   0.45410156  0.61816406  0.5395508 ] 4   2 \n",
      "[-1.4003906  -0.19213867  0.0769043   0.71191406  0.30639648 -0.12854004] 3   1 \n",
      "[ 0.08508301  0.27319336  0.28686523 -0.17675781 -0.58447266 -0.60839844] 2   2 Match 27\n",
      "\n",
      "[-0.5288086   0.23291016  0.2446289   0.28344727 -0.3479004  -0.48535156] 3   5 \n",
      "[-0.47729492  0.3334961   0.07226562  0.03213501 -0.38891602 -0.3869629 ] 1   5 \n",
      "[-1.5537109   0.15600586 -0.25708008  0.39892578  0.71875     0.27441406] 4   2 \n",
      "[-0.34643555  0.1751709   0.03887939 -0.21264648 -0.14233398 -0.02479553] 1   0 \n",
      "[-1.0478516   0.03015137  0.3251953   0.46948242  0.00249481 -0.37036133] 3   2 \n",
      "[-1.2568359   0.05413818  0.03460693  0.4020996   0.18310547  0.1451416 ] 3   5 \n",
      "[-1.6621094  -0.09857178 -0.02641296  0.7241211   0.8198242   0.20141602] 4   4 Match 28\n",
      "\n",
      "[-0.21862793  1.0556641  -0.3918457  -0.26953125 -0.7729492  -0.2130127 ] 1   1 Match 29\n",
      "\n",
      "[-0.28051758  0.01322937  0.29785156 -0.00652695 -0.5        -0.5620117 ] 2   0 \n",
      "[-0.3947754   0.17529297 -0.44604492 -0.26953125  0.14099121  0.22949219] 5   5 Match 30\n",
      "\n",
      "[-1.4101562  -0.15783691  0.19250488  0.7026367   0.17602539 -0.09356689] 3   1 \n",
      "[-0.36328125  0.25341797  0.35742188  0.02424622 -0.5991211  -0.65283203] 2   1 \n",
      "[-1.8183594  -0.05111694 -0.28393555  0.5522461   1.0322266   0.609375  ] 4   3 \n",
      "[-0.9267578   0.21813965 -0.06842041  0.15551758 -0.09265137  0.08758545] 1   2 \n",
      "[-0.44458008  0.45996094  0.07495117 -0.10546875 -0.3852539  -0.2902832 ] 1   2 \n",
      "[-1.6289062  -0.13391113 -0.7138672   0.3955078   1.0214844   1.0244141 ] 5   4 \n",
      "[-1.71875    -0.14196777 -0.1743164   0.59375     0.57910156  0.22888184] 3   4 \n",
      "[-0.80810547  0.15124512  0.18920898  0.2524414  -0.20166016 -0.28588867] 3   5 \n",
      "[-0.5996094   0.33007812  0.26953125  0.12524414 -0.34301758 -0.35742188] 1   1 Match 31\n",
      "\n",
      "[-1.1064453   0.26000977 -0.2319336   0.1899414   0.17700195  0.17102051] 1   1 Match 32\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.3828125  -0.05761719  0.11505127  0.6118164   0.06762695 -0.03848267] 3   4 \n",
      "[-1.7207031  -0.24768066 -0.22644043  0.76220703  0.7314453   0.46875   ] 3   5 \n",
      "[-1.6347656  -0.09094238 -0.09320068  0.54003906  0.94628906  0.24414062] 4   1 \n",
      "[-1.7802734  -0.14526367  0.05651855  0.9868164   0.5498047  -0.03082275] 3   2 \n",
      "[-0.4013672   0.37768555 -0.40942383 -0.27490234 -0.2397461   0.09002686] 1   2 \n",
      "[ 0.2277832   0.33642578  0.01015472 -0.48364258 -0.8598633  -0.44189453] 1   1 Match 33\n",
      "\n",
      "[-0.83984375  0.22277832 -0.203125    0.24853516  0.3395996   0.14465332] 4   2 \n",
      "[-1.2675781  -0.01068878  0.16381836  0.6689453   0.23413086 -0.20776367] 3   1 \n",
      "[-0.72558594  0.27368164 -0.27783203 -0.11212158 -0.08703613  0.20654297] 1   2 \n",
      "[-1.4482422  -0.17736816 -0.3173828   0.5493164   0.6748047   0.37719727] 4   5 \n",
      "[-0.6381836   0.5136719  -0.28930664 -0.24951172 -0.19311523  0.14611816] 1   5 \n",
      "[-1.3789062   0.08428955 -0.14428711  0.39892578  0.38232422  0.1270752 ] 3   2 \n",
      "[-1.0478516  -0.06100464 -0.0010643   0.6435547   0.2241211  -0.20397949] 3   3 Match 34\n",
      "\n",
      "[-0.4699707   0.12280273  0.45214844  0.4584961  -0.31054688 -0.75634766] 3   1 \n",
      "[-1.6347656 -0.2631836 -0.4362793  0.6826172  1.140625   0.5800781] 4   2 \n",
      "[-1.2480469   0.41845703 -0.24890137  0.24707031  0.18640137  0.2019043 ] 1   1 Match 35\n",
      "\n",
      "[-0.78222656  0.19580078 -0.06069946  0.2109375   0.12304688 -0.1776123 ] 3   4 \n",
      "[-1.9208984  -0.34521484 -0.03598022  0.9609375   0.71191406  0.20007324] 3   3 Match 36\n",
      "\n",
      "[-1.6728516  -0.11883545  0.02340698  0.8383789   0.50878906 -0.02650452] 3   4 \n",
      "[-1.5576172  -0.03372192  0.0881958   0.8178711   0.28466797 -0.24829102] 3   3 Match 37\n",
      "\n",
      "[ 0.04876709  0.3918457  -0.03518677 -0.25585938 -0.46411133 -0.3935547 ] 1   3 \n",
      "[-1.6191406  -0.16333008 -0.55029297  0.4189453   0.96875     0.8798828 ] 4   5 \n",
      "[ 0.1586914   0.42773438 -0.06512451 -0.18115234 -0.6953125  -0.45996094] 1   4 \n",
      "[-0.11456299  0.4790039  -0.05401611 -0.40527344 -0.75390625 -0.42236328] 1   1 Match 38\n",
      "\n",
      "[-1.8300781  -0.1887207  -0.16723633  0.7915039   0.8066406   0.24865723] 4   2 \n",
      "[-0.18395996  0.17077637  0.06976318 -0.3515625  -0.5830078  -0.09716797] 1   1 Match 39\n",
      "\n",
      "[-1.2548828   0.08306885 -0.10601807  0.44335938  0.46704102  0.11199951] 4   3 \n",
      "[-0.39892578  0.2286377   0.3569336   0.12103271 -0.45629883 -0.5283203 ] 2   2 Match 40\n",
      "\n",
      "[-0.54248047  0.15148926  0.36450195  0.1986084  -0.33911133 -0.43798828] 2   3 \n",
      "[-1.7324219  -0.14953613 -0.48950195  0.5834961   1.1494141   0.8129883 ] 4   5 \n",
      "[-1.7177734   0.1027832  -0.14892578  0.58691406  0.8671875   0.4663086 ] 4   4 Match 41\n",
      "\n",
      "[-1.1132812  -0.10968018  0.09643555  0.6352539   0.17053223 -0.18566895] 3   4 \n",
      "[-1.6904297  -0.11712646 -0.32080078  0.41918945  0.93115234  0.57714844] 4   5 \n",
      "[-1.3730469  -0.29760742  0.0859375   0.7944336   0.14526367 -0.16027832] 3   5 \n",
      "[-0.4645996   0.04284668  0.1496582  -0.11224365 -0.05880737 -0.234375  ] 2   1 \n",
      "[-0.90185547  0.26000977  0.12109375  0.47387695 -0.16992188 -0.33911133] 3   4 \n",
      "[-0.31640625  1.3339844  -0.5800781  -0.16418457 -0.65625     0.0184021 ] 1   3 \n",
      "[-1.6181641   0.13464355 -0.4272461   0.3256836   0.69970703  0.77490234] 5   3 \n",
      "[-1.3574219  -0.03775024  0.16027832  0.7109375   0.39208984 -0.28857422] 3   5 \n",
      "[-0.5444336   0.21643066  0.01875305  0.01199341 -0.40161133 -0.23156738] 1   3 \n",
      "[-1.8457031  -0.24975586 -0.36645508  0.5708008   1.0761719   0.69140625] 4   2 \n",
      "[-0.4272461   0.33691406 -0.38891602 -0.27368164 -0.3425293   0.04373169] 1   3 \n",
      "[-0.28466797  0.5239258  -0.13085938 -0.12512207 -0.49414062 -0.35791016] 1   1 Match 42\n",
      "\n",
      "[-1.15625     0.1463623   0.19628906  0.3713379   0.31054688 -0.02638245] 3   3 Match 43\n",
      "\n",
      "[-1.6640625  -0.22705078  0.02850342  0.8613281   0.6982422   0.04101562] 3   2 \n",
      "[-0.73779297  0.12384033 -0.04492188  0.05206299 -0.30273438  0.01251221] 1   5 \n",
      "[-1.7666016  -0.2783203  -0.5307617   0.53759766  1.0986328   0.88183594] 4   5 \n",
      "[-0.0670166   0.92529297 -0.46850586 -0.41088867 -0.8442383  -0.1496582 ] 1   3 \n",
      "[-1.0185547  -0.10247803  0.19873047  0.43579102  0.01811218 -0.28173828] 3   5 \n",
      "[-1.6416016  -0.0748291  -0.5449219   0.20959473  0.9897461   0.95751953] 4   3 \n",
      "[-0.85546875 -0.016922    0.4165039   0.60791016 -0.09069824 -0.50097656] 3   4 \n",
      "[-1.1552734  -0.20922852  0.16430664  0.5205078   0.33911133 -0.17822266] 3   1 \n",
      "[-1.7705078  -0.15112305 -0.36914062  0.49267578  1.0214844   0.72802734] 4   2 \n",
      "[-1.4443359   0.13439941 -0.61816406  0.03811646  0.73779297  0.95654297] 5   5 Match 44\n",
      "\n",
      "[-1.6201172   0.05731201 -0.3425293   0.37548828  0.99560547  0.4946289 ] 4   3 \n",
      "[-0.8666992   0.1619873  -0.09747314  0.07385254 -0.10614014 -0.07049561] 1   3 \n",
      "[-0.6201172   0.60058594 -0.21276855 -0.19482422 -0.32128906  0.13879395] 1   1 Match 45\n",
      "\n",
      "[-1.1132812   0.10632324 -0.14086914  0.29370117  0.26953125  0.12902832] 3   1 \n",
      "[-0.62060547  0.28637695 -0.0226593  -0.1463623  -0.4206543   0.01968384] 1   0 \n",
      "[-0.34960938  0.24353027  0.0645752  -0.08209229 -0.44702148 -0.32714844] 1   0 \n",
      "[-0.9326172   0.35864258 -0.14672852  0.15356445  0.29882812  0.09820557] 1   4 \n",
      "[-1.3085938  -0.09002686 -0.07275391  0.5053711   0.17492676 -0.06359863] 3   1 \n",
      "[-1.3359375   0.17895508 -0.4230957   0.02177429  0.5522461   0.5551758 ] 5   5 Match 46\n",
      "\n",
      "[-1.0224609   0.19995117  0.43945312  0.5620117   0.06204224 -0.5136719 ] 3   2 \n",
      "[-1.5537109  -0.3076172  -0.57373047  0.3881836   1.0625      0.90771484] 4   5 \n",
      "[-1.0556641   0.41455078 -0.24401855  0.1821289   0.3630371   0.14465332] 1   5 \n",
      "[-1.5058594  -0.0397644  -0.2475586   0.25390625  0.9682617   0.65234375] 4   0 \n",
      "[-0.5761719   0.1907959   0.015625    0.06860352  0.04302979 -0.40625   ] 1   1 Match 47\n",
      "\n",
      "[-0.40063477  1.2207031  -0.4880371  -0.06445312 -0.7182617  -0.08691406] 1   1 Match 48\n",
      "\n",
      "[-0.5107422   0.52978516 -0.3544922  -0.18249512 -0.29174805  0.08221436] 1   2 \n",
      "[-0.48364258  0.08221436  0.25048828  0.05987549 -0.11987305 -0.44433594] 2   3 \n",
      "[-1.0986328   0.03182983  0.35009766  0.5180664   0.1229248  -0.2956543 ] 3   3 Match 49\n",
      "\n",
      "[-0.21643066  0.2849121   0.07434082 -0.3618164  -0.578125   -0.14562988] 1   1 Match 50\n",
      "\n",
      "[ 0.27807617  0.19799805  0.24060059 -0.26098633 -0.5439453  -0.42358398] 0   1 \n",
      "[-1.5605469  -0.3840332  -0.17346191  0.75439453  0.43481445  0.18579102] 3   2 \n",
      "[-0.78271484  0.07946777  0.17041016  0.23840332 -0.12408447 -0.10974121] 3   3 Match 51\n",
      "\n",
      "[-1.6679688   0.07611084 -0.12353516  0.4362793   0.7495117   0.3630371 ] 4   3 \n",
      "[-1.5019531  -0.08343506 -0.28930664  0.51708984  1.0244141   0.37182617] 4   1 \n",
      "[-0.27075195  0.37524414  0.12158203  0.08917236 -0.2055664  -0.34448242] 1   1 Match 52\n",
      "\n",
      "[-1.7861328   0.05038452 -0.02529907  0.75927734  0.5136719   0.08789062] 3   4 \n",
      "[-1.3427734  -0.25073242 -0.3725586   0.15515137  1.0263672   0.64990234] 4   5 \n",
      "[-1.5390625   0.12097168 -0.112854    0.40576172  0.5214844   0.36645508] 4   3 \n",
      "[-0.81103516  0.03952026  0.09539795  0.42895508  0.33569336 -0.13952637] 3   3 Match 53\n",
      "\n",
      "[-0.33764648  0.11254883  0.40795898  0.14709473 -0.42749023 -0.54345703] 2   1 \n",
      "[-0.9272461   0.1270752   0.28149414  0.42163086 -0.13098145 -0.38745117] 3   3 Match 54\n",
      "\n",
      "[-0.27807617  1.1005859  -0.39794922 -0.21252441 -0.72021484 -0.28100586] 1   3 \n",
      "[ 0.23144531  0.28076172  0.02731323 -0.40405273 -0.4958496  -0.39453125] 1   0 \n",
      "[-0.5029297   0.27661133  0.13146973  0.18383789 -0.28588867 -0.36767578] 1   2 \n",
      "[-0.40063477  0.32788086 -0.1661377  -0.23156738 -0.2084961  -0.02314758] 1   5 \n",
      "[-0.7480469   0.36743164  0.27539062  0.3088379  -0.28344727 -0.5371094 ] 1   2 \n",
      "[-1.6953125  -0.27246094 -0.5493164   0.47998047  0.9482422   0.7944336 ] 4   4 Match 55\n",
      "\n",
      "[ 0.18835449  0.5332031  -0.05435181 -0.51123047 -0.7792969  -0.21923828] 1   3 \n",
      "[ 0.20166016 -0.0166626   0.00069475 -0.5097656  -0.59521484 -0.19433594] 0   4 \n",
      "[-0.94189453  0.04806519 -0.03158569  0.37719727 -0.29467773 -0.13549805] 3   4 \n",
      "[-0.14221191  0.5708008  -0.04748535 -0.3137207  -0.27563477 -0.19702148] 1   1 Match 56\n",
      "\n",
      "[-1.2763672   0.00515747  0.14587402  0.6020508   0.11798096 -0.05410767] 3   4 \n",
      "[-0.22705078  0.17260742  0.28637695 -0.04147339 -0.39233398 -0.55126953] 2   2 Match 57\n",
      "\n",
      "[-1.2998047   0.11431885  0.27148438  0.5410156   0.13391113 -0.00343895] 3   1 \n",
      "[-1.7929688  -0.10437012  0.02816772  0.96533203  0.6484375  -0.04455566] 3   2 \n",
      "[ 0.05801392  0.30810547  0.25854492 -0.2319336  -0.70751953 -0.4543457 ] 1   3 \n",
      "[-1.2080078   0.23876953  0.08032227  0.27783203  0.41088867  0.13110352] 4   1 \n",
      "[-1.5683594  -0.16296387 -0.05899048  0.8886719   0.39794922  0.04275513] 3   3 Match 58\n",
      "\n",
      "[-0.01850891  0.32128906  0.1459961  -0.48608398 -0.6616211  -0.35229492] 1   0 \n",
      "[-1.6054688  -0.08978271 -0.24523926  0.56591797  0.9296875   0.35717773] 4   3 \n",
      "[-1.0185547   0.0958252  -0.11242676  0.2319336   0.25317383  0.12084961] 4   1 \n",
      "[ 0.23071289  0.16772461  0.28759766 -0.06835938 -0.41674805 -0.54345703] 2   0 \n",
      "[-0.93310547  0.21704102 -0.31323242 -0.06304932  0.08673096  0.37280273] 5   0 \n",
      "[-1.7402344  -0.02870178 -0.234375    0.6479492   0.68359375  0.51416016] 4   1 \n",
      "[ 0.03146362  0.2998047   0.25512695 -0.01126099 -0.4975586  -0.58203125] 1   3 \n",
      "[-1.1484375  -0.06518555  0.2800293   0.79296875  0.0369873  -0.38793945] 3   5 \n",
      "[ 0.38183594  0.44604492 -0.08441162 -0.71972656 -0.7817383  -0.30151367] 1   0 \n",
      "[-1.6933594  -0.25952148 -0.5703125   0.43530273  0.9682617   0.9760742 ] 5   4 \n",
      "[-0.71728516 -0.01303864  0.56152344  0.5522461  -0.04040527 -0.7470703 ] 2   2 Match 59\n",
      "\n",
      "[ 0.16723633  0.40429688  0.00127792 -0.48608398 -0.5854492  -0.35351562] 1   2 \n",
      "[-0.17053223  0.38378906 -0.19763184 -0.4272461  -0.16625977 -0.07342529] 1   1 Match 60\n",
      "\n",
      "[-0.6201172   0.06494141  0.30126953  0.27075195 -0.11108398 -0.28735352] 2   3 \n",
      "[-0.19750977  0.16833496  0.01007843 -0.40014648 -0.74560547 -0.24829102] 1   5 \n",
      "[-0.14282227  0.16149902  0.23840332 -0.21557617 -0.40625    -0.37841797] 2   4 \n",
      "[-0.7988281   0.38476562 -0.32202148 -0.1394043  -0.01296234  0.3088379 ] 1   1 Match 61\n",
      "\n",
      "[ 0.23535156  0.28320312  0.25683594 -0.3876953  -0.81152344 -0.55322266] 1   0 \n",
      "[-0.47851562  1.3769531  -0.54296875 -0.09039307 -0.6113281  -0.12731934] 1   1 Match 62\n",
      "\n",
      "[-1.3017578e+00  9.0885162e-04  1.9274902e-01  5.7470703e-01\n",
      "  1.7968750e-01 -1.2731934e-01] 3   3 Match 63\n",
      "\n",
      "[ 0.0657959   0.30004883  0.22912598 -0.20690918 -0.57714844 -0.51904297] 1   2 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.18969727  0.22021484  0.23742676 -0.10852051 -0.4248047  -0.4555664 ] 2   2 Match 64\n",
      "\n",
      "[ 0.28881836  0.44995117 -0.27978516 -0.64404297 -0.57128906 -0.09368896] 1   5 \n",
      "[-0.1427002   0.17456055  0.40795898  0.22668457 -0.19189453 -0.6201172 ] 2   3 \n",
      "[-0.9682617  -0.09442139  0.18237305  0.46777344  0.15466309 -0.15332031] 3   4 \n",
      "[-1.3330078   0.02597046 -0.28686523  0.38330078  0.79345703  0.63720703] 4   1 \n",
      "[-0.6152344   0.1875      0.20300293 -0.02572632  0.11468506 -0.17932129] 2   1 \n",
      "[-1.4541016   0.03030396 -0.47753906  0.40112305  0.61328125  0.47216797] 4   1 \n",
      "[-0.2890625   0.01476288 -0.1361084  -0.25830078 -0.35546875 -0.2631836 ] 1   0 \n",
      "[-0.35424805  0.15332031  0.43603516  0.26342773 -0.45092773 -0.6152344 ] 2   4 \n",
      "[-0.7285156   0.1685791   0.4321289   0.46923828 -0.04400635 -0.5234375 ] 3   1 \n",
      "[-1.0595703   0.02639771  0.24621582  0.59033203 -0.12548828 -0.2944336 ] 3   3 Match 65\n",
      "\n",
      "[-0.09130859  0.11883545  0.43920898  0.09545898 -0.4404297  -0.56689453] 2   1 \n",
      "[-1.0830078   0.2565918  -0.03022766  0.2319336  -0.04806519  0.11364746] 1   1 Match 66\n",
      "\n",
      "[-1.5136719  -0.10272217  0.04901123  0.45703125  0.39331055  0.34472656] 3   3 Match 67\n",
      "\n",
      "[-0.37548828  0.2043457   0.3154297   0.21032715 -0.21228027 -0.57177734] 2   0 \n",
      "[-1.0507812   0.3083496  -0.09033203  0.1977539   0.02560425  0.20153809] 1   5 \n",
      "[-0.9716797   0.12792969 -0.2619629   0.12207031 -0.05621338  0.03665161] 1   0 \n",
      "[-1.7783203  -0.26000977 -0.37280273  0.55371094  1.0048828   0.7128906 ] 4   3 \n",
      "[-1.7070312  -0.19677734 -0.23950195  0.5810547   0.8222656   0.53125   ] 4   2 \n",
      "[-0.71728516  0.52685547 -0.10552979  0.10327148  0.36572266  0.09924316] 1   0 \n",
      "[ 0.27368164  0.16870117  0.13098145 -0.3623047  -0.5390625  -0.4033203 ] 0   0 Match 68\n",
      "\n",
      "[-1.5478516  -0.02407837  0.2919922   0.7910156   0.39257812 -0.09143066] 3   4 \n",
      "[-0.18908691  0.3564453   0.0401001  -0.25463867 -0.5649414  -0.16748047] 1   1 Match 69\n",
      "\n",
      "[-1.1171875   0.04162598  0.3642578   0.82177734  0.1640625  -0.59228516] 3   2 \n",
      "[-0.2064209   0.5703125  -0.28466797 -0.47802734 -0.5449219   0.07098389] 1   3 \n",
      "[-1.0400391   0.06756592  0.26416016  0.6074219   0.13305664 -0.3642578 ] 3   2 \n",
      "[-1.5        -0.21557617 -0.62158203  0.4321289   1.109375    0.79833984] 4   5 \n",
      "[-0.16845703  0.9248047  -0.75341797 -0.22436523 -0.14440918  0.19238281] 1   3 \n",
      "[-1.7890625  -0.11901855 -0.19677734  0.73779297  0.7529297   0.3251953 ] 4   5 \n",
      "[-1.5        -0.12512207 -0.26391602  0.58447266  0.73583984  0.28222656] 4   4 Match 70\n",
      "\n",
      "[-1.5566406  -0.29760742 -0.28222656  0.70703125  0.6152344   0.49121094] 3   4 \n",
      "[-0.80078125 -0.06323242 -0.17456055  0.13171387  0.36914062  0.07214355] 4   1 \n",
      "[-1.5556641   0.03022766  0.12426758  0.8095703   0.47631836 -0.21789551] 3   4 \n",
      "[-1.0341797  -0.04135132  0.28271484  0.3166504   0.2709961  -0.06182861] 3   3 Match 71\n",
      "\n",
      "[-0.46020508  0.09136963  0.43481445  0.12109375 -0.17614746 -0.5205078 ] 2   0 \n",
      "[-1.1865234   0.01168823  0.25        0.6748047  -0.09985352 -0.46411133] 3   3 Match 72\n",
      "\n",
      "[-1.3496094  -0.01302338 -0.25708008  0.3659668   0.6870117   0.6743164 ] 4   3 \n",
      "[-0.49072266  0.9819336  -0.5131836  -0.2836914  -0.6098633  -0.05102539] 1   3 \n",
      "[-1.7353516  -0.21069336 -0.1003418   0.90722656  0.72802734  0.06192017] 3   4 \n",
      "[-0.7895508   0.18945312  0.18518066  0.48168945 -0.1907959  -0.6171875 ] 3   0 \n",
      "[-1.1054688   0.07470703  0.04644775  0.28564453  0.05343628 -0.05444336] 3   1 \n",
      "[-1.4482422  -0.22290039 -0.59277344  0.4716797   0.9589844   0.80566406] 4   4 Match 73\n",
      "\n",
      "[-0.16845703  0.64501953 -0.23815918 -0.4428711  -0.6020508  -0.16552734] 1   1 Match 74\n",
      "\n",
      "[-0.5361328   1.1972656  -0.36914062  0.04275513 -0.6645508  -0.26538086] 1   1 Match 75\n",
      "\n",
      "[ 0.3347168   0.14282227 -0.17504883 -0.6196289  -0.46826172 -0.30932617] 0   0 Match 76\n",
      "\n",
      "[-1.0986328   0.03463745 -0.01473999  0.36083984  0.45239258 -0.03573608] 4   2 \n",
      "[-1.6552734  -0.06210327  0.03585815  0.8022461   0.39672852 -0.03250122] 3   4 \n",
      "[-1.3271484   0.1274414   0.21948242  0.6196289   0.1763916  -0.24243164] 3   1 \n",
      "[-0.8173828   0.38891602 -0.41552734  0.00950623  0.11761475  0.26757812] 1   2 \n",
      "[-1.3203125   0.10498047  0.11279297  0.36376953  0.3046875   0.0958252 ] 3   4 \n",
      "[-1.6064453  -0.20629883 -0.6303711   0.32421875  0.97998047  1.0107422 ] 5   1 \n",
      "[-0.5751953   0.16833496  0.4189453   0.34521484 -0.48779297 -0.6098633 ] 2   1 \n",
      "[-0.9951172   0.06158447 -0.58984375  0.28051758  1.1660156   0.82128906] 4   3 \n",
      "[-1.1757812  -0.22790527 -0.72265625  0.12792969  0.8754883   0.8334961 ] 4   5 \n",
      "[-0.38549805  0.20458984  0.01295471 -0.11218262 -0.39086914 -0.20251465] 1   5 \n",
      "[-1.5244141   0.04907227  0.03384399  0.5566406   0.3857422   0.21252441] 3   4 \n",
      "[-0.67578125  0.01823425  0.37036133  0.31762695 -0.08740234 -0.49902344] 2   2 Match 77\n",
      "\n",
      "[-1.4541016   0.19104004  0.05926514  0.5126953   0.24536133  0.05499268] 3   5 \n",
      "[-1.1220703   0.09301758 -0.07049561  0.20703125  0.21862793  0.19445801] 4   3 \n",
      "[-1.5234375  -0.04650879  0.02793884  0.63720703  0.24572754  0.03979492] 3   4 \n",
      "[-1.0595703   0.22790527 -0.07897949  0.22277832  0.14233398  0.07836914] 1   1 Match 78\n",
      "\n",
      "[-1.4072266   0.05514526 -0.23034668  0.39770508  0.5620117   0.43359375] 4   3 \n",
      "[-0.25        0.29345703  0.21496582 -0.25390625 -0.4819336  -0.3046875 ] 1   1 Match 79\n",
      "\n",
      "[-1.5332031  -0.10656738  0.13085938  0.80371094  0.28051758 -0.1895752 ] 3   4 \n",
      "[-1.1259766   0.25732422  0.12927246  0.3227539  -0.13256836 -0.13671875] 3   0 \n",
      "[-1.4912109  -0.07086182  0.08148193  0.6821289   0.40771484 -0.08105469] 3   5 \n",
      "[-1.6298828  -0.24230957 -0.5209961   0.5678711   0.98291016  0.80908203] 4   5 \n",
      "[-0.22961426  0.17443848  0.04522705 -0.03536987 -0.21813965 -0.45263672] 1   3 \n",
      "[-1.7490234  -0.20092773 -0.42504883  0.60302734  1.0039062   0.7211914 ] 4   3 \n",
      "[-1.4257812  -0.08892822  0.09136963  0.7729492   0.29663086 -0.01141357] 3   3 Match 80\n",
      "\n",
      "[-0.91503906  0.52734375  0.04510498  0.39086914  0.2644043  -0.25073242] 1   4 \n",
      "[-1.7568359  -0.38793945 -0.31591797  0.7260742   0.97021484  0.4897461 ] 4   4 Match 81\n",
      "\n",
      "[-8.6816406e-01  6.1431885e-02  3.1860352e-01  4.5922852e-01\n",
      " -6.0796738e-04 -3.9404297e-01] 3   2 \n",
      "[-0.3022461   0.16333008 -0.57470703 -0.04849243  0.35620117  0.5292969 ] 5   1 \n",
      "[-1.3681641   0.3244629  -0.17016602  0.40356445  0.31933594  0.17614746] 3   1 \n",
      "[-0.7661133   0.04434204  0.16870117  0.41552734 -0.06982422 -0.29003906] 3   0 \n",
      "[-0.28173828  0.58496094 -0.29052734 -0.42163086 -0.09570312  0.16442871] 1   5 \n",
      "[-1.6591797  -0.11517334 -0.6064453   0.2980957   1.0332031   0.9584961 ] 4   3 \n",
      "[-0.89990234  0.41064453 -0.375      -0.12139893  0.00782776  0.33447266] 1   5 \n",
      "[-1.2138672   0.36645508 -0.0375061   0.1977539   0.01418304  0.03396606] 1   1 Match 82\n",
      "\n",
      "[-1.6591797  -0.02044678 -0.4333496   0.41455078  0.96435547  0.8378906 ] 4   5 \n",
      "[-1.          0.23132324  0.17602539  0.46899414 -0.06106567 -0.17822266] 3   4 \n",
      "[-1.5996094  -0.00975037 -0.28125     0.4267578   1.0712891   0.28076172] 4   3 \n",
      "[-0.82958984  0.33325195  0.28564453  0.3947754   0.04867554 -0.40161133] 3   2 \n",
      "[-0.5629883   0.12493896 -0.02445984 -0.12536621 -0.22827148 -0.00346947] 1   0 \n",
      "[-0.07342529  0.45703125 -0.12408447 -0.26782227 -0.46557617 -0.4416504 ] 1   1 Match 83\n",
      "\n",
      "[-0.4790039   0.31933594 -0.3984375  -0.25561523 -0.12286377  0.1763916 ] 1   5 \n",
      "[-1.4746094  -0.14160156 -0.20703125  0.6201172   0.60498047  0.22692871] 3   3 Match 84\n",
      "\n",
      "[-1.4609375   0.11224365  0.01994324  0.39160156  0.24401855  0.2668457 ] 3   4 \n",
      "[-0.71972656  0.30493164  0.02746582  0.1887207  -0.21313477 -0.26367188] 1   1 Match 85\n",
      "\n",
      "[-1.5224609  -0.03533936 -0.28295898  0.31445312  0.98046875  0.61328125] 4   1 \n",
      "[-1.1279297   0.39038086 -0.12091064  0.33422852  0.1763916   0.15551758] 1   3 \n",
      "[-1.6523438  -0.17810059 -0.15771484  0.640625    0.86279297  0.7167969 ] 4   4 Match 86\n",
      "\n",
      "[-0.8222656   0.37451172  0.2770996   0.39086914 -0.0871582  -0.50927734] 3   1 \n",
      "[-1.3105469  -0.01305389  0.0196991   0.59765625  0.2824707  -0.03366089] 3   3 Match 87\n",
      "\n",
      "[-0.8120117   0.3581543  -0.10925293  0.2800293   0.00589371 -0.22497559] 1   5 \n",
      "[-1.3876953  -0.01178741 -0.12609863  0.27856445  0.54541016  0.35351562] 4   2 \n",
      "[-0.63916016 -0.06695557  0.34155273  0.41577148  0.08197021 -0.41503906] 3   3 Match 88\n",
      "\n",
      "[-0.703125    0.8730469  -0.23620605  0.21533203 -0.6123047  -0.18188477] 1   3 \n",
      "[-0.38256836  0.16101074 -0.07507324 -0.19604492 -0.4375     -0.24291992] 1   2 \n",
      "[-0.3088379   0.5385742  -0.06921387 -0.15246582  0.04431152 -0.18151855] 1   3 \n",
      "[-0.64453125  0.36254883 -0.10955811  0.01441956  0.03909302 -0.06732178] 1   0 \n",
      "[-1.7519531  -0.1538086  -0.39208984  0.625       1.140625    0.61035156] 4   4 Match 89\n",
      "\n",
      "[-0.9682617   0.03985596 -0.05947876  0.53515625  0.059021   -0.16772461] 3   1 \n",
      "[-1.3544922  -0.00190639 -0.44018555  0.03887939  0.9243164   0.7441406 ] 4   3 \n",
      "[-1.3125     -0.0625      0.24987793  0.61572266  0.13464355 -0.26831055] 3   3 Match 90\n",
      "\n",
      "[-0.60595703  1.2207031  -0.48413086 -0.04452515 -0.5292969  -0.19335938] 1   5 \n",
      "[-1.203125   -0.19189453  0.02604675  0.62060547  0.45629883 -0.02474976] 3   4 \n",
      "[-1.3124943e-04  4.4970703e-01  7.2021484e-02 -6.3842773e-02\n",
      " -4.6899414e-01 -5.1806641e-01] 1   1 Match 91\n",
      "\n",
      "[-1.0917969   0.17407227 -0.09228516  0.32836914  0.12841797 -0.05725098] 3   2 \n",
      "[-1.5107422 -0.2705078 -0.5761719  0.515625   1.0664062  0.6621094] 4   4 Match 92\n",
      "\n",
      "[-1.6728516e+00 -1.8017578e-01 -1.0929108e-03  6.2988281e-01\n",
      "  7.5830078e-01  3.6840820e-01] 4   1 \n",
      "[-0.15136719  0.31054688 -0.21362305 -0.38354492 -0.28198242 -0.24206543] 1   1 Match 93\n",
      "\n",
      "[-3.0322266e-01  1.3085938e+00 -6.5966797e-01 -7.4951172e-02\n",
      " -6.0156250e-01  3.2234192e-04] 1   1 Match 94\n",
      "\n",
      "[-0.07836914  0.040802    0.11437988 -0.22692871 -0.2565918  -0.3774414 ] 2   2 Match 95\n",
      "\n",
      "[-0.9785156   0.21447754  0.05422974  0.32177734  0.3154297  -0.13110352] 3   0 \n",
      "[-0.04360962  0.16760254 -0.05563354 -0.30664062 -0.54248047 -0.34350586] 1   4 \n",
      "[-0.06848145  0.3095703   0.07275391 -0.37036133 -0.5673828  -0.3894043 ] 1   1 Match 96\n",
      "\n",
      "[-1.8330078  -0.22802734 -0.3395996   0.7011719   1.1181641   0.6274414 ] 4   4 Match 97\n",
      "\n",
      "[-0.9355469   0.31054688  0.05181885  0.25195312 -0.05270386 -0.07879639] 1   1 Match 98\n",
      "\n",
      "[-0.6503906   0.25439453 -0.07977295  0.1595459   0.12286377 -0.2265625 ] 1   0 \n",
      "[-0.6845703   0.3256836  -0.25756836 -0.00396347 -0.03033447  0.09106445] 1   1 Match 99\n",
      "\n",
      "[-1.5400391  -0.05822754 -0.7036133   0.14575195  1.0195312   1.1367188 ] 5   5 Match 100\n",
      "\n",
      "[-1.1113281   0.09161377 -0.6118164  -0.10644531  1.0927734   0.93310547] 4   4 Match 101\n",
      "\n",
      "[-1.6103516  -0.3383789  -0.44189453  0.5292969   0.9584961   0.70654297] 4   5 \n",
      "[-1.7802734  -0.32592773 -0.08306885  0.8510742   0.49194336  0.20959473] 3   1 \n",
      "[-1.8398438  -0.27661133 -0.44360352  0.55078125  1.0693359   0.828125  ] 4   3 \n",
      "[-1.6484375  -0.21459961 -0.33032227  0.49194336  0.98876953  0.5317383 ] 4   2 \n",
      "[-1.5234375  -0.14575195 -0.28930664  0.35083008  0.7114258   0.3239746 ] 4   2 \n",
      "[-0.3408203   0.47021484 -0.08013916 -0.21765137 -0.46191406 -0.16516113] 1   1 Match 102\n",
      "\n",
      "[-1.2763672   0.04641724  0.3215332   0.5600586   0.22375488 -0.20898438] 3   4 \n",
      "[-1.1308594   0.1463623  -0.43847656  0.04574585  1.0585938   0.66015625] 4   1 \n",
      "[-0.33398438  0.5961914  -0.07006836 -0.1161499  -0.4621582  -0.43579102] 1   4 \n",
      "[-1.5234375  -0.0760498  -0.4333496   0.29516602  1.0146484   0.6484375 ] 4   3 \n",
      "[-0.60546875  0.35302734 -0.09234619 -0.03945923 -0.24865723 -0.13952637] 1   3 \n",
      "[-1.7021484  -0.02197266 -0.30786133  0.6220703   0.6044922   0.38330078] 3   3 Match 103\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[-1.7119141  -0.29638672 -0.13500977  1.0126953   0.6665039   0.24938965] 3   3 Match 104\n",
      "\n",
      "[-0.46069336  0.07800293  0.35253906  0.27075195 -0.1381836  -0.47998047] 2   2 Match 105\n",
      "\n",
      "[-0.90966797  0.42456055 -0.02626038  0.26782227 -0.01687622 -0.15637207] 1   1 Match 106\n",
      "\n",
      "[-1.7958984   0.01930237  0.007164    0.55371094  0.49560547  0.3503418 ] 3   3 Match 107\n",
      "\n",
      "[-0.61376953  0.18676758 -0.22131348 -0.03433228  0.02947998  0.01580811] 1   3 \n",
      "[-0.37475586  0.01322174  0.49926758  0.28051758 -0.43139648 -0.6635742 ] 2   1 \n",
      "[-0.66845703  1.2763672  -0.5078125   0.06878662 -0.4729004  -0.08947754] 1   1 Match 108\n",
      "\n",
      "[ 0.11547852  0.40527344  0.30517578 -0.40185547 -0.57128906 -0.50341797] 1   1 Match 109\n",
      "\n",
      "[ 0.03988647  0.45092773 -0.06500244 -0.30493164 -0.53808594 -0.09490967] 1   4 \n",
      "[-1.1064453   0.08392334  0.28320312  0.6010742   0.17004395 -0.39331055] 3   3 Match 110\n",
      "\n",
      "[-1.5380859   0.03787231  0.13098145  0.63427734  0.5566406  -0.04437256] 3   3 Match 111\n",
      "\n",
      "[-0.46850586  0.79003906 -0.5048828  -0.12915039 -0.53271484 -0.15344238] 1   1 Match 112\n",
      "\n",
      "[-0.71435547  0.10144043  0.21459961  0.13745117 -0.25268555 -0.21435547] 2   4 \n",
      "[-1.6308594  -0.19885254 -0.75341797  0.40722656  1.1269531   1.0458984 ] 4   4 Match 113\n",
      "\n",
      "[-1.5712891  -0.0328064   0.1239624   0.90283203  0.5644531   0.00366402] 3   4 \n",
      "[-0.66552734  0.25805664 -0.0385437  -0.01647949 -0.28466797 -0.17919922] 1   4 \n",
      "[ 0.11126709  0.23571777  0.3935547  -0.13500977 -0.51123047 -0.62597656] 2   0 \n",
      "[-0.09875488  0.57910156 -0.02862549 -0.2685547  -0.5283203  -0.35498047] 1   1 Match 114\n",
      "\n",
      "[-1.7568359  -0.19909668 -0.17492676  0.6171875   1.1132812   0.48828125] 4   4 Match 115\n",
      "\n",
      "[-0.84033203  0.04360962 -0.13000488  0.12927246  0.03109741  0.04953003] 3   5 \n",
      "[-0.35546875  0.41479492 -0.09979248 -0.21582031 -0.5439453  -0.10150146] 1   1 Match 116\n",
      "\n",
      "[-0.98779297  0.08569336 -0.12902832  0.41577148  0.06051636  0.00220871] 3   3 Match 117\n",
      "\n",
      "[-1.1806641   0.13110352  0.22216797  0.4104004   0.23608398 -0.14819336] 3   3 Match 118\n",
      "\n",
      "[-1.4951172  -0.15771484 -0.5629883   0.3083496   1.1347656   0.8535156 ] 4   4 Match 119\n",
      "\n",
      "[-0.83154297  0.17443848  0.19104004  0.1204834  -0.08746338 -0.13537598] 2   3 \n",
      "[-0.1586914   0.18859863  0.49145508  0.01118469 -0.49438477 -0.7026367 ] 2   1 \n",
      "[ 0.09503174  0.40698242  0.18908691 -0.3166504  -0.53564453 -0.4440918 ] 1   4 \n",
      "[-1.4355469  -0.0369873  -0.55371094  0.26245117  0.93652344  0.7089844 ] 4   2 \n",
      "[-0.7451172   0.21008301  0.36523438  0.29956055  0.20812988 -0.41210938] 2   0 \n",
      "[-0.4206543   0.46679688 -0.16577148 -0.05639648 -0.44873047 -0.14257812] 1   1 Match 120\n",
      "\n",
      "[-1.7724609  -0.17614746 -0.27001953  0.8642578   0.8208008   0.29345703] 3   1 \n",
      "[-1.7304688   0.10595703 -0.27075195  0.51416016  0.8051758   0.5410156 ] 4   5 \n",
      "[-1.8066406   0.07305908 -0.37304688  0.5390625   0.8305664   0.68408203] 4   4 Match 121\n",
      "\n",
      "[-0.9482422   0.19836426 -0.67333984 -0.13330078  0.61279297  0.84814453] 5   4 \n",
      "[-0.12878418  0.2939453   0.29614258 -0.24182129 -0.4267578  -0.3696289 ] 2   0 \n",
      "[-1.1904297   0.09442139 -0.35205078  0.30297852  0.7338867   0.33691406] 4   5 \n",
      "[-1.7861328  -0.22583008 -0.52783203  0.50878906  1.1855469   0.94189453] 4   5 \n",
      "[-0.8652344   0.2709961  -0.34887695  0.17272949  0.2919922   0.24768066] 4   1 \n",
      "[-0.49169922  0.32617188  0.11553955  0.0473938  -0.17980957 -0.38256836] 1   3 \n",
      "[-1.5097656  -0.22216797 -0.1427002   0.4711914   0.8105469   0.53564453] 4   3 \n",
      "[-1.5166016   0.11413574 -0.33203125  0.2775879   0.3762207   0.6411133 ] 5   1 \n",
      "[-1.6142578  -0.04562378 -0.01525116  0.8540039   0.703125    0.17126465] 3   3 Match 122\n",
      "\n",
      "[-1.5537109  -0.16564941 -0.11987305  0.57177734  0.7114258   0.2915039 ] 4   4 Match 123\n",
      "\n",
      "[-1.9462891  -0.31079102 -0.19042969  0.7573242   0.9633789   0.5263672 ] 4   3 \n",
      "[-0.5996094   0.4621582   0.05621338  0.04800415 -0.47485352 -0.29345703] 1   5 \n",
      "[-1.1298828   0.07244873  0.14929199  0.36328125  0.28076172  0.05895996] 3   1 \n",
      "[-1.4140625  -0.05722046  0.06896973  0.61865234  0.3935547  -0.09887695] 3   2 \n",
      "[-1.1142578   0.20776367  0.00295067  0.7265625   0.25146484 -0.25024414] 3   4 \n",
      "[-0.98583984  0.14562988  0.48779297  0.5839844   0.24072266 -0.5209961 ] 3   3 Match 124\n",
      "\n",
      "[-1.6572266  -0.40649414 -0.16174316  0.90771484  0.8100586   0.26757812] 3   2 \n",
      "[-1.4648438   0.06921387  0.17810059  0.8198242   0.2783203  -0.15002441] 3   4 \n",
      "[-1.5224609  -0.14331055  0.03146362  0.74658203  0.43530273  0.05783081] 3   3 Match 125\n",
      "\n",
      "[-0.22106934  0.22009277  0.10516357 -0.2619629  -0.40356445 -0.24511719] 1   4 \n",
      "[-1.6640625  -0.06439209 -0.30029297  0.39282227  0.6928711   0.4765625 ] 4   0 \n",
      "[-1.8554688  -0.2121582  -0.1628418   0.7890625   0.7910156   0.39331055] 4   5 \n",
      "[-1.4736328  -0.05325317  0.14746094  0.86376953  0.40014648 -0.27734375] 3   5 \n",
      "[-0.35107422  0.20617676  0.45703125  0.02798462 -0.17712402 -0.6489258 ] 2   2 Match 126\n",
      "\n",
      "[-1.4462891   0.0484314   0.18066406  0.58935547  0.32226562 -0.23583984] 3   1 \n",
      "[-1.7636719   0.14367676 -0.27514648  0.6972656   0.7314453   0.42529297] 4   4 Match 127\n",
      "\n",
      "[-0.38745117  0.0015831   0.3503418   0.05511475 -0.02922058 -0.3828125 ] 2   2 Match 128\n",
      "\n",
      "[-1.2646484   0.02885437  0.36572266  0.8540039   0.33081055 -0.60009766] 3   3 Match 129\n",
      "\n",
      "[-0.48706055  0.00085831  0.35888672  0.28198242  0.07507324 -0.50390625] 2   2 Match 130\n",
      "\n",
      "[-0.6816406   0.32470703  0.14660645  0.34887695 -0.07635498 -0.46484375] 3   1 \n",
      "[-1.0869141   0.13183594  0.00774765  0.5449219   0.27319336 -0.15881348] 3   5 \n",
      "[-0.3017578   0.0227356   0.48779297  0.13366699 -0.5371094  -0.5263672 ] 2   1 \n",
      "[ 0.00775528  0.15063477  0.17578125 -0.36035156 -0.2631836  -0.3005371 ] 2   1 \n",
      "[-1.8339844  -0.3071289  -0.02012634  0.96484375  0.7026367   0.26464844] 3   3 Match 131\n",
      "\n",
      "[-1.3945312  -0.06585693  0.26220703  0.890625    0.42871094 -0.453125  ] 3   3 Match 132\n",
      "\n",
      "[-1.5361328  -0.23803711  0.08953857  0.7885742   0.515625    0.03359985] 3   4 \n",
      "[-1.8066406  -0.27490234 -0.20178223  0.93066406  0.7631836   0.17993164] 3   4 \n",
      "[-0.8964844   0.16516113  0.34375     0.44848633  0.04107666 -0.41577148] 3   5 \n",
      "[-1.8310547  -0.2446289  -0.1385498   0.93310547  0.7988281   0.30859375] 3   3 Match 133\n",
      "\n",
      "[-1.8359375  -0.32421875 -0.15966797  0.9086914   0.75634766  0.23620605] 3   1 \n",
      "[-1.0058594   0.02532959  0.47216797  0.59277344  0.07348633 -0.55810547] 3   1 \n",
      "[-1.4599609  -0.05654907 -0.01802063  0.7319336   0.37329102  0.14550781] 3   5 \n",
      "[-0.98583984  0.04995728  0.41503906  0.6645508  -0.10656738 -0.4892578 ] 3   2 \n",
      "[-1.4941406  -0.17932129 -0.66503906  0.22497559  1.0214844   1.0898438 ] 5   3 \n",
      "[-1.421875   -0.08001709  0.05560303  0.72314453  0.52490234 -0.11865234] 3   4 \n",
      "[-1.4169922   0.04586792 -0.02862549  0.61083984  0.6699219   0.15917969] 4   1 \n",
      "[-0.3852539   0.30444336  0.35961914  0.24157715 -0.3251953  -0.6357422 ] 2   3 \n",
      "[-1.0322266   0.27783203  0.10870361  0.36254883  0.29248047 -0.2758789 ] 3   1 \n",
      "[-0.40649414  0.5605469  -0.10327148 -0.3371582  -0.4248047  -0.08502197] 1   3 \n",
      "[-0.6328125  -0.02224731  0.25952148  0.3256836  -0.08807373 -0.46728516] 3   1 \n",
      "[-0.5986328   0.30541992 -0.25585938 -0.13330078 -0.13830566  0.04858398] 1   3 \n",
      "[-0.16308594  0.07928467  0.42382812 -0.04925537 -0.3154297  -0.57373047] 2   2 Match 134\n",
      "\n",
      "[-1.5390625  -0.1854248  -0.13745117  0.76660156  0.57958984  0.02328491] 3   5 \n",
      "[-0.48657227  0.3581543  -0.43725586 -0.36523438 -0.16821289  0.25073242] 1   1 Match 135\n",
      "\n",
      "[-1.5253906  -0.09918213 -0.5029297   0.3408203   1.1240234   0.9033203 ] 4   3 \n",
      "[-1.0966797   0.1307373   0.15490723  0.4152832   0.04818726 -0.31518555] 3   3 Match 136\n",
      "\n",
      "[-0.29589844  0.2454834   0.23132324  0.00410461 -0.31274414 -0.43115234] 1   3 \n",
      "[-0.44091797  0.04159546  0.21118164 -0.05987549 -0.28173828 -0.31274414] 2   3 \n",
      "[-1.1064453  -0.06030273  0.25341797  0.6816406   0.03433228 -0.47314453] 3   4 \n",
      "[-0.8598633   0.21362305  0.43847656  0.5385742   0.02345276 -0.57177734] 3   3 Match 137\n",
      "\n",
      "[-1.5576172  -0.13146973  0.1743164   0.8959961   0.28222656 -0.1986084 ] 3   3 Match 138\n",
      "\n",
      "[-0.734375    0.32763672  0.31567383  0.2890625  -0.10217285 -0.5288086 ] 1   5 \n",
      "[-1.4599609  -0.01361084 -0.14404297  0.6816406   0.5541992   0.13879395] 3   4 \n",
      "[-1.6035156  -0.1854248  -0.25634766  0.5649414   0.8754883   0.48339844] 4   5 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.90527344  0.27148438 -0.21191406 -0.07110596 -0.2861328   0.16174316] 1   1 Match 139\n",
      "\n",
      "[-0.2788086   0.16699219  0.5004883   0.12890625 -0.64990234 -0.67871094] 2   2 Match 140\n",
      "\n",
      "[-0.97998047  0.12817383  0.15344238  0.23901367 -0.02760315 -0.03744507] 3   4 \n",
      "[-1.453125    0.07666016  0.17199707  0.48779297  0.48876953  0.0435791 ] 4   2 \n",
      "[ 0.2644043   0.24389648 -0.04724121 -0.45361328 -0.6464844  -0.36206055] 0   2 \n",
      "[-0.50683594  0.35083008 -0.23486328 -0.3203125  -0.49291992  0.03988647] 1   3 \n",
      "[-1.3574219   0.21020508 -0.35888672  0.2932129   0.3798828   0.5151367 ] 5   5 Match 141\n",
      "\n",
      "[-0.19396973  0.36816406  0.10253906 -0.08282471 -0.3330078  -0.3359375 ] 1   2 \n",
      "[-1.2021484   0.09417725  0.08093262  0.5053711   0.5761719  -0.06976318] 4   0 \n",
      "[-1.8242188  -0.15197754 -0.41992188  0.59277344  0.93359375  0.6738281 ] 4   4 Match 142\n",
      "\n",
      "[-1.2460938   0.24560547  0.1463623   0.7524414   0.12988281 -0.46313477] 3   1 \n",
      "[-0.04174805  0.4182129   0.36523438 -0.24829102 -0.6142578  -0.67871094] 1   1 Match 143\n",
      "\n",
      "[ 0.2939453   0.4489746  -0.10162354 -0.5053711  -0.8027344  -0.4814453 ] 1   0 \n",
      "[-1.2724609  -0.07763672  0.19250488  0.8066406   0.1817627  -0.16455078] 3   3 Match 144\n",
      "\n",
      "[-1.2089844   0.04550171 -0.5629883   0.00585175  0.71972656  0.86035156] 5   4 \n",
      "[-0.71533203  0.20288086  0.4260254   0.3100586   0.01354218 -0.52783203] 2   0 \n",
      "[-1.6982422  -0.16247559 -0.51708984  0.46362305  0.9946289   0.8105469 ] 4   4 Match 145\n",
      "\n",
      "[ 0.19958496  0.6113281  -0.23144531 -0.5595703  -0.8027344  -0.40185547] 1   3 \n",
      "[-1.5019531  -0.13220215 -0.00869751  0.65527344  0.57958984 -0.03909302] 3   5 \n",
      "[-0.08380127  0.32348633  0.25146484  0.01649475 -0.609375   -0.69970703] 1   1 Match 146\n",
      "\n",
      "[-0.6196289   0.29077148  0.43164062  0.2631836  -0.33154297 -0.57128906] 2   3 \n",
      "[-1.5732422  -0.02624512 -0.20446777  0.48828125  0.87158203  0.4321289 ] 4   5 \n",
      "[-0.94677734  0.18322754  0.20800781  0.38476562  0.22314453 -0.18884277] 3   3 Match 147\n",
      "\n",
      "[-0.08178711  0.5102539   0.07965088 -0.3010254  -0.7963867  -0.58984375] 1   1 Match 148\n",
      "\n",
      "[-1.8173828  -0.20361328 -0.27929688  0.63427734  1.1162109   0.5488281 ] 4   4 Match 149\n",
      "\n",
      "[-0.7553711   0.0612793  -0.65722656 -0.06045532  0.64990234  0.8876953 ] 5   3 \n",
      "[-1.5380859  -0.17736816 -0.09765625  0.6074219   0.6508789   0.20251465] 4   3 \n",
      "[-1.3808594   0.08026123  0.04632568  0.6220703   0.3630371  -0.05264282] 3   3 Match 150\n",
      "\n",
      "[-1.5332031  -0.27026367 -0.55322266  0.37670898  1.0966797   0.97558594] 4   5 \n",
      "[-0.12573242  0.36523438  0.25805664 -0.10693359 -0.6542969  -0.5756836 ] 1   1 Match 151\n",
      "\n",
      "[-0.9321289   0.16210938  0.12322998  0.5175781   0.25390625 -0.22387695] 3   1 \n",
      "[-1.2441406  -0.01618958 -0.22045898  0.14697266  0.36401367  0.5131836 ] 5   4 \n",
      "[-1.609375   -0.20922852 -0.29907227  0.5385742   1.0371094   0.5756836 ] 4   5 \n",
      "[-0.7553711   0.19177246  0.19628906  0.46826172  0.13745117 -0.34448242] 3   3 Match 152\n",
      "\n",
      "[-1.3525391  -0.04223633  0.06976318  0.73535156  0.3725586  -0.1763916 ] 3   5 \n",
      "[ 0.45996094  0.43823242 -0.01548004 -0.7163086  -0.6176758  -0.3034668 ] 0   1 \n",
      "[-1.6728516  -0.25073242 -0.46728516  0.4699707   1.0908203   0.9511719 ] 4   5 \n",
      "[-1.2919922  -0.05648804 -0.01608276  0.7163086   0.03778076 -0.21655273] 3   1 \n",
      "[-0.2290039   0.19824219  0.22790527  0.3203125  -0.38330078 -0.72021484] 3   3 Match 153\n",
      "\n",
      "[-0.7265625   0.26538086  0.33154297  0.2980957   0.11114502 -0.54785156] 2   5 \n",
      "[-1.8320312  -0.13684082 -0.28222656  0.66259766  1.0507812   0.63134766] 4   4 Match 154\n",
      "\n",
      "[-0.3383789   0.14953613  0.13061523 -0.14526367 -0.33276367 -0.24438477] 1   1 Match 155\n",
      "\n",
      "[-0.9555664   0.359375   -0.41015625 -0.00901794  0.4074707   0.5605469 ] 5   5 Match 156\n",
      "\n",
      "[-1.1953125   0.19567871 -0.6557617  -0.02140808  0.6699219   0.9194336 ] 5   2 \n",
      "[ 0.06292725  0.3413086   0.12322998 -0.44091797 -0.58691406 -0.3815918 ] 1   3 \n",
      "[-1.6035156  -0.35375977 -0.07537842  0.85595703  0.5258789   0.1472168 ] 3   3 Match 157\n",
      "\n",
      "[-1.8056641  -0.18151855 -0.4567871   0.54833984  1.0703125   0.8017578 ] 4   5 \n",
      "[-1.3115234   0.04483032 -0.07086182  0.5839844   0.5883789   0.0574646 ] 4   5 \n",
      "[ 0.21362305  0.49951172  0.10595703 -0.31445312 -0.7446289  -0.5566406 ] 1   2 \n",
      "[-3.1423569e-04  4.1723633e-01  5.8898926e-02 -4.5019531e-01\n",
      " -6.8652344e-01 -3.9770508e-01] 1   0 \n",
      "[-0.6533203   0.09051514 -0.29760742 -0.03900146  0.3112793   0.1295166 ] 4   1 \n",
      "[ 0.09539795  0.55322266  0.10388184 -0.2932129  -0.6333008  -0.65234375] 1   1 Match 158\n",
      "\n",
      "[-1.7783203   0.00515747 -0.0814209   0.75390625  0.57714844  0.03945923] 3   3 Match 159\n",
      "\n",
      "[-1.4042969   0.11993408 -0.41723633  0.27807617  0.5073242   0.5761719 ] 5   1 \n",
      "[-1.0888672   0.10955811 -0.40283203  0.00624084  0.82128906  0.65771484] 4   0 \n",
      "[-0.39208984  0.6459961  -0.15466309 -0.26586914 -0.24084473 -0.29125977] 1   2 \n",
      "[-0.8696289  -0.01763916 -0.5786133  -0.12133789  0.28466797  0.75      ] 5   5 Match 160\n",
      "\n",
      "[-1.2285156   0.03564453 -0.21606445  0.37182617  0.35839844  0.3725586 ] 5   3 \n",
      "[-1.7148438  -0.22802734 -0.42285156  0.6118164   0.8671875   0.73046875] 4   5 \n",
      "[-1.4755859  -0.2746582  -0.06982422  0.7631836   0.69873047  0.13891602] 3   3 Match 161\n",
      "\n",
      "[-0.3256836  -0.07757568  0.16418457 -0.09210205 -0.32250977 -0.2866211 ] 2   2 Match 162\n",
      "\n",
      "[-0.97314453  0.18701172 -0.08221436  0.10394287  0.05340576 -0.04943848] 1   1 Match 163\n",
      "\n",
      "[-1.0917969   0.03186035 -0.13378906  0.4482422   0.23339844 -0.03092957] 3   3 Match 164\n",
      "\n",
      "[-0.17102051  0.5996094   0.13916016 -0.22790527 -0.6533203  -0.5024414 ] 1   0 \n",
      "[-1.2011719   0.3479004   0.10894775  0.32885742  0.40600586 -0.15368652] 4   5 \n",
      "[-1.7675781  -0.22644043 -0.40039062  0.5600586   1.1669922   0.74902344] 4   4 Match 165\n",
      "\n",
      "[-0.9506836   0.19970703  0.35424805  0.36694336  0.23754883 -0.33007812] 3   2 \n",
      "[ 0.05535889  0.14855957 -0.02947998 -0.5541992  -0.6274414  -0.32666016] 1   1 Match 166\n",
      "\n",
      "[-0.24572754  0.29370117  0.23828125 -0.04040527 -0.28564453 -0.36547852] 1   3 \n",
      "[-1.1474609   0.08349609  0.28833008  0.7260742   0.26611328 -0.53222656] 3   1 \n",
      "[ 0.01531982  0.4633789   0.08496094 -0.30419922 -0.6621094  -0.6435547 ] 1   1 Match 167\n",
      "\n",
      "[ 0.04678345  0.39526367 -0.34887695 -0.57714844 -0.6430664   0.01779175] 1   2 \n",
      "[-0.8256836   0.17028809  0.22229004  0.23413086  0.10736084 -0.23352051] 3   3 Match 168\n",
      "\n",
      "[-0.86572266  0.32495117  0.29345703  0.4934082   0.11572266 -0.56591797] 3   3 Match 169\n",
      "\n",
      "[-0.32958984  0.05670166  0.42626953  0.12420654 -0.50390625 -0.68359375] 2   2 Match 170\n",
      "\n",
      "[-1.4335938  -0.0914917  -0.23010254  0.22473145  0.78466797  0.36669922] 4   2 \n",
      "[ 0.03231812  0.49926758  0.03216553 -0.41918945 -0.66259766 -0.36376953] 1   1 Match 171\n",
      "\n",
      "[-0.03930664  0.8330078  -0.3642578  -0.38793945 -0.8642578  -0.3569336 ] 1   5 \n",
      "[-1.7255859  -0.16748047 -0.26416016  0.54785156  0.84277344  0.51708984] 4   5 \n",
      "[-1.6894531  -0.01622009 -0.09399414  0.70410156  0.67529297  0.171875  ] 3   1 \n",
      "[-0.8491211   0.15759277 -0.23388672  0.13989258  0.24633789  0.2841797 ] 5   1 \n",
      "[-0.45361328  0.04684448  0.3852539   0.27075195 -0.23803711 -0.57666016] 2   0 \n",
      "[-1.7441406  -0.05859375 -0.43530273  0.5390625   0.9760742   0.8144531 ] 4   1 \n",
      "[-1.3330078  -0.05804443 -0.14855957  0.27661133  0.76708984  0.5517578 ] 4   3 \n",
      "[-1.7822266  -0.01128387 -0.01315308  0.8378906   0.7680664   0.13061523] 3   4 \n",
      "[-0.98779297  0.17626953 -0.13903809  0.36279297  0.05627441  0.11895752] 3   1 \n",
      "[-1.4375      0.0958252   0.12329102  0.4375      0.19567871  0.05969238] 3   3 Match 172\n",
      "\n",
      "[-0.7529297   0.03598022 -0.07702637  0.16809082 -0.03025818  0.08752441] 3   5 \n",
      "[-1.9453125  -0.2446289  -0.2442627   0.8691406   0.8574219   0.43164062] 3   3 Match 173\n",
      "\n",
      "[-1.1425781   0.17919922 -0.56347656  0.19702148  0.7294922   0.74658203] 5   3 \n",
      "[ 0.39501953  0.3347168   0.02326965 -0.5800781  -0.5366211  -0.36523438] 0   0 Match 174\n",
      "\n",
      "[-0.35253906  0.47851562 -0.62353516 -0.546875   -0.07757568  0.4423828 ] 1   1 Match 175\n",
      "\n",
      "[-1.8369141  -0.20324707 -0.38110352  0.74121094  1.1308594   0.57714844] 4   2 \n",
      "[-1.6582031  -0.30371094 -0.11358643  0.6611328   0.6386719   0.25756836] 3   2 \n",
      "[-0.52490234  0.71240234 -0.39624023 -0.4519043  -0.18395996  0.33691406] 1   4 \n",
      "[ 0.15148926  0.22717285 -0.03057861 -0.35302734 -0.6904297  -0.45874023] 1   3 \n",
      "[-1.6865234  -0.17944336 -0.29370117  0.59814453  1.0849609   0.65966797] 4   4 Match 176\n",
      "\n",
      "[ 0.0770874   0.33447266  0.24438477 -0.08526611 -0.5571289  -0.67285156] 1   2 \n",
      "[-0.25952148  0.12298584  0.24035645 -0.01579285 -0.14770508 -0.42773438] 2   2 Match 177\n",
      "\n",
      "[-1.8066406  -0.20739746 -0.23901367  0.7651367   0.8300781   0.4169922 ] 4   1 \n",
      "[-0.17553711  0.32763672 -0.02667236 -0.22912598 -0.46728516 -0.2697754 ] 1   0 \n",
      "[-0.6503906   0.30932617  0.28100586  0.13696289 -0.07202148 -0.21740723] 1   1 Match 178\n",
      "\n",
      "[-1.1982422  -0.05493164 -0.52197266  0.08331299  0.5957031   0.78222656] 5   1 \n",
      "[-0.921875    0.04312134  0.42993164  0.5913086  -0.1986084  -0.65234375] 3   2 \n",
      "[-1.0117188   0.4951172  -0.2998047   0.02560425  0.27124023  0.28564453] 1   5 \n",
      "[-1.6132812  -0.20617676 -0.31274414  0.60058594  0.86816406  0.62353516] 4   3 \n",
      "[-1.6044922  -0.30664062 -0.45263672  0.6323242   1.0097656   0.57177734] 4   2 \n",
      "[-1.5605469  -0.0308075   0.08843994  0.68408203  0.6801758   0.04473877] 3   2 \n",
      "[ 0.23156738  0.38671875 -0.11999512 -0.5058594  -0.7783203  -0.47875977] 1   0 \n",
      "[-1.6767578  -0.15673828 -0.5151367   0.43188477  1.0332031   1.0234375 ] 4   3 \n",
      "[-0.77490234  0.45214844 -0.00805664  0.265625   -0.328125   -0.22033691] 1   2 \n",
      "[ 0.3173828   0.26171875  0.07244873 -0.36108398 -0.41577148 -0.30444336] 0   3 \n",
      "[-0.96875     0.22619629  0.17932129  0.49658203 -0.06872559 -0.3479004 ] 3   0 \n",
      "[-0.7998047   0.18603516  0.03759766  0.11920166 -0.08447266 -0.31201172] 1   1 Match 179\n",
      "\n",
      "[-0.42382812  0.16796875  0.47705078  0.29492188 -0.5209961  -0.63427734] 2   4 \n",
      "[-1.1552734   0.0645752  -0.04425049  0.5395508   0.42382812 -0.12878418] 3   3 Match 180\n",
      "\n",
      "[-1.8671875   0.00376129 -0.31225586  0.6538086   0.9511719   0.6542969 ] 4   1 \n",
      "[-0.51708984  0.013237    0.41601562  0.47338867 -0.20739746 -0.58447266] 3   2 \n",
      "[-1.4931641  -0.05679321 -0.05215454  0.61083984  0.49072266  0.2322998 ] 3   5 \n",
      "[-0.5473633   0.1385498   0.47802734  0.45166016 -0.18481445 -0.7104492 ] 2   2 Match 181\n",
      "\n",
      "[-0.7363281   0.4946289   0.01751709 -0.13793945 -0.04360962  0.04003906] 1   4 \n",
      "[-1.1337891  -0.14013672  0.3918457   0.6801758   0.21728516 -0.46972656] 3   3 Match 182\n",
      "\n",
      "[-0.6254883   0.32983398 -0.36132812 -0.13781738 -0.15979004 -0.00077343] 1   3 \n",
      "[-1.4033203  -0.01637268  0.23376465  0.69433594  0.16333008 -0.16113281] 3   1 \n",
      "[ 0.16088867  0.23657227  0.15893555 -0.12878418 -0.3684082  -0.43652344] 1   3 \n",
      "[-0.03109741  0.47753906  0.15393066 -0.1977539  -0.70703125 -0.6245117 ] 1   3 \n",
      "[-1.4306641  -0.23803711 -0.48754883  0.4428711   0.96191406  0.6767578 ] 4   4 Match 183\n",
      "\n",
      "[-0.51464844  0.39990234  0.1821289   0.08404541 -0.1459961  -0.4482422 ] 1   1 Match 184\n",
      "\n",
      "[-1.1884766   0.13745117  0.43017578  0.7084961   0.22058105 -0.5908203 ] 3   5 \n",
      "[-0.9848633   0.16259766  0.33984375  0.56933594  0.29663086 -0.40600586] 3   3 Match 185\n",
      "\n",
      "[ 0.10083008  0.3322754   0.11828613 -0.38330078 -0.6801758  -0.4584961 ] 1   1 Match 186\n",
      "\n",
      "[-1.0039062  -0.10388184  0.30493164  0.57128906 -0.10046387 -0.4128418 ] 3   4 \n",
      "[-1.171875    0.25878906  0.02645874  0.25024414  0.21716309  0.15661621] 1   5 \n",
      "[-1.6259766   0.05877686 -0.4013672   0.44677734  0.9038086   0.6513672 ] 4   5 \n",
      "[-1.1865234   0.04968262  0.30029297  0.5463867   0.41748047 -0.24133301] 3   3 Match 187\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.7773438  -0.32885742 -0.32739258  0.7290039   0.94628906  0.5854492 ] 4   3 \n",
      "[-0.22912598  0.21557617  0.11047363 -0.07623291 -0.3083496  -0.36523438] 1   3 \n",
      "[-1.6113281  -0.13623047  0.02963257  0.86083984  0.4399414  -0.07849121] 3   2 \n",
      "[-1.7304688  -0.14050293 -0.3725586   0.65234375  0.98535156  0.5698242 ] 4   4 Match 188\n",
      "\n",
      "[-0.7675781   0.01719666  0.19482422  0.2783203  -0.12597656 -0.29174805] 3   5 \n",
      "[-0.8046875   0.16442871  0.14855957  0.32104492 -0.20617676 -0.21264648] 3   1 \n",
      "[-1.3173828   0.12237549 -0.33129883  0.3400879   0.35351562  0.39038086] 5   2 \n",
      "[-0.34936523  0.2541504   0.30029297  0.1796875  -0.3527832  -0.4741211 ] 2   4 \n",
      "[-0.7661133   0.09881592  0.27441406  0.42138672 -0.12438965 -0.42773438] 3   3 Match 189\n",
      "\n",
      "[-1.6259766   0.14196777 -0.5004883   0.21728516  0.7792969   0.9511719 ] 5   5 Match 190\n",
      "\n",
      "[-1.1005859   0.13012695 -0.40844727  0.18066406  0.3137207   0.19909668] 4   0 \n",
      "[-0.3088379   0.26733398  0.27685547 -0.07397461 -0.25146484 -0.40478516] 2   0 \n",
      "[-1.2353516   0.03652954  0.40161133  0.56884766  0.16955566 -0.31274414] 3   1 \n",
      "[-0.50146484  0.32592773  0.33154297  0.16027832 -0.22717285 -0.55126953] 2   1 \n",
      "[-0.47314453  0.30664062  0.28295898  0.2166748  -0.29345703 -0.5385742 ] 1   4 \n",
      "[-1.2167969   0.01904297 -0.77197266  0.17700195  0.74609375  1.1064453 ] 5   5 Match 191\n",
      "\n",
      "[-1.5273438   0.18322754 -0.09661865  0.59277344  0.74560547  0.2980957 ] 4   0 \n",
      "[-0.40185547  0.25952148  0.29125977 -0.03015137 -0.26293945 -0.18725586] 2   4 \n",
      "[-0.3635254   0.28564453  0.30517578  0.23388672 -0.28198242 -0.515625  ] 2   2 Match 192\n",
      "\n",
      "[-0.74609375 -0.08605957  0.2956543   0.5986328   0.01114655 -0.52246094] 3   4 \n",
      "[-1.1435547  -0.06976318  0.36108398  0.79589844  0.05001831 -0.55322266] 3   2 \n",
      "[-0.72265625  0.17919922  0.46484375  0.33520508  0.04177856 -0.49780273] 2   2 Match 193\n",
      "\n",
      "[-1.7333984  -0.11877441 -0.03961182  0.7675781   0.48095703  0.13867188] 3   2 \n",
      "[-0.38354492  0.26123047  0.11694336  0.03186035 -0.31469727 -0.43798828] 1   0 \n",
      "[-0.60546875  0.27270508  0.2866211   0.3149414  -0.26098633 -0.5253906 ] 3   2 \n",
      "[-0.30151367  0.24389648 -0.35253906 -0.30297852 -0.23046875 -0.01994324] 1   2 \n",
      "[-1.1826172  -0.04946899  0.32470703  0.6796875   0.03256226 -0.48486328] 3   1 \n",
      "[-1.1015625   0.24243164 -0.21826172  0.02729797  0.27270508  0.39331055] 5   4 \n",
      "[-0.7558594   0.2709961   0.1862793   0.26879883 -0.15124512 -0.35888672] 1   2 \n",
      "[-1.1015625  -0.06604004  0.0491333   0.46777344  0.26171875 -0.11651611] 3   3 Match 194\n",
      "\n",
      "[ 0.02790833  0.45361328 -0.10839844 -0.43725586 -0.515625   -0.36669922] 1   3 \n",
      "[-1.8847656  -0.30541992 -0.2939453   0.7626953   1.0146484   0.51904297] 4   4 Match 195\n",
      "\n",
      "[-1.6669922  -0.0435791   0.07904053  0.75683594  0.36572266 -0.02536011] 3   2 \n",
      "[-1.0175781  -0.02288818  0.5102539   0.8027344   0.22619629 -0.66064453] 3   2 \n",
      "[-1.7109375  -0.00269699 -0.46142578  0.45922852  0.85302734  0.7529297 ] 4   3 \n",
      "[-0.40966797  0.2298584   0.32788086  0.04727173 -0.3840332  -0.5102539 ] 2   2 Match 196\n",
      "\n",
      "[-1.1708984   0.02209473 -0.0201416   0.45214844  0.48876953  0.05249023] 4   4 Match 197\n",
      "\n",
      "[-0.41430664  0.11132812  0.37353516  0.34643555 -0.36791992 -0.7441406 ] 2   3 \n",
      "[-0.6015625   0.5214844   0.1270752   0.02441406 -0.3803711  -0.35888672] 1   1 Match 198\n",
      "\n",
      "[-1.7246094  -0.17224121 -0.29858398  0.7080078   1.0400391   0.36645508] 4   5 \n",
      "[ 0.00767136  0.0838623   0.06463623 -0.4333496  -0.58154297 -0.10992432] 1   3 \n",
      "[-1.2285156  -0.10302734 -0.23181152  0.36376953  0.57373047  0.421875  ] 4   4 Match 199\n",
      "\n",
      "[-1.484375    0.23291016 -0.12371826  0.50390625  0.57177734  0.24890137] 4   5 \n",
      "[-0.14916992  0.5620117   0.00643158 -0.2836914  -0.43798828 -0.22363281] 1   2 \n",
      "[-1.2333984  -0.05349731  0.28857422  0.7084961   0.2800293  -0.2705078 ] 3   3 Match 200\n",
      "\n",
      "[-1.0966797   0.16015625  0.10681152  0.41992188  0.265625   -0.15405273] 3   5 \n",
      "[-0.96777344 -0.03314209  0.18127441  0.59521484 -0.2019043  -0.38305664] 3   2 \n",
      "[-1.6240234  -0.27416992 -0.10882568  0.69091797  0.71435547  0.2783203 ] 4   5 \n",
      "[-1.8730469  -0.11053467 -0.4868164   0.5649414   1.0214844   0.83447266] 4   4 Match 201\n",
      "\n",
      "[-1.3574219   0.0402832  -0.24353027  0.26586914  0.7524414   0.54345703] 4   2 \n",
      "[-1.7382812  -0.06481934 -0.25830078  0.5371094   0.9824219   0.45776367] 4   3 \n",
      "[-0.6489258   0.10693359  0.01035309  0.09838867 -0.11138916 -0.11920166] 1   0 \n",
      "[-1.4863281  -0.046875   -0.33325195  0.57421875  0.8623047   0.41381836] 4   2 \n",
      "[-1.5644531  -0.23034668 -0.45263672  0.5776367   0.9145508   0.7265625 ] 4   5 \n",
      "[-1.4365234   0.08660889 -0.57373047  0.23388672  0.7558594   0.85546875] 5   5 Match 202\n",
      "\n",
      "[-1.5849609e+00 -3.1709671e-04 -4.3994141e-01  4.6997070e-01\n",
      "  7.2656250e-01  4.9169922e-01] 4   3 \n",
      "[-0.5830078   0.38427734  0.07305908  0.01033783  0.04284668 -0.171875  ] 1   2 \n",
      "[-0.8105469   0.31054688  0.10266113  0.38598633  0.15319824 -0.25170898] 3   4 \n",
      "[-1.5214844   0.1015625  -0.11437988  0.60595703  0.41235352  0.26586914] 3   1 \n",
      "[-0.9658203   0.13085938 -0.52246094  0.01354218  0.83691406  0.9345703 ] 5   4 \n",
      "[-1.7792969  -0.16564941 -0.22021484  0.51171875  0.68359375  0.42382812] 4   3 \n",
      "[-1.8798828  -0.2397461  -0.13110352  0.96435547  0.77246094  0.29541016] 3   3 Match 203\n",
      "\n",
      "[-1.7929688   0.05627441 -0.2548828   0.65771484  0.8256836   0.37353516] 4   1 \n",
      "[-1.6650391  -0.08856201 -0.48461914  0.25927734  1.1992188   0.95947266] 4   4 Match 204\n",
      "\n",
      "[-1.34375    -0.02148438 -0.08081055  0.5366211   0.65966797 -0.00917816] 4   5 \n",
      "[-0.6479492   0.61621094 -0.18005371 -0.11767578 -0.26293945 -0.21044922] 1   2 \n",
      "[-0.5834961   0.15209961  0.4555664   0.4729004  -0.08380127 -0.6875    ] 3   0 \n",
      "[ 0.00875092  0.29785156  0.05886841 -0.3701172  -0.44848633 -0.37768555] 1   1 Match 205\n",
      "\n",
      "[-1.5537109  -0.28076172 -0.265625    0.5024414   0.6308594   0.42919922] 4   3 \n",
      "[-1.4199219   0.02987671 -0.2607422   0.6435547   0.8540039   0.38110352] 4   3 \n",
      "[-1.3896484e+00 -1.3427734e-03 -1.9604492e-01  4.6850586e-01\n",
      "  7.3730469e-01  4.1015625e-01] 4   2 \n",
      "[-1.5888672   0.11791992 -0.02461243  0.5366211   0.75        0.12420654] 4   5 \n",
      "[-1.1845703   0.20947266  0.06390381  0.35473633  0.25219727 -0.05163574] 3   2 \n",
      "[-1.3710938  -0.2668457  -0.34033203  0.30566406  1.1308594   0.58935547] 4   5 \n",
      "[-0.15930176  0.41015625  0.06427002 -0.2536621  -0.68652344 -0.5390625 ] 1   3 \n",
      "[-1.6025391e+00 -1.2707520e-01 -1.2521744e-03  6.8505859e-01\n",
      "  8.7597656e-01  2.0617676e-01] 4   4 Match 206\n",
      "\n",
      "[-1.6845703  -0.1282959  -0.3400879   0.5786133   0.66064453  0.47021484] 4   2 \n",
      "[-1.3525391   0.04223633 -0.20690918  0.3400879   0.70947266  0.5307617 ] 4   4 Match 207\n",
      "\n",
      "[-0.42822266  0.35009766 -0.1307373  -0.12878418 -0.17443848 -0.2109375 ] 1   2 \n",
      "[-1.1855469   0.15759277  0.23864746  0.45898438  0.11193848 -0.19897461] 3   4 \n",
      "[-1.5214844   0.11663818 -0.1784668   0.44311523  0.4807129   0.24121094] 4   4 Match 208\n",
      "\n",
      "[-1.2119141  -0.00987244 -0.44799805  0.28466797  0.77783203  0.5541992 ] 4   0 \n",
      "[-2.2583008e-01  3.3251953e-01 -2.7942657e-04 -2.0715332e-01\n",
      " -4.8876953e-01 -2.4658203e-01] 1   2 \n",
      "[-0.4038086   0.26293945  0.37451172  0.08300781 -0.36816406 -0.49804688] 2   5 \n",
      "[-1.4433594  -0.20910645 -0.5136719   0.38354492  0.8178711   0.6948242 ] 4   5 \n",
      "[ 0.05953979  0.15710449  0.16455078 -0.22277832 -0.3395996  -0.34960938] 2   2 Match 209\n",
      "\n",
      "[-1.0146484   0.1484375   0.06158447  0.33935547  0.07220459 -0.06207275] 3   3 Match 210\n",
      "\n",
      "[-0.6855469   0.36743164 -0.21044922 -0.10614014 -0.19946289 -0.08129883] 1   1 Match 211\n",
      "\n",
      "[-1.4130859  -0.20666504 -0.16723633  0.6591797   0.86865234  0.08050537] 4   3 \n",
      "[-1.7861328  -0.07940674 -0.0191803   0.80126953  0.3486328   0.22485352] 3   3 Match 212\n",
      "\n",
      "[-1.0292969   0.21594238  0.3125      0.36572266 -0.02853394 -0.17858887] 3   0 \n",
      "[-1.2587891  -0.17944336  0.081604    0.7558594   0.34033203 -0.11138916] 3   2 \n",
      "[-1.19335938e+00 -2.66075134e-03 -1.06933594e-01  6.63085938e-01\n",
      "  3.20800781e-01  9.53197479e-04] 3   4 \n",
      "[-1.1220703   0.19348145 -0.02862549  0.34936523  0.42456055  0.17529297] 4   4 Match 213\n",
      "\n",
      "[-1.3330078   0.23205566 -0.09863281  0.38330078  0.16638184  0.17333984] 3   4 \n",
      "[-1.6181641  -0.09484863  0.01042938  0.6088867   0.8925781   0.17529297] 4   4 Match 214\n",
      "\n",
      "[-0.9555664   0.0065155   0.18798828  0.30615234  0.33007812 -0.10620117] 4   3 \n",
      "[-1.1074219   0.10461426  0.23291016  0.68408203  0.20141602 -0.3557129 ] 3   0 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.7373047  -0.06958008  0.00954437  0.62646484  0.83984375  0.2770996 ] 4   5 \n",
      "[-0.7451172   0.3149414   0.08880615  0.17163086 -0.30688477 -0.24768066] 1   2 \n",
      "[-0.6040039   0.46240234 -0.20837402 -0.01296997 -0.20471191 -0.01307678] 1   2 \n",
      "[-1.2011719   0.22021484 -0.00966644  0.41967773  0.11444092  0.00474548] 3   4 \n",
      "[-1.4541016   0.01255035 -0.1899414   0.49438477  0.75878906  0.42138672] 4   1 \n",
      "[-1.5791016   0.20129395 -0.26489258  0.2763672   0.6411133   0.6381836 ] 4   4 Match 215\n",
      "\n",
      "[-0.3239746   0.22717285 -0.22680664 -0.12780762 -0.09222412 -0.22338867] 1   3 \n",
      "[-1.4560547  -0.21606445 -0.16003418  0.4580078   0.79541016  0.3876953 ] 4   4 Match 216\n",
      "\n",
      "[-0.54541016  1.3369141  -0.640625   -0.17626953 -0.7451172  -0.16699219] 1   5 \n",
      "[-1.3486328   0.30200195 -0.03173828  0.37426758  0.3395996   0.00933838] 3   2 \n",
      "[-1.2021484   0.12670898 -0.11669922  0.5136719   0.44799805  0.07434082] 3   5 \n",
      "[-1.328125    0.05032349 -0.18383789  0.36499023  0.6069336   0.21447754] 4   3 \n",
      "[-1.5048828  -0.02194214 -0.0150528   0.6230469   0.41357422  0.01285553] 3   3 Match 217\n",
      "\n",
      "[-0.37036133  0.3557129   0.12121582  0.05508423 -0.26879883 -0.3149414 ] 1   1 Match 218\n",
      "\n",
      "[-1.4609375   0.19897461 -0.42944336  0.30908203  0.7783203   0.5371094 ] 4   4 Match 219\n",
      "\n",
      "[-1.0078125   0.04626465  0.3293457   0.6088867   0.02516174 -0.4609375 ] 3   2 \n",
      "[-0.12017822  0.8208008  -0.32373047 -0.2944336  -0.67041016 -0.16296387] 1   1 Match 220\n",
      "\n",
      "[-0.39575195  0.43652344 -0.18823242 -0.34570312 -0.0947876   0.0904541 ] 1   4 \n",
      "[-1.6152344  -0.06671143 -0.14221191  0.5473633   0.84033203  0.5078125 ] 4   4 Match 221\n",
      "\n",
      "[-1.3613281   0.00160599  0.125       0.51708984  0.42211914  0.12719727] 3   3 Match 222\n",
      "\n",
      "[-1.578125   -0.08178711 -0.34204102  0.36279297  1.0683594   0.8354492 ] 4   3 \n",
      "[-0.94628906  0.08215332  0.1418457   0.29882812 -0.04092407 -0.15734863] 3   2 \n",
      "[ 0.17565918  0.33422852 -0.03619385 -0.3701172  -0.42871094 -0.31201172] 1   0 \n",
      "[-0.88623047  0.37353516  0.13500977  0.3095703   0.06018066 -0.19714355] 1   1 Match 223\n",
      "\n",
      "[-1.5830078  -0.05609131 -0.56591797  0.22753906  1.0039062   0.9472656 ] 4   4 Match 224\n",
      "\n",
      "[-1.7900391  -0.29003906 -0.14318848  0.84228516  0.71728516  0.3137207 ] 3   4 \n",
      "[-1.2832031   0.31713867 -0.35864258  0.15686035  0.73828125  0.79785156] 5   4 \n",
      "[-1.1083984   0.13891602 -0.6035156   0.02398682  0.9892578   0.7949219 ] 4   5 \n",
      "[-1.5576172  -0.08398438  0.16589355  0.7675781   0.72216797  0.01456451] 3   3 Match 225\n",
      "\n",
      "[-1.4785156  -0.11102295 -0.13708496  0.46020508  0.87841797  0.2800293 ] 4   2 \n",
      "[-0.60302734  0.5205078  -0.50341797 -0.33911133  0.02668762  0.29541016] 1   5 \n",
      "[-0.25219727  0.4560547  -0.25097656 -0.26416016 -0.16320801 -0.12902832] 1   0 \n",
      "[-1.0400391  -0.03250122  0.27441406  0.80029297  0.13305664 -0.40527344] 3   3 Match 226\n",
      "\n",
      "[-0.57666016  0.48657227 -0.22570801 -0.08892822 -0.01989746 -0.00414276] 1   0 \n",
      "[-1.5986328  -0.15283203 -0.39111328  0.32250977  0.9897461   0.7426758 ] 4   4 Match 227\n",
      "\n",
      "[-0.98828125  0.29956055 -0.16809082  0.21240234  0.11224365  0.03555298] 1   4 \n",
      "[-0.07763672 -0.14086914 -0.05679321 -0.38452148 -0.5151367  -0.0254364 ] 5   4 \n",
      "[-0.4284668   0.3178711   0.06994629 -0.07989502 -0.47094727 -0.20422363] 1   3 \n",
      "[-1.3222656   0.11315918  0.21032715  0.68896484  0.41625977 -0.15893555] 3   2 \n",
      "[-0.08587646  0.21850586  0.10876465 -0.12219238 -0.23803711 -0.3383789 ] 1   5 \n",
      "[-1.2558594  -0.02035522 -0.05606079  0.46020508  0.6977539   0.19274902] 4   5 \n",
      "[-0.47436523  0.24841309 -0.14343262 -0.15698242 -0.1986084  -0.09912109] 1   1 Match 228\n",
      "\n",
      "[-1.7041016   0.0378418  -0.31030273  0.49267578  1.0302734   0.36669922] 4   1 \n",
      "[-1.03125     0.40112305 -0.44262695  0.03765869  0.45996094  0.48706055] 5   3 \n",
      "[-1.6386719  -0.14990234 -0.4650879   0.35375977  0.9379883   0.9404297 ] 5   2 \n",
      "[-1.0800781   0.19934082 -0.59765625  0.09490967  0.6152344   0.70751953] 5   5 Match 229\n",
      "\n",
      "[-0.98339844  0.14758301 -0.15527344  0.23400879  0.30517578  0.20507812] 4   2 \n",
      "[-0.06750488  0.4033203  -0.21984863 -0.20874023 -0.42749023 -0.20153809] 1   1 Match 230\n",
      "\n",
      "[-0.44921875  1.1064453  -0.8930664  -0.02230835 -0.02391052  0.31567383] 1   3 \n",
      "[-1.6240234  -0.28588867  0.00443649  0.8178711   0.8408203   0.12805176] 4   3 \n",
      "[-0.69921875  0.6591797  -0.27319336 -0.28173828  0.07189941  0.18945312] 1   1 Match 231\n",
      "\n",
      "[-0.9736328   0.33203125  0.0690918   0.42236328 -0.0904541  -0.13378906] 3   3 Match 232\n",
      "\n",
      "[-1.6328125  -0.16601562 -0.24304199  0.55566406  1.0234375   0.5439453 ] 4   4 Match 233\n",
      "\n",
      "[-1.3320312   0.09735107  0.2475586   0.7241211   0.27368164 -0.29638672] 3   5 \n",
      "[-1.4511719  -0.01408386 -0.18945312  0.40551758  0.7558594   0.33398438] 4   4 Match 234\n",
      "\n",
      "[-1.7617188  -0.2154541  -0.42504883  0.47314453  1.1806641   0.7109375 ] 4   1 \n",
      "[-1.2724609   0.05825806 -0.19299316  0.5175781   0.70703125  0.30786133] 4   3 \n",
      "[-1.0908203   0.1307373  -0.31835938  0.07733154  0.3305664   0.33422852] 5   4 \n",
      "[ 0.02896118  0.35351562 -0.05136108 -0.4921875  -0.6738281  -0.30737305] 1   0 \n",
      "[-1.3369141   0.14990234 -0.6538086   0.0586853   0.7783203   0.9135742 ] 5   2 \n",
      "[-1.2285156   0.28710938 -0.2512207   0.28857422  0.26123047  0.18762207] 3   1 \n",
      "[-0.6948242   0.3803711  -0.08294678  0.0473938  -0.26879883 -0.02612305] 1   5 \n",
      "[-1.59375    -0.22290039 -0.0892334   0.85058594  0.9458008   0.06286621] 4   2 \n",
      "[-1.8710938  -0.20117188 -0.21472168  0.6352539   1.0068359   0.65527344] 4   4 Match 235\n",
      "\n",
      "[-1.6113281  -0.28295898  0.06317139  0.9165039   0.46118164  0.00914001] 3   3 Match 236\n",
      "\n",
      "[-1.1474609  -0.00734329  0.01242828  0.49682617  0.09643555 -0.01600647] 3   4 \n",
      "[-0.26342773  0.16638184  0.1003418  -0.04086304 -0.4267578  -0.4543457 ] 1   5 \n",
      "[-0.8955078   0.23962402  0.2290039   0.14099121  0.03424072 -0.03411865] 1   1 Match 237\n",
      "\n",
      "[ 0.15039062  0.47558594 -0.0692749  -0.4104004  -0.5541992  -0.48242188] 1   0 \n",
      "[-0.6171875   0.56396484 -0.3569336  -0.1730957  -0.17993164  0.13574219] 1   2 \n",
      "[-0.39648438  0.21044922  0.13378906 -0.04418945 -0.22021484 -0.19128418] 1   2 \n",
      "[-1.6728516  -0.05926514 -0.3425293   0.5136719   0.7163086   0.72509766] 5   1 \n",
      "[-1.5224609  -0.03030396  0.06140137  0.7524414   0.5263672   0.12927246] 3   1 \n",
      "[-1.6689453  -0.22424316 -0.32226562  0.6816406   0.73535156  0.62109375] 4   4 Match 238\n",
      "\n",
      "[-0.65722656  0.1694336   0.36669922  0.25708008 -0.13244629 -0.4650879 ] 2   2 Match 239\n",
      "\n",
      "[-1.4755859  -0.04602051 -0.6201172   0.24645996  1.0078125   0.8745117 ] 4   1 \n",
      "[-1.0214844   0.27001953  0.23657227  0.3972168  -0.10845947 -0.25708008] 3   5 \n",
      "[-1.6376953  -0.14099121 -0.39916992  0.4645996   0.8984375   0.69140625] 4   4 Match 240\n",
      "\n",
      "[-1.703125   -0.01202393 -0.12731934  0.58251953  0.67041016  0.4658203 ] 4   5 \n",
      "[-0.86279297 -0.0562439  -0.08306885  0.23486328  0.15576172 -0.15490723] 3   3 Match 241\n",
      "\n",
      "[-0.6645508   0.18908691  0.4086914   0.4477539  -0.06933594 -0.6411133 ] 3   1 \n",
      "[-1.0400391   0.13208008 -0.38500977  0.08880615  0.4633789   0.29101562] 4   2 \n",
      "[-1.3710938  -0.17175293 -0.42651367  0.36743164  0.7739258   0.54296875] 4   2 \n",
      "[-0.01573181  0.48706055  0.15637207 -0.33251953 -0.6948242  -0.3256836 ] 1   3 \n",
      "[-1.7099609   0.13146973 -0.61816406  0.31103516  0.9082031   0.90771484] 4   5 \n",
      "[-1.0810547   0.16052246 -0.3239746   0.05026245  0.37768555  0.38452148] 5   1 \n",
      "[-0.07672119  0.33642578  0.3076172  -0.16296387 -0.46020508 -0.3359375 ] 1   3 \n",
      "[-0.21850586  0.2770996   0.33276367  0.21154785 -0.4699707  -0.79345703] 2   3 \n",
      "[-1.4882812  -0.15002441 -0.51123047  0.20983887  1.0898438   1.0537109 ] 4   5 \n",
      "[-0.59472656  0.5058594   0.25634766  0.1081543  -0.19763184 -0.33642578] 1   2 \n",
      "[-5.4687500e-01  6.7187500e-01 -2.0214844e-01 -2.2680664e-01\n",
      " -3.5693359e-01 -4.8804283e-04] 1   1 Match 242\n",
      "\n",
      "[-1.0224609  -0.02835083  0.24365234  0.48168945 -0.14099121 -0.15100098] 3   3 Match 243\n",
      "\n",
      "[-0.3359375   1.2421875  -0.62060547 -0.16833496 -0.66015625 -0.10198975] 1   3 \n",
      "[-1.3232422  -0.00990295 -0.32592773  0.24829102  0.6665039   0.42773438] 4   5 \n",
      "[-0.51416016  0.6875     -0.6333008  -0.22631836  0.08709717  0.44458008] 1   5 \n",
      "[-0.3154297   0.18798828  0.28759766 -0.02253723 -0.46899414 -0.4243164 ] 2   2 Match 244\n",
      "\n",
      "[-1.7832031  -0.26782227 -0.17541504  0.7939453   0.7470703   0.3479004 ] 3   5 \n",
      "[-1.6162109  -0.22277832 -0.6328125   0.37451172  1.1171875   1.0439453 ] 4   5 \n",
      "[-0.43823242  0.17565918 -0.19799805 -0.2084961  -0.60839844 -0.09899902] 1   3 \n",
      "[-0.2529297   0.23413086  0.21850586  0.02359009 -0.2685547  -0.50439453] 1   1 Match 245\n",
      "\n",
      "[-1.6669922  -0.24584961 -0.57470703  0.39257812  1.109375    0.91015625] 4   4 Match 246\n",
      "\n",
      "[-1.65625    -0.23706055 -0.10534668  0.7792969   0.63378906  0.15026855] 3   3 Match 247\n",
      "\n",
      "[-0.5307617   0.27734375 -0.55126953 -0.1796875   0.09484863  0.3557129 ] 5   1 \n",
      "[-1.4013672   0.3779297  -0.14282227  0.5708008   0.14587402 -0.16821289] 3   4 \n",
      "[-1.5644531  -0.1274414  -0.33813477  0.50439453  0.86816406  0.5913086 ] 4   1 \n",
      "[-1.7890625  -0.07904053 -0.49560547  0.53808594  1.1347656   0.9350586 ] 4   5 \n",
      "[-1.8125     -0.21166992 -0.2998047   0.67822266  0.9790039   0.33666992] 4   3 \n",
      "[-1.7226562  -0.01170349 -0.2175293   0.53564453  0.8227539   0.28881836] 4   4 Match 248\n",
      "\n",
      "[-1.5966797   0.3076172  -0.24450684  0.1796875   0.36645508  0.68408203] 5   3 \n",
      "[-1.1162109   0.22814941  0.17736816  0.5776367   0.22387695 -0.40600586] 3   1 \n",
      "[-1.3837891   0.06628418 -0.76220703  0.15124512  0.99365234  1.0371094 ] 5   3 \n",
      "[-0.86376953  0.27075195 -0.29882812 -0.01849365 -0.2734375   0.02928162] 1   4 \n",
      "[-1.7714844  -0.01410675 -0.44360352  0.44726562  1.0097656   0.64160156] 4   4 Match 249\n",
      "\n",
      "[-1.4423828  -0.10064697  0.01100159  0.7631836   0.46972656  0.01586914] 3   5 \n",
      "[-0.48608398  0.39086914 -0.48632812 -0.33081055  0.06329346  0.2783203 ] 1   4 \n",
      "[-1.6630859  -0.4008789  -0.18566895  0.8286133   0.39941406  0.11505127] 3   4 \n",
      "[-1.0244141   0.07250977 -0.02677917  0.39770508  0.22180176 -0.02787781] 3   5 \n",
      "[-0.14379883  0.4140625   0.03338623 -0.3059082  -0.73535156 -0.3076172 ] 1   5 \n",
      "[-0.7133789   0.05474854  0.3317871   0.38378906 -0.29614258 -0.51904297] 3   4 \n",
      "[-1.3476562   0.01150513  0.20544434  0.68847656  0.14331055 -0.19750977] 3   5 \n",
      "[-1.703125   -0.13317871 -0.28710938  0.43847656  1.0751953   0.8076172 ] 4   4 Match 250\n",
      "\n",
      "[-1.5400391  -0.01663208  0.07080078  0.75390625  0.41235352 -0.11120605] 3   3 Match 251\n",
      "\n",
      "[-0.33935547  0.13305664  0.46801758  0.06878662 -0.42797852 -0.5258789 ] 2   0 \n",
      "[-0.34448242  0.2619629   0.41210938  0.11682129 -0.2475586  -0.6230469 ] 2   2 Match 252\n",
      "\n",
      "[-1.6855469  -0.1038208  -0.32177734  0.5136719   1.0849609   0.7006836 ] 4   4 Match 253\n",
      "\n",
      "[-0.59765625  0.41870117 -0.0028286  -0.12115479 -0.24829102 -0.13171387] 1   4 \n",
      "[-1.5517578  -0.07305908 -0.42407227  0.20568848  1.0263672   0.72216797] 4   2 \n",
      "[-1.6875     -0.11346436 -0.15527344  0.7104492   0.9995117   0.3034668 ] 4   3 \n",
      "[-1.8544922  -0.06817627 -0.18823242  0.71533203  1.0068359   0.48754883] 4   5 \n",
      "[-1.0009766   0.078125    0.4609375   0.5800781   0.2800293  -0.51660156] 3   4 \n",
      "[-1.3994141   0.05307007  0.05755615  0.53125     0.36865234  0.01856995] 3   4 \n",
      "[-0.07641602  0.17773438  0.32006836 -0.1697998  -0.47387695 -0.60253906] 2   0 \n",
      "[-0.8964844   0.14294434  0.32641602  0.44384766 -0.0949707  -0.50439453] 3   4 \n",
      "[-0.39770508  0.31445312 -0.20056152 -0.19799805 -0.13806152 -0.12115479] 1   5 \n",
      "[-1.5234375  -0.12371826 -0.09490967  0.7446289   0.5961914   0.24255371] 3   1 \n",
      "[-0.46801758  0.15283203  0.01625061 -0.03433228 -0.13842773 -0.15612793] 1   2 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.38598633  0.21618652  0.41870117  0.19421387 -0.5292969  -0.67333984] 2   2 Match 254\n",
      "\n",
      "[-0.37963867  0.14221191  0.35058594  0.2956543  -0.04421997 -0.5444336 ] 2   0 \n",
      "[-0.9707031   0.23498535 -0.10961914  0.25170898  0.2524414   0.00871277] 4   4 Match 255\n",
      "\n",
      "[-1.4824219  -0.15405273 -0.23181152  0.45336914  0.7832031   0.36035156] 4   3 \n",
      "[-1.0537109   0.30151367 -0.35009766  0.14855957  0.6088867   0.35302734] 4   5 \n",
      "[-0.5083008   0.29492188  0.27563477  0.22351074 -0.50878906 -0.61572266] 1   2 \n",
      "[-0.07781982  0.75683594 -0.40844727 -0.3635254  -0.29125977 -0.1821289 ] 1   1 Match 256\n",
      "\n",
      "[-0.5444336   0.3256836  -0.02482605 -0.02157593 -0.41064453 -0.17810059] 1   2 \n",
      "[-1.7568359  -0.05871582 -0.3190918   0.4716797   1.0009766   0.7421875 ] 4   4 Match 257\n",
      "\n",
      "[-0.26757812  0.48510742 -0.40454102 -0.4404297  -0.11291504  0.19946289] 1   5 \n",
      "[ 0.12939453  0.46264648  0.22509766 -0.18762207 -0.55078125 -0.5571289 ] 1   5 \n",
      "[-1.6220703  -0.09606934 -0.06817627  0.6845703   0.88183594  0.17773438] 4   1 \n",
      "[-1.4677734  -0.0201416   0.10791016  0.5683594   0.48510742  0.1607666 ] 3   3 Match 258\n",
      "\n",
      "[-1.2851562  -0.07122803 -0.30273438  0.2614746   1.0146484   0.39868164] 4   1 \n",
      "[-0.515625    0.3154297   0.1459961   0.1685791  -0.32617188 -0.37548828] 1   2 \n",
      "[-1.3837891  -0.23144531 -0.06939697  0.42871094  0.55322266  0.2529297 ] 4   3 \n",
      "[-1.6152344  -0.28393555 -0.4729004   0.6230469   1.0996094   0.7260742 ] 4   1 \n",
      "[ 0.23425293  0.3840332   0.05953979 -0.40527344 -0.56347656 -0.33740234] 1   0 \n",
      "[-1.1162109   0.3701172  -0.16320801 -0.00541306  0.00989532  0.28979492] 1   5 \n",
      "[-1.828125   -0.14172363 -0.3076172   0.7026367   1.1044922   0.6074219 ] 4   5 \n",
      "[-1.6552734  -0.06378174 -0.23718262  0.45751953  0.8696289   0.6191406 ] 4   1 \n",
      "[-0.7553711   0.02281189 -0.1529541   0.08203125 -0.16308594  0.00834656] 3   1 \n",
      "[-0.9970703  -0.09918213  0.29589844  0.6591797  -0.1965332  -0.44604492] 3   0 \n",
      "[ 0.04919434  0.36523438 -0.06530762 -0.42626953 -0.5517578  -0.29101562] 1   1 Match 259\n",
      "\n",
      "[-1.4111328  -0.07220459 -0.00610352  0.7265625   0.5205078   0.05172729] 3   3 Match 260\n",
      "\n",
      "[-0.20080566  0.4230957   0.14135742 -0.32104492 -0.22192383 -0.19030762] 1   0 \n",
      "[-1.3125     -0.02606201  0.06234741  0.5053711   0.35058594 -0.0567627 ] 3   4 \n",
      "[-1.0761719   0.11322021 -0.32983398 -0.07159424  0.39697266  0.6044922 ] 5   4 \n",
      "[-0.21472168  0.32788086  0.4111328   0.09014893 -0.3684082  -0.5839844 ] 2   5 \n",
      "[-0.16638184  0.38476562  0.02742004 -0.21899414 -0.5234375  -0.3256836 ] 1   3 \n",
      "[-3.3984375e-01  1.2585449e-01 -2.3639202e-04 -5.4397583e-03\n",
      " -3.3227539e-01 -4.1503906e-01] 1   2 \n",
      "[ 2.0503998e-05  2.4938965e-01  1.5502930e-01 -3.4863281e-01\n",
      " -5.1074219e-01 -3.8598633e-01] 1   0 \n",
      "[-1.1357422   0.18457031  0.21533203  0.41918945  0.37963867 -0.1652832 ] 3   4 \n",
      "[-1.6220703  -0.07745361  0.06082153  0.9013672   0.39282227 -0.13476562] 3   2 \n",
      "[-0.80810547  0.14318848  0.4560547   0.46679688 -0.11553955 -0.48999023] 3   2 \n",
      "[-0.546875    0.40112305  0.14929199  0.16821289 -0.30297852 -0.33544922] 1   2 \n",
      "[-1.1816406  -0.11590576  0.25756836  0.7348633   0.17565918 -0.44628906] 3   4 \n",
      "[-0.8979492   0.16845703  0.08532715  0.4699707   0.20776367 -0.38720703] 3   5 \n",
      "[-1.4511719  -0.07830811  0.00265121  0.6928711   0.52685547  0.01535034] 3   4 \n",
      "[ 0.3330078   0.3071289   0.16369629 -0.45996094 -0.64453125 -0.37231445] 0   2 \n",
      "[-0.46435547  0.11645508  0.13537598  0.07055664 -0.36572266 -0.4104004 ] 2   4 \n",
      "[-1.6152344  -0.26904297 -0.00178814  0.87597656  0.66748047 -0.05123901] 3   4 \n",
      "[-0.9951172   0.2536621   0.01280212  0.31323242 -0.11462402 -0.02583313] 3   2 \n",
      "[-0.27294922  0.4230957  -0.55078125 -0.45825195 -0.27539062  0.27783203] 1   3 \n",
      "[-1.5078125   0.00702667 -0.09594727  0.5317383   0.54248047  0.3466797 ] 4   2 \n",
      "[-1.1357422   0.05722046  0.0725708   0.44018555 -0.13708496 -0.07647705] 3   4 \n",
      "[-1.1005859   0.04440308 -0.67626953  0.30859375  1.2382812   0.64697266] 4   3 \n",
      "[-1.4853516  -0.08282471 -0.41625977  0.2331543   0.97558594  0.69921875] 4   2 \n",
      "[-0.06317139  0.38793945  0.0949707  -0.08709717 -0.4272461  -0.51220703] 1   1 Match 261\n",
      "\n",
      "[-1.3857422  -0.02098083 -0.6567383   0.03677368  0.9760742   0.8691406 ] 4   4 Match 262\n",
      "\n",
      "[-1.1337891   0.0617981   0.31347656  0.5493164   0.19213867 -0.36572266] 3   0 \n",
      "[ 0.07250977  0.42529297 -0.140625   -0.40063477 -0.58251953 -0.27319336] 1   2 \n",
      "[-0.98535156  0.03173828  0.1751709   0.4338379   0.3317871  -0.29663086] 3   3 Match 263\n",
      "\n",
      "[ 0.05215454  0.15490723  0.0859375  -0.4350586  -0.5097656  -0.13427734] 1   0 \n",
      "[ 0.43139648  0.36279297  0.14147949 -0.48413086 -0.46923828 -0.36816406] 0   2 \n",
      "[ 0.1003418   0.24780273  0.30566406 -0.08282471 -0.59521484 -0.7285156 ] 2   1 \n",
      "[-1.8896484  -0.2277832  -0.32470703  0.61816406  1.1503906   0.6958008 ] 4   4 Match 264\n",
      "\n",
      "[-0.95166016  0.1151123  -0.10864258  0.11383057  0.51953125  0.1607666 ] 4   1 \n",
      "[-0.22314453  0.42944336  0.10565186 -0.25268555 -0.43652344 -0.34423828] 1   3 \n",
      "[-0.5839844   0.31103516 -0.25708008 -0.00882721 -0.22814941 -0.16821289] 1   0 \n",
      "[-0.64990234  0.08502197 -0.71191406 -0.2993164   0.01268005  0.8100586 ] 5   1 \n",
      "[-0.87109375  0.26904297  0.2479248   0.32006836  0.24291992 -0.35717773] 3   3 Match 265\n",
      "\n",
      "[-1.7666016   0.01570129 -0.31030273  0.5961914   1.0800781   0.62402344] 4   5 \n",
      "[-1.3095703   0.03619385  0.17785645  0.6875      0.2277832  -0.23217773] 3   4 \n",
      "[-1.5332031  -0.13659668 -0.32910156  0.4609375   1.0771484   0.51464844] 4   4 Match 266\n",
      "\n",
      "[-0.42578125  0.4506836   0.08203125  0.04742432 -0.5419922  -0.38085938] 1   0 \n",
      "[-0.3737793   0.29101562 -0.35375977 -0.23718262 -0.31811523 -0.05105591] 1   0 \n",
      "[-0.56689453  0.3947754   0.11706543  0.24023438 -0.0904541  -0.38549805] 1   2 \n",
      "[-1.3466797  -0.19519043 -0.35913086  0.5942383   0.6044922   0.37280273] 4   0 \n",
      "[-0.46679688  0.4296875  -0.25561523 -0.34179688 -0.15710449 -0.02075195] 1   2 \n",
      "[-1.4941406  -0.10028076 -0.39526367  0.43652344  0.8364258   0.45947266] 4   1 \n",
      "[-1.453125    0.08056641 -0.19104004  0.5732422   0.8222656   0.28076172] 4   3 \n",
      "[-0.92089844  0.14550781  0.0703125   0.25732422  0.32080078 -0.09283447] 4   3 \n",
      "[-1.3867188  -0.14355469 -0.10900879  0.5180664   0.1977539   0.28320312] 3   5 \n",
      "[-0.80859375  0.07897949  0.4675293   0.54003906  0.1809082  -0.57128906] 3   3 Match 267\n",
      "\n",
      "[ 0.05197144  0.34155273  0.38232422 -0.30371094 -0.640625   -0.48754883] 2   1 \n",
      "[-0.39648438  0.21984863  0.49951172  0.2919922  -0.16223145 -0.6479492 ] 2   0 \n",
      "[-0.6196289   0.07843018 -0.6035156  -0.3815918   0.04083252  0.0881958 ] 5   2 \n",
      "[-1.1455078   0.16589355 -0.00774384  0.23669434  0.06286621  0.23303223] 3   2 \n",
      "[-0.1274414   0.11560059  0.21472168 -0.18261719 -0.44482422 -0.3400879 ] 2   1 \n",
      "[-1.4257812   0.20874023 -0.18310547  0.4099121   0.34960938  0.3227539 ] 3   5 \n",
      "[-0.6508789   0.25268555 -0.10772705 -0.03256226 -0.23779297 -0.05734253] 1   2 \n",
      "[-0.83251953  0.05963135  0.48486328  0.69140625  0.11932373 -0.6879883 ] 3   1 \n",
      "[-1.5654297  -0.26538086 -0.5205078   0.36621094  0.9892578   0.83691406] 4   4 Match 268\n",
      "\n",
      "[-1.3251953  -0.17529297 -0.37524414  0.25976562  1.0273438   0.6328125 ] 4   1 \n",
      "[-0.6699219   0.32470703  0.06027222  0.0803833  -0.2668457  -0.08068848] 1   1 Match 269\n",
      "\n",
      "[-1.6123047  -0.15112305  0.04333496  0.88378906  0.49829102 -0.10961914] 3   4 \n",
      "[-0.22143555  0.2442627  -0.11071777 -0.14416504 -0.43725586 -0.26000977] 1   3 \n",
      "[-1.2363281   0.01532745  0.3840332   0.7705078   0.3330078  -0.38989258] 3   4 \n",
      "[-0.1508789   0.19519043  0.328125   -0.05700684 -0.33081055 -0.55078125] 2   4 \n",
      "[-0.30078125  0.2697754   0.234375    0.17004395 -0.39624023 -0.6791992 ] 1   2 \n",
      "[-1.5888672   0.10229492 -0.3491211   0.11419678  0.71191406  0.76220703] 5   4 \n",
      "[-0.15063477  0.29907227  0.07653809 -0.2454834  -0.60302734 -0.42333984] 1   4 \n",
      "[-1.7470703  -0.39111328 -0.3984375   0.66015625  0.8647461   0.66064453] 4   4 Match 270\n",
      "\n",
      "[-1.4960938  -0.15625    -0.49829102  0.3984375   0.9013672   0.80859375] 4   5 \n",
      "[-0.57470703  0.37329102 -0.54345703 -0.34448242  0.0791626   0.5107422 ] 5   5 Match 271\n",
      "\n",
      "[-1.4882812  -0.18701172 -0.20959473  0.46020508  0.8232422   0.54589844] 4   0 \n",
      "[-1.8261719  -0.23657227 -0.40576172  0.6044922   0.9086914   0.82177734] 4   5 \n",
      "[-1.5869141  -0.0116272  -0.30371094  0.6220703   1.0625      0.5024414 ] 4   3 \n",
      "[-1.8486328  -0.15576172 -0.09356689  0.6723633   0.9433594   0.3659668 ] 4   4 Match 272\n",
      "\n",
      "[-0.43066406  0.3359375  -0.19470215 -0.27294922 -0.04052734 -0.16271973] 1   3 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.80371094  0.10839844  0.39135742  0.46142578 -0.05352783 -0.5678711 ] 3   3 Match 273\n",
      "\n",
      "[-0.44726562  0.02236938  0.30932617  0.10687256 -0.31713867 -0.4165039 ] 2   4 \n",
      "[-1.0585938   0.13793945  0.15344238  0.51660156  0.14453125 -0.22094727] 3   3 Match 274\n",
      "\n",
      "[ 0.12915039  0.30004883  0.13586426 -0.14294434 -0.48535156 -0.43823242] 1   1 Match 275\n",
      "\n",
      "[-0.27416992  0.5449219  -0.12792969 -0.31835938 -0.42236328 -0.07568359] 1   1 Match 276\n",
      "\n",
      "[-1.1689453   0.22924805 -0.10369873  0.22851562 -0.05895996  0.16833496] 1   1 Match 277\n",
      "\n",
      "[-1.2509766   0.02453613 -0.46875     0.05273438  0.671875    0.6723633 ] 5   5 Match 278\n",
      "\n",
      "[ 0.00935364  0.32006836  0.09533691 -0.3569336  -0.7451172  -0.3359375 ] 1   0 \n",
      "[-1.8466797  -0.22888184 -0.15368652  0.88964844  0.79345703  0.33740234] 3   1 \n",
      "[-0.81933594  0.10614014  0.32592773  0.32226562 -0.13720703 -0.31469727] 2   3 \n",
      "[-0.7475586   0.28442383 -0.29858398 -0.22631836  0.17614746  0.50341797] 5   1 \n",
      "[-0.5571289   1.1699219  -0.39648438 -0.1459961  -0.7763672  -0.40161133] 1   1 Match 279\n",
      "\n",
      "[-1.09375    -0.02983093 -0.40454102 -0.08343506  0.3137207   0.53564453] 5   5 Match 280\n",
      "\n",
      "[-1.6005859   0.24536133 -0.20678711  0.50634766  0.6196289   0.53271484] 4   4 Match 281\n",
      "\n",
      "[-0.8334961   0.13513184  0.29003906  0.4790039  -0.14782715 -0.5258789 ] 3   2 \n",
      "[-1.3984375  -0.15734863 -0.05404663  0.59472656  0.35595703  0.15698242] 3   3 Match 282\n",
      "\n",
      "[-1.3232422  -0.08117676  0.25439453  0.64501953  0.3503418  -0.17712402] 3   1 \n",
      "[-0.71875     0.38110352 -0.06054688 -0.08044434 -0.03366089 -0.09832764] 1   2 \n",
      "[-1.4541016   0.05456543  0.02127075  0.4855957   0.38208008  0.22570801] 3   1 \n",
      "[-0.73339844  0.47338867 -0.29492188 -0.07647705 -0.0247345   0.2097168 ] 1   2 \n",
      "[-0.73046875  0.09381104  0.1373291   0.30419922 -0.23254395 -0.18737793] 3   4 \n",
      "[ 0.08221436  0.5083008  -0.06463623 -0.5629883  -0.8666992  -0.32836914] 1   0 \n",
      "[-1.6806641  -0.3881836  -0.4958496   0.46972656  1.0761719   0.85595703] 4   4 Match 283\n",
      "\n",
      "[-0.8364258  -0.0378418   0.40673828  0.46850586 -0.23608398 -0.47314453] 3   4 \n",
      "[-0.4724121   0.359375    0.13574219  0.02616882 -0.12231445 -0.38549805] 1   4 \n",
      "[-1.2080078   0.12646484 -0.5175781   0.11474609  0.67578125  0.75683594] 5   4 \n",
      "[-1.8535156  -0.2722168  -0.16235352  0.8310547   0.8964844   0.54052734] 4   5 \n",
      "[-1.6191406  -0.25561523 -0.13891602  0.6816406   1.0371094   0.38867188] 4   5 \n",
      "[-0.5332031   0.19433594  0.29614258  0.12902832 -0.38305664 -0.5439453 ] 2   2 Match 284\n",
      "\n",
      "[-1.3212891  -0.00353432 -0.19348145  0.37451172  0.9291992   0.3671875 ] 4   1 \n",
      "[-1.5429688  -0.20117188 -0.08068848  0.9145508   0.52001953 -0.15563965] 3   4 \n",
      "[-1.3994141  -0.06591797 -0.6303711   0.29907227  0.8105469   0.8979492 ] 5   4 \n",
      "[-1.2236328  -0.13232422 -0.0980835   0.26416016  0.6616211   0.16308594] 4   3 \n",
      "[-1.6591797   0.13244629 -0.11279297  0.56152344  0.80566406  0.29907227] 4   3 \n",
      "[-0.8222656   0.3623047   0.09649658  0.27978516 -0.11395264 -0.24731445] 1   3 \n",
      "[-0.81933594  0.26391602 -0.09820557  0.11187744 -0.22802734 -0.12927246] 1   2 \n",
      "[-1.6767578  -0.15759277 -0.56103516  0.4567871   0.8964844   0.75439453] 4   3 \n",
      "[-1.4892578   0.04388428 -0.22851562  0.3232422   0.66064453  0.22021484] 4   3 \n",
      "[ 0.18615723  0.5214844  -0.11688232 -0.5341797  -0.80615234 -0.4897461 ] 1   4 \n",
      "[-1.7441406  -0.35327148 -0.26367188  0.7426758   0.9091797   0.38867188] 4   1 \n",
      "[-1.6787109  -0.19580078 -0.5800781   0.36645508  0.86083984  1.0693359 ] 5   4 \n",
      "[-1.8300781  -0.42138672 -0.32958984  0.74121094  1.1923828   0.44262695] 4   3 \n",
      "[-1.2832031   0.2232666  -0.5488281   0.15307617  0.74316406  0.5942383 ] 4   5 \n",
      "[-0.6635742   1.0078125  -0.3227539   0.07318115 -0.7050781  -0.23400879] 1   1 Match 285\n",
      "\n",
      "[-0.7890625   0.22937012  0.21704102  0.3425293   0.11126709 -0.296875  ] 3   1 \n",
      "[-1.6064453  -0.25048828 -0.38061523  0.53027344  0.7270508   0.6035156 ] 4   5 \n",
      "[-0.42797852  0.20703125  0.24353027  0.09136963 -0.48217773 -0.52197266] 2   3 \n",
      "[-1.3017578  -0.00703049 -0.33911133  0.21716309  0.7553711   0.39257812] 4   1 \n",
      "[-1.4794922   0.05053711  0.19348145  0.9057617   0.21728516 -0.21044922] 3   2 \n",
      "[-1.5380859   0.0847168  -0.57373047  0.2927246   0.7495117   0.7138672 ] 4   4 Match 286\n",
      "\n",
      "[-0.24731445  0.24633789 -0.07025146 -0.09124756 -0.41723633 -0.05444336] 1   1 Match 287\n",
      "\n",
      "[-0.64453125  0.13232422  0.43725586  0.21899414 -0.3449707  -0.48608398] 2   1 \n",
      "[-0.15698242  0.00621033  0.27734375  0.09356689 -0.31884766 -0.5522461 ] 2   3 \n",
      "[-1.0078125   0.03866577 -0.01940918  0.29125977  0.21130371 -0.19128418] 3   0 \n",
      "[-1.4833984  -0.11450195 -0.42773438  0.33251953  1.1513672   0.82666016] 4   1 \n",
      "[-1.3818359  -0.04653931 -0.54052734  0.13964844  1.234375    0.76123047] 4   5 \n",
      "[-0.2578125   0.10406494  0.13891602 -0.20031738 -0.41723633 -0.39257812] 2   2 Match 288\n",
      "\n",
      "[-0.44018555  1.2529297  -0.50683594 -0.16503906 -0.6870117  -0.30688477] 1   3 \n",
      "[-0.4428711   0.60595703  0.06994629 -0.12194824 -0.2944336  -0.25805664] 1   4 \n",
      "[-0.70458984  0.13635254 -0.56396484 -0.18676758  0.6826172   0.16882324] 4   2 \n",
      "[-0.91503906  0.38085938 -0.04559326  0.11181641 -0.13952637  0.1083374 ] 1   1 Match 289\n",
      "\n",
      "[-0.9277344   0.26586914  0.00915527  0.39257812  0.02331543 -0.19238281] 3   3 Match 290\n",
      "\n",
      "[-1.6230469  -0.14978027 -0.24987793  0.546875    0.875       0.41967773] 4   4 Match 291\n",
      "\n",
      "[-0.8388672   0.24279785  0.07281494  0.5136719  -0.00456238 -0.27563477] 3   1 \n",
      "[-0.9555664   0.1282959   0.21459961  0.375      -0.10424805 -0.24108887] 3   3 Match 292\n",
      "\n",
      "[-1.7421875  -0.1262207  -0.4013672   0.43603516  0.9682617   0.8852539 ] 4   5 \n",
      "[-0.57128906  0.39916992  0.16040039  0.11328125 -0.1484375  -0.22741699] 1   1 Match 293\n",
      "\n",
      "[-1.609375   -0.05749512 -0.25341797  0.44067383  0.90527344  0.57373047] 4   1 \n",
      "[-1.6601562  -0.3166504  -0.02308655  0.8359375   0.6772461   0.1328125 ] 3   0 \n",
      "[-1.3642578   0.00296974 -0.6333008   0.08953857  0.9272461   0.9267578 ] 4   5 \n",
      "[-1.4003906  -0.05612183 -0.44848633  0.2121582   0.9902344   0.97802734] 4   3 \n",
      "[-0.48828125  0.29785156  0.35375977  0.07727051 -0.15527344 -0.3996582 ] 2   4 \n",
      "[-1.4296875   0.18481445 -0.33935547  0.26660156  0.81591797  0.5019531 ] 4   1 \n",
      "[-1.546875   -0.07940674 -0.0970459   0.7871094   0.56640625  0.19250488] 3   4 \n",
      "[-1.4238281   0.06390381 -0.44750977  0.18798828  1.1318359   0.6923828 ] 4   5 \n",
      "[-0.23364258  0.28466797  0.1427002  -0.29516602 -0.44213867 -0.3269043 ] 1   2 \n",
      "[-0.67333984  0.34277344 -0.1282959   0.09729004 -0.10015869 -0.08319092] 1   0 \n",
      "[-0.171875    0.9379883  -0.35742188 -0.28735352 -0.6665039  -0.19250488] 1   1 Match 294\n",
      "\n",
      "[-1.6494141  -0.35791016 -0.31689453  0.7163086   0.89501953  0.48583984] 4   4 Match 295\n",
      "\n",
      "[-1.5556641  -0.03659058 -0.46557617  0.21716309  1.1796875   0.7524414 ] 4   5 \n",
      "[-0.7675781   0.27001953  0.09033203  0.3774414   0.16003418 -0.31176758] 3   1 \n",
      "[-1.5712891  -0.07641602 -0.18029785  0.55566406  0.78222656  0.44311523] 4   5 \n",
      "[-0.0723877   0.08654785  0.17016602 -0.11309814 -0.38354492 -0.37524414] 2   3 \n",
      "[-1.5400391  -0.1295166  -0.42089844  0.3083496   1.0185547   0.8730469 ] 4   5 \n",
      "[-0.8183594   0.30859375 -0.07434082  0.00357628 -0.20495605  0.02398682] 1   1 Match 296\n",
      "\n",
      "[-0.77197266  0.11529541 -0.43554688  0.03182983  0.36401367  0.33935547] 4   5 \n",
      "[-1.3974609  -0.109375   -0.04434204  0.5205078   0.57958984  0.10980225] 4   1 \n",
      "[-0.5498047   0.33374023  0.21386719  0.08990479 -0.15515137 -0.34521484] 1   4 \n",
      "[-1.6376953 -0.2697754 -0.5053711  0.5361328  0.953125   0.8417969] 4   2 \n",
      "[-0.12536621  0.49926758 -0.06744385 -0.30395508 -0.2692871  -0.2536621 ] 1   5 \n",
      "[ 0.23242188  0.37304688  0.12768555 -0.41918945 -0.71484375 -0.5029297 ] 1   1 Match 297\n",
      "\n",
      "[-1.3203125  -0.04556274 -0.38720703  0.04138184  0.57128906  0.61816406] 5   5 Match 298\n",
      "\n",
      "[-1.6171875  -0.20703125 -0.48046875  0.41577148  0.8144531   0.93847656] 5   4 \n",
      "[-0.09649658  0.34326172  0.00663376 -0.19689941 -0.6503906  -0.40112305] 1   5 \n",
      "[-0.18713379  0.5214844  -0.125      -0.11053467 -0.5961914  -0.3544922 ] 1   4 \n",
      "[-0.44750977  0.3737793  -0.10168457 -0.08520508 -0.17297363 -0.0297699 ] 1   1 Match 299\n",
      "\n",
      "[-1.6376953   0.06652832 -0.05328369  0.66748047  0.6411133   0.14123535] 3   2 \n",
      "[-0.27685547  0.54296875  0.13598633  0.10174561 -0.41455078 -0.6225586 ] 1   5 \n",
      "[-1.5761719  -0.11480713 -0.24487305  0.49243164  1.015625    0.3540039 ] 4   1 \n",
      "[-1.7089844  -0.03866577 -0.24121094  0.7363281   0.8754883   0.27368164] 4   4 Match 300\n",
      "\n",
      "[-1.5810547  -0.04882812 -0.02281189  0.7758789   0.6230469   0.02716064] 3   4 \n",
      "[-1.2314453   0.09838867 -0.5258789  -0.09631348  0.6386719   0.8198242 ] 5   4 \n",
      "[-1.9375     -0.02426147 -0.43286133  0.5390625   0.97802734  0.7841797 ] 4   5 \n",
      "[-0.09326172  0.2322998   0.44848633  0.14208984 -0.33398438 -0.8095703 ] 2   3 \n",
      "[-1.4472656  -0.09960938 -0.54296875  0.41552734  0.9736328   0.93603516] 4   5 \n",
      "[-0.68603516  0.3095703   0.15405273  0.23620605  0.11730957 -0.32202148] 1   4 \n",
      "[-1.1201172   0.12054443  0.30981445  0.6953125   0.14916992 -0.4033203 ] 3   4 \n",
      "[-1.390625    0.04067993 -0.12719727  0.6347656   0.49682617 -0.01160431] 3   1 \n",
      "[-0.28759766  0.39233398 -0.22875977 -0.15075684 -0.49072266 -0.14050293] 1   0 \n",
      "[-0.5654297   0.24951172 -0.73046875 -0.35327148 -0.14123535  0.51171875] 5   4 \n",
      "[-1.5722656  -0.02185059 -0.28076172  0.68652344  0.5629883   0.27368164] 3   3 Match 301\n",
      "\n",
      "[-0.5576172   0.30639648  0.32714844  0.42041016 -0.20385742 -0.73779297] 3   3 Match 302\n",
      "\n",
      "[-0.16723633  0.23364258  0.28100586  0.07641602 -0.42773438 -0.52685547] 2   1 \n",
      "[-1.7285156  -0.1998291  -0.6225586   0.5493164   1.0136719   0.80908203] 4   4 Match 303\n",
      "\n",
      "[-0.7207031   0.03408813  0.02238464  0.43066406 -0.45288086 -0.19848633] 3   2 \n",
      "[-1.2998047   0.05578613  0.17321777  0.6816406   0.3894043  -0.1875    ] 3   3 Match 304\n",
      "\n",
      "[-1.3935547   0.00333405 -0.6870117   0.07855225  0.97265625  1.0673828 ] 5   4 \n",
      "[-0.9189453   0.19213867 -0.0186615  -0.00852966  0.11694336  0.02442932] 1   4 \n",
      "[-0.6767578   0.6254883   0.00203323  0.30541992 -0.14367676 -0.3972168 ] 1   4 \n",
      "[-0.1151123   0.203125    0.33813477  0.07531738 -0.31201172 -0.5019531 ] 2   3 \n",
      "[-1.53125    -0.19543457  0.00627136  0.64746094  0.5776367   0.20812988] 3   4 \n",
      "[-0.46801758  0.23803711 -0.14575195 -0.11364746 -0.10308838 -0.07092285] 1   4 \n",
      "[-0.20361328  0.14038086  0.06256104 -0.13000488 -0.1973877  -0.33154297] 1   2 \n",
      "[-1.7558594  -0.07757568 -0.28076172  0.42114258  0.9165039   0.75146484] 4   5 \n",
      "[-1.1464844   0.02513123  0.42993164  0.72998047  0.21154785 -0.57177734] 3   4 \n",
      "[ 0.13757324  0.22009277  0.3684082  -0.17443848 -0.6411133  -0.6777344 ] 2   1 \n",
      "[-0.91796875  0.30688477 -0.097229    0.0246582  -0.16540527  0.06365967] 1   1 Match 305\n",
      "\n",
      "[-1.5791016  -0.21289062 -0.43164062  0.47680664  0.98779297  0.70458984] 4   2 \n",
      "[-1.9121094  -0.2993164  -0.26513672  0.86279297  0.94189453  0.4724121 ] 4   5 \n",
      "[-1.2597656   0.11828613  0.29052734  0.66845703  0.20898438 -0.1459961 ] 3   3 Match 306\n",
      "\n",
      "[-1.6445312  -0.17651367 -0.36157227  0.46166992  1.0869141   0.7006836 ] 4   4 Match 307\n",
      "\n",
      "[-1.7128906  -0.05053711 -0.48217773  0.4177246   1.1279297   0.74902344] 4   3 \n",
      "[-0.8041992   0.13757324  0.48779297  0.61035156  0.11114502 -0.7709961 ] 3   4 \n",
      "[-0.73583984  0.3395996   0.06744385  0.25439453 -0.21679688 -0.16455078] 1   0 \n",
      "[-1.6416016  -0.05764771 -0.22937012  0.5776367   0.81347656  0.36938477] 4   3 \n",
      "[-0.54541016  0.3017578  -0.03485107  0.08874512 -0.40795898 -0.44677734] 1   1 Match 308\n",
      "\n",
      "[-1.6777344  -0.2854004  -0.16992188  0.8178711   0.88183594  0.20825195] 4   4 Match 309\n",
      "\n",
      "[-0.34765625  0.30664062 -0.26513672 -0.2932129  -0.32910156  0.04052734] 1   4 \n",
      "[-1.8476562  -0.11138916 -0.30859375  0.7270508   1.0419922   0.5834961 ] 4   4 Match 310\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.4355469  -0.1385498  -0.36791992  0.32348633  0.9140625   0.5942383 ] 4   4 Match 311\n",
      "\n",
      "[-0.85009766  0.25585938  0.2064209   0.18786621 -0.07818604 -0.1928711 ] 1   1 Match 312\n",
      "\n",
      "[-1.7167969  -0.15197754  0.09661865  0.9736328   0.38232422 -0.18395996] 3   2 \n",
      "[-1.5957031  -0.14807129 -0.28833008  0.6767578   0.69921875  0.44384766] 4   1 \n",
      "[-0.21069336  0.22460938  0.10083008 -0.21984863 -0.6176758  -0.25708008] 1   4 \n",
      "[-0.43701172 -0.06298828  0.24890137  0.06536865 -0.32348633 -0.3737793 ] 2   1 \n",
      "[-0.31396484  0.19519043  0.21435547  0.05688477 -0.328125   -0.50390625] 2   2 Match 313\n",
      "\n",
      "[-1.3164062   0.05044556 -0.06524658  0.4020996   0.5151367   0.19274902] 4   5 \n",
      "[-1.7509766  -0.19628906 -0.1706543   0.8417969   0.98291016  0.19812012] 4   2 \n",
      "[-1.5097656   0.08880615  0.15124512  0.66015625  0.03347778 -0.0526123 ] 3   3 Match 314\n",
      "\n",
      "[-1.5439453   0.07110596 -0.3762207   0.47485352  0.9399414   0.52197266] 4   4 Match 315\n",
      "\n",
      "[-0.82714844  0.13317871  0.48217773  0.44995117  0.14660645 -0.46777344] 2   5 \n",
      "[-1.7431641  -0.23657227 -0.3828125   0.6503906   1.0302734   0.66064453] 4   0 \n",
      "[-1.1943359   0.10021973 -0.6738281   0.07495117  1.2148438   0.9682617 ] 4   3 \n",
      "[-1.4521484   0.21691895 -0.2442627   0.5083008   0.66552734  0.2631836 ] 4   5 \n",
      "[-1.2773438   0.1505127  -0.36767578  0.15490723  0.7363281   0.40771484] 4   2 \n",
      "[ 0.20812988  0.48828125  0.07727051 -0.5644531  -0.6044922  -0.35498047] 1   3 \n",
      "[-0.703125    0.24902344  0.09234619  0.37451172  0.01757812 -0.34570312] 3   4 \n",
      "[-1.5683594  -0.00798798 -0.5415039   0.5205078   0.8779297   0.6621094 ] 4   5 \n",
      "[-0.62353516  0.16564941 -0.06195068  0.01667786 -0.06088257  0.01263428] 1   3 \n",
      "[-0.3088379   0.34106445  0.00888062 -0.10516357 -0.40039062 -0.19958496] 1   0 \n",
      "[-0.6875      0.09735107  0.65722656  0.4753418  -0.03013611 -0.6660156 ] 2   2 Match 316\n",
      "\n",
      "[-0.36694336  0.2401123   0.28955078  0.3071289  -0.22937012 -0.55810547] 3   1 \n",
      "[-1.3886719   0.15234375 -0.0770874   0.49951172  0.4477539   0.23815918] 3   2 \n",
      "[-0.18811035  0.14941406  0.29614258 -0.06216431 -0.18640137 -0.48535156] 2   1 \n",
      "[ 0.03726196  0.51660156  0.01927185 -0.28833008 -0.3659668  -0.32763672] 1   5 \n",
      "[-0.54003906  0.16259766  0.06408691 -0.01380157 -0.26464844 -0.22668457] 1   2 \n",
      "[-0.41796875  0.25561523  0.26049805  0.25170898 -0.14501953 -0.5073242 ] 2   0 \n",
      "[-1.1464844   0.11968994 -0.51464844 -0.007164    0.20324707  0.75683594] 5   2 \n",
      "[ 0.03100586  0.4650879  -0.1854248  -0.5004883  -0.40966797 -0.3100586 ] 1   5 \n",
      "[-0.9760742   0.1348877   0.39135742  0.6328125  -0.04440308 -0.60009766] 3   3 Match 317\n",
      "\n",
      "[-1.5117188   0.004776    0.00806427  0.5410156   0.4572754   0.14489746] 3   5 \n",
      "[-0.31323242  0.0881958   0.29077148  0.04785156 -0.04171753 -0.5361328 ] 2   1 \n",
      "[-0.7133789   0.23779297 -0.86865234 -0.19396973  0.35302734  1.0341797 ] 5   1 \n",
      "[-0.91064453  0.25170898  0.06854248  0.24914551 -0.1529541  -0.19689941] 1   5 \n",
      "[-0.62158203  0.41674805 -0.4807129  -0.21777344 -0.10870361  0.42163086] 5   1 \n",
      "[-5.4638672e-01  9.9755859e-01 -3.8378906e-01 -8.8262558e-04\n",
      " -5.7470703e-01 -2.5952148e-01] 1   1 Match 318\n",
      "\n",
      "[-0.7783203   0.27148438 -0.18640137  0.08984375  0.17138672 -0.06195068] 1   3 \n",
      "[-1.234375    0.14135742 -0.45410156  0.15698242  0.96435547  0.53222656] 4   4 Match 319\n",
      "\n",
      "[-0.23449707  0.6738281  -0.35107422 -0.17407227 -0.36132812 -0.19433594] 1   3 \n",
      "[-0.02294922  0.32006836  0.10174561 -0.17382812 -0.4411621  -0.48217773] 1   3 \n",
      "[-0.95703125  0.29833984 -0.16882324 -0.02180481  0.08636475  0.36132812] 5   4 \n",
      "[-1.4873047   0.10296631 -0.5395508   0.07574463  0.9580078   0.6508789 ] 4   5 \n",
      "[-0.38208008  0.5800781  -0.5136719  -0.51708984 -0.21496582 -0.02815247] 1   5 \n",
      "[ 0.17370605  0.32641602  0.07623291 -0.3605957  -0.5727539  -0.5073242 ] 1   5 \n",
      "[-1.4003906   0.25195312 -0.29370117  0.27612305  0.48535156  0.39086914] 4   2 \n",
      "[-1.5966797  -0.09796143 -0.5488281   0.3317871   1.03125     0.80859375] 4   4 Match 320\n",
      "\n",
      "[-0.44677734  0.22644043 -0.83154297 -0.0802002   0.53027344  0.94091797] 5   2 \n",
      "[-0.5595703   0.19042969  0.25341797  0.04748535 -0.08117676 -0.30493164] 2   4 \n",
      "[-0.4958496   0.37597656  0.05758667  0.00216484 -0.40283203 -0.14196777] 1   4 \n",
      "[-0.5756836   0.30639648  0.3347168   0.19470215 -0.43017578 -0.48413086] 2   2 Match 321\n",
      "\n",
      "[-1.6230469  -0.22619629 -0.07733154  0.7583008   0.66259766  0.07452393] 3   2 \n",
      "[ 0.05389404  0.04031372  0.06182861 -0.34716797 -0.35717773 -0.28881836] 2   2 Match 322\n",
      "\n",
      "[ 0.00400925  0.20458984  0.31420898 -0.08862305 -0.5566406  -0.56103516] 2   2 Match 323\n",
      "\n",
      "[-0.71875     0.41577148  0.1706543   0.3161621  -0.26757812 -0.4741211 ] 1   3 \n",
      "[-0.66308594  0.1875     -0.4350586  -0.06408691  0.12817383  0.21704102] 5   4 \n",
      "[ 0.30126953  0.4025879   0.01170349 -0.52685547 -0.52197266 -0.3388672 ] 1   0 \n",
      "[-0.7866211   0.15234375  0.47851562  0.5805664  -0.15112305 -0.7348633 ] 3   3 Match 324\n",
      "\n",
      "[-1.0302734   0.20861816 -0.3815918   0.22705078  0.45947266  0.2512207 ] 4   5 \n",
      "[-0.5493164   0.29101562  0.29467773  0.05554199 -0.18676758 -0.3881836 ] 2   3 \n",
      "[-0.8798828   0.2878418  -0.00652695  0.203125    0.07324219 -0.13183594] 1   1 Match 325\n",
      "\n",
      "[-1.5908203  -0.08972168 -0.17504883  0.5888672   0.82373047  0.27368164] 4   4 Match 326\n",
      "\n",
      "[-0.56103516 -0.10705566  0.5258789   0.43359375 -0.29956055 -0.6035156 ] 2   4 \n",
      "[-1.5966797  -0.25927734 -0.46728516  0.47021484  1.1142578   0.69189453] 4   3 \n",
      "[-1.1611328   0.18859863 -0.28320312  0.07373047  0.23547363  0.43676758] 5   5 Match 327\n",
      "\n",
      "[-0.94873047  0.27075195  0.00500107  0.19641113 -0.15771484 -0.17077637] 1   4 \n",
      "[-0.84228516  0.00712585  0.43481445  0.4855957  -0.10821533 -0.42285156] 3   4 \n",
      "[-1.0234375   0.05789185 -0.49902344 -0.06390381  0.72753906  0.8300781 ] 5   4 \n",
      "[ 0.21252441  0.2644043   0.16479492 -0.3647461  -0.57958984 -0.54589844] 1   2 \n",
      "[-0.70166016  0.14196777  0.1595459   0.07043457 -0.2286377  -0.05929565] 2   4 \n",
      "[-0.28222656  0.5131836   0.05209351 -0.11767578 -0.5107422  -0.4560547 ] 1   2 \n",
      "[-1.6416016  -0.25756836 -0.5209961   0.5239258   0.98583984  0.7529297 ] 4   5 \n",
      "[-1.3261719   0.13427734  0.05203247  0.7011719   0.47045898 -0.1538086 ] 3   2 \n",
      "[-1.4228516  -0.15148926 -0.18115234  0.52685547  0.42944336  0.22766113] 3   4 \n",
      "[-0.97998047  0.2434082   0.09979248  0.37670898  0.1586914  -0.14477539] 3   2 \n",
      "[-1.2353516  -0.01493835 -0.60595703  0.24560547  0.8305664   1.0849609 ] 5   5 Match 328\n",
      "\n",
      "[-1.3339844  -0.08935547 -0.62402344  0.25024414  0.9165039   0.91845703] 5   5 Match 329\n",
      "\n",
      "[-0.72265625  0.24133301  0.43774414  0.49438477  0.10015869 -0.53027344] 3   2 \n",
      "[-0.15625     0.19970703  0.32299805 -0.10418701 -0.49414062 -0.5961914 ] 2   0 \n",
      "[-0.69140625  0.26586914  0.00366592  0.0037899  -0.22644043 -0.03509521] 1   1 Match 330\n",
      "\n",
      "[-1.1328125  -0.04421997 -0.15942383  0.22912598  0.4736328   0.24255371] 4   4 Match 331\n",
      "\n",
      "[-0.27563477  0.20678711  0.03509521 -0.0184021  -0.3059082  -0.33789062] 1   2 \n",
      "[-0.63916016  0.37109375 -0.04342651 -0.13952637 -0.07617188 -0.06137085] 1   4 \n",
      "[-1.3945312   0.26635742 -0.11303711  0.3918457   0.6176758   0.34814453] 4   2 \n",
      "[ 0.28393555  0.31201172  0.1282959  -0.5078125  -0.58691406 -0.3935547 ] 1   5 \n",
      "[-1.6708984  -0.15661621 -0.08526611  0.5336914   0.6826172   0.56103516] 4   2 \n",
      "[-1.5224609  -0.20996094 -0.2763672   0.5839844   0.78125     0.38964844] 4   2 \n",
      "[-0.5571289   0.43432617 -0.43115234 -0.2631836  -0.13024902 -0.02085876] 1   1 Match 332\n",
      "\n",
      "[-1.5732422   0.06134033 -0.01161957  0.69970703  0.6723633  -0.00881195] 3   5 \n",
      "[ 0.10455322  0.50927734  0.1348877  -0.23254395 -0.61083984 -0.46289062] 1   4 \n",
      "[-1.0644531   0.32495117 -0.18737793  0.24902344  0.31079102  0.13232422] 1   1 Match 333\n",
      "\n",
      "[-0.01991272  0.53515625 -0.24414062 -0.36743164 -0.39648438 -0.26708984] 1   2 \n",
      "[-0.51416016  0.15893555  0.0670166   0.29589844 -0.0637207  -0.35986328] 3   3 Match 334\n",
      "\n",
      "[ 0.14648438  0.45288086  0.02279663 -0.32080078 -0.5004883  -0.6279297 ] 1   1 Match 335\n",
      "\n",
      "[-0.3137207   0.3239746  -0.58691406 -0.44921875 -0.00081015  0.32495117] 5   4 \n",
      "[-1.3427734   0.11932373  0.17382812  0.46240234  0.2800293  -0.00349045] 3   2 \n",
      "[-1.2519531   0.08251953 -0.40771484  0.1920166   1.0087891   0.59765625] 4   5 \n",
      "[-0.7758789   0.2421875   0.4248047   0.49682617 -0.06225586 -0.5708008 ] 3   5 \n",
      "[-0.7392578  -0.05014038  0.06567383  0.24377441  0.04891968 -0.11987305] 3   2 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.53466797  0.2788086   0.03695679  0.04266357 -0.50927734 -0.30200195] 1   2 \n",
      "[-1.6894531  -0.06945801 -0.0075531   0.96728516  0.5683594  -0.01358795] 3   4 \n",
      "[-1.46875    -0.10394287 -0.5263672   0.18249512  0.80859375  0.84716797] 5   4 \n",
      "[-0.7480469   0.3022461  -0.11376953  0.11016846 -0.3852539  -0.03207397] 1   1 Match 336\n",
      "\n",
      "[-3.77297401e-05  2.64160156e-01 -1.23291016e-01 -3.58886719e-01\n",
      " -3.75244141e-01 -1.75048828e-01] 1   0 \n",
      "[-1.4873047  -0.17077637 -0.31225586  0.49804688  0.8300781   0.47338867] 4   4 Match 337\n",
      "\n",
      "[-0.55029297  0.20336914  0.45336914  0.31396484 -0.28100586 -0.5073242 ] 2   3 \n",
      "[-1.1005859   0.3083496  -0.12695312  0.29589844 -0.0824585  -0.01942444] 1   1 Match 338\n",
      "\n",
      "[-0.8027344   0.18249512  0.35107422  0.42163086 -0.2277832  -0.4074707 ] 3   2 \n",
      "[-1.8320312  -0.13891602 -0.3071289   0.6064453   1.0429688   0.59814453] 4   3 \n",
      "[-1.6533203  -0.29174805 -0.30737305  0.7265625   0.9770508   0.515625  ] 4   3 \n",
      "[-0.9448242   0.08581543 -0.16564941  0.03598022  0.24182129  0.07788086] 4   4 Match 339\n",
      "\n",
      "[-0.35327148  0.3317871  -0.02104187 -0.4140625  -0.28515625  0.01085663] 1   5 \n",
      "[-0.19494629  0.47753906  0.02246094 -0.32958984 -0.55566406 -0.39697266] 1   3 \n",
      "[-0.74609375  0.0848999   0.3178711   0.48754883  0.09747314 -0.31689453] 3   2 \n",
      "[-0.1574707   0.28295898  0.2553711   0.05578613 -0.46069336 -0.6201172 ] 1   2 \n",
      "[-1.6640625   0.07940674 -0.33618164  0.48339844  0.86328125  0.5625    ] 4   4 Match 340\n",
      "\n",
      "[ 0.16015625  0.30322266 -0.01251221 -0.62158203 -0.45922852 -0.12658691] 1   1 Match 341\n",
      "\n",
      "[-0.14331055  1.0712891  -0.6796875  -0.38793945 -0.8671875  -0.18554688] 1   1 Match 342\n",
      "\n",
      "[-0.1619873   0.3918457   0.10473633 -0.12683105 -0.5776367  -0.46899414] 1   5 \n",
      "[-1.7294922  -0.3581543  -0.54003906  0.5932617   1.1064453   0.7529297 ] 4   5 \n",
      "[-1.1435547   0.07678223  0.16809082  0.66503906  0.2298584  -0.21203613] 3   3 Match 343\n",
      "\n",
      "[-1.2724609  -0.06933594  0.00185108  0.53125     0.27661133 -0.1328125 ] 3   2 \n",
      "[-1.1806641  -0.11322021 -0.55908203  0.17321777  0.73583984  0.9863281 ] 5   0 \n",
      "[-1.3056641   0.19482422  0.16601562  0.51708984  0.3408203  -0.0748291 ] 3   3 Match 344\n",
      "\n",
      "[-1.4814453   0.07659912 -0.1640625   0.3293457   0.7973633   0.43945312] 4   5 \n",
      "[ 0.0894165   0.15649414  0.36132812 -0.11340332 -0.51953125 -0.66503906] 2   4 \n",
      "[-1.6875      0.13964844 -0.16210938  0.71484375  0.7402344   0.13842773] 4   5 \n",
      "[ 0.10162354  0.31396484  0.14074707 -0.3017578  -0.68847656 -0.58447266] 1   3 \n",
      "[-0.98046875  0.12927246  0.39013672  0.42382812  0.11138916 -0.19995117] 3   2 \n",
      "[-0.2775879   0.17712402  0.10778809 -0.13684082 -0.26489258 -0.45532227] 1   2 \n",
      "[-1.296875    0.1472168   0.06427002  0.6044922   0.28881836 -0.1541748 ] 3   1 \n",
      "[-1.3193359   0.22607422 -0.28320312  0.21606445  0.578125    0.26293945] 4   1 \n",
      "[-1.0292969   0.15100098 -0.10760498  0.34985352 -0.11260986 -0.07806396] 3   3 Match 345\n",
      "\n",
      "[-1.2158203   0.19812012  0.1105957   0.46875     0.2536621   0.03384399] 3   5 \n",
      "[-0.09509277  0.35888672  0.1505127  -0.3239746  -0.57421875 -0.32006836] 1   4 \n",
      "[-1.3515625   0.03277588 -0.32299805  0.39453125  0.82470703  0.2800293 ] 4   0 \n",
      "[-1.5253906   0.11541748  0.04971313  0.76464844  0.36767578 -0.10571289] 3   2 \n",
      "[-1.6103516  -0.2565918  -0.31982422  0.5756836   0.98779297  0.5541992 ] 4   5 \n",
      "[-1.0810547  -0.02149963  0.40161133  0.62939453  0.18811035 -0.36669922] 3   4 \n",
      "[-0.38183594  0.32666016  0.08929443 -0.06726074 -0.17211914 -0.25390625] 1   2 \n",
      "[-0.47924805  0.23608398  0.38964844  0.2746582  -0.12023926 -0.5283203 ] 2   3 \n",
      "[-0.7739258   0.28149414  0.40039062  0.3857422  -0.23754883 -0.63183594] 2   2 Match 346\n",
      "\n",
      "[-1.1748047   0.17370605  0.19787598  0.66015625  0.05459595 -0.40942383] 3   3 Match 347\n",
      "\n",
      "[-1.1367188e+00 -3.2949448e-04  2.5341797e-01  4.1625977e-01\n",
      "  3.8500977e-01 -1.9616699e-01] 3   1 \n",
      "[-0.6870117   0.19946289  0.05923462  0.1640625  -0.21447754 -0.20129395] 1   2 \n",
      "[-1.1962891  -0.17382812  0.27612305  0.66845703 -0.03417969 -0.3305664 ] 3   5 \n",
      "[-0.02182007  0.31152344  0.2310791  -0.07391357 -0.46191406 -0.56689453] 1   5 \n",
      "[-1.1992188  -0.07720947  0.28466797  0.7763672   0.23376465 -0.30615234] 3   3 Match 348\n",
      "\n",
      "[-0.03424072  0.5473633   0.14770508 -0.22680664 -0.55371094 -0.65185547] 1   3 \n",
      "[-0.53027344  0.37329102 -0.08026123 -0.19433594 -0.3581543   0.01325226] 1   2 \n",
      "[-0.8388672   0.10406494  0.15246582  0.39404297  0.17236328 -0.2758789 ] 3   4 \n",
      "[-0.7163086   0.23388672  0.4177246   0.34155273  0.13549805 -0.43286133] 2   4 \n",
      "[-0.06994629  0.32421875  0.05810547 -0.14526367 -0.37353516 -0.42504883] 1   3 \n",
      "[-0.73876953  0.11199951  0.3395996   0.5361328  -0.11474609 -0.6381836 ] 3   1 \n",
      "[-1.2177734  -0.03649902  0.03118896  0.57958984  0.2253418   0.04345703] 3   3 Match 349\n",
      "\n",
      "[-1.09375     0.01480103  0.3935547   0.69921875  0.26635742 -0.57373047] 3   4 \n",
      "[-0.57666016 -0.00404358  0.40625     0.5986328   0.07183838 -0.6616211 ] 3   3 Match 350\n",
      "\n",
      "[-0.0982666   0.17297363  0.44335938  0.09588623 -0.5107422  -0.8076172 ] 2   2 Match 351\n",
      "\n",
      "[-0.26293945  0.20288086  0.3095703   0.0592041  -0.5180664  -0.5864258 ] 2   1 \n",
      "[-1.1601562   0.3720703  -0.1809082   0.06799316  0.1776123   0.33520508] 1   4 \n",
      "[-0.78515625  0.36206055  0.19897461  0.19763184  0.04330444 -0.19384766] 1   3 \n",
      "[-1.6865234  -0.18774414 -0.47314453  0.43554688  1.2451172   0.83984375] 4   4 Match 352\n",
      "\n",
      "[-0.14978027  0.33398438  0.35888672  0.0769043  -0.4741211  -0.8129883 ] 2   1 \n",
      "[-0.20410156  0.36083984 -0.05480957 -0.38354492 -0.60302734 -0.29077148] 1   2 \n",
      "[-0.38452148  0.20458984  0.12243652  0.09906006 -0.4975586  -0.39892578] 1   2 \n",
      "[-1.3261719  -0.05178833 -0.02255249  0.59521484  0.36987305  0.06298828] 3   0 \n",
      "[-1.2011719   0.09698486  0.00836945  0.1081543   0.35424805  0.23254395] 4   2 \n",
      "[-0.16223145  0.29711914  0.3034668  -0.13195801 -0.4741211  -0.46362305] 2   2 Match 353\n",
      "\n",
      "[-0.54785156  0.33911133  0.3791504   0.31958008  0.00731659 -0.59814453] 2   3 \n",
      "[-0.33154297  0.36108398  0.06964111 -0.01096344 -0.34277344 -0.07391357] 1   5 \n",
      "[-0.2265625   0.35961914 -0.12658691  0.03549194 -0.33691406 -0.35742188] 1   4 \n",
      "[-0.64697266  0.02853394  0.48510742  0.5449219  -0.2854004  -0.78027344] 3   2 \n",
      "[-1.4404297   0.01187134 -0.41088867  0.39282227  0.6430664   0.59765625] 4   3 \n",
      "[-0.31811523  0.50146484 -0.2133789  -0.32885742 -0.55810547 -0.16662598] 1   3 \n",
      "[-0.41967773  0.15722656  0.51904297  0.30908203 -0.27734375 -0.6713867 ] 2   4 \n",
      "[-1.2412109   0.19128418 -0.03515625  0.5957031   0.5541992  -0.11309814] 3   4 \n",
      "[-0.9013672   0.03451538  0.40063477  0.55859375  0.12469482 -0.46948242] 3   2 \n",
      "[-1.4355469   0.00831604 -0.35742188  0.20349121  1.0087891   0.7836914 ] 4   3 \n",
      "[-1.6455078   0.00305367 -0.2512207   0.50927734  0.8486328   0.6201172 ] 4   2 \n",
      "[-0.31201172  0.34228516  0.171875    0.27392578 -0.29492188 -0.6220703 ] 1   5 \n",
      "[-0.3684082   0.30493164 -0.06225586 -0.4086914  -0.2861328  -0.13085938] 1   1 Match 354\n",
      "\n",
      "[-1.4208984   0.0231781   0.38427734  0.7470703   0.25805664 -0.42651367] 3   2 \n",
      "[ 0.14465332  0.43701172 -0.06585693 -0.5541992  -0.6933594  -0.31884766] 1   0 \n",
      "[-0.7841797   0.26293945 -0.48364258  0.18347168  0.2421875   0.3737793 ] 5   0 \n",
      "[-0.46362305  0.1986084   0.1899414   0.04974365 -0.41967773 -0.19006348] 1   3 \n",
      "[-1.1748047   0.11083984  0.33447266  0.70166016  0.1977539  -0.41210938] 3   2 \n",
      "[-1.4677734  -0.13134766 -0.3618164   0.4736328   1.0439453   0.7260742 ] 4   1 \n",
      "[-0.48901367  0.56933594  0.1459961   0.0619812  -0.42626953 -0.5004883 ] 1   4 \n",
      "[ 0.44580078  0.38476562 -0.02737427 -0.5961914  -0.74609375 -0.48535156] 0   2 \n",
      "[ 0.2364502   0.24389648 -0.11480713 -0.41748047 -0.66552734 -0.18615723] 1   0 \n",
      "[-0.6904297   0.5263672  -0.15612793 -0.03494263 -0.13513184 -0.05627441] 1   1 Match 355\n",
      "\n",
      "355\n"
     ]
    }
   ],
   "source": [
    " Pred=[]\n",
    "\n",
    "countCorrect=0\n",
    "\n",
    "for row in range(TestModel_outputs.shape[0]):\n",
    "    outputs=TestModel_outputs[row]\n",
    "    #print(test.iloc[row,0])\n",
    "    print(outputs, end=' ')\n",
    "    \n",
    "    result=0\n",
    "    if outputs[0]<outputs[1]:result=1\n",
    "    if outputs[result]<outputs[2]:result=2\n",
    "    if outputs[result]<outputs[3]:result=3\n",
    "    if outputs[result]<outputs[4]:result=4\n",
    "    if outputs[result]<outputs[5]:result=5\n",
    "    Pred.append(result)\n",
    "    print(result, ' ',test.iloc[row,1], end=' ')\n",
    "    if result==test.iloc[row,1]:\n",
    "        countCorrect+=1\n",
    "        print('Match',countCorrect)\n",
    "    print('')\n",
    "\n",
    "print(countCorrect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  4  44  17  13  11   3]\n",
      " [  2 112  23  54  46  13]\n",
      " [  4  63  36  62  41   8]\n",
      " [  1  74  22  99  62   9]\n",
      " [  1  43  16  79  84  26]\n",
      " [  0  52   5  53  81  20]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    " \n",
    "print(metrics.confusion_matrix(test['labels'],Pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Pants       0.33      0.04      0.08        92\n",
      "       False       0.29      0.45      0.35       250\n",
      " Barely-True       0.30      0.17      0.22       214\n",
      "   Half-True       0.28      0.37      0.32       267\n",
      " Mostly-True       0.26      0.34      0.29       249\n",
      "        True       0.25      0.09      0.14       211\n",
      "\n",
      "    accuracy                           0.28      1283\n",
      "   macro avg       0.29      0.24      0.23      1283\n",
      "weighted avg       0.28      0.28      0.26      1283\n",
      "\n"
     ]
    }
   ],
   "source": [
    "target_names = ['Pants', 'False', 'Barely-True','Half-True','Mostly-True','True']\n",
    "\n",
    "print(metrics.classification_report(test['labels'], Pred,target_names =target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving...\n",
      "Saving Complete on 2020-05-01 09:43:39.161107 in: ./TunedModels/bert/bert-base-cased/Saves/\n"
     ]
    }
   ],
   "source": [
    "# saving the output of the models to CSVs\n",
    "#these are 1X6 classification vectors\n",
    "\n",
    "SavesDirectory='./TunedModels/'+model_class+'/'+model_version+\"/Saves/\"\n",
    "print('Saving...')\n",
    "trainOut = pd.DataFrame(data= TrainModel_outputs )\n",
    "trainOut.to_csv(SavesDirectory+'trainOut.tsv', sep='\\t',  index=False)\n",
    "\n",
    "evalOut = pd.DataFrame(data= EvalModel_outputs )\n",
    "evalOut.to_csv(SavesDirectory+'evalOut.tsv', sep='\\t',  index=False)\n",
    "\n",
    "testOut = pd.DataFrame(data= TestModel_outputs )\n",
    "testOut.to_csv(SavesDirectory+'testOut.tsv', sep='\\t',  index=False)\n",
    "\n",
    "print('Saving Complete on',datetime.now() ,'in:', SavesDirectory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "del(model)\n",
    "del(train,Eval,test)\n",
    "del(trainOut,evalOut,testOut)\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Adding the reputation vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section takes the output results from the transformer used above and uses it together with the speaker's reputation to enhance the classification.\n",
    "\n",
    "Before running this section it is suggested that you halt the program and start running it again from this cell.\n",
    "The neural net will likely have an error caused by some unreleased variable used by thr simple transformers library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PantsTotal</th>\n",
       "      <th>NotRealTotal</th>\n",
       "      <th>BarelyTotal</th>\n",
       "      <th>HalfTotal</th>\n",
       "      <th>MostlyTotal</th>\n",
       "      <th>Truths</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.005</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.533691</td>\n",
       "      <td>0.247803</td>\n",
       "      <td>-0.193848</td>\n",
       "      <td>-0.126465</td>\n",
       "      <td>-0.089417</td>\n",
       "      <td>0.063416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.095</td>\n",
       "      <td>0.160</td>\n",
       "      <td>0.170</td>\n",
       "      <td>0.290</td>\n",
       "      <td>0.165</td>\n",
       "      <td>0.165</td>\n",
       "      <td>-1.366211</td>\n",
       "      <td>-0.036041</td>\n",
       "      <td>0.095459</td>\n",
       "      <td>0.850098</td>\n",
       "      <td>0.082397</td>\n",
       "      <td>-0.231812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.005</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.040</td>\n",
       "      <td>0.010</td>\n",
       "      <td>-1.458984</td>\n",
       "      <td>-0.033417</td>\n",
       "      <td>0.235718</td>\n",
       "      <td>0.880859</td>\n",
       "      <td>0.232178</td>\n",
       "      <td>-0.344482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.005</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.040</td>\n",
       "      <td>0.010</td>\n",
       "      <td>-1.730469</td>\n",
       "      <td>-0.323242</td>\n",
       "      <td>-0.382812</td>\n",
       "      <td>0.850098</td>\n",
       "      <td>0.841309</td>\n",
       "      <td>0.455322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.035</td>\n",
       "      <td>0.145</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.345</td>\n",
       "      <td>0.380</td>\n",
       "      <td>0.365</td>\n",
       "      <td>-1.690430</td>\n",
       "      <td>-0.112061</td>\n",
       "      <td>-0.055603</td>\n",
       "      <td>0.768555</td>\n",
       "      <td>0.890137</td>\n",
       "      <td>0.208252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10264</th>\n",
       "      <td>0.005</td>\n",
       "      <td>0.030</td>\n",
       "      <td>0.070</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.020</td>\n",
       "      <td>-1.382812</td>\n",
       "      <td>-0.120605</td>\n",
       "      <td>0.241333</td>\n",
       "      <td>0.741211</td>\n",
       "      <td>0.223022</td>\n",
       "      <td>0.005543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10265</th>\n",
       "      <td>0.055</td>\n",
       "      <td>0.075</td>\n",
       "      <td>0.080</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.035</td>\n",
       "      <td>-1.219727</td>\n",
       "      <td>0.326416</td>\n",
       "      <td>0.036774</td>\n",
       "      <td>0.218262</td>\n",
       "      <td>0.193237</td>\n",
       "      <td>0.149048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10266</th>\n",
       "      <td>0.035</td>\n",
       "      <td>0.115</td>\n",
       "      <td>0.140</td>\n",
       "      <td>0.190</td>\n",
       "      <td>0.170</td>\n",
       "      <td>0.075</td>\n",
       "      <td>-1.498047</td>\n",
       "      <td>-0.096313</td>\n",
       "      <td>0.275879</td>\n",
       "      <td>0.799316</td>\n",
       "      <td>0.517090</td>\n",
       "      <td>-0.206299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10267</th>\n",
       "      <td>0.305</td>\n",
       "      <td>0.570</td>\n",
       "      <td>0.315</td>\n",
       "      <td>0.255</td>\n",
       "      <td>0.185</td>\n",
       "      <td>0.070</td>\n",
       "      <td>-1.075195</td>\n",
       "      <td>0.350342</td>\n",
       "      <td>-0.005589</td>\n",
       "      <td>0.159546</td>\n",
       "      <td>-0.111633</td>\n",
       "      <td>0.172729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10268</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000806</td>\n",
       "      <td>0.191650</td>\n",
       "      <td>0.352539</td>\n",
       "      <td>-0.222046</td>\n",
       "      <td>-0.408691</td>\n",
       "      <td>-0.510742</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10269 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       PantsTotal  NotRealTotal  BarelyTotal  HalfTotal  MostlyTotal  Truths  \\\n",
       "0           0.005         0.000        0.000      0.000        0.000   0.000   \n",
       "1           0.095         0.160        0.170      0.290        0.165   0.165   \n",
       "2           0.005         0.010        0.005      0.015        0.040   0.010   \n",
       "3           0.005         0.010        0.005      0.015        0.040   0.010   \n",
       "4           0.035         0.145        0.200      0.345        0.380   0.365   \n",
       "...           ...           ...          ...        ...          ...     ...   \n",
       "10264       0.005         0.030        0.070      0.050        0.050   0.020   \n",
       "10265       0.055         0.075        0.080      0.100        0.050   0.035   \n",
       "10266       0.035         0.115        0.140      0.190        0.170   0.075   \n",
       "10267       0.305         0.570        0.315      0.255        0.185   0.070   \n",
       "10268       0.000         0.005        0.000      0.000        0.000   0.000   \n",
       "\n",
       "              0         1         2         3         4         5  \n",
       "0     -0.533691  0.247803 -0.193848 -0.126465 -0.089417  0.063416  \n",
       "1     -1.366211 -0.036041  0.095459  0.850098  0.082397 -0.231812  \n",
       "2     -1.458984 -0.033417  0.235718  0.880859  0.232178 -0.344482  \n",
       "3     -1.730469 -0.323242 -0.382812  0.850098  0.841309  0.455322  \n",
       "4     -1.690430 -0.112061 -0.055603  0.768555  0.890137  0.208252  \n",
       "...         ...       ...       ...       ...       ...       ...  \n",
       "10264 -1.382812 -0.120605  0.241333  0.741211  0.223022  0.005543  \n",
       "10265 -1.219727  0.326416  0.036774  0.218262  0.193237  0.149048  \n",
       "10266 -1.498047 -0.096313  0.275879  0.799316  0.517090 -0.206299  \n",
       "10267 -1.075195  0.350342 -0.005589  0.159546 -0.111633  0.172729  \n",
       "10268  0.000806  0.191650  0.352539 -0.222046 -0.408691 -0.510742  \n",
       "\n",
       "[10269 rows x 12 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "train=pd.read_excel('trainReputation.xlsx' )\n",
    "train=train.iloc[:,:-2].astype(float)\n",
    "train=train/200  #for scaling\n",
    "#train\n",
    "\n",
    "model_class='bert'  # bert or roberta or albert\n",
    "model_version='bert-base-cased' #bert-base-cased, roberta-base, roberta-large, albert-base-v2 OR albert-large-v2\n",
    "SavesDirectory='./TunedModels/'+model_class+'/'+model_version+\"/Saves/\"\n",
    "TF_Output=pd.read_csv( SavesDirectory+'trainOut.tsv', sep='\\t')\n",
    "\n",
    "train=pd.concat([train,TF_Output], axis=1)\n",
    "\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10264</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10265</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10266</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10267</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10268</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10269 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0  1  2  3  4  5\n",
       "0      1  0  0  0  0  0\n",
       "1      0  0  0  1  0  0\n",
       "2      0  0  0  0  1  0\n",
       "3      0  0  0  0  1  0\n",
       "4      0  0  0  0  0  1\n",
       "...   .. .. .. .. .. ..\n",
       "10264  0  0  0  0  1  0\n",
       "10265  0  0  0  0  0  1\n",
       "10266  0  0  0  1  0  0\n",
       "10267  0  1  0  0  0  0\n",
       "10268  0  1  0  0  0  0\n",
       "\n",
       "[10269 rows x 6 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TrainLables=pd.read_excel('trainReputation.xlsx' )\n",
    "TrainLables=TrainLables.iloc[:,-1] \n",
    "\n",
    "TrainLables=pd.get_dummies(TrainLables)\n",
    "TrainLables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0050,  0.0000,  0.0000,  ..., -0.1265, -0.0894,  0.0634],\n",
       "        [ 0.0950,  0.1600,  0.1700,  ...,  0.8501,  0.0824, -0.2318],\n",
       "        [ 0.0050,  0.0100,  0.0050,  ...,  0.8809,  0.2322, -0.3445],\n",
       "        ...,\n",
       "        [ 0.0350,  0.1150,  0.1400,  ...,  0.7993,  0.5171, -0.2063],\n",
       "        [ 0.3050,  0.5700,  0.3150,  ...,  0.1595, -0.1116,  0.1727],\n",
       "        [ 0.0000,  0.0050,  0.0000,  ..., -0.2220, -0.4087, -0.5107]],\n",
       "       dtype=torch.float64)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input=torch.tensor(train.values)\n",
    "input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 1., 0., 0.],\n",
       "        [0., 0., 0., 0., 1., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0., 0., 0.],\n",
       "        [0., 1., 0., 0., 0., 0.]], dtype=torch.float64)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets=torch.tensor(TrainLables.astype(float).values)\n",
    "\n",
    "targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input size: 12\n",
      "output size: 6\n"
     ]
    }
   ],
   "source": [
    " \n",
    "size= torch.tensor(input[0].size())\n",
    "InputSize=size.item()\n",
    "\n",
    "OutputSize=torch.tensor(targets[0].size()).item()\n",
    "\n",
    "print('input size:', InputSize)\n",
    "print('output size:', OutputSize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Net(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "         \n",
    "        # an affine operation: y = Wx + b\n",
    "        self.fc1 = nn.Linear(InputSize, 24)  # input size 32\n",
    "        self.fc2 = nn.Linear(24, 12)\n",
    "        self.fc3 = nn.Linear(12, OutputSize)  #classifies 'outputsize' different classes\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.tanh(self.fc1(x))\n",
    "        x = torch.tanh(self.fc2(x)) \n",
    "        x = torch.tanh(self.fc3(x)).double()\n",
    "        return x\n",
    "\n",
    "    \n",
    "\n",
    "#now we use it\n",
    "\n",
    "net = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here we  setup the neural network parameters\n",
    "# pick an optimizer (Simple Gradient Descent)\n",
    "\n",
    "learning_rate = 9e-4\n",
    "criterion = nn.MSELoss()  #computes the loss Function\n",
    "\n",
    "import torch.optim as optim\n",
    "\n",
    "# creating optimizer\n",
    "#optimizer = optim.SGD(net.parameters(), lr=learning_rate)\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor(0.1261, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 0\n",
      "Loss: tensor(0.1261, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1\n",
      "Loss: tensor(0.1261, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2\n",
      "Loss: tensor(0.1261, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3\n",
      "Loss: tensor(0.1261, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4\n",
      "Loss: tensor(0.1261, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5\n",
      "Loss: tensor(0.1261, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6\n",
      "Loss: tensor(0.1261, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7\n",
      "Loss: tensor(0.1261, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8\n",
      "Loss: tensor(0.1261, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 9\n",
      "Loss: tensor(0.1261, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 10\n",
      "Loss: tensor(0.1261, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 11\n",
      "Loss: tensor(0.1261, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 12\n",
      "Loss: tensor(0.1261, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 13\n",
      "Loss: tensor(0.1261, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 14\n",
      "Loss: tensor(0.1261, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 15\n",
      "Loss: tensor(0.1261, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 16\n",
      "Loss: tensor(0.1261, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 17\n",
      "Loss: tensor(0.1261, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 18\n",
      "Loss: tensor(0.1261, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 19\n",
      "Loss: tensor(0.1261, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 20\n",
      "Loss: tensor(0.1261, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 21\n",
      "Loss: tensor(0.1261, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 22\n",
      "Loss: tensor(0.1261, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 23\n",
      "Loss: tensor(0.1261, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 24\n",
      "Loss: tensor(0.1261, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 25\n",
      "Loss: tensor(0.1261, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 26\n",
      "Loss: tensor(0.1261, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 27\n",
      "Loss: tensor(0.1261, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 28\n",
      "Loss: tensor(0.1261, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 29\n",
      "Loss: tensor(0.1261, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 30\n",
      "Loss: tensor(0.1261, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 31\n",
      "Loss: tensor(0.1261, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 32\n",
      "Loss: tensor(0.1260, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 33\n",
      "Loss: tensor(0.1260, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 34\n",
      "Loss: tensor(0.1260, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 35\n",
      "Loss: tensor(0.1260, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 36\n",
      "Loss: tensor(0.1260, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 37\n",
      "Loss: tensor(0.1260, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 38\n",
      "Loss: tensor(0.1260, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 39\n",
      "Loss: tensor(0.1260, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 40\n",
      "Loss: tensor(0.1260, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 41\n",
      "Loss: tensor(0.1260, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 42\n",
      "Loss: tensor(0.1260, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 43\n",
      "Loss: tensor(0.1260, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 44\n",
      "Loss: tensor(0.1260, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 45\n",
      "Loss: tensor(0.1260, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 46\n",
      "Loss: tensor(0.1260, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 47\n",
      "Loss: tensor(0.1260, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 48\n",
      "Loss: tensor(0.1260, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 49\n",
      "Loss: tensor(0.1260, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 50\n",
      "Loss: tensor(0.1260, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 51\n",
      "Loss: tensor(0.1260, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 52\n",
      "Loss: tensor(0.1260, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 53\n",
      "Loss: tensor(0.1260, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 54\n",
      "Loss: tensor(0.1260, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 55\n",
      "Loss: tensor(0.1260, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 56\n",
      "Loss: tensor(0.1260, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 57\n",
      "Loss: tensor(0.1260, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 58\n",
      "Loss: tensor(0.1260, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 59\n",
      "Loss: tensor(0.1260, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 60\n",
      "Loss: tensor(0.1260, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 61\n",
      "Loss: tensor(0.1260, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 62\n",
      "Loss: tensor(0.1260, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 63\n",
      "Loss: tensor(0.1260, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 64\n",
      "Loss: tensor(0.1260, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 65\n",
      "Loss: tensor(0.1260, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 66\n",
      "Loss: tensor(0.1260, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 67\n",
      "Loss: tensor(0.1260, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 68\n",
      "Loss: tensor(0.1260, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 69\n",
      "Loss: tensor(0.1260, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 70\n",
      "Loss: tensor(0.1260, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 71\n",
      "Loss: tensor(0.1260, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 72\n",
      "Loss: tensor(0.1260, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 73\n",
      "Loss: tensor(0.1260, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 74\n",
      "Loss: tensor(0.1260, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 75\n",
      "Loss: tensor(0.1260, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 76\n",
      "Loss: tensor(0.1260, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 77\n",
      "Loss: tensor(0.1260, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 78\n",
      "Loss: tensor(0.1260, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 79\n",
      "Loss: tensor(0.1260, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 80\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 81\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 82\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 83\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 84\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 85\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 86\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 87\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 88\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 89\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 90\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 91\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 92\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 93\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 94\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 95\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 96\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 97\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 98\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 99\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 100\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 101\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 102\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 103\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 104\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 105\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 106\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 107\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 108\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 109\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 110\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 111\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 112\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 113\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 114\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 115\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 116\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 117\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 118\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 119\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 120\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 121\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 122\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 123\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 124\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 125\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 126\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 127\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 128\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 129\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 130\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 131\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 132\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 133\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 134\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 135\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 136\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 137\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 138\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 139\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 140\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 141\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 142\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 143\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 144\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 145\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 146\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 147\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 148\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 149\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 150\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 151\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 152\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 153\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 154\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 155\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 156\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 157\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 158\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 159\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 160\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 161\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 162\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 163\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 164\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 165\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 166\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 167\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 168\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 169\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 170\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 171\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 172\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 173\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 174\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 175\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 176\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 177\n",
      "Loss: tensor(0.1257, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 178\n",
      "Loss: tensor(0.1257, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 179\n",
      "Loss: tensor(0.1257, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 180\n",
      "Loss: tensor(0.1257, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 181\n",
      "Loss: tensor(0.1257, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 182\n",
      "Loss: tensor(0.1257, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 183\n",
      "Loss: tensor(0.1257, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 184\n",
      "Loss: tensor(0.1257, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 185\n",
      "Loss: tensor(0.1257, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 186\n",
      "Loss: tensor(0.1257, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 187\n",
      "Loss: tensor(0.1257, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 188\n",
      "Loss: tensor(0.1257, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 189\n",
      "Loss: tensor(0.1257, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 190\n",
      "Loss: tensor(0.1257, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 191\n",
      "Loss: tensor(0.1257, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 192\n",
      "Loss: tensor(0.1257, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 193\n",
      "Loss: tensor(0.1257, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 194\n",
      "Loss: tensor(0.1257, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 195\n",
      "Loss: tensor(0.1257, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 196\n",
      "Loss: tensor(0.1257, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 197\n",
      "Loss: tensor(0.1257, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 198\n",
      "Loss: tensor(0.1257, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 199\n",
      "Loss: tensor(0.1257, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 200\n",
      "Loss: tensor(0.1257, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 201\n",
      "Loss: tensor(0.1257, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 202\n",
      "Loss: tensor(0.1257, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 203\n",
      "Loss: tensor(0.1257, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 204\n",
      "Loss: tensor(0.1257, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 205\n",
      "Loss: tensor(0.1257, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 206\n",
      "Loss: tensor(0.1257, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 207\n",
      "Loss: tensor(0.1257, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 208\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor(0.1257, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 209\n",
      "Loss: tensor(0.1257, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 210\n",
      "Loss: tensor(0.1257, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 211\n",
      "Loss: tensor(0.1257, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 212\n",
      "Loss: tensor(0.1257, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 213\n",
      "Loss: tensor(0.1257, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 214\n",
      "Loss: tensor(0.1257, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 215\n",
      "Loss: tensor(0.1257, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 216\n",
      "Loss: tensor(0.1257, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 217\n",
      "Loss: tensor(0.1257, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 218\n",
      "Loss: tensor(0.1257, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 219\n",
      "Loss: tensor(0.1257, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 220\n",
      "Loss: tensor(0.1257, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 221\n",
      "Loss: tensor(0.1257, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 222\n",
      "Loss: tensor(0.1257, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 223\n",
      "Loss: tensor(0.1257, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 224\n",
      "Loss: tensor(0.1257, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 225\n",
      "Loss: tensor(0.1256, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 226\n",
      "Loss: tensor(0.1256, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 227\n",
      "Loss: tensor(0.1256, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 228\n",
      "Loss: tensor(0.1256, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 229\n",
      "Loss: tensor(0.1256, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 230\n",
      "Loss: tensor(0.1256, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 231\n",
      "Loss: tensor(0.1256, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 232\n",
      "Loss: tensor(0.1256, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 233\n",
      "Loss: tensor(0.1256, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 234\n",
      "Loss: tensor(0.1256, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 235\n",
      "Loss: tensor(0.1256, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 236\n",
      "Loss: tensor(0.1256, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 237\n",
      "Loss: tensor(0.1256, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 238\n",
      "Loss: tensor(0.1256, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 239\n",
      "Loss: tensor(0.1256, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 240\n",
      "Loss: tensor(0.1256, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 241\n",
      "Loss: tensor(0.1256, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 242\n",
      "Loss: tensor(0.1256, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 243\n",
      "Loss: tensor(0.1256, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 244\n",
      "Loss: tensor(0.1256, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 245\n",
      "Loss: tensor(0.1256, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 246\n",
      "Loss: tensor(0.1256, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 247\n",
      "Loss: tensor(0.1256, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 248\n",
      "Loss: tensor(0.1256, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 249\n",
      "Loss: tensor(0.1256, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 250\n",
      "Loss: tensor(0.1256, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 251\n",
      "Loss: tensor(0.1256, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 252\n",
      "Loss: tensor(0.1256, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 253\n",
      "Loss: tensor(0.1256, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 254\n",
      "Loss: tensor(0.1256, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 255\n",
      "Loss: tensor(0.1256, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 256\n",
      "Loss: tensor(0.1256, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 257\n",
      "Loss: tensor(0.1256, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 258\n",
      "Loss: tensor(0.1256, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 259\n",
      "Loss: tensor(0.1256, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 260\n",
      "Loss: tensor(0.1256, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 261\n",
      "Loss: tensor(0.1256, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 262\n",
      "Loss: tensor(0.1256, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 263\n",
      "Loss: tensor(0.1256, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 264\n",
      "Loss: tensor(0.1256, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 265\n",
      "Loss: tensor(0.1256, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 266\n",
      "Loss: tensor(0.1256, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 267\n",
      "Loss: tensor(0.1256, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 268\n",
      "Loss: tensor(0.1256, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 269\n",
      "Loss: tensor(0.1256, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 270\n",
      "Loss: tensor(0.1256, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 271\n",
      "Loss: tensor(0.1256, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 272\n",
      "Loss: tensor(0.1255, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 273\n",
      "Loss: tensor(0.1255, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 274\n",
      "Loss: tensor(0.1255, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 275\n",
      "Loss: tensor(0.1255, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 276\n",
      "Loss: tensor(0.1255, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 277\n",
      "Loss: tensor(0.1255, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 278\n",
      "Loss: tensor(0.1255, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 279\n",
      "Loss: tensor(0.1255, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 280\n",
      "Loss: tensor(0.1255, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 281\n",
      "Loss: tensor(0.1255, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 282\n",
      "Loss: tensor(0.1255, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 283\n",
      "Loss: tensor(0.1255, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 284\n",
      "Loss: tensor(0.1255, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 285\n",
      "Loss: tensor(0.1255, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 286\n",
      "Loss: tensor(0.1255, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 287\n",
      "Loss: tensor(0.1255, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 288\n",
      "Loss: tensor(0.1255, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 289\n",
      "Loss: tensor(0.1255, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 290\n",
      "Loss: tensor(0.1255, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 291\n",
      "Loss: tensor(0.1255, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 292\n",
      "Loss: tensor(0.1255, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 293\n",
      "Loss: tensor(0.1255, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 294\n",
      "Loss: tensor(0.1255, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 295\n",
      "Loss: tensor(0.1255, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 296\n",
      "Loss: tensor(0.1255, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 297\n",
      "Loss: tensor(0.1255, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 298\n",
      "Loss: tensor(0.1255, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 299\n",
      "Loss: tensor(0.1255, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 300\n",
      "Loss: tensor(0.1255, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 301\n",
      "Loss: tensor(0.1255, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 302\n",
      "Loss: tensor(0.1255, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 303\n",
      "Loss: tensor(0.1255, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 304\n",
      "Loss: tensor(0.1255, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 305\n",
      "Loss: tensor(0.1255, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 306\n",
      "Loss: tensor(0.1255, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 307\n",
      "Loss: tensor(0.1255, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 308\n",
      "Loss: tensor(0.1255, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 309\n",
      "Loss: tensor(0.1255, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 310\n",
      "Loss: tensor(0.1255, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 311\n",
      "Loss: tensor(0.1255, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 312\n",
      "Loss: tensor(0.1255, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 313\n",
      "Loss: tensor(0.1255, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 314\n",
      "Loss: tensor(0.1255, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 315\n",
      "Loss: tensor(0.1255, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 316\n",
      "Loss: tensor(0.1255, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 317\n",
      "Loss: tensor(0.1255, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 318\n",
      "Loss: tensor(0.1255, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 319\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor(0.1254, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 320\n",
      "Loss: tensor(0.1254, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 321\n",
      "Loss: tensor(0.1254, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 322\n",
      "Loss: tensor(0.1254, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 323\n",
      "Loss: tensor(0.1254, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 324\n",
      "Loss: tensor(0.1254, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 325\n",
      "Loss: tensor(0.1254, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 326\n",
      "Loss: tensor(0.1254, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 327\n",
      "Loss: tensor(0.1254, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 328\n",
      "Loss: tensor(0.1254, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 329\n",
      "Loss: tensor(0.1254, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 330\n",
      "Loss: tensor(0.1254, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 331\n",
      "Loss: tensor(0.1254, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 332\n",
      "Loss: tensor(0.1254, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 333\n",
      "Loss: tensor(0.1254, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 334\n",
      "Loss: tensor(0.1254, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 335\n",
      "Loss: tensor(0.1254, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 336\n",
      "Loss: tensor(0.1254, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 337\n",
      "Loss: tensor(0.1254, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 338\n",
      "Loss: tensor(0.1254, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 339\n",
      "Loss: tensor(0.1254, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 340\n",
      "Loss: tensor(0.1254, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 341\n",
      "Loss: tensor(0.1254, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 342\n",
      "Loss: tensor(0.1254, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 343\n",
      "Loss: tensor(0.1254, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 344\n",
      "Loss: tensor(0.1254, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 345\n",
      "Loss: tensor(0.1254, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 346\n",
      "Loss: tensor(0.1254, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 347\n",
      "Loss: tensor(0.1254, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 348\n",
      "Loss: tensor(0.1254, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 349\n",
      "Loss: tensor(0.1254, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 350\n",
      "Loss: tensor(0.1254, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 351\n",
      "Loss: tensor(0.1254, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 352\n",
      "Loss: tensor(0.1254, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 353\n",
      "Loss: tensor(0.1254, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 354\n",
      "Loss: tensor(0.1254, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 355\n",
      "Loss: tensor(0.1254, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 356\n",
      "Loss: tensor(0.1254, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 357\n",
      "Loss: tensor(0.1254, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 358\n",
      "Loss: tensor(0.1254, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 359\n",
      "Loss: tensor(0.1254, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 360\n",
      "Loss: tensor(0.1254, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 361\n",
      "Loss: tensor(0.1254, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 362\n",
      "Loss: tensor(0.1254, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 363\n",
      "Loss: tensor(0.1254, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 364\n",
      "Loss: tensor(0.1254, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 365\n",
      "Loss: tensor(0.1253, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 366\n",
      "Loss: tensor(0.1253, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 367\n",
      "Loss: tensor(0.1253, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 368\n",
      "Loss: tensor(0.1253, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 369\n",
      "Loss: tensor(0.1253, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 370\n",
      "Loss: tensor(0.1253, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 371\n",
      "Loss: tensor(0.1253, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 372\n",
      "Loss: tensor(0.1253, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 373\n",
      "Loss: tensor(0.1253, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 374\n",
      "Loss: tensor(0.1253, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 375\n",
      "Loss: tensor(0.1253, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 376\n",
      "Loss: tensor(0.1253, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 377\n",
      "Loss: tensor(0.1253, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 378\n",
      "Loss: tensor(0.1253, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 379\n",
      "Loss: tensor(0.1253, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 380\n",
      "Loss: tensor(0.1253, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 381\n",
      "Loss: tensor(0.1253, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 382\n",
      "Loss: tensor(0.1253, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 383\n",
      "Loss: tensor(0.1253, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 384\n",
      "Loss: tensor(0.1253, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 385\n",
      "Loss: tensor(0.1253, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 386\n",
      "Loss: tensor(0.1253, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 387\n",
      "Loss: tensor(0.1253, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 388\n",
      "Loss: tensor(0.1253, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 389\n",
      "Loss: tensor(0.1253, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 390\n",
      "Loss: tensor(0.1253, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 391\n",
      "Loss: tensor(0.1253, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 392\n",
      "Loss: tensor(0.1253, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 393\n",
      "Loss: tensor(0.1253, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 394\n",
      "Loss: tensor(0.1253, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 395\n",
      "Loss: tensor(0.1253, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 396\n",
      "Loss: tensor(0.1253, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 397\n",
      "Loss: tensor(0.1253, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 398\n",
      "Loss: tensor(0.1253, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 399\n",
      "Loss: tensor(0.1253, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 400\n",
      "Loss: tensor(0.1253, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 401\n",
      "Loss: tensor(0.1253, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 402\n",
      "Loss: tensor(0.1253, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 403\n",
      "Loss: tensor(0.1253, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 404\n",
      "Loss: tensor(0.1253, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 405\n",
      "Loss: tensor(0.1253, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 406\n",
      "Loss: tensor(0.1253, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 407\n",
      "Loss: tensor(0.1253, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 408\n",
      "Loss: tensor(0.1253, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 409\n",
      "Loss: tensor(0.1253, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 410\n",
      "Loss: tensor(0.1252, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 411\n",
      "Loss: tensor(0.1252, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 412\n",
      "Loss: tensor(0.1252, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 413\n",
      "Loss: tensor(0.1252, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 414\n",
      "Loss: tensor(0.1252, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 415\n",
      "Loss: tensor(0.1252, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 416\n",
      "Loss: tensor(0.1252, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 417\n",
      "Loss: tensor(0.1252, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 418\n",
      "Loss: tensor(0.1252, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 419\n",
      "Loss: tensor(0.1252, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 420\n",
      "Loss: tensor(0.1252, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 421\n",
      "Loss: tensor(0.1252, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 422\n",
      "Loss: tensor(0.1252, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 423\n",
      "Loss: tensor(0.1252, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 424\n",
      "Loss: tensor(0.1252, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 425\n",
      "Loss: tensor(0.1252, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 426\n",
      "Loss: tensor(0.1252, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 427\n",
      "Loss: tensor(0.1252, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 428\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor(0.1252, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 429\n",
      "Loss: tensor(0.1252, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 430\n",
      "Loss: tensor(0.1252, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 431\n",
      "Loss: tensor(0.1252, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 432\n",
      "Loss: tensor(0.1252, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 433\n",
      "Loss: tensor(0.1252, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 434\n",
      "Loss: tensor(0.1252, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 435\n",
      "Loss: tensor(0.1252, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 436\n",
      "Loss: tensor(0.1252, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 437\n",
      "Loss: tensor(0.1252, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 438\n",
      "Loss: tensor(0.1252, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 439\n",
      "Loss: tensor(0.1252, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 440\n",
      "Loss: tensor(0.1252, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 441\n",
      "Loss: tensor(0.1252, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 442\n",
      "Loss: tensor(0.1252, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 443\n",
      "Loss: tensor(0.1252, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 444\n",
      "Loss: tensor(0.1252, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 445\n",
      "Loss: tensor(0.1252, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 446\n",
      "Loss: tensor(0.1252, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 447\n",
      "Loss: tensor(0.1252, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 448\n",
      "Loss: tensor(0.1252, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 449\n",
      "Loss: tensor(0.1252, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 450\n",
      "Loss: tensor(0.1252, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 451\n",
      "Loss: tensor(0.1252, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 452\n",
      "Loss: tensor(0.1252, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 453\n",
      "Loss: tensor(0.1251, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 454\n",
      "Loss: tensor(0.1251, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 455\n",
      "Loss: tensor(0.1251, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 456\n",
      "Loss: tensor(0.1251, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 457\n",
      "Loss: tensor(0.1251, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 458\n",
      "Loss: tensor(0.1251, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 459\n",
      "Loss: tensor(0.1251, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 460\n",
      "Loss: tensor(0.1251, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 461\n",
      "Loss: tensor(0.1251, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 462\n",
      "Loss: tensor(0.1251, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 463\n",
      "Loss: tensor(0.1251, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 464\n",
      "Loss: tensor(0.1251, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 465\n",
      "Loss: tensor(0.1251, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 466\n",
      "Loss: tensor(0.1251, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 467\n",
      "Loss: tensor(0.1251, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 468\n",
      "Loss: tensor(0.1251, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 469\n",
      "Loss: tensor(0.1251, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 470\n",
      "Loss: tensor(0.1251, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 471\n",
      "Loss: tensor(0.1251, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 472\n",
      "Loss: tensor(0.1251, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 473\n",
      "Loss: tensor(0.1251, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 474\n",
      "Loss: tensor(0.1251, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 475\n",
      "Loss: tensor(0.1251, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 476\n",
      "Loss: tensor(0.1251, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 477\n",
      "Loss: tensor(0.1251, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 478\n",
      "Loss: tensor(0.1251, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 479\n",
      "Loss: tensor(0.1251, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 480\n",
      "Loss: tensor(0.1251, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 481\n",
      "Loss: tensor(0.1251, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 482\n",
      "Loss: tensor(0.1251, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 483\n",
      "Loss: tensor(0.1251, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 484\n",
      "Loss: tensor(0.1251, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 485\n",
      "Loss: tensor(0.1251, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 486\n",
      "Loss: tensor(0.1251, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 487\n",
      "Loss: tensor(0.1251, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 488\n",
      "Loss: tensor(0.1251, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 489\n",
      "Loss: tensor(0.1251, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 490\n",
      "Loss: tensor(0.1251, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 491\n",
      "Loss: tensor(0.1251, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 492\n",
      "Loss: tensor(0.1251, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 493\n",
      "Loss: tensor(0.1251, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 494\n",
      "Loss: tensor(0.1251, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 495\n",
      "Loss: tensor(0.1251, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 496\n",
      "Loss: tensor(0.1250, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 497\n",
      "Loss: tensor(0.1250, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 498\n",
      "Loss: tensor(0.1250, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 499\n",
      "Loss: tensor(0.1250, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 500\n",
      "Loss: tensor(0.1250, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 501\n",
      "Loss: tensor(0.1250, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 502\n",
      "Loss: tensor(0.1250, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 503\n",
      "Loss: tensor(0.1250, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 504\n",
      "Loss: tensor(0.1250, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 505\n",
      "Loss: tensor(0.1250, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 506\n",
      "Loss: tensor(0.1250, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 507\n",
      "Loss: tensor(0.1250, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 508\n",
      "Loss: tensor(0.1250, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 509\n",
      "Loss: tensor(0.1250, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 510\n",
      "Loss: tensor(0.1250, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 511\n",
      "Loss: tensor(0.1250, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 512\n",
      "Loss: tensor(0.1250, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 513\n",
      "Loss: tensor(0.1250, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 514\n",
      "Loss: tensor(0.1250, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 515\n",
      "Loss: tensor(0.1250, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 516\n",
      "Loss: tensor(0.1250, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 517\n",
      "Loss: tensor(0.1250, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 518\n",
      "Loss: tensor(0.1250, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 519\n",
      "Loss: tensor(0.1250, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 520\n",
      "Loss: tensor(0.1250, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 521\n",
      "Loss: tensor(0.1250, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 522\n",
      "Loss: tensor(0.1250, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 523\n",
      "Loss: tensor(0.1250, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 524\n",
      "Loss: tensor(0.1250, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 525\n",
      "Loss: tensor(0.1250, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 526\n",
      "Loss: tensor(0.1250, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 527\n",
      "Loss: tensor(0.1250, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 528\n",
      "Loss: tensor(0.1250, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 529\n",
      "Loss: tensor(0.1250, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 530\n",
      "Loss: tensor(0.1250, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 531\n",
      "Loss: tensor(0.1250, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 532\n",
      "Loss: tensor(0.1250, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 533\n",
      "Loss: tensor(0.1250, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 534\n",
      "Loss: tensor(0.1250, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 535\n",
      "Loss: tensor(0.1250, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 536\n",
      "Loss: tensor(0.1250, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 537\n",
      "Loss: tensor(0.1250, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 538\n",
      "Loss: tensor(0.1249, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 539\n",
      "Loss: tensor(0.1249, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 540\n",
      "Loss: tensor(0.1249, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 541\n",
      "Loss: tensor(0.1249, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 542\n",
      "Loss: tensor(0.1249, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 543\n",
      "Loss: tensor(0.1249, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 544\n",
      "Loss: tensor(0.1249, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 545\n",
      "Loss: tensor(0.1249, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 546\n",
      "Loss: tensor(0.1249, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 547\n",
      "Loss: tensor(0.1249, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 548\n",
      "Loss: tensor(0.1249, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 549\n",
      "Loss: tensor(0.1249, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 550\n",
      "Loss: tensor(0.1249, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 551\n",
      "Loss: tensor(0.1249, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 552\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor(0.1249, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 553\n",
      "Loss: tensor(0.1249, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 554\n",
      "Loss: tensor(0.1249, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 555\n",
      "Loss: tensor(0.1249, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 556\n",
      "Loss: tensor(0.1249, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 557\n",
      "Loss: tensor(0.1249, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 558\n",
      "Loss: tensor(0.1249, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 559\n",
      "Loss: tensor(0.1249, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 560\n",
      "Loss: tensor(0.1249, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 561\n",
      "Loss: tensor(0.1249, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 562\n",
      "Loss: tensor(0.1249, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 563\n",
      "Loss: tensor(0.1249, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 564\n",
      "Loss: tensor(0.1249, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 565\n",
      "Loss: tensor(0.1249, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 566\n",
      "Loss: tensor(0.1249, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 567\n",
      "Loss: tensor(0.1249, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 568\n",
      "Loss: tensor(0.1249, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 569\n",
      "Loss: tensor(0.1249, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 570\n",
      "Loss: tensor(0.1249, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 571\n",
      "Loss: tensor(0.1249, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 572\n",
      "Loss: tensor(0.1249, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 573\n",
      "Loss: tensor(0.1249, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 574\n",
      "Loss: tensor(0.1249, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 575\n",
      "Loss: tensor(0.1249, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 576\n",
      "Loss: tensor(0.1249, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 577\n",
      "Loss: tensor(0.1249, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 578\n",
      "Loss: tensor(0.1249, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 579\n",
      "Loss: tensor(0.1248, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 580\n",
      "Loss: tensor(0.1248, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 581\n",
      "Loss: tensor(0.1248, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 582\n",
      "Loss: tensor(0.1248, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 583\n",
      "Loss: tensor(0.1248, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 584\n",
      "Loss: tensor(0.1248, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 585\n",
      "Loss: tensor(0.1248, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 586\n",
      "Loss: tensor(0.1248, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 587\n",
      "Loss: tensor(0.1248, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 588\n",
      "Loss: tensor(0.1248, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 589\n",
      "Loss: tensor(0.1248, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 590\n",
      "Loss: tensor(0.1248, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 591\n",
      "Loss: tensor(0.1248, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 592\n",
      "Loss: tensor(0.1248, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 593\n",
      "Loss: tensor(0.1248, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 594\n",
      "Loss: tensor(0.1248, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 595\n",
      "Loss: tensor(0.1248, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 596\n",
      "Loss: tensor(0.1248, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 597\n",
      "Loss: tensor(0.1248, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 598\n",
      "Loss: tensor(0.1248, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 599\n",
      "Loss: tensor(0.1248, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 600\n",
      "Loss: tensor(0.1248, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 601\n",
      "Loss: tensor(0.1248, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 602\n",
      "Loss: tensor(0.1248, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 603\n",
      "Loss: tensor(0.1248, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 604\n",
      "Loss: tensor(0.1248, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 605\n",
      "Loss: tensor(0.1248, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 606\n",
      "Loss: tensor(0.1248, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 607\n",
      "Loss: tensor(0.1248, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 608\n",
      "Loss: tensor(0.1248, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 609\n",
      "Loss: tensor(0.1248, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 610\n",
      "Loss: tensor(0.1248, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 611\n",
      "Loss: tensor(0.1248, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 612\n",
      "Loss: tensor(0.1248, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 613\n",
      "Loss: tensor(0.1248, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 614\n",
      "Loss: tensor(0.1248, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 615\n",
      "Loss: tensor(0.1248, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 616\n",
      "Loss: tensor(0.1248, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 617\n",
      "Loss: tensor(0.1248, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 618\n",
      "Loss: tensor(0.1248, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 619\n",
      "Loss: tensor(0.1248, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 620\n",
      "Loss: tensor(0.1248, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 621\n",
      "Loss: tensor(0.1247, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 622\n",
      "Loss: tensor(0.1247, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 623\n",
      "Loss: tensor(0.1247, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 624\n",
      "Loss: tensor(0.1247, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 625\n",
      "Loss: tensor(0.1247, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 626\n",
      "Loss: tensor(0.1247, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 627\n",
      "Loss: tensor(0.1247, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 628\n",
      "Loss: tensor(0.1247, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 629\n",
      "Loss: tensor(0.1247, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 630\n",
      "Loss: tensor(0.1247, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 631\n",
      "Loss: tensor(0.1247, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 632\n",
      "Loss: tensor(0.1247, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 633\n",
      "Loss: tensor(0.1247, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 634\n",
      "Loss: tensor(0.1247, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 635\n",
      "Loss: tensor(0.1247, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 636\n",
      "Loss: tensor(0.1247, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 637\n",
      "Loss: tensor(0.1247, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 638\n",
      "Loss: tensor(0.1247, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 639\n",
      "Loss: tensor(0.1247, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 640\n",
      "Loss: tensor(0.1247, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 641\n",
      "Loss: tensor(0.1247, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 642\n",
      "Loss: tensor(0.1247, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 643\n",
      "Loss: tensor(0.1247, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 644\n",
      "Loss: tensor(0.1247, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 645\n",
      "Loss: tensor(0.1247, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 646\n",
      "Loss: tensor(0.1247, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 647\n",
      "Loss: tensor(0.1247, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 648\n",
      "Loss: tensor(0.1247, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 649\n",
      "Loss: tensor(0.1247, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 650\n",
      "Loss: tensor(0.1247, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 651\n",
      "Loss: tensor(0.1247, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 652\n",
      "Loss: tensor(0.1247, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 653\n",
      "Loss: tensor(0.1247, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 654\n",
      "Loss: tensor(0.1247, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 655\n",
      "Loss: tensor(0.1247, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 656\n",
      "Loss: tensor(0.1247, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 657\n",
      "Loss: tensor(0.1247, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 658\n",
      "Loss: tensor(0.1247, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 659\n",
      "Loss: tensor(0.1247, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 660\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor(0.1247, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 661\n",
      "Loss: tensor(0.1247, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 662\n",
      "Loss: tensor(0.1247, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 663\n",
      "Loss: tensor(0.1246, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 664\n",
      "Loss: tensor(0.1246, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 665\n",
      "Loss: tensor(0.1246, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 666\n",
      "Loss: tensor(0.1246, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 667\n",
      "Loss: tensor(0.1246, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 668\n",
      "Loss: tensor(0.1246, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 669\n",
      "Loss: tensor(0.1246, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 670\n",
      "Loss: tensor(0.1246, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 671\n",
      "Loss: tensor(0.1246, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 672\n",
      "Loss: tensor(0.1246, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 673\n",
      "Loss: tensor(0.1246, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 674\n",
      "Loss: tensor(0.1246, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 675\n",
      "Loss: tensor(0.1246, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 676\n",
      "Loss: tensor(0.1246, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 677\n",
      "Loss: tensor(0.1246, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 678\n",
      "Loss: tensor(0.1246, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 679\n",
      "Loss: tensor(0.1246, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 680\n",
      "Loss: tensor(0.1246, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 681\n",
      "Loss: tensor(0.1246, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 682\n",
      "Loss: tensor(0.1246, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 683\n",
      "Loss: tensor(0.1246, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 684\n",
      "Loss: tensor(0.1246, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 685\n",
      "Loss: tensor(0.1246, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 686\n",
      "Loss: tensor(0.1246, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 687\n",
      "Loss: tensor(0.1246, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 688\n",
      "Loss: tensor(0.1246, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 689\n",
      "Loss: tensor(0.1246, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 690\n",
      "Loss: tensor(0.1246, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 691\n",
      "Loss: tensor(0.1246, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 692\n",
      "Loss: tensor(0.1246, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 693\n",
      "Loss: tensor(0.1246, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 694\n",
      "Loss: tensor(0.1246, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 695\n",
      "Loss: tensor(0.1246, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 696\n",
      "Loss: tensor(0.1246, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 697\n",
      "Loss: tensor(0.1246, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 698\n",
      "Loss: tensor(0.1246, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 699\n",
      "Loss: tensor(0.1246, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 700\n",
      "Loss: tensor(0.1246, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 701\n",
      "Loss: tensor(0.1246, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 702\n",
      "Loss: tensor(0.1246, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 703\n",
      "Loss: tensor(0.1246, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 704\n",
      "Loss: tensor(0.1246, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 705\n",
      "Loss: tensor(0.1246, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 706\n",
      "Loss: tensor(0.1245, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 707\n",
      "Loss: tensor(0.1245, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 708\n",
      "Loss: tensor(0.1245, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 709\n",
      "Loss: tensor(0.1245, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 710\n",
      "Loss: tensor(0.1245, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 711\n",
      "Loss: tensor(0.1245, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 712\n",
      "Loss: tensor(0.1245, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 713\n",
      "Loss: tensor(0.1245, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 714\n",
      "Loss: tensor(0.1245, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 715\n",
      "Loss: tensor(0.1245, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 716\n",
      "Loss: tensor(0.1245, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 717\n",
      "Loss: tensor(0.1245, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 718\n",
      "Loss: tensor(0.1245, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 719\n",
      "Loss: tensor(0.1245, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 720\n",
      "Loss: tensor(0.1245, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 721\n",
      "Loss: tensor(0.1245, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 722\n",
      "Loss: tensor(0.1245, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 723\n",
      "Loss: tensor(0.1245, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 724\n",
      "Loss: tensor(0.1245, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 725\n",
      "Loss: tensor(0.1245, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 726\n",
      "Loss: tensor(0.1245, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 727\n",
      "Loss: tensor(0.1245, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 728\n",
      "Loss: tensor(0.1245, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 729\n",
      "Loss: tensor(0.1245, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 730\n",
      "Loss: tensor(0.1245, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 731\n",
      "Loss: tensor(0.1245, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 732\n",
      "Loss: tensor(0.1245, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 733\n",
      "Loss: tensor(0.1245, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 734\n",
      "Loss: tensor(0.1245, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 735\n",
      "Loss: tensor(0.1245, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 736\n",
      "Loss: tensor(0.1245, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 737\n",
      "Loss: tensor(0.1245, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 738\n",
      "Loss: tensor(0.1245, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 739\n",
      "Loss: tensor(0.1245, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 740\n",
      "Loss: tensor(0.1245, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 741\n",
      "Loss: tensor(0.1245, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 742\n",
      "Loss: tensor(0.1245, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 743\n",
      "Loss: tensor(0.1245, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 744\n",
      "Loss: tensor(0.1245, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 745\n",
      "Loss: tensor(0.1245, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 746\n",
      "Loss: tensor(0.1245, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 747\n",
      "Loss: tensor(0.1245, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 748\n",
      "Loss: tensor(0.1245, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 749\n",
      "Loss: tensor(0.1245, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 750\n",
      "Loss: tensor(0.1244, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 751\n",
      "Loss: tensor(0.1244, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 752\n",
      "Loss: tensor(0.1244, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 753\n",
      "Loss: tensor(0.1244, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 754\n",
      "Loss: tensor(0.1244, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 755\n",
      "Loss: tensor(0.1244, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 756\n",
      "Loss: tensor(0.1244, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 757\n",
      "Loss: tensor(0.1244, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 758\n",
      "Loss: tensor(0.1244, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 759\n",
      "Loss: tensor(0.1244, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 760\n",
      "Loss: tensor(0.1244, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 761\n",
      "Loss: tensor(0.1244, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 762\n",
      "Loss: tensor(0.1244, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 763\n",
      "Loss: tensor(0.1244, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 764\n",
      "Loss: tensor(0.1244, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 765\n",
      "Loss: tensor(0.1244, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 766\n",
      "Loss: tensor(0.1244, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 767\n",
      "Loss: tensor(0.1244, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 768\n",
      "Loss: tensor(0.1244, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 769\n",
      "Loss: tensor(0.1244, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 770\n",
      "Loss: tensor(0.1244, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 771\n",
      "Loss: tensor(0.1244, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 772\n",
      "Loss: tensor(0.1244, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 773\n",
      "Loss: tensor(0.1244, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 774\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor(0.1244, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 775\n",
      "Loss: tensor(0.1244, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 776\n",
      "Loss: tensor(0.1244, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 777\n",
      "Loss: tensor(0.1244, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 778\n",
      "Loss: tensor(0.1244, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 779\n",
      "Loss: tensor(0.1244, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 780\n",
      "Loss: tensor(0.1244, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 781\n",
      "Loss: tensor(0.1244, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 782\n",
      "Loss: tensor(0.1244, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 783\n",
      "Loss: tensor(0.1244, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 784\n",
      "Loss: tensor(0.1244, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 785\n",
      "Loss: tensor(0.1244, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 786\n",
      "Loss: tensor(0.1244, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 787\n",
      "Loss: tensor(0.1244, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 788\n",
      "Loss: tensor(0.1244, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 789\n",
      "Loss: tensor(0.1244, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 790\n",
      "Loss: tensor(0.1244, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 791\n",
      "Loss: tensor(0.1244, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 792\n",
      "Loss: tensor(0.1244, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 793\n",
      "Loss: tensor(0.1244, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 794\n",
      "Loss: tensor(0.1244, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 795\n",
      "Loss: tensor(0.1244, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 796\n",
      "Loss: tensor(0.1243, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 797\n",
      "Loss: tensor(0.1243, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 798\n",
      "Loss: tensor(0.1243, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 799\n",
      "Loss: tensor(0.1243, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 800\n",
      "Loss: tensor(0.1243, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 801\n",
      "Loss: tensor(0.1243, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 802\n",
      "Loss: tensor(0.1243, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 803\n",
      "Loss: tensor(0.1243, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 804\n",
      "Loss: tensor(0.1243, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 805\n",
      "Loss: tensor(0.1243, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 806\n",
      "Loss: tensor(0.1243, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 807\n",
      "Loss: tensor(0.1243, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 808\n",
      "Loss: tensor(0.1243, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 809\n",
      "Loss: tensor(0.1243, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 810\n",
      "Loss: tensor(0.1243, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 811\n",
      "Loss: tensor(0.1243, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 812\n",
      "Loss: tensor(0.1243, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 813\n",
      "Loss: tensor(0.1243, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 814\n",
      "Loss: tensor(0.1243, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 815\n",
      "Loss: tensor(0.1243, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 816\n",
      "Loss: tensor(0.1243, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 817\n",
      "Loss: tensor(0.1243, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 818\n",
      "Loss: tensor(0.1243, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 819\n",
      "Loss: tensor(0.1243, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 820\n",
      "Loss: tensor(0.1243, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 821\n",
      "Loss: tensor(0.1243, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 822\n",
      "Loss: tensor(0.1243, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 823\n",
      "Loss: tensor(0.1243, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 824\n",
      "Loss: tensor(0.1243, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 825\n",
      "Loss: tensor(0.1243, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 826\n",
      "Loss: tensor(0.1243, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 827\n",
      "Loss: tensor(0.1243, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 828\n",
      "Loss: tensor(0.1243, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 829\n",
      "Loss: tensor(0.1243, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 830\n",
      "Loss: tensor(0.1243, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 831\n",
      "Loss: tensor(0.1243, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 832\n",
      "Loss: tensor(0.1243, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 833\n",
      "Loss: tensor(0.1243, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 834\n",
      "Loss: tensor(0.1243, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 835\n",
      "Loss: tensor(0.1243, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 836\n",
      "Loss: tensor(0.1243, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 837\n",
      "Loss: tensor(0.1243, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 838\n",
      "Loss: tensor(0.1243, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 839\n",
      "Loss: tensor(0.1243, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 840\n",
      "Loss: tensor(0.1243, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 841\n",
      "Loss: tensor(0.1243, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 842\n",
      "Loss: tensor(0.1242, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 843\n",
      "Loss: tensor(0.1242, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 844\n",
      "Loss: tensor(0.1242, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 845\n",
      "Loss: tensor(0.1242, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 846\n",
      "Loss: tensor(0.1242, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 847\n",
      "Loss: tensor(0.1242, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 848\n",
      "Loss: tensor(0.1242, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 849\n",
      "Loss: tensor(0.1242, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 850\n",
      "Loss: tensor(0.1242, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 851\n",
      "Loss: tensor(0.1242, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 852\n",
      "Loss: tensor(0.1242, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 853\n",
      "Loss: tensor(0.1242, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 854\n",
      "Loss: tensor(0.1242, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 855\n",
      "Loss: tensor(0.1242, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 856\n",
      "Loss: tensor(0.1242, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 857\n",
      "Loss: tensor(0.1242, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 858\n",
      "Loss: tensor(0.1242, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 859\n",
      "Loss: tensor(0.1242, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 860\n",
      "Loss: tensor(0.1242, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 861\n",
      "Loss: tensor(0.1242, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 862\n",
      "Loss: tensor(0.1242, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 863\n",
      "Loss: tensor(0.1242, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 864\n",
      "Loss: tensor(0.1242, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 865\n",
      "Loss: tensor(0.1242, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 866\n",
      "Loss: tensor(0.1242, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 867\n",
      "Loss: tensor(0.1242, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 868\n",
      "Loss: tensor(0.1242, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 869\n",
      "Loss: tensor(0.1242, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 870\n",
      "Loss: tensor(0.1242, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 871\n",
      "Loss: tensor(0.1242, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 872\n",
      "Loss: tensor(0.1242, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 873\n",
      "Loss: tensor(0.1242, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 874\n",
      "Loss: tensor(0.1242, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 875\n",
      "Loss: tensor(0.1242, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 876\n",
      "Loss: tensor(0.1242, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 877\n",
      "Loss: tensor(0.1242, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 878\n",
      "Loss: tensor(0.1242, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 879\n",
      "Loss: tensor(0.1242, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 880\n",
      "Loss: tensor(0.1242, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 881\n",
      "Loss: tensor(0.1242, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 882\n",
      "Loss: tensor(0.1242, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 883\n",
      "Loss: tensor(0.1242, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 884\n",
      "Loss: tensor(0.1242, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 885\n",
      "Loss: tensor(0.1242, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 886\n",
      "Loss: tensor(0.1242, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 887\n",
      "Loss: tensor(0.1242, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 888\n",
      "Loss: tensor(0.1242, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 889\n",
      "Loss: tensor(0.1241, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 890\n",
      "Loss: tensor(0.1241, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 891\n",
      "Loss: tensor(0.1241, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 892\n",
      "Loss: tensor(0.1241, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 893\n",
      "Loss: tensor(0.1241, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 894\n",
      "Loss: tensor(0.1241, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 895\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor(0.1241, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 896\n",
      "Loss: tensor(0.1241, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 897\n",
      "Loss: tensor(0.1241, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 898\n",
      "Loss: tensor(0.1241, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 899\n",
      "Loss: tensor(0.1241, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 900\n",
      "Loss: tensor(0.1241, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 901\n",
      "Loss: tensor(0.1241, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 902\n",
      "Loss: tensor(0.1241, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 903\n",
      "Loss: tensor(0.1241, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 904\n",
      "Loss: tensor(0.1241, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 905\n",
      "Loss: tensor(0.1241, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 906\n",
      "Loss: tensor(0.1241, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 907\n",
      "Loss: tensor(0.1241, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 908\n",
      "Loss: tensor(0.1241, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 909\n",
      "Loss: tensor(0.1241, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 910\n",
      "Loss: tensor(0.1241, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 911\n",
      "Loss: tensor(0.1241, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 912\n",
      "Loss: tensor(0.1241, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 913\n",
      "Loss: tensor(0.1241, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 914\n",
      "Loss: tensor(0.1241, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 915\n",
      "Loss: tensor(0.1241, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 916\n",
      "Loss: tensor(0.1241, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 917\n",
      "Loss: tensor(0.1241, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 918\n",
      "Loss: tensor(0.1241, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 919\n",
      "Loss: tensor(0.1241, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 920\n",
      "Loss: tensor(0.1241, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 921\n",
      "Loss: tensor(0.1241, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 922\n",
      "Loss: tensor(0.1241, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 923\n",
      "Loss: tensor(0.1241, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 924\n",
      "Loss: tensor(0.1241, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 925\n",
      "Loss: tensor(0.1241, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 926\n",
      "Loss: tensor(0.1241, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 927\n",
      "Loss: tensor(0.1241, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 928\n",
      "Loss: tensor(0.1241, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 929\n",
      "Loss: tensor(0.1241, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 930\n",
      "Loss: tensor(0.1241, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 931\n",
      "Loss: tensor(0.1241, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 932\n",
      "Loss: tensor(0.1241, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 933\n",
      "Loss: tensor(0.1241, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 934\n",
      "Loss: tensor(0.1240, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 935\n",
      "Loss: tensor(0.1240, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 936\n",
      "Loss: tensor(0.1240, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 937\n",
      "Loss: tensor(0.1240, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 938\n",
      "Loss: tensor(0.1240, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 939\n",
      "Loss: tensor(0.1240, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 940\n",
      "Loss: tensor(0.1240, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 941\n",
      "Loss: tensor(0.1240, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 942\n",
      "Loss: tensor(0.1240, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 943\n",
      "Loss: tensor(0.1240, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 944\n",
      "Loss: tensor(0.1240, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 945\n",
      "Loss: tensor(0.1240, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 946\n",
      "Loss: tensor(0.1240, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 947\n",
      "Loss: tensor(0.1240, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 948\n",
      "Loss: tensor(0.1240, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 949\n",
      "Loss: tensor(0.1240, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 950\n",
      "Loss: tensor(0.1240, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 951\n",
      "Loss: tensor(0.1240, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 952\n",
      "Loss: tensor(0.1240, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 953\n",
      "Loss: tensor(0.1240, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 954\n",
      "Loss: tensor(0.1240, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 955\n",
      "Loss: tensor(0.1240, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 956\n",
      "Loss: tensor(0.1240, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 957\n",
      "Loss: tensor(0.1240, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 958\n",
      "Loss: tensor(0.1240, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 959\n",
      "Loss: tensor(0.1240, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 960\n",
      "Loss: tensor(0.1240, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 961\n",
      "Loss: tensor(0.1240, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 962\n",
      "Loss: tensor(0.1240, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 963\n",
      "Loss: tensor(0.1240, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 964\n",
      "Loss: tensor(0.1240, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 965\n",
      "Loss: tensor(0.1240, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 966\n",
      "Loss: tensor(0.1240, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 967\n",
      "Loss: tensor(0.1240, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 968\n",
      "Loss: tensor(0.1240, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 969\n",
      "Loss: tensor(0.1240, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 970\n",
      "Loss: tensor(0.1240, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 971\n",
      "Loss: tensor(0.1240, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 972\n",
      "Loss: tensor(0.1240, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 973\n",
      "Loss: tensor(0.1240, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 974\n",
      "Loss: tensor(0.1240, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 975\n",
      "Loss: tensor(0.1240, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 976\n",
      "Loss: tensor(0.1240, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 977\n",
      "Loss: tensor(0.1239, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 978\n",
      "Loss: tensor(0.1239, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 979\n",
      "Loss: tensor(0.1239, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 980\n",
      "Loss: tensor(0.1239, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 981\n",
      "Loss: tensor(0.1239, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 982\n",
      "Loss: tensor(0.1239, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 983\n",
      "Loss: tensor(0.1239, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 984\n",
      "Loss: tensor(0.1239, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 985\n",
      "Loss: tensor(0.1239, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 986\n",
      "Loss: tensor(0.1239, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 987\n",
      "Loss: tensor(0.1239, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 988\n",
      "Loss: tensor(0.1239, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 989\n",
      "Loss: tensor(0.1239, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 990\n",
      "Loss: tensor(0.1239, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 991\n",
      "Loss: tensor(0.1239, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 992\n",
      "Loss: tensor(0.1239, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 993\n",
      "Loss: tensor(0.1239, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 994\n",
      "Loss: tensor(0.1239, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 995\n",
      "Loss: tensor(0.1239, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 996\n",
      "Loss: tensor(0.1239, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 997\n",
      "Loss: tensor(0.1239, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 998\n",
      "Loss: tensor(0.1239, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 999\n",
      "Loss: tensor(0.1239, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1000\n",
      "Loss: tensor(0.1239, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1001\n",
      "Loss: tensor(0.1239, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1002\n",
      "Loss: tensor(0.1239, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1003\n",
      "Loss: tensor(0.1239, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1004\n",
      "Loss: tensor(0.1239, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1005\n",
      "Loss: tensor(0.1239, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1006\n",
      "Loss: tensor(0.1239, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1007\n",
      "Loss: tensor(0.1239, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1008\n",
      "Loss: tensor(0.1239, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1009\n",
      "Loss: tensor(0.1239, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1010\n",
      "Loss: tensor(0.1239, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1011\n",
      "Loss: tensor(0.1239, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1012\n",
      "Loss: tensor(0.1239, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1013\n",
      "Loss: tensor(0.1239, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1014\n",
      "Loss: tensor(0.1239, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1015\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor(0.1239, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1016\n",
      "Loss: tensor(0.1239, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1017\n",
      "Loss: tensor(0.1239, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1018\n",
      "Loss: tensor(0.1238, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1019\n",
      "Loss: tensor(0.1238, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1020\n",
      "Loss: tensor(0.1238, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1021\n",
      "Loss: tensor(0.1238, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1022\n",
      "Loss: tensor(0.1238, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1023\n",
      "Loss: tensor(0.1238, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1024\n",
      "Loss: tensor(0.1238, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1025\n",
      "Loss: tensor(0.1238, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1026\n",
      "Loss: tensor(0.1238, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1027\n",
      "Loss: tensor(0.1238, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1028\n",
      "Loss: tensor(0.1238, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1029\n",
      "Loss: tensor(0.1238, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1030\n",
      "Loss: tensor(0.1238, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1031\n",
      "Loss: tensor(0.1238, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1032\n",
      "Loss: tensor(0.1238, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1033\n",
      "Loss: tensor(0.1238, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1034\n",
      "Loss: tensor(0.1238, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1035\n",
      "Loss: tensor(0.1238, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1036\n",
      "Loss: tensor(0.1238, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1037\n",
      "Loss: tensor(0.1238, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1038\n",
      "Loss: tensor(0.1238, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1039\n",
      "Loss: tensor(0.1238, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1040\n",
      "Loss: tensor(0.1238, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1041\n",
      "Loss: tensor(0.1238, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1042\n",
      "Loss: tensor(0.1238, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1043\n",
      "Loss: tensor(0.1238, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1044\n",
      "Loss: tensor(0.1238, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1045\n",
      "Loss: tensor(0.1238, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1046\n",
      "Loss: tensor(0.1238, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1047\n",
      "Loss: tensor(0.1238, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1048\n",
      "Loss: tensor(0.1238, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1049\n",
      "Loss: tensor(0.1238, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1050\n",
      "Loss: tensor(0.1238, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1051\n",
      "Loss: tensor(0.1238, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1052\n",
      "Loss: tensor(0.1238, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1053\n",
      "Loss: tensor(0.1238, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1054\n",
      "Loss: tensor(0.1238, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1055\n",
      "Loss: tensor(0.1237, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1056\n",
      "Loss: tensor(0.1237, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1057\n",
      "Loss: tensor(0.1237, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1058\n",
      "Loss: tensor(0.1237, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1059\n",
      "Loss: tensor(0.1237, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1060\n",
      "Loss: tensor(0.1237, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1061\n",
      "Loss: tensor(0.1237, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1062\n",
      "Loss: tensor(0.1237, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1063\n",
      "Loss: tensor(0.1237, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1064\n",
      "Loss: tensor(0.1237, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1065\n",
      "Loss: tensor(0.1237, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1066\n",
      "Loss: tensor(0.1237, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1067\n",
      "Loss: tensor(0.1237, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1068\n",
      "Loss: tensor(0.1237, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1069\n",
      "Loss: tensor(0.1237, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1070\n",
      "Loss: tensor(0.1237, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1071\n",
      "Loss: tensor(0.1237, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1072\n",
      "Loss: tensor(0.1237, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1073\n",
      "Loss: tensor(0.1237, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1074\n",
      "Loss: tensor(0.1237, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1075\n",
      "Loss: tensor(0.1237, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1076\n",
      "Loss: tensor(0.1237, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1077\n",
      "Loss: tensor(0.1237, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1078\n",
      "Loss: tensor(0.1237, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1079\n",
      "Loss: tensor(0.1237, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1080\n",
      "Loss: tensor(0.1237, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1081\n",
      "Loss: tensor(0.1237, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1082\n",
      "Loss: tensor(0.1237, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1083\n",
      "Loss: tensor(0.1237, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1084\n",
      "Loss: tensor(0.1237, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1085\n",
      "Loss: tensor(0.1237, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1086\n",
      "Loss: tensor(0.1237, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1087\n",
      "Loss: tensor(0.1237, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1088\n",
      "Loss: tensor(0.1237, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1089\n",
      "Loss: tensor(0.1237, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1090\n",
      "Loss: tensor(0.1237, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1091\n",
      "Loss: tensor(0.1236, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1092\n",
      "Loss: tensor(0.1236, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1093\n",
      "Loss: tensor(0.1236, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1094\n",
      "Loss: tensor(0.1236, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1095\n",
      "Loss: tensor(0.1236, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1096\n",
      "Loss: tensor(0.1236, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1097\n",
      "Loss: tensor(0.1236, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1098\n",
      "Loss: tensor(0.1236, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1099\n",
      "Loss: tensor(0.1236, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1100\n",
      "Loss: tensor(0.1236, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1101\n",
      "Loss: tensor(0.1236, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1102\n",
      "Loss: tensor(0.1236, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1103\n",
      "Loss: tensor(0.1236, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1104\n",
      "Loss: tensor(0.1236, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1105\n",
      "Loss: tensor(0.1236, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1106\n",
      "Loss: tensor(0.1236, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1107\n",
      "Loss: tensor(0.1236, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1108\n",
      "Loss: tensor(0.1236, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1109\n",
      "Loss: tensor(0.1236, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1110\n",
      "Loss: tensor(0.1236, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1111\n",
      "Loss: tensor(0.1236, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1112\n",
      "Loss: tensor(0.1236, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1113\n",
      "Loss: tensor(0.1236, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1114\n",
      "Loss: tensor(0.1236, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1115\n",
      "Loss: tensor(0.1236, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1116\n",
      "Loss: tensor(0.1236, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1117\n",
      "Loss: tensor(0.1236, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1118\n",
      "Loss: tensor(0.1236, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1119\n",
      "Loss: tensor(0.1236, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1120\n",
      "Loss: tensor(0.1236, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1121\n",
      "Loss: tensor(0.1236, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1122\n",
      "Loss: tensor(0.1236, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1123\n",
      "Loss: tensor(0.1235, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1124\n",
      "Loss: tensor(0.1235, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1125\n",
      "Loss: tensor(0.1235, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1126\n",
      "Loss: tensor(0.1235, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1127\n",
      "Loss: tensor(0.1235, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1128\n",
      "Loss: tensor(0.1235, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1129\n",
      "Loss: tensor(0.1235, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1130\n",
      "Loss: tensor(0.1235, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1131\n",
      "Loss: tensor(0.1235, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1132\n",
      "Loss: tensor(0.1235, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1133\n",
      "Loss: tensor(0.1235, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1134\n",
      "Loss: tensor(0.1235, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1135\n",
      "Loss: tensor(0.1235, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1136\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor(0.1235, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1137\n",
      "Loss: tensor(0.1235, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1138\n",
      "Loss: tensor(0.1235, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1139\n",
      "Loss: tensor(0.1235, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1140\n",
      "Loss: tensor(0.1235, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1141\n",
      "Loss: tensor(0.1235, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1142\n",
      "Loss: tensor(0.1235, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1143\n",
      "Loss: tensor(0.1235, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1144\n",
      "Loss: tensor(0.1235, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1145\n",
      "Loss: tensor(0.1235, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1146\n",
      "Loss: tensor(0.1235, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1147\n",
      "Loss: tensor(0.1235, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1148\n",
      "Loss: tensor(0.1235, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1149\n",
      "Loss: tensor(0.1235, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1150\n",
      "Loss: tensor(0.1235, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1151\n",
      "Loss: tensor(0.1235, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1152\n",
      "Loss: tensor(0.1235, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1153\n",
      "Loss: tensor(0.1235, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1154\n",
      "Loss: tensor(0.1234, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1155\n",
      "Loss: tensor(0.1234, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1156\n",
      "Loss: tensor(0.1234, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1157\n",
      "Loss: tensor(0.1234, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1158\n",
      "Loss: tensor(0.1234, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1159\n",
      "Loss: tensor(0.1234, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1160\n",
      "Loss: tensor(0.1234, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1161\n",
      "Loss: tensor(0.1234, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1162\n",
      "Loss: tensor(0.1234, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1163\n",
      "Loss: tensor(0.1234, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1164\n",
      "Loss: tensor(0.1234, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1165\n",
      "Loss: tensor(0.1234, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1166\n",
      "Loss: tensor(0.1234, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1167\n",
      "Loss: tensor(0.1234, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1168\n",
      "Loss: tensor(0.1234, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1169\n",
      "Loss: tensor(0.1234, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1170\n",
      "Loss: tensor(0.1234, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1171\n",
      "Loss: tensor(0.1234, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1172\n",
      "Loss: tensor(0.1234, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1173\n",
      "Loss: tensor(0.1234, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1174\n",
      "Loss: tensor(0.1234, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1175\n",
      "Loss: tensor(0.1234, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1176\n",
      "Loss: tensor(0.1234, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1177\n",
      "Loss: tensor(0.1234, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1178\n",
      "Loss: tensor(0.1234, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1179\n",
      "Loss: tensor(0.1234, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1180\n",
      "Loss: tensor(0.1234, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1181\n",
      "Loss: tensor(0.1234, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1182\n",
      "Loss: tensor(0.1234, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1183\n",
      "Loss: tensor(0.1233, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1184\n",
      "Loss: tensor(0.1233, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1185\n",
      "Loss: tensor(0.1233, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1186\n",
      "Loss: tensor(0.1233, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1187\n",
      "Loss: tensor(0.1233, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1188\n",
      "Loss: tensor(0.1233, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1189\n",
      "Loss: tensor(0.1233, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1190\n",
      "Loss: tensor(0.1233, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1191\n",
      "Loss: tensor(0.1233, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1192\n",
      "Loss: tensor(0.1233, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1193\n",
      "Loss: tensor(0.1233, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1194\n",
      "Loss: tensor(0.1233, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1195\n",
      "Loss: tensor(0.1233, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1196\n",
      "Loss: tensor(0.1233, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1197\n",
      "Loss: tensor(0.1233, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1198\n",
      "Loss: tensor(0.1233, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1199\n",
      "Loss: tensor(0.1233, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1200\n",
      "Loss: tensor(0.1233, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1201\n",
      "Loss: tensor(0.1233, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1202\n",
      "Loss: tensor(0.1233, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1203\n",
      "Loss: tensor(0.1233, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1204\n",
      "Loss: tensor(0.1233, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1205\n",
      "Loss: tensor(0.1233, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1206\n",
      "Loss: tensor(0.1233, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1207\n",
      "Loss: tensor(0.1233, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1208\n",
      "Loss: tensor(0.1233, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1209\n",
      "Loss: tensor(0.1233, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1210\n",
      "Loss: tensor(0.1232, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1211\n",
      "Loss: tensor(0.1232, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1212\n",
      "Loss: tensor(0.1232, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1213\n",
      "Loss: tensor(0.1232, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1214\n",
      "Loss: tensor(0.1232, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1215\n",
      "Loss: tensor(0.1232, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1216\n",
      "Loss: tensor(0.1232, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1217\n",
      "Loss: tensor(0.1232, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1218\n",
      "Loss: tensor(0.1232, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1219\n",
      "Loss: tensor(0.1232, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1220\n",
      "Loss: tensor(0.1232, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1221\n",
      "Loss: tensor(0.1232, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1222\n",
      "Loss: tensor(0.1232, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1223\n",
      "Loss: tensor(0.1232, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1224\n",
      "Loss: tensor(0.1232, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1225\n",
      "Loss: tensor(0.1232, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1226\n",
      "Loss: tensor(0.1232, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1227\n",
      "Loss: tensor(0.1232, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1228\n",
      "Loss: tensor(0.1232, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1229\n",
      "Loss: tensor(0.1232, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1230\n",
      "Loss: tensor(0.1232, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1231\n",
      "Loss: tensor(0.1232, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1232\n",
      "Loss: tensor(0.1232, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1233\n",
      "Loss: tensor(0.1232, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1234\n",
      "Loss: tensor(0.1232, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1235\n",
      "Loss: tensor(0.1231, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1236\n",
      "Loss: tensor(0.1231, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1237\n",
      "Loss: tensor(0.1231, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1238\n",
      "Loss: tensor(0.1231, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1239\n",
      "Loss: tensor(0.1231, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1240\n",
      "Loss: tensor(0.1231, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1241\n",
      "Loss: tensor(0.1231, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1242\n",
      "Loss: tensor(0.1231, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1243\n",
      "Loss: tensor(0.1231, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1244\n",
      "Loss: tensor(0.1231, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1245\n",
      "Loss: tensor(0.1231, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1246\n",
      "Loss: tensor(0.1231, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1247\n",
      "Loss: tensor(0.1231, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1248\n",
      "Loss: tensor(0.1231, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1249\n",
      "Loss: tensor(0.1231, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1250\n",
      "Loss: tensor(0.1231, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1251\n",
      "Loss: tensor(0.1231, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1252\n",
      "Loss: tensor(0.1231, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1253\n",
      "Loss: tensor(0.1231, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1254\n",
      "Loss: tensor(0.1231, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1255\n",
      "Loss: tensor(0.1231, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1256\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor(0.1231, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1257\n",
      "Loss: tensor(0.1231, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1258\n",
      "Loss: tensor(0.1231, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1259\n",
      "Loss: tensor(0.1230, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1260\n",
      "Loss: tensor(0.1230, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1261\n",
      "Loss: tensor(0.1230, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1262\n",
      "Loss: tensor(0.1230, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1263\n",
      "Loss: tensor(0.1230, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1264\n",
      "Loss: tensor(0.1230, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1265\n",
      "Loss: tensor(0.1230, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1266\n",
      "Loss: tensor(0.1230, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1267\n",
      "Loss: tensor(0.1230, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1268\n",
      "Loss: tensor(0.1230, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1269\n",
      "Loss: tensor(0.1230, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1270\n",
      "Loss: tensor(0.1230, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1271\n",
      "Loss: tensor(0.1230, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1272\n",
      "Loss: tensor(0.1230, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1273\n",
      "Loss: tensor(0.1230, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1274\n",
      "Loss: tensor(0.1230, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1275\n",
      "Loss: tensor(0.1230, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1276\n",
      "Loss: tensor(0.1230, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1277\n",
      "Loss: tensor(0.1230, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1278\n",
      "Loss: tensor(0.1230, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1279\n",
      "Loss: tensor(0.1230, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1280\n",
      "Loss: tensor(0.1230, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1281\n",
      "Loss: tensor(0.1230, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1282\n",
      "Loss: tensor(0.1229, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1283\n",
      "Loss: tensor(0.1229, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1284\n",
      "Loss: tensor(0.1229, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1285\n",
      "Loss: tensor(0.1229, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1286\n",
      "Loss: tensor(0.1229, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1287\n",
      "Loss: tensor(0.1229, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1288\n",
      "Loss: tensor(0.1229, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1289\n",
      "Loss: tensor(0.1229, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1290\n",
      "Loss: tensor(0.1229, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1291\n",
      "Loss: tensor(0.1229, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1292\n",
      "Loss: tensor(0.1229, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1293\n",
      "Loss: tensor(0.1229, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1294\n",
      "Loss: tensor(0.1229, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1295\n",
      "Loss: tensor(0.1229, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1296\n",
      "Loss: tensor(0.1229, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1297\n",
      "Loss: tensor(0.1229, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1298\n",
      "Loss: tensor(0.1229, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1299\n",
      "Loss: tensor(0.1229, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1300\n",
      "Loss: tensor(0.1229, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1301\n",
      "Loss: tensor(0.1229, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1302\n",
      "Loss: tensor(0.1229, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1303\n",
      "Loss: tensor(0.1229, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1304\n",
      "Loss: tensor(0.1228, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1305\n",
      "Loss: tensor(0.1228, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1306\n",
      "Loss: tensor(0.1228, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1307\n",
      "Loss: tensor(0.1228, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1308\n",
      "Loss: tensor(0.1228, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1309\n",
      "Loss: tensor(0.1228, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1310\n",
      "Loss: tensor(0.1228, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1311\n",
      "Loss: tensor(0.1228, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1312\n",
      "Loss: tensor(0.1228, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1313\n",
      "Loss: tensor(0.1228, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1314\n",
      "Loss: tensor(0.1228, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1315\n",
      "Loss: tensor(0.1228, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1316\n",
      "Loss: tensor(0.1228, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1317\n",
      "Loss: tensor(0.1228, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1318\n",
      "Loss: tensor(0.1228, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1319\n",
      "Loss: tensor(0.1228, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1320\n",
      "Loss: tensor(0.1228, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1321\n",
      "Loss: tensor(0.1228, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1322\n",
      "Loss: tensor(0.1228, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1323\n",
      "Loss: tensor(0.1228, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1324\n",
      "Loss: tensor(0.1228, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1325\n",
      "Loss: tensor(0.1227, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1326\n",
      "Loss: tensor(0.1227, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1327\n",
      "Loss: tensor(0.1227, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1328\n",
      "Loss: tensor(0.1227, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1329\n",
      "Loss: tensor(0.1227, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1330\n",
      "Loss: tensor(0.1227, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1331\n",
      "Loss: tensor(0.1227, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1332\n",
      "Loss: tensor(0.1227, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1333\n",
      "Loss: tensor(0.1227, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1334\n",
      "Loss: tensor(0.1227, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1335\n",
      "Loss: tensor(0.1227, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1336\n",
      "Loss: tensor(0.1227, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1337\n",
      "Loss: tensor(0.1227, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1338\n",
      "Loss: tensor(0.1227, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1339\n",
      "Loss: tensor(0.1227, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1340\n",
      "Loss: tensor(0.1227, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1341\n",
      "Loss: tensor(0.1227, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1342\n",
      "Loss: tensor(0.1227, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1343\n",
      "Loss: tensor(0.1227, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1344\n",
      "Loss: tensor(0.1227, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1345\n",
      "Loss: tensor(0.1226, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1346\n",
      "Loss: tensor(0.1226, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1347\n",
      "Loss: tensor(0.1226, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1348\n",
      "Loss: tensor(0.1226, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1349\n",
      "Loss: tensor(0.1226, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1350\n",
      "Loss: tensor(0.1226, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1351\n",
      "Loss: tensor(0.1226, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1352\n",
      "Loss: tensor(0.1226, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1353\n",
      "Loss: tensor(0.1226, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1354\n",
      "Loss: tensor(0.1226, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1355\n",
      "Loss: tensor(0.1226, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1356\n",
      "Loss: tensor(0.1226, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1357\n",
      "Loss: tensor(0.1226, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1358\n",
      "Loss: tensor(0.1226, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1359\n",
      "Loss: tensor(0.1226, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1360\n",
      "Loss: tensor(0.1226, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1361\n",
      "Loss: tensor(0.1226, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1362\n",
      "Loss: tensor(0.1226, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1363\n",
      "Loss: tensor(0.1226, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1364\n",
      "Loss: tensor(0.1226, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1365\n",
      "Loss: tensor(0.1225, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1366\n",
      "Loss: tensor(0.1225, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1367\n",
      "Loss: tensor(0.1225, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1368\n",
      "Loss: tensor(0.1225, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1369\n",
      "Loss: tensor(0.1225, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1370\n",
      "Loss: tensor(0.1225, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1371\n",
      "Loss: tensor(0.1225, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1372\n",
      "Loss: tensor(0.1225, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1373\n",
      "Loss: tensor(0.1225, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1374\n",
      "Loss: tensor(0.1225, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1375\n",
      "Loss: tensor(0.1225, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1376\n",
      "Loss: tensor(0.1225, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1377\n",
      "Loss: tensor(0.1225, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1378\n",
      "Loss: tensor(0.1225, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1379\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor(0.1225, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1380\n",
      "Loss: tensor(0.1225, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1381\n",
      "Loss: tensor(0.1225, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1382\n",
      "Loss: tensor(0.1225, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1383\n",
      "Loss: tensor(0.1224, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1384\n",
      "Loss: tensor(0.1224, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1385\n",
      "Loss: tensor(0.1224, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1386\n",
      "Loss: tensor(0.1224, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1387\n",
      "Loss: tensor(0.1224, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1388\n",
      "Loss: tensor(0.1224, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1389\n",
      "Loss: tensor(0.1224, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1390\n",
      "Loss: tensor(0.1224, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1391\n",
      "Loss: tensor(0.1224, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1392\n",
      "Loss: tensor(0.1224, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1393\n",
      "Loss: tensor(0.1224, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1394\n",
      "Loss: tensor(0.1224, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1395\n",
      "Loss: tensor(0.1224, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1396\n",
      "Loss: tensor(0.1224, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1397\n",
      "Loss: tensor(0.1224, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1398\n",
      "Loss: tensor(0.1224, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1399\n",
      "Loss: tensor(0.1224, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1400\n",
      "Loss: tensor(0.1224, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1401\n",
      "Loss: tensor(0.1223, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1402\n",
      "Loss: tensor(0.1223, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1403\n",
      "Loss: tensor(0.1223, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1404\n",
      "Loss: tensor(0.1223, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1405\n",
      "Loss: tensor(0.1223, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1406\n",
      "Loss: tensor(0.1223, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1407\n",
      "Loss: tensor(0.1223, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1408\n",
      "Loss: tensor(0.1223, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1409\n",
      "Loss: tensor(0.1223, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1410\n",
      "Loss: tensor(0.1223, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1411\n",
      "Loss: tensor(0.1223, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1412\n",
      "Loss: tensor(0.1223, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1413\n",
      "Loss: tensor(0.1223, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1414\n",
      "Loss: tensor(0.1223, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1415\n",
      "Loss: tensor(0.1223, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1416\n",
      "Loss: tensor(0.1223, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1417\n",
      "Loss: tensor(0.1223, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1418\n",
      "Loss: tensor(0.1223, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1419\n",
      "Loss: tensor(0.1222, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1420\n",
      "Loss: tensor(0.1222, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1421\n",
      "Loss: tensor(0.1222, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1422\n",
      "Loss: tensor(0.1222, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1423\n",
      "Loss: tensor(0.1222, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1424\n",
      "Loss: tensor(0.1222, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1425\n",
      "Loss: tensor(0.1222, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1426\n",
      "Loss: tensor(0.1222, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1427\n",
      "Loss: tensor(0.1222, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1428\n",
      "Loss: tensor(0.1222, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1429\n",
      "Loss: tensor(0.1222, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1430\n",
      "Loss: tensor(0.1222, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1431\n",
      "Loss: tensor(0.1222, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1432\n",
      "Loss: tensor(0.1222, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1433\n",
      "Loss: tensor(0.1222, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1434\n",
      "Loss: tensor(0.1222, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1435\n",
      "Loss: tensor(0.1222, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1436\n",
      "Loss: tensor(0.1221, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1437\n",
      "Loss: tensor(0.1221, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1438\n",
      "Loss: tensor(0.1221, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1439\n",
      "Loss: tensor(0.1221, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1440\n",
      "Loss: tensor(0.1221, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1441\n",
      "Loss: tensor(0.1221, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1442\n",
      "Loss: tensor(0.1221, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1443\n",
      "Loss: tensor(0.1221, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1444\n",
      "Loss: tensor(0.1221, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1445\n",
      "Loss: tensor(0.1221, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1446\n",
      "Loss: tensor(0.1221, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1447\n",
      "Loss: tensor(0.1221, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1448\n",
      "Loss: tensor(0.1221, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1449\n",
      "Loss: tensor(0.1221, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1450\n",
      "Loss: tensor(0.1221, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1451\n",
      "Loss: tensor(0.1221, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1452\n",
      "Loss: tensor(0.1221, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1453\n",
      "Loss: tensor(0.1220, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1454\n",
      "Loss: tensor(0.1220, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1455\n",
      "Loss: tensor(0.1220, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1456\n",
      "Loss: tensor(0.1220, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1457\n",
      "Loss: tensor(0.1220, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1458\n",
      "Loss: tensor(0.1220, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1459\n",
      "Loss: tensor(0.1220, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1460\n",
      "Loss: tensor(0.1220, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1461\n",
      "Loss: tensor(0.1220, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1462\n",
      "Loss: tensor(0.1220, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1463\n",
      "Loss: tensor(0.1220, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1464\n",
      "Loss: tensor(0.1220, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1465\n",
      "Loss: tensor(0.1220, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1466\n",
      "Loss: tensor(0.1220, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1467\n",
      "Loss: tensor(0.1220, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1468\n",
      "Loss: tensor(0.1220, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1469\n",
      "Loss: tensor(0.1219, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1470\n",
      "Loss: tensor(0.1219, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1471\n",
      "Loss: tensor(0.1219, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1472\n",
      "Loss: tensor(0.1219, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1473\n",
      "Loss: tensor(0.1219, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1474\n",
      "Loss: tensor(0.1219, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1475\n",
      "Loss: tensor(0.1219, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1476\n",
      "Loss: tensor(0.1219, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1477\n",
      "Loss: tensor(0.1219, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1478\n",
      "Loss: tensor(0.1219, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1479\n",
      "Loss: tensor(0.1219, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1480\n",
      "Loss: tensor(0.1219, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1481\n",
      "Loss: tensor(0.1219, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1482\n",
      "Loss: tensor(0.1219, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1483\n",
      "Loss: tensor(0.1219, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1484\n",
      "Loss: tensor(0.1218, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1485\n",
      "Loss: tensor(0.1218, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1486\n",
      "Loss: tensor(0.1218, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1487\n",
      "Loss: tensor(0.1218, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1488\n",
      "Loss: tensor(0.1218, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1489\n",
      "Loss: tensor(0.1218, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1490\n",
      "Loss: tensor(0.1218, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1491\n",
      "Loss: tensor(0.1218, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1492\n",
      "Loss: tensor(0.1218, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1493\n",
      "Loss: tensor(0.1218, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1494\n",
      "Loss: tensor(0.1218, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1495\n",
      "Loss: tensor(0.1218, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1496\n",
      "Loss: tensor(0.1218, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1497\n",
      "Loss: tensor(0.1218, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1498\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor(0.1218, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1499\n",
      "Loss: tensor(0.1218, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1500\n",
      "Loss: tensor(0.1217, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1501\n",
      "Loss: tensor(0.1217, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1502\n",
      "Loss: tensor(0.1217, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1503\n",
      "Loss: tensor(0.1217, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1504\n",
      "Loss: tensor(0.1217, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1505\n",
      "Loss: tensor(0.1217, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1506\n",
      "Loss: tensor(0.1217, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1507\n",
      "Loss: tensor(0.1217, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1508\n",
      "Loss: tensor(0.1217, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1509\n",
      "Loss: tensor(0.1217, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1510\n",
      "Loss: tensor(0.1217, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1511\n",
      "Loss: tensor(0.1217, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1512\n",
      "Loss: tensor(0.1217, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1513\n",
      "Loss: tensor(0.1217, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1514\n",
      "Loss: tensor(0.1217, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1515\n",
      "Loss: tensor(0.1216, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1516\n",
      "Loss: tensor(0.1216, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1517\n",
      "Loss: tensor(0.1216, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1518\n",
      "Loss: tensor(0.1216, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1519\n",
      "Loss: tensor(0.1216, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1520\n",
      "Loss: tensor(0.1216, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1521\n",
      "Loss: tensor(0.1216, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1522\n",
      "Loss: tensor(0.1216, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1523\n",
      "Loss: tensor(0.1216, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1524\n",
      "Loss: tensor(0.1216, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1525\n",
      "Loss: tensor(0.1216, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1526\n",
      "Loss: tensor(0.1216, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1527\n",
      "Loss: tensor(0.1216, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1528\n",
      "Loss: tensor(0.1216, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1529\n",
      "Loss: tensor(0.1215, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1530\n",
      "Loss: tensor(0.1215, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1531\n",
      "Loss: tensor(0.1215, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1532\n",
      "Loss: tensor(0.1215, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1533\n",
      "Loss: tensor(0.1215, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1534\n",
      "Loss: tensor(0.1215, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1535\n",
      "Loss: tensor(0.1215, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1536\n",
      "Loss: tensor(0.1215, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1537\n",
      "Loss: tensor(0.1215, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1538\n",
      "Loss: tensor(0.1215, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1539\n",
      "Loss: tensor(0.1215, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1540\n",
      "Loss: tensor(0.1215, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1541\n",
      "Loss: tensor(0.1215, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1542\n",
      "Loss: tensor(0.1215, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1543\n",
      "Loss: tensor(0.1215, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1544\n",
      "Loss: tensor(0.1214, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1545\n",
      "Loss: tensor(0.1214, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1546\n",
      "Loss: tensor(0.1214, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1547\n",
      "Loss: tensor(0.1214, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1548\n",
      "Loss: tensor(0.1214, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1549\n",
      "Loss: tensor(0.1214, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1550\n",
      "Loss: tensor(0.1214, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1551\n",
      "Loss: tensor(0.1214, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1552\n",
      "Loss: tensor(0.1214, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1553\n",
      "Loss: tensor(0.1214, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1554\n",
      "Loss: tensor(0.1214, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1555\n",
      "Loss: tensor(0.1214, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1556\n",
      "Loss: tensor(0.1214, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1557\n",
      "Loss: tensor(0.1214, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1558\n",
      "Loss: tensor(0.1213, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1559\n",
      "Loss: tensor(0.1213, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1560\n",
      "Loss: tensor(0.1213, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1561\n",
      "Loss: tensor(0.1213, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1562\n",
      "Loss: tensor(0.1213, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1563\n",
      "Loss: tensor(0.1213, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1564\n",
      "Loss: tensor(0.1213, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1565\n",
      "Loss: tensor(0.1213, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1566\n",
      "Loss: tensor(0.1213, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1567\n",
      "Loss: tensor(0.1213, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1568\n",
      "Loss: tensor(0.1213, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1569\n",
      "Loss: tensor(0.1213, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1570\n",
      "Loss: tensor(0.1213, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1571\n",
      "Loss: tensor(0.1213, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1572\n",
      "Loss: tensor(0.1212, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1573\n",
      "Loss: tensor(0.1212, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1574\n",
      "Loss: tensor(0.1212, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1575\n",
      "Loss: tensor(0.1212, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1576\n",
      "Loss: tensor(0.1212, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1577\n",
      "Loss: tensor(0.1212, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1578\n",
      "Loss: tensor(0.1212, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1579\n",
      "Loss: tensor(0.1212, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1580\n",
      "Loss: tensor(0.1212, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1581\n",
      "Loss: tensor(0.1212, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1582\n",
      "Loss: tensor(0.1212, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1583\n",
      "Loss: tensor(0.1212, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1584\n",
      "Loss: tensor(0.1212, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1585\n",
      "Loss: tensor(0.1212, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1586\n",
      "Loss: tensor(0.1211, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1587\n",
      "Loss: tensor(0.1211, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1588\n",
      "Loss: tensor(0.1211, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1589\n",
      "Loss: tensor(0.1211, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1590\n",
      "Loss: tensor(0.1211, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1591\n",
      "Loss: tensor(0.1211, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1592\n",
      "Loss: tensor(0.1211, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1593\n",
      "Loss: tensor(0.1211, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1594\n",
      "Loss: tensor(0.1211, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1595\n",
      "Loss: tensor(0.1211, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1596\n",
      "Loss: tensor(0.1211, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1597\n",
      "Loss: tensor(0.1211, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1598\n",
      "Loss: tensor(0.1211, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1599\n",
      "Loss: tensor(0.1210, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1600\n",
      "Loss: tensor(0.1210, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1601\n",
      "Loss: tensor(0.1210, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1602\n",
      "Loss: tensor(0.1210, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1603\n",
      "Loss: tensor(0.1210, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1604\n",
      "Loss: tensor(0.1210, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1605\n",
      "Loss: tensor(0.1210, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1606\n",
      "Loss: tensor(0.1210, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1607\n",
      "Loss: tensor(0.1210, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1608\n",
      "Loss: tensor(0.1210, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1609\n",
      "Loss: tensor(0.1210, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1610\n",
      "Loss: tensor(0.1210, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1611\n",
      "Loss: tensor(0.1210, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1612\n",
      "Loss: tensor(0.1210, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1613\n",
      "Loss: tensor(0.1209, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1614\n",
      "Loss: tensor(0.1209, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1615\n",
      "Loss: tensor(0.1209, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1616\n",
      "Loss: tensor(0.1209, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1617\n",
      "Loss: tensor(0.1209, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1618\n",
      "Loss: tensor(0.1209, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1619\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor(0.1209, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1620\n",
      "Loss: tensor(0.1209, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1621\n",
      "Loss: tensor(0.1209, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1622\n",
      "Loss: tensor(0.1209, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1623\n",
      "Loss: tensor(0.1209, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1624\n",
      "Loss: tensor(0.1209, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1625\n",
      "Loss: tensor(0.1209, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1626\n",
      "Loss: tensor(0.1208, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1627\n",
      "Loss: tensor(0.1208, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1628\n",
      "Loss: tensor(0.1208, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1629\n",
      "Loss: tensor(0.1208, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1630\n",
      "Loss: tensor(0.1208, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1631\n",
      "Loss: tensor(0.1208, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1632\n",
      "Loss: tensor(0.1208, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1633\n",
      "Loss: tensor(0.1208, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1634\n",
      "Loss: tensor(0.1208, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1635\n",
      "Loss: tensor(0.1208, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1636\n",
      "Loss: tensor(0.1208, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1637\n",
      "Loss: tensor(0.1208, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1638\n",
      "Loss: tensor(0.1208, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1639\n",
      "Loss: tensor(0.1207, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1640\n",
      "Loss: tensor(0.1207, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1641\n",
      "Loss: tensor(0.1207, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1642\n",
      "Loss: tensor(0.1207, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1643\n",
      "Loss: tensor(0.1207, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1644\n",
      "Loss: tensor(0.1207, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1645\n",
      "Loss: tensor(0.1207, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1646\n",
      "Loss: tensor(0.1207, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1647\n",
      "Loss: tensor(0.1207, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1648\n",
      "Loss: tensor(0.1207, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1649\n",
      "Loss: tensor(0.1207, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1650\n",
      "Loss: tensor(0.1207, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1651\n",
      "Loss: tensor(0.1206, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1652\n",
      "Loss: tensor(0.1206, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1653\n",
      "Loss: tensor(0.1206, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1654\n",
      "Loss: tensor(0.1206, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1655\n",
      "Loss: tensor(0.1206, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1656\n",
      "Loss: tensor(0.1206, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1657\n",
      "Loss: tensor(0.1206, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1658\n",
      "Loss: tensor(0.1206, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1659\n",
      "Loss: tensor(0.1206, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1660\n",
      "Loss: tensor(0.1206, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1661\n",
      "Loss: tensor(0.1206, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1662\n",
      "Loss: tensor(0.1206, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1663\n",
      "Loss: tensor(0.1206, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1664\n",
      "Loss: tensor(0.1205, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1665\n",
      "Loss: tensor(0.1205, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1666\n",
      "Loss: tensor(0.1205, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1667\n",
      "Loss: tensor(0.1205, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1668\n",
      "Loss: tensor(0.1205, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1669\n",
      "Loss: tensor(0.1205, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1670\n",
      "Loss: tensor(0.1205, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1671\n",
      "Loss: tensor(0.1205, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1672\n",
      "Loss: tensor(0.1205, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1673\n",
      "Loss: tensor(0.1205, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1674\n",
      "Loss: tensor(0.1205, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1675\n",
      "Loss: tensor(0.1205, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1676\n",
      "Loss: tensor(0.1204, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1677\n",
      "Loss: tensor(0.1204, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1678\n",
      "Loss: tensor(0.1204, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1679\n",
      "Loss: tensor(0.1204, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1680\n",
      "Loss: tensor(0.1204, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1681\n",
      "Loss: tensor(0.1204, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1682\n",
      "Loss: tensor(0.1204, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1683\n",
      "Loss: tensor(0.1204, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1684\n",
      "Loss: tensor(0.1204, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1685\n",
      "Loss: tensor(0.1204, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1686\n",
      "Loss: tensor(0.1204, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1687\n",
      "Loss: tensor(0.1204, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1688\n",
      "Loss: tensor(0.1203, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1689\n",
      "Loss: tensor(0.1203, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1690\n",
      "Loss: tensor(0.1203, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1691\n",
      "Loss: tensor(0.1203, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1692\n",
      "Loss: tensor(0.1203, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1693\n",
      "Loss: tensor(0.1203, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1694\n",
      "Loss: tensor(0.1203, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1695\n",
      "Loss: tensor(0.1203, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1696\n",
      "Loss: tensor(0.1203, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1697\n",
      "Loss: tensor(0.1203, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1698\n",
      "Loss: tensor(0.1203, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1699\n",
      "Loss: tensor(0.1203, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1700\n",
      "Loss: tensor(0.1202, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1701\n",
      "Loss: tensor(0.1202, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1702\n",
      "Loss: tensor(0.1202, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1703\n",
      "Loss: tensor(0.1202, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1704\n",
      "Loss: tensor(0.1202, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1705\n",
      "Loss: tensor(0.1202, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1706\n",
      "Loss: tensor(0.1202, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1707\n",
      "Loss: tensor(0.1202, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1708\n",
      "Loss: tensor(0.1202, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1709\n",
      "Loss: tensor(0.1202, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1710\n",
      "Loss: tensor(0.1202, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1711\n",
      "Loss: tensor(0.1202, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1712\n",
      "Loss: tensor(0.1201, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1713\n",
      "Loss: tensor(0.1201, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1714\n",
      "Loss: tensor(0.1201, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1715\n",
      "Loss: tensor(0.1201, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1716\n",
      "Loss: tensor(0.1201, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1717\n",
      "Loss: tensor(0.1201, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1718\n",
      "Loss: tensor(0.1201, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1719\n",
      "Loss: tensor(0.1201, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1720\n",
      "Loss: tensor(0.1201, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1721\n",
      "Loss: tensor(0.1201, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1722\n",
      "Loss: tensor(0.1201, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1723\n",
      "Loss: tensor(0.1201, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1724\n",
      "Loss: tensor(0.1200, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1725\n",
      "Loss: tensor(0.1200, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1726\n",
      "Loss: tensor(0.1200, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1727\n",
      "Loss: tensor(0.1200, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1728\n",
      "Loss: tensor(0.1200, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1729\n",
      "Loss: tensor(0.1200, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1730\n",
      "Loss: tensor(0.1200, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1731\n",
      "Loss: tensor(0.1200, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1732\n",
      "Loss: tensor(0.1200, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1733\n",
      "Loss: tensor(0.1200, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1734\n",
      "Loss: tensor(0.1200, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1735\n",
      "Loss: tensor(0.1200, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1736\n",
      "Loss: tensor(0.1199, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1737\n",
      "Loss: tensor(0.1199, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1738\n",
      "Loss: tensor(0.1199, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1739\n",
      "Loss: tensor(0.1199, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1740\n",
      "Loss: tensor(0.1199, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1741\n",
      "Loss: tensor(0.1199, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1742\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor(0.1199, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1743\n",
      "Loss: tensor(0.1199, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1744\n",
      "Loss: tensor(0.1199, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1745\n",
      "Loss: tensor(0.1199, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1746\n",
      "Loss: tensor(0.1199, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1747\n",
      "Loss: tensor(0.1198, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1748\n",
      "Loss: tensor(0.1198, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1749\n",
      "Loss: tensor(0.1198, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1750\n",
      "Loss: tensor(0.1198, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1751\n",
      "Loss: tensor(0.1198, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1752\n",
      "Loss: tensor(0.1198, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1753\n",
      "Loss: tensor(0.1198, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1754\n",
      "Loss: tensor(0.1198, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1755\n",
      "Loss: tensor(0.1198, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1756\n",
      "Loss: tensor(0.1198, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1757\n",
      "Loss: tensor(0.1198, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1758\n",
      "Loss: tensor(0.1198, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1759\n",
      "Loss: tensor(0.1197, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1760\n",
      "Loss: tensor(0.1197, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1761\n",
      "Loss: tensor(0.1197, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1762\n",
      "Loss: tensor(0.1197, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1763\n",
      "Loss: tensor(0.1197, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1764\n",
      "Loss: tensor(0.1197, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1765\n",
      "Loss: tensor(0.1197, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1766\n",
      "Loss: tensor(0.1197, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1767\n",
      "Loss: tensor(0.1197, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1768\n",
      "Loss: tensor(0.1197, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1769\n",
      "Loss: tensor(0.1197, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1770\n",
      "Loss: tensor(0.1196, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1771\n",
      "Loss: tensor(0.1196, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1772\n",
      "Loss: tensor(0.1196, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1773\n",
      "Loss: tensor(0.1196, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1774\n",
      "Loss: tensor(0.1196, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1775\n",
      "Loss: tensor(0.1196, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1776\n",
      "Loss: tensor(0.1196, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1777\n",
      "Loss: tensor(0.1196, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1778\n",
      "Loss: tensor(0.1196, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1779\n",
      "Loss: tensor(0.1196, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1780\n",
      "Loss: tensor(0.1196, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1781\n",
      "Loss: tensor(0.1195, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1782\n",
      "Loss: tensor(0.1195, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1783\n",
      "Loss: tensor(0.1195, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1784\n",
      "Loss: tensor(0.1195, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1785\n",
      "Loss: tensor(0.1195, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1786\n",
      "Loss: tensor(0.1195, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1787\n",
      "Loss: tensor(0.1195, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1788\n",
      "Loss: tensor(0.1195, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1789\n",
      "Loss: tensor(0.1195, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1790\n",
      "Loss: tensor(0.1195, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1791\n",
      "Loss: tensor(0.1195, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1792\n",
      "Loss: tensor(0.1195, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1793\n",
      "Loss: tensor(0.1194, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1794\n",
      "Loss: tensor(0.1194, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1795\n",
      "Loss: tensor(0.1194, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1796\n",
      "Loss: tensor(0.1194, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1797\n",
      "Loss: tensor(0.1194, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1798\n",
      "Loss: tensor(0.1194, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1799\n",
      "Loss: tensor(0.1194, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1800\n",
      "Loss: tensor(0.1194, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1801\n",
      "Loss: tensor(0.1194, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1802\n",
      "Loss: tensor(0.1194, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1803\n",
      "Loss: tensor(0.1194, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1804\n",
      "Loss: tensor(0.1193, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1805\n",
      "Loss: tensor(0.1193, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1806\n",
      "Loss: tensor(0.1193, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1807\n",
      "Loss: tensor(0.1193, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1808\n",
      "Loss: tensor(0.1193, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1809\n",
      "Loss: tensor(0.1193, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1810\n",
      "Loss: tensor(0.1193, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1811\n",
      "Loss: tensor(0.1193, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1812\n",
      "Loss: tensor(0.1193, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1813\n",
      "Loss: tensor(0.1193, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1814\n",
      "Loss: tensor(0.1192, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1815\n",
      "Loss: tensor(0.1192, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1816\n",
      "Loss: tensor(0.1192, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1817\n",
      "Loss: tensor(0.1192, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1818\n",
      "Loss: tensor(0.1192, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1819\n",
      "Loss: tensor(0.1192, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1820\n",
      "Loss: tensor(0.1192, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1821\n",
      "Loss: tensor(0.1192, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1822\n",
      "Loss: tensor(0.1192, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1823\n",
      "Loss: tensor(0.1192, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1824\n",
      "Loss: tensor(0.1192, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1825\n",
      "Loss: tensor(0.1191, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1826\n",
      "Loss: tensor(0.1191, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1827\n",
      "Loss: tensor(0.1191, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1828\n",
      "Loss: tensor(0.1191, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1829\n",
      "Loss: tensor(0.1191, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1830\n",
      "Loss: tensor(0.1191, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1831\n",
      "Loss: tensor(0.1191, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1832\n",
      "Loss: tensor(0.1191, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1833\n",
      "Loss: tensor(0.1191, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1834\n",
      "Loss: tensor(0.1191, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1835\n",
      "Loss: tensor(0.1191, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1836\n",
      "Loss: tensor(0.1190, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1837\n",
      "Loss: tensor(0.1190, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1838\n",
      "Loss: tensor(0.1190, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1839\n",
      "Loss: tensor(0.1190, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1840\n",
      "Loss: tensor(0.1190, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1841\n",
      "Loss: tensor(0.1190, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1842\n",
      "Loss: tensor(0.1190, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1843\n",
      "Loss: tensor(0.1190, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1844\n",
      "Loss: tensor(0.1190, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1845\n",
      "Loss: tensor(0.1190, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1846\n",
      "Loss: tensor(0.1190, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1847\n",
      "Loss: tensor(0.1189, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1848\n",
      "Loss: tensor(0.1189, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1849\n",
      "Loss: tensor(0.1189, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1850\n",
      "Loss: tensor(0.1189, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1851\n",
      "Loss: tensor(0.1189, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1852\n",
      "Loss: tensor(0.1189, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1853\n",
      "Loss: tensor(0.1189, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1854\n",
      "Loss: tensor(0.1189, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1855\n",
      "Loss: tensor(0.1189, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1856\n",
      "Loss: tensor(0.1189, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1857\n",
      "Loss: tensor(0.1188, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1858\n",
      "Loss: tensor(0.1188, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1859\n",
      "Loss: tensor(0.1188, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1860\n",
      "Loss: tensor(0.1188, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1861\n",
      "Loss: tensor(0.1188, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1862\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor(0.1188, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1863\n",
      "Loss: tensor(0.1188, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1864\n",
      "Loss: tensor(0.1188, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1865\n",
      "Loss: tensor(0.1188, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1866\n",
      "Loss: tensor(0.1188, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1867\n",
      "Loss: tensor(0.1188, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1868\n",
      "Loss: tensor(0.1187, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1869\n",
      "Loss: tensor(0.1187, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1870\n",
      "Loss: tensor(0.1187, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1871\n",
      "Loss: tensor(0.1187, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1872\n",
      "Loss: tensor(0.1187, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1873\n",
      "Loss: tensor(0.1187, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1874\n",
      "Loss: tensor(0.1187, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1875\n",
      "Loss: tensor(0.1187, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1876\n",
      "Loss: tensor(0.1187, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1877\n",
      "Loss: tensor(0.1187, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1878\n",
      "Loss: tensor(0.1187, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1879\n",
      "Loss: tensor(0.1186, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1880\n",
      "Loss: tensor(0.1186, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1881\n",
      "Loss: tensor(0.1186, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1882\n",
      "Loss: tensor(0.1186, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1883\n",
      "Loss: tensor(0.1186, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1884\n",
      "Loss: tensor(0.1186, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1885\n",
      "Loss: tensor(0.1186, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1886\n",
      "Loss: tensor(0.1186, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1887\n",
      "Loss: tensor(0.1186, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1888\n",
      "Loss: tensor(0.1186, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1889\n",
      "Loss: tensor(0.1185, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1890\n",
      "Loss: tensor(0.1185, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1891\n",
      "Loss: tensor(0.1185, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1892\n",
      "Loss: tensor(0.1185, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1893\n",
      "Loss: tensor(0.1185, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1894\n",
      "Loss: tensor(0.1185, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1895\n",
      "Loss: tensor(0.1185, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1896\n",
      "Loss: tensor(0.1185, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1897\n",
      "Loss: tensor(0.1185, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1898\n",
      "Loss: tensor(0.1185, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1899\n",
      "Loss: tensor(0.1184, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1900\n",
      "Loss: tensor(0.1184, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1901\n",
      "Loss: tensor(0.1184, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1902\n",
      "Loss: tensor(0.1184, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1903\n",
      "Loss: tensor(0.1184, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1904\n",
      "Loss: tensor(0.1184, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1905\n",
      "Loss: tensor(0.1184, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1906\n",
      "Loss: tensor(0.1184, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1907\n",
      "Loss: tensor(0.1184, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1908\n",
      "Loss: tensor(0.1184, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1909\n",
      "Loss: tensor(0.1183, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1910\n",
      "Loss: tensor(0.1183, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1911\n",
      "Loss: tensor(0.1183, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1912\n",
      "Loss: tensor(0.1183, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1913\n",
      "Loss: tensor(0.1183, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1914\n",
      "Loss: tensor(0.1183, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1915\n",
      "Loss: tensor(0.1183, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1916\n",
      "Loss: tensor(0.1183, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1917\n",
      "Loss: tensor(0.1183, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1918\n",
      "Loss: tensor(0.1183, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1919\n",
      "Loss: tensor(0.1182, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1920\n",
      "Loss: tensor(0.1182, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1921\n",
      "Loss: tensor(0.1182, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1922\n",
      "Loss: tensor(0.1182, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1923\n",
      "Loss: tensor(0.1182, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1924\n",
      "Loss: tensor(0.1182, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1925\n",
      "Loss: tensor(0.1182, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1926\n",
      "Loss: tensor(0.1182, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1927\n",
      "Loss: tensor(0.1182, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1928\n",
      "Loss: tensor(0.1182, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1929\n",
      "Loss: tensor(0.1181, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1930\n",
      "Loss: tensor(0.1181, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1931\n",
      "Loss: tensor(0.1181, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1932\n",
      "Loss: tensor(0.1181, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1933\n",
      "Loss: tensor(0.1181, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1934\n",
      "Loss: tensor(0.1181, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1935\n",
      "Loss: tensor(0.1181, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1936\n",
      "Loss: tensor(0.1181, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1937\n",
      "Loss: tensor(0.1181, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1938\n",
      "Loss: tensor(0.1181, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1939\n",
      "Loss: tensor(0.1180, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1940\n",
      "Loss: tensor(0.1180, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1941\n",
      "Loss: tensor(0.1180, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1942\n",
      "Loss: tensor(0.1180, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1943\n",
      "Loss: tensor(0.1180, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1944\n",
      "Loss: tensor(0.1180, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1945\n",
      "Loss: tensor(0.1180, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1946\n",
      "Loss: tensor(0.1180, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1947\n",
      "Loss: tensor(0.1180, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1948\n",
      "Loss: tensor(0.1180, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1949\n",
      "Loss: tensor(0.1179, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1950\n",
      "Loss: tensor(0.1179, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1951\n",
      "Loss: tensor(0.1179, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1952\n",
      "Loss: tensor(0.1179, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1953\n",
      "Loss: tensor(0.1179, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1954\n",
      "Loss: tensor(0.1179, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1955\n",
      "Loss: tensor(0.1179, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1956\n",
      "Loss: tensor(0.1179, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1957\n",
      "Loss: tensor(0.1179, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1958\n",
      "Loss: tensor(0.1179, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1959\n",
      "Loss: tensor(0.1178, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1960\n",
      "Loss: tensor(0.1178, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1961\n",
      "Loss: tensor(0.1178, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1962\n",
      "Loss: tensor(0.1178, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1963\n",
      "Loss: tensor(0.1178, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1964\n",
      "Loss: tensor(0.1178, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1965\n",
      "Loss: tensor(0.1178, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1966\n",
      "Loss: tensor(0.1178, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1967\n",
      "Loss: tensor(0.1178, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1968\n",
      "Loss: tensor(0.1178, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1969\n",
      "Loss: tensor(0.1177, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1970\n",
      "Loss: tensor(0.1177, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1971\n",
      "Loss: tensor(0.1177, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1972\n",
      "Loss: tensor(0.1177, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1973\n",
      "Loss: tensor(0.1177, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1974\n",
      "Loss: tensor(0.1177, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1975\n",
      "Loss: tensor(0.1177, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1976\n",
      "Loss: tensor(0.1177, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1977\n",
      "Loss: tensor(0.1177, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1978\n",
      "Loss: tensor(0.1176, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1979\n",
      "Loss: tensor(0.1176, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1980\n",
      "Loss: tensor(0.1176, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1981\n",
      "Loss: tensor(0.1176, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1982\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor(0.1176, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1983\n",
      "Loss: tensor(0.1176, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1984\n",
      "Loss: tensor(0.1176, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1985\n",
      "Loss: tensor(0.1176, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1986\n",
      "Loss: tensor(0.1176, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1987\n",
      "Loss: tensor(0.1176, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1988\n",
      "Loss: tensor(0.1175, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1989\n",
      "Loss: tensor(0.1175, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1990\n",
      "Loss: tensor(0.1175, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1991\n",
      "Loss: tensor(0.1175, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1992\n",
      "Loss: tensor(0.1175, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1993\n",
      "Loss: tensor(0.1175, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1994\n",
      "Loss: tensor(0.1175, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1995\n",
      "Loss: tensor(0.1175, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1996\n",
      "Loss: tensor(0.1175, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1997\n",
      "Loss: tensor(0.1175, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1998\n",
      "Loss: tensor(0.1174, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1999\n",
      "Loss: tensor(0.1174, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2000\n",
      "Loss: tensor(0.1174, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2001\n",
      "Loss: tensor(0.1174, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2002\n",
      "Loss: tensor(0.1174, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2003\n",
      "Loss: tensor(0.1174, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2004\n",
      "Loss: tensor(0.1174, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2005\n",
      "Loss: tensor(0.1174, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2006\n",
      "Loss: tensor(0.1174, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2007\n",
      "Loss: tensor(0.1173, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2008\n",
      "Loss: tensor(0.1173, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2009\n",
      "Loss: tensor(0.1173, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2010\n",
      "Loss: tensor(0.1173, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2011\n",
      "Loss: tensor(0.1173, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2012\n",
      "Loss: tensor(0.1173, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2013\n",
      "Loss: tensor(0.1173, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2014\n",
      "Loss: tensor(0.1173, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2015\n",
      "Loss: tensor(0.1173, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2016\n",
      "Loss: tensor(0.1173, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2017\n",
      "Loss: tensor(0.1172, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2018\n",
      "Loss: tensor(0.1172, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2019\n",
      "Loss: tensor(0.1172, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2020\n",
      "Loss: tensor(0.1172, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2021\n",
      "Loss: tensor(0.1172, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2022\n",
      "Loss: tensor(0.1172, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2023\n",
      "Loss: tensor(0.1172, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2024\n",
      "Loss: tensor(0.1172, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2025\n",
      "Loss: tensor(0.1172, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2026\n",
      "Loss: tensor(0.1171, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2027\n",
      "Loss: tensor(0.1171, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2028\n",
      "Loss: tensor(0.1171, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2029\n",
      "Loss: tensor(0.1171, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2030\n",
      "Loss: tensor(0.1171, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2031\n",
      "Loss: tensor(0.1171, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2032\n",
      "Loss: tensor(0.1171, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2033\n",
      "Loss: tensor(0.1171, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2034\n",
      "Loss: tensor(0.1171, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2035\n",
      "Loss: tensor(0.1171, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2036\n",
      "Loss: tensor(0.1170, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2037\n",
      "Loss: tensor(0.1170, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2038\n",
      "Loss: tensor(0.1170, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2039\n",
      "Loss: tensor(0.1170, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2040\n",
      "Loss: tensor(0.1170, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2041\n",
      "Loss: tensor(0.1170, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2042\n",
      "Loss: tensor(0.1170, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2043\n",
      "Loss: tensor(0.1170, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2044\n",
      "Loss: tensor(0.1170, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2045\n",
      "Loss: tensor(0.1169, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2046\n",
      "Loss: tensor(0.1169, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2047\n",
      "Loss: tensor(0.1169, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2048\n",
      "Loss: tensor(0.1169, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2049\n",
      "Loss: tensor(0.1169, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2050\n",
      "Loss: tensor(0.1169, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2051\n",
      "Loss: tensor(0.1169, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2052\n",
      "Loss: tensor(0.1169, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2053\n",
      "Loss: tensor(0.1169, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2054\n",
      "Loss: tensor(0.1168, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2055\n",
      "Loss: tensor(0.1168, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2056\n",
      "Loss: tensor(0.1168, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2057\n",
      "Loss: tensor(0.1168, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2058\n",
      "Loss: tensor(0.1168, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2059\n",
      "Loss: tensor(0.1168, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2060\n",
      "Loss: tensor(0.1168, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2061\n",
      "Loss: tensor(0.1168, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2062\n",
      "Loss: tensor(0.1168, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2063\n",
      "Loss: tensor(0.1168, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2064\n",
      "Loss: tensor(0.1167, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2065\n",
      "Loss: tensor(0.1167, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2066\n",
      "Loss: tensor(0.1167, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2067\n",
      "Loss: tensor(0.1167, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2068\n",
      "Loss: tensor(0.1167, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2069\n",
      "Loss: tensor(0.1167, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2070\n",
      "Loss: tensor(0.1167, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2071\n",
      "Loss: tensor(0.1167, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2072\n",
      "Loss: tensor(0.1167, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2073\n",
      "Loss: tensor(0.1166, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2074\n",
      "Loss: tensor(0.1166, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2075\n",
      "Loss: tensor(0.1166, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2076\n",
      "Loss: tensor(0.1166, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2077\n",
      "Loss: tensor(0.1166, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2078\n",
      "Loss: tensor(0.1166, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2079\n",
      "Loss: tensor(0.1166, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2080\n",
      "Loss: tensor(0.1166, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2081\n",
      "Loss: tensor(0.1166, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2082\n",
      "Loss: tensor(0.1165, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2083\n",
      "Loss: tensor(0.1165, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2084\n",
      "Loss: tensor(0.1165, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2085\n",
      "Loss: tensor(0.1165, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2086\n",
      "Loss: tensor(0.1165, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2087\n",
      "Loss: tensor(0.1165, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2088\n",
      "Loss: tensor(0.1165, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2089\n",
      "Loss: tensor(0.1165, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2090\n",
      "Loss: tensor(0.1165, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2091\n",
      "Loss: tensor(0.1164, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2092\n",
      "Loss: tensor(0.1164, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2093\n",
      "Loss: tensor(0.1164, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2094\n",
      "Loss: tensor(0.1164, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2095\n",
      "Loss: tensor(0.1164, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2096\n",
      "Loss: tensor(0.1164, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2097\n",
      "Loss: tensor(0.1164, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2098\n",
      "Loss: tensor(0.1164, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2099\n",
      "Loss: tensor(0.1164, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2100\n",
      "Loss: tensor(0.1163, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2101\n",
      "Loss: tensor(0.1163, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2102\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor(0.1163, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2103\n",
      "Loss: tensor(0.1163, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2104\n",
      "Loss: tensor(0.1163, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2105\n",
      "Loss: tensor(0.1163, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2106\n",
      "Loss: tensor(0.1163, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2107\n",
      "Loss: tensor(0.1163, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2108\n",
      "Loss: tensor(0.1163, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2109\n",
      "Loss: tensor(0.1163, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2110\n",
      "Loss: tensor(0.1162, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2111\n",
      "Loss: tensor(0.1162, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2112\n",
      "Loss: tensor(0.1162, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2113\n",
      "Loss: tensor(0.1162, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2114\n",
      "Loss: tensor(0.1162, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2115\n",
      "Loss: tensor(0.1162, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2116\n",
      "Loss: tensor(0.1162, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2117\n",
      "Loss: tensor(0.1162, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2118\n",
      "Loss: tensor(0.1162, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2119\n",
      "Loss: tensor(0.1162, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2120\n",
      "Loss: tensor(0.1161, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2121\n",
      "Loss: tensor(0.1161, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2122\n",
      "Loss: tensor(0.1161, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2123\n",
      "Loss: tensor(0.1161, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2124\n",
      "Loss: tensor(0.1161, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2125\n",
      "Loss: tensor(0.1161, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2126\n",
      "Loss: tensor(0.1161, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2127\n",
      "Loss: tensor(0.1161, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2128\n",
      "Loss: tensor(0.1160, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2129\n",
      "Loss: tensor(0.1160, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2130\n",
      "Loss: tensor(0.1160, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2131\n",
      "Loss: tensor(0.1160, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2132\n",
      "Loss: tensor(0.1160, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2133\n",
      "Loss: tensor(0.1160, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2134\n",
      "Loss: tensor(0.1160, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2135\n",
      "Loss: tensor(0.1160, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2136\n",
      "Loss: tensor(0.1160, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2137\n",
      "Loss: tensor(0.1159, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2138\n",
      "Loss: tensor(0.1159, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2139\n",
      "Loss: tensor(0.1159, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2140\n",
      "Loss: tensor(0.1159, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2141\n",
      "Loss: tensor(0.1159, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2142\n",
      "Loss: tensor(0.1159, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2143\n",
      "Loss: tensor(0.1159, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2144\n",
      "Loss: tensor(0.1159, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2145\n",
      "Loss: tensor(0.1159, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2146\n",
      "Loss: tensor(0.1158, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2147\n",
      "Loss: tensor(0.1158, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2148\n",
      "Loss: tensor(0.1158, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2149\n",
      "Loss: tensor(0.1158, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2150\n",
      "Loss: tensor(0.1158, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2151\n",
      "Loss: tensor(0.1158, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2152\n",
      "Loss: tensor(0.1158, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2153\n",
      "Loss: tensor(0.1158, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2154\n",
      "Loss: tensor(0.1158, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2155\n",
      "Loss: tensor(0.1157, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2156\n",
      "Loss: tensor(0.1157, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2157\n",
      "Loss: tensor(0.1157, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2158\n",
      "Loss: tensor(0.1157, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2159\n",
      "Loss: tensor(0.1157, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2160\n",
      "Loss: tensor(0.1157, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2161\n",
      "Loss: tensor(0.1157, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2162\n",
      "Loss: tensor(0.1157, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2163\n",
      "Loss: tensor(0.1157, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2164\n",
      "Loss: tensor(0.1156, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2165\n",
      "Loss: tensor(0.1156, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2166\n",
      "Loss: tensor(0.1156, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2167\n",
      "Loss: tensor(0.1156, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2168\n",
      "Loss: tensor(0.1156, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2169\n",
      "Loss: tensor(0.1156, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2170\n",
      "Loss: tensor(0.1156, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2171\n",
      "Loss: tensor(0.1156, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2172\n",
      "Loss: tensor(0.1155, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2173\n",
      "Loss: tensor(0.1155, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2174\n",
      "Loss: tensor(0.1155, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2175\n",
      "Loss: tensor(0.1155, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2176\n",
      "Loss: tensor(0.1155, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2177\n",
      "Loss: tensor(0.1155, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2178\n",
      "Loss: tensor(0.1155, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2179\n",
      "Loss: tensor(0.1155, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2180\n",
      "Loss: tensor(0.1155, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2181\n",
      "Loss: tensor(0.1155, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2182\n",
      "Loss: tensor(0.1154, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2183\n",
      "Loss: tensor(0.1154, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2184\n",
      "Loss: tensor(0.1154, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2185\n",
      "Loss: tensor(0.1154, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2186\n",
      "Loss: tensor(0.1154, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2187\n",
      "Loss: tensor(0.1154, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2188\n",
      "Loss: tensor(0.1154, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2189\n",
      "Loss: tensor(0.1154, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2190\n",
      "Loss: tensor(0.1154, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2191\n",
      "Loss: tensor(0.1153, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2192\n",
      "Loss: tensor(0.1153, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2193\n",
      "Loss: tensor(0.1153, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2194\n",
      "Loss: tensor(0.1153, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2195\n",
      "Loss: tensor(0.1153, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2196\n",
      "Loss: tensor(0.1153, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2197\n",
      "Loss: tensor(0.1153, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2198\n",
      "Loss: tensor(0.1153, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2199\n",
      "Loss: tensor(0.1152, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2200\n",
      "Loss: tensor(0.1152, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2201\n",
      "Loss: tensor(0.1152, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2202\n",
      "Loss: tensor(0.1152, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2203\n",
      "Loss: tensor(0.1152, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2204\n",
      "Loss: tensor(0.1152, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2205\n",
      "Loss: tensor(0.1152, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2206\n",
      "Loss: tensor(0.1152, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2207\n",
      "Loss: tensor(0.1152, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2208\n",
      "Loss: tensor(0.1151, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2209\n",
      "Loss: tensor(0.1151, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2210\n",
      "Loss: tensor(0.1151, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2211\n",
      "Loss: tensor(0.1151, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2212\n",
      "Loss: tensor(0.1151, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2213\n",
      "Loss: tensor(0.1151, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2214\n",
      "Loss: tensor(0.1151, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2215\n",
      "Loss: tensor(0.1151, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2216\n",
      "Loss: tensor(0.1151, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2217\n",
      "Loss: tensor(0.1150, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2218\n",
      "Loss: tensor(0.1150, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2219\n",
      "Loss: tensor(0.1150, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2220\n",
      "Loss: tensor(0.1150, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2221\n",
      "Loss: tensor(0.1150, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2222\n",
      "Loss: tensor(0.1150, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2223\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor(0.1150, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2224\n",
      "Loss: tensor(0.1150, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2225\n",
      "Loss: tensor(0.1149, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2226\n",
      "Loss: tensor(0.1149, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2227\n",
      "Loss: tensor(0.1149, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2228\n",
      "Loss: tensor(0.1149, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2229\n",
      "Loss: tensor(0.1149, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2230\n",
      "Loss: tensor(0.1149, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2231\n",
      "Loss: tensor(0.1149, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2232\n",
      "Loss: tensor(0.1149, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2233\n",
      "Loss: tensor(0.1149, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2234\n",
      "Loss: tensor(0.1148, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2235\n",
      "Loss: tensor(0.1148, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2236\n",
      "Loss: tensor(0.1148, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2237\n",
      "Loss: tensor(0.1148, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2238\n",
      "Loss: tensor(0.1148, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2239\n",
      "Loss: tensor(0.1148, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2240\n",
      "Loss: tensor(0.1148, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2241\n",
      "Loss: tensor(0.1148, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2242\n",
      "Loss: tensor(0.1148, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2243\n",
      "Loss: tensor(0.1147, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2244\n",
      "Loss: tensor(0.1147, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2245\n",
      "Loss: tensor(0.1147, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2246\n",
      "Loss: tensor(0.1147, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2247\n",
      "Loss: tensor(0.1147, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2248\n",
      "Loss: tensor(0.1147, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2249\n",
      "Loss: tensor(0.1147, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2250\n",
      "Loss: tensor(0.1147, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2251\n",
      "Loss: tensor(0.1146, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2252\n",
      "Loss: tensor(0.1146, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2253\n",
      "Loss: tensor(0.1146, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2254\n",
      "Loss: tensor(0.1146, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2255\n",
      "Loss: tensor(0.1146, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2256\n",
      "Loss: tensor(0.1146, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2257\n",
      "Loss: tensor(0.1146, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2258\n",
      "Loss: tensor(0.1146, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2259\n",
      "Loss: tensor(0.1146, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2260\n",
      "Loss: tensor(0.1145, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2261\n",
      "Loss: tensor(0.1145, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2262\n",
      "Loss: tensor(0.1145, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2263\n",
      "Loss: tensor(0.1145, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2264\n",
      "Loss: tensor(0.1145, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2265\n",
      "Loss: tensor(0.1145, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2266\n",
      "Loss: tensor(0.1145, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2267\n",
      "Loss: tensor(0.1145, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2268\n",
      "Loss: tensor(0.1144, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2269\n",
      "Loss: tensor(0.1144, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2270\n",
      "Loss: tensor(0.1144, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2271\n",
      "Loss: tensor(0.1144, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2272\n",
      "Loss: tensor(0.1144, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2273\n",
      "Loss: tensor(0.1144, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2274\n",
      "Loss: tensor(0.1144, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2275\n",
      "Loss: tensor(0.1144, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2276\n",
      "Loss: tensor(0.1144, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2277\n",
      "Loss: tensor(0.1143, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2278\n",
      "Loss: tensor(0.1143, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2279\n",
      "Loss: tensor(0.1143, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2280\n",
      "Loss: tensor(0.1143, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2281\n",
      "Loss: tensor(0.1143, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2282\n",
      "Loss: tensor(0.1143, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2283\n",
      "Loss: tensor(0.1143, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2284\n",
      "Loss: tensor(0.1143, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2285\n",
      "Loss: tensor(0.1143, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2286\n",
      "Loss: tensor(0.1142, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2287\n",
      "Loss: tensor(0.1142, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2288\n",
      "Loss: tensor(0.1142, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2289\n",
      "Loss: tensor(0.1142, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2290\n",
      "Loss: tensor(0.1142, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2291\n",
      "Loss: tensor(0.1142, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2292\n",
      "Loss: tensor(0.1142, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2293\n",
      "Loss: tensor(0.1142, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2294\n",
      "Loss: tensor(0.1141, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2295\n",
      "Loss: tensor(0.1141, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2296\n",
      "Loss: tensor(0.1141, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2297\n",
      "Loss: tensor(0.1141, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2298\n",
      "Loss: tensor(0.1141, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2299\n",
      "Loss: tensor(0.1141, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2300\n",
      "Loss: tensor(0.1141, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2301\n",
      "Loss: tensor(0.1141, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2302\n",
      "Loss: tensor(0.1140, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2303\n",
      "Loss: tensor(0.1140, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2304\n",
      "Loss: tensor(0.1140, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2305\n",
      "Loss: tensor(0.1140, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2306\n",
      "Loss: tensor(0.1140, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2307\n",
      "Loss: tensor(0.1140, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2308\n",
      "Loss: tensor(0.1140, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2309\n",
      "Loss: tensor(0.1140, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2310\n",
      "Loss: tensor(0.1140, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2311\n",
      "Loss: tensor(0.1140, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2312\n",
      "Loss: tensor(0.1140, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2313\n",
      "Loss: tensor(0.1139, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2314\n",
      "Loss: tensor(0.1139, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2315\n",
      "Loss: tensor(0.1139, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2316\n",
      "Loss: tensor(0.1139, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2317\n",
      "Loss: tensor(0.1139, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2318\n",
      "Loss: tensor(0.1139, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2319\n",
      "Loss: tensor(0.1138, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2320\n",
      "Loss: tensor(0.1138, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2321\n",
      "Loss: tensor(0.1138, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2322\n",
      "Loss: tensor(0.1138, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2323\n",
      "Loss: tensor(0.1138, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2324\n",
      "Loss: tensor(0.1138, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2325\n",
      "Loss: tensor(0.1138, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2326\n",
      "Loss: tensor(0.1138, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2327\n",
      "Loss: tensor(0.1138, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2328\n",
      "Loss: tensor(0.1137, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2329\n",
      "Loss: tensor(0.1137, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2330\n",
      "Loss: tensor(0.1137, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2331\n",
      "Loss: tensor(0.1137, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2332\n",
      "Loss: tensor(0.1137, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2333\n",
      "Loss: tensor(0.1137, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2334\n",
      "Loss: tensor(0.1137, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2335\n",
      "Loss: tensor(0.1137, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2336\n",
      "Loss: tensor(0.1136, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2337\n",
      "Loss: tensor(0.1136, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2338\n",
      "Loss: tensor(0.1136, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2339\n",
      "Loss: tensor(0.1136, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2340\n",
      "Loss: tensor(0.1136, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2341\n",
      "Loss: tensor(0.1136, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2342\n",
      "Loss: tensor(0.1136, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2343\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor(0.1136, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2344\n",
      "Loss: tensor(0.1135, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2345\n",
      "Loss: tensor(0.1135, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2346\n",
      "Loss: tensor(0.1135, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2347\n",
      "Loss: tensor(0.1135, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2348\n",
      "Loss: tensor(0.1135, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2349\n",
      "Loss: tensor(0.1135, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2350\n",
      "Loss: tensor(0.1135, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2351\n",
      "Loss: tensor(0.1135, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2352\n",
      "Loss: tensor(0.1135, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2353\n",
      "Loss: tensor(0.1134, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2354\n",
      "Loss: tensor(0.1134, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2355\n",
      "Loss: tensor(0.1134, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2356\n",
      "Loss: tensor(0.1134, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2357\n",
      "Loss: tensor(0.1134, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2358\n",
      "Loss: tensor(0.1134, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2359\n",
      "Loss: tensor(0.1134, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2360\n",
      "Loss: tensor(0.1134, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2361\n",
      "Loss: tensor(0.1133, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2362\n",
      "Loss: tensor(0.1133, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2363\n",
      "Loss: tensor(0.1133, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2364\n",
      "Loss: tensor(0.1133, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2365\n",
      "Loss: tensor(0.1133, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2366\n",
      "Loss: tensor(0.1133, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2367\n",
      "Loss: tensor(0.1133, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2368\n",
      "Loss: tensor(0.1133, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2369\n",
      "Loss: tensor(0.1132, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2370\n",
      "Loss: tensor(0.1132, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2371\n",
      "Loss: tensor(0.1132, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2372\n",
      "Loss: tensor(0.1132, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2373\n",
      "Loss: tensor(0.1132, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2374\n",
      "Loss: tensor(0.1132, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2375\n",
      "Loss: tensor(0.1132, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2376\n",
      "Loss: tensor(0.1132, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2377\n",
      "Loss: tensor(0.1132, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2378\n",
      "Loss: tensor(0.1131, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2379\n",
      "Loss: tensor(0.1131, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2380\n",
      "Loss: tensor(0.1131, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2381\n",
      "Loss: tensor(0.1131, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2382\n",
      "Loss: tensor(0.1131, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2383\n",
      "Loss: tensor(0.1131, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2384\n",
      "Loss: tensor(0.1131, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2385\n",
      "Loss: tensor(0.1131, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2386\n",
      "Loss: tensor(0.1130, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2387\n",
      "Loss: tensor(0.1130, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2388\n",
      "Loss: tensor(0.1130, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2389\n",
      "Loss: tensor(0.1130, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2390\n",
      "Loss: tensor(0.1130, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2391\n",
      "Loss: tensor(0.1130, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2392\n",
      "Loss: tensor(0.1130, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2393\n",
      "Loss: tensor(0.1130, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2394\n",
      "Loss: tensor(0.1129, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2395\n",
      "Loss: tensor(0.1129, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2396\n",
      "Loss: tensor(0.1129, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2397\n",
      "Loss: tensor(0.1129, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2398\n",
      "Loss: tensor(0.1129, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2399\n",
      "Loss: tensor(0.1129, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2400\n",
      "Loss: tensor(0.1129, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2401\n",
      "Loss: tensor(0.1129, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2402\n",
      "Loss: tensor(0.1128, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2403\n",
      "Loss: tensor(0.1128, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2404\n",
      "Loss: tensor(0.1128, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2405\n",
      "Loss: tensor(0.1128, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2406\n",
      "Loss: tensor(0.1128, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2407\n",
      "Loss: tensor(0.1128, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2408\n",
      "Loss: tensor(0.1128, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2409\n",
      "Loss: tensor(0.1128, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2410\n",
      "Loss: tensor(0.1127, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2411\n",
      "Loss: tensor(0.1127, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2412\n",
      "Loss: tensor(0.1127, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2413\n",
      "Loss: tensor(0.1127, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2414\n",
      "Loss: tensor(0.1127, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2415\n",
      "Loss: tensor(0.1127, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2416\n",
      "Loss: tensor(0.1127, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2417\n",
      "Loss: tensor(0.1127, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2418\n",
      "Loss: tensor(0.1126, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2419\n",
      "Loss: tensor(0.1126, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2420\n",
      "Loss: tensor(0.1126, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2421\n",
      "Loss: tensor(0.1126, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2422\n",
      "Loss: tensor(0.1126, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2423\n",
      "Loss: tensor(0.1126, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2424\n",
      "Loss: tensor(0.1126, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2425\n",
      "Loss: tensor(0.1126, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2426\n",
      "Loss: tensor(0.1125, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2427\n",
      "Loss: tensor(0.1125, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2428\n",
      "Loss: tensor(0.1125, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2429\n",
      "Loss: tensor(0.1125, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2430\n",
      "Loss: tensor(0.1125, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2431\n",
      "Loss: tensor(0.1125, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2432\n",
      "Loss: tensor(0.1125, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2433\n",
      "Loss: tensor(0.1125, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2434\n",
      "Loss: tensor(0.1124, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2435\n",
      "Loss: tensor(0.1124, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2436\n",
      "Loss: tensor(0.1124, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2437\n",
      "Loss: tensor(0.1124, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2438\n",
      "Loss: tensor(0.1124, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2439\n",
      "Loss: tensor(0.1124, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2440\n",
      "Loss: tensor(0.1124, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2441\n",
      "Loss: tensor(0.1124, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2442\n",
      "Loss: tensor(0.1124, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2443\n",
      "Loss: tensor(0.1124, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2444\n",
      "Loss: tensor(0.1123, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2445\n",
      "Loss: tensor(0.1123, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2446\n",
      "Loss: tensor(0.1123, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2447\n",
      "Loss: tensor(0.1123, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2448\n",
      "Loss: tensor(0.1123, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2449\n",
      "Loss: tensor(0.1123, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2450\n",
      "Loss: tensor(0.1123, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2451\n",
      "Loss: tensor(0.1122, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2452\n",
      "Loss: tensor(0.1122, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2453\n",
      "Loss: tensor(0.1122, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2454\n",
      "Loss: tensor(0.1122, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2455\n",
      "Loss: tensor(0.1122, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2456\n",
      "Loss: tensor(0.1122, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2457\n",
      "Loss: tensor(0.1122, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2458\n",
      "Loss: tensor(0.1122, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2459\n",
      "Loss: tensor(0.1121, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2460\n",
      "Loss: tensor(0.1121, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2461\n",
      "Loss: tensor(0.1121, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2462\n",
      "Loss: tensor(0.1121, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2463\n",
      "Loss: tensor(0.1121, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2464\n",
      "Loss: tensor(0.1121, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2465\n",
      "Loss: tensor(0.1121, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2466\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor(0.1121, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2467\n",
      "Loss: tensor(0.1120, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2468\n",
      "Loss: tensor(0.1120, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2469\n",
      "Loss: tensor(0.1120, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2470\n",
      "Loss: tensor(0.1120, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2471\n",
      "Loss: tensor(0.1120, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2472\n",
      "Loss: tensor(0.1120, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2473\n",
      "Loss: tensor(0.1120, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2474\n",
      "Loss: tensor(0.1120, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2475\n",
      "Loss: tensor(0.1119, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2476\n",
      "Loss: tensor(0.1119, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2477\n",
      "Loss: tensor(0.1119, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2478\n",
      "Loss: tensor(0.1119, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2479\n",
      "Loss: tensor(0.1119, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2480\n",
      "Loss: tensor(0.1119, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2481\n",
      "Loss: tensor(0.1119, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2482\n",
      "Loss: tensor(0.1119, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2483\n",
      "Loss: tensor(0.1118, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2484\n",
      "Loss: tensor(0.1118, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2485\n",
      "Loss: tensor(0.1118, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2486\n",
      "Loss: tensor(0.1118, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2487\n",
      "Loss: tensor(0.1118, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2488\n",
      "Loss: tensor(0.1118, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2489\n",
      "Loss: tensor(0.1118, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2490\n",
      "Loss: tensor(0.1118, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2491\n",
      "Loss: tensor(0.1117, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2492\n",
      "Loss: tensor(0.1117, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2493\n",
      "Loss: tensor(0.1117, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2494\n",
      "Loss: tensor(0.1117, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2495\n",
      "Loss: tensor(0.1117, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2496\n",
      "Loss: tensor(0.1117, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2497\n",
      "Loss: tensor(0.1117, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2498\n",
      "Loss: tensor(0.1117, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2499\n",
      "Loss: tensor(0.1116, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2500\n",
      "Loss: tensor(0.1116, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2501\n",
      "Loss: tensor(0.1116, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2502\n",
      "Loss: tensor(0.1116, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2503\n",
      "Loss: tensor(0.1116, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2504\n",
      "Loss: tensor(0.1116, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2505\n",
      "Loss: tensor(0.1116, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2506\n",
      "Loss: tensor(0.1116, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2507\n",
      "Loss: tensor(0.1115, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2508\n",
      "Loss: tensor(0.1115, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2509\n",
      "Loss: tensor(0.1115, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2510\n",
      "Loss: tensor(0.1115, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2511\n",
      "Loss: tensor(0.1115, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2512\n",
      "Loss: tensor(0.1115, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2513\n",
      "Loss: tensor(0.1115, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2514\n",
      "Loss: tensor(0.1115, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2515\n",
      "Loss: tensor(0.1114, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2516\n",
      "Loss: tensor(0.1114, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2517\n",
      "Loss: tensor(0.1114, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2518\n",
      "Loss: tensor(0.1114, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2519\n",
      "Loss: tensor(0.1114, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2520\n",
      "Loss: tensor(0.1114, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2521\n",
      "Loss: tensor(0.1114, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2522\n",
      "Loss: tensor(0.1114, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2523\n",
      "Loss: tensor(0.1113, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2524\n",
      "Loss: tensor(0.1113, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2525\n",
      "Loss: tensor(0.1113, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2526\n",
      "Loss: tensor(0.1113, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2527\n",
      "Loss: tensor(0.1113, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2528\n",
      "Loss: tensor(0.1113, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2529\n",
      "Loss: tensor(0.1113, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2530\n",
      "Loss: tensor(0.1113, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2531\n",
      "Loss: tensor(0.1112, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2532\n",
      "Loss: tensor(0.1112, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2533\n",
      "Loss: tensor(0.1112, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2534\n",
      "Loss: tensor(0.1112, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2535\n",
      "Loss: tensor(0.1112, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2536\n",
      "Loss: tensor(0.1112, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2537\n",
      "Loss: tensor(0.1112, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2538\n",
      "Loss: tensor(0.1112, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2539\n",
      "Loss: tensor(0.1111, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2540\n",
      "Loss: tensor(0.1111, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2541\n",
      "Loss: tensor(0.1111, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2542\n",
      "Loss: tensor(0.1111, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2543\n",
      "Loss: tensor(0.1111, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2544\n",
      "Loss: tensor(0.1111, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2545\n",
      "Loss: tensor(0.1111, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2546\n",
      "Loss: tensor(0.1111, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2547\n",
      "Loss: tensor(0.1110, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2548\n",
      "Loss: tensor(0.1110, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2549\n",
      "Loss: tensor(0.1110, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2550\n",
      "Loss: tensor(0.1110, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2551\n",
      "Loss: tensor(0.1110, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2552\n",
      "Loss: tensor(0.1110, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2553\n",
      "Loss: tensor(0.1110, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2554\n",
      "Loss: tensor(0.1110, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2555\n",
      "Loss: tensor(0.1109, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2556\n",
      "Loss: tensor(0.1109, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2557\n",
      "Loss: tensor(0.1109, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2558\n",
      "Loss: tensor(0.1109, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2559\n",
      "Loss: tensor(0.1109, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2560\n",
      "Loss: tensor(0.1109, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2561\n",
      "Loss: tensor(0.1109, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2562\n",
      "Loss: tensor(0.1109, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2563\n",
      "Loss: tensor(0.1108, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2564\n",
      "Loss: tensor(0.1108, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2565\n",
      "Loss: tensor(0.1108, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2566\n",
      "Loss: tensor(0.1108, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2567\n",
      "Loss: tensor(0.1108, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2568\n",
      "Loss: tensor(0.1108, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2569\n",
      "Loss: tensor(0.1108, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2570\n",
      "Loss: tensor(0.1108, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2571\n",
      "Loss: tensor(0.1107, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2572\n",
      "Loss: tensor(0.1107, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2573\n",
      "Loss: tensor(0.1107, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2574\n",
      "Loss: tensor(0.1107, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2575\n",
      "Loss: tensor(0.1107, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2576\n",
      "Loss: tensor(0.1107, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2577\n",
      "Loss: tensor(0.1107, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2578\n",
      "Loss: tensor(0.1107, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2579\n",
      "Loss: tensor(0.1106, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2580\n",
      "Loss: tensor(0.1106, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2581\n",
      "Loss: tensor(0.1106, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2582\n",
      "Loss: tensor(0.1106, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2583\n",
      "Loss: tensor(0.1106, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2584\n",
      "Loss: tensor(0.1106, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2585\n",
      "Loss: tensor(0.1106, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2586\n",
      "Loss: tensor(0.1106, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2587\n",
      "Loss: tensor(0.1105, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2588\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor(0.1105, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2589\n",
      "Loss: tensor(0.1105, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2590\n",
      "Loss: tensor(0.1105, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2591\n",
      "Loss: tensor(0.1105, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2592\n",
      "Loss: tensor(0.1105, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2593\n",
      "Loss: tensor(0.1105, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2594\n",
      "Loss: tensor(0.1105, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2595\n",
      "Loss: tensor(0.1104, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2596\n",
      "Loss: tensor(0.1104, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2597\n",
      "Loss: tensor(0.1104, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2598\n",
      "Loss: tensor(0.1104, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2599\n",
      "Loss: tensor(0.1104, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2600\n",
      "Loss: tensor(0.1104, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2601\n",
      "Loss: tensor(0.1104, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2602\n",
      "Loss: tensor(0.1104, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2603\n",
      "Loss: tensor(0.1104, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2604\n",
      "Loss: tensor(0.1103, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2605\n",
      "Loss: tensor(0.1103, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2606\n",
      "Loss: tensor(0.1103, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2607\n",
      "Loss: tensor(0.1103, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2608\n",
      "Loss: tensor(0.1103, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2609\n",
      "Loss: tensor(0.1103, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2610\n",
      "Loss: tensor(0.1103, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2611\n",
      "Loss: tensor(0.1102, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2612\n",
      "Loss: tensor(0.1102, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2613\n",
      "Loss: tensor(0.1102, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2614\n",
      "Loss: tensor(0.1102, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2615\n",
      "Loss: tensor(0.1102, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2616\n",
      "Loss: tensor(0.1102, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2617\n",
      "Loss: tensor(0.1102, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2618\n",
      "Loss: tensor(0.1102, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2619\n",
      "Loss: tensor(0.1101, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2620\n",
      "Loss: tensor(0.1101, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2621\n",
      "Loss: tensor(0.1101, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2622\n",
      "Loss: tensor(0.1101, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2623\n",
      "Loss: tensor(0.1101, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2624\n",
      "Loss: tensor(0.1101, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2625\n",
      "Loss: tensor(0.1101, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2626\n",
      "Loss: tensor(0.1101, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2627\n",
      "Loss: tensor(0.1101, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2628\n",
      "Loss: tensor(0.1100, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2629\n",
      "Loss: tensor(0.1100, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2630\n",
      "Loss: tensor(0.1100, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2631\n",
      "Loss: tensor(0.1100, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2632\n",
      "Loss: tensor(0.1100, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2633\n",
      "Loss: tensor(0.1100, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2634\n",
      "Loss: tensor(0.1100, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2635\n",
      "Loss: tensor(0.1100, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2636\n",
      "Loss: tensor(0.1099, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2637\n",
      "Loss: tensor(0.1099, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2638\n",
      "Loss: tensor(0.1099, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2639\n",
      "Loss: tensor(0.1099, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2640\n",
      "Loss: tensor(0.1099, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2641\n",
      "Loss: tensor(0.1099, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2642\n",
      "Loss: tensor(0.1099, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2643\n",
      "Loss: tensor(0.1099, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2644\n",
      "Loss: tensor(0.1098, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2645\n",
      "Loss: tensor(0.1098, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2646\n",
      "Loss: tensor(0.1098, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2647\n",
      "Loss: tensor(0.1098, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2648\n",
      "Loss: tensor(0.1098, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2649\n",
      "Loss: tensor(0.1098, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2650\n",
      "Loss: tensor(0.1098, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2651\n",
      "Loss: tensor(0.1098, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2652\n",
      "Loss: tensor(0.1098, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2653\n",
      "Loss: tensor(0.1097, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2654\n",
      "Loss: tensor(0.1097, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2655\n",
      "Loss: tensor(0.1097, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2656\n",
      "Loss: tensor(0.1097, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2657\n",
      "Loss: tensor(0.1097, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2658\n",
      "Loss: tensor(0.1097, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2659\n",
      "Loss: tensor(0.1097, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2660\n",
      "Loss: tensor(0.1097, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2661\n",
      "Loss: tensor(0.1097, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2662\n",
      "Loss: tensor(0.1096, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2663\n",
      "Loss: tensor(0.1096, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2664\n",
      "Loss: tensor(0.1096, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2665\n",
      "Loss: tensor(0.1096, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2666\n",
      "Loss: tensor(0.1096, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2667\n",
      "Loss: tensor(0.1096, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2668\n",
      "Loss: tensor(0.1096, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2669\n",
      "Loss: tensor(0.1096, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2670\n",
      "Loss: tensor(0.1095, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2671\n",
      "Loss: tensor(0.1095, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2672\n",
      "Loss: tensor(0.1095, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2673\n",
      "Loss: tensor(0.1095, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2674\n",
      "Loss: tensor(0.1095, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2675\n",
      "Loss: tensor(0.1095, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2676\n",
      "Loss: tensor(0.1095, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2677\n",
      "Loss: tensor(0.1095, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2678\n",
      "Loss: tensor(0.1094, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2679\n",
      "Loss: tensor(0.1094, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2680\n",
      "Loss: tensor(0.1094, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2681\n",
      "Loss: tensor(0.1094, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2682\n",
      "Loss: tensor(0.1094, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2683\n",
      "Loss: tensor(0.1094, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2684\n",
      "Loss: tensor(0.1094, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2685\n",
      "Loss: tensor(0.1094, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2686\n",
      "Loss: tensor(0.1093, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2687\n",
      "Loss: tensor(0.1093, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2688\n",
      "Loss: tensor(0.1093, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2689\n",
      "Loss: tensor(0.1093, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2690\n",
      "Loss: tensor(0.1093, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2691\n",
      "Loss: tensor(0.1093, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2692\n",
      "Loss: tensor(0.1093, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2693\n",
      "Loss: tensor(0.1093, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2694\n",
      "Loss: tensor(0.1093, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2695\n",
      "Loss: tensor(0.1092, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2696\n",
      "Loss: tensor(0.1092, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2697\n",
      "Loss: tensor(0.1092, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2698\n",
      "Loss: tensor(0.1092, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2699\n",
      "Loss: tensor(0.1092, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2700\n",
      "Loss: tensor(0.1092, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2701\n",
      "Loss: tensor(0.1092, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2702\n",
      "Loss: tensor(0.1092, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2703\n",
      "Loss: tensor(0.1092, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2704\n",
      "Loss: tensor(0.1091, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2705\n",
      "Loss: tensor(0.1091, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2706\n",
      "Loss: tensor(0.1091, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2707\n",
      "Loss: tensor(0.1091, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2708\n",
      "Loss: tensor(0.1091, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2709\n",
      "Loss: tensor(0.1091, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2710\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor(0.1091, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2711\n",
      "Loss: tensor(0.1091, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2712\n",
      "Loss: tensor(0.1090, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2713\n",
      "Loss: tensor(0.1090, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2714\n",
      "Loss: tensor(0.1090, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2715\n",
      "Loss: tensor(0.1090, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2716\n",
      "Loss: tensor(0.1090, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2717\n",
      "Loss: tensor(0.1090, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2718\n",
      "Loss: tensor(0.1090, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2719\n",
      "Loss: tensor(0.1090, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2720\n",
      "Loss: tensor(0.1090, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2721\n",
      "Loss: tensor(0.1090, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2722\n",
      "Loss: tensor(0.1089, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2723\n",
      "Loss: tensor(0.1089, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2724\n",
      "Loss: tensor(0.1089, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2725\n",
      "Loss: tensor(0.1089, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2726\n",
      "Loss: tensor(0.1089, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2727\n",
      "Loss: tensor(0.1089, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2728\n",
      "Loss: tensor(0.1089, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2729\n",
      "Loss: tensor(0.1089, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2730\n",
      "Loss: tensor(0.1088, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2731\n",
      "Loss: tensor(0.1088, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2732\n",
      "Loss: tensor(0.1088, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2733\n",
      "Loss: tensor(0.1088, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2734\n",
      "Loss: tensor(0.1088, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2735\n",
      "Loss: tensor(0.1088, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2736\n",
      "Loss: tensor(0.1088, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2737\n",
      "Loss: tensor(0.1088, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2738\n",
      "Loss: tensor(0.1088, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2739\n",
      "Loss: tensor(0.1087, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2740\n",
      "Loss: tensor(0.1087, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2741\n",
      "Loss: tensor(0.1087, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2742\n",
      "Loss: tensor(0.1087, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2743\n",
      "Loss: tensor(0.1087, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2744\n",
      "Loss: tensor(0.1087, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2745\n",
      "Loss: tensor(0.1087, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2746\n",
      "Loss: tensor(0.1087, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2747\n",
      "Loss: tensor(0.1087, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2748\n",
      "Loss: tensor(0.1086, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2749\n",
      "Loss: tensor(0.1086, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2750\n",
      "Loss: tensor(0.1086, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2751\n",
      "Loss: tensor(0.1086, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2752\n",
      "Loss: tensor(0.1086, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2753\n",
      "Loss: tensor(0.1086, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2754\n",
      "Loss: tensor(0.1086, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2755\n",
      "Loss: tensor(0.1086, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2756\n",
      "Loss: tensor(0.1086, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2757\n",
      "Loss: tensor(0.1085, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2758\n",
      "Loss: tensor(0.1085, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2759\n",
      "Loss: tensor(0.1085, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2760\n",
      "Loss: tensor(0.1085, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2761\n",
      "Loss: tensor(0.1085, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2762\n",
      "Loss: tensor(0.1085, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2763\n",
      "Loss: tensor(0.1085, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2764\n",
      "Loss: tensor(0.1085, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2765\n",
      "Loss: tensor(0.1085, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2766\n",
      "Loss: tensor(0.1084, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2767\n",
      "Loss: tensor(0.1084, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2768\n",
      "Loss: tensor(0.1084, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2769\n",
      "Loss: tensor(0.1084, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2770\n",
      "Loss: tensor(0.1084, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2771\n",
      "Loss: tensor(0.1084, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2772\n",
      "Loss: tensor(0.1084, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2773\n",
      "Loss: tensor(0.1084, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2774\n",
      "Loss: tensor(0.1084, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2775\n",
      "Loss: tensor(0.1083, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2776\n",
      "Loss: tensor(0.1083, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2777\n",
      "Loss: tensor(0.1083, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2778\n",
      "Loss: tensor(0.1083, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2779\n",
      "Loss: tensor(0.1083, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2780\n",
      "Loss: tensor(0.1083, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2781\n",
      "Loss: tensor(0.1083, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2782\n",
      "Loss: tensor(0.1083, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2783\n",
      "Loss: tensor(0.1083, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2784\n",
      "Loss: tensor(0.1082, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2785\n",
      "Loss: tensor(0.1082, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2786\n",
      "Loss: tensor(0.1082, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2787\n",
      "Loss: tensor(0.1082, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2788\n",
      "Loss: tensor(0.1082, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2789\n",
      "Loss: tensor(0.1082, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2790\n",
      "Loss: tensor(0.1082, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2791\n",
      "Loss: tensor(0.1082, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2792\n",
      "Loss: tensor(0.1082, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2793\n",
      "Loss: tensor(0.1081, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2794\n",
      "Loss: tensor(0.1081, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2795\n",
      "Loss: tensor(0.1081, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2796\n",
      "Loss: tensor(0.1081, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2797\n",
      "Loss: tensor(0.1081, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2798\n",
      "Loss: tensor(0.1081, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2799\n",
      "Loss: tensor(0.1081, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2800\n",
      "Loss: tensor(0.1081, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2801\n",
      "Loss: tensor(0.1081, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2802\n",
      "Loss: tensor(0.1081, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2803\n",
      "Loss: tensor(0.1080, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2804\n",
      "Loss: tensor(0.1080, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2805\n",
      "Loss: tensor(0.1080, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2806\n",
      "Loss: tensor(0.1080, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2807\n",
      "Loss: tensor(0.1080, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2808\n",
      "Loss: tensor(0.1080, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2809\n",
      "Loss: tensor(0.1080, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2810\n",
      "Loss: tensor(0.1080, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2811\n",
      "Loss: tensor(0.1080, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2812\n",
      "Loss: tensor(0.1079, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2813\n",
      "Loss: tensor(0.1079, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2814\n",
      "Loss: tensor(0.1079, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2815\n",
      "Loss: tensor(0.1079, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2816\n",
      "Loss: tensor(0.1079, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2817\n",
      "Loss: tensor(0.1079, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2818\n",
      "Loss: tensor(0.1079, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2819\n",
      "Loss: tensor(0.1079, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2820\n",
      "Loss: tensor(0.1079, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2821\n",
      "Loss: tensor(0.1078, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2822\n",
      "Loss: tensor(0.1078, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2823\n",
      "Loss: tensor(0.1078, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2824\n",
      "Loss: tensor(0.1078, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2825\n",
      "Loss: tensor(0.1078, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2826\n",
      "Loss: tensor(0.1078, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2827\n",
      "Loss: tensor(0.1078, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2828\n",
      "Loss: tensor(0.1078, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2829\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor(0.1078, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2830\n",
      "Loss: tensor(0.1078, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2831\n",
      "Loss: tensor(0.1077, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2832\n",
      "Loss: tensor(0.1077, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2833\n",
      "Loss: tensor(0.1077, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2834\n",
      "Loss: tensor(0.1077, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2835\n",
      "Loss: tensor(0.1077, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2836\n",
      "Loss: tensor(0.1077, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2837\n",
      "Loss: tensor(0.1077, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2838\n",
      "Loss: tensor(0.1077, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2839\n",
      "Loss: tensor(0.1077, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2840\n",
      "Loss: tensor(0.1077, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2841\n",
      "Loss: tensor(0.1076, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2842\n",
      "Loss: tensor(0.1076, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2843\n",
      "Loss: tensor(0.1076, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2844\n",
      "Loss: tensor(0.1076, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2845\n",
      "Loss: tensor(0.1076, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2846\n",
      "Loss: tensor(0.1076, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2847\n",
      "Loss: tensor(0.1076, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2848\n",
      "Loss: tensor(0.1076, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2849\n",
      "Loss: tensor(0.1076, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2850\n",
      "Loss: tensor(0.1076, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2851\n",
      "Loss: tensor(0.1076, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2852\n",
      "Loss: tensor(0.1076, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2853\n",
      "Loss: tensor(0.1076, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2854\n",
      "Loss: tensor(0.1075, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2855\n",
      "Loss: tensor(0.1075, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2856\n",
      "Loss: tensor(0.1075, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2857\n",
      "Loss: tensor(0.1075, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2858\n",
      "Loss: tensor(0.1075, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2859\n",
      "Loss: tensor(0.1075, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2860\n",
      "Loss: tensor(0.1075, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2861\n",
      "Loss: tensor(0.1074, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2862\n",
      "Loss: tensor(0.1074, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2863\n",
      "Loss: tensor(0.1074, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2864\n",
      "Loss: tensor(0.1074, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2865\n",
      "Loss: tensor(0.1074, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2866\n",
      "Loss: tensor(0.1074, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2867\n",
      "Loss: tensor(0.1074, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2868\n",
      "Loss: tensor(0.1074, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2869\n",
      "Loss: tensor(0.1074, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2870\n",
      "Loss: tensor(0.1073, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2871\n",
      "Loss: tensor(0.1073, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2872\n",
      "Loss: tensor(0.1073, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2873\n",
      "Loss: tensor(0.1073, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2874\n",
      "Loss: tensor(0.1073, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2875\n",
      "Loss: tensor(0.1073, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2876\n",
      "Loss: tensor(0.1073, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2877\n",
      "Loss: tensor(0.1073, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2878\n",
      "Loss: tensor(0.1073, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2879\n",
      "Loss: tensor(0.1073, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2880\n",
      "Loss: tensor(0.1072, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2881\n",
      "Loss: tensor(0.1072, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2882\n",
      "Loss: tensor(0.1072, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2883\n",
      "Loss: tensor(0.1072, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2884\n",
      "Loss: tensor(0.1072, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2885\n",
      "Loss: tensor(0.1072, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2886\n",
      "Loss: tensor(0.1072, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2887\n",
      "Loss: tensor(0.1072, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2888\n",
      "Loss: tensor(0.1072, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2889\n",
      "Loss: tensor(0.1072, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2890\n",
      "Loss: tensor(0.1071, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2891\n",
      "Loss: tensor(0.1071, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2892\n",
      "Loss: tensor(0.1071, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2893\n",
      "Loss: tensor(0.1071, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2894\n",
      "Loss: tensor(0.1071, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2895\n",
      "Loss: tensor(0.1071, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2896\n",
      "Loss: tensor(0.1071, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2897\n",
      "Loss: tensor(0.1071, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2898\n",
      "Loss: tensor(0.1071, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2899\n",
      "Loss: tensor(0.1071, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2900\n",
      "Loss: tensor(0.1070, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2901\n",
      "Loss: tensor(0.1070, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2902\n",
      "Loss: tensor(0.1070, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2903\n",
      "Loss: tensor(0.1070, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2904\n",
      "Loss: tensor(0.1070, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2905\n",
      "Loss: tensor(0.1070, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2906\n",
      "Loss: tensor(0.1070, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2907\n",
      "Loss: tensor(0.1070, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2908\n",
      "Loss: tensor(0.1070, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2909\n",
      "Loss: tensor(0.1070, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2910\n",
      "Loss: tensor(0.1069, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2911\n",
      "Loss: tensor(0.1069, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2912\n",
      "Loss: tensor(0.1069, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2913\n",
      "Loss: tensor(0.1069, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2914\n",
      "Loss: tensor(0.1069, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2915\n",
      "Loss: tensor(0.1069, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2916\n",
      "Loss: tensor(0.1069, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2917\n",
      "Loss: tensor(0.1069, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2918\n",
      "Loss: tensor(0.1069, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2919\n",
      "Loss: tensor(0.1069, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2920\n",
      "Loss: tensor(0.1069, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2921\n",
      "Loss: tensor(0.1068, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2922\n",
      "Loss: tensor(0.1068, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2923\n",
      "Loss: tensor(0.1068, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2924\n",
      "Loss: tensor(0.1068, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2925\n",
      "Loss: tensor(0.1068, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2926\n",
      "Loss: tensor(0.1068, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2927\n",
      "Loss: tensor(0.1068, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2928\n",
      "Loss: tensor(0.1068, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2929\n",
      "Loss: tensor(0.1068, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2930\n",
      "Loss: tensor(0.1068, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2931\n",
      "Loss: tensor(0.1067, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2932\n",
      "Loss: tensor(0.1067, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2933\n",
      "Loss: tensor(0.1067, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2934\n",
      "Loss: tensor(0.1067, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2935\n",
      "Loss: tensor(0.1067, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2936\n",
      "Loss: tensor(0.1067, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2937\n",
      "Loss: tensor(0.1067, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2938\n",
      "Loss: tensor(0.1067, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2939\n",
      "Loss: tensor(0.1067, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2940\n",
      "Loss: tensor(0.1067, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2941\n",
      "Loss: tensor(0.1067, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2942\n",
      "Loss: tensor(0.1067, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2943\n",
      "Loss: tensor(0.1066, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2944\n",
      "Loss: tensor(0.1066, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2945\n",
      "Loss: tensor(0.1066, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2946\n",
      "Loss: tensor(0.1066, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2947\n",
      "Loss: tensor(0.1066, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2948\n",
      "Loss: tensor(0.1066, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2949\n",
      "Loss: tensor(0.1066, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2950\n",
      "Loss: tensor(0.1066, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2951\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor(0.1066, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2952\n",
      "Loss: tensor(0.1066, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2953\n",
      "Loss: tensor(0.1065, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2954\n",
      "Loss: tensor(0.1065, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2955\n",
      "Loss: tensor(0.1065, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2956\n",
      "Loss: tensor(0.1065, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2957\n",
      "Loss: tensor(0.1065, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2958\n",
      "Loss: tensor(0.1065, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2959\n",
      "Loss: tensor(0.1065, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2960\n",
      "Loss: tensor(0.1065, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2961\n",
      "Loss: tensor(0.1065, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2962\n",
      "Loss: tensor(0.1065, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2963\n",
      "Loss: tensor(0.1064, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2964\n",
      "Loss: tensor(0.1064, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2965\n",
      "Loss: tensor(0.1064, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2966\n",
      "Loss: tensor(0.1064, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2967\n",
      "Loss: tensor(0.1064, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2968\n",
      "Loss: tensor(0.1064, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2969\n",
      "Loss: tensor(0.1064, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2970\n",
      "Loss: tensor(0.1064, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2971\n",
      "Loss: tensor(0.1064, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2972\n",
      "Loss: tensor(0.1064, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2973\n",
      "Loss: tensor(0.1064, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2974\n",
      "Loss: tensor(0.1063, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2975\n",
      "Loss: tensor(0.1063, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2976\n",
      "Loss: tensor(0.1063, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2977\n",
      "Loss: tensor(0.1063, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2978\n",
      "Loss: tensor(0.1063, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2979\n",
      "Loss: tensor(0.1063, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2980\n",
      "Loss: tensor(0.1063, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2981\n",
      "Loss: tensor(0.1063, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2982\n",
      "Loss: tensor(0.1063, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2983\n",
      "Loss: tensor(0.1063, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2984\n",
      "Loss: tensor(0.1063, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2985\n",
      "Loss: tensor(0.1062, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2986\n",
      "Loss: tensor(0.1062, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2987\n",
      "Loss: tensor(0.1062, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2988\n",
      "Loss: tensor(0.1062, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2989\n",
      "Loss: tensor(0.1062, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2990\n",
      "Loss: tensor(0.1062, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2991\n",
      "Loss: tensor(0.1062, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2992\n",
      "Loss: tensor(0.1062, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2993\n",
      "Loss: tensor(0.1062, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2994\n",
      "Loss: tensor(0.1062, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2995\n",
      "Loss: tensor(0.1062, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2996\n",
      "Loss: tensor(0.1061, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2997\n",
      "Loss: tensor(0.1061, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2998\n",
      "Loss: tensor(0.1061, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2999\n",
      "Loss: tensor(0.1061, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3000\n",
      "Loss: tensor(0.1061, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3001\n",
      "Loss: tensor(0.1061, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3002\n",
      "Loss: tensor(0.1061, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3003\n",
      "Loss: tensor(0.1061, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3004\n",
      "Loss: tensor(0.1061, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3005\n",
      "Loss: tensor(0.1061, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3006\n",
      "Loss: tensor(0.1061, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3007\n",
      "Loss: tensor(0.1061, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3008\n",
      "Loss: tensor(0.1060, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3009\n",
      "Loss: tensor(0.1060, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3010\n",
      "Loss: tensor(0.1060, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3011\n",
      "Loss: tensor(0.1060, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3012\n",
      "Loss: tensor(0.1060, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3013\n",
      "Loss: tensor(0.1060, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3014\n",
      "Loss: tensor(0.1060, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3015\n",
      "Loss: tensor(0.1060, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3016\n",
      "Loss: tensor(0.1060, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3017\n",
      "Loss: tensor(0.1060, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3018\n",
      "Loss: tensor(0.1060, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3019\n",
      "Loss: tensor(0.1059, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3020\n",
      "Loss: tensor(0.1059, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3021\n",
      "Loss: tensor(0.1059, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3022\n",
      "Loss: tensor(0.1059, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3023\n",
      "Loss: tensor(0.1059, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3024\n",
      "Loss: tensor(0.1059, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3025\n",
      "Loss: tensor(0.1059, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3026\n",
      "Loss: tensor(0.1059, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3027\n",
      "Loss: tensor(0.1059, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3028\n",
      "Loss: tensor(0.1059, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3029\n",
      "Loss: tensor(0.1059, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3030\n",
      "Loss: tensor(0.1058, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3031\n",
      "Loss: tensor(0.1058, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3032\n",
      "Loss: tensor(0.1058, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3033\n",
      "Loss: tensor(0.1058, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3034\n",
      "Loss: tensor(0.1058, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3035\n",
      "Loss: tensor(0.1058, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3036\n",
      "Loss: tensor(0.1058, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3037\n",
      "Loss: tensor(0.1058, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3038\n",
      "Loss: tensor(0.1058, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3039\n",
      "Loss: tensor(0.1058, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3040\n",
      "Loss: tensor(0.1058, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3041\n",
      "Loss: tensor(0.1057, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3042\n",
      "Loss: tensor(0.1057, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3043\n",
      "Loss: tensor(0.1057, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3044\n",
      "Loss: tensor(0.1057, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3045\n",
      "Loss: tensor(0.1057, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3046\n",
      "Loss: tensor(0.1057, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3047\n",
      "Loss: tensor(0.1057, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3048\n",
      "Loss: tensor(0.1057, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3049\n",
      "Loss: tensor(0.1057, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3050\n",
      "Loss: tensor(0.1057, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3051\n",
      "Loss: tensor(0.1057, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3052\n",
      "Loss: tensor(0.1056, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3053\n",
      "Loss: tensor(0.1056, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3054\n",
      "Loss: tensor(0.1056, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3055\n",
      "Loss: tensor(0.1056, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3056\n",
      "Loss: tensor(0.1056, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3057\n",
      "Loss: tensor(0.1056, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3058\n",
      "Loss: tensor(0.1056, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3059\n",
      "Loss: tensor(0.1056, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3060\n",
      "Loss: tensor(0.1056, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3061\n",
      "Loss: tensor(0.1056, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3062\n",
      "Loss: tensor(0.1056, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3063\n",
      "Loss: tensor(0.1056, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3064\n",
      "Loss: tensor(0.1055, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3065\n",
      "Loss: tensor(0.1055, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3066\n",
      "Loss: tensor(0.1055, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3067\n",
      "Loss: tensor(0.1055, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3068\n",
      "Loss: tensor(0.1055, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3069\n",
      "Loss: tensor(0.1055, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3070\n",
      "Loss: tensor(0.1055, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3071\n",
      "Loss: tensor(0.1055, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3072\n",
      "Loss: tensor(0.1055, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3073\n",
      "Loss: tensor(0.1055, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3074\n",
      "Loss: tensor(0.1055, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3075\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor(0.1055, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3076\n",
      "Loss: tensor(0.1054, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3077\n",
      "Loss: tensor(0.1054, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3078\n",
      "Loss: tensor(0.1054, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3079\n",
      "Loss: tensor(0.1054, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3080\n",
      "Loss: tensor(0.1054, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3081\n",
      "Loss: tensor(0.1054, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3082\n",
      "Loss: tensor(0.1054, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3083\n",
      "Loss: tensor(0.1054, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3084\n",
      "Loss: tensor(0.1054, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3085\n",
      "Loss: tensor(0.1054, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3086\n",
      "Loss: tensor(0.1054, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3087\n",
      "Loss: tensor(0.1054, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3088\n",
      "Loss: tensor(0.1053, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3089\n",
      "Loss: tensor(0.1053, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3090\n",
      "Loss: tensor(0.1053, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3091\n",
      "Loss: tensor(0.1053, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3092\n",
      "Loss: tensor(0.1053, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3093\n",
      "Loss: tensor(0.1053, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3094\n",
      "Loss: tensor(0.1053, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3095\n",
      "Loss: tensor(0.1053, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3096\n",
      "Loss: tensor(0.1053, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3097\n",
      "Loss: tensor(0.1053, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3098\n",
      "Loss: tensor(0.1053, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3099\n",
      "Loss: tensor(0.1053, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3100\n",
      "Loss: tensor(0.1052, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3101\n",
      "Loss: tensor(0.1052, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3102\n",
      "Loss: tensor(0.1052, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3103\n",
      "Loss: tensor(0.1052, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3104\n",
      "Loss: tensor(0.1052, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3105\n",
      "Loss: tensor(0.1052, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3106\n",
      "Loss: tensor(0.1052, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3107\n",
      "Loss: tensor(0.1052, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3108\n",
      "Loss: tensor(0.1052, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3109\n",
      "Loss: tensor(0.1052, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3110\n",
      "Loss: tensor(0.1052, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3111\n",
      "Loss: tensor(0.1052, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3112\n",
      "Loss: tensor(0.1052, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3113\n",
      "Loss: tensor(0.1052, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3114\n",
      "Loss: tensor(0.1051, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3115\n",
      "Loss: tensor(0.1051, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3116\n",
      "Loss: tensor(0.1051, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3117\n",
      "Loss: tensor(0.1051, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3118\n",
      "Loss: tensor(0.1051, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3119\n",
      "Loss: tensor(0.1051, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3120\n",
      "Loss: tensor(0.1051, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3121\n",
      "Loss: tensor(0.1051, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3122\n",
      "Loss: tensor(0.1051, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3123\n",
      "Loss: tensor(0.1051, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3124\n",
      "Loss: tensor(0.1051, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3125\n",
      "Loss: tensor(0.1050, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3126\n",
      "Loss: tensor(0.1050, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3127\n",
      "Loss: tensor(0.1050, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3128\n",
      "Loss: tensor(0.1050, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3129\n",
      "Loss: tensor(0.1050, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3130\n",
      "Loss: tensor(0.1050, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3131\n",
      "Loss: tensor(0.1050, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3132\n",
      "Loss: tensor(0.1050, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3133\n",
      "Loss: tensor(0.1050, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3134\n",
      "Loss: tensor(0.1050, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3135\n",
      "Loss: tensor(0.1050, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3136\n",
      "Loss: tensor(0.1050, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3137\n",
      "Loss: tensor(0.1049, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3138\n",
      "Loss: tensor(0.1049, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3139\n",
      "Loss: tensor(0.1049, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3140\n",
      "Loss: tensor(0.1049, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3141\n",
      "Loss: tensor(0.1049, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3142\n",
      "Loss: tensor(0.1049, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3143\n",
      "Loss: tensor(0.1049, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3144\n",
      "Loss: tensor(0.1049, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3145\n",
      "Loss: tensor(0.1049, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3146\n",
      "Loss: tensor(0.1049, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3147\n",
      "Loss: tensor(0.1049, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3148\n",
      "Loss: tensor(0.1049, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3149\n",
      "Loss: tensor(0.1048, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3150\n",
      "Loss: tensor(0.1048, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3151\n",
      "Loss: tensor(0.1048, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3152\n",
      "Loss: tensor(0.1048, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3153\n",
      "Loss: tensor(0.1048, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3154\n",
      "Loss: tensor(0.1048, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3155\n",
      "Loss: tensor(0.1048, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3156\n",
      "Loss: tensor(0.1048, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3157\n",
      "Loss: tensor(0.1048, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3158\n",
      "Loss: tensor(0.1048, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3159\n",
      "Loss: tensor(0.1048, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3160\n",
      "Loss: tensor(0.1048, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3161\n",
      "Loss: tensor(0.1048, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3162\n",
      "Loss: tensor(0.1047, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3163\n",
      "Loss: tensor(0.1047, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3164\n",
      "Loss: tensor(0.1047, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3165\n",
      "Loss: tensor(0.1047, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3166\n",
      "Loss: tensor(0.1047, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3167\n",
      "Loss: tensor(0.1047, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3168\n",
      "Loss: tensor(0.1047, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3169\n",
      "Loss: tensor(0.1047, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3170\n",
      "Loss: tensor(0.1047, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3171\n",
      "Loss: tensor(0.1047, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3172\n",
      "Loss: tensor(0.1047, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3173\n",
      "Loss: tensor(0.1047, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3174\n",
      "Loss: tensor(0.1047, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3175\n",
      "Loss: tensor(0.1046, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3176\n",
      "Loss: tensor(0.1046, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3177\n",
      "Loss: tensor(0.1046, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3178\n",
      "Loss: tensor(0.1046, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3179\n",
      "Loss: tensor(0.1046, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3180\n",
      "Loss: tensor(0.1046, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3181\n",
      "Loss: tensor(0.1046, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3182\n",
      "Loss: tensor(0.1046, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3183\n",
      "Loss: tensor(0.1046, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3184\n",
      "Loss: tensor(0.1046, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3185\n",
      "Loss: tensor(0.1046, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3186\n",
      "Loss: tensor(0.1046, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3187\n",
      "Loss: tensor(0.1046, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3188\n",
      "Loss: tensor(0.1045, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3189\n",
      "Loss: tensor(0.1045, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3190\n",
      "Loss: tensor(0.1045, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3191\n",
      "Loss: tensor(0.1045, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3192\n",
      "Loss: tensor(0.1045, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3193\n",
      "Loss: tensor(0.1045, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3194\n",
      "Loss: tensor(0.1045, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3195\n",
      "Loss: tensor(0.1045, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3196\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor(0.1045, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3197\n",
      "Loss: tensor(0.1045, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3198\n",
      "Loss: tensor(0.1045, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3199\n",
      "Loss: tensor(0.1045, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3200\n",
      "Loss: tensor(0.1045, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3201\n",
      "Loss: tensor(0.1044, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3202\n",
      "Loss: tensor(0.1044, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3203\n",
      "Loss: tensor(0.1044, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3204\n",
      "Loss: tensor(0.1044, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3205\n",
      "Loss: tensor(0.1044, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3206\n",
      "Loss: tensor(0.1044, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3207\n",
      "Loss: tensor(0.1044, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3208\n",
      "Loss: tensor(0.1044, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3209\n",
      "Loss: tensor(0.1044, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3210\n",
      "Loss: tensor(0.1044, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3211\n",
      "Loss: tensor(0.1044, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3212\n",
      "Loss: tensor(0.1044, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3213\n",
      "Loss: tensor(0.1044, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3214\n",
      "Loss: tensor(0.1043, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3215\n",
      "Loss: tensor(0.1043, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3216\n",
      "Loss: tensor(0.1043, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3217\n",
      "Loss: tensor(0.1043, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3218\n",
      "Loss: tensor(0.1043, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3219\n",
      "Loss: tensor(0.1043, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3220\n",
      "Loss: tensor(0.1043, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3221\n",
      "Loss: tensor(0.1043, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3222\n",
      "Loss: tensor(0.1043, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3223\n",
      "Loss: tensor(0.1043, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3224\n",
      "Loss: tensor(0.1043, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3225\n",
      "Loss: tensor(0.1043, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3226\n",
      "Loss: tensor(0.1043, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3227\n",
      "Loss: tensor(0.1043, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3228\n",
      "Loss: tensor(0.1042, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3229\n",
      "Loss: tensor(0.1042, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3230\n",
      "Loss: tensor(0.1042, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3231\n",
      "Loss: tensor(0.1042, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3232\n",
      "Loss: tensor(0.1042, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3233\n",
      "Loss: tensor(0.1042, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3234\n",
      "Loss: tensor(0.1042, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3235\n",
      "Loss: tensor(0.1042, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3236\n",
      "Loss: tensor(0.1042, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3237\n",
      "Loss: tensor(0.1042, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3238\n",
      "Loss: tensor(0.1042, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3239\n",
      "Loss: tensor(0.1042, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3240\n",
      "Loss: tensor(0.1042, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3241\n",
      "Loss: tensor(0.1041, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3242\n",
      "Loss: tensor(0.1041, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3243\n",
      "Loss: tensor(0.1041, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3244\n",
      "Loss: tensor(0.1041, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3245\n",
      "Loss: tensor(0.1041, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3246\n",
      "Loss: tensor(0.1041, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3247\n",
      "Loss: tensor(0.1041, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3248\n",
      "Loss: tensor(0.1041, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3249\n",
      "Loss: tensor(0.1041, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3250\n",
      "Loss: tensor(0.1041, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3251\n",
      "Loss: tensor(0.1041, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3252\n",
      "Loss: tensor(0.1041, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3253\n",
      "Loss: tensor(0.1041, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3254\n",
      "Loss: tensor(0.1041, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3255\n",
      "Loss: tensor(0.1040, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3256\n",
      "Loss: tensor(0.1040, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3257\n",
      "Loss: tensor(0.1040, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3258\n",
      "Loss: tensor(0.1040, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3259\n",
      "Loss: tensor(0.1040, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3260\n",
      "Loss: tensor(0.1040, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3261\n",
      "Loss: tensor(0.1040, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3262\n",
      "Loss: tensor(0.1040, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3263\n",
      "Loss: tensor(0.1040, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3264\n",
      "Loss: tensor(0.1040, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3265\n",
      "Loss: tensor(0.1040, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3266\n",
      "Loss: tensor(0.1040, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3267\n",
      "Loss: tensor(0.1040, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3268\n",
      "Loss: tensor(0.1039, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3269\n",
      "Loss: tensor(0.1039, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3270\n",
      "Loss: tensor(0.1039, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3271\n",
      "Loss: tensor(0.1039, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3272\n",
      "Loss: tensor(0.1039, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3273\n",
      "Loss: tensor(0.1039, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3274\n",
      "Loss: tensor(0.1039, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3275\n",
      "Loss: tensor(0.1039, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3276\n",
      "Loss: tensor(0.1039, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3277\n",
      "Loss: tensor(0.1039, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3278\n",
      "Loss: tensor(0.1039, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3279\n",
      "Loss: tensor(0.1039, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3280\n",
      "Loss: tensor(0.1039, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3281\n",
      "Loss: tensor(0.1039, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3282\n",
      "Loss: tensor(0.1039, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3283\n",
      "Loss: tensor(0.1038, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3284\n",
      "Loss: tensor(0.1038, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3285\n",
      "Loss: tensor(0.1038, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3286\n",
      "Loss: tensor(0.1038, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3287\n",
      "Loss: tensor(0.1038, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3288\n",
      "Loss: tensor(0.1038, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3289\n",
      "Loss: tensor(0.1038, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3290\n",
      "Loss: tensor(0.1038, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3291\n",
      "Loss: tensor(0.1038, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3292\n",
      "Loss: tensor(0.1038, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3293\n",
      "Loss: tensor(0.1038, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3294\n",
      "Loss: tensor(0.1038, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3295\n",
      "Loss: tensor(0.1038, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3296\n",
      "Loss: tensor(0.1037, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3297\n",
      "Loss: tensor(0.1037, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3298\n",
      "Loss: tensor(0.1037, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3299\n",
      "Loss: tensor(0.1037, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3300\n",
      "Loss: tensor(0.1037, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3301\n",
      "Loss: tensor(0.1037, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3302\n",
      "Loss: tensor(0.1037, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3303\n",
      "Loss: tensor(0.1037, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3304\n",
      "Loss: tensor(0.1037, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3305\n",
      "Loss: tensor(0.1037, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3306\n",
      "Loss: tensor(0.1037, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3307\n",
      "Loss: tensor(0.1037, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3308\n",
      "Loss: tensor(0.1037, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3309\n",
      "Loss: tensor(0.1037, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3310\n",
      "Loss: tensor(0.1036, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3311\n",
      "Loss: tensor(0.1036, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3312\n",
      "Loss: tensor(0.1036, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3313\n",
      "Loss: tensor(0.1036, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3314\n",
      "Loss: tensor(0.1036, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3315\n",
      "Loss: tensor(0.1036, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3316\n",
      "Loss: tensor(0.1036, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3317\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor(0.1036, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3318\n",
      "Loss: tensor(0.1036, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3319\n",
      "Loss: tensor(0.1036, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3320\n",
      "Loss: tensor(0.1036, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3321\n",
      "Loss: tensor(0.1036, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3322\n",
      "Loss: tensor(0.1036, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3323\n",
      "Loss: tensor(0.1036, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3324\n",
      "Loss: tensor(0.1036, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3325\n",
      "Loss: tensor(0.1035, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3326\n",
      "Loss: tensor(0.1035, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3327\n",
      "Loss: tensor(0.1035, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3328\n",
      "Loss: tensor(0.1035, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3329\n",
      "Loss: tensor(0.1035, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3330\n",
      "Loss: tensor(0.1035, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3331\n",
      "Loss: tensor(0.1035, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3332\n",
      "Loss: tensor(0.1035, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3333\n",
      "Loss: tensor(0.1035, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3334\n",
      "Loss: tensor(0.1035, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3335\n",
      "Loss: tensor(0.1035, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3336\n",
      "Loss: tensor(0.1035, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3337\n",
      "Loss: tensor(0.1035, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3338\n",
      "Loss: tensor(0.1035, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3339\n",
      "Loss: tensor(0.1035, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3340\n",
      "Loss: tensor(0.1034, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3341\n",
      "Loss: tensor(0.1034, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3342\n",
      "Loss: tensor(0.1034, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3343\n",
      "Loss: tensor(0.1034, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3344\n",
      "Loss: tensor(0.1034, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3345\n",
      "Loss: tensor(0.1034, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3346\n",
      "Loss: tensor(0.1034, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3347\n",
      "Loss: tensor(0.1034, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3348\n",
      "Loss: tensor(0.1034, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3349\n",
      "Loss: tensor(0.1034, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3350\n",
      "Loss: tensor(0.1034, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3351\n",
      "Loss: tensor(0.1034, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3352\n",
      "Loss: tensor(0.1034, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3353\n",
      "Loss: tensor(0.1034, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3354\n",
      "Loss: tensor(0.1033, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3355\n",
      "Loss: tensor(0.1033, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3356\n",
      "Loss: tensor(0.1033, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3357\n",
      "Loss: tensor(0.1033, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3358\n",
      "Loss: tensor(0.1033, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3359\n",
      "Loss: tensor(0.1033, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3360\n",
      "Loss: tensor(0.1033, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3361\n",
      "Loss: tensor(0.1033, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3362\n",
      "Loss: tensor(0.1033, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3363\n",
      "Loss: tensor(0.1033, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3364\n",
      "Loss: tensor(0.1033, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3365\n",
      "Loss: tensor(0.1033, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3366\n",
      "Loss: tensor(0.1033, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3367\n",
      "Loss: tensor(0.1033, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3368\n",
      "Loss: tensor(0.1033, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3369\n",
      "Loss: tensor(0.1032, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3370\n",
      "Loss: tensor(0.1032, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3371\n",
      "Loss: tensor(0.1032, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3372\n",
      "Loss: tensor(0.1032, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3373\n",
      "Loss: tensor(0.1032, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3374\n",
      "Loss: tensor(0.1032, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3375\n",
      "Loss: tensor(0.1032, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3376\n",
      "Loss: tensor(0.1032, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3377\n",
      "Loss: tensor(0.1032, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3378\n",
      "Loss: tensor(0.1032, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3379\n",
      "Loss: tensor(0.1032, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3380\n",
      "Loss: tensor(0.1032, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3381\n",
      "Loss: tensor(0.1032, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3382\n",
      "Loss: tensor(0.1032, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3383\n",
      "Loss: tensor(0.1032, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3384\n",
      "Loss: tensor(0.1031, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3385\n",
      "Loss: tensor(0.1031, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3386\n",
      "Loss: tensor(0.1031, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3387\n",
      "Loss: tensor(0.1031, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3388\n",
      "Loss: tensor(0.1031, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3389\n",
      "Loss: tensor(0.1031, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3390\n",
      "Loss: tensor(0.1031, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3391\n",
      "Loss: tensor(0.1031, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3392\n",
      "Loss: tensor(0.1031, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3393\n",
      "Loss: tensor(0.1031, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3394\n",
      "Loss: tensor(0.1031, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3395\n",
      "Loss: tensor(0.1031, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3396\n",
      "Loss: tensor(0.1031, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3397\n",
      "Loss: tensor(0.1031, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3398\n",
      "Loss: tensor(0.1031, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3399\n",
      "Loss: tensor(0.1030, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3400\n",
      "Loss: tensor(0.1030, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3401\n",
      "Loss: tensor(0.1030, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3402\n",
      "Loss: tensor(0.1030, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3403\n",
      "Loss: tensor(0.1030, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3404\n",
      "Loss: tensor(0.1030, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3405\n",
      "Loss: tensor(0.1030, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3406\n",
      "Loss: tensor(0.1030, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3407\n",
      "Loss: tensor(0.1030, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3408\n",
      "Loss: tensor(0.1030, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3409\n",
      "Loss: tensor(0.1030, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3410\n",
      "Loss: tensor(0.1030, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3411\n",
      "Loss: tensor(0.1030, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3412\n",
      "Loss: tensor(0.1030, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3413\n",
      "Loss: tensor(0.1030, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3414\n",
      "Loss: tensor(0.1030, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3415\n",
      "Loss: tensor(0.1029, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3416\n",
      "Loss: tensor(0.1029, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3417\n",
      "Loss: tensor(0.1029, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3418\n",
      "Loss: tensor(0.1029, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3419\n",
      "Loss: tensor(0.1029, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3420\n",
      "Loss: tensor(0.1029, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3421\n",
      "Loss: tensor(0.1029, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3422\n",
      "Loss: tensor(0.1029, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3423\n",
      "Loss: tensor(0.1029, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3424\n",
      "Loss: tensor(0.1029, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3425\n",
      "Loss: tensor(0.1029, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3426\n",
      "Loss: tensor(0.1029, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3427\n",
      "Loss: tensor(0.1029, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3428\n",
      "Loss: tensor(0.1029, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3429\n",
      "Loss: tensor(0.1029, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3430\n",
      "Loss: tensor(0.1028, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3431\n",
      "Loss: tensor(0.1028, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3432\n",
      "Loss: tensor(0.1028, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3433\n",
      "Loss: tensor(0.1028, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3434\n",
      "Loss: tensor(0.1028, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3435\n",
      "Loss: tensor(0.1028, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3436\n",
      "Loss: tensor(0.1028, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3437\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor(0.1028, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3438\n",
      "Loss: tensor(0.1028, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3439\n",
      "Loss: tensor(0.1028, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3440\n",
      "Loss: tensor(0.1028, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3441\n",
      "Loss: tensor(0.1028, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3442\n",
      "Loss: tensor(0.1028, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3443\n",
      "Loss: tensor(0.1028, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3444\n",
      "Loss: tensor(0.1028, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3445\n",
      "Loss: tensor(0.1028, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3446\n",
      "Loss: tensor(0.1027, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3447\n",
      "Loss: tensor(0.1027, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3448\n",
      "Loss: tensor(0.1027, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3449\n",
      "Loss: tensor(0.1027, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3450\n",
      "Loss: tensor(0.1027, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3451\n",
      "Loss: tensor(0.1027, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3452\n",
      "Loss: tensor(0.1027, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3453\n",
      "Loss: tensor(0.1027, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3454\n",
      "Loss: tensor(0.1027, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3455\n",
      "Loss: tensor(0.1027, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3456\n",
      "Loss: tensor(0.1027, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3457\n",
      "Loss: tensor(0.1027, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3458\n",
      "Loss: tensor(0.1027, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3459\n",
      "Loss: tensor(0.1027, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3460\n",
      "Loss: tensor(0.1027, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3461\n",
      "Loss: tensor(0.1027, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3462\n",
      "Loss: tensor(0.1027, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3463\n",
      "Loss: tensor(0.1026, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3464\n",
      "Loss: tensor(0.1026, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3465\n",
      "Loss: tensor(0.1026, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3466\n",
      "Loss: tensor(0.1026, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3467\n",
      "Loss: tensor(0.1026, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3468\n",
      "Loss: tensor(0.1026, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3469\n",
      "Loss: tensor(0.1026, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3470\n",
      "Loss: tensor(0.1026, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3471\n",
      "Loss: tensor(0.1026, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3472\n",
      "Loss: tensor(0.1026, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3473\n",
      "Loss: tensor(0.1026, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3474\n",
      "Loss: tensor(0.1026, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3475\n",
      "Loss: tensor(0.1026, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3476\n",
      "Loss: tensor(0.1026, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3477\n",
      "Loss: tensor(0.1026, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3478\n",
      "Loss: tensor(0.1026, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3479\n",
      "Loss: tensor(0.1025, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3480\n",
      "Loss: tensor(0.1025, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3481\n",
      "Loss: tensor(0.1025, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3482\n",
      "Loss: tensor(0.1025, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3483\n",
      "Loss: tensor(0.1025, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3484\n",
      "Loss: tensor(0.1025, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3485\n",
      "Loss: tensor(0.1025, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3486\n",
      "Loss: tensor(0.1025, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3487\n",
      "Loss: tensor(0.1025, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3488\n",
      "Loss: tensor(0.1025, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3489\n",
      "Loss: tensor(0.1025, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3490\n",
      "Loss: tensor(0.1025, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3491\n",
      "Loss: tensor(0.1025, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3492\n",
      "Loss: tensor(0.1025, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3493\n",
      "Loss: tensor(0.1025, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3494\n",
      "Loss: tensor(0.1025, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3495\n",
      "Loss: tensor(0.1025, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3496\n",
      "Loss: tensor(0.1024, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3497\n",
      "Loss: tensor(0.1024, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3498\n",
      "Loss: tensor(0.1024, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3499\n",
      "Loss: tensor(0.1024, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3500\n",
      "Loss: tensor(0.1024, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3501\n",
      "Loss: tensor(0.1024, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3502\n",
      "Loss: tensor(0.1024, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3503\n",
      "Loss: tensor(0.1024, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3504\n",
      "Loss: tensor(0.1024, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3505\n",
      "Loss: tensor(0.1024, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3506\n",
      "Loss: tensor(0.1024, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3507\n",
      "Loss: tensor(0.1024, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3508\n",
      "Loss: tensor(0.1024, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3509\n",
      "Loss: tensor(0.1024, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3510\n",
      "Loss: tensor(0.1024, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3511\n",
      "Loss: tensor(0.1024, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3512\n",
      "Loss: tensor(0.1023, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3513\n",
      "Loss: tensor(0.1023, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3514\n",
      "Loss: tensor(0.1023, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3515\n",
      "Loss: tensor(0.1023, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3516\n",
      "Loss: tensor(0.1023, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3517\n",
      "Loss: tensor(0.1023, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3518\n",
      "Loss: tensor(0.1023, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3519\n",
      "Loss: tensor(0.1023, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3520\n",
      "Loss: tensor(0.1023, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3521\n",
      "Loss: tensor(0.1023, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3522\n",
      "Loss: tensor(0.1023, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3523\n",
      "Loss: tensor(0.1023, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3524\n",
      "Loss: tensor(0.1023, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3525\n",
      "Loss: tensor(0.1023, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3526\n",
      "Loss: tensor(0.1023, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3527\n",
      "Loss: tensor(0.1023, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3528\n",
      "Loss: tensor(0.1023, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3529\n",
      "Loss: tensor(0.1023, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3530\n",
      "Loss: tensor(0.1022, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3531\n",
      "Loss: tensor(0.1022, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3532\n",
      "Loss: tensor(0.1022, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3533\n",
      "Loss: tensor(0.1022, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3534\n",
      "Loss: tensor(0.1022, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3535\n",
      "Loss: tensor(0.1022, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3536\n",
      "Loss: tensor(0.1022, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3537\n",
      "Loss: tensor(0.1022, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3538\n",
      "Loss: tensor(0.1022, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3539\n",
      "Loss: tensor(0.1022, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3540\n",
      "Loss: tensor(0.1022, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3541\n",
      "Loss: tensor(0.1022, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3542\n",
      "Loss: tensor(0.1022, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3543\n",
      "Loss: tensor(0.1022, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3544\n",
      "Loss: tensor(0.1022, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3545\n",
      "Loss: tensor(0.1022, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3546\n",
      "Loss: tensor(0.1022, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3547\n",
      "Loss: tensor(0.1021, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3548\n",
      "Loss: tensor(0.1021, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3549\n",
      "Loss: tensor(0.1021, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3550\n",
      "Loss: tensor(0.1021, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3551\n",
      "Loss: tensor(0.1021, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3552\n",
      "Loss: tensor(0.1021, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3553\n",
      "Loss: tensor(0.1021, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3554\n",
      "Loss: tensor(0.1021, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3555\n",
      "Loss: tensor(0.1021, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3556\n",
      "Loss: tensor(0.1021, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3557\n",
      "Loss: tensor(0.1021, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3558\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor(0.1021, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3559\n",
      "Loss: tensor(0.1021, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3560\n",
      "Loss: tensor(0.1021, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3561\n",
      "Loss: tensor(0.1021, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3562\n",
      "Loss: tensor(0.1021, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3563\n",
      "Loss: tensor(0.1021, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3564\n",
      "Loss: tensor(0.1021, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3565\n",
      "Loss: tensor(0.1021, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3566\n",
      "Loss: tensor(0.1020, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3567\n",
      "Loss: tensor(0.1020, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3568\n",
      "Loss: tensor(0.1020, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3569\n",
      "Loss: tensor(0.1020, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3570\n",
      "Loss: tensor(0.1020, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3571\n",
      "Loss: tensor(0.1020, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3572\n",
      "Loss: tensor(0.1020, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3573\n",
      "Loss: tensor(0.1020, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3574\n",
      "Loss: tensor(0.1020, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3575\n",
      "Loss: tensor(0.1020, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3576\n",
      "Loss: tensor(0.1020, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3577\n",
      "Loss: tensor(0.1020, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3578\n",
      "Loss: tensor(0.1020, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3579\n",
      "Loss: tensor(0.1020, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3580\n",
      "Loss: tensor(0.1020, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3581\n",
      "Loss: tensor(0.1020, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3582\n",
      "Loss: tensor(0.1020, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3583\n",
      "Loss: tensor(0.1019, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3584\n",
      "Loss: tensor(0.1019, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3585\n",
      "Loss: tensor(0.1019, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3586\n",
      "Loss: tensor(0.1019, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3587\n",
      "Loss: tensor(0.1019, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3588\n",
      "Loss: tensor(0.1019, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3589\n",
      "Loss: tensor(0.1019, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3590\n",
      "Loss: tensor(0.1019, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3591\n",
      "Loss: tensor(0.1019, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3592\n",
      "Loss: tensor(0.1019, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3593\n",
      "Loss: tensor(0.1019, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3594\n",
      "Loss: tensor(0.1019, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3595\n",
      "Loss: tensor(0.1019, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3596\n",
      "Loss: tensor(0.1019, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3597\n",
      "Loss: tensor(0.1019, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3598\n",
      "Loss: tensor(0.1019, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3599\n",
      "Loss: tensor(0.1019, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3600\n",
      "Loss: tensor(0.1019, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3601\n",
      "Loss: tensor(0.1018, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3602\n",
      "Loss: tensor(0.1018, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3603\n",
      "Loss: tensor(0.1018, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3604\n",
      "Loss: tensor(0.1018, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3605\n",
      "Loss: tensor(0.1018, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3606\n",
      "Loss: tensor(0.1018, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3607\n",
      "Loss: tensor(0.1018, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3608\n",
      "Loss: tensor(0.1018, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3609\n",
      "Loss: tensor(0.1018, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3610\n",
      "Loss: tensor(0.1018, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3611\n",
      "Loss: tensor(0.1018, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3612\n",
      "Loss: tensor(0.1018, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3613\n",
      "Loss: tensor(0.1018, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3614\n",
      "Loss: tensor(0.1018, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3615\n",
      "Loss: tensor(0.1018, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3616\n",
      "Loss: tensor(0.1018, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3617\n",
      "Loss: tensor(0.1018, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3618\n",
      "Loss: tensor(0.1018, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3619\n",
      "Loss: tensor(0.1018, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3620\n",
      "Loss: tensor(0.1018, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3621\n",
      "Loss: tensor(0.1017, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3622\n",
      "Loss: tensor(0.1017, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3623\n",
      "Loss: tensor(0.1017, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3624\n",
      "Loss: tensor(0.1017, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3625\n",
      "Loss: tensor(0.1017, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3626\n",
      "Loss: tensor(0.1017, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3627\n",
      "Loss: tensor(0.1017, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3628\n",
      "Loss: tensor(0.1017, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3629\n",
      "Loss: tensor(0.1017, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3630\n",
      "Loss: tensor(0.1017, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3631\n",
      "Loss: tensor(0.1017, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3632\n",
      "Loss: tensor(0.1017, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3633\n",
      "Loss: tensor(0.1017, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3634\n",
      "Loss: tensor(0.1017, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3635\n",
      "Loss: tensor(0.1017, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3636\n",
      "Loss: tensor(0.1017, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3637\n",
      "Loss: tensor(0.1017, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3638\n",
      "Loss: tensor(0.1017, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3639\n",
      "Loss: tensor(0.1016, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3640\n",
      "Loss: tensor(0.1016, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3641\n",
      "Loss: tensor(0.1016, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3642\n",
      "Loss: tensor(0.1016, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3643\n",
      "Loss: tensor(0.1016, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3644\n",
      "Loss: tensor(0.1016, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3645\n",
      "Loss: tensor(0.1016, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3646\n",
      "Loss: tensor(0.1016, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3647\n",
      "Loss: tensor(0.1016, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3648\n",
      "Loss: tensor(0.1016, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3649\n",
      "Loss: tensor(0.1016, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3650\n",
      "Loss: tensor(0.1016, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3651\n",
      "Loss: tensor(0.1016, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3652\n",
      "Loss: tensor(0.1016, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3653\n",
      "Loss: tensor(0.1016, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3654\n",
      "Loss: tensor(0.1016, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3655\n",
      "Loss: tensor(0.1016, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3656\n",
      "Loss: tensor(0.1016, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3657\n",
      "Loss: tensor(0.1016, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3658\n",
      "Loss: tensor(0.1016, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3659\n",
      "Loss: tensor(0.1015, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3660\n",
      "Loss: tensor(0.1015, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3661\n",
      "Loss: tensor(0.1015, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3662\n",
      "Loss: tensor(0.1015, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3663\n",
      "Loss: tensor(0.1015, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3664\n",
      "Loss: tensor(0.1015, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3665\n",
      "Loss: tensor(0.1015, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3666\n",
      "Loss: tensor(0.1015, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3667\n",
      "Loss: tensor(0.1015, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3668\n",
      "Loss: tensor(0.1015, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3669\n",
      "Loss: tensor(0.1015, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3670\n",
      "Loss: tensor(0.1015, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3671\n",
      "Loss: tensor(0.1015, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3672\n",
      "Loss: tensor(0.1015, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3673\n",
      "Loss: tensor(0.1015, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3674\n",
      "Loss: tensor(0.1015, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3675\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor(0.1015, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3676\n",
      "Loss: tensor(0.1015, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3677\n",
      "Loss: tensor(0.1015, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3678\n",
      "Loss: tensor(0.1015, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3679\n",
      "Loss: tensor(0.1014, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3680\n",
      "Loss: tensor(0.1014, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3681\n",
      "Loss: tensor(0.1014, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3682\n",
      "Loss: tensor(0.1014, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3683\n",
      "Loss: tensor(0.1014, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3684\n",
      "Loss: tensor(0.1014, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3685\n",
      "Loss: tensor(0.1014, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3686\n",
      "Loss: tensor(0.1014, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3687\n",
      "Loss: tensor(0.1014, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3688\n",
      "Loss: tensor(0.1014, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3689\n",
      "Loss: tensor(0.1014, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3690\n",
      "Loss: tensor(0.1014, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3691\n",
      "Loss: tensor(0.1014, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3692\n",
      "Loss: tensor(0.1014, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3693\n",
      "Loss: tensor(0.1014, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3694\n",
      "Loss: tensor(0.1014, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3695\n",
      "Loss: tensor(0.1014, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3696\n",
      "Loss: tensor(0.1014, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3697\n",
      "Loss: tensor(0.1014, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3698\n",
      "Loss: tensor(0.1014, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3699\n",
      "Loss: tensor(0.1014, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3700\n",
      "Loss: tensor(0.1013, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3701\n",
      "Loss: tensor(0.1013, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3702\n",
      "Loss: tensor(0.1013, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3703\n",
      "Loss: tensor(0.1013, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3704\n",
      "Loss: tensor(0.1013, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3705\n",
      "Loss: tensor(0.1013, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3706\n",
      "Loss: tensor(0.1013, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3707\n",
      "Loss: tensor(0.1013, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3708\n",
      "Loss: tensor(0.1013, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3709\n",
      "Loss: tensor(0.1013, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3710\n",
      "Loss: tensor(0.1013, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3711\n",
      "Loss: tensor(0.1013, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3712\n",
      "Loss: tensor(0.1013, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3713\n",
      "Loss: tensor(0.1013, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3714\n",
      "Loss: tensor(0.1013, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3715\n",
      "Loss: tensor(0.1013, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3716\n",
      "Loss: tensor(0.1013, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3717\n",
      "Loss: tensor(0.1013, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3718\n",
      "Loss: tensor(0.1013, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3719\n",
      "Loss: tensor(0.1013, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3720\n",
      "Loss: tensor(0.1013, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3721\n",
      "Loss: tensor(0.1012, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3722\n",
      "Loss: tensor(0.1012, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3723\n",
      "Loss: tensor(0.1012, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3724\n",
      "Loss: tensor(0.1012, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3725\n",
      "Loss: tensor(0.1012, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3726\n",
      "Loss: tensor(0.1012, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3727\n",
      "Loss: tensor(0.1012, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3728\n",
      "Loss: tensor(0.1012, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3729\n",
      "Loss: tensor(0.1012, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3730\n",
      "Loss: tensor(0.1012, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3731\n",
      "Loss: tensor(0.1012, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3732\n",
      "Loss: tensor(0.1012, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3733\n",
      "Loss: tensor(0.1012, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3734\n",
      "Loss: tensor(0.1012, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3735\n",
      "Loss: tensor(0.1012, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3736\n",
      "Loss: tensor(0.1012, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3737\n",
      "Loss: tensor(0.1012, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3738\n",
      "Loss: tensor(0.1012, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3739\n",
      "Loss: tensor(0.1012, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3740\n",
      "Loss: tensor(0.1012, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3741\n",
      "Loss: tensor(0.1012, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3742\n",
      "Loss: tensor(0.1011, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3743\n",
      "Loss: tensor(0.1011, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3744\n",
      "Loss: tensor(0.1011, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3745\n",
      "Loss: tensor(0.1011, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3746\n",
      "Loss: tensor(0.1011, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3747\n",
      "Loss: tensor(0.1011, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3748\n",
      "Loss: tensor(0.1011, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3749\n",
      "Loss: tensor(0.1011, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3750\n",
      "Loss: tensor(0.1011, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3751\n",
      "Loss: tensor(0.1011, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3752\n",
      "Loss: tensor(0.1011, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3753\n",
      "Loss: tensor(0.1011, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3754\n",
      "Loss: tensor(0.1011, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3755\n",
      "Loss: tensor(0.1011, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3756\n",
      "Loss: tensor(0.1011, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3757\n",
      "Loss: tensor(0.1011, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3758\n",
      "Loss: tensor(0.1011, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3759\n",
      "Loss: tensor(0.1011, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3760\n",
      "Loss: tensor(0.1011, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3761\n",
      "Loss: tensor(0.1011, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3762\n",
      "Loss: tensor(0.1011, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3763\n",
      "Loss: tensor(0.1011, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3764\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3765\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3766\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3767\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3768\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3769\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3770\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3771\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3772\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3773\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3774\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3775\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3776\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3777\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3778\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3779\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3780\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3781\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3782\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3783\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3784\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3785\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3786\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3787\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3788\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3789\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3790\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3791\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3792\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3793\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3794\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3795\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3796\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3797\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3798\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3799\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3800\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3801\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3802\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3803\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3804\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3805\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3806\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3807\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3808\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3809\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3810\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3811\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3812\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3813\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3814\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3815\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3816\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3817\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3818\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3819\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3820\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3821\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3822\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3823\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3824\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3825\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3826\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3827\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3828\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3829\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3830\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3831\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3832\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3833\n",
      "Loss: tensor(0.1007, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3834\n",
      "Loss: tensor(0.1007, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3835\n",
      "Loss: tensor(0.1007, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3836\n",
      "Loss: tensor(0.1007, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3837\n",
      "Loss: tensor(0.1007, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3838\n",
      "Loss: tensor(0.1007, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3839\n",
      "Loss: tensor(0.1007, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3840\n",
      "Loss: tensor(0.1007, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3841\n",
      "Loss: tensor(0.1007, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3842\n",
      "Loss: tensor(0.1007, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3843\n",
      "Loss: tensor(0.1007, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3844\n",
      "Loss: tensor(0.1007, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3845\n",
      "Loss: tensor(0.1007, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3846\n",
      "Loss: tensor(0.1007, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3847\n",
      "Loss: tensor(0.1007, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3848\n",
      "Loss: tensor(0.1007, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3849\n",
      "Loss: tensor(0.1007, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3850\n",
      "Loss: tensor(0.1007, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3851\n",
      "Loss: tensor(0.1007, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3852\n",
      "Loss: tensor(0.1007, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3853\n",
      "Loss: tensor(0.1007, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3854\n",
      "Loss: tensor(0.1007, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3855\n",
      "Loss: tensor(0.1007, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3856\n",
      "Loss: tensor(0.1007, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3857\n",
      "Loss: tensor(0.1007, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3858\n",
      "Loss: tensor(0.1007, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3859\n",
      "Loss: tensor(0.1007, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3860\n",
      "Loss: tensor(0.1007, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3861\n",
      "Loss: tensor(0.1006, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3862\n",
      "Loss: tensor(0.1006, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3863\n",
      "Loss: tensor(0.1006, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3864\n",
      "Loss: tensor(0.1006, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3865\n",
      "Loss: tensor(0.1006, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3866\n",
      "Loss: tensor(0.1006, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3867\n",
      "Loss: tensor(0.1006, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3868\n",
      "Loss: tensor(0.1006, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3869\n",
      "Loss: tensor(0.1006, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3870\n",
      "Loss: tensor(0.1006, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3871\n",
      "Loss: tensor(0.1006, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3872\n",
      "Loss: tensor(0.1006, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3873\n",
      "Loss: tensor(0.1006, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3874\n",
      "Loss: tensor(0.1006, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3875\n",
      "Loss: tensor(0.1006, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3876\n",
      "Loss: tensor(0.1006, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3877\n",
      "Loss: tensor(0.1006, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3878\n",
      "Loss: tensor(0.1006, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3879\n",
      "Loss: tensor(0.1006, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3880\n",
      "Loss: tensor(0.1006, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3881\n",
      "Loss: tensor(0.1006, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3882\n",
      "Loss: tensor(0.1006, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3883\n",
      "Loss: tensor(0.1005, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3884\n",
      "Loss: tensor(0.1005, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3885\n",
      "Loss: tensor(0.1005, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3886\n",
      "Loss: tensor(0.1005, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3887\n",
      "Loss: tensor(0.1005, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3888\n",
      "Loss: tensor(0.1005, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3889\n",
      "Loss: tensor(0.1005, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3890\n",
      "Loss: tensor(0.1005, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3891\n",
      "Loss: tensor(0.1005, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3892\n",
      "Loss: tensor(0.1005, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3893\n",
      "Loss: tensor(0.1005, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3894\n",
      "Loss: tensor(0.1005, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3895\n",
      "Loss: tensor(0.1005, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3896\n",
      "Loss: tensor(0.1005, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3897\n",
      "Loss: tensor(0.1005, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3898\n",
      "Loss: tensor(0.1005, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3899\n",
      "Loss: tensor(0.1005, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3900\n",
      "Loss: tensor(0.1005, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3901\n",
      "Loss: tensor(0.1005, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3902\n",
      "Loss: tensor(0.1005, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3903\n",
      "Loss: tensor(0.1005, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3904\n",
      "Loss: tensor(0.1005, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3905\n",
      "Loss: tensor(0.1005, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3906\n",
      "Loss: tensor(0.1005, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3907\n",
      "Loss: tensor(0.1005, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3908\n",
      "Loss: tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3909\n",
      "Loss: tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3910\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3911\n",
      "Loss: tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3912\n",
      "Loss: tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3913\n",
      "Loss: tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3914\n",
      "Loss: tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3915\n",
      "Loss: tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3916\n",
      "Loss: tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3917\n",
      "Loss: tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3918\n",
      "Loss: tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3919\n",
      "Loss: tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3920\n",
      "Loss: tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3921\n",
      "Loss: tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3922\n",
      "Loss: tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3923\n",
      "Loss: tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3924\n",
      "Loss: tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3925\n",
      "Loss: tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3926\n",
      "Loss: tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3927\n",
      "Loss: tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3928\n",
      "Loss: tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3929\n",
      "Loss: tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3930\n",
      "Loss: tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3931\n",
      "Loss: tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3932\n",
      "Loss: tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3933\n",
      "Loss: tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3934\n",
      "Loss: tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3935\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3936\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3937\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3938\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3939\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3940\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3941\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3942\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3943\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3944\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3945\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3946\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3947\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3948\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3949\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3950\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3951\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3952\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3953\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3954\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3955\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3956\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3957\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3958\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3959\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3960\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3961\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3962\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3963\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3964\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3965\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3966\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3967\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3968\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3969\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3970\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3971\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3972\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3973\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3974\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3975\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3976\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3977\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3978\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3979\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3980\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3981\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3982\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3983\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3984\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3985\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3986\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3987\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3988\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3989\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3990\n",
      "Loss: tensor(0.1001, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3991\n",
      "Loss: tensor(0.1001, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3992\n",
      "Loss: tensor(0.1001, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3993\n",
      "Loss: tensor(0.1001, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3994\n",
      "Loss: tensor(0.1001, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3995\n",
      "Loss: tensor(0.1001, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3996\n",
      "Loss: tensor(0.1001, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3997\n",
      "Loss: tensor(0.1001, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3998\n",
      "Loss: tensor(0.1001, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3999\n",
      "Loss: tensor(0.1001, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4000\n",
      "Loss: tensor(0.1001, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4001\n",
      "Loss: tensor(0.1001, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4002\n",
      "Loss: tensor(0.1001, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4003\n",
      "Loss: tensor(0.1001, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4004\n",
      "Loss: tensor(0.1001, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4005\n",
      "Loss: tensor(0.1001, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4006\n",
      "Loss: tensor(0.1001, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4007\n",
      "Loss: tensor(0.1001, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4008\n",
      "Loss: tensor(0.1001, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4009\n",
      "Loss: tensor(0.1001, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4010\n",
      "Loss: tensor(0.1001, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4011\n",
      "Loss: tensor(0.1001, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4012\n",
      "Loss: tensor(0.1001, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4013\n",
      "Loss: tensor(0.1001, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4014\n",
      "Loss: tensor(0.1001, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4015\n",
      "Loss: tensor(0.1001, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4016\n",
      "Loss: tensor(0.1001, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4017\n",
      "Loss: tensor(0.1001, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4018\n",
      "Loss: tensor(0.1001, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4019\n",
      "Loss: tensor(0.1000, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4020\n",
      "Loss: tensor(0.1000, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4021\n",
      "Loss: tensor(0.1000, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4022\n",
      "Loss: tensor(0.1000, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4023\n",
      "Loss: tensor(0.1000, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4024\n",
      "Loss: tensor(0.1000, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4025\n",
      "Loss: tensor(0.1000, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4026\n",
      "Loss: tensor(0.1000, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4027\n",
      "Loss: tensor(0.1000, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4028\n",
      "Loss: tensor(0.1000, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4029\n",
      "Loss: tensor(0.1000, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4030\n",
      "Loss: tensor(0.1000, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4031\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor(0.1000, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4032\n",
      "Loss: tensor(0.1000, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4033\n",
      "Loss: tensor(0.1000, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4034\n",
      "Loss: tensor(0.1000, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4035\n",
      "Loss: tensor(0.1000, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4036\n",
      "Loss: tensor(0.1000, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4037\n",
      "Loss: tensor(0.1000, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4038\n",
      "Loss: tensor(0.1000, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4039\n",
      "Loss: tensor(0.1000, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4040\n",
      "Loss: tensor(0.1000, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4041\n",
      "Loss: tensor(0.1000, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4042\n",
      "Loss: tensor(0.1000, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4043\n",
      "Loss: tensor(0.1000, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4044\n",
      "Loss: tensor(0.1000, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4045\n",
      "Loss: tensor(0.1000, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4046\n",
      "Loss: tensor(0.1000, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4047\n",
      "Loss: tensor(0.1000, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4048\n",
      "Loss: tensor(0.0999, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4049\n",
      "Loss: tensor(0.0999, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4050\n",
      "Loss: tensor(0.0999, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4051\n",
      "Loss: tensor(0.0999, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4052\n",
      "Loss: tensor(0.0999, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4053\n",
      "Loss: tensor(0.0999, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4054\n",
      "Loss: tensor(0.0999, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4055\n",
      "Loss: tensor(0.0999, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4056\n",
      "Loss: tensor(0.0999, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4057\n",
      "Loss: tensor(0.0999, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4058\n",
      "Loss: tensor(0.0999, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4059\n",
      "Loss: tensor(0.0999, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4060\n",
      "Loss: tensor(0.0999, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4061\n",
      "Loss: tensor(0.0999, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4062\n",
      "Loss: tensor(0.0999, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4063\n",
      "Loss: tensor(0.0999, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4064\n",
      "Loss: tensor(0.0999, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4065\n",
      "Loss: tensor(0.0999, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4066\n",
      "Loss: tensor(0.0999, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4067\n",
      "Loss: tensor(0.0999, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4068\n",
      "Loss: tensor(0.0999, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4069\n",
      "Loss: tensor(0.0999, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4070\n",
      "Loss: tensor(0.0999, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4071\n",
      "Loss: tensor(0.0999, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4072\n",
      "Loss: tensor(0.0999, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4073\n",
      "Loss: tensor(0.0999, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4074\n",
      "Loss: tensor(0.0999, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4075\n",
      "Loss: tensor(0.0999, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4076\n",
      "Loss: tensor(0.0999, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4077\n",
      "Loss: tensor(0.0999, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4078\n",
      "Loss: tensor(0.0999, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4079\n",
      "Loss: tensor(0.0999, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4080\n",
      "Loss: tensor(0.0998, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4081\n",
      "Loss: tensor(0.0998, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4082\n",
      "Loss: tensor(0.0998, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4083\n",
      "Loss: tensor(0.0998, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4084\n",
      "Loss: tensor(0.0998, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4085\n",
      "Loss: tensor(0.0998, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4086\n",
      "Loss: tensor(0.0998, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4087\n",
      "Loss: tensor(0.0998, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4088\n",
      "Loss: tensor(0.0998, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4089\n",
      "Loss: tensor(0.0998, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4090\n",
      "Loss: tensor(0.0998, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4091\n",
      "Loss: tensor(0.0998, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4092\n",
      "Loss: tensor(0.0998, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4093\n",
      "Loss: tensor(0.0998, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4094\n",
      "Loss: tensor(0.0998, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4095\n",
      "Loss: tensor(0.0998, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4096\n",
      "Loss: tensor(0.0998, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4097\n",
      "Loss: tensor(0.0998, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4098\n",
      "Loss: tensor(0.0998, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4099\n",
      "Loss: tensor(0.0998, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4100\n",
      "Loss: tensor(0.0998, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4101\n",
      "Loss: tensor(0.0998, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4102\n",
      "Loss: tensor(0.0998, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4103\n",
      "Loss: tensor(0.0998, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4104\n",
      "Loss: tensor(0.0998, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4105\n",
      "Loss: tensor(0.0998, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4106\n",
      "Loss: tensor(0.0998, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4107\n",
      "Loss: tensor(0.0998, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4108\n",
      "Loss: tensor(0.0998, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4109\n",
      "Loss: tensor(0.0998, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4110\n",
      "Loss: tensor(0.0998, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4111\n",
      "Loss: tensor(0.0998, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4112\n",
      "Loss: tensor(0.0997, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4113\n",
      "Loss: tensor(0.0997, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4114\n",
      "Loss: tensor(0.0997, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4115\n",
      "Loss: tensor(0.0997, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4116\n",
      "Loss: tensor(0.0997, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4117\n",
      "Loss: tensor(0.0997, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4118\n",
      "Loss: tensor(0.0997, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4119\n",
      "Loss: tensor(0.0997, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4120\n",
      "Loss: tensor(0.0997, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4121\n",
      "Loss: tensor(0.0997, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4122\n",
      "Loss: tensor(0.0997, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4123\n",
      "Loss: tensor(0.0997, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4124\n",
      "Loss: tensor(0.0997, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4125\n",
      "Loss: tensor(0.0997, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4126\n",
      "Loss: tensor(0.0997, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4127\n",
      "Loss: tensor(0.0997, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4128\n",
      "Loss: tensor(0.0997, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4129\n",
      "Loss: tensor(0.0997, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4130\n",
      "Loss: tensor(0.0997, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4131\n",
      "Loss: tensor(0.0997, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4132\n",
      "Loss: tensor(0.0997, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4133\n",
      "Loss: tensor(0.0997, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4134\n",
      "Loss: tensor(0.0997, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4135\n",
      "Loss: tensor(0.0997, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4136\n",
      "Loss: tensor(0.0997, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4137\n",
      "Loss: tensor(0.0997, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4138\n",
      "Loss: tensor(0.0997, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4139\n",
      "Loss: tensor(0.0997, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4140\n",
      "Loss: tensor(0.0997, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4141\n",
      "Loss: tensor(0.0997, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4142\n",
      "Loss: tensor(0.0997, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4143\n",
      "Loss: tensor(0.0997, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4144\n",
      "Loss: tensor(0.0996, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4145\n",
      "Loss: tensor(0.0996, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4146\n",
      "Loss: tensor(0.0996, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4147\n",
      "Loss: tensor(0.0996, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4148\n",
      "Loss: tensor(0.0996, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4149\n",
      "Loss: tensor(0.0996, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4150\n",
      "Loss: tensor(0.0996, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4151\n",
      "Loss: tensor(0.0996, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4152\n",
      "Loss: tensor(0.0996, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4153\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor(0.0996, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4154\n",
      "Loss: tensor(0.0996, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4155\n",
      "Loss: tensor(0.0996, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4156\n",
      "Loss: tensor(0.0996, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4157\n",
      "Loss: tensor(0.0996, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4158\n",
      "Loss: tensor(0.0996, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4159\n",
      "Loss: tensor(0.0996, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4160\n",
      "Loss: tensor(0.0996, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4161\n",
      "Loss: tensor(0.0996, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4162\n",
      "Loss: tensor(0.0996, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4163\n",
      "Loss: tensor(0.0996, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4164\n",
      "Loss: tensor(0.0996, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4165\n",
      "Loss: tensor(0.0996, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4166\n",
      "Loss: tensor(0.0996, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4167\n",
      "Loss: tensor(0.0996, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4168\n",
      "Loss: tensor(0.0996, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4169\n",
      "Loss: tensor(0.0996, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4170\n",
      "Loss: tensor(0.0996, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4171\n",
      "Loss: tensor(0.0996, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4172\n",
      "Loss: tensor(0.0996, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4173\n",
      "Loss: tensor(0.0996, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4174\n",
      "Loss: tensor(0.0996, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4175\n",
      "Loss: tensor(0.0996, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4176\n",
      "Loss: tensor(0.0996, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4177\n",
      "Loss: tensor(0.0996, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4178\n",
      "Loss: tensor(0.0996, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4179\n",
      "Loss: tensor(0.0995, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4180\n",
      "Loss: tensor(0.0995, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4181\n",
      "Loss: tensor(0.0995, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4182\n",
      "Loss: tensor(0.0995, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4183\n",
      "Loss: tensor(0.0995, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4184\n",
      "Loss: tensor(0.0995, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4185\n",
      "Loss: tensor(0.0995, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4186\n",
      "Loss: tensor(0.0995, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4187\n",
      "Loss: tensor(0.0995, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4188\n",
      "Loss: tensor(0.0995, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4189\n",
      "Loss: tensor(0.0995, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4190\n",
      "Loss: tensor(0.0995, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4191\n",
      "Loss: tensor(0.0995, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4192\n",
      "Loss: tensor(0.0995, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4193\n",
      "Loss: tensor(0.0995, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4194\n",
      "Loss: tensor(0.0995, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4195\n",
      "Loss: tensor(0.0995, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4196\n",
      "Loss: tensor(0.0995, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4197\n",
      "Loss: tensor(0.0995, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4198\n",
      "Loss: tensor(0.0995, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4199\n",
      "Loss: tensor(0.0995, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4200\n",
      "Loss: tensor(0.0995, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4201\n",
      "Loss: tensor(0.0995, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4202\n",
      "Loss: tensor(0.0995, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4203\n",
      "Loss: tensor(0.0995, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4204\n",
      "Loss: tensor(0.0995, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4205\n",
      "Loss: tensor(0.0995, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4206\n",
      "Loss: tensor(0.0995, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4207\n",
      "Loss: tensor(0.0995, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4208\n",
      "Loss: tensor(0.0995, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4209\n",
      "Loss: tensor(0.0995, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4210\n",
      "Loss: tensor(0.0995, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4211\n",
      "Loss: tensor(0.0995, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4212\n",
      "Loss: tensor(0.0995, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4213\n",
      "Loss: tensor(0.0995, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4214\n",
      "Loss: tensor(0.0995, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4215\n",
      "Loss: tensor(0.0995, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4216\n",
      "Loss: tensor(0.0994, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4217\n",
      "Loss: tensor(0.0994, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4218\n",
      "Loss: tensor(0.0994, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4219\n",
      "Loss: tensor(0.0994, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4220\n",
      "Loss: tensor(0.0994, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4221\n",
      "Loss: tensor(0.0994, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4222\n",
      "Loss: tensor(0.0994, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4223\n",
      "Loss: tensor(0.0994, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4224\n",
      "Loss: tensor(0.0994, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4225\n",
      "Loss: tensor(0.0994, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4226\n",
      "Loss: tensor(0.0994, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4227\n",
      "Loss: tensor(0.0994, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4228\n",
      "Loss: tensor(0.0994, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4229\n",
      "Loss: tensor(0.0994, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4230\n",
      "Loss: tensor(0.0994, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4231\n",
      "Loss: tensor(0.0994, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4232\n",
      "Loss: tensor(0.0994, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4233\n",
      "Loss: tensor(0.0994, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4234\n",
      "Loss: tensor(0.0994, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4235\n",
      "Loss: tensor(0.0994, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4236\n",
      "Loss: tensor(0.0994, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4237\n",
      "Loss: tensor(0.0994, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4238\n",
      "Loss: tensor(0.0994, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4239\n",
      "Loss: tensor(0.0994, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4240\n",
      "Loss: tensor(0.0994, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4241\n",
      "Loss: tensor(0.0994, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4242\n",
      "Loss: tensor(0.0994, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4243\n",
      "Loss: tensor(0.0994, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4244\n",
      "Loss: tensor(0.0994, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4245\n",
      "Loss: tensor(0.0994, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4246\n",
      "Loss: tensor(0.0994, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4247\n",
      "Loss: tensor(0.0994, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4248\n",
      "Loss: tensor(0.0994, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4249\n",
      "Loss: tensor(0.0994, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4250\n",
      "Loss: tensor(0.0994, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4251\n",
      "Loss: tensor(0.0994, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4252\n",
      "Loss: tensor(0.0994, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4253\n",
      "Loss: tensor(0.0994, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4254\n",
      "Loss: tensor(0.0993, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4255\n",
      "Loss: tensor(0.0993, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4256\n",
      "Loss: tensor(0.0993, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4257\n",
      "Loss: tensor(0.0993, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4258\n",
      "Loss: tensor(0.0993, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4259\n",
      "Loss: tensor(0.0993, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4260\n",
      "Loss: tensor(0.0993, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4261\n",
      "Loss: tensor(0.0993, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4262\n",
      "Loss: tensor(0.0993, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4263\n",
      "Loss: tensor(0.0993, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4264\n",
      "Loss: tensor(0.0993, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4265\n",
      "Loss: tensor(0.0993, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4266\n",
      "Loss: tensor(0.0993, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4267\n",
      "Loss: tensor(0.0993, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4268\n",
      "Loss: tensor(0.0993, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4269\n",
      "Loss: tensor(0.0993, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4270\n",
      "Loss: tensor(0.0993, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4271\n",
      "Loss: tensor(0.0993, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4272\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor(0.0993, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4273\n",
      "Loss: tensor(0.0993, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4274\n",
      "Loss: tensor(0.0993, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4275\n",
      "Loss: tensor(0.0993, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4276\n",
      "Loss: tensor(0.0993, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4277\n",
      "Loss: tensor(0.0993, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4278\n",
      "Loss: tensor(0.0993, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4279\n",
      "Loss: tensor(0.0993, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4280\n",
      "Loss: tensor(0.0993, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4281\n",
      "Loss: tensor(0.0993, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4282\n",
      "Loss: tensor(0.0993, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4283\n",
      "Loss: tensor(0.0993, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4284\n",
      "Loss: tensor(0.0993, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4285\n",
      "Loss: tensor(0.0993, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4286\n",
      "Loss: tensor(0.0993, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4287\n",
      "Loss: tensor(0.0993, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4288\n",
      "Loss: tensor(0.0993, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4289\n",
      "Loss: tensor(0.0993, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4290\n",
      "Loss: tensor(0.0992, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4291\n",
      "Loss: tensor(0.0992, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4292\n",
      "Loss: tensor(0.0992, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4293\n",
      "Loss: tensor(0.0992, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4294\n",
      "Loss: tensor(0.0992, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4295\n",
      "Loss: tensor(0.0992, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4296\n",
      "Loss: tensor(0.0992, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4297\n",
      "Loss: tensor(0.0992, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4298\n",
      "Loss: tensor(0.0992, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4299\n",
      "Loss: tensor(0.0992, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4300\n",
      "Loss: tensor(0.0992, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4301\n",
      "Loss: tensor(0.0992, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4302\n",
      "Loss: tensor(0.0992, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4303\n",
      "Loss: tensor(0.0992, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4304\n",
      "Loss: tensor(0.0992, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4305\n",
      "Loss: tensor(0.0992, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4306\n",
      "Loss: tensor(0.0992, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4307\n",
      "Loss: tensor(0.0992, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4308\n",
      "Loss: tensor(0.0992, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4309\n",
      "Loss: tensor(0.0992, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4310\n",
      "Loss: tensor(0.0992, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4311\n",
      "Loss: tensor(0.0992, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4312\n",
      "Loss: tensor(0.0992, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4313\n",
      "Loss: tensor(0.0992, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4314\n",
      "Loss: tensor(0.0992, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4315\n",
      "Loss: tensor(0.0992, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4316\n",
      "Loss: tensor(0.0992, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4317\n",
      "Loss: tensor(0.0992, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4318\n",
      "Loss: tensor(0.0992, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4319\n",
      "Loss: tensor(0.0992, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4320\n",
      "Loss: tensor(0.0992, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4321\n",
      "Loss: tensor(0.0992, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4322\n",
      "Loss: tensor(0.0992, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4323\n",
      "Loss: tensor(0.0992, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4324\n",
      "Loss: tensor(0.0992, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4325\n",
      "Loss: tensor(0.0992, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4326\n",
      "Loss: tensor(0.0992, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4327\n",
      "Loss: tensor(0.0992, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4328\n",
      "Loss: tensor(0.0992, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4329\n",
      "Loss: tensor(0.0992, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4330\n",
      "Loss: tensor(0.0992, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4331\n",
      "Loss: tensor(0.0991, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4332\n",
      "Loss: tensor(0.0991, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4333\n",
      "Loss: tensor(0.0991, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4334\n",
      "Loss: tensor(0.0991, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4335\n",
      "Loss: tensor(0.0991, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4336\n",
      "Loss: tensor(0.0991, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4337\n",
      "Loss: tensor(0.0991, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4338\n",
      "Loss: tensor(0.0991, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4339\n",
      "Loss: tensor(0.0991, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4340\n",
      "Loss: tensor(0.0991, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4341\n",
      "Loss: tensor(0.0991, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4342\n",
      "Loss: tensor(0.0991, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4343\n",
      "Loss: tensor(0.0991, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4344\n",
      "Loss: tensor(0.0991, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4345\n",
      "Loss: tensor(0.0991, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4346\n",
      "Loss: tensor(0.0991, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4347\n",
      "Loss: tensor(0.0991, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4348\n",
      "Loss: tensor(0.0991, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4349\n",
      "Loss: tensor(0.0991, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4350\n",
      "Loss: tensor(0.0991, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4351\n",
      "Loss: tensor(0.0991, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4352\n",
      "Loss: tensor(0.0991, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4353\n",
      "Loss: tensor(0.0991, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4354\n",
      "Loss: tensor(0.0991, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4355\n",
      "Loss: tensor(0.0991, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4356\n",
      "Loss: tensor(0.0991, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4357\n",
      "Loss: tensor(0.0991, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4358\n",
      "Loss: tensor(0.0991, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4359\n",
      "Loss: tensor(0.0991, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4360\n",
      "Loss: tensor(0.0991, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4361\n",
      "Loss: tensor(0.0991, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4362\n",
      "Loss: tensor(0.0991, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4363\n",
      "Loss: tensor(0.0991, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4364\n",
      "Loss: tensor(0.0991, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4365\n",
      "Loss: tensor(0.0991, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4366\n",
      "Loss: tensor(0.0991, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4367\n",
      "Loss: tensor(0.0991, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4368\n",
      "Loss: tensor(0.0991, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4369\n",
      "Loss: tensor(0.0991, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4370\n",
      "Loss: tensor(0.0991, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4371\n",
      "Loss: tensor(0.0991, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4372\n",
      "Loss: tensor(0.0990, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4373\n",
      "Loss: tensor(0.0990, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4374\n",
      "Loss: tensor(0.0990, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4375\n",
      "Loss: tensor(0.0990, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4376\n",
      "Loss: tensor(0.0990, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4377\n",
      "Loss: tensor(0.0990, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4378\n",
      "Loss: tensor(0.0990, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4379\n",
      "Loss: tensor(0.0990, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4380\n",
      "Loss: tensor(0.0990, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4381\n",
      "Loss: tensor(0.0990, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4382\n",
      "Loss: tensor(0.0990, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4383\n",
      "Loss: tensor(0.0990, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4384\n",
      "Loss: tensor(0.0990, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4385\n",
      "Loss: tensor(0.0990, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4386\n",
      "Loss: tensor(0.0990, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4387\n",
      "Loss: tensor(0.0990, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4388\n",
      "Loss: tensor(0.0990, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4389\n",
      "Loss: tensor(0.0990, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4390\n",
      "Loss: tensor(0.0990, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4391\n",
      "Loss: tensor(0.0990, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4392\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor(0.0990, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4393\n",
      "Loss: tensor(0.0990, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4394\n",
      "Loss: tensor(0.0990, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4395\n",
      "Loss: tensor(0.0990, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4396\n",
      "Loss: tensor(0.0990, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4397\n",
      "Loss: tensor(0.0990, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4398\n",
      "Loss: tensor(0.0990, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4399\n",
      "Loss: tensor(0.0990, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4400\n",
      "Loss: tensor(0.0990, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4401\n",
      "Loss: tensor(0.0990, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4402\n",
      "Loss: tensor(0.0990, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4403\n",
      "Loss: tensor(0.0990, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4404\n",
      "Loss: tensor(0.0990, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4405\n",
      "Loss: tensor(0.0990, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4406\n",
      "Loss: tensor(0.0990, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4407\n",
      "Loss: tensor(0.0990, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4408\n",
      "Loss: tensor(0.0990, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4409\n",
      "Loss: tensor(0.0990, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4410\n",
      "Loss: tensor(0.0990, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4411\n",
      "Loss: tensor(0.0990, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4412\n",
      "Loss: tensor(0.0990, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4413\n",
      "Loss: tensor(0.0990, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4414\n",
      "Loss: tensor(0.0989, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4415\n",
      "Loss: tensor(0.0989, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4416\n",
      "Loss: tensor(0.0989, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4417\n",
      "Loss: tensor(0.0989, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4418\n",
      "Loss: tensor(0.0989, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4419\n",
      "Loss: tensor(0.0989, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4420\n",
      "Loss: tensor(0.0989, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4421\n",
      "Loss: tensor(0.0989, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4422\n",
      "Loss: tensor(0.0989, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4423\n",
      "Loss: tensor(0.0989, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4424\n",
      "Loss: tensor(0.0989, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4425\n",
      "Loss: tensor(0.0989, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4426\n",
      "Loss: tensor(0.0989, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4427\n",
      "Loss: tensor(0.0989, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4428\n",
      "Loss: tensor(0.0989, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4429\n",
      "Loss: tensor(0.0989, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4430\n",
      "Loss: tensor(0.0989, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4431\n",
      "Loss: tensor(0.0989, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4432\n",
      "Loss: tensor(0.0989, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4433\n",
      "Loss: tensor(0.0989, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4434\n",
      "Loss: tensor(0.0989, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4435\n",
      "Loss: tensor(0.0989, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4436\n",
      "Loss: tensor(0.0989, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4437\n",
      "Loss: tensor(0.0989, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4438\n",
      "Loss: tensor(0.0989, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4439\n",
      "Loss: tensor(0.0989, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4440\n",
      "Loss: tensor(0.0989, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4441\n",
      "Loss: tensor(0.0989, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4442\n",
      "Loss: tensor(0.0989, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4443\n",
      "Loss: tensor(0.0989, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4444\n",
      "Loss: tensor(0.0989, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4445\n",
      "Loss: tensor(0.0989, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4446\n",
      "Loss: tensor(0.0989, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4447\n",
      "Loss: tensor(0.0989, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4448\n",
      "Loss: tensor(0.0989, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4449\n",
      "Loss: tensor(0.0989, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4450\n",
      "Loss: tensor(0.0989, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4451\n",
      "Loss: tensor(0.0989, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4452\n",
      "Loss: tensor(0.0989, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4453\n",
      "Loss: tensor(0.0989, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4454\n",
      "Loss: tensor(0.0989, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4455\n",
      "Loss: tensor(0.0989, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4456\n",
      "Loss: tensor(0.0989, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4457\n",
      "Loss: tensor(0.0989, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4458\n",
      "Loss: tensor(0.0989, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4459\n",
      "Loss: tensor(0.0989, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4460\n",
      "Loss: tensor(0.0989, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4461\n",
      "Loss: tensor(0.0989, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4462\n",
      "Loss: tensor(0.0989, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4463\n",
      "Loss: tensor(0.0989, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4464\n",
      "Loss: tensor(0.0989, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4465\n",
      "Loss: tensor(0.0988, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4466\n",
      "Loss: tensor(0.0988, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4467\n",
      "Loss: tensor(0.0988, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4468\n",
      "Loss: tensor(0.0988, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4469\n",
      "Loss: tensor(0.0988, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4470\n",
      "Loss: tensor(0.0988, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4471\n",
      "Loss: tensor(0.0988, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4472\n",
      "Loss: tensor(0.0988, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4473\n",
      "Loss: tensor(0.0988, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4474\n",
      "Loss: tensor(0.0988, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4475\n",
      "Loss: tensor(0.0988, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4476\n",
      "Loss: tensor(0.0988, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4477\n",
      "Loss: tensor(0.0988, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4478\n",
      "Loss: tensor(0.0988, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4479\n",
      "Loss: tensor(0.0988, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4480\n",
      "Loss: tensor(0.0988, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4481\n",
      "Loss: tensor(0.0988, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4482\n",
      "Loss: tensor(0.0988, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4483\n",
      "Loss: tensor(0.0988, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4484\n",
      "Loss: tensor(0.0988, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4485\n",
      "Loss: tensor(0.0988, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4486\n",
      "Loss: tensor(0.0988, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4487\n",
      "Loss: tensor(0.0988, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4488\n",
      "Loss: tensor(0.0988, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4489\n",
      "Loss: tensor(0.0988, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4490\n",
      "Loss: tensor(0.0988, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4491\n",
      "Loss: tensor(0.0988, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4492\n",
      "Loss: tensor(0.0988, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4493\n",
      "Loss: tensor(0.0988, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4494\n",
      "Loss: tensor(0.0988, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4495\n",
      "Loss: tensor(0.0988, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4496\n",
      "Loss: tensor(0.0988, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4497\n",
      "Loss: tensor(0.0988, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4498\n",
      "Loss: tensor(0.0988, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4499\n",
      "Loss: tensor(0.0988, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4500\n",
      "Loss: tensor(0.0988, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4501\n",
      "Loss: tensor(0.0988, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4502\n",
      "Loss: tensor(0.0988, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4503\n",
      "Loss: tensor(0.0988, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4504\n",
      "Loss: tensor(0.0988, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4505\n",
      "Loss: tensor(0.0988, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4506\n",
      "Loss: tensor(0.0987, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4507\n",
      "Loss: tensor(0.0987, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4508\n",
      "Loss: tensor(0.0987, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4509\n",
      "Loss: tensor(0.0987, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4510\n",
      "Loss: tensor(0.0987, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4511\n",
      "Loss: tensor(0.0987, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4512\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor(0.0987, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4513\n",
      "Loss: tensor(0.0987, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4514\n",
      "Loss: tensor(0.0987, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4515\n",
      "Loss: tensor(0.0987, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4516\n",
      "Loss: tensor(0.0987, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4517\n",
      "Loss: tensor(0.0987, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4518\n",
      "Loss: tensor(0.0987, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4519\n",
      "Loss: tensor(0.0987, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4520\n",
      "Loss: tensor(0.0987, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4521\n",
      "Loss: tensor(0.0987, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4522\n",
      "Loss: tensor(0.0987, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4523\n",
      "Loss: tensor(0.0987, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4524\n",
      "Loss: tensor(0.0987, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4525\n",
      "Loss: tensor(0.0987, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4526\n",
      "Loss: tensor(0.0987, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4527\n",
      "Loss: tensor(0.0987, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4528\n",
      "Loss: tensor(0.0987, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4529\n",
      "Loss: tensor(0.0987, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4530\n",
      "Loss: tensor(0.0987, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4531\n",
      "Loss: tensor(0.0987, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4532\n",
      "Loss: tensor(0.0987, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4533\n",
      "Loss: tensor(0.0987, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4534\n",
      "Loss: tensor(0.0987, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4535\n",
      "Loss: tensor(0.0987, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4536\n",
      "Loss: tensor(0.0987, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4537\n",
      "Loss: tensor(0.0987, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4538\n",
      "Loss: tensor(0.0987, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4539\n",
      "Loss: tensor(0.0987, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4540\n",
      "Loss: tensor(0.0987, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4541\n",
      "Loss: tensor(0.0987, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4542\n",
      "Loss: tensor(0.0987, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4543\n",
      "Loss: tensor(0.0987, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4544\n",
      "Loss: tensor(0.0987, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4545\n",
      "Loss: tensor(0.0987, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4546\n",
      "Loss: tensor(0.0987, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4547\n",
      "Loss: tensor(0.0987, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4548\n",
      "Loss: tensor(0.0987, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4549\n",
      "Loss: tensor(0.0987, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4550\n",
      "Loss: tensor(0.0987, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4551\n",
      "Loss: tensor(0.0987, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4552\n",
      "Loss: tensor(0.0987, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4553\n",
      "Loss: tensor(0.0987, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4554\n",
      "Loss: tensor(0.0987, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4555\n",
      "Loss: tensor(0.0987, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4556\n",
      "Loss: tensor(0.0987, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4557\n",
      "Loss: tensor(0.0986, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4558\n",
      "Loss: tensor(0.0986, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4559\n",
      "Loss: tensor(0.0986, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4560\n",
      "Loss: tensor(0.0986, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4561\n",
      "Loss: tensor(0.0986, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4562\n",
      "Loss: tensor(0.0986, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4563\n",
      "Loss: tensor(0.0986, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4564\n",
      "Loss: tensor(0.0986, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4565\n",
      "Loss: tensor(0.0986, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4566\n",
      "Loss: tensor(0.0986, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4567\n",
      "Loss: tensor(0.0986, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4568\n",
      "Loss: tensor(0.0986, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4569\n",
      "Loss: tensor(0.0986, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4570\n",
      "Loss: tensor(0.0986, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4571\n",
      "Loss: tensor(0.0986, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4572\n",
      "Loss: tensor(0.0986, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4573\n",
      "Loss: tensor(0.0986, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4574\n",
      "Loss: tensor(0.0986, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4575\n",
      "Loss: tensor(0.0986, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4576\n",
      "Loss: tensor(0.0986, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4577\n",
      "Loss: tensor(0.0986, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4578\n",
      "Loss: tensor(0.0986, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4579\n",
      "Loss: tensor(0.0986, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4580\n",
      "Loss: tensor(0.0986, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4581\n",
      "Loss: tensor(0.0986, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4582\n",
      "Loss: tensor(0.0986, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4583\n",
      "Loss: tensor(0.0986, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4584\n",
      "Loss: tensor(0.0986, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4585\n",
      "Loss: tensor(0.0986, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4586\n",
      "Loss: tensor(0.0986, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4587\n",
      "Loss: tensor(0.0986, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4588\n",
      "Loss: tensor(0.0986, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4589\n",
      "Loss: tensor(0.0986, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4590\n",
      "Loss: tensor(0.0986, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4591\n",
      "Loss: tensor(0.0986, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4592\n",
      "Loss: tensor(0.0986, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4593\n",
      "Loss: tensor(0.0986, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4594\n",
      "Loss: tensor(0.0986, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4595\n",
      "Loss: tensor(0.0986, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4596\n",
      "Loss: tensor(0.0986, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4597\n",
      "Loss: tensor(0.0986, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4598\n",
      "Loss: tensor(0.0986, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4599\n",
      "Loss: tensor(0.0986, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4600\n",
      "Loss: tensor(0.0986, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4601\n",
      "Loss: tensor(0.0986, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4602\n",
      "Loss: tensor(0.0986, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4603\n",
      "Loss: tensor(0.0986, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4604\n",
      "Loss: tensor(0.0986, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4605\n",
      "Loss: tensor(0.0986, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4606\n",
      "Loss: tensor(0.0985, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4607\n",
      "Loss: tensor(0.0985, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4608\n",
      "Loss: tensor(0.0985, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4609\n",
      "Loss: tensor(0.0985, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4610\n",
      "Loss: tensor(0.0985, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4611\n",
      "Loss: tensor(0.0985, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4612\n",
      "Loss: tensor(0.0985, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4613\n",
      "Loss: tensor(0.0985, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4614\n",
      "Loss: tensor(0.0985, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4615\n",
      "Loss: tensor(0.0985, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4616\n",
      "Loss: tensor(0.0985, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4617\n",
      "Loss: tensor(0.0985, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4618\n",
      "Loss: tensor(0.0985, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4619\n",
      "Loss: tensor(0.0985, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4620\n",
      "Loss: tensor(0.0985, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4621\n",
      "Loss: tensor(0.0985, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4622\n",
      "Loss: tensor(0.0985, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4623\n",
      "Loss: tensor(0.0985, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4624\n",
      "Loss: tensor(0.0985, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4625\n",
      "Loss: tensor(0.0985, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4626\n",
      "Loss: tensor(0.0985, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4627\n",
      "Loss: tensor(0.0985, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4628\n",
      "Loss: tensor(0.0985, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4629\n",
      "Loss: tensor(0.0985, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4630\n",
      "Loss: tensor(0.0985, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4631\n",
      "Loss: tensor(0.0985, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4632\n",
      "Loss: tensor(0.0985, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4633\n",
      "Loss: tensor(0.0985, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4634\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor(0.0985, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4635\n",
      "Loss: tensor(0.0985, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4636\n",
      "Loss: tensor(0.0985, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4637\n",
      "Loss: tensor(0.0985, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4638\n",
      "Loss: tensor(0.0985, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4639\n",
      "Loss: tensor(0.0985, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4640\n",
      "Loss: tensor(0.0985, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4641\n",
      "Loss: tensor(0.0985, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4642\n",
      "Loss: tensor(0.0985, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4643\n",
      "Loss: tensor(0.0985, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4644\n",
      "Loss: tensor(0.0985, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4645\n",
      "Loss: tensor(0.0985, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4646\n",
      "Loss: tensor(0.0985, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4647\n",
      "Loss: tensor(0.0985, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4648\n",
      "Loss: tensor(0.0985, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4649\n",
      "Loss: tensor(0.0985, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4650\n",
      "Loss: tensor(0.0985, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4651\n",
      "Loss: tensor(0.0985, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4652\n",
      "Loss: tensor(0.0985, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4653\n",
      "Loss: tensor(0.0985, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4654\n",
      "Loss: tensor(0.0985, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4655\n",
      "Loss: tensor(0.0985, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4656\n",
      "Loss: tensor(0.0985, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4657\n",
      "Loss: tensor(0.0985, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4658\n",
      "Loss: tensor(0.0985, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4659\n",
      "Loss: tensor(0.0984, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4660\n",
      "Loss: tensor(0.0984, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4661\n",
      "Loss: tensor(0.0984, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4662\n",
      "Loss: tensor(0.0984, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4663\n",
      "Loss: tensor(0.0984, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4664\n",
      "Loss: tensor(0.0984, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4665\n",
      "Loss: tensor(0.0984, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4666\n",
      "Loss: tensor(0.0984, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4667\n",
      "Loss: tensor(0.0984, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4668\n",
      "Loss: tensor(0.0984, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4669\n",
      "Loss: tensor(0.0984, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4670\n",
      "Loss: tensor(0.0984, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4671\n",
      "Loss: tensor(0.0984, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4672\n",
      "Loss: tensor(0.0984, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4673\n",
      "Loss: tensor(0.0984, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4674\n",
      "Loss: tensor(0.0984, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4675\n",
      "Loss: tensor(0.0984, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4676\n",
      "Loss: tensor(0.0984, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4677\n",
      "Loss: tensor(0.0984, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4678\n",
      "Loss: tensor(0.0984, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4679\n",
      "Loss: tensor(0.0984, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4680\n",
      "Loss: tensor(0.0984, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4681\n",
      "Loss: tensor(0.0984, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4682\n",
      "Loss: tensor(0.0984, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4683\n",
      "Loss: tensor(0.0984, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4684\n",
      "Loss: tensor(0.0984, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4685\n",
      "Loss: tensor(0.0984, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4686\n",
      "Loss: tensor(0.0984, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4687\n",
      "Loss: tensor(0.0984, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4688\n",
      "Loss: tensor(0.0984, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4689\n",
      "Loss: tensor(0.0984, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4690\n",
      "Loss: tensor(0.0984, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4691\n",
      "Loss: tensor(0.0984, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4692\n",
      "Loss: tensor(0.0984, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4693\n",
      "Loss: tensor(0.0984, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4694\n",
      "Loss: tensor(0.0984, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4695\n",
      "Loss: tensor(0.0984, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4696\n",
      "Loss: tensor(0.0984, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4697\n",
      "Loss: tensor(0.0984, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4698\n",
      "Loss: tensor(0.0984, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4699\n",
      "Loss: tensor(0.0984, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4700\n",
      "Loss: tensor(0.0984, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4701\n",
      "Loss: tensor(0.0984, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4702\n",
      "Loss: tensor(0.0984, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4703\n",
      "Loss: tensor(0.0984, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4704\n",
      "Loss: tensor(0.0984, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4705\n",
      "Loss: tensor(0.0984, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4706\n",
      "Loss: tensor(0.0984, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4707\n",
      "Loss: tensor(0.0984, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4708\n",
      "Loss: tensor(0.0984, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4709\n",
      "Loss: tensor(0.0984, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4710\n",
      "Loss: tensor(0.0984, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4711\n",
      "Loss: tensor(0.0984, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4712\n",
      "Loss: tensor(0.0984, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4713\n",
      "Loss: tensor(0.0984, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4714\n",
      "Loss: tensor(0.0984, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4715\n",
      "Loss: tensor(0.0984, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4716\n",
      "Loss: tensor(0.0984, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4717\n",
      "Loss: tensor(0.0983, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4718\n",
      "Loss: tensor(0.0983, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4719\n",
      "Loss: tensor(0.0983, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4720\n",
      "Loss: tensor(0.0983, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4721\n",
      "Loss: tensor(0.0983, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4722\n",
      "Loss: tensor(0.0983, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4723\n",
      "Loss: tensor(0.0983, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4724\n",
      "Loss: tensor(0.0983, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4725\n",
      "Loss: tensor(0.0983, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4726\n",
      "Loss: tensor(0.0983, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4727\n",
      "Loss: tensor(0.0983, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4728\n",
      "Loss: tensor(0.0983, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4729\n",
      "Loss: tensor(0.0983, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4730\n",
      "Loss: tensor(0.0983, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4731\n",
      "Loss: tensor(0.0983, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4732\n",
      "Loss: tensor(0.0983, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4733\n",
      "Loss: tensor(0.0983, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4734\n",
      "Loss: tensor(0.0983, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4735\n",
      "Loss: tensor(0.0983, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4736\n",
      "Loss: tensor(0.0983, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4737\n",
      "Loss: tensor(0.0983, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4738\n",
      "Loss: tensor(0.0983, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4739\n",
      "Loss: tensor(0.0983, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4740\n",
      "Loss: tensor(0.0983, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4741\n",
      "Loss: tensor(0.0983, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4742\n",
      "Loss: tensor(0.0983, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4743\n",
      "Loss: tensor(0.0983, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4744\n",
      "Loss: tensor(0.0983, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4745\n",
      "Loss: tensor(0.0983, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4746\n",
      "Loss: tensor(0.0983, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4747\n",
      "Loss: tensor(0.0983, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4748\n",
      "Loss: tensor(0.0983, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4749\n",
      "Loss: tensor(0.0983, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4750\n",
      "Loss: tensor(0.0983, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4751\n",
      "Loss: tensor(0.0983, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4752\n",
      "Loss: tensor(0.0983, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4753\n",
      "Loss: tensor(0.0983, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4754\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor(0.0983, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4755\n",
      "Loss: tensor(0.0983, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4756\n",
      "Loss: tensor(0.0983, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4757\n",
      "Loss: tensor(0.0983, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4758\n",
      "Loss: tensor(0.0983, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4759\n",
      "Loss: tensor(0.0983, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4760\n",
      "Loss: tensor(0.0983, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4761\n",
      "Loss: tensor(0.0983, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4762\n",
      "Loss: tensor(0.0983, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4763\n",
      "Loss: tensor(0.0983, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4764\n",
      "Loss: tensor(0.0983, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4765\n",
      "Loss: tensor(0.0983, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4766\n",
      "Loss: tensor(0.0983, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4767\n",
      "Loss: tensor(0.0983, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4768\n",
      "Loss: tensor(0.0983, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4769\n",
      "Loss: tensor(0.0983, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4770\n",
      "Loss: tensor(0.0983, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4771\n",
      "Loss: tensor(0.0983, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4772\n",
      "Loss: tensor(0.0983, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4773\n",
      "Loss: tensor(0.0983, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4774\n",
      "Loss: tensor(0.0983, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4775\n",
      "Loss: tensor(0.0983, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4776\n",
      "Loss: tensor(0.0982, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4777\n",
      "Loss: tensor(0.0982, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4778\n",
      "Loss: tensor(0.0982, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4779\n",
      "Loss: tensor(0.0982, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4780\n",
      "Loss: tensor(0.0982, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4781\n",
      "Loss: tensor(0.0982, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4782\n",
      "Loss: tensor(0.0982, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4783\n",
      "Loss: tensor(0.0982, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4784\n",
      "Loss: tensor(0.0982, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4785\n",
      "Loss: tensor(0.0982, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4786\n",
      "Loss: tensor(0.0982, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4787\n",
      "Loss: tensor(0.0982, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4788\n",
      "Loss: tensor(0.0982, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4789\n",
      "Loss: tensor(0.0982, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4790\n",
      "Loss: tensor(0.0982, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4791\n",
      "Loss: tensor(0.0982, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4792\n",
      "Loss: tensor(0.0982, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4793\n",
      "Loss: tensor(0.0982, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4794\n",
      "Loss: tensor(0.0982, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4795\n",
      "Loss: tensor(0.0982, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4796\n",
      "Loss: tensor(0.0982, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4797\n",
      "Loss: tensor(0.0982, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4798\n",
      "Loss: tensor(0.0982, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4799\n",
      "Loss: tensor(0.0982, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4800\n",
      "Loss: tensor(0.0982, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4801\n",
      "Loss: tensor(0.0982, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4802\n",
      "Loss: tensor(0.0982, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4803\n",
      "Loss: tensor(0.0982, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4804\n",
      "Loss: tensor(0.0982, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4805\n",
      "Loss: tensor(0.0982, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4806\n",
      "Loss: tensor(0.0982, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4807\n",
      "Loss: tensor(0.0982, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4808\n",
      "Loss: tensor(0.0982, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4809\n",
      "Loss: tensor(0.0982, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4810\n",
      "Loss: tensor(0.0982, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4811\n",
      "Loss: tensor(0.0982, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4812\n",
      "Loss: tensor(0.0982, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4813\n",
      "Loss: tensor(0.0982, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4814\n",
      "Loss: tensor(0.0982, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4815\n",
      "Loss: tensor(0.0982, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4816\n",
      "Loss: tensor(0.0982, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4817\n",
      "Loss: tensor(0.0982, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4818\n",
      "Loss: tensor(0.0982, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4819\n",
      "Loss: tensor(0.0982, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4820\n",
      "Loss: tensor(0.0982, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4821\n",
      "Loss: tensor(0.0982, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4822\n",
      "Loss: tensor(0.0982, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4823\n",
      "Loss: tensor(0.0982, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4824\n",
      "Loss: tensor(0.0982, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4825\n",
      "Loss: tensor(0.0982, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4826\n",
      "Loss: tensor(0.0982, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4827\n",
      "Loss: tensor(0.0982, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4828\n",
      "Loss: tensor(0.0982, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4829\n",
      "Loss: tensor(0.0982, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4830\n",
      "Loss: tensor(0.0982, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4831\n",
      "Loss: tensor(0.0982, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4832\n",
      "Loss: tensor(0.0982, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4833\n",
      "Loss: tensor(0.0981, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4834\n",
      "Loss: tensor(0.0981, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4835\n",
      "Loss: tensor(0.0981, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4836\n",
      "Loss: tensor(0.0981, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4837\n",
      "Loss: tensor(0.0981, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4838\n",
      "Loss: tensor(0.0981, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4839\n",
      "Loss: tensor(0.0981, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4840\n",
      "Loss: tensor(0.0981, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4841\n",
      "Loss: tensor(0.0981, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4842\n",
      "Loss: tensor(0.0981, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4843\n",
      "Loss: tensor(0.0981, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4844\n",
      "Loss: tensor(0.0981, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4845\n",
      "Loss: tensor(0.0981, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4846\n",
      "Loss: tensor(0.0981, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4847\n",
      "Loss: tensor(0.0981, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4848\n",
      "Loss: tensor(0.0981, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4849\n",
      "Loss: tensor(0.0981, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4850\n",
      "Loss: tensor(0.0981, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4851\n",
      "Loss: tensor(0.0981, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4852\n",
      "Loss: tensor(0.0981, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4853\n",
      "Loss: tensor(0.0981, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4854\n",
      "Loss: tensor(0.0981, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4855\n",
      "Loss: tensor(0.0981, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4856\n",
      "Loss: tensor(0.0981, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4857\n",
      "Loss: tensor(0.0981, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4858\n",
      "Loss: tensor(0.0981, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4859\n",
      "Loss: tensor(0.0981, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4860\n",
      "Loss: tensor(0.0981, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4861\n",
      "Loss: tensor(0.0981, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4862\n",
      "Loss: tensor(0.0981, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4863\n",
      "Loss: tensor(0.0981, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4864\n",
      "Loss: tensor(0.0981, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4865\n",
      "Loss: tensor(0.0981, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4866\n",
      "Loss: tensor(0.0981, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4867\n",
      "Loss: tensor(0.0981, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4868\n",
      "Loss: tensor(0.0981, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4869\n",
      "Loss: tensor(0.0981, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4870\n",
      "Loss: tensor(0.0981, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4871\n",
      "Loss: tensor(0.0981, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4872\n",
      "Loss: tensor(0.0981, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4873\n",
      "Loss: tensor(0.0981, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4874\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor(0.0981, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4875\n",
      "Loss: tensor(0.0981, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4876\n",
      "Loss: tensor(0.0981, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4877\n",
      "Loss: tensor(0.0981, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4878\n",
      "Loss: tensor(0.0981, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4879\n",
      "Loss: tensor(0.0981, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4880\n",
      "Loss: tensor(0.0981, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4881\n",
      "Loss: tensor(0.0981, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4882\n",
      "Loss: tensor(0.0981, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4883\n",
      "Loss: tensor(0.0981, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4884\n",
      "Loss: tensor(0.0981, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4885\n",
      "Loss: tensor(0.0981, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4886\n",
      "Loss: tensor(0.0981, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4887\n",
      "Loss: tensor(0.0981, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4888\n",
      "Loss: tensor(0.0981, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4889\n",
      "Loss: tensor(0.0981, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4890\n",
      "Loss: tensor(0.0981, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4891\n",
      "Loss: tensor(0.0981, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4892\n",
      "Loss: tensor(0.0981, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4893\n",
      "Loss: tensor(0.0981, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4894\n",
      "Loss: tensor(0.0981, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4895\n",
      "Loss: tensor(0.0981, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4896\n",
      "Loss: tensor(0.0980, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4897\n",
      "Loss: tensor(0.0980, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4898\n",
      "Loss: tensor(0.0980, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4899\n",
      "Loss: tensor(0.0980, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4900\n",
      "Loss: tensor(0.0980, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4901\n",
      "Loss: tensor(0.0980, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4902\n",
      "Loss: tensor(0.0980, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4903\n",
      "Loss: tensor(0.0980, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4904\n",
      "Loss: tensor(0.0980, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4905\n",
      "Loss: tensor(0.0980, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4906\n",
      "Loss: tensor(0.0980, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4907\n",
      "Loss: tensor(0.0980, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4908\n",
      "Loss: tensor(0.0980, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4909\n",
      "Loss: tensor(0.0980, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4910\n",
      "Loss: tensor(0.0980, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4911\n",
      "Loss: tensor(0.0980, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4912\n",
      "Loss: tensor(0.0980, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4913\n",
      "Loss: tensor(0.0980, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4914\n",
      "Loss: tensor(0.0980, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4915\n",
      "Loss: tensor(0.0980, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4916\n",
      "Loss: tensor(0.0980, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4917\n",
      "Loss: tensor(0.0980, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4918\n",
      "Loss: tensor(0.0980, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4919\n",
      "Loss: tensor(0.0980, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4920\n",
      "Loss: tensor(0.0980, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4921\n",
      "Loss: tensor(0.0980, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4922\n",
      "Loss: tensor(0.0980, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4923\n",
      "Loss: tensor(0.0980, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4924\n",
      "Loss: tensor(0.0980, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4925\n",
      "Loss: tensor(0.0980, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4926\n",
      "Loss: tensor(0.0980, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4927\n",
      "Loss: tensor(0.0980, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4928\n",
      "Loss: tensor(0.0980, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4929\n",
      "Loss: tensor(0.0980, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4930\n",
      "Loss: tensor(0.0980, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4931\n",
      "Loss: tensor(0.0980, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4932\n",
      "Loss: tensor(0.0980, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4933\n",
      "Loss: tensor(0.0980, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4934\n",
      "Loss: tensor(0.0980, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4935\n",
      "Loss: tensor(0.0980, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4936\n",
      "Loss: tensor(0.0980, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4937\n",
      "Loss: tensor(0.0980, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4938\n",
      "Loss: tensor(0.0980, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4939\n",
      "Loss: tensor(0.0980, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4940\n",
      "Loss: tensor(0.0980, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4941\n",
      "Loss: tensor(0.0980, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4942\n",
      "Loss: tensor(0.0980, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4943\n",
      "Loss: tensor(0.0980, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4944\n",
      "Loss: tensor(0.0980, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4945\n",
      "Loss: tensor(0.0980, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4946\n",
      "Loss: tensor(0.0980, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4947\n",
      "Loss: tensor(0.0980, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4948\n",
      "Loss: tensor(0.0980, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4949\n",
      "Loss: tensor(0.0980, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4950\n",
      "Loss: tensor(0.0980, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4951\n",
      "Loss: tensor(0.0980, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4952\n",
      "Loss: tensor(0.0980, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4953\n",
      "Loss: tensor(0.0980, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4954\n",
      "Loss: tensor(0.0980, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4955\n",
      "Loss: tensor(0.0980, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4956\n",
      "Loss: tensor(0.0980, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4957\n",
      "Loss: tensor(0.0980, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4958\n",
      "Loss: tensor(0.0980, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4959\n",
      "Loss: tensor(0.0980, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4960\n",
      "Loss: tensor(0.0980, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4961\n",
      "Loss: tensor(0.0980, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4962\n",
      "Loss: tensor(0.0980, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4963\n",
      "Loss: tensor(0.0979, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4964\n",
      "Loss: tensor(0.0979, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4965\n",
      "Loss: tensor(0.0979, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4966\n",
      "Loss: tensor(0.0979, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4967\n",
      "Loss: tensor(0.0979, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4968\n",
      "Loss: tensor(0.0979, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4969\n",
      "Loss: tensor(0.0979, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4970\n",
      "Loss: tensor(0.0979, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4971\n",
      "Loss: tensor(0.0979, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4972\n",
      "Loss: tensor(0.0979, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4973\n",
      "Loss: tensor(0.0979, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4974\n",
      "Loss: tensor(0.0979, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4975\n",
      "Loss: tensor(0.0979, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4976\n",
      "Loss: tensor(0.0979, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4977\n",
      "Loss: tensor(0.0979, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4978\n",
      "Loss: tensor(0.0979, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4979\n",
      "Loss: tensor(0.0979, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4980\n",
      "Loss: tensor(0.0979, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4981\n",
      "Loss: tensor(0.0979, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4982\n",
      "Loss: tensor(0.0979, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4983\n",
      "Loss: tensor(0.0979, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4984\n",
      "Loss: tensor(0.0979, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4985\n",
      "Loss: tensor(0.0979, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4986\n",
      "Loss: tensor(0.0979, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4987\n",
      "Loss: tensor(0.0979, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4988\n",
      "Loss: tensor(0.0979, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4989\n",
      "Loss: tensor(0.0979, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4990\n",
      "Loss: tensor(0.0979, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4991\n",
      "Loss: tensor(0.0979, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4992\n",
      "Loss: tensor(0.0979, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4993\n",
      "Loss: tensor(0.0979, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4994\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor(0.0979, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4995\n",
      "Loss: tensor(0.0979, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4996\n",
      "Loss: tensor(0.0979, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4997\n",
      "Loss: tensor(0.0979, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4998\n",
      "Loss: tensor(0.0979, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4999\n",
      "Loss: tensor(0.0979, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5000\n",
      "Loss: tensor(0.0979, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5001\n",
      "Loss: tensor(0.0979, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5002\n",
      "Loss: tensor(0.0979, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5003\n",
      "Loss: tensor(0.0979, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5004\n",
      "Loss: tensor(0.0979, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5005\n",
      "Loss: tensor(0.0979, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5006\n",
      "Loss: tensor(0.0979, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5007\n",
      "Loss: tensor(0.0979, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5008\n",
      "Loss: tensor(0.0979, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5009\n",
      "Loss: tensor(0.0979, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5010\n",
      "Loss: tensor(0.0979, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5011\n",
      "Loss: tensor(0.0979, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5012\n",
      "Loss: tensor(0.0979, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5013\n",
      "Loss: tensor(0.0979, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5014\n",
      "Loss: tensor(0.0979, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5015\n",
      "Loss: tensor(0.0979, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5016\n",
      "Loss: tensor(0.0979, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5017\n",
      "Loss: tensor(0.0979, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5018\n",
      "Loss: tensor(0.0979, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5019\n",
      "Loss: tensor(0.0979, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5020\n",
      "Loss: tensor(0.0979, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5021\n",
      "Loss: tensor(0.0979, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5022\n",
      "Loss: tensor(0.0979, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5023\n",
      "Loss: tensor(0.0979, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5024\n",
      "Loss: tensor(0.0979, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5025\n",
      "Loss: tensor(0.0979, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5026\n",
      "Loss: tensor(0.0979, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5027\n",
      "Loss: tensor(0.0979, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5028\n",
      "Loss: tensor(0.0979, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5029\n",
      "Loss: tensor(0.0979, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5030\n",
      "Loss: tensor(0.0979, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5031\n",
      "Loss: tensor(0.0979, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5032\n",
      "Loss: tensor(0.0979, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5033\n",
      "Loss: tensor(0.0979, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5034\n",
      "Loss: tensor(0.0978, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5035\n",
      "Loss: tensor(0.0978, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5036\n",
      "Loss: tensor(0.0978, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5037\n",
      "Loss: tensor(0.0978, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5038\n",
      "Loss: tensor(0.0978, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5039\n",
      "Loss: tensor(0.0978, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5040\n",
      "Loss: tensor(0.0978, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5041\n",
      "Loss: tensor(0.0978, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5042\n",
      "Loss: tensor(0.0978, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5043\n",
      "Loss: tensor(0.0978, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5044\n",
      "Loss: tensor(0.0978, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5045\n",
      "Loss: tensor(0.0978, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5046\n",
      "Loss: tensor(0.0978, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5047\n",
      "Loss: tensor(0.0978, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5048\n",
      "Loss: tensor(0.0978, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5049\n",
      "Loss: tensor(0.0978, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5050\n",
      "Loss: tensor(0.0978, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5051\n",
      "Loss: tensor(0.0978, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5052\n",
      "Loss: tensor(0.0978, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5053\n",
      "Loss: tensor(0.0978, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5054\n",
      "Loss: tensor(0.0978, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5055\n",
      "Loss: tensor(0.0978, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5056\n",
      "Loss: tensor(0.0978, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5057\n",
      "Loss: tensor(0.0978, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5058\n",
      "Loss: tensor(0.0978, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5059\n",
      "Loss: tensor(0.0978, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5060\n",
      "Loss: tensor(0.0978, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5061\n",
      "Loss: tensor(0.0978, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5062\n",
      "Loss: tensor(0.0978, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5063\n",
      "Loss: tensor(0.0978, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5064\n",
      "Loss: tensor(0.0978, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5065\n",
      "Loss: tensor(0.0978, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5066\n",
      "Loss: tensor(0.0978, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5067\n",
      "Loss: tensor(0.0978, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5068\n",
      "Loss: tensor(0.0978, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5069\n",
      "Loss: tensor(0.0978, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5070\n",
      "Loss: tensor(0.0978, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5071\n",
      "Loss: tensor(0.0978, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5072\n",
      "Loss: tensor(0.0978, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5073\n",
      "Loss: tensor(0.0978, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5074\n",
      "Loss: tensor(0.0978, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5075\n",
      "Loss: tensor(0.0978, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5076\n",
      "Loss: tensor(0.0978, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5077\n",
      "Loss: tensor(0.0978, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5078\n",
      "Loss: tensor(0.0978, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5079\n",
      "Loss: tensor(0.0978, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5080\n",
      "Loss: tensor(0.0978, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5081\n",
      "Loss: tensor(0.0978, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5082\n",
      "Loss: tensor(0.0978, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5083\n",
      "Loss: tensor(0.0978, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5084\n",
      "Loss: tensor(0.0978, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5085\n",
      "Loss: tensor(0.0978, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5086\n",
      "Loss: tensor(0.0978, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5087\n",
      "Loss: tensor(0.0978, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5088\n",
      "Loss: tensor(0.0978, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5089\n",
      "Loss: tensor(0.0978, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5090\n",
      "Loss: tensor(0.0978, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5091\n",
      "Loss: tensor(0.0978, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5092\n",
      "Loss: tensor(0.0978, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5093\n",
      "Loss: tensor(0.0978, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5094\n",
      "Loss: tensor(0.0978, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5095\n",
      "Loss: tensor(0.0978, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5096\n",
      "Loss: tensor(0.0978, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5097\n",
      "Loss: tensor(0.0978, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5098\n",
      "Loss: tensor(0.0978, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5099\n",
      "Loss: tensor(0.0978, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5100\n",
      "Loss: tensor(0.0978, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5101\n",
      "Loss: tensor(0.0978, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5102\n",
      "Loss: tensor(0.0978, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5103\n",
      "Loss: tensor(0.0978, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5104\n",
      "Loss: tensor(0.0978, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5105\n",
      "Loss: tensor(0.0978, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5106\n",
      "Loss: tensor(0.0978, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5107\n",
      "Loss: tensor(0.0978, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5108\n",
      "Loss: tensor(0.0978, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5109\n",
      "Loss: tensor(0.0977, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5110\n",
      "Loss: tensor(0.0977, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5111\n",
      "Loss: tensor(0.0977, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5112\n",
      "Loss: tensor(0.0977, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5113\n",
      "Loss: tensor(0.0977, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5114\n",
      "Loss: tensor(0.0977, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5115\n",
      "Loss: tensor(0.0977, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5116\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor(0.0977, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5117\n",
      "Loss: tensor(0.0977, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5118\n",
      "Loss: tensor(0.0977, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5119\n",
      "Loss: tensor(0.0977, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5120\n",
      "Loss: tensor(0.0977, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5121\n",
      "Loss: tensor(0.0977, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5122\n",
      "Loss: tensor(0.0977, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5123\n",
      "Loss: tensor(0.0977, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5124\n",
      "Loss: tensor(0.0977, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5125\n",
      "Loss: tensor(0.0977, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5126\n",
      "Loss: tensor(0.0977, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5127\n",
      "Loss: tensor(0.0977, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5128\n",
      "Loss: tensor(0.0977, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5129\n",
      "Loss: tensor(0.0977, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5130\n",
      "Loss: tensor(0.0977, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5131\n",
      "Loss: tensor(0.0977, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5132\n",
      "Loss: tensor(0.0977, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5133\n",
      "Loss: tensor(0.0977, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5134\n",
      "Loss: tensor(0.0977, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5135\n",
      "Loss: tensor(0.0977, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5136\n",
      "Loss: tensor(0.0977, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5137\n",
      "Loss: tensor(0.0977, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5138\n",
      "Loss: tensor(0.0977, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5139\n",
      "Loss: tensor(0.0977, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5140\n",
      "Loss: tensor(0.0977, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5141\n",
      "Loss: tensor(0.0977, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5142\n",
      "Loss: tensor(0.0977, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5143\n",
      "Loss: tensor(0.0977, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5144\n",
      "Loss: tensor(0.0977, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5145\n",
      "Loss: tensor(0.0977, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5146\n",
      "Loss: tensor(0.0977, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5147\n",
      "Loss: tensor(0.0977, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5148\n",
      "Loss: tensor(0.0977, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5149\n",
      "Loss: tensor(0.0977, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5150\n",
      "Loss: tensor(0.0977, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5151\n",
      "Loss: tensor(0.0977, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5152\n",
      "Loss: tensor(0.0977, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5153\n",
      "Loss: tensor(0.0977, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5154\n",
      "Loss: tensor(0.0977, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5155\n",
      "Loss: tensor(0.0977, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5156\n",
      "Loss: tensor(0.0977, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5157\n",
      "Loss: tensor(0.0977, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5158\n",
      "Loss: tensor(0.0977, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5159\n",
      "Loss: tensor(0.0977, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5160\n",
      "Loss: tensor(0.0977, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5161\n",
      "Loss: tensor(0.0977, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5162\n",
      "Loss: tensor(0.0977, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5163\n",
      "Loss: tensor(0.0977, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5164\n",
      "Loss: tensor(0.0977, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5165\n",
      "Loss: tensor(0.0977, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5166\n",
      "Loss: tensor(0.0977, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5167\n",
      "Loss: tensor(0.0977, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5168\n",
      "Loss: tensor(0.0977, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5169\n",
      "Loss: tensor(0.0977, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5170\n",
      "Loss: tensor(0.0977, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5171\n",
      "Loss: tensor(0.0977, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5172\n",
      "Loss: tensor(0.0977, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5173\n",
      "Loss: tensor(0.0977, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5174\n",
      "Loss: tensor(0.0977, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5175\n",
      "Loss: tensor(0.0977, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5176\n",
      "Loss: tensor(0.0977, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5177\n",
      "Loss: tensor(0.0977, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5178\n",
      "Loss: tensor(0.0977, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5179\n",
      "Loss: tensor(0.0977, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5180\n",
      "Loss: tensor(0.0977, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5181\n",
      "Loss: tensor(0.0977, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5182\n",
      "Loss: tensor(0.0977, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5183\n",
      "Loss: tensor(0.0977, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5184\n",
      "Loss: tensor(0.0977, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5185\n",
      "Loss: tensor(0.0977, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5186\n",
      "Loss: tensor(0.0977, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5187\n",
      "Loss: tensor(0.0976, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5188\n",
      "Loss: tensor(0.0976, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5189\n",
      "Loss: tensor(0.0976, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5190\n",
      "Loss: tensor(0.0976, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5191\n",
      "Loss: tensor(0.0976, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5192\n",
      "Loss: tensor(0.0976, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5193\n",
      "Loss: tensor(0.0976, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5194\n",
      "Loss: tensor(0.0976, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5195\n",
      "Loss: tensor(0.0976, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5196\n",
      "Loss: tensor(0.0976, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5197\n",
      "Loss: tensor(0.0976, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5198\n",
      "Loss: tensor(0.0976, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5199\n",
      "Loss: tensor(0.0976, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5200\n",
      "Loss: tensor(0.0976, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5201\n",
      "Loss: tensor(0.0976, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5202\n",
      "Loss: tensor(0.0976, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5203\n",
      "Loss: tensor(0.0976, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5204\n",
      "Loss: tensor(0.0976, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5205\n",
      "Loss: tensor(0.0976, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5206\n",
      "Loss: tensor(0.0976, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5207\n",
      "Loss: tensor(0.0976, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5208\n",
      "Loss: tensor(0.0976, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5209\n",
      "Loss: tensor(0.0976, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5210\n",
      "Loss: tensor(0.0976, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5211\n",
      "Loss: tensor(0.0976, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5212\n",
      "Loss: tensor(0.0976, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5213\n",
      "Loss: tensor(0.0976, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5214\n",
      "Loss: tensor(0.0976, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5215\n",
      "Loss: tensor(0.0976, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5216\n",
      "Loss: tensor(0.0976, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5217\n",
      "Loss: tensor(0.0976, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5218\n",
      "Loss: tensor(0.0976, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5219\n",
      "Loss: tensor(0.0976, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5220\n",
      "Loss: tensor(0.0976, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5221\n",
      "Loss: tensor(0.0976, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5222\n",
      "Loss: tensor(0.0976, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5223\n",
      "Loss: tensor(0.0976, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5224\n",
      "Loss: tensor(0.0976, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5225\n",
      "Loss: tensor(0.0976, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5226\n",
      "Loss: tensor(0.0976, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5227\n",
      "Loss: tensor(0.0976, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5228\n",
      "Loss: tensor(0.0976, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5229\n",
      "Loss: tensor(0.0976, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5230\n",
      "Loss: tensor(0.0976, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5231\n",
      "Loss: tensor(0.0976, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5232\n",
      "Loss: tensor(0.0976, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5233\n",
      "Loss: tensor(0.0976, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5234\n",
      "Loss: tensor(0.0976, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5235\n",
      "Loss: tensor(0.0976, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5236\n",
      "Loss: tensor(0.0976, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5237\n",
      "Loss: tensor(0.0976, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5238\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor(0.0976, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5239\n",
      "Loss: tensor(0.0976, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5240\n",
      "Loss: tensor(0.0976, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5241\n",
      "Loss: tensor(0.0976, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5242\n",
      "Loss: tensor(0.0976, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5243\n",
      "Loss: tensor(0.0976, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5244\n",
      "Loss: tensor(0.0976, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5245\n",
      "Loss: tensor(0.0976, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5246\n",
      "Loss: tensor(0.0976, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5247\n",
      "Loss: tensor(0.0976, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5248\n",
      "Loss: tensor(0.0976, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5249\n",
      "Loss: tensor(0.0976, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5250\n",
      "Loss: tensor(0.0976, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5251\n",
      "Loss: tensor(0.0976, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5252\n",
      "Loss: tensor(0.0976, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5253\n",
      "Loss: tensor(0.0976, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5254\n",
      "Loss: tensor(0.0976, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5255\n",
      "Loss: tensor(0.0976, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5256\n",
      "Loss: tensor(0.0976, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5257\n",
      "Loss: tensor(0.0976, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5258\n",
      "Loss: tensor(0.0976, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5259\n",
      "Loss: tensor(0.0976, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5260\n",
      "Loss: tensor(0.0976, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5261\n",
      "Loss: tensor(0.0976, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5262\n",
      "Loss: tensor(0.0976, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5263\n",
      "Loss: tensor(0.0976, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5264\n",
      "Loss: tensor(0.0976, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5265\n",
      "Loss: tensor(0.0976, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5266\n",
      "Loss: tensor(0.0976, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5267\n",
      "Loss: tensor(0.0976, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5268\n",
      "Loss: tensor(0.0976, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5269\n",
      "Loss: tensor(0.0975, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5270\n",
      "Loss: tensor(0.0975, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5271\n",
      "Loss: tensor(0.0975, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5272\n",
      "Loss: tensor(0.0975, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5273\n",
      "Loss: tensor(0.0975, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5274\n",
      "Loss: tensor(0.0975, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5275\n",
      "Loss: tensor(0.0975, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5276\n",
      "Loss: tensor(0.0975, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5277\n",
      "Loss: tensor(0.0975, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5278\n",
      "Loss: tensor(0.0975, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5279\n",
      "Loss: tensor(0.0975, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5280\n",
      "Loss: tensor(0.0975, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5281\n",
      "Loss: tensor(0.0975, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5282\n",
      "Loss: tensor(0.0975, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5283\n",
      "Loss: tensor(0.0975, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5284\n",
      "Loss: tensor(0.0975, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5285\n",
      "Loss: tensor(0.0975, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5286\n",
      "Loss: tensor(0.0975, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5287\n",
      "Loss: tensor(0.0975, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5288\n",
      "Loss: tensor(0.0975, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5289\n",
      "Loss: tensor(0.0975, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5290\n",
      "Loss: tensor(0.0975, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5291\n",
      "Loss: tensor(0.0975, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5292\n",
      "Loss: tensor(0.0975, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5293\n",
      "Loss: tensor(0.0975, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5294\n",
      "Loss: tensor(0.0975, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5295\n",
      "Loss: tensor(0.0975, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5296\n",
      "Loss: tensor(0.0975, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5297\n",
      "Loss: tensor(0.0975, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5298\n",
      "Loss: tensor(0.0975, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5299\n",
      "Loss: tensor(0.0975, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5300\n",
      "Loss: tensor(0.0975, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5301\n",
      "Loss: tensor(0.0975, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5302\n",
      "Loss: tensor(0.0975, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5303\n",
      "Loss: tensor(0.0975, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5304\n",
      "Loss: tensor(0.0975, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5305\n",
      "Loss: tensor(0.0975, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5306\n",
      "Loss: tensor(0.0975, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5307\n",
      "Loss: tensor(0.0975, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5308\n",
      "Loss: tensor(0.0975, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5309\n",
      "Loss: tensor(0.0975, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5310\n",
      "Loss: tensor(0.0975, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5311\n",
      "Loss: tensor(0.0975, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5312\n",
      "Loss: tensor(0.0975, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5313\n",
      "Loss: tensor(0.0975, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5314\n",
      "Loss: tensor(0.0975, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5315\n",
      "Loss: tensor(0.0975, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5316\n",
      "Loss: tensor(0.0975, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5317\n",
      "Loss: tensor(0.0975, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5318\n",
      "Loss: tensor(0.0975, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5319\n",
      "Loss: tensor(0.0975, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5320\n",
      "Loss: tensor(0.0975, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5321\n",
      "Loss: tensor(0.0975, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5322\n",
      "Loss: tensor(0.0975, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5323\n",
      "Loss: tensor(0.0975, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5324\n",
      "Loss: tensor(0.0975, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5325\n",
      "Loss: tensor(0.0975, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5326\n",
      "Loss: tensor(0.0975, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5327\n",
      "Loss: tensor(0.0975, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5328\n",
      "Loss: tensor(0.0975, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5329\n",
      "Loss: tensor(0.0975, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5330\n",
      "Loss: tensor(0.0975, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5331\n",
      "Loss: tensor(0.0975, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5332\n",
      "Loss: tensor(0.0975, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5333\n",
      "Loss: tensor(0.0975, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5334\n",
      "Loss: tensor(0.0975, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5335\n",
      "Loss: tensor(0.0975, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5336\n",
      "Loss: tensor(0.0975, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5337\n",
      "Loss: tensor(0.0975, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5338\n",
      "Loss: tensor(0.0975, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5339\n",
      "Loss: tensor(0.0975, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5340\n",
      "Loss: tensor(0.0975, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5341\n",
      "Loss: tensor(0.0975, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5342\n",
      "Loss: tensor(0.0975, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5343\n",
      "Loss: tensor(0.0975, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5344\n",
      "Loss: tensor(0.0975, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5345\n",
      "Loss: tensor(0.0975, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5346\n",
      "Loss: tensor(0.0975, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5347\n",
      "Loss: tensor(0.0975, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5348\n",
      "Loss: tensor(0.0975, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5349\n",
      "Loss: tensor(0.0975, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5350\n",
      "Loss: tensor(0.0975, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5351\n",
      "Loss: tensor(0.0975, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5352\n",
      "Loss: tensor(0.0975, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5353\n",
      "Loss: tensor(0.0975, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5354\n",
      "Loss: tensor(0.0975, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5355\n",
      "Loss: tensor(0.0975, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5356\n",
      "Loss: tensor(0.0975, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5357\n",
      "Loss: tensor(0.0975, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5358\n",
      "Loss: tensor(0.0974, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5359\n",
      "Loss: tensor(0.0974, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5360\n",
      "Loss: tensor(0.0974, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5361\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor(0.0974, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5362\n",
      "Loss: tensor(0.0974, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5363\n",
      "Loss: tensor(0.0974, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5364\n",
      "Loss: tensor(0.0974, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5365\n",
      "Loss: tensor(0.0974, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5366\n",
      "Loss: tensor(0.0974, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5367\n",
      "Loss: tensor(0.0974, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5368\n",
      "Loss: tensor(0.0974, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5369\n",
      "Loss: tensor(0.0974, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5370\n",
      "Loss: tensor(0.0974, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5371\n",
      "Loss: tensor(0.0974, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5372\n",
      "Loss: tensor(0.0974, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5373\n",
      "Loss: tensor(0.0974, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5374\n",
      "Loss: tensor(0.0974, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5375\n",
      "Loss: tensor(0.0974, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5376\n",
      "Loss: tensor(0.0974, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5377\n",
      "Loss: tensor(0.0974, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5378\n",
      "Loss: tensor(0.0974, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5379\n",
      "Loss: tensor(0.0974, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5380\n",
      "Loss: tensor(0.0974, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5381\n",
      "Loss: tensor(0.0974, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5382\n",
      "Loss: tensor(0.0974, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5383\n",
      "Loss: tensor(0.0974, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5384\n",
      "Loss: tensor(0.0974, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5385\n",
      "Loss: tensor(0.0974, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5386\n",
      "Loss: tensor(0.0974, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5387\n",
      "Loss: tensor(0.0974, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5388\n",
      "Loss: tensor(0.0974, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5389\n",
      "Loss: tensor(0.0974, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5390\n",
      "Loss: tensor(0.0974, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5391\n",
      "Loss: tensor(0.0974, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5392\n",
      "Loss: tensor(0.0974, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5393\n",
      "Loss: tensor(0.0974, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5394\n",
      "Loss: tensor(0.0974, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5395\n",
      "Loss: tensor(0.0974, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5396\n",
      "Loss: tensor(0.0974, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5397\n",
      "Loss: tensor(0.0974, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5398\n",
      "Loss: tensor(0.0974, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5399\n",
      "Loss: tensor(0.0974, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5400\n",
      "Loss: tensor(0.0974, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5401\n",
      "Loss: tensor(0.0974, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5402\n",
      "Loss: tensor(0.0974, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5403\n",
      "Loss: tensor(0.0974, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5404\n",
      "Loss: tensor(0.0974, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5405\n",
      "Loss: tensor(0.0974, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5406\n",
      "Loss: tensor(0.0974, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5407\n",
      "Loss: tensor(0.0974, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5408\n",
      "Loss: tensor(0.0974, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5409\n",
      "Loss: tensor(0.0974, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5410\n",
      "Loss: tensor(0.0974, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5411\n",
      "Loss: tensor(0.0974, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5412\n",
      "Loss: tensor(0.0974, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5413\n",
      "Loss: tensor(0.0974, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5414\n",
      "Loss: tensor(0.0974, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5415\n",
      "Loss: tensor(0.0974, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5416\n",
      "Loss: tensor(0.0974, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5417\n",
      "Loss: tensor(0.0974, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5418\n",
      "Loss: tensor(0.0974, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5419\n",
      "Loss: tensor(0.0974, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5420\n",
      "Loss: tensor(0.0974, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5421\n",
      "Loss: tensor(0.0974, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5422\n",
      "Loss: tensor(0.0974, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5423\n",
      "Loss: tensor(0.0974, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5424\n",
      "Loss: tensor(0.0974, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5425\n",
      "Loss: tensor(0.0974, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5426\n",
      "Loss: tensor(0.0974, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5427\n",
      "Loss: tensor(0.0974, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5428\n",
      "Loss: tensor(0.0974, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5429\n",
      "Loss: tensor(0.0974, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5430\n",
      "Loss: tensor(0.0974, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5431\n",
      "Loss: tensor(0.0974, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5432\n",
      "Loss: tensor(0.0974, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5433\n",
      "Loss: tensor(0.0974, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5434\n",
      "Loss: tensor(0.0974, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5435\n",
      "Loss: tensor(0.0974, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5436\n",
      "Loss: tensor(0.0974, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5437\n",
      "Loss: tensor(0.0974, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5438\n",
      "Loss: tensor(0.0974, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5439\n",
      "Loss: tensor(0.0974, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5440\n",
      "Loss: tensor(0.0974, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5441\n",
      "Loss: tensor(0.0974, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5442\n",
      "Loss: tensor(0.0974, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5443\n",
      "Loss: tensor(0.0974, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5444\n",
      "Loss: tensor(0.0974, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5445\n",
      "Loss: tensor(0.0974, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5446\n",
      "Loss: tensor(0.0974, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5447\n",
      "Loss: tensor(0.0974, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5448\n",
      "Loss: tensor(0.0974, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5449\n",
      "Loss: tensor(0.0974, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5450\n",
      "Loss: tensor(0.0973, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5451\n",
      "Loss: tensor(0.0973, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5452\n",
      "Loss: tensor(0.0973, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5453\n",
      "Loss: tensor(0.0973, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5454\n",
      "Loss: tensor(0.0973, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5455\n",
      "Loss: tensor(0.0973, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5456\n",
      "Loss: tensor(0.0973, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5457\n",
      "Loss: tensor(0.0973, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5458\n",
      "Loss: tensor(0.0973, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5459\n",
      "Loss: tensor(0.0973, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5460\n",
      "Loss: tensor(0.0973, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5461\n",
      "Loss: tensor(0.0973, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5462\n",
      "Loss: tensor(0.0973, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5463\n",
      "Loss: tensor(0.0973, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5464\n",
      "Loss: tensor(0.0973, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5465\n",
      "Loss: tensor(0.0973, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5466\n",
      "Loss: tensor(0.0973, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5467\n",
      "Loss: tensor(0.0973, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5468\n",
      "Loss: tensor(0.0973, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5469\n",
      "Loss: tensor(0.0973, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5470\n",
      "Loss: tensor(0.0973, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5471\n",
      "Loss: tensor(0.0973, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5472\n",
      "Loss: tensor(0.0973, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5473\n",
      "Loss: tensor(0.0973, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5474\n",
      "Loss: tensor(0.0973, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5475\n",
      "Loss: tensor(0.0973, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5476\n",
      "Loss: tensor(0.0973, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5477\n",
      "Loss: tensor(0.0973, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5478\n",
      "Loss: tensor(0.0973, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5479\n",
      "Loss: tensor(0.0973, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5480\n",
      "Loss: tensor(0.0973, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5481\n",
      "Loss: tensor(0.0973, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5482\n",
      "Loss: tensor(0.0973, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5483\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor(0.0973, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5484\n",
      "Loss: tensor(0.0973, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5485\n",
      "Loss: tensor(0.0973, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5486\n",
      "Loss: tensor(0.0973, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5487\n",
      "Loss: tensor(0.0973, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5488\n",
      "Loss: tensor(0.0973, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5489\n",
      "Loss: tensor(0.0973, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5490\n",
      "Loss: tensor(0.0973, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5491\n",
      "Loss: tensor(0.0973, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5492\n",
      "Loss: tensor(0.0973, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5493\n",
      "Loss: tensor(0.0973, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5494\n",
      "Loss: tensor(0.0973, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5495\n",
      "Loss: tensor(0.0973, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5496\n",
      "Loss: tensor(0.0973, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5497\n",
      "Loss: tensor(0.0973, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5498\n",
      "Loss: tensor(0.0973, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5499\n",
      "Loss: tensor(0.0973, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5500\n",
      "Loss: tensor(0.0973, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5501\n",
      "Loss: tensor(0.0973, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5502\n",
      "Loss: tensor(0.0973, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5503\n",
      "Loss: tensor(0.0973, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5504\n",
      "Loss: tensor(0.0973, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5505\n",
      "Loss: tensor(0.0973, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5506\n",
      "Loss: tensor(0.0973, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5507\n",
      "Loss: tensor(0.0973, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5508\n",
      "Loss: tensor(0.0973, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5509\n",
      "Loss: tensor(0.0973, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5510\n",
      "Loss: tensor(0.0973, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5511\n",
      "Loss: tensor(0.0973, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5512\n",
      "Loss: tensor(0.0973, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5513\n",
      "Loss: tensor(0.0973, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5514\n",
      "Loss: tensor(0.0973, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5515\n",
      "Loss: tensor(0.0973, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5516\n",
      "Loss: tensor(0.0973, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5517\n",
      "Loss: tensor(0.0973, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5518\n",
      "Loss: tensor(0.0973, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5519\n",
      "Loss: tensor(0.0973, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5520\n",
      "Loss: tensor(0.0973, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5521\n",
      "Loss: tensor(0.0973, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5522\n",
      "Loss: tensor(0.0973, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5523\n",
      "Loss: tensor(0.0973, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5524\n",
      "Loss: tensor(0.0973, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5525\n",
      "Loss: tensor(0.0973, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5526\n",
      "Loss: tensor(0.0973, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5527\n",
      "Loss: tensor(0.0973, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5528\n",
      "Loss: tensor(0.0973, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5529\n",
      "Loss: tensor(0.0973, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5530\n",
      "Loss: tensor(0.0973, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5531\n",
      "Loss: tensor(0.0973, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5532\n",
      "Loss: tensor(0.0973, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5533\n",
      "Loss: tensor(0.0973, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5534\n",
      "Loss: tensor(0.0973, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5535\n",
      "Loss: tensor(0.0973, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5536\n",
      "Loss: tensor(0.0973, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5537\n",
      "Loss: tensor(0.0973, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5538\n",
      "Loss: tensor(0.0973, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5539\n",
      "Loss: tensor(0.0973, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5540\n",
      "Loss: tensor(0.0973, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5541\n",
      "Loss: tensor(0.0973, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5542\n",
      "Loss: tensor(0.0973, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5543\n",
      "Loss: tensor(0.0973, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5544\n",
      "Loss: tensor(0.0973, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5545\n",
      "Loss: tensor(0.0973, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5546\n",
      "Loss: tensor(0.0973, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5547\n",
      "Loss: tensor(0.0973, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5548\n",
      "Loss: tensor(0.0973, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5549\n",
      "Loss: tensor(0.0973, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5550\n",
      "Loss: tensor(0.0973, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5551\n",
      "Loss: tensor(0.0973, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5552\n",
      "Loss: tensor(0.0973, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5553\n",
      "Loss: tensor(0.0973, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5554\n",
      "Loss: tensor(0.0972, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5555\n",
      "Loss: tensor(0.0972, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5556\n",
      "Loss: tensor(0.0972, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5557\n",
      "Loss: tensor(0.0972, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5558\n",
      "Loss: tensor(0.0972, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5559\n",
      "Loss: tensor(0.0972, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5560\n",
      "Loss: tensor(0.0972, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5561\n",
      "Loss: tensor(0.0972, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5562\n",
      "Loss: tensor(0.0972, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5563\n",
      "Loss: tensor(0.0972, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5564\n",
      "Loss: tensor(0.0972, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5565\n",
      "Loss: tensor(0.0972, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5566\n",
      "Loss: tensor(0.0972, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5567\n",
      "Loss: tensor(0.0972, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5568\n",
      "Loss: tensor(0.0972, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5569\n",
      "Loss: tensor(0.0972, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5570\n",
      "Loss: tensor(0.0972, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5571\n",
      "Loss: tensor(0.0972, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5572\n",
      "Loss: tensor(0.0972, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5573\n",
      "Loss: tensor(0.0972, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5574\n",
      "Loss: tensor(0.0972, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5575\n",
      "Loss: tensor(0.0972, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5576\n",
      "Loss: tensor(0.0972, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5577\n",
      "Loss: tensor(0.0972, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5578\n",
      "Loss: tensor(0.0972, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5579\n",
      "Loss: tensor(0.0972, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5580\n",
      "Loss: tensor(0.0972, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5581\n",
      "Loss: tensor(0.0972, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5582\n",
      "Loss: tensor(0.0972, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5583\n",
      "Loss: tensor(0.0972, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5584\n",
      "Loss: tensor(0.0972, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5585\n",
      "Loss: tensor(0.0972, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5586\n",
      "Loss: tensor(0.0972, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5587\n",
      "Loss: tensor(0.0972, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5588\n",
      "Loss: tensor(0.0972, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5589\n",
      "Loss: tensor(0.0972, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5590\n",
      "Loss: tensor(0.0972, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5591\n",
      "Loss: tensor(0.0972, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5592\n",
      "Loss: tensor(0.0972, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5593\n",
      "Loss: tensor(0.0972, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5594\n",
      "Loss: tensor(0.0972, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5595\n",
      "Loss: tensor(0.0972, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5596\n",
      "Loss: tensor(0.0972, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5597\n",
      "Loss: tensor(0.0972, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5598\n",
      "Loss: tensor(0.0972, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5599\n",
      "Loss: tensor(0.0972, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5600\n",
      "Loss: tensor(0.0972, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5601\n",
      "Loss: tensor(0.0972, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5602\n",
      "Loss: tensor(0.0972, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5603\n",
      "Loss: tensor(0.0972, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5604\n",
      "Loss: tensor(0.0972, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5605\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor(0.0972, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5606\n",
      "Loss: tensor(0.0972, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5607\n",
      "Loss: tensor(0.0972, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5608\n",
      "Loss: tensor(0.0972, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5609\n",
      "Loss: tensor(0.0972, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5610\n",
      "Loss: tensor(0.0972, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5611\n",
      "Loss: tensor(0.0972, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5612\n",
      "Loss: tensor(0.0972, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5613\n",
      "Loss: tensor(0.0972, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5614\n",
      "Loss: tensor(0.0972, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5615\n",
      "Loss: tensor(0.0972, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5616\n",
      "Loss: tensor(0.0972, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5617\n",
      "Loss: tensor(0.0972, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5618\n",
      "Loss: tensor(0.0972, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5619\n",
      "Loss: tensor(0.0972, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5620\n",
      "Loss: tensor(0.0972, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5621\n",
      "Loss: tensor(0.0972, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5622\n",
      "Loss: tensor(0.0972, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5623\n",
      "Loss: tensor(0.0972, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5624\n",
      "Loss: tensor(0.0972, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5625\n",
      "Loss: tensor(0.0972, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5626\n",
      "Loss: tensor(0.0972, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5627\n",
      "Loss: tensor(0.0972, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5628\n",
      "Loss: tensor(0.0972, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5629\n",
      "Loss: tensor(0.0972, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5630\n",
      "Loss: tensor(0.0972, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5631\n",
      "Loss: tensor(0.0972, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5632\n",
      "Loss: tensor(0.0972, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5633\n",
      "Loss: tensor(0.0972, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5634\n",
      "Loss: tensor(0.0972, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5635\n",
      "Loss: tensor(0.0972, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5636\n",
      "Loss: tensor(0.0972, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5637\n",
      "Loss: tensor(0.0972, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5638\n",
      "Loss: tensor(0.0972, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5639\n",
      "Loss: tensor(0.0972, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5640\n",
      "Loss: tensor(0.0972, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5641\n",
      "Loss: tensor(0.0972, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5642\n",
      "Loss: tensor(0.0972, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5643\n",
      "Loss: tensor(0.0972, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5644\n",
      "Loss: tensor(0.0972, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5645\n",
      "Loss: tensor(0.0972, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5646\n",
      "Loss: tensor(0.0972, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5647\n",
      "Loss: tensor(0.0972, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5648\n",
      "Loss: tensor(0.0972, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5649\n",
      "Loss: tensor(0.0972, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5650\n",
      "Loss: tensor(0.0972, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5651\n",
      "Loss: tensor(0.0972, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5652\n",
      "Loss: tensor(0.0972, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5653\n",
      "Loss: tensor(0.0972, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5654\n",
      "Loss: tensor(0.0971, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5655\n",
      "Loss: tensor(0.0971, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5656\n",
      "Loss: tensor(0.0971, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5657\n",
      "Loss: tensor(0.0971, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5658\n",
      "Loss: tensor(0.0971, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5659\n",
      "Loss: tensor(0.0971, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5660\n",
      "Loss: tensor(0.0971, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5661\n",
      "Loss: tensor(0.0971, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5662\n",
      "Loss: tensor(0.0972, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5663\n",
      "Loss: tensor(0.0972, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5664\n",
      "Loss: tensor(0.0972, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5665\n",
      "Loss: tensor(0.0972, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5666\n",
      "Loss: tensor(0.0972, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5667\n",
      "Loss: tensor(0.0971, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5668\n",
      "Loss: tensor(0.0971, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5669\n",
      "Loss: tensor(0.0971, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5670\n",
      "Loss: tensor(0.0971, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5671\n",
      "Loss: tensor(0.0971, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5672\n",
      "Loss: tensor(0.0971, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5673\n",
      "Loss: tensor(0.0971, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5674\n",
      "Loss: tensor(0.0971, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5675\n",
      "Loss: tensor(0.0971, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5676\n",
      "Loss: tensor(0.0971, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5677\n",
      "Loss: tensor(0.0971, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5678\n",
      "Loss: tensor(0.0971, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5679\n",
      "Loss: tensor(0.0971, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5680\n",
      "Loss: tensor(0.0971, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5681\n",
      "Loss: tensor(0.0971, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5682\n",
      "Loss: tensor(0.0971, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5683\n",
      "Loss: tensor(0.0971, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5684\n",
      "Loss: tensor(0.0971, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5685\n",
      "Loss: tensor(0.0971, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5686\n",
      "Loss: tensor(0.0971, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5687\n",
      "Loss: tensor(0.0971, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5688\n",
      "Loss: tensor(0.0971, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5689\n",
      "Loss: tensor(0.0971, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5690\n",
      "Loss: tensor(0.0971, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5691\n",
      "Loss: tensor(0.0971, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5692\n",
      "Loss: tensor(0.0971, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5693\n",
      "Loss: tensor(0.0971, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5694\n",
      "Loss: tensor(0.0971, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5695\n",
      "Loss: tensor(0.0971, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5696\n",
      "Loss: tensor(0.0971, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5697\n",
      "Loss: tensor(0.0971, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5698\n",
      "Loss: tensor(0.0971, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5699\n",
      "Loss: tensor(0.0971, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5700\n",
      "Loss: tensor(0.0971, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5701\n",
      "Loss: tensor(0.0971, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5702\n",
      "Loss: tensor(0.0971, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5703\n",
      "Loss: tensor(0.0971, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5704\n",
      "Loss: tensor(0.0971, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5705\n",
      "Loss: tensor(0.0971, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5706\n",
      "Loss: tensor(0.0971, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5707\n",
      "Loss: tensor(0.0971, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5708\n",
      "Loss: tensor(0.0971, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5709\n",
      "Loss: tensor(0.0971, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5710\n",
      "Loss: tensor(0.0971, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5711\n",
      "Loss: tensor(0.0971, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5712\n",
      "Loss: tensor(0.0971, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5713\n",
      "Loss: tensor(0.0971, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5714\n",
      "Loss: tensor(0.0971, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5715\n",
      "Loss: tensor(0.0971, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5716\n",
      "Loss: tensor(0.0971, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5717\n",
      "Loss: tensor(0.0971, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5718\n",
      "Loss: tensor(0.0971, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5719\n",
      "Loss: tensor(0.0971, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5720\n",
      "Loss: tensor(0.0971, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5721\n",
      "Loss: tensor(0.0971, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5722\n",
      "Loss: tensor(0.0971, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5723\n",
      "Loss: tensor(0.0971, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5724\n",
      "Loss: tensor(0.0971, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5725\n",
      "Loss: tensor(0.0971, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5726\n",
      "Loss: tensor(0.0971, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5727\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor(0.0971, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5728\n",
      "Loss: tensor(0.0971, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5729\n",
      "Loss: tensor(0.0971, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5730\n",
      "Loss: tensor(0.0971, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5731\n",
      "Loss: tensor(0.0971, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5732\n",
      "Loss: tensor(0.0971, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5733\n",
      "Loss: tensor(0.0971, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5734\n",
      "Loss: tensor(0.0971, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5735\n",
      "Loss: tensor(0.0971, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5736\n",
      "Loss: tensor(0.0971, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5737\n",
      "Loss: tensor(0.0971, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5738\n",
      "Loss: tensor(0.0971, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5739\n",
      "Loss: tensor(0.0971, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5740\n",
      "Loss: tensor(0.0971, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5741\n",
      "Loss: tensor(0.0971, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5742\n",
      "Loss: tensor(0.0971, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5743\n",
      "Loss: tensor(0.0971, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5744\n",
      "Loss: tensor(0.0971, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5745\n",
      "Loss: tensor(0.0971, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5746\n",
      "Loss: tensor(0.0971, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5747\n",
      "Loss: tensor(0.0971, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5748\n",
      "Loss: tensor(0.0971, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5749\n",
      "Loss: tensor(0.0971, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5750\n",
      "Loss: tensor(0.0971, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5751\n",
      "Loss: tensor(0.0971, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5752\n",
      "Loss: tensor(0.0971, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5753\n",
      "Loss: tensor(0.0971, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5754\n",
      "Loss: tensor(0.0971, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5755\n",
      "Loss: tensor(0.0971, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5756\n",
      "Loss: tensor(0.0971, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5757\n",
      "Loss: tensor(0.0971, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5758\n",
      "Loss: tensor(0.0971, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5759\n",
      "Loss: tensor(0.0971, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5760\n",
      "Loss: tensor(0.0971, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5761\n",
      "Loss: tensor(0.0971, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5762\n",
      "Loss: tensor(0.0971, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5763\n",
      "Loss: tensor(0.0971, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5764\n",
      "Loss: tensor(0.0971, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5765\n",
      "Loss: tensor(0.0971, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5766\n",
      "Loss: tensor(0.0970, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5767\n",
      "Loss: tensor(0.0970, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5768\n",
      "Loss: tensor(0.0970, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5769\n",
      "Loss: tensor(0.0970, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5770\n",
      "Loss: tensor(0.0970, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5771\n",
      "Loss: tensor(0.0970, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5772\n",
      "Loss: tensor(0.0970, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5773\n",
      "Loss: tensor(0.0970, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5774\n",
      "Loss: tensor(0.0970, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5775\n",
      "Loss: tensor(0.0970, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5776\n",
      "Loss: tensor(0.0970, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5777\n",
      "Loss: tensor(0.0970, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5778\n",
      "Loss: tensor(0.0970, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5779\n",
      "Loss: tensor(0.0970, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5780\n",
      "Loss: tensor(0.0970, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5781\n",
      "Loss: tensor(0.0970, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5782\n",
      "Loss: tensor(0.0970, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5783\n",
      "Loss: tensor(0.0970, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5784\n",
      "Loss: tensor(0.0970, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5785\n",
      "Loss: tensor(0.0970, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5786\n",
      "Loss: tensor(0.0970, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5787\n",
      "Loss: tensor(0.0970, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5788\n",
      "Loss: tensor(0.0970, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5789\n",
      "Loss: tensor(0.0970, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5790\n",
      "Loss: tensor(0.0970, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5791\n",
      "Loss: tensor(0.0970, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5792\n",
      "Loss: tensor(0.0970, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5793\n",
      "Loss: tensor(0.0970, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5794\n",
      "Loss: tensor(0.0970, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5795\n",
      "Loss: tensor(0.0970, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5796\n",
      "Loss: tensor(0.0970, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5797\n",
      "Loss: tensor(0.0970, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5798\n",
      "Loss: tensor(0.0970, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5799\n",
      "Loss: tensor(0.0970, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5800\n",
      "Loss: tensor(0.0970, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5801\n",
      "Loss: tensor(0.0970, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5802\n",
      "Loss: tensor(0.0970, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5803\n",
      "Loss: tensor(0.0970, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5804\n",
      "Loss: tensor(0.0970, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5805\n",
      "Loss: tensor(0.0970, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5806\n",
      "Loss: tensor(0.0970, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5807\n",
      "Loss: tensor(0.0970, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5808\n",
      "Loss: tensor(0.0970, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5809\n",
      "Loss: tensor(0.0970, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5810\n",
      "Loss: tensor(0.0970, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5811\n",
      "Loss: tensor(0.0970, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5812\n",
      "Loss: tensor(0.0970, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5813\n",
      "Loss: tensor(0.0970, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5814\n",
      "Loss: tensor(0.0970, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5815\n",
      "Loss: tensor(0.0970, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5816\n",
      "Loss: tensor(0.0970, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5817\n",
      "Loss: tensor(0.0970, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5818\n",
      "Loss: tensor(0.0970, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5819\n",
      "Loss: tensor(0.0970, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5820\n",
      "Loss: tensor(0.0970, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5821\n",
      "Loss: tensor(0.0970, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5822\n",
      "Loss: tensor(0.0970, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5823\n",
      "Loss: tensor(0.0970, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5824\n",
      "Loss: tensor(0.0970, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5825\n",
      "Loss: tensor(0.0970, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5826\n",
      "Loss: tensor(0.0970, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5827\n",
      "Loss: tensor(0.0970, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5828\n",
      "Loss: tensor(0.0970, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5829\n",
      "Loss: tensor(0.0970, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5830\n",
      "Loss: tensor(0.0970, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5831\n",
      "Loss: tensor(0.0970, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5832\n",
      "Loss: tensor(0.0970, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5833\n",
      "Loss: tensor(0.0970, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5834\n",
      "Loss: tensor(0.0970, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5835\n",
      "Loss: tensor(0.0970, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5836\n",
      "Loss: tensor(0.0970, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5837\n",
      "Loss: tensor(0.0970, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5838\n",
      "Loss: tensor(0.0970, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5839\n",
      "Loss: tensor(0.0970, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5840\n",
      "Loss: tensor(0.0970, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5841\n",
      "Loss: tensor(0.0970, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5842\n",
      "Loss: tensor(0.0970, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5843\n",
      "Loss: tensor(0.0970, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5844\n",
      "Loss: tensor(0.0970, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5845\n",
      "Loss: tensor(0.0970, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5846\n",
      "Loss: tensor(0.0970, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5847\n",
      "Loss: tensor(0.0970, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5848\n",
      "Loss: tensor(0.0970, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5849\n",
      "Loss: tensor(0.0970, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5850\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor(0.0970, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5851\n",
      "Loss: tensor(0.0970, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5852\n",
      "Loss: tensor(0.0970, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5853\n",
      "Loss: tensor(0.0970, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5854\n",
      "Loss: tensor(0.0970, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5855\n",
      "Loss: tensor(0.0970, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5856\n",
      "Loss: tensor(0.0970, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5857\n",
      "Loss: tensor(0.0970, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5858\n",
      "Loss: tensor(0.0970, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5859\n",
      "Loss: tensor(0.0970, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5860\n",
      "Loss: tensor(0.0970, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5861\n",
      "Loss: tensor(0.0970, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5862\n",
      "Loss: tensor(0.0970, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5863\n",
      "Loss: tensor(0.0970, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5864\n",
      "Loss: tensor(0.0970, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5865\n",
      "Loss: tensor(0.0970, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5866\n",
      "Loss: tensor(0.0970, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5867\n",
      "Loss: tensor(0.0970, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5868\n",
      "Loss: tensor(0.0970, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5869\n",
      "Loss: tensor(0.0970, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5870\n",
      "Loss: tensor(0.0970, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5871\n",
      "Loss: tensor(0.0970, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5872\n",
      "Loss: tensor(0.0970, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5873\n",
      "Loss: tensor(0.0970, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5874\n",
      "Loss: tensor(0.0970, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5875\n",
      "Loss: tensor(0.0970, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5876\n",
      "Loss: tensor(0.0970, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5877\n",
      "Loss: tensor(0.0970, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5878\n",
      "Loss: tensor(0.0970, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5879\n",
      "Loss: tensor(0.0970, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5880\n",
      "Loss: tensor(0.0970, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5881\n",
      "Loss: tensor(0.0970, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5882\n",
      "Loss: tensor(0.0970, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5883\n",
      "Loss: tensor(0.0970, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5884\n",
      "Loss: tensor(0.0970, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5885\n",
      "Loss: tensor(0.0970, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5886\n",
      "Loss: tensor(0.0970, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5887\n",
      "Loss: tensor(0.0970, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5888\n",
      "Loss: tensor(0.0970, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5889\n",
      "Loss: tensor(0.0969, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5890\n",
      "Loss: tensor(0.0969, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5891\n",
      "Loss: tensor(0.0969, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5892\n",
      "Loss: tensor(0.0969, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5893\n",
      "Loss: tensor(0.0969, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5894\n",
      "Loss: tensor(0.0969, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5895\n",
      "Loss: tensor(0.0969, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5896\n",
      "Loss: tensor(0.0969, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5897\n",
      "Loss: tensor(0.0969, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5898\n",
      "Loss: tensor(0.0969, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5899\n",
      "Loss: tensor(0.0969, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5900\n",
      "Loss: tensor(0.0969, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5901\n",
      "Loss: tensor(0.0969, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5902\n",
      "Loss: tensor(0.0969, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5903\n",
      "Loss: tensor(0.0969, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5904\n",
      "Loss: tensor(0.0969, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5905\n",
      "Loss: tensor(0.0969, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5906\n",
      "Loss: tensor(0.0969, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5907\n",
      "Loss: tensor(0.0969, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5908\n",
      "Loss: tensor(0.0969, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5909\n",
      "Loss: tensor(0.0969, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5910\n",
      "Loss: tensor(0.0969, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5911\n",
      "Loss: tensor(0.0969, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5912\n",
      "Loss: tensor(0.0969, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5913\n",
      "Loss: tensor(0.0969, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5914\n",
      "Loss: tensor(0.0969, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5915\n",
      "Loss: tensor(0.0969, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5916\n",
      "Loss: tensor(0.0969, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5917\n",
      "Loss: tensor(0.0969, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5918\n",
      "Loss: tensor(0.0969, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5919\n",
      "Loss: tensor(0.0969, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5920\n",
      "Loss: tensor(0.0969, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5921\n",
      "Loss: tensor(0.0969, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5922\n",
      "Loss: tensor(0.0969, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5923\n",
      "Loss: tensor(0.0969, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5924\n",
      "Loss: tensor(0.0969, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5925\n",
      "Loss: tensor(0.0969, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5926\n",
      "Loss: tensor(0.0969, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5927\n",
      "Loss: tensor(0.0969, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5928\n",
      "Loss: tensor(0.0969, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5929\n",
      "Loss: tensor(0.0969, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5930\n",
      "Loss: tensor(0.0969, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5931\n",
      "Loss: tensor(0.0969, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5932\n",
      "Loss: tensor(0.0969, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5933\n",
      "Loss: tensor(0.0969, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5934\n",
      "Loss: tensor(0.0969, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5935\n",
      "Loss: tensor(0.0969, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5936\n",
      "Loss: tensor(0.0969, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5937\n",
      "Loss: tensor(0.0969, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5938\n",
      "Loss: tensor(0.0969, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5939\n",
      "Loss: tensor(0.0969, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5940\n",
      "Loss: tensor(0.0969, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5941\n",
      "Loss: tensor(0.0969, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5942\n",
      "Loss: tensor(0.0969, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5943\n",
      "Loss: tensor(0.0969, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5944\n",
      "Loss: tensor(0.0969, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5945\n",
      "Loss: tensor(0.0969, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5946\n",
      "Loss: tensor(0.0969, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5947\n",
      "Loss: tensor(0.0969, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5948\n",
      "Loss: tensor(0.0969, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5949\n",
      "Loss: tensor(0.0969, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5950\n",
      "Loss: tensor(0.0969, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5951\n",
      "Loss: tensor(0.0969, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5952\n",
      "Loss: tensor(0.0969, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5953\n",
      "Loss: tensor(0.0969, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5954\n",
      "Loss: tensor(0.0969, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5955\n",
      "Loss: tensor(0.0969, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5956\n",
      "Loss: tensor(0.0969, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5957\n",
      "Loss: tensor(0.0969, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5958\n",
      "Loss: tensor(0.0969, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5959\n",
      "Loss: tensor(0.0969, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5960\n",
      "Loss: tensor(0.0969, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5961\n",
      "Loss: tensor(0.0969, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5962\n",
      "Loss: tensor(0.0969, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5963\n",
      "Loss: tensor(0.0969, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5964\n",
      "Loss: tensor(0.0969, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5965\n",
      "Loss: tensor(0.0969, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5966\n",
      "Loss: tensor(0.0969, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5967\n",
      "Loss: tensor(0.0969, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5968\n",
      "Loss: tensor(0.0969, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5969\n",
      "Loss: tensor(0.0969, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5970\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor(0.0969, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5971\n",
      "Loss: tensor(0.0969, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5972\n",
      "Loss: tensor(0.0969, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5973\n",
      "Loss: tensor(0.0969, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5974\n",
      "Loss: tensor(0.0969, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5975\n",
      "Loss: tensor(0.0969, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5976\n",
      "Loss: tensor(0.0969, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5977\n",
      "Loss: tensor(0.0969, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5978\n",
      "Loss: tensor(0.0969, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5979\n",
      "Loss: tensor(0.0969, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5980\n",
      "Loss: tensor(0.0969, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5981\n",
      "Loss: tensor(0.0969, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5982\n",
      "Loss: tensor(0.0969, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5983\n",
      "Loss: tensor(0.0969, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5984\n",
      "Loss: tensor(0.0969, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5985\n",
      "Loss: tensor(0.0969, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5986\n",
      "Loss: tensor(0.0969, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5987\n",
      "Loss: tensor(0.0969, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5988\n",
      "Loss: tensor(0.0969, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5989\n",
      "Loss: tensor(0.0969, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5990\n",
      "Loss: tensor(0.0969, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5991\n",
      "Loss: tensor(0.0969, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5992\n",
      "Loss: tensor(0.0969, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5993\n",
      "Loss: tensor(0.0969, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5994\n",
      "Loss: tensor(0.0969, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5995\n",
      "Loss: tensor(0.0969, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5996\n",
      "Loss: tensor(0.0969, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5997\n",
      "Loss: tensor(0.0969, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5998\n",
      "Loss: tensor(0.0969, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5999\n",
      "Loss: tensor(0.0969, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6000\n",
      "Loss: tensor(0.0969, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6001\n",
      "Loss: tensor(0.0969, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6002\n",
      "Loss: tensor(0.0969, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6003\n",
      "Loss: tensor(0.0969, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6004\n",
      "Loss: tensor(0.0969, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6005\n",
      "Loss: tensor(0.0969, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6006\n",
      "Loss: tensor(0.0969, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6007\n",
      "Loss: tensor(0.0969, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6008\n",
      "Loss: tensor(0.0969, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6009\n",
      "Loss: tensor(0.0969, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6010\n",
      "Loss: tensor(0.0969, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6011\n",
      "Loss: tensor(0.0969, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6012\n",
      "Loss: tensor(0.0968, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6013\n",
      "Loss: tensor(0.0968, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6014\n",
      "Loss: tensor(0.0968, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6015\n",
      "Loss: tensor(0.0968, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6016\n",
      "Loss: tensor(0.0968, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6017\n",
      "Loss: tensor(0.0968, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6018\n",
      "Loss: tensor(0.0968, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6019\n",
      "Loss: tensor(0.0968, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6020\n",
      "Loss: tensor(0.0968, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6021\n",
      "Loss: tensor(0.0968, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6022\n",
      "Loss: tensor(0.0968, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6023\n",
      "Loss: tensor(0.0968, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6024\n",
      "Loss: tensor(0.0968, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6025\n",
      "Loss: tensor(0.0968, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6026\n",
      "Loss: tensor(0.0968, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6027\n",
      "Loss: tensor(0.0968, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6028\n",
      "Loss: tensor(0.0968, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6029\n",
      "Loss: tensor(0.0968, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6030\n",
      "Loss: tensor(0.0968, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6031\n",
      "Loss: tensor(0.0968, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6032\n",
      "Loss: tensor(0.0968, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6033\n",
      "Loss: tensor(0.0968, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6034\n",
      "Loss: tensor(0.0968, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6035\n",
      "Loss: tensor(0.0968, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6036\n",
      "Loss: tensor(0.0968, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6037\n",
      "Loss: tensor(0.0968, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6038\n",
      "Loss: tensor(0.0968, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6039\n",
      "Loss: tensor(0.0968, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6040\n",
      "Loss: tensor(0.0968, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6041\n",
      "Loss: tensor(0.0968, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6042\n",
      "Loss: tensor(0.0968, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6043\n",
      "Loss: tensor(0.0968, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6044\n",
      "Loss: tensor(0.0968, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6045\n",
      "Loss: tensor(0.0968, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6046\n",
      "Loss: tensor(0.0968, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6047\n",
      "Loss: tensor(0.0968, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6048\n",
      "Loss: tensor(0.0968, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6049\n",
      "Loss: tensor(0.0968, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6050\n",
      "Loss: tensor(0.0968, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6051\n",
      "Loss: tensor(0.0968, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6052\n",
      "Loss: tensor(0.0968, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6053\n",
      "Loss: tensor(0.0968, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6054\n",
      "Loss: tensor(0.0968, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6055\n",
      "Loss: tensor(0.0968, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6056\n",
      "Loss: tensor(0.0968, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6057\n",
      "Loss: tensor(0.0968, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6058\n",
      "Loss: tensor(0.0968, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6059\n",
      "Loss: tensor(0.0968, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6060\n",
      "Loss: tensor(0.0968, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6061\n",
      "Loss: tensor(0.0968, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6062\n",
      "Loss: tensor(0.0968, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6063\n",
      "Loss: tensor(0.0968, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6064\n",
      "Loss: tensor(0.0968, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6065\n",
      "Loss: tensor(0.0968, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6066\n",
      "Loss: tensor(0.0968, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6067\n",
      "Loss: tensor(0.0968, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6068\n",
      "Loss: tensor(0.0968, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6069\n",
      "Loss: tensor(0.0968, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6070\n",
      "Loss: tensor(0.0968, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6071\n",
      "Loss: tensor(0.0968, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6072\n",
      "Loss: tensor(0.0968, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6073\n",
      "Loss: tensor(0.0968, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6074\n",
      "Loss: tensor(0.0968, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6075\n",
      "Loss: tensor(0.0968, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6076\n",
      "Loss: tensor(0.0968, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6077\n",
      "Loss: tensor(0.0968, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6078\n",
      "Loss: tensor(0.0968, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6079\n",
      "Loss: tensor(0.0968, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6080\n",
      "Loss: tensor(0.0968, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6081\n",
      "Loss: tensor(0.0968, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6082\n",
      "Loss: tensor(0.0968, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6083\n",
      "Loss: tensor(0.0968, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6084\n",
      "Loss: tensor(0.0968, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6085\n",
      "Loss: tensor(0.0968, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6086\n",
      "Loss: tensor(0.0968, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6087\n",
      "Loss: tensor(0.0968, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6088\n",
      "Loss: tensor(0.0968, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6089\n",
      "Loss: tensor(0.0968, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6090\n",
      "Loss: tensor(0.0968, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6091\n",
      "Loss: tensor(0.0968, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6092\n",
      "Loss: tensor(0.0968, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6093\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor(0.0968, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6094\n",
      "Loss: tensor(0.0968, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6095\n",
      "Loss: tensor(0.0968, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6096\n",
      "Loss: tensor(0.0968, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6097\n",
      "Loss: tensor(0.0968, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6098\n",
      "Loss: tensor(0.0968, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6099\n",
      "Loss: tensor(0.0968, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6100\n",
      "Loss: tensor(0.0968, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6101\n",
      "Loss: tensor(0.0968, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6102\n",
      "Loss: tensor(0.0968, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6103\n",
      "Loss: tensor(0.0968, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6104\n",
      "Loss: tensor(0.0968, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6105\n",
      "Loss: tensor(0.0968, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6106\n",
      "Loss: tensor(0.0968, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6107\n",
      "Loss: tensor(0.0968, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6108\n",
      "Loss: tensor(0.0968, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6109\n",
      "Loss: tensor(0.0968, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6110\n",
      "Loss: tensor(0.0968, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6111\n",
      "Loss: tensor(0.0968, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6112\n",
      "Loss: tensor(0.0968, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6113\n",
      "Loss: tensor(0.0968, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6114\n",
      "Loss: tensor(0.0968, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6115\n",
      "Loss: tensor(0.0968, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6116\n",
      "Loss: tensor(0.0968, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6117\n",
      "Loss: tensor(0.0968, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6118\n",
      "Loss: tensor(0.0968, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6119\n",
      "Loss: tensor(0.0968, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6120\n",
      "Loss: tensor(0.0968, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6121\n",
      "Loss: tensor(0.0968, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6122\n",
      "Loss: tensor(0.0968, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6123\n",
      "Loss: tensor(0.0968, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6124\n",
      "Loss: tensor(0.0968, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6125\n",
      "Loss: tensor(0.0968, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6126\n",
      "Loss: tensor(0.0968, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6127\n",
      "Loss: tensor(0.0968, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6128\n",
      "Loss: tensor(0.0968, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6129\n",
      "Loss: tensor(0.0968, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6130\n",
      "Loss: tensor(0.0968, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6131\n",
      "Loss: tensor(0.0968, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6132\n",
      "Loss: tensor(0.0968, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6133\n",
      "Loss: tensor(0.0968, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6134\n",
      "Loss: tensor(0.0968, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6135\n",
      "Loss: tensor(0.0968, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6136\n",
      "Loss: tensor(0.0968, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6137\n",
      "Loss: tensor(0.0968, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6138\n",
      "Loss: tensor(0.0968, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6139\n",
      "Loss: tensor(0.0968, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6140\n",
      "Loss: tensor(0.0968, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6141\n",
      "Loss: tensor(0.0968, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6142\n",
      "Loss: tensor(0.0968, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6143\n",
      "Loss: tensor(0.0968, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6144\n",
      "Loss: tensor(0.0968, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6145\n",
      "Loss: tensor(0.0967, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6146\n",
      "Loss: tensor(0.0967, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6147\n",
      "Loss: tensor(0.0967, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6148\n",
      "Loss: tensor(0.0967, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6149\n",
      "Loss: tensor(0.0967, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6150\n",
      "Loss: tensor(0.0967, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6151\n",
      "Loss: tensor(0.0967, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6152\n",
      "Loss: tensor(0.0967, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6153\n",
      "Loss: tensor(0.0967, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6154\n",
      "Loss: tensor(0.0967, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6155\n",
      "Loss: tensor(0.0967, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6156\n",
      "Loss: tensor(0.0967, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6157\n",
      "Loss: tensor(0.0967, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6158\n",
      "Loss: tensor(0.0967, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6159\n",
      "Loss: tensor(0.0967, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6160\n",
      "Loss: tensor(0.0967, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6161\n",
      "Loss: tensor(0.0967, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6162\n",
      "Loss: tensor(0.0967, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6163\n",
      "Loss: tensor(0.0967, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6164\n",
      "Loss: tensor(0.0967, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6165\n",
      "Loss: tensor(0.0967, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6166\n",
      "Loss: tensor(0.0967, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6167\n",
      "Loss: tensor(0.0967, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6168\n",
      "Loss: tensor(0.0967, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6169\n",
      "Loss: tensor(0.0967, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6170\n",
      "Loss: tensor(0.0967, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6171\n",
      "Loss: tensor(0.0967, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6172\n",
      "Loss: tensor(0.0967, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6173\n",
      "Loss: tensor(0.0967, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6174\n",
      "Loss: tensor(0.0967, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6175\n",
      "Loss: tensor(0.0967, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6176\n",
      "Loss: tensor(0.0967, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6177\n",
      "Loss: tensor(0.0967, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6178\n",
      "Loss: tensor(0.0967, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6179\n",
      "Loss: tensor(0.0967, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6180\n",
      "Loss: tensor(0.0967, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6181\n",
      "Loss: tensor(0.0967, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6182\n",
      "Loss: tensor(0.0967, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6183\n",
      "Loss: tensor(0.0967, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6184\n",
      "Loss: tensor(0.0967, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6185\n",
      "Loss: tensor(0.0967, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6186\n",
      "Loss: tensor(0.0967, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6187\n",
      "Loss: tensor(0.0967, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6188\n",
      "Loss: tensor(0.0967, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6189\n",
      "Loss: tensor(0.0967, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6190\n",
      "Loss: tensor(0.0967, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6191\n",
      "Loss: tensor(0.0967, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6192\n",
      "Loss: tensor(0.0967, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6193\n",
      "Loss: tensor(0.0967, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6194\n",
      "Loss: tensor(0.0967, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6195\n",
      "Loss: tensor(0.0967, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6196\n",
      "Loss: tensor(0.0967, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6197\n",
      "Loss: tensor(0.0967, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6198\n",
      "Loss: tensor(0.0967, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6199\n",
      "Loss: tensor(0.0967, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6200\n",
      "Loss: tensor(0.0967, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6201\n",
      "Loss: tensor(0.0967, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6202\n",
      "Loss: tensor(0.0967, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6203\n",
      "Loss: tensor(0.0967, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6204\n",
      "Loss: tensor(0.0967, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6205\n",
      "Loss: tensor(0.0967, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6206\n",
      "Loss: tensor(0.0967, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6207\n",
      "Loss: tensor(0.0967, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6208\n",
      "Loss: tensor(0.0967, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6209\n",
      "Loss: tensor(0.0967, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6210\n",
      "Loss: tensor(0.0967, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6211\n",
      "Loss: tensor(0.0967, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6212\n",
      "Loss: tensor(0.0967, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6213\n",
      "Loss: tensor(0.0967, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6214\n",
      "Loss: tensor(0.0967, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6215\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor(0.0967, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6216\n",
      "Loss: tensor(0.0967, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6217\n",
      "Loss: tensor(0.0967, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6218\n",
      "Loss: tensor(0.0967, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6219\n",
      "Loss: tensor(0.0967, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6220\n",
      "Loss: tensor(0.0967, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6221\n",
      "Loss: tensor(0.0967, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6222\n",
      "Loss: tensor(0.0967, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6223\n",
      "Loss: tensor(0.0967, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6224\n",
      "Loss: tensor(0.0967, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6225\n",
      "Loss: tensor(0.0967, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6226\n",
      "Loss: tensor(0.0967, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6227\n",
      "Loss: tensor(0.0967, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6228\n",
      "Loss: tensor(0.0967, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6229\n",
      "Loss: tensor(0.0967, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6230\n",
      "Loss: tensor(0.0967, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6231\n",
      "Loss: tensor(0.0967, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6232\n",
      "Loss: tensor(0.0967, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6233\n",
      "Loss: tensor(0.0967, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6234\n",
      "Loss: tensor(0.0967, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6235\n",
      "Loss: tensor(0.0967, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6236\n",
      "Loss: tensor(0.0967, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6237\n",
      "Loss: tensor(0.0967, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6238\n",
      "Loss: tensor(0.0967, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6239\n",
      "Loss: tensor(0.0967, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6240\n",
      "Loss: tensor(0.0967, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6241\n",
      "Loss: tensor(0.0967, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6242\n",
      "Loss: tensor(0.0967, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6243\n",
      "Loss: tensor(0.0967, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6244\n",
      "Loss: tensor(0.0967, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6245\n",
      "Loss: tensor(0.0967, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6246\n",
      "Loss: tensor(0.0967, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6247\n",
      "Loss: tensor(0.0967, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6248\n",
      "Loss: tensor(0.0967, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6249\n",
      "Loss: tensor(0.0967, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6250\n",
      "Loss: tensor(0.0967, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6251\n",
      "Loss: tensor(0.0967, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6252\n",
      "Loss: tensor(0.0967, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6253\n",
      "Loss: tensor(0.0967, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6254\n",
      "Loss: tensor(0.0967, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6255\n",
      "Loss: tensor(0.0967, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6256\n",
      "Loss: tensor(0.0967, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6257\n",
      "Loss: tensor(0.0967, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6258\n",
      "Loss: tensor(0.0967, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6259\n",
      "Loss: tensor(0.0967, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6260\n",
      "Loss: tensor(0.0967, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6261\n",
      "Loss: tensor(0.0967, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6262\n",
      "Loss: tensor(0.0967, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6263\n",
      "Loss: tensor(0.0967, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6264\n",
      "Loss: tensor(0.0967, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6265\n",
      "Loss: tensor(0.0967, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6266\n",
      "Loss: tensor(0.0967, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6267\n",
      "Loss: tensor(0.0967, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6268\n",
      "Loss: tensor(0.0967, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6269\n",
      "Loss: tensor(0.0967, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6270\n",
      "Loss: tensor(0.0967, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6271\n",
      "Loss: tensor(0.0967, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6272\n",
      "Loss: tensor(0.0967, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6273\n",
      "Loss: tensor(0.0967, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6274\n",
      "Loss: tensor(0.0967, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6275\n",
      "Loss: tensor(0.0967, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6276\n",
      "Loss: tensor(0.0967, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6277\n",
      "Loss: tensor(0.0967, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6278\n",
      "Loss: tensor(0.0967, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6279\n",
      "Loss: tensor(0.0967, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6280\n",
      "Loss: tensor(0.0967, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6281\n",
      "Loss: tensor(0.0967, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6282\n",
      "Loss: tensor(0.0967, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6283\n",
      "Loss: tensor(0.0967, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6284\n",
      "Loss: tensor(0.0967, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6285\n",
      "Loss: tensor(0.0967, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6286\n",
      "Loss: tensor(0.0967, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6287\n",
      "Loss: tensor(0.0967, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6288\n",
      "Loss: tensor(0.0967, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6289\n",
      "Loss: tensor(0.0967, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6290\n",
      "Loss: tensor(0.0966, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6291\n",
      "Loss: tensor(0.0966, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6292\n",
      "Loss: tensor(0.0966, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6293\n",
      "Loss: tensor(0.0966, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6294\n",
      "Loss: tensor(0.0966, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6295\n",
      "Loss: tensor(0.0966, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6296\n",
      "Loss: tensor(0.0966, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6297\n",
      "Loss: tensor(0.0966, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6298\n",
      "Loss: tensor(0.0966, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6299\n",
      "Loss: tensor(0.0966, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6300\n",
      "Loss: tensor(0.0966, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6301\n",
      "Loss: tensor(0.0966, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6302\n",
      "Loss: tensor(0.0966, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6303\n",
      "Loss: tensor(0.0966, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6304\n",
      "Loss: tensor(0.0966, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6305\n",
      "Loss: tensor(0.0966, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6306\n",
      "Loss: tensor(0.0966, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6307\n",
      "Loss: tensor(0.0966, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6308\n",
      "Loss: tensor(0.0966, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6309\n",
      "Loss: tensor(0.0966, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6310\n",
      "Loss: tensor(0.0966, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6311\n",
      "Loss: tensor(0.0966, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6312\n",
      "Loss: tensor(0.0966, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6313\n",
      "Loss: tensor(0.0966, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6314\n",
      "Loss: tensor(0.0966, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6315\n",
      "Loss: tensor(0.0966, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6316\n",
      "Loss: tensor(0.0966, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6317\n",
      "Loss: tensor(0.0966, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6318\n",
      "Loss: tensor(0.0966, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6319\n",
      "Loss: tensor(0.0966, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6320\n",
      "Loss: tensor(0.0966, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6321\n",
      "Loss: tensor(0.0966, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6322\n",
      "Loss: tensor(0.0966, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6323\n",
      "Loss: tensor(0.0966, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6324\n",
      "Loss: tensor(0.0966, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6325\n",
      "Loss: tensor(0.0966, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6326\n",
      "Loss: tensor(0.0966, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6327\n",
      "Loss: tensor(0.0966, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6328\n",
      "Loss: tensor(0.0966, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6329\n",
      "Loss: tensor(0.0966, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6330\n",
      "Loss: tensor(0.0966, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6331\n",
      "Loss: tensor(0.0966, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6332\n",
      "Loss: tensor(0.0966, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6333\n",
      "Loss: tensor(0.0966, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6334\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor(0.0966, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6335\n",
      "Loss: tensor(0.0966, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6336\n",
      "Loss: tensor(0.0966, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6337\n",
      "Loss: tensor(0.0966, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6338\n",
      "Loss: tensor(0.0966, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6339\n",
      "Loss: tensor(0.0966, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6340\n",
      "Loss: tensor(0.0966, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6341\n",
      "Loss: tensor(0.0966, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6342\n",
      "Loss: tensor(0.0966, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6343\n",
      "Loss: tensor(0.0966, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6344\n",
      "Loss: tensor(0.0966, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6345\n",
      "Loss: tensor(0.0966, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6346\n",
      "Loss: tensor(0.0966, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6347\n",
      "Loss: tensor(0.0966, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6348\n",
      "Loss: tensor(0.0966, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6349\n",
      "Loss: tensor(0.0966, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6350\n",
      "Loss: tensor(0.0966, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6351\n",
      "Loss: tensor(0.0966, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6352\n",
      "Loss: tensor(0.0966, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6353\n",
      "Loss: tensor(0.0966, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6354\n",
      "Loss: tensor(0.0966, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6355\n",
      "Loss: tensor(0.0966, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6356\n",
      "Loss: tensor(0.0966, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6357\n",
      "Loss: tensor(0.0966, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6358\n",
      "Loss: tensor(0.0966, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6359\n",
      "Loss: tensor(0.0966, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6360\n",
      "Loss: tensor(0.0966, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6361\n",
      "Loss: tensor(0.0966, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6362\n",
      "Loss: tensor(0.0966, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6363\n",
      "Loss: tensor(0.0966, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6364\n",
      "Loss: tensor(0.0966, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6365\n",
      "Loss: tensor(0.0966, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6366\n",
      "Loss: tensor(0.0966, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6367\n",
      "Loss: tensor(0.0966, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6368\n",
      "Loss: tensor(0.0966, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6369\n",
      "Loss: tensor(0.0966, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6370\n",
      "Loss: tensor(0.0966, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6371\n",
      "Loss: tensor(0.0966, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6372\n",
      "Loss: tensor(0.0966, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6373\n",
      "Loss: tensor(0.0966, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6374\n",
      "Loss: tensor(0.0966, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6375\n",
      "Loss: tensor(0.0966, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6376\n",
      "Loss: tensor(0.0966, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6377\n",
      "Loss: tensor(0.0966, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6378\n",
      "Loss: tensor(0.0966, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6379\n",
      "Loss: tensor(0.0966, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6380\n",
      "Loss: tensor(0.0966, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6381\n",
      "Loss: tensor(0.0966, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6382\n",
      "Loss: tensor(0.0966, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6383\n",
      "Loss: tensor(0.0966, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6384\n",
      "Loss: tensor(0.0966, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6385\n",
      "Loss: tensor(0.0966, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6386\n",
      "Loss: tensor(0.0966, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6387\n",
      "Loss: tensor(0.0966, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6388\n",
      "Loss: tensor(0.0966, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6389\n",
      "Loss: tensor(0.0966, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6390\n",
      "Loss: tensor(0.0966, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6391\n",
      "Loss: tensor(0.0966, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6392\n",
      "Loss: tensor(0.0966, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6393\n",
      "Loss: tensor(0.0966, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6394\n",
      "Loss: tensor(0.0966, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6395\n",
      "Loss: tensor(0.0966, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6396\n",
      "Loss: tensor(0.0966, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6397\n",
      "Loss: tensor(0.0966, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6398\n",
      "Loss: tensor(0.0966, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6399\n",
      "Loss: tensor(0.0966, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6400\n",
      "Loss: tensor(0.0966, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6401\n",
      "Loss: tensor(0.0966, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6402\n",
      "Loss: tensor(0.0966, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6403\n",
      "Loss: tensor(0.0966, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6404\n",
      "Loss: tensor(0.0966, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6405\n",
      "Loss: tensor(0.0966, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6406\n",
      "Loss: tensor(0.0966, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6407\n",
      "Loss: tensor(0.0966, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6408\n",
      "Loss: tensor(0.0966, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6409\n",
      "Loss: tensor(0.0966, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6410\n",
      "Loss: tensor(0.0966, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6411\n",
      "Loss: tensor(0.0966, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6412\n",
      "Loss: tensor(0.0966, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6413\n",
      "Loss: tensor(0.0966, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6414\n",
      "Loss: tensor(0.0966, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6415\n",
      "Loss: tensor(0.0966, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6416\n",
      "Loss: tensor(0.0966, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6417\n",
      "Loss: tensor(0.0966, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6418\n",
      "Loss: tensor(0.0966, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6419\n",
      "Loss: tensor(0.0966, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6420\n",
      "Loss: tensor(0.0966, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6421\n",
      "Loss: tensor(0.0966, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6422\n",
      "Loss: tensor(0.0966, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6423\n",
      "Loss: tensor(0.0966, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6424\n",
      "Loss: tensor(0.0966, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6425\n",
      "Loss: tensor(0.0966, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6426\n",
      "Loss: tensor(0.0966, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6427\n",
      "Loss: tensor(0.0966, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6428\n",
      "Loss: tensor(0.0966, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6429\n",
      "Loss: tensor(0.0966, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6430\n",
      "Loss: tensor(0.0966, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6431\n",
      "Loss: tensor(0.0966, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6432\n",
      "Loss: tensor(0.0966, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6433\n",
      "Loss: tensor(0.0966, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6434\n",
      "Loss: tensor(0.0966, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6435\n",
      "Loss: tensor(0.0966, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6436\n",
      "Loss: tensor(0.0966, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6437\n",
      "Loss: tensor(0.0966, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6438\n",
      "Loss: tensor(0.0966, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6439\n",
      "Loss: tensor(0.0966, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6440\n",
      "Loss: tensor(0.0966, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6441\n",
      "Loss: tensor(0.0966, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6442\n",
      "Loss: tensor(0.0966, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6443\n",
      "Loss: tensor(0.0966, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6444\n",
      "Loss: tensor(0.0965, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6445\n",
      "Loss: tensor(0.0965, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6446\n",
      "Loss: tensor(0.0965, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6447\n",
      "Loss: tensor(0.0965, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6448\n",
      "Loss: tensor(0.0965, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6449\n",
      "Loss: tensor(0.0965, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6450\n",
      "Loss: tensor(0.0965, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6451\n",
      "Loss: tensor(0.0965, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6452\n",
      "Loss: tensor(0.0965, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6453\n",
      "Loss: tensor(0.0965, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6454\n",
      "Loss: tensor(0.0965, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6455\n",
      "Loss: tensor(0.0965, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6456\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor(0.0965, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6457\n",
      "Loss: tensor(0.0965, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6458\n",
      "Loss: tensor(0.0965, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6459\n",
      "Loss: tensor(0.0965, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6460\n",
      "Loss: tensor(0.0965, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6461\n",
      "Loss: tensor(0.0965, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6462\n",
      "Loss: tensor(0.0965, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6463\n",
      "Loss: tensor(0.0965, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6464\n",
      "Loss: tensor(0.0965, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6465\n",
      "Loss: tensor(0.0965, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6466\n",
      "Loss: tensor(0.0965, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6467\n",
      "Loss: tensor(0.0965, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6468\n",
      "Loss: tensor(0.0965, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6469\n",
      "Loss: tensor(0.0965, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6470\n",
      "Loss: tensor(0.0965, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6471\n",
      "Loss: tensor(0.0965, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6472\n",
      "Loss: tensor(0.0965, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6473\n",
      "Loss: tensor(0.0965, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6474\n",
      "Loss: tensor(0.0965, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6475\n",
      "Loss: tensor(0.0965, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6476\n",
      "Loss: tensor(0.0965, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6477\n",
      "Loss: tensor(0.0965, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6478\n",
      "Loss: tensor(0.0965, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6479\n",
      "Loss: tensor(0.0965, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6480\n",
      "Loss: tensor(0.0965, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6481\n",
      "Loss: tensor(0.0965, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6482\n",
      "Loss: tensor(0.0965, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6483\n",
      "Loss: tensor(0.0965, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6484\n",
      "Loss: tensor(0.0965, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6485\n",
      "Loss: tensor(0.0965, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6486\n",
      "Loss: tensor(0.0965, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6487\n",
      "Loss: tensor(0.0965, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6488\n",
      "Loss: tensor(0.0965, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6489\n",
      "Loss: tensor(0.0965, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6490\n",
      "Loss: tensor(0.0965, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6491\n",
      "Loss: tensor(0.0965, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6492\n",
      "Loss: tensor(0.0965, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6493\n",
      "Loss: tensor(0.0965, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6494\n",
      "Loss: tensor(0.0965, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6495\n",
      "Loss: tensor(0.0965, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6496\n",
      "Loss: tensor(0.0965, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6497\n",
      "Loss: tensor(0.0965, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6498\n",
      "Loss: tensor(0.0965, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6499\n",
      "Loss: tensor(0.0965, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6500\n",
      "Loss: tensor(0.0965, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6501\n",
      "Loss: tensor(0.0965, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6502\n",
      "Loss: tensor(0.0965, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6503\n",
      "Loss: tensor(0.0965, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6504\n",
      "Loss: tensor(0.0965, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6505\n",
      "Loss: tensor(0.0965, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6506\n",
      "Loss: tensor(0.0965, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6507\n",
      "Loss: tensor(0.0965, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6508\n",
      "Loss: tensor(0.0965, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6509\n",
      "Loss: tensor(0.0965, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6510\n",
      "Loss: tensor(0.0965, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6511\n",
      "Loss: tensor(0.0965, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6512\n",
      "Loss: tensor(0.0965, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6513\n",
      "Loss: tensor(0.0965, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6514\n",
      "Loss: tensor(0.0965, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6515\n",
      "Loss: tensor(0.0965, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6516\n",
      "Loss: tensor(0.0965, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6517\n",
      "Loss: tensor(0.0965, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6518\n",
      "Loss: tensor(0.0965, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6519\n",
      "Loss: tensor(0.0965, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6520\n",
      "Loss: tensor(0.0965, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6521\n",
      "Loss: tensor(0.0965, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6522\n",
      "Loss: tensor(0.0965, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6523\n",
      "Loss: tensor(0.0965, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6524\n",
      "Loss: tensor(0.0965, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6525\n",
      "Loss: tensor(0.0965, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6526\n",
      "Loss: tensor(0.0965, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6527\n",
      "Loss: tensor(0.0965, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6528\n",
      "Loss: tensor(0.0965, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6529\n",
      "Loss: tensor(0.0965, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6530\n",
      "Loss: tensor(0.0965, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6531\n",
      "Loss: tensor(0.0965, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6532\n",
      "Loss: tensor(0.0965, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6533\n",
      "Loss: tensor(0.0965, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6534\n",
      "Loss: tensor(0.0965, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6535\n",
      "Loss: tensor(0.0965, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6536\n",
      "Loss: tensor(0.0965, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6537\n",
      "Loss: tensor(0.0965, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6538\n",
      "Loss: tensor(0.0965, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6539\n",
      "Loss: tensor(0.0965, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6540\n",
      "Loss: tensor(0.0965, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6541\n",
      "Loss: tensor(0.0965, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6542\n",
      "Loss: tensor(0.0965, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6543\n",
      "Loss: tensor(0.0965, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6544\n",
      "Loss: tensor(0.0965, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6545\n",
      "Loss: tensor(0.0965, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6546\n",
      "Loss: tensor(0.0965, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6547\n",
      "Loss: tensor(0.0965, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6548\n",
      "Loss: tensor(0.0965, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6549\n",
      "Loss: tensor(0.0965, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6550\n",
      "Loss: tensor(0.0965, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6551\n",
      "Loss: tensor(0.0965, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6552\n",
      "Loss: tensor(0.0965, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6553\n",
      "Loss: tensor(0.0965, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6554\n",
      "Loss: tensor(0.0965, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6555\n",
      "Loss: tensor(0.0965, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6556\n",
      "Loss: tensor(0.0965, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6557\n",
      "Loss: tensor(0.0965, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6558\n",
      "Loss: tensor(0.0965, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6559\n",
      "Loss: tensor(0.0965, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6560\n",
      "Loss: tensor(0.0965, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6561\n",
      "Loss: tensor(0.0965, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6562\n",
      "Loss: tensor(0.0965, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6563\n",
      "Loss: tensor(0.0965, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6564\n",
      "Loss: tensor(0.0965, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6565\n",
      "Loss: tensor(0.0965, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6566\n",
      "Loss: tensor(0.0965, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6567\n",
      "Loss: tensor(0.0965, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6568\n",
      "Loss: tensor(0.0965, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6569\n",
      "Loss: tensor(0.0965, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6570\n",
      "Loss: tensor(0.0965, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6571\n",
      "Loss: tensor(0.0965, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6572\n",
      "Loss: tensor(0.0965, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6573\n",
      "Loss: tensor(0.0965, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6574\n",
      "Loss: tensor(0.0965, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6575\n",
      "Loss: tensor(0.0965, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6576\n",
      "Loss: tensor(0.0965, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6577\n",
      "Loss: tensor(0.0965, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6578\n",
      "Loss: tensor(0.0965, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6579\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor(0.0965, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6580\n",
      "Loss: tensor(0.0965, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6581\n",
      "Loss: tensor(0.0965, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6582\n",
      "Loss: tensor(0.0965, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6583\n",
      "Loss: tensor(0.0965, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6584\n",
      "Loss: tensor(0.0965, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6585\n",
      "Loss: tensor(0.0965, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6586\n",
      "Loss: tensor(0.0965, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6587\n",
      "Loss: tensor(0.0965, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6588\n",
      "Loss: tensor(0.0965, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6589\n",
      "Loss: tensor(0.0965, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6590\n",
      "Loss: tensor(0.0965, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6591\n",
      "Loss: tensor(0.0965, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6592\n",
      "Loss: tensor(0.0965, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6593\n",
      "Loss: tensor(0.0965, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6594\n",
      "Loss: tensor(0.0965, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6595\n",
      "Loss: tensor(0.0965, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6596\n",
      "Loss: tensor(0.0965, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6597\n",
      "Loss: tensor(0.0965, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6598\n",
      "Loss: tensor(0.0965, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6599\n",
      "Loss: tensor(0.0965, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6600\n",
      "Loss: tensor(0.0965, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6601\n",
      "Loss: tensor(0.0965, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6602\n",
      "Loss: tensor(0.0965, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6603\n",
      "Loss: tensor(0.0965, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6604\n",
      "Loss: tensor(0.0965, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6605\n",
      "Loss: tensor(0.0965, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6606\n",
      "Loss: tensor(0.0965, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6607\n",
      "Loss: tensor(0.0965, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6608\n",
      "Loss: tensor(0.0964, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6609\n",
      "Loss: tensor(0.0964, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6610\n",
      "Loss: tensor(0.0964, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6611\n",
      "Loss: tensor(0.0964, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6612\n",
      "Loss: tensor(0.0964, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6613\n",
      "Loss: tensor(0.0964, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6614\n",
      "Loss: tensor(0.0964, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6615\n",
      "Loss: tensor(0.0964, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6616\n",
      "Loss: tensor(0.0964, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6617\n",
      "Loss: tensor(0.0964, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6618\n",
      "Loss: tensor(0.0964, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6619\n",
      "Loss: tensor(0.0964, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6620\n",
      "Loss: tensor(0.0964, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6621\n",
      "Loss: tensor(0.0964, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6622\n",
      "Loss: tensor(0.0964, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6623\n",
      "Loss: tensor(0.0964, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6624\n",
      "Loss: tensor(0.0964, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6625\n",
      "Loss: tensor(0.0964, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6626\n",
      "Loss: tensor(0.0964, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6627\n",
      "Loss: tensor(0.0964, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6628\n",
      "Loss: tensor(0.0964, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6629\n",
      "Loss: tensor(0.0964, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6630\n",
      "Loss: tensor(0.0964, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6631\n",
      "Loss: tensor(0.0964, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6632\n",
      "Loss: tensor(0.0964, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6633\n",
      "Loss: tensor(0.0964, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6634\n",
      "Loss: tensor(0.0964, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6635\n",
      "Loss: tensor(0.0964, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6636\n",
      "Loss: tensor(0.0964, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6637\n",
      "Loss: tensor(0.0964, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6638\n",
      "Loss: tensor(0.0964, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6639\n",
      "Loss: tensor(0.0964, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6640\n",
      "Loss: tensor(0.0964, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6641\n",
      "Loss: tensor(0.0964, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6642\n",
      "Loss: tensor(0.0964, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6643\n",
      "Loss: tensor(0.0964, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6644\n",
      "Loss: tensor(0.0964, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6645\n",
      "Loss: tensor(0.0964, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6646\n",
      "Loss: tensor(0.0964, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6647\n",
      "Loss: tensor(0.0964, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6648\n",
      "Loss: tensor(0.0964, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6649\n",
      "Loss: tensor(0.0964, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6650\n",
      "Loss: tensor(0.0964, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6651\n",
      "Loss: tensor(0.0964, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6652\n",
      "Loss: tensor(0.0964, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6653\n",
      "Loss: tensor(0.0964, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6654\n",
      "Loss: tensor(0.0964, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6655\n",
      "Loss: tensor(0.0964, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6656\n",
      "Loss: tensor(0.0964, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6657\n",
      "Loss: tensor(0.0964, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6658\n",
      "Loss: tensor(0.0964, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6659\n",
      "Loss: tensor(0.0964, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6660\n",
      "Loss: tensor(0.0964, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6661\n",
      "Loss: tensor(0.0964, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6662\n",
      "Loss: tensor(0.0964, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6663\n",
      "Loss: tensor(0.0964, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6664\n",
      "Loss: tensor(0.0964, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6665\n",
      "Loss: tensor(0.0964, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6666\n",
      "Loss: tensor(0.0964, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6667\n",
      "Loss: tensor(0.0964, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6668\n",
      "Loss: tensor(0.0964, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6669\n",
      "Loss: tensor(0.0964, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6670\n",
      "Loss: tensor(0.0964, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6671\n",
      "Loss: tensor(0.0964, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6672\n",
      "Loss: tensor(0.0964, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6673\n",
      "Loss: tensor(0.0964, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6674\n",
      "Loss: tensor(0.0964, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6675\n",
      "Loss: tensor(0.0964, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6676\n",
      "Loss: tensor(0.0964, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6677\n",
      "Loss: tensor(0.0964, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6678\n",
      "Loss: tensor(0.0964, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6679\n",
      "Loss: tensor(0.0964, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6680\n",
      "Loss: tensor(0.0964, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6681\n",
      "Loss: tensor(0.0964, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6682\n",
      "Loss: tensor(0.0964, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6683\n",
      "Loss: tensor(0.0964, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6684\n",
      "Loss: tensor(0.0964, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6685\n",
      "Loss: tensor(0.0964, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6686\n",
      "Loss: tensor(0.0964, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6687\n",
      "Loss: tensor(0.0964, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6688\n",
      "Loss: tensor(0.0964, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6689\n",
      "Loss: tensor(0.0964, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6690\n",
      "Loss: tensor(0.0964, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6691\n",
      "Loss: tensor(0.0964, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6692\n",
      "Loss: tensor(0.0964, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6693\n",
      "Loss: tensor(0.0964, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6694\n",
      "Loss: tensor(0.0964, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6695\n",
      "Loss: tensor(0.0964, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6696\n",
      "Loss: tensor(0.0964, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6697\n",
      "Loss: tensor(0.0964, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6698\n",
      "Loss: tensor(0.0964, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6699\n",
      "Loss: tensor(0.0964, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor(0.0964, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6701\n",
      "Loss: tensor(0.0964, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6702\n",
      "Loss: tensor(0.0964, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6703\n",
      "Loss: tensor(0.0964, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6704\n",
      "Loss: tensor(0.0964, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6705\n",
      "Loss: tensor(0.0964, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6706\n",
      "Loss: tensor(0.0964, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6707\n",
      "Loss: tensor(0.0964, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6708\n",
      "Loss: tensor(0.0964, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6709\n",
      "Loss: tensor(0.0964, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6710\n",
      "Loss: tensor(0.0964, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6711\n",
      "Loss: tensor(0.0964, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6712\n",
      "Loss: tensor(0.0964, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6713\n",
      "Loss: tensor(0.0964, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6714\n",
      "Loss: tensor(0.0964, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6715\n",
      "Loss: tensor(0.0964, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6716\n",
      "Loss: tensor(0.0964, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6717\n",
      "Loss: tensor(0.0964, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6718\n",
      "Loss: tensor(0.0964, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6719\n",
      "Loss: tensor(0.0964, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6720\n",
      "Loss: tensor(0.0964, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6721\n",
      "Loss: tensor(0.0964, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6722\n",
      "Loss: tensor(0.0964, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6723\n",
      "Loss: tensor(0.0964, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6724\n",
      "Loss: tensor(0.0964, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6725\n",
      "Loss: tensor(0.0964, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6726\n",
      "Loss: tensor(0.0964, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6727\n",
      "Loss: tensor(0.0964, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6728\n",
      "Loss: tensor(0.0964, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6729\n",
      "Loss: tensor(0.0964, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6730\n",
      "Loss: tensor(0.0964, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6731\n",
      "Loss: tensor(0.0964, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6732\n",
      "Loss: tensor(0.0964, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6733\n",
      "Loss: tensor(0.0964, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6734\n",
      "Loss: tensor(0.0964, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6735\n",
      "Loss: tensor(0.0964, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6736\n",
      "Loss: tensor(0.0964, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6737\n",
      "Loss: tensor(0.0964, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6738\n",
      "Loss: tensor(0.0964, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6739\n",
      "Loss: tensor(0.0964, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6740\n",
      "Loss: tensor(0.0964, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6741\n",
      "Loss: tensor(0.0964, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6742\n",
      "Loss: tensor(0.0964, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6743\n",
      "Loss: tensor(0.0964, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6744\n",
      "Loss: tensor(0.0964, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6745\n",
      "Loss: tensor(0.0964, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6746\n",
      "Loss: tensor(0.0964, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6747\n",
      "Loss: tensor(0.0964, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6748\n",
      "Loss: tensor(0.0964, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6749\n",
      "Loss: tensor(0.0964, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6750\n",
      "Loss: tensor(0.0964, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6751\n",
      "Loss: tensor(0.0964, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6752\n",
      "Loss: tensor(0.0964, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6753\n",
      "Loss: tensor(0.0964, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6754\n",
      "Loss: tensor(0.0964, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6755\n",
      "Loss: tensor(0.0964, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6756\n",
      "Loss: tensor(0.0964, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6757\n",
      "Loss: tensor(0.0964, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6758\n",
      "Loss: tensor(0.0964, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6759\n",
      "Loss: tensor(0.0964, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6760\n",
      "Loss: tensor(0.0964, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6761\n",
      "Loss: tensor(0.0964, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6762\n",
      "Loss: tensor(0.0964, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6763\n",
      "Loss: tensor(0.0964, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6764\n",
      "Loss: tensor(0.0964, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6765\n",
      "Loss: tensor(0.0964, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6766\n",
      "Loss: tensor(0.0964, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6767\n",
      "Loss: tensor(0.0964, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6768\n",
      "Loss: tensor(0.0964, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6769\n",
      "Loss: tensor(0.0964, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6770\n",
      "Loss: tensor(0.0964, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6771\n",
      "Loss: tensor(0.0964, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6772\n",
      "Loss: tensor(0.0964, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6773\n",
      "Loss: tensor(0.0964, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6774\n",
      "Loss: tensor(0.0964, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6775\n",
      "Loss: tensor(0.0964, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6776\n",
      "Loss: tensor(0.0964, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6777\n",
      "Loss: tensor(0.0964, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6778\n",
      "Loss: tensor(0.0964, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6779\n",
      "Loss: tensor(0.0964, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6780\n",
      "Loss: tensor(0.0963, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6781\n",
      "Loss: tensor(0.0963, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6782\n",
      "Loss: tensor(0.0963, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6783\n",
      "Loss: tensor(0.0963, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6784\n",
      "Loss: tensor(0.0963, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6785\n",
      "Loss: tensor(0.0963, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6786\n",
      "Loss: tensor(0.0963, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6787\n",
      "Loss: tensor(0.0963, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6788\n",
      "Loss: tensor(0.0963, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6789\n",
      "Loss: tensor(0.0963, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6790\n",
      "Loss: tensor(0.0963, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6791\n",
      "Loss: tensor(0.0963, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6792\n",
      "Loss: tensor(0.0963, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6793\n",
      "Loss: tensor(0.0963, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6794\n",
      "Loss: tensor(0.0963, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6795\n",
      "Loss: tensor(0.0963, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6796\n",
      "Loss: tensor(0.0963, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6797\n",
      "Loss: tensor(0.0963, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6798\n",
      "Loss: tensor(0.0963, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6799\n",
      "Loss: tensor(0.0963, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6800\n",
      "Loss: tensor(0.0963, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6801\n",
      "Loss: tensor(0.0963, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6802\n",
      "Loss: tensor(0.0963, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6803\n",
      "Loss: tensor(0.0963, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6804\n",
      "Loss: tensor(0.0963, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6805\n",
      "Loss: tensor(0.0963, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6806\n",
      "Loss: tensor(0.0963, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6807\n",
      "Loss: tensor(0.0963, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6808\n",
      "Loss: tensor(0.0963, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6809\n",
      "Loss: tensor(0.0963, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6810\n",
      "Loss: tensor(0.0963, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6811\n",
      "Loss: tensor(0.0963, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6812\n",
      "Loss: tensor(0.0963, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6813\n",
      "Loss: tensor(0.0963, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6814\n",
      "Loss: tensor(0.0963, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6815\n",
      "Loss: tensor(0.0963, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6816\n",
      "Loss: tensor(0.0963, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6817\n",
      "Loss: tensor(0.0963, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6818\n",
      "Loss: tensor(0.0963, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6819\n",
      "Loss: tensor(0.0963, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6820\n",
      "Loss: tensor(0.0963, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6821\n",
      "Loss: tensor(0.0963, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6822\n",
      "Loss: tensor(0.0963, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6823\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor(0.0963, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6824\n",
      "Loss: tensor(0.0963, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6825\n",
      "Loss: tensor(0.0963, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6826\n",
      "Loss: tensor(0.0963, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6827\n",
      "Loss: tensor(0.0963, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6828\n",
      "Loss: tensor(0.0963, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6829\n",
      "Loss: tensor(0.0963, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6830\n",
      "Loss: tensor(0.0963, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6831\n",
      "Loss: tensor(0.0963, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6832\n",
      "Loss: tensor(0.0963, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6833\n",
      "Loss: tensor(0.0963, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6834\n",
      "Loss: tensor(0.0963, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6835\n",
      "Loss: tensor(0.0963, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6836\n",
      "Loss: tensor(0.0963, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6837\n",
      "Loss: tensor(0.0963, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6838\n",
      "Loss: tensor(0.0963, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6839\n",
      "Loss: tensor(0.0963, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6840\n",
      "Loss: tensor(0.0963, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6841\n",
      "Loss: tensor(0.0963, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6842\n",
      "Loss: tensor(0.0963, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6843\n",
      "Loss: tensor(0.0963, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6844\n",
      "Loss: tensor(0.0963, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6845\n",
      "Loss: tensor(0.0963, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6846\n",
      "Loss: tensor(0.0963, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6847\n",
      "Loss: tensor(0.0963, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6848\n",
      "Loss: tensor(0.0963, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6849\n",
      "Loss: tensor(0.0963, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6850\n",
      "Loss: tensor(0.0963, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6851\n",
      "Loss: tensor(0.0963, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6852\n",
      "Loss: tensor(0.0963, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6853\n",
      "Loss: tensor(0.0963, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6854\n",
      "Loss: tensor(0.0963, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6855\n",
      "Loss: tensor(0.0963, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6856\n",
      "Loss: tensor(0.0963, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6857\n",
      "Loss: tensor(0.0963, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6858\n",
      "Loss: tensor(0.0963, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6859\n",
      "Loss: tensor(0.0963, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6860\n",
      "Loss: tensor(0.0963, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6861\n",
      "Loss: tensor(0.0963, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6862\n",
      "Loss: tensor(0.0963, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6863\n",
      "Loss: tensor(0.0963, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6864\n",
      "Loss: tensor(0.0963, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6865\n",
      "Loss: tensor(0.0963, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6866\n",
      "Loss: tensor(0.0963, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6867\n",
      "Loss: tensor(0.0963, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6868\n",
      "Loss: tensor(0.0963, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6869\n",
      "Loss: tensor(0.0963, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6870\n",
      "Loss: tensor(0.0963, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6871\n",
      "Loss: tensor(0.0963, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6872\n",
      "Loss: tensor(0.0963, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6873\n",
      "Loss: tensor(0.0963, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6874\n",
      "Loss: tensor(0.0963, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6875\n",
      "Loss: tensor(0.0963, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6876\n",
      "Loss: tensor(0.0963, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6877\n",
      "Loss: tensor(0.0963, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6878\n",
      "Loss: tensor(0.0963, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6879\n",
      "Loss: tensor(0.0963, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6880\n",
      "Loss: tensor(0.0963, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6881\n",
      "Loss: tensor(0.0963, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6882\n",
      "Loss: tensor(0.0963, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6883\n",
      "Loss: tensor(0.0963, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6884\n",
      "Loss: tensor(0.0963, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6885\n",
      "Loss: tensor(0.0963, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6886\n",
      "Loss: tensor(0.0963, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6887\n",
      "Loss: tensor(0.0963, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6888\n",
      "Loss: tensor(0.0963, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6889\n",
      "Loss: tensor(0.0963, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6890\n",
      "Loss: tensor(0.0963, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6891\n",
      "Loss: tensor(0.0963, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6892\n",
      "Loss: tensor(0.0963, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6893\n",
      "Loss: tensor(0.0963, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6894\n",
      "Loss: tensor(0.0963, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6895\n",
      "Loss: tensor(0.0963, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6896\n",
      "Loss: tensor(0.0963, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6897\n",
      "Loss: tensor(0.0963, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6898\n",
      "Loss: tensor(0.0963, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6899\n",
      "Loss: tensor(0.0963, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6900\n",
      "Loss: tensor(0.0963, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6901\n",
      "Loss: tensor(0.0963, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6902\n",
      "Loss: tensor(0.0963, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6903\n",
      "Loss: tensor(0.0963, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6904\n",
      "Loss: tensor(0.0963, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6905\n",
      "Loss: tensor(0.0963, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6906\n",
      "Loss: tensor(0.0963, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6907\n",
      "Loss: tensor(0.0963, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6908\n",
      "Loss: tensor(0.0963, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6909\n",
      "Loss: tensor(0.0963, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6910\n",
      "Loss: tensor(0.0963, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6911\n",
      "Loss: tensor(0.0963, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6912\n",
      "Loss: tensor(0.0963, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6913\n",
      "Loss: tensor(0.0963, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6914\n",
      "Loss: tensor(0.0963, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6915\n",
      "Loss: tensor(0.0963, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6916\n",
      "Loss: tensor(0.0963, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6917\n",
      "Loss: tensor(0.0963, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6918\n",
      "Loss: tensor(0.0963, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6919\n",
      "Loss: tensor(0.0963, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6920\n",
      "Loss: tensor(0.0963, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6921\n",
      "Loss: tensor(0.0963, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6922\n",
      "Loss: tensor(0.0963, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6923\n",
      "Loss: tensor(0.0963, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6924\n",
      "Loss: tensor(0.0963, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6925\n",
      "Loss: tensor(0.0963, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6926\n",
      "Loss: tensor(0.0963, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6927\n",
      "Loss: tensor(0.0963, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6928\n",
      "Loss: tensor(0.0963, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6929\n",
      "Loss: tensor(0.0963, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6930\n",
      "Loss: tensor(0.0963, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6931\n",
      "Loss: tensor(0.0963, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6932\n",
      "Loss: tensor(0.0963, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6933\n",
      "Loss: tensor(0.0963, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6934\n",
      "Loss: tensor(0.0963, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6935\n",
      "Loss: tensor(0.0963, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6936\n",
      "Loss: tensor(0.0963, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6937\n",
      "Loss: tensor(0.0963, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6938\n",
      "Loss: tensor(0.0963, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6939\n",
      "Loss: tensor(0.0963, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6940\n",
      "Loss: tensor(0.0963, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6941\n",
      "Loss: tensor(0.0963, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6942\n",
      "Loss: tensor(0.0963, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6943\n",
      "Loss: tensor(0.0963, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6944\n",
      "Loss: tensor(0.0963, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6945\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor(0.0963, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6946\n",
      "Loss: tensor(0.0963, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6947\n",
      "Loss: tensor(0.0963, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6948\n",
      "Loss: tensor(0.0963, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6949\n",
      "Loss: tensor(0.0963, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6950\n",
      "Loss: tensor(0.0963, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6951\n",
      "Loss: tensor(0.0963, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6952\n",
      "Loss: tensor(0.0963, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6953\n",
      "Loss: tensor(0.0963, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6954\n",
      "Loss: tensor(0.0963, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6955\n",
      "Loss: tensor(0.0963, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6956\n",
      "Loss: tensor(0.0963, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6957\n",
      "Loss: tensor(0.0963, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6958\n",
      "Loss: tensor(0.0963, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6959\n",
      "Loss: tensor(0.0963, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6960\n",
      "Loss: tensor(0.0963, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6961\n",
      "Loss: tensor(0.0963, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6962\n",
      "Loss: tensor(0.0963, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6963\n",
      "Loss: tensor(0.0963, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6964\n",
      "Loss: tensor(0.0962, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6965\n",
      "Loss: tensor(0.0963, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6966\n",
      "Loss: tensor(0.0963, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6967\n",
      "Loss: tensor(0.0963, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6968\n",
      "Loss: tensor(0.0963, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6969\n",
      "Loss: tensor(0.0963, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6970\n",
      "Loss: tensor(0.0963, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6971\n",
      "Loss: tensor(0.0963, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6972\n",
      "Loss: tensor(0.0963, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6973\n",
      "Loss: tensor(0.0963, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6974\n",
      "Loss: tensor(0.0962, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6975\n",
      "Loss: tensor(0.0962, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6976\n",
      "Loss: tensor(0.0962, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6977\n",
      "Loss: tensor(0.0962, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6978\n",
      "Loss: tensor(0.0962, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6979\n",
      "Loss: tensor(0.0962, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6980\n",
      "Loss: tensor(0.0962, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6981\n",
      "Loss: tensor(0.0962, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6982\n",
      "Loss: tensor(0.0962, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6983\n",
      "Loss: tensor(0.0962, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6984\n",
      "Loss: tensor(0.0962, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6985\n",
      "Loss: tensor(0.0962, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6986\n",
      "Loss: tensor(0.0962, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6987\n",
      "Loss: tensor(0.0962, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6988\n",
      "Loss: tensor(0.0962, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6989\n",
      "Loss: tensor(0.0962, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6990\n",
      "Loss: tensor(0.0962, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6991\n",
      "Loss: tensor(0.0962, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6992\n",
      "Loss: tensor(0.0962, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6993\n",
      "Loss: tensor(0.0962, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6994\n",
      "Loss: tensor(0.0962, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6995\n",
      "Loss: tensor(0.0962, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6996\n",
      "Loss: tensor(0.0962, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6997\n",
      "Loss: tensor(0.0962, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6998\n",
      "Loss: tensor(0.0962, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6999\n",
      "Loss: tensor(0.0962, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7000\n",
      "Loss: tensor(0.0962, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7001\n",
      "Loss: tensor(0.0962, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7002\n",
      "Loss: tensor(0.0962, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7003\n",
      "Loss: tensor(0.0962, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7004\n",
      "Loss: tensor(0.0962, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7005\n",
      "Loss: tensor(0.0962, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7006\n",
      "Loss: tensor(0.0962, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7007\n",
      "Loss: tensor(0.0962, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7008\n",
      "Loss: tensor(0.0962, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7009\n",
      "Loss: tensor(0.0962, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7010\n",
      "Loss: tensor(0.0962, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7011\n",
      "Loss: tensor(0.0962, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7012\n",
      "Loss: tensor(0.0962, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7013\n",
      "Loss: tensor(0.0962, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7014\n",
      "Loss: tensor(0.0962, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7015\n",
      "Loss: tensor(0.0962, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7016\n",
      "Loss: tensor(0.0962, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7017\n",
      "Loss: tensor(0.0962, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7018\n",
      "Loss: tensor(0.0962, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7019\n",
      "Loss: tensor(0.0962, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7020\n",
      "Loss: tensor(0.0962, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7021\n",
      "Loss: tensor(0.0962, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7022\n",
      "Loss: tensor(0.0962, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7023\n",
      "Loss: tensor(0.0962, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7024\n",
      "Loss: tensor(0.0962, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7025\n",
      "Loss: tensor(0.0962, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7026\n",
      "Loss: tensor(0.0962, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7027\n",
      "Loss: tensor(0.0962, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7028\n",
      "Loss: tensor(0.0962, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7029\n",
      "Loss: tensor(0.0962, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7030\n",
      "Loss: tensor(0.0962, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7031\n",
      "Loss: tensor(0.0962, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7032\n",
      "Loss: tensor(0.0962, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7033\n",
      "Loss: tensor(0.0962, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7034\n",
      "Loss: tensor(0.0962, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7035\n",
      "Loss: tensor(0.0962, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7036\n",
      "Loss: tensor(0.0962, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7037\n",
      "Loss: tensor(0.0962, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7038\n",
      "Loss: tensor(0.0962, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7039\n",
      "Loss: tensor(0.0962, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7040\n",
      "Loss: tensor(0.0962, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7041\n",
      "Loss: tensor(0.0962, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7042\n",
      "Loss: tensor(0.0962, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7043\n",
      "Loss: tensor(0.0962, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7044\n",
      "Loss: tensor(0.0962, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7045\n",
      "Loss: tensor(0.0962, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7046\n",
      "Loss: tensor(0.0962, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7047\n",
      "Loss: tensor(0.0962, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7048\n",
      "Loss: tensor(0.0962, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7049\n",
      "Loss: tensor(0.0962, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7050\n",
      "Loss: tensor(0.0962, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7051\n",
      "Loss: tensor(0.0962, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7052\n",
      "Loss: tensor(0.0962, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7053\n",
      "Loss: tensor(0.0962, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7054\n",
      "Loss: tensor(0.0962, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7055\n",
      "Loss: tensor(0.0962, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7056\n",
      "Loss: tensor(0.0962, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7057\n",
      "Loss: tensor(0.0962, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7058\n",
      "Loss: tensor(0.0962, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7059\n",
      "Loss: tensor(0.0962, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7060\n",
      "Loss: tensor(0.0962, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7061\n",
      "Loss: tensor(0.0962, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7062\n",
      "Loss: tensor(0.0962, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7063\n",
      "Loss: tensor(0.0962, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7064\n",
      "Loss: tensor(0.0962, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7065\n",
      "Loss: tensor(0.0962, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7066\n",
      "Loss: tensor(0.0962, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7067\n",
      "Loss: tensor(0.0962, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7068\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor(0.0962, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7069\n",
      "Loss: tensor(0.0962, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7070\n",
      "Loss: tensor(0.0962, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7071\n",
      "Loss: tensor(0.0962, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7072\n",
      "Loss: tensor(0.0962, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7073\n",
      "Loss: tensor(0.0962, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7074\n",
      "Loss: tensor(0.0962, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7075\n",
      "Loss: tensor(0.0962, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7076\n",
      "Loss: tensor(0.0962, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7077\n",
      "Loss: tensor(0.0962, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7078\n",
      "Loss: tensor(0.0962, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7079\n",
      "Loss: tensor(0.0962, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7080\n",
      "Loss: tensor(0.0962, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7081\n",
      "Loss: tensor(0.0962, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7082\n",
      "Loss: tensor(0.0962, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7083\n",
      "Loss: tensor(0.0962, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7084\n",
      "Loss: tensor(0.0962, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7085\n",
      "Loss: tensor(0.0962, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7086\n",
      "Loss: tensor(0.0962, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7087\n",
      "Loss: tensor(0.0962, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7088\n",
      "Loss: tensor(0.0962, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7089\n",
      "Loss: tensor(0.0962, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7090\n",
      "Loss: tensor(0.0962, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7091\n",
      "Loss: tensor(0.0962, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7092\n",
      "Loss: tensor(0.0962, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7093\n",
      "Loss: tensor(0.0962, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7094\n",
      "Loss: tensor(0.0962, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7095\n",
      "Loss: tensor(0.0962, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7096\n",
      "Loss: tensor(0.0962, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7097\n",
      "Loss: tensor(0.0962, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7098\n",
      "Loss: tensor(0.0962, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7099\n",
      "Loss: tensor(0.0962, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7100\n",
      "Loss: tensor(0.0962, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7101\n",
      "Loss: tensor(0.0962, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7102\n",
      "Loss: tensor(0.0962, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7103\n",
      "Loss: tensor(0.0962, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7104\n",
      "Loss: tensor(0.0962, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7105\n",
      "Loss: tensor(0.0962, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7106\n",
      "Loss: tensor(0.0962, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7107\n",
      "Loss: tensor(0.0962, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7108\n",
      "Loss: tensor(0.0962, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7109\n",
      "Loss: tensor(0.0962, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7110\n",
      "Loss: tensor(0.0962, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7111\n",
      "Loss: tensor(0.0962, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7112\n",
      "Loss: tensor(0.0962, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7113\n",
      "Loss: tensor(0.0962, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7114\n",
      "Loss: tensor(0.0962, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7115\n",
      "Loss: tensor(0.0962, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7116\n",
      "Loss: tensor(0.0962, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7117\n",
      "Loss: tensor(0.0962, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7118\n",
      "Loss: tensor(0.0962, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7119\n",
      "Loss: tensor(0.0962, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7120\n",
      "Loss: tensor(0.0962, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7121\n",
      "Loss: tensor(0.0962, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7122\n",
      "Loss: tensor(0.0962, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7123\n",
      "Loss: tensor(0.0962, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7124\n",
      "Loss: tensor(0.0962, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7125\n",
      "Loss: tensor(0.0962, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7126\n",
      "Loss: tensor(0.0962, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7127\n",
      "Loss: tensor(0.0962, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7128\n",
      "Loss: tensor(0.0962, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7129\n",
      "Loss: tensor(0.0962, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7130\n",
      "Loss: tensor(0.0962, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7131\n",
      "Loss: tensor(0.0962, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7132\n",
      "Loss: tensor(0.0962, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7133\n",
      "Loss: tensor(0.0962, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7134\n",
      "Loss: tensor(0.0962, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7135\n",
      "Loss: tensor(0.0962, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7136\n",
      "Loss: tensor(0.0962, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7137\n",
      "Loss: tensor(0.0962, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7138\n",
      "Loss: tensor(0.0962, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7139\n",
      "Loss: tensor(0.0962, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7140\n",
      "Loss: tensor(0.0962, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7141\n",
      "Loss: tensor(0.0962, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7142\n",
      "Loss: tensor(0.0962, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7143\n",
      "Loss: tensor(0.0962, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7144\n",
      "Loss: tensor(0.0962, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7145\n",
      "Loss: tensor(0.0962, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7146\n",
      "Loss: tensor(0.0962, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7147\n",
      "Loss: tensor(0.0962, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7148\n",
      "Loss: tensor(0.0962, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7149\n",
      "Loss: tensor(0.0962, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7150\n",
      "Loss: tensor(0.0962, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7151\n",
      "Loss: tensor(0.0962, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7152\n",
      "Loss: tensor(0.0962, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7153\n",
      "Loss: tensor(0.0962, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7154\n",
      "Loss: tensor(0.0962, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7155\n",
      "Loss: tensor(0.0962, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7156\n",
      "Loss: tensor(0.0962, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7157\n",
      "Loss: tensor(0.0962, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7158\n",
      "Loss: tensor(0.0962, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7159\n",
      "Loss: tensor(0.0961, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7160\n",
      "Loss: tensor(0.0961, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7161\n",
      "Loss: tensor(0.0961, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7162\n",
      "Loss: tensor(0.0961, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7163\n",
      "Loss: tensor(0.0961, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7164\n",
      "Loss: tensor(0.0961, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7165\n",
      "Loss: tensor(0.0961, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7166\n",
      "Loss: tensor(0.0961, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7167\n",
      "Loss: tensor(0.0961, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7168\n",
      "Loss: tensor(0.0961, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7169\n",
      "Loss: tensor(0.0961, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7170\n",
      "Loss: tensor(0.0961, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7171\n",
      "Loss: tensor(0.0961, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7172\n",
      "Loss: tensor(0.0961, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7173\n",
      "Loss: tensor(0.0961, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7174\n",
      "Loss: tensor(0.0961, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7175\n",
      "Loss: tensor(0.0961, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7176\n",
      "Loss: tensor(0.0961, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7177\n",
      "Loss: tensor(0.0961, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7178\n",
      "Loss: tensor(0.0961, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7179\n",
      "Loss: tensor(0.0961, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7180\n",
      "Loss: tensor(0.0961, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7181\n",
      "Loss: tensor(0.0961, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7182\n",
      "Loss: tensor(0.0961, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7183\n",
      "Loss: tensor(0.0961, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7184\n",
      "Loss: tensor(0.0961, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7185\n",
      "Loss: tensor(0.0961, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7186\n",
      "Loss: tensor(0.0961, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7187\n",
      "Loss: tensor(0.0961, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7188\n",
      "Loss: tensor(0.0961, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7189\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor(0.0961, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7190\n",
      "Loss: tensor(0.0961, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7191\n",
      "Loss: tensor(0.0961, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7192\n",
      "Loss: tensor(0.0961, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7193\n",
      "Loss: tensor(0.0961, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7194\n",
      "Loss: tensor(0.0961, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7195\n",
      "Loss: tensor(0.0961, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7196\n",
      "Loss: tensor(0.0961, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7197\n",
      "Loss: tensor(0.0961, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7198\n",
      "Loss: tensor(0.0961, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7199\n",
      "Loss: tensor(0.0961, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7200\n",
      "Loss: tensor(0.0961, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7201\n",
      "Loss: tensor(0.0961, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7202\n",
      "Loss: tensor(0.0961, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7203\n",
      "Loss: tensor(0.0961, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7204\n",
      "Loss: tensor(0.0961, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7205\n",
      "Loss: tensor(0.0961, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7206\n",
      "Loss: tensor(0.0961, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7207\n",
      "Loss: tensor(0.0961, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7208\n",
      "Loss: tensor(0.0961, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7209\n",
      "Loss: tensor(0.0961, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7210\n",
      "Loss: tensor(0.0961, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7211\n",
      "Loss: tensor(0.0961, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7212\n",
      "Loss: tensor(0.0961, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7213\n",
      "Loss: tensor(0.0961, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7214\n",
      "Loss: tensor(0.0961, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7215\n",
      "Loss: tensor(0.0961, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7216\n",
      "Loss: tensor(0.0961, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7217\n",
      "Loss: tensor(0.0961, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7218\n",
      "Loss: tensor(0.0961, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7219\n",
      "Loss: tensor(0.0961, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7220\n",
      "Loss: tensor(0.0961, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7221\n",
      "Loss: tensor(0.0961, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7222\n",
      "Loss: tensor(0.0961, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7223\n",
      "Loss: tensor(0.0961, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7224\n",
      "Loss: tensor(0.0961, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7225\n",
      "Loss: tensor(0.0961, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7226\n",
      "Loss: tensor(0.0961, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7227\n",
      "Loss: tensor(0.0961, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7228\n",
      "Loss: tensor(0.0961, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7229\n",
      "Loss: tensor(0.0961, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7230\n",
      "Loss: tensor(0.0961, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7231\n",
      "Loss: tensor(0.0961, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7232\n",
      "Loss: tensor(0.0961, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7233\n",
      "Loss: tensor(0.0961, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7234\n",
      "Loss: tensor(0.0961, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7235\n",
      "Loss: tensor(0.0961, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7236\n",
      "Loss: tensor(0.0961, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7237\n",
      "Loss: tensor(0.0961, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7238\n",
      "Loss: tensor(0.0961, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7239\n",
      "Loss: tensor(0.0961, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7240\n",
      "Loss: tensor(0.0961, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7241\n",
      "Loss: tensor(0.0961, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7242\n",
      "Loss: tensor(0.0961, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7243\n",
      "Loss: tensor(0.0961, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7244\n",
      "Loss: tensor(0.0961, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7245\n",
      "Loss: tensor(0.0961, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7246\n",
      "Loss: tensor(0.0961, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7247\n",
      "Loss: tensor(0.0961, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7248\n",
      "Loss: tensor(0.0961, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7249\n",
      "Loss: tensor(0.0961, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7250\n",
      "Loss: tensor(0.0961, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7251\n",
      "Loss: tensor(0.0961, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7252\n",
      "Loss: tensor(0.0961, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7253\n",
      "Loss: tensor(0.0961, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7254\n",
      "Loss: tensor(0.0961, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7255\n",
      "Loss: tensor(0.0961, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7256\n",
      "Loss: tensor(0.0961, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7257\n",
      "Loss: tensor(0.0961, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7258\n",
      "Loss: tensor(0.0961, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7259\n",
      "Loss: tensor(0.0961, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7260\n",
      "Loss: tensor(0.0961, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7261\n",
      "Loss: tensor(0.0961, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7262\n",
      "Loss: tensor(0.0961, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7263\n",
      "Loss: tensor(0.0961, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7264\n",
      "Loss: tensor(0.0961, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7265\n",
      "Loss: tensor(0.0961, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7266\n",
      "Loss: tensor(0.0961, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7267\n",
      "Loss: tensor(0.0961, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7268\n",
      "Loss: tensor(0.0961, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7269\n",
      "Loss: tensor(0.0961, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7270\n",
      "Loss: tensor(0.0961, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7271\n",
      "Loss: tensor(0.0961, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7272\n",
      "Loss: tensor(0.0961, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7273\n",
      "Loss: tensor(0.0961, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7274\n",
      "Loss: tensor(0.0961, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7275\n",
      "Loss: tensor(0.0961, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7276\n",
      "Loss: tensor(0.0961, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7277\n",
      "Loss: tensor(0.0961, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7278\n",
      "Loss: tensor(0.0961, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7279\n",
      "Loss: tensor(0.0961, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7280\n",
      "Loss: tensor(0.0961, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7281\n",
      "Loss: tensor(0.0961, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7282\n",
      "Loss: tensor(0.0961, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7283\n",
      "Loss: tensor(0.0961, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7284\n",
      "Loss: tensor(0.0961, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7285\n",
      "Loss: tensor(0.0961, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7286\n",
      "Loss: tensor(0.0961, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7287\n",
      "Loss: tensor(0.0961, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7288\n",
      "Loss: tensor(0.0961, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7289\n",
      "Loss: tensor(0.0961, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7290\n",
      "Loss: tensor(0.0961, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7291\n",
      "Loss: tensor(0.0961, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7292\n",
      "Loss: tensor(0.0961, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7293\n",
      "Loss: tensor(0.0961, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7294\n",
      "Loss: tensor(0.0961, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7295\n",
      "Loss: tensor(0.0961, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7296\n",
      "Loss: tensor(0.0961, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7297\n",
      "Loss: tensor(0.0961, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7298\n",
      "Loss: tensor(0.0961, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7299\n",
      "Loss: tensor(0.0961, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7300\n",
      "Loss: tensor(0.0961, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7301\n",
      "Loss: tensor(0.0961, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7302\n",
      "Loss: tensor(0.0961, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7303\n",
      "Loss: tensor(0.0961, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7304\n",
      "Loss: tensor(0.0961, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7305\n",
      "Loss: tensor(0.0961, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7306\n",
      "Loss: tensor(0.0961, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7307\n",
      "Loss: tensor(0.0961, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7308\n",
      "Loss: tensor(0.0961, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7309\n",
      "Loss: tensor(0.0961, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7310\n",
      "Loss: tensor(0.0961, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7311\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor(0.0961, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7312\n",
      "Loss: tensor(0.0961, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7313\n",
      "Loss: tensor(0.0961, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7314\n",
      "Loss: tensor(0.0961, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7315\n",
      "Loss: tensor(0.0961, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7316\n",
      "Loss: tensor(0.0961, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7317\n",
      "Loss: tensor(0.0961, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7318\n",
      "Loss: tensor(0.0961, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7319\n",
      "Loss: tensor(0.0961, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7320\n",
      "Loss: tensor(0.0961, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7321\n",
      "Loss: tensor(0.0961, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7322\n",
      "Loss: tensor(0.0961, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7323\n",
      "Loss: tensor(0.0961, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7324\n",
      "Loss: tensor(0.0961, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7325\n",
      "Loss: tensor(0.0961, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7326\n",
      "Loss: tensor(0.0961, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7327\n",
      "Loss: tensor(0.0961, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7328\n",
      "Loss: tensor(0.0961, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7329\n",
      "Loss: tensor(0.0961, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7330\n",
      "Loss: tensor(0.0961, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7331\n",
      "Loss: tensor(0.0961, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7332\n",
      "Loss: tensor(0.0961, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7333\n",
      "Loss: tensor(0.0961, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7334\n",
      "Loss: tensor(0.0961, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7335\n",
      "Loss: tensor(0.0961, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7336\n",
      "Loss: tensor(0.0961, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7337\n",
      "Loss: tensor(0.0961, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7338\n",
      "Loss: tensor(0.0961, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7339\n",
      "Loss: tensor(0.0961, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7340\n",
      "Loss: tensor(0.0961, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7341\n",
      "Loss: tensor(0.0961, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7342\n",
      "Loss: tensor(0.0961, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7343\n",
      "Loss: tensor(0.0961, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7344\n",
      "Loss: tensor(0.0961, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7345\n",
      "Loss: tensor(0.0961, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7346\n",
      "Loss: tensor(0.0960, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7347\n",
      "Loss: tensor(0.0960, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7348\n",
      "Loss: tensor(0.0960, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7349\n",
      "Loss: tensor(0.0960, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7350\n",
      "Loss: tensor(0.0960, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7351\n",
      "Loss: tensor(0.0960, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7352\n",
      "Loss: tensor(0.0960, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7353\n",
      "Loss: tensor(0.0960, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7354\n",
      "Loss: tensor(0.0960, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7355\n",
      "Loss: tensor(0.0960, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7356\n",
      "Loss: tensor(0.0960, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7357\n",
      "Loss: tensor(0.0960, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7358\n",
      "Loss: tensor(0.0960, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7359\n",
      "Loss: tensor(0.0960, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7360\n",
      "Loss: tensor(0.0960, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7361\n",
      "Loss: tensor(0.0960, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7362\n",
      "Loss: tensor(0.0960, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7363\n",
      "Loss: tensor(0.0960, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7364\n",
      "Loss: tensor(0.0960, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7365\n",
      "Loss: tensor(0.0960, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7366\n",
      "Loss: tensor(0.0960, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7367\n",
      "Loss: tensor(0.0960, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7368\n",
      "Loss: tensor(0.0960, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7369\n",
      "Loss: tensor(0.0960, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7370\n",
      "Loss: tensor(0.0960, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7371\n",
      "Loss: tensor(0.0960, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7372\n",
      "Loss: tensor(0.0960, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7373\n",
      "Loss: tensor(0.0960, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7374\n",
      "Loss: tensor(0.0960, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7375\n",
      "Loss: tensor(0.0960, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7376\n",
      "Loss: tensor(0.0960, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7377\n",
      "Loss: tensor(0.0960, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7378\n",
      "Loss: tensor(0.0960, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7379\n",
      "Loss: tensor(0.0960, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7380\n",
      "Loss: tensor(0.0960, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7381\n",
      "Loss: tensor(0.0960, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7382\n",
      "Loss: tensor(0.0960, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7383\n",
      "Loss: tensor(0.0960, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7384\n",
      "Loss: tensor(0.0960, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7385\n",
      "Loss: tensor(0.0960, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7386\n",
      "Loss: tensor(0.0960, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7387\n",
      "Loss: tensor(0.0960, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7388\n",
      "Loss: tensor(0.0960, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7389\n",
      "Loss: tensor(0.0960, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7390\n",
      "Loss: tensor(0.0960, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7391\n",
      "Loss: tensor(0.0960, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7392\n",
      "Loss: tensor(0.0960, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7393\n",
      "Loss: tensor(0.0960, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7394\n",
      "Loss: tensor(0.0960, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7395\n",
      "Loss: tensor(0.0960, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7396\n",
      "Loss: tensor(0.0960, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7397\n",
      "Loss: tensor(0.0960, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7398\n",
      "Loss: tensor(0.0961, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7399\n",
      "Loss: tensor(0.0960, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7400\n",
      "Loss: tensor(0.0960, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7401\n",
      "Loss: tensor(0.0960, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7402\n",
      "Loss: tensor(0.0960, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7403\n",
      "Loss: tensor(0.0960, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7404\n",
      "Loss: tensor(0.0960, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7405\n",
      "Loss: tensor(0.0960, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7406\n",
      "Loss: tensor(0.0960, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7407\n",
      "Loss: tensor(0.0960, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7408\n",
      "Loss: tensor(0.0960, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7409\n",
      "Loss: tensor(0.0960, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7410\n",
      "Loss: tensor(0.0960, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7411\n",
      "Loss: tensor(0.0960, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7412\n",
      "Loss: tensor(0.0960, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7413\n",
      "Loss: tensor(0.0960, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7414\n",
      "Loss: tensor(0.0960, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7415\n",
      "Loss: tensor(0.0960, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7416\n",
      "Loss: tensor(0.0960, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7417\n",
      "Loss: tensor(0.0960, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7418\n",
      "Loss: tensor(0.0960, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7419\n",
      "Loss: tensor(0.0960, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7420\n",
      "Loss: tensor(0.0960, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7421\n",
      "Loss: tensor(0.0960, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7422\n",
      "Loss: tensor(0.0960, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7423\n",
      "Loss: tensor(0.0960, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7424\n",
      "Loss: tensor(0.0960, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7425\n",
      "Loss: tensor(0.0960, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7426\n",
      "Loss: tensor(0.0960, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7427\n",
      "Loss: tensor(0.0960, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7428\n",
      "Loss: tensor(0.0960, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7429\n",
      "Loss: tensor(0.0960, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7430\n",
      "Loss: tensor(0.0960, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7431\n",
      "Loss: tensor(0.0960, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7432\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor(0.0960, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7433\n",
      "Loss: tensor(0.0960, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7434\n",
      "Loss: tensor(0.0960, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7435\n",
      "Loss: tensor(0.0960, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7436\n",
      "Loss: tensor(0.0960, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7437\n",
      "Loss: tensor(0.0960, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7438\n",
      "Loss: tensor(0.0960, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7439\n",
      "Loss: tensor(0.0960, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7440\n",
      "Loss: tensor(0.0960, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7441\n",
      "Loss: tensor(0.0960, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7442\n",
      "Loss: tensor(0.0960, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7443\n",
      "Loss: tensor(0.0960, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7444\n",
      "Loss: tensor(0.0960, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7445\n",
      "Loss: tensor(0.0960, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7446\n",
      "Loss: tensor(0.0960, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7447\n",
      "Loss: tensor(0.0960, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7448\n",
      "Loss: tensor(0.0960, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7449\n",
      "Loss: tensor(0.0960, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7450\n",
      "Loss: tensor(0.0960, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7451\n",
      "Loss: tensor(0.0960, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7452\n",
      "Loss: tensor(0.0960, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7453\n",
      "Loss: tensor(0.0960, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7454\n",
      "Loss: tensor(0.0960, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7455\n",
      "Loss: tensor(0.0960, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7456\n",
      "Loss: tensor(0.0960, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7457\n",
      "Loss: tensor(0.0960, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7458\n",
      "Loss: tensor(0.0960, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7459\n",
      "Loss: tensor(0.0960, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7460\n",
      "Loss: tensor(0.0960, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7461\n",
      "Loss: tensor(0.0960, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7462\n",
      "Loss: tensor(0.0960, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7463\n",
      "Loss: tensor(0.0960, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7464\n",
      "Loss: tensor(0.0960, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7465\n",
      "Loss: tensor(0.0960, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7466\n",
      "Loss: tensor(0.0960, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7467\n",
      "Loss: tensor(0.0960, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7468\n",
      "Loss: tensor(0.0960, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7469\n",
      "Loss: tensor(0.0960, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7470\n",
      "Loss: tensor(0.0960, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7471\n",
      "Loss: tensor(0.0960, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7472\n",
      "Loss: tensor(0.0960, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7473\n",
      "Loss: tensor(0.0960, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7474\n",
      "Loss: tensor(0.0960, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7475\n",
      "Loss: tensor(0.0960, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7476\n",
      "Loss: tensor(0.0960, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7477\n",
      "Loss: tensor(0.0960, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7478\n",
      "Loss: tensor(0.0960, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7479\n",
      "Loss: tensor(0.0960, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7480\n",
      "Loss: tensor(0.0960, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7481\n",
      "Loss: tensor(0.0960, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7482\n",
      "Loss: tensor(0.0960, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7483\n",
      "Loss: tensor(0.0960, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7484\n",
      "Loss: tensor(0.0960, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7485\n",
      "Loss: tensor(0.0960, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7486\n",
      "Loss: tensor(0.0960, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7487\n",
      "Loss: tensor(0.0960, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7488\n",
      "Loss: tensor(0.0960, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7489\n",
      "Loss: tensor(0.0960, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7490\n",
      "Loss: tensor(0.0960, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7491\n",
      "Loss: tensor(0.0960, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7492\n",
      "Loss: tensor(0.0960, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7493\n",
      "Loss: tensor(0.0960, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7494\n",
      "Loss: tensor(0.0960, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7495\n",
      "Loss: tensor(0.0960, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7496\n",
      "Loss: tensor(0.0960, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7497\n",
      "Loss: tensor(0.0960, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7498\n",
      "Loss: tensor(0.0960, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7499\n",
      "Loss: tensor(0.0960, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7500\n",
      "Loss: tensor(0.0960, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7501\n",
      "Loss: tensor(0.0960, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7502\n",
      "Loss: tensor(0.0960, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7503\n",
      "Loss: tensor(0.0960, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7504\n",
      "Loss: tensor(0.0960, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7505\n",
      "Loss: tensor(0.0960, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7506\n",
      "Loss: tensor(0.0960, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7507\n",
      "Loss: tensor(0.0960, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7508\n",
      "Loss: tensor(0.0960, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7509\n",
      "Loss: tensor(0.0960, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7510\n",
      "Loss: tensor(0.0960, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7511\n",
      "Loss: tensor(0.0960, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7512\n",
      "Loss: tensor(0.0960, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7513\n",
      "Loss: tensor(0.0960, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7514\n",
      "Loss: tensor(0.0960, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7515\n",
      "Loss: tensor(0.0960, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7516\n",
      "Loss: tensor(0.0960, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7517\n",
      "Loss: tensor(0.0960, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7518\n",
      "Loss: tensor(0.0960, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7519\n",
      "Loss: tensor(0.0960, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7520\n",
      "Loss: tensor(0.0960, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7521\n",
      "Loss: tensor(0.0960, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7522\n",
      "Loss: tensor(0.0960, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7523\n",
      "Loss: tensor(0.0960, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7524\n",
      "Loss: tensor(0.0960, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7525\n",
      "Loss: tensor(0.0960, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7526\n",
      "Loss: tensor(0.0960, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7527\n",
      "Loss: tensor(0.0960, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7528\n",
      "Loss: tensor(0.0960, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7529\n",
      "Loss: tensor(0.0960, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7530\n",
      "Loss: tensor(0.0960, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7531\n",
      "Loss: tensor(0.0960, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7532\n",
      "Loss: tensor(0.0960, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7533\n",
      "Loss: tensor(0.0960, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7534\n",
      "Loss: tensor(0.0960, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7535\n",
      "Loss: tensor(0.0960, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7536\n",
      "Loss: tensor(0.0960, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7537\n",
      "Loss: tensor(0.0960, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7538\n",
      "Loss: tensor(0.0960, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7539\n",
      "Loss: tensor(0.0960, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7540\n",
      "Loss: tensor(0.0960, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7541\n",
      "Loss: tensor(0.0960, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7542\n",
      "Loss: tensor(0.0960, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7543\n",
      "Loss: tensor(0.0960, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7544\n",
      "Loss: tensor(0.0960, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7545\n",
      "Loss: tensor(0.0960, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7546\n",
      "Loss: tensor(0.0960, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7547\n",
      "Loss: tensor(0.0960, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7548\n",
      "Loss: tensor(0.0960, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7549\n",
      "Loss: tensor(0.0960, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7550\n",
      "Loss: tensor(0.0960, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7551\n",
      "Loss: tensor(0.0960, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7552\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7553\n",
      "Loss: tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7554\n",
      "Loss: tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7555\n",
      "Loss: tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7556\n",
      "Loss: tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7557\n",
      "Loss: tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7558\n",
      "Loss: tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7559\n",
      "Loss: tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7560\n",
      "Loss: tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7561\n",
      "Loss: tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7562\n",
      "Loss: tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7563\n",
      "Loss: tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7564\n",
      "Loss: tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7565\n",
      "Loss: tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7566\n",
      "Loss: tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7567\n",
      "Loss: tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7568\n",
      "Loss: tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7569\n",
      "Loss: tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7570\n",
      "Loss: tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7571\n",
      "Loss: tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7572\n",
      "Loss: tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7573\n",
      "Loss: tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7574\n",
      "Loss: tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7575\n",
      "Loss: tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7576\n",
      "Loss: tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7577\n",
      "Loss: tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7578\n",
      "Loss: tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7579\n",
      "Loss: tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7580\n",
      "Loss: tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7581\n",
      "Loss: tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7582\n",
      "Loss: tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7583\n",
      "Loss: tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7584\n",
      "Loss: tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7585\n",
      "Loss: tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7586\n",
      "Loss: tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7587\n",
      "Loss: tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7588\n",
      "Loss: tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7589\n",
      "Loss: tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7590\n",
      "Loss: tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7591\n",
      "Loss: tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7592\n",
      "Loss: tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7593\n",
      "Loss: tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7594\n",
      "Loss: tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7595\n",
      "Loss: tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7596\n",
      "Loss: tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7597\n",
      "Loss: tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7598\n",
      "Loss: tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7599\n",
      "Loss: tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7600\n",
      "Loss: tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7601\n",
      "Loss: tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7602\n",
      "Loss: tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7603\n",
      "Loss: tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7604\n",
      "Loss: tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7605\n",
      "Loss: tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7606\n",
      "Loss: tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7607\n",
      "Loss: tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7608\n",
      "Loss: tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7609\n",
      "Loss: tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7610\n",
      "Loss: tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7611\n",
      "Loss: tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7612\n",
      "Loss: tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7613\n",
      "Loss: tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7614\n",
      "Loss: tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7615\n",
      "Loss: tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7616\n",
      "Loss: tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7617\n",
      "Loss: tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7618\n",
      "Loss: tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7619\n",
      "Loss: tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7620\n",
      "Loss: tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7621\n",
      "Loss: tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7622\n",
      "Loss: tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7623\n",
      "Loss: tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7624\n",
      "Loss: tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7625\n",
      "Loss: tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7626\n",
      "Loss: tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7627\n",
      "Loss: tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7628\n",
      "Loss: tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7629\n",
      "Loss: tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7630\n",
      "Loss: tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7631\n",
      "Loss: tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7632\n",
      "Loss: tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7633\n",
      "Loss: tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7634\n",
      "Loss: tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7635\n",
      "Loss: tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7636\n",
      "Loss: tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7637\n",
      "Loss: tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7638\n",
      "Loss: tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7639\n",
      "Loss: tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7640\n",
      "Loss: tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7641\n",
      "Loss: tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7642\n",
      "Loss: tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7643\n",
      "Loss: tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7644\n",
      "Loss: tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7645\n",
      "Loss: tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7646\n",
      "Loss: tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7647\n",
      "Loss: tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7648\n",
      "Loss: tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7649\n",
      "Loss: tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7650\n",
      "Loss: tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7651\n",
      "Loss: tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7652\n",
      "Loss: tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7653\n",
      "Loss: tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7654\n",
      "Loss: tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7655\n",
      "Loss: tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7656\n",
      "Loss: tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7657\n",
      "Loss: tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7658\n",
      "Loss: tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7659\n",
      "Loss: tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7660\n",
      "Loss: tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7661\n",
      "Loss: tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7662\n",
      "Loss: tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7663\n",
      "Loss: tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7664\n",
      "Loss: tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7665\n",
      "Loss: tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7666\n",
      "Loss: tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7667\n",
      "Loss: tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7668\n",
      "Loss: tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7669\n",
      "Loss: tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7670\n",
      "Loss: tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7671\n",
      "Loss: tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7672\n",
      "Loss: tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7673\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7674\n",
      "Loss: tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7675\n",
      "Loss: tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7676\n",
      "Loss: tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7677\n",
      "Loss: tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7678\n",
      "Loss: tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7679\n",
      "Loss: tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7680\n",
      "Loss: tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7681\n",
      "Loss: tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7682\n",
      "Loss: tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7683\n",
      "Loss: tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7684\n",
      "Loss: tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7685\n",
      "Loss: tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7686\n",
      "Loss: tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7687\n",
      "Loss: tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7688\n",
      "Loss: tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7689\n",
      "Loss: tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7690\n",
      "Loss: tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7691\n",
      "Loss: tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7692\n",
      "Loss: tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7693\n",
      "Loss: tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7694\n",
      "Loss: tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7695\n",
      "Loss: tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7696\n",
      "Loss: tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7697\n",
      "Loss: tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7698\n",
      "Loss: tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7699\n",
      "Loss: tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7700\n",
      "Loss: tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7701\n",
      "Loss: tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7702\n",
      "Loss: tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7703\n",
      "Loss: tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7704\n",
      "Loss: tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7705\n",
      "Loss: tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7706\n",
      "Loss: tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7707\n",
      "Loss: tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7708\n",
      "Loss: tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7709\n",
      "Loss: tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7710\n",
      "Loss: tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7711\n",
      "Loss: tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7712\n",
      "Loss: tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7713\n",
      "Loss: tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7714\n",
      "Loss: tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7715\n",
      "Loss: tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7716\n",
      "Loss: tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7717\n",
      "Loss: tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7718\n",
      "Loss: tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7719\n",
      "Loss: tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7720\n",
      "Loss: tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7721\n",
      "Loss: tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7722\n",
      "Loss: tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7723\n",
      "Loss: tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7724\n",
      "Loss: tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7725\n",
      "Loss: tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7726\n",
      "Loss: tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7727\n",
      "Loss: tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7728\n",
      "Loss: tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7729\n",
      "Loss: tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7730\n",
      "Loss: tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7731\n",
      "Loss: tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7732\n",
      "Loss: tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7733\n",
      "Loss: tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7734\n",
      "Loss: tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7735\n",
      "Loss: tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7736\n",
      "Loss: tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7737\n",
      "Loss: tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7738\n",
      "Loss: tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7739\n",
      "Loss: tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7740\n",
      "Loss: tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7741\n",
      "Loss: tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7742\n",
      "Loss: tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7743\n",
      "Loss: tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7744\n",
      "Loss: tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7745\n",
      "Loss: tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7746\n",
      "Loss: tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7747\n",
      "Loss: tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7748\n",
      "Loss: tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7749\n",
      "Loss: tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7750\n",
      "Loss: tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7751\n",
      "Loss: tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7752\n",
      "Loss: tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7753\n",
      "Loss: tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7754\n",
      "Loss: tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7755\n",
      "Loss: tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7756\n",
      "Loss: tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7757\n",
      "Loss: tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7758\n",
      "Loss: tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7759\n",
      "Loss: tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7760\n",
      "Loss: tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7761\n",
      "Loss: tensor(0.0958, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7762\n",
      "Loss: tensor(0.0958, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7763\n",
      "Loss: tensor(0.0958, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7764\n",
      "Loss: tensor(0.0958, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7765\n",
      "Loss: tensor(0.0958, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7766\n",
      "Loss: tensor(0.0958, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7767\n",
      "Loss: tensor(0.0958, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7768\n",
      "Loss: tensor(0.0958, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7769\n",
      "Loss: tensor(0.0958, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7770\n",
      "Loss: tensor(0.0958, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7771\n",
      "Loss: tensor(0.0958, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7772\n",
      "Loss: tensor(0.0958, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7773\n",
      "Loss: tensor(0.0958, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7774\n",
      "Loss: tensor(0.0958, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7775\n",
      "Loss: tensor(0.0958, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7776\n",
      "Loss: tensor(0.0958, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7777\n",
      "Loss: tensor(0.0958, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7778\n",
      "Loss: tensor(0.0958, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7779\n",
      "Loss: tensor(0.0958, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7780\n",
      "Loss: tensor(0.0958, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7781\n",
      "Loss: tensor(0.0958, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7782\n",
      "Loss: tensor(0.0958, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7783\n",
      "Loss: tensor(0.0958, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7784\n",
      "Loss: tensor(0.0958, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7785\n",
      "Loss: tensor(0.0958, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7786\n",
      "Loss: tensor(0.0958, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7787\n",
      "Loss: tensor(0.0958, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7788\n",
      "Loss: tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7789\n",
      "Loss: tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7790\n",
      "Loss: tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7791\n",
      "Loss: tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7792\n",
      "Loss: tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7793\n",
      "Loss: tensor(0.0958, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7794\n",
      "Loss: tensor(0.0958, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7795\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor(0.0958, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7796\n",
      "Loss: tensor(0.0958, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7797\n",
      "Loss: tensor(0.0958, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7798\n",
      "Loss: tensor(0.0958, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7799\n",
      "Loss: tensor(0.0958, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7800\n",
      "Loss: tensor(0.0958, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7801\n",
      "Loss: tensor(0.0958, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7802\n",
      "Loss: tensor(0.0958, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7803\n",
      "Loss: tensor(0.0958, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7804\n",
      "Loss: tensor(0.0958, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7805\n",
      "Loss: tensor(0.0958, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7806\n",
      "Loss: tensor(0.0958, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7807\n",
      "Loss: tensor(0.0958, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7808\n",
      "Loss: tensor(0.0958, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7809\n",
      "Loss: tensor(0.0958, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7810\n",
      "Loss: tensor(0.0958, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7811\n",
      "Loss: tensor(0.0958, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7812\n",
      "Loss: tensor(0.0958, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7813\n",
      "Loss: tensor(0.0958, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7814\n",
      "Loss: tensor(0.0958, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7815\n",
      "Loss: tensor(0.0958, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7816\n",
      "Loss: tensor(0.0958, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7817\n",
      "Loss: tensor(0.0958, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7818\n",
      "Loss: tensor(0.0958, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7819\n",
      "Loss: tensor(0.0958, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7820\n",
      "Loss: tensor(0.0958, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7821\n",
      "Loss: tensor(0.0958, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7822\n",
      "Loss: tensor(0.0958, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7823\n",
      "Loss: tensor(0.0958, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7824\n",
      "Loss: tensor(0.0958, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7825\n",
      "Loss: tensor(0.0958, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7826\n",
      "Loss: tensor(0.0958, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7827\n",
      "Loss: tensor(0.0958, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7828\n",
      "Loss: tensor(0.0958, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7829\n",
      "Loss: tensor(0.0958, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7830\n",
      "Loss: tensor(0.0958, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7831\n",
      "Loss: tensor(0.0958, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7832\n",
      "Loss: tensor(0.0958, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7833\n",
      "Loss: tensor(0.0958, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7834\n",
      "Loss: tensor(0.0958, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7835\n",
      "Loss: tensor(0.0958, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7836\n",
      "Loss: tensor(0.0958, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7837\n",
      "Loss: tensor(0.0958, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7838\n",
      "Loss: tensor(0.0958, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7839\n",
      "Loss: tensor(0.0958, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7840\n",
      "Loss: tensor(0.0958, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7841\n",
      "Loss: tensor(0.0958, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7842\n",
      "Loss: tensor(0.0958, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7843\n",
      "Loss: tensor(0.0958, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7844\n",
      "Loss: tensor(0.0958, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7845\n",
      "Loss: tensor(0.0958, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7846\n",
      "Loss: tensor(0.0958, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7847\n",
      "Loss: tensor(0.0958, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7848\n",
      "Loss: tensor(0.0958, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7849\n",
      "Loss: tensor(0.0958, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7850\n",
      "Loss: tensor(0.0958, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7851\n",
      "Loss: tensor(0.0958, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7852\n",
      "Loss: tensor(0.0958, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7853\n",
      "Loss: tensor(0.0958, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7854\n",
      "Loss: tensor(0.0958, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7855\n",
      "Loss: tensor(0.0958, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7856\n",
      "Loss: tensor(0.0958, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7857\n",
      "Loss: tensor(0.0958, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7858\n",
      "Loss: tensor(0.0958, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7859\n",
      "Loss: tensor(0.0958, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7860\n",
      "Loss: tensor(0.0958, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7861\n",
      "Loss: tensor(0.0958, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7862\n",
      "Loss: tensor(0.0958, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7863\n",
      "Loss: tensor(0.0958, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7864\n",
      "Loss: tensor(0.0958, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7865\n",
      "Loss: tensor(0.0958, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7866\n",
      "Loss: tensor(0.0958, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7867\n",
      "Loss: tensor(0.0958, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7868\n",
      "Loss: tensor(0.0958, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7869\n",
      "Loss: tensor(0.0958, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7870\n",
      "Loss: tensor(0.0958, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7871\n",
      "Loss: tensor(0.0958, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7872\n",
      "Loss: tensor(0.0958, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7873\n",
      "Loss: tensor(0.0958, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7874\n",
      "Loss: tensor(0.0958, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7875\n",
      "Loss: tensor(0.0958, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7876\n",
      "Loss: tensor(0.0958, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7877\n",
      "Loss: tensor(0.0958, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7878\n",
      "Loss: tensor(0.0958, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7879\n",
      "Loss: tensor(0.0958, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7880\n",
      "Loss: tensor(0.0958, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7881\n",
      "Loss: tensor(0.0958, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7882\n",
      "Loss: tensor(0.0958, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7883\n",
      "Loss: tensor(0.0958, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7884\n",
      "Loss: tensor(0.0958, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7885\n",
      "Loss: tensor(0.0958, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7886\n",
      "Loss: tensor(0.0958, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7887\n",
      "Loss: tensor(0.0958, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7888\n",
      "Loss: tensor(0.0958, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7889\n",
      "Loss: tensor(0.0958, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7890\n",
      "Loss: tensor(0.0958, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7891\n",
      "Loss: tensor(0.0958, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7892\n",
      "Loss: tensor(0.0958, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7893\n",
      "Loss: tensor(0.0958, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7894\n",
      "Loss: tensor(0.0958, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7895\n",
      "Loss: tensor(0.0958, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7896\n",
      "Loss: tensor(0.0958, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7897\n",
      "Loss: tensor(0.0958, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7898\n",
      "Loss: tensor(0.0958, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7899\n",
      "Loss: tensor(0.0958, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7900\n",
      "Loss: tensor(0.0958, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7901\n",
      "Loss: tensor(0.0958, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7902\n",
      "Loss: tensor(0.0958, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7903\n",
      "Loss: tensor(0.0958, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7904\n",
      "Loss: tensor(0.0958, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7905\n",
      "Loss: tensor(0.0958, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7906\n",
      "Loss: tensor(0.0958, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7907\n",
      "Loss: tensor(0.0958, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7908\n",
      "Loss: tensor(0.0958, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7909\n",
      "Loss: tensor(0.0958, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7910\n",
      "Loss: tensor(0.0958, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7911\n",
      "Loss: tensor(0.0958, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7912\n",
      "Loss: tensor(0.0958, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7913\n",
      "Loss: tensor(0.0958, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7914\n",
      "Loss: tensor(0.0958, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7915\n",
      "Loss: tensor(0.0958, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7916\n",
      "Loss: tensor(0.0958, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7917\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor(0.0958, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7918\n",
      "Loss: tensor(0.0958, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7919\n",
      "Loss: tensor(0.0958, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7920\n",
      "Loss: tensor(0.0958, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7921\n",
      "Loss: tensor(0.0958, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7922\n",
      "Loss: tensor(0.0958, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7923\n",
      "Loss: tensor(0.0958, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7924\n",
      "Loss: tensor(0.0958, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7925\n",
      "Loss: tensor(0.0958, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7926\n",
      "Loss: tensor(0.0958, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7927\n",
      "Loss: tensor(0.0958, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7928\n",
      "Loss: tensor(0.0958, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7929\n",
      "Loss: tensor(0.0958, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7930\n",
      "Loss: tensor(0.0958, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7931\n",
      "Loss: tensor(0.0958, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7932\n",
      "Loss: tensor(0.0958, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7933\n",
      "Loss: tensor(0.0958, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7934\n",
      "Loss: tensor(0.0958, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7935\n",
      "Loss: tensor(0.0958, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7936\n",
      "Loss: tensor(0.0958, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7937\n",
      "Loss: tensor(0.0958, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7938\n",
      "Loss: tensor(0.0958, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7939\n",
      "Loss: tensor(0.0958, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7940\n",
      "Loss: tensor(0.0958, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7941\n",
      "Loss: tensor(0.0958, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7942\n",
      "Loss: tensor(0.0958, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7943\n",
      "Loss: tensor(0.0958, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7944\n",
      "Loss: tensor(0.0958, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7945\n",
      "Loss: tensor(0.0958, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7946\n",
      "Loss: tensor(0.0958, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7947\n",
      "Loss: tensor(0.0958, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7948\n",
      "Loss: tensor(0.0958, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7949\n",
      "Loss: tensor(0.0958, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7950\n",
      "Loss: tensor(0.0958, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7951\n",
      "Loss: tensor(0.0958, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7952\n",
      "Loss: tensor(0.0958, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7953\n",
      "Loss: tensor(0.0958, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7954\n",
      "Loss: tensor(0.0958, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7955\n",
      "Loss: tensor(0.0958, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7956\n",
      "Loss: tensor(0.0958, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7957\n",
      "Loss: tensor(0.0958, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7958\n",
      "Loss: tensor(0.0958, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7959\n",
      "Loss: tensor(0.0958, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7960\n",
      "Loss: tensor(0.0958, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7961\n",
      "Loss: tensor(0.0958, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7962\n",
      "Loss: tensor(0.0958, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7963\n",
      "Loss: tensor(0.0958, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7964\n",
      "Loss: tensor(0.0958, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7965\n",
      "Loss: tensor(0.0958, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7966\n",
      "Loss: tensor(0.0958, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7967\n",
      "Loss: tensor(0.0958, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7968\n",
      "Loss: tensor(0.0958, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7969\n",
      "Loss: tensor(0.0957, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7970\n",
      "Loss: tensor(0.0957, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7971\n",
      "Loss: tensor(0.0957, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7972\n",
      "Loss: tensor(0.0957, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7973\n",
      "Loss: tensor(0.0957, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7974\n",
      "Loss: tensor(0.0957, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7975\n",
      "Loss: tensor(0.0957, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7976\n",
      "Loss: tensor(0.0957, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7977\n",
      "Loss: tensor(0.0957, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7978\n",
      "Loss: tensor(0.0957, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7979\n",
      "Loss: tensor(0.0957, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7980\n",
      "Loss: tensor(0.0957, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7981\n",
      "Loss: tensor(0.0957, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7982\n",
      "Loss: tensor(0.0957, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7983\n",
      "Loss: tensor(0.0957, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7984\n",
      "Loss: tensor(0.0957, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7985\n",
      "Loss: tensor(0.0957, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7986\n",
      "Loss: tensor(0.0957, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7987\n",
      "Loss: tensor(0.0957, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7988\n",
      "Loss: tensor(0.0957, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7989\n",
      "Loss: tensor(0.0957, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7990\n",
      "Loss: tensor(0.0957, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7991\n",
      "Loss: tensor(0.0957, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7992\n",
      "Loss: tensor(0.0957, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7993\n",
      "Loss: tensor(0.0957, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7994\n",
      "Loss: tensor(0.0957, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7995\n",
      "Loss: tensor(0.0957, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7996\n",
      "Loss: tensor(0.0957, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7997\n",
      "Loss: tensor(0.0957, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7998\n",
      "Loss: tensor(0.0957, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7999\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1000):  \n",
    "        \n",
    "    optimizer.zero_grad()   # zero the gradient buffers\n",
    "    output = net(input.float())\n",
    "\n",
    "    loss = criterion(output, targets)\n",
    "    print('Loss:', loss, ' at epoch:', epoch)\n",
    "\n",
    "    loss.backward()  #backprop\n",
    "    optimizer.step()    # Does the update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'PATH' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-32b36623c260>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m#PATH = SavesDirectory+'Tanh_MSE_adam4801.pth'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mPATH\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;31m# more on saving pytorch networks: https://pytorch.org/docs/stable/notes/serialization.html\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'PATH' is not defined"
     ]
    }
   ],
   "source": [
    "#save the FCNN model\n",
    "\n",
    "stage='NNetwork/'\n",
    "SavesDirectory='./TunedModels/'+model_class+'/'+model_version+\"/\"+stage\n",
    "#PATH = SavesDirectory+'Tanh_MSE_adam4801.pth'\n",
    "\n",
    "torch.save(net.state_dict(), PATH)\n",
    "\n",
    "# more on saving pytorch networks: https://pytorch.org/docs/stable/notes/serialization.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load previously saved FCNN model \n",
    "\n",
    "stage='NNetwork/'\n",
    "SavesDirectory='./TunedModels/'+model_class+'/'+model_version+\"/\"+stage\n",
    "PATH = SavesDirectory+'Tanh_MSE_adam4801.pth'\n",
    "\n",
    "net = Net()\n",
    "net.load_state_dict(torch.load(PATH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 3 4 4 3 1 4 2 2 1 3 4 4 5 3 5 1 5 3 3 5 1 5 4 3 2 4 1 3 1 4 1 1 3 5 3 4 4 5 4 3 5 4 4 5 5 3 2 5 1 5 4 3 1 4 3 3 3 1 2 1 4 5 1 2 3 4 5 4 3 4 3 2 1 5 4 4 3 3 5 3 3 4 3 3 3 3 5 1 1 3 3 3 0 0 1 4 2 3 1 1 4 4 4 4 2 4 3 5 3 4 4 1 1 4 3 2 3 4 3 4 3 5 5 0 3 3 3 1 1 3 3 1 5 4 1 1 1 4 1 1 2 1 3 3 3 4 3 5 2 2 3 1 5 2 1 3 3 4 1 5 4 3 1 1 0 1 2 3 3 3 5 4 4 1 5 5 5 0 3 4 2 3 4 3 2 3 2 4 3 1 2 3 4 4 5 2 4 3 3 2 2 0 5 1 1 1 4 2 2 3 0 0 0 1 3 2 4 4 5 3 3 3 3 1 2 0 3 0 3 1 4 1 1 2 3 5 5 5 2 1 5 3 3 3 1 3 4 4 3 3 3 4 3 2 3 3 5 5 4 2 0 5 4 1 1 5 3 4 1 5 3 4 1 5 0 0 0 3 5 3 0 2 1 1 3 4 3 4 2 4 2 4 4 2 1 3 1 1 1 4 1 1 3 1 4 3 4 4 1 0 0 0 1 4 4 5 5 3 0 3 1 4 1 5 1 1 5 2 1 3 1 1 3 2 1 1 5 3 2 4 4 4 4 4 1 4 3 2 3 3 3 2 5 3 0 1 3 5 2 0 4 4 4 4 4 4 4 4 3 4 1 1 5 4 1 1 1 5 4 2 3 1 3 1 3 4 3 2 1 5 1 0 0 1 4 1 4 4 4 1 4 5 0 3 3 3 2 4 4 3 3 3 3 3 2 3 5 3 3 4 1 4 3 3 0 4 1 1 5 3 3 1 0 3 4 1 0 3 2 2 1 2 4 4 5 5 4 1 1 1 3 1 3 3 1 1 1 3 1 0 2 0 1 1 2 5 3 1 1 1 1 0 1 1 4 4 3 2 3 2 1 3 2 4 3 3 0 4 1 4 1 1 1 4 1 1 3 3 3 3 1 4 4 3 4 4 3 1 2 1 0 3 2 5 3 4 3 2 4 4 3 1 1 5 1 1 1 3 1 2 4 1 4 1 5 1 1 2 2 1 1 1 2 1 0 3 0 0 1 0 1 4 1 4 4 1 2 1 1 3 3 3 2 4 3 4 4 2 4 1 2 5 5 4 4 1 3 5 4 2 4 1 4 4 3 3 5 1 1 2 1 2 2 3 1 1 3 1 1 1 3 4 4 1 4 1 3 4 2 1 5 1 1 4 2 1 1 3 3 5 2 3 3 1 2 2 1 2 0 1 5 1 3 1 0 4 4 2 4 1 3 4 1 3 2 3 1 5 1 1 1 4 1 2 3 2 4 4 2 1 1 5 1 3 4 4 5 0 0 5 1 3 5 1 3 3 5 1 3 3 1 5 1 4 4 3 5 1 2 1 5 5 0 4 4 2 3 1 1 0 3 5 5 5 5 3 4 1 1 0 1 1 2 1 3 4 1 3 1 1 4 1 3 1 1 2 0 1 0 1 4 2 1 5 1 1 3 1 2 1 1 2 5 3 3 3 3 1 3 5 1 5 2 2 1 4 1 4 4 1 1 5 4 4 1 2 1 4 1 4 1 1 5 0 0 0 3 1 4 4 2 1 2 2 3 1 4 1 1 3 3 1 3 4 4 0 4 4 4 4 0 1 0 4 3 4 1 0 3 4 4 5 1 5 1 1 1 1 1 1 1 1 2 3 2 5 4 1 5 1 1 3 0 4 2 3 1 2 5 3 1 1 3 3 2 3 1 4 0 1 1 1 2 2 2 4 1 4 1 1 1 4 1 1 0 1 1 2 1 1 3 4 2 1 1 4 4 4 1 4 1 3 1 3 1 1 1 2 3 4 3 5 1 2 2 1 4 4 4 3 2 4 2 5 1 3 1 1 5 5 3 1 0 0 3 4 3 4 4 3 1 0 2 3 3 1 5 3 2 5 1 1 1 4 0 3 1 3 0 3 1 3 1 2 3 3 3 1 3 3 3 2 4 1 3 5 1 5 1 1 5 3 0 1 1 4 3 2 0 5 0 0 1 0 4 4 3 5 1 3 3 5 3 5 4 1 1 3 4 1 1 3 1 3 3 4 3 3 1 1 2 1 2 2 5 1 3 5 2 4 4 1 3 3 1 2 5 3 0 4 1 3 4 2 1 3 4 1 1 1 5 4 4 1 1 4 0 0 5 5 1 1 1 4 1 4 2 4 1 3 4 3 4 3 5 3 0 1 1 5 3 1 1 1 3 3 3 4 3 1 3 3 1 3 4 3 5 1 1 1 1 1 2 3 3 2 3 1 1 3 4 2 3 1 2 3 3 3 3 1 4 2 1 1 1 2 1 3 1 4 3 3 1 3 3 2 2 3 3 2 3 1 5 5 0 3 3 4 5 5 3 3 3 3 5 3 4 4 1 3 2 3 1 1 2 4 3 5 5 3 1 5 3 2 5 3 1 0 1 4 1 2 3 4 0 2 2 5 2 3 3 2 3 3 1 3 5 0 3 3 3 5 3 1 2 2 4 3 2 1 1 1 2 2 5 3 2 3 1 1 2 1 1 5 1 2 2 3 1 3 2 3 4 3 2 2 3 1 3 3 3 1 5 5 4 3 5 4 5 3 4 1 1 1 4 4 4 2 1 5 3 1 0 1 3 5 4 2 5 3 1 5 2 1 3 1 1 3 5 3 3 4 3 1 1 3 1 3 3 1 1 3 5 3 4 2 1 1 4 5 1 1 1 4 5 5 5 5 1 4 1 3 1 1 4 1 1 5 5 4 1 1 3 4 1 1 1 4 2 5 1 4 4 5 3 0 1 1 1 1 1 5 4 2 3 3 2 2 4 1 5 1 2 1 4 2 4 3 3 4 0 2 5 3 3 3 3 5 5 3 3 2 3 3 3 4 2 4 1 1 1 2 5 4 2 4 1 1 2 2 2 1 4 3 4 5 5 4 3 4 2 3 3 3 0 3 0 3 2 3 3 3 4 1 3 2 1 5 3 5 4 0 3 5 2 5 3 0 1 0 5 3 1 3 2 3 3 1 3 4 2 3 3 1 0 2 3 4 1 3 1 5 4 1 1 0 1 3 3 1 2 2 5 4 1 2 2 2 1 4 0 5 1 1 1 1 3 3 4 4 3 1 3 5 1 5 5 2 1 3 5 3 2 2 5 4 4 4 4 2 1 4 0 0 0 3 2 1 1 3 2 2 3 1 5 5 5 1 0 1 0 4 4 4 3 1 1 2 1 2 4 5 5 4 2 2 3 3 5 2 5 0 1 2 1 3 3 4 3 5 2 1 3 2 3 3 5 2 2 2 2 1 3 3 1 2 3 5 3 3 1 1 1 5 4 2 2 4 4 2 5 5 1 2 3 2 4 3 2 4 5 5 1 1 5 2 3 4 1 3 3 3 1 3 5 5 5 4 1 0 5 3 3 2 2 3 3 5 2 1 2 4 4 5 3 1 3 1 5 3 4 1 0 5 1 4 3 3 1 5 0 0 2 1 2 4 2 3 3 3 3 2 5 2 3 1 0 1 3 0 4 1 0 3 1 1 3 2 3 3 5 0 2 1 2 5 4 2 1 1 3 5 5 3 1 5 0 4 2 3 0 1 2 4 2 5 4 4 4 4 3 4 1 2 5 4 4 3 4 1 3 4 2 1 2 1 5 5 4 2 2 1 5 1 1 1 4 0 1 3 4 3 2 2 5 1 5 4 2 2 5 2 3 3 5 1 1 5 5 1 2 3 3 4 4 5 5 3 5 2 5 2 2 1 1 5 2 2 5 0 0 1 2 2 3 4 4 3 1 3 4 1 3 1 5 3 5 4 1 3 0 2 4 1 3 2 3 2 3 5 1 3 1 4 3 3 0 3 5 3 1 5 4 2 3 1 4 2 1 4 5 1 5 5 3 2 1 2 1 2 2 3 2 1 2 3 2 3 2 3 3 3 3 2 4 2 5 0 2 3 1 3 3 4 3 3 4 5 4 3 1 3 3 2 3 5 2 3 2 4 3 3 2 1 3 3 4 1 2 1 1 3 1 1 4 4 3 1 3 2 3 1 5 2 3 1 2 3 5 3 0 2 4 4 5 3 5 3 0 1 0 3 1 2 1 1 2 1 1 1 1 1 2 4 3 2 2 4 0 5 1 3 1 3 2 1 4 2 1 1 1 0 2 1 4 2 1 5 3 2 4 3 3 1 3 1 1 1 3 4 3 4 1 2 1 3 3 2 5 4 4 3 3 3 4 2 0 3 5 1 0 4 2 3 1 2 2 3 2 2 5 5 3 1 2 2 2 0 3 1 5 2 0 5 1 3 1 4 4 2 0 3 5 3 3 3 3 3 1 4 3 2 0 3 1 4 3 3 2 2 1 3 3 2 1 4 1 3 3 5 1 3 4 3 3 3 3 5 1 1 4 3 5 3 5 2 2 2 2 0 5 1 1 2 2 0 1 3 1 5 4 3 2 3 3 3 1 0 4 0 1 3 5 3 1 0 2 3 3 2 2 2 5 3 2 1 1 3 4 1 3 0 2 3 4 1 3 3 1 2 3 3 3 1 1 1 4 4 2 2 1 1 4 1 0 5 3 3 1 0 4 2 3 5 1 2 4 2 3 1 2 4 4 5 3 5 0 5 5 0 1 3 4 4 1 5 1 5 1 5 4 5 5 2 5 5 2 2 3 3 5 4 1 1 4 3 3 1 1 4 3 2 1 5 3 3 2 4 4 1 5 3 3 4 0 4 2 1 4 5 5 1 5 4 4 3 1 3 3 1 1 5 1 3 3 1 5 5 3 0 1 4 1 4 4 2 5 4 3 5 5 3 1 3 4 3 4 0 0 1 4 2 3 4 4 4 2 4 1 4 2 5 4 1 4 1 1 4 1 4 3 4 5 0 4 4 4 5 1 1 2 2 3 0 1 5 1 1 5 1 4 4 4 5 1 2 5 1 3 5 3 4 4 4 5 5 3 1 4 2 5 5 1 5 3 4 0 5 1 5 5 1 1 5 2 4 1 5 1 2 1 1 5 2 1 5 3 4 3 2 5 4 4 2 1 4 4 0 1 1 5 1 1 4 1 2 3 0 5 3 1 4 5 5 1 4 4 3 5 4 1 4 1 2 2 4 4 4 4 3 1 1 1 4 3 4 3 5 5 2 3 4 1 4 1 4 2 5 3 1 1 1 5 3 4 4 4 1 2 4 2 1 1 3 2 5 1 4 0 1 4 3 1 1 3 3 1 1 5 5 1 5 2 3 3 0 4 3 4 5 5 3 4 1 1 4 3 2 0 1 3 4 5 4 4 5 5 4 3 1 5 1 5 4 3 4 1 4 2 4 0 4 3 1 3 1 3 1 2 3 2 3 4 2 5 2 3 4 1 3 3 2 1 1 1 1 1 1 3 3 0 5 1 4 2 2 5 1 3 2 5 4 4 1 3 3 3 1 1 4 4 1 3 3 1 2 1 4 1 0 4 4 4 5 5 1 0 1 2 3 4 2 5 1 4 4 1 5 3 5 1 3 0 4 5 1 1 3 4 4 5 1 2 1 4 4 3 5 3 5 1 4 4 1 1 3 4 5 1 4 1 3 0 3 1 1 2 2 4 5 0 1 5 5 0 2 3 2 2 4 4 2 1 0 4 5 4 1 2 1 4 5 5 1 5 4 4 1 1 3 3 4 4 1 4 2 1 4 4 3 4 4 5 2 1 1 2 3 1 5 4 4 3 3 4 2 5 1 3 5 2 3 3 3 2 3 3 1 4 3 1 5 1 3 4 1 5 1 5 1 0 5 5 2 4 0 4 1 4 1 4 4 2 3 1 3 1 4 3 3 2 1 3 4 3 1 5 4 1 5 3 4 3 5 1 4 4 3 4 0 5 2 3 5 3 4 4 3 1 3 1 5 4 3 3 5 3 4 3 1 4 1 1 0 4 4 5 5 4 4 3 3 2 3 0 1 4 0 1 1 4 1 1 4 3 1 1 3 1 1 1 1 2 4 3 0 3 3 4 3 4 4 1 5 3 4 4 2 3 5 5 1 4 1 1 3 5 3 5 3 2 1 3 4 5 1 1 5 0 1 2 1 1 4 1 4 1 3 5 5 4 5 3 5 1 4 3 2 1 3 1 5 0 1 4 4 4 3 1 5 3 2 1 3 3 4 0 4 4 2 3 3 4 1 1 2 1 2 2 5 3 2 1 1 3 4 2 4 4 4 4 3 4 5 2 4 3 3 5 4 4 1 5 1 3 3 5 0 3 4 3 3 2 5 3 5 1 5 2 5 3 2 5 5 4 3 1 4 5 4 3 5 2 3 2 1 1 4 3 4 4 1 3 2 0 2 5 3 1 2 4 4 2 5 4 1 2 4 1 4 0 5 4 0 4 1 5 1 1 3 3 3 3 1 3 1 4 1 0 5 3 2 1 3 3 0 3 4 4 2 1 4 4 4 1 4 5 3 0 1 1 2 4 1 1 2 2 2 2 5 4 2 2 2 0 4 1 5 4 1 5 2 4 4 1 2 5 1 1 3 4 3 5 1 1 0 4 5 3 4 5 1 1 5 3 5 3 1 4 4 1 3 0 4 1 3 3 4 4 3 5 5 5 4 4 1 4 3 2 1 3 3 4 1 4 2 3 3 1 1 3 5 3 3 3 4 5 1 3 5 4 3 5 0 4 1 5 2 1 3 3 4 1 4 3 4 1 4 2 5 2 3 5 0 5 5 3 1 3 2 4 3 1 4 4 4 2 1 1 5 1 1 4 2 4 1 1 5 2 1 2 5 3 1 5 4 5 1 0 5 4 4 1 3 3 3 2 1 1 5 3 3 4 4 2 3 0 4 4 1 5 3 1 3 4 3 3 1 2 4 4 4 4 3 3 1 2 3 3 1 5 5 3 3 1 5 2 4 5 4 1 3 1 1 3 0 1 1 4 4 5 4 0 3 3 3 5 5 3 2 4 3 1 2 4 4 5 4 4 2 1 5 2 1 4 3 2 2 3 2 3 5 3 0 1 1 4 4 0 4 3 5 4 1 1 4 4 4 1 5 4 1 0 5 4 1 5 3 4 2 1 3 2 4 2 1 5 3 1 4 3 5 3 3 2 2 4 5 1 2 1 2 4 3 2 5 5 4 1 1 3 1 4 3 5 3 1 3 2 1 1 2 5 2 5 4 3 3 5 3 3 1 2 3 2 3 3 4 1 3 3 3 4 1 1 1 3 5 5 5 3 1 2 2 4 1 1 1 2 3 2 2 1 5 5 3 3 1 3 3 1 1 0 3 4 1 5 1 4 3 2 1 1 0 5 4 5 1 4 4 3 4 1 1 4 4 4 1 3 4 2 5 3 1 1 1 3 3 4 1 1 4 3 4 0 5 2 1 1 3 1 5 1 0 3 4 5 4 1 3 1 0 0 1 5 1 0 0 3 3 0 1 4 4 5 3 1 3 3 5 2 3 2 4 3 1 1 3 1 1 3 4 3 4 2 2 0 4 3 3 3 1 2 1 5 3 2 4 3 3 1 1 1 5 4 0 5 3 5 2 5 1 2 1 4 3 2 0 1 4 1 1 3 1 2 1 4 5 4 4 3 5 3 4 2 5 3 4 2 2 0 3 5 4 0 4 2 2 1 1 1 5 1 3 1 1 2 1 5 1 3 4 4 4 1 3 1 1 5 3 3 4 3 5 5 0 3 1 2 5 3 3 3 3 1 5 1 4 5 1 1 2 1 1 4 4 4 5 1 3 3 2 1 0 3 4 4 5 3 1 5 4 2 1 1 2 3 4 2 1 3 3 1 3 1 4 5 1 1 1 3 4 1 3 1 2 1 1 3 2 5 5 4 2 3 4 3 4 5 1 0 1 4 1 2 3 1 3 4 3 1 1 3 5 3 1 3 1 1 1 5 5 1 3 4 2 4 1 1 1 2 3 3 3 3 3 4 5 2 1 2 1 3 3 3 3 3 1 5 4 3 2 2 0 1 3 2 0 3 5 1 3 1 1 4 4 5 1 4 3 1 4 3 2 5 1 1 1 3 1 2 4 4 1 3 5 5 2 1 3 3 3 4 4 3 3 4 4 3 4 3 3 0 5 1 5 3 3 3 2 3 1 3 5 3 1 3 3 3 4 4 5 2 1 3 1 3 2 4 4 2 1 1 1 1 1 1 1 5 1 4 5 4 2 2 1 2 4 2 2 1 4 2 1 4 1 3 2 1 3 1 4 2 5 3 3 4 3 3 1 3 1 5 3 3 0 5 4 0 4 3 1 3 2 1 3 3 4 5 1 3 1 1 3 5 2 4 2 3 2 5 5 4 3 3 2 1 2 3 2 0 1 5 1 3 5 4 5 4 2 1 4 2 1 0 4 5 5 1 3 1 1 5 2 1 3 5 1 1 3 3 4 3 4 3 2 5 4 3 3 1 3 4 3 1 1 2 5 4 3 2 1 1 2 4 3 2 1 2 1 0 4 3 3 4 2 2 5 1 2 4 3 1 2 3 4 5 5 3 1 1 0 5 1 3 3 3 1 5 5 3 4 3 2 4 1 1 2 1 2 4 2 2 3 3 3 3 4 5 3 3 1 2 3 1 4 2 1 3 3 1 1 1 5 3 2 3 3 2 4 3 2 4 4 1 3 4 4 3 3 1 4 4 3 1 2 3 3 1 5 4 3 2 3 1 1 1 3 1 4 2 1 3 3 3 2 3 0 3 0 1 3 3 2 4 5 3 4 1 2 1 1 1 4 3 2 2 2 3 1 2 2 3 3 1 1 2 3 2 4 5 5 3 1 2 4 4 5 4 4 2 1 2 1 4 2 5 5 1 4 1 4 1 5 3 3 4 3 2 3 1 1 2 4 5 2 5 2 1 2 3 0 4 4 2 3 5 1 0 4 3 1 3 1 1 5 3 2 3 4 1 4 5 4 5 2 3 1 1 4 1 1 0 0 3 4 3 2 1 3 2 3 1 4 2 5 5 1 2 4 5 4 1 2 3 3 3 3 2 3 2 1 4 1 1 2 5 5 5 1 0 5 3 2 0 2 2 3 1 1 2 5 3 1 3 0 2 4 1 5 2 3 4 3 3 3 1 4 2 5 3 1 4 3 5 4 1 3 4 0 3 4 5 5 5 1 1 1 3 0 5 5 0 1 5 0 3 1 1 5 1 3 1 1 1 1 2 1 3 5 3 4 3 2 4 2 1 3 1 1 4 5 3 3 3 4 5 3 3 3 3 3 1 4 3 1 4 5 3 3 2 4 2 1 4 1 3 4 5 1 4 5"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 3 1 5 2 3 3 1 3 2 5 4 3 2 4 3 4 3 4 5 3 3 5 2 1 0 4 2 2 1 5 3 0 4 1 4 4 0 4 3 1 4 3 3 1 3 2 1 3 5 3 4 2 4 1 3 3 4 5 5 4 1 4 3 4 4 4 3 2 3 1 3 5 4 5 4 1 3 1 2 3 1 3 2 5 2 2 3 0 0 2 5 1 1 1 5 1 2 3 2 0 1 5 4 4 1 2 4 2 4 2 5 4 4 2 3 5 5 3 1 2 0 3 3 1 5 1 3 3 4 1 2 3 1 2 5 4 3 3 1 3 3 4 3 3 5 2 3 0 3 5 2 3 4 4 3 1 4 5 2 3 2 1 3 3 3 1 2 3 2 3 4 5 4 4 1 3 1 2 3 3 5 3 0 4 1 4 5 3 5 5 2 5 5 3 4 2 3 3 3 5 4 3 4 3 4 2 3 2 3 1 1 4 2 1 3 1 1 1 4 5 5 3 2 0 1 4 3 5 3 4 2 0 4 5 3 1 5 2 3 5 3 2 2 3 0 3 4 4 2 4 1 4 1 3 3 1 5 4 1 4 5 4 5 4 3 3 4 5 5 5 4 3 5 5 2 4 1 2 4 1 1 3 3 2 3 1 2 1 3 3 2 4 4 3 0 3 2 4 1 1 1 2 3 1 1 0 1 2 1 3 1 5 3 4 1 5 1 0 4 1 2 4 3 2 4 3 1 1 3 2 1 2 2 4 2 3 1 1 2 2 3 1 1 4 2 2 3 3 4 3 2 1 1 2 2 2 5 4 3 5 0 4 1 3 4 5 1 4 3 3 3 4 3 3 3 4 5 3 3 3 3 2 3 3 4 3 2 1 1 4 5 3 3 3 0 4 5 4 3 3 1 3 1 2 1 1 2 1 3 1 3 5 5 5 4 3 5 5 2 3 3 3 3 4 1 4 2 3 2 5 5 2 5 1 4 2 1 2 1 2 1 4 1 4 1 1 1 5 1 5 3 4 4 2 1 3 2 3 5 1 3 0 3 5 4 5 4 4 2 1 3 1 3 3 0 1 5 5 4 5 3 3 2 1 0 0 3 4 5 2 3 1 1 5 3 1 4 3 4 1 1 1 3 4 3 3 3 4 0 5 1 3 5 2 4 1 1 2 4 4 1 3 1 1 5 1 3 5 5 1 2 5 3 2 4 2 1 3 3 3 4 4 0 1 3 5 1 5 1 1 2 5 3 1 5 2 1 5 3 2 4 3 4 2 1 1 2 2 4 1 4 3 0 3 4 3 1 4 5 3 2 2 4 1 2 4 1 1 4 1 3 3 1 4 1 2 1 2 1 5 3 5 1 1 5 1 3 3 0 2 2 0 2 0 5 5 1 5 4 3 4 2 1 3 3 2 3 3 2 1 2 1 5 1 2 1 3 4 4 0 2 0 2 1 4 1 0 1 5 3 3 2 2 3 4 5 3 4 2 3 1 3 3 4 3 5 4 5 1 4 5 1 1 2 4 1 3 3 2 1 3 2 2 4 4 1 5 3 2 3 1 2 5 3 3 1 2 5 2 5 1 1 0 3 4 0 1 2 1 4 5 2 4 3 4 3 1 2 3 4 2 2 1 2 3 5 3 2 3 4 4 2 5 2 1 5 4 3 1 1 4 2 2 2 2 2 1 3 4 5 2 2 5 3 2 4 2 3 4 5 5 2 5 1 0 5 3 0 3 5 1 4 2 3 1 3 1 1 2 3 3 1 4 2 1 4 4 3 1 3 1 0 1 3 2 3 2 3 2 3 1 1 2 3 2 1 3 1 2 3 5 2 3 3 1 4 5 3 3 3 3 1 5 4 1 5 4 3 1 4 3 4 3 3 2 3 4 2 4 4 3 3 3 3 4 3 3 2 1 2 3 3 4 1 4 0 3 2 4 4 3 4 2 2 4 4 3 3 3 3 3 3 1 4 5 4 1 5 1 1 1 1 2 3 2 5 4 3 3 3 5 3 3 5 5 0 1 1 2 1 5 4 2 1 3 3 2 3 2 1 2 2 3 4 3 3 4 4 1 3 2 4 1 1 0 0 0 5 0 0 5 3 3 3 3 0 2 4 3 3 4 2 4 3 3 1 2 2 3 3 2 5 0 4 2 1 1 1 5 2 5 2 4 3 2 3 0 3 4 3 1 3 2 4 3 3 0 3 4 2 3 3 5 2 3 4 2 3 1 1 1 4 3 3 4 3 2 1 4 2 3 4 4 4 2 3 3 2 1 3 3 4 2 3 2 2 3 2 2 1 1 1 2 5 2 3 1 1 2 5 2 1 1 3 3 3 3 3 3 3 1 4 5 3 2 4 2 1 4 3 4 2 1 3 5 1 2 5 4 4 1 2 1 1 3 1 3 3 2 2 5 5 4 5 5 5 5 3 3 3 5 0 2 3 2 4 3 3 4 1 4 3 2 4 2 2 4 2 3 3 5 0 2 2 3 4 3 4 4 3 0 2 1 2 1 3 3 3 1 5 5 0 5 3 3 2 2 2 3 3 3 3 4 3 1 1 2 2 1 4 4 2 5 5 1 2 3 2 3 2 1 4 4 1 2 3 2 4 5 5 3 3 1 4 4 2 3 2 1 4 1 4 3 4 5 4 3 3 3 1 5 4 5 0 4 0 5 1 1 2 2 3 5 5 2 1 5 4 1 5 5 3 5 5 4 5 3 1 4 4 1 3 3 4 4 5 5 3 2 5 4 1 3 3 0 3 4 2 3 2 5 4 4 5 3 3 4 3 5 4 3 1 1 4 4 5 1 3 5 5 5 3 1 4 4 3 3 5 5 5 5 3 5 4 4 5 4 2 5 2 3 1 3 3 3 4 3 4 2 3 1 3 5 4 3 3 0 0 3 3 5 1 4 3 3 3 0 4 5 1 1 4 3 5 3 4 5 4 1 3 4 3 3 1 5 5 3 4 3 4 0 2 5 1 4 3 4 0 2 5 1 3 4 3 3 2 0 4 5 3 1 4 4 3 4 2 4 2 4 3 4 3 4 5 1 0 5 3 0 3 5 3 2 3 3 1 5 3 4 1 1 4 4 4 4 5 4 5 5 3 4 5 3 5 1 1 5 3 4 4 1 3 4 3 1 5 4 5 1 3 3 4 5 1 5 5 4 2 1 2 4 4 1 5 1 4 5 4 1 3 1 4 2 5 1 4 4 3 3 3 4 4 4 4 2 2 4 3 3 1 1 2 3 4 4 1 3 2 4 4 2 3 4 1 5 1 5 4 3 4 3 2 3 3 4 1 4 4 3 2 3 5 3 1 1 3 5 1 5 3 1 3 2 5 4 5 5 4 1 3 4 3 2 4 3 4 3 5 3 1 1 1 3 3 0 1 4 4 3 3 5 4 5 5 0 1 3 3 4 0 5 1 1 3 2 1 2 3 1 1 3 5 4 4 4 4 3 5 1 1 3 4 3 2 4 3 3 1 3 5 5 2 5 1 5 4 2 4 4 4 3 3 3 3 1 3 4 1 3 5 1 4 4 2 2 1 4 4 1 1 2 0 3 4 3 5 3 5 5 4 1 4 3 2 1 4 5 1 3 3 1 2 5 1 1 3 4 1 2 2 5 3 1 1 3 3 0 5 4 2 1 5 1 4 4 5 2 3 1 4 4 4 3 5 5 2 0 4 4 1 1 0 3 5 3 3 3 3 2 4 1 4 2 4 2 3 3 3 4 5 2 2 0 2 3 5 3 4 1 4 3 3 3 2 3 1 1 3 5 3 3 2 3 2 3 2 4 3 1 3 5 3 4 3 3 3 3 3 4 4 4 3 5 2 5 1 1 3 4 1 3 3 4 3 3 1 5 4 2 2 4 4 5 1 1 2 3 2 3 1 2 3 3 4 1 4 0 4 4 3 2 4 1 1 2 3 4 2 4 3 5 5 4 3 2 1 4 0 3 4 4 5 5 4 1 5 5 2 3 2 5 1 1 4 3 2 5 1 5 2 4 2 2 3 4 4 4 4 5 2 2 5 3 2 1 4 4 4 1 5 4 3 3 4 4 4 4 2 0 4 5 0 4 5 4 3 3 2 5 1 5 4 4 4 5 4 1 5 1 3 4 3 5 4 4 5 1 1 1 4 3 1 4 0 5 1 3 1 1 2 3 1 4 1 3 2 1 4 1 4 2 4 0 2 4 1 1 4 3 2 5 0 4 5 5 3 3 3 2 4 4 3 1 3 3 1 0 1 3 2 4 2 4 1 2 3 1 0 2 1 1 3 5 5 5 1 3 2 3 4 4 4 4 2 3 3 2 3 1 5 3 5 3 2 3 2 5 5 4 4 1 4 2 0 1 2 5 3 3 1 2 5 1 3 1 2 3 5 4 1 1 0 3 1 2 4 1 5 4 3 5 5 4 1 4 2 4 4 4 3 1 5 1 2 5 3 3 3 1 4 1 5 4 1 2 2 2 1 4 2 3 4 5 1 4 2 3 4 2 3 2 4 4 5 2 1 1 1 3 4 1 4 3 2 4 1 3 4 5 1 0 3 3 4 5 4 3 5 3 4 4 4 3 2 4 1 4 4 1 4 1 1 4 4 3 1 1 1 4 3 0 3 2 3 4 4 1 3 2 3 0 1 1 1 4 4 5 2 2 2 2 5 1 3 4 3 3 3 5 5 1 3 2 4 2 2 3 3 4 4 4 5 1 5 3 2 1 2 5 3 1 1 5 3 2 3 5 3 3 5 4 4 2 4 1 3 5 5 3 1 2 1 5 3 2 1 2 5 5 1 1 1 1 5 4 2 2 2 5 1 1 2 0 2 2 2 4 1 1 2 3 3 0 3 1 5 2 3 4 1 1 1 5 2 1 1 3 1 2 1 3 1 1 4 1 1 1 4 2 4 1 2 3 1 0 1 5 0 2 1 3 1 4 4 3 4 3 4 1 4 5 1 4 0 2 4 2 1 5 4 4 1 1 0 2 0 2 4 1 2 1 4 1 4 1 1 4 4 3 4 3 1 3 2 4 1 3 2 2 3 3 4 3 5 2 4 4 4 4 5 4 3 2 3 5 1 0 3 3 2 1 3 3 3 1 2 1 5 3 2 3 1 3 4 3 4 3 2 1 2 3 5 1 3 4 4 3 2 3 1 2 5 1 3 1 1 1 4 4 5 4 4 3 4 2 4 1 1 1 2 4 3 1 1 4 4 4 1 1 5 2 4 2 2 3 3 2 4 2 3 5 2 5 3 5 4 3 1 1 3 3 1 4 3 1 3 3 5 4 5 0 3 4 1 1 1 3 3 0 1 4 4 4 4 3 0 3 3 1 3 3 4 4 2 3 3 2 1 3 2 1 1 1 3 1 4 1 4 1 2 1 3 1 5 0 4 2 1 0 4 3 5 1 2 1 4 4 5 4 4 4 4 1 2 1 4 1 3 4 2 5 3 5 4 1 2 3 3 5 5 4 3 2 1 4 5 4 4 3 5 5 4 0 0 5 4 4 2 4 1 4 4 4 1 2 4 5 1 3 5 2 2 2 3 5 4 3 4 3 3 4 5 2 2 3 1 5 1 1 2 1 5 5 1 5 4 1 2 2 5 5 1 4 5 1 0 4 4 3 1 5 5 4 1 4 1 1 3 1 1 2 4 5 1 5 3 5 5 0 1 1 4 0 1 3 3 3 1 5 5 1 5 4 4 5 3 4 1 3 1 2 1 4 3 4 1 1 2 1 3 1 1 1 3 4 2 5 2 2 1 2 2 1 5 3 4 4 3 3 4 4 2 5 1 2 3 4 3 3 5 3 4 5 3 4 2 3 5 3 1 2 4 4 1 1 0 1 1 4 5 2 4 2 4 3 4 5 3 3 4 4 3 1 1 4 3 4 2 1 5 3 4 3 3 3 4 5 5 1 1 3 2 1 1 1 3 1 2 4 3 3 2 1 1 2 4 2 4 5 5 1 3 2 3 3 3 1 1 0 2 4 4 4 2 2 3 4 5 4 1 1 5 4 2 2 2 3 3 4 4 3 4 5 3 4 4 4 5 3 2 1 3 5 3 3 2 4 2 1 4 1 5 3 3 4 4 3 1 2 5 2 1 2 1 3 2 0 0 4 2 1 2 4 4 4 2 5 2 3 5 3 1 3 2 2 4 3 1 1 1 2 3 3 2 2 3 5 5 4 2 4 2 4 2 2 3 4 4 4 1 2 4 3 2 2 4 1 3 3 1 4 4 4 5 5 2 4 3 3 4 1 4 4 4 4 3 3 0 2 2 0 0 2 3 3 2 1 4 4 0 2 5 0 2 5 4 1 1 2 3 3 0 4 3 1 2 2 1 1 4 0 1 2 1 4 2 4 4 5 4 3 0 3 3 2 0 4 4 4 3 4 4 2 1 3 3 1 2 1 4 3 1 2 1 4 4 3 4 0 4 3 2 3 1 3 1 2 3 1 4 2 1 2 5 4 3 1 3 5 3 3 1 4 3 2 0 3 1 2 3 1 2 3 3 1 2 1 3 1 3 4 0 1 3 3 2 1 4 0 2 4 4 3 1 2 3 4 4 4 3 5 2 1 5 2 3 0 2 5 2 4 2 1 4 1 5 3 2 0 4 4 2 4 5 3 4 5 1 1 2 3 4 3 3 0 1 3 4 3 0 1 4 4 4 4 3 4 4 1 2 4 5 1 3 3 1 0 1 3 5 1 1 1 4 5 3 3 5 3 4 1 3 0 3 3 4 3 1 3 5 4 4 1 2 3 1 2 3 2 1 1 1 1 4 1 1 4 2 1 3 3 3 1 3 1 4 5 3 2 3 1 2 1 4 4 5 3 2 3 2 0 2 4 2 3 5 3 3 1 4 2 1 1 0 3 1 1 3 1 1 2 1 4 2 3 1 4 1 4 1 5 1 5 0 3 0 1 1 4 2 1 1 3 2 5 2 2 4 1 4 3 2 3 1 2 4 4 3 2 3 4 2 3 5 5 3 4 4 1 4 3 2 4 2 1 3 1 1 3 4 3 2 2 4 3 3 1 2 4 3 2 2 5 3 3 2 2 4 0 5 1 3 3 3 5 1 3 1 2 2 4 1 4 0 5 3 3 2 5 1 1 1 1 3 1 2 3 4 3 0 2 2 2 4 4 3 5 3 1 0 4 4 2 1 4 4 3 2 2 1 2 2 3 3 3 0 4 5 2 1 0 1 1 3 0 4 1 1 0 4 5 5 2 1 2 1 1 3 5 3 3 4 1 2 1 3 3 5 4 4 2 1 1 3 5 1 1 2 2 1 4 1 1 2 2 3 4 4 5 3 4 1 1 3 3 3 5 3 4 1 2 2 4 2 3 5 5 4 1 1 3 1 4 5 1 4 2 2 4 1 3 1 3 4 3 1 3 1 3 1 2 5 1 2 1 3 3 2 2 4 1 5 1 2 1 4 1 4 3 3 5 4 3 5 0 2 2 2 1 5 0 3 3 3 1 3 4 4 5 2 2 1 3 3 2 0 1 3 5 1 1 4 3 2 2 2 2 3 3 4 4 1 3 2 3 1 4 2 4 1 1 5 4 2 0 2 1 4 2 2 3 2 1 2 4 2 1 3 3 3 3 4 1 3 4 4 1 1 5 2 3 3 5 4 4 5 1 2 4 2 4 2 3 2 0 3 1 1 3 3 4 1 2 3 3 0 4 2 3 1 1 4 2 4 1 3 3 1 2 2 2 3 1 1 3 3 3 0 2 1 2 3 5 2 1 1 1 2 1 4 3 2 3 2 2 3 1 1 3 4 3 3 4 3 4 2 1 1 3 1 2 5 3 3 3 2 4 5 5 1 1 1 5 2 1 0 3 2 5 1 3 4 1 2 2 5 2 3 3 2 3 4 2 1 3 1 5 1 3 4 5 4 2 5 5 1 1 1 2 1 0 3 3 4 1 3 5 4 4 1 0 1 0 5 1 5 5 2 1 2 2 4 4 4 2 5 3 4 0 5 4 1 5 1 1 0 5 1 4 4 2 3 1 2 4 4 5 4 1 4 5 1 3 3 3 4 5 5 1 4 5 4 2 5 2 4 4 3 0 3 4 3 4 5 5 4 1 3 5 4 4 5 3 1 1 4 4 1 3 1 1 1 4 1 2 4 2 4 3 4 0 2 3 4 0 3 1 3 4 3 1 4 4 5 4 3 4 2 2 3 3 4 3 0 2 0 1 4 1 1 2 3 4 3 1 1 5 4 5 1 5 5 5 4 1 2 2 3 4 3 5 2 1 0 4 1 1 4 3 3 1 3 3 4 4 3 1 5 3 2 5 4 3 4 3 5 4 3 4 4 3 4 5 3 3 1 3 5 3 4 3 4 5 4 3 4 3 1 1 5 1 3 1 4 3 4 1 5 4 2 3 1 4 3 3 4 4 0 2 5 5 1 5 3 1 3 3 3 4 4 0 5 1 5 4 2 0 3 0 4 0 4 1 1 1 4 1 3 4 4 3 4 1 1 4 3 3 1 1 3 4 3 2 3 2 4 5 1 2 5 3 4 0 3 2 5 2 3 1 5 3 3 2 3 4 2 5 1 5 4 1 1 1 1 2 1 3 4 3 5 5 5 2 2 1 1 3 1 2 4 3 3 5 4 3 1 1 3 1 1 4 1 2 1 4 5 4 2 1 1 5 1 1 4 4 2 2 4 2 4 2 1 5 4 2 3 2 4 2 2 3 2 1 1 2 5 4 5 2 5 1 4 1 4 3 3 2 4 5 3 3 4 1 1 3 3 4 1 3 1 3 1 3 1 4 1 1 5 1 4 0 5 3 1 5 1 3 2 4 3 3 3 1 2 2 5 1 2 2 1 5 4 2 4 4 1 4 4 1 5 1 4 1 5 5 2 1 3 1 4 4 3 1 5 1 4 2 5 5 3 4 3 2 3 4 3 4 1 5 5 1 5 5 4 3 2 2 3 0 1 4 1 1 3 3 3 4 4 2 3 0 2 3 3 1 4 1 1 4 3 5 4 1 5 1 5 5 3 2 4 3 2 2 1 5 5 4 4 5 4 3 3 4 3 3 1 1 5 4 3 1 2 1 1 3 2 5 3 5 4 2 1 2 0 3 3 2 3 1 5 2 4 3 3 4 2 1 3 5 3 5 3 3 3 4 3 3 1 2 0 4 4 5 5 3 3 4 3 1 1 4 3 5 3 5 4 3 5 0 1 1 1 4 4 3 1 3 4 1 2 1 4 2 4 1 1 3 0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 3 1 1 0 4 0 1 4 3 3 3 4 2 4 1 5 4 1 4 3 2 4 5 4 5 4 1 2 1 1 3 4 3 2 2 3 5 0 2 1 2 4 1 3 4 3 3 3 5 3 2 3 0 1 4 1 1 4 1 5 5 3 4 0 3 3 3 5 4 1 4 3 5 0 0 4 4 4 4 2 4 1 2 1 3 2 5 1 2 3 4 3 3 1 4 5 4 3 4 1 2 0 0 2 5 1 3 1 1 1 3 1 3 1 5 1 1 4 1 0 1 3 3 3 1 0 3 2 1 3 4 5 4 3 2 4 1 5 1 4 3 4 1 1 5 5 4 3 1 1 3 2 4 4 1 1 1 4 4 1 3 1 3 5 4 1 0 4 2 1 2 1 5 1 4 0 4 0 2 1 1 4 5 1 0 1 4 3 3 3 1 4 4 1 1 1 4 1 5 4 3 5 4 3 3 3 2 1 5 5 2 1 5 1 2 4 1 1 1 5 5 1 2 3 1 2 1 1 2 1 3 4 1 2 3 2 2 5 5 2 1 2 1 1 1 1 4 1 4 5 3 3 2 4 2 1 4 4 1 2 3 2 4 2 2 1 2 5 2 4 2 1 1 3 2 3 1 2 1 1 3 2 2 4 1 2 2 1 0 4 4 3 2 4 3 5 4 1 4 1 4 5 5 4 2 1 1 5 3 2 5 4 4 4 5 5 5 3 2 4 1 3 1 2 3 0 0 1 2 2 0 5 1 3 1 4 4 1 1 4 1 5 4 2 4 4 4 1 3 3 5 1 4 1 4 3 1 3 1 1 3 5 3 4 4 1 4 2 4 1 1 4 4 2 5 1 4 1 4 2 1 0 4 4 1 5 1 1 4 0 4 2 1 4 3 5 2 1 2 5 4 4 5 2 3 3 4 1 4 2 0 3 5 1 3 3 1 3 0 4 1 4 2 2 5 1 2 1 5 3 5 5 5 2 1 1 1 1 1 1 3 3 1 1 4 3 2 4 1 1 3 1 1 4 3 3 3 3 2 4 3 1 1 4 1 5 2 0 1 2 1 5 3 1 1 2 2 4 3 3 4 4 4 4 5 2 1 4 4 4 2 2 1 4 3 1 2 2 1 4 1 2 2 5 3 1 3 5 4 1 5 3 4 1 1 3 1 3 2 3 2 3 3 4 2 1 1 4 5 2 1 1 1 3 5 0 4 3 1 4 4 4 2 4 3 5 3 1 2 4 4 4 1 1 2 4 2 3 2 5 3 3 1 1 1 2 2 1 3 3 1 3 1 3 4 1 0 4 2 1 3 3 4 3 2 2 4 4 2 4 4 1 4 2 4 2 0 4 3 0 1 4 4 1 2 2 1 1 1 2 1 2 3 3 5 3 4 3 4 1 2 2 1 5 2 2 1 3 5 2 2 4 4 1 3 4 1 5 2 5 4 1 3 3 2 5 4 3 3 1 1 3 4 3 2 3 3 3 3 1 1 1 5 1 1 1 2 3 1 5 4 3 2 4 2 3 2 3 5 5 1 5 3 4 3 2 5 2 3 4 0 1 2 4 3 3 2 2 1 1 4 4 1 3 0 2 4 3 3 1 1 4 1 4 3 4 2 1 4 3 4 4 4 0 2 2 2 0 1 5 2 1 4 2 5 5 4 2 4 2 1 3 2 5 4 4 4 4 3 3 4 4 4 1 2 3 1 0 3 4 4 1 1 4 2 4 4 4 0 1 3 2 2 2 1 2 2 4 3 3 1 4 3 3 2 1 5 3 1 2 3 0 5 1 1 2 3 3 1 5 1 1 4 3 4 5 4 4 2 5 3 3 3 0 1 4 3 2 1 4 5 3 4 3 2 5 2 1 2 5 4 1 1 5 2 4 5 4 0 1 4 5 4 2 2 2 4 3 3 4 4 5 2 2 2 3 4 5 4 1 3 4 3 4 2 0 4 2 1 5 2 4 5 3 3 3 4 1 3 5 1 1 1 5 4 2 4 4 4 1 4 4 4 2 3 3 2 1 1 1 1 1 4 1 5 3 4 4 4 5 1 1 1 2 1 1 5 0 3 4 3 2 1 2 1 4 4 1 1 4 1 3 4 4 4 5 3 1 3 4 4 1 3 0 3 3 2 3 3 0 4 1 1 4 5 1 1 4 1 0 3 4 4 3 2 5 2 4 3 3 5 3 1 3 4 5 3 4 2 4 0 3 5 3 3 4 5 2 2 4 4 3 1 1 2 1 4 0 1 3 1 1 4 4 0 3 3 2 1 4 2 4 4 3 3 3 2 5 4 1 3 2 1 2 0 1 1 4 1 1 4 2 4 4 5 4 3 4 1 3 2 5 3 0 4 3 1 5 2 1 1 1 3 3 2 3 3 3 3 3 1 3 5 3 4 2 1 1 2 4 2 2 3 2 5 2 1 1 2 1 3 1 4 1 4 3 1 2 5 4 4 3 3 3 0 4 3 2 3 2 3 1 2 2 4 4 4 5 5 1 1 3 5 5 5 4 1 3 5 3 4 0 3 1 1 2 4 4 4 5 3 4 3 4 1 2 4 1 3 4 1 1 1 4 4 1 1 4 3 3 0 1 0 2 4 4 4 1 3 5 2 1 3 2 4 2 3 1 4 2 3 4 3 1 2 4 5 2 0 3 4 3 3 1 4 3 1 3 4 3 1 5 2 1 1 4 2 2 4 4 1 4 3 2 5 1 5 3 3 3 2 3 2 4 5 1 0 3 5 1 2 4 3 1 3 1 4 1 4 4 5 5 0 5 3 2 5 4 4 2 1 4 3 1 5 3 4 1 3 3 4 3 2 2 3 3 1 3 0 4 1 2 4 1 2 5 5 1 5 4 4 3 0 4 1 1 4 2 1 2 4 2 5 3 1 2 2 3 2 1 2 4 0 3 3 3 3 4 5 1 5 1 1 4 3 3 4 1 5 1 4 2 5 3 5 1 1 4 4 3 4 2 1 2 0 4 1 3 4 1 4 2 1 1 1 2 1 0 2 1 3 2 3 3 2 2 4 1 4 2 1 3 3 1 3 3 3 3 1 1 5 1 1 1 4 0 2 4 4 4 1 4 4 2 4 4 3 4 4 3 4 3 3 1 3 3 1 1 1 1 2 3 5 3 3 3 4 4 3 0 2 2 3 1 5 4 4 3 1 1 4 3 3 3 1 3 2 1 1 1 4 1 2 1 0 5 2 1 3 3 5 1 0 1 4 1 5 3 2 1 2 1 1 5 1 1 2 4 3 3 2 2 1 1 3 2 4 1 4 3 4 3 2 2 4 4 2 5 1 1 5 1 4 2 4 2 1 5 3 3 1 3 2 2 1 2 1 5 3 1 1 4 2 3 1 2 1 4 1 3 2 5 3 5 1 1 4 4 4 4 3 1 3 4 4 2 5 1 4 3 2 1 0 2 3 3 5 1 4 3 1 3 4 1 2 3 4 2 3 4 3 2 1 1 3 3 1 2 5 4 2 3 4 2 2 3 5 3 2 5 2 5 4 3 3 3 4 1 4 2 2 1 3 1 3 2 5 2 1 1 5 2 3 3 3 1 1 2 2 3 4 3 2 3 3 3 5 0 1 1 4 1 4 3 3 5 4 3 0 3 1 1 4 1 3 2 1 1 1 5 1 2 3 3 5 1 1 2 3 2 3 5 1 3 4 3 1 2 4 3 3 3 3 1 2 4 5 5 4 2 1 4 3 1 1 3 5 3 2 0 4 2 1 1 1 2 1 0 2 1 4 0 3 3 3 2 3 2 2 3 2 5 3 1 3 5 3 5 1 0 1 3 2 3 2 2 3 3 3 3 3 1 2 3 3 4 2 1 1 1 5 3 3 4 2 2 2 4 3 2 2 3 2 1 1 2 2 3 3 2 0 1 4 0 3 1 0 3 1 3 1 2 3 1 1 2 2 5 1 3 2 1 1 4 2 2 0 2 5 0 1 3 1 3 2 5 3 1 1 3 1 1 3 2 3 3 2 2 4 2 3 3 1 0 3 2 3 3 1 4 0 1 1 1 4 4 4 1 1 1 4 3 0 5 3 3 5 3 3 1 1 3 5 3 5 4 1 4 2 4 5 2 4 1 4 3 0 4 5 4 5 0 1 4 1 0 3 4 3 2 3 2 2 3 3 4 2 2 3 3 5 2 0 5 4 2 1 0 1 3 2 2 3 3 1 3 2 3 2 0 2 2 3 1 1 3 4 3 2 5 3 1 3 2 3 4 2 0 1 1 3 2 2 5 3 1 3 3 3 2 2 2 1 4 1 1 2 1 1 4 3 0 1 1 0 2 0 5 1 1 2 1 3 5 1 4 4 3 1 1 0 0 1 4 1 3 1 1 3 1 0 3 0 5 0 0 5 5 2 2 2 2 2 3 1 1 5 1 1 3 2 3 3 2 1 3 1 1 Correct: 5439 out of: 10269\n",
      "Accuracy of the network :  52.965235173824134\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "countCorrect0=0\n",
    "countCorrect1=0\n",
    "count0=0\n",
    "count1=0\n",
    "labels=pd.read_excel('trainReputation.xlsx' )\n",
    "\n",
    "Y=[]  #target\n",
    "Pred=[]  #predicted\n",
    "\n",
    "with torch.no_grad():\n",
    "    for row in range(len(input)):\n",
    "        outputs = net(input[row,:].float())\n",
    "        result=0\n",
    "        total+=1\n",
    "        if outputs[0]<outputs[1]:result=1\n",
    "        if outputs[result]<outputs[2]:result=2\n",
    "        if outputs[result]<outputs[3]:result=3\n",
    "        if outputs[result]<outputs[4]:result=4\n",
    "        if outputs[result]<outputs[5]:result=5\n",
    "        \n",
    "        if TrainLables.iloc[row,result]==1: correct+=1\n",
    "        \n",
    "        Y.append(labels.iloc[row])\n",
    "        Pred.append(result)\n",
    "        \n",
    "        print(result, end=' ')\n",
    "        \n",
    "    \n",
    "print('Correct:', correct, 'out of:', total )\n",
    "print('Accuracy of the network : ',( 100 * correct / total))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0200,  0.0500,  0.0550,  ..., -0.4009, -0.7607, -0.2063],\n",
       "        [ 0.0100,  0.0300,  0.0300,  ...,  0.2151, -0.2423, -0.4741],\n",
       "        [ 0.0450,  0.3550,  0.3500,  ...,  0.3970, -0.1581, -0.2169],\n",
       "        ...,\n",
       "        [ 0.0000,  0.0000,  0.0000,  ...,  0.3386,  1.2178,  0.9692],\n",
       "        [ 0.0000,  0.0500,  0.0400,  ...,  0.5190,  0.7275,  0.4744],\n",
       "        [ 0.0000,  0.0000,  0.0000,  ...,  0.6270,  0.7715,  0.3784]],\n",
       "       dtype=torch.float64)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the validation data\n",
    "\n",
    "ValidData=pd.read_excel('validReputation.xlsx' )\n",
    "ValidData=ValidData.iloc[:,:-2].astype(float)\n",
    "ValidData=ValidData/200\n",
    "\n",
    "SavesDirectory='./TunedModels/'+model_class+'/'+model_version+\"/Saves/\"\n",
    "TF_Output=pd.read_csv( SavesDirectory+'evalOut.tsv', sep='\\t')\n",
    "\n",
    "ValidData=pd.concat([ValidData,TF_Output], axis=1)\n",
    "\n",
    "\n",
    "ValidData=torch.tensor(ValidData.values)\n",
    "ValidData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1279</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1280</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1281</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1282</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1283</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1284 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0  1  2  3  4  5\n",
       "0     1  0  0  0  0  0\n",
       "1     0  0  0  1  0  0\n",
       "2     0  0  0  1  0  0\n",
       "3     0  0  0  0  1  0\n",
       "4     0  0  0  0  1  0\n",
       "...  .. .. .. .. .. ..\n",
       "1279  0  1  0  0  0  0\n",
       "1280  0  0  1  0  0  0\n",
       "1281  0  0  0  0  1  0\n",
       "1282  0  0  0  0  1  0\n",
       "1283  0  0  0  1  0  0\n",
       "\n",
       "[1284 rows x 6 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels=pd.read_excel('validReputation.xlsx' )\n",
    "\n",
    "labels=labels.iloc[:,-1] \n",
    "labelsOneHot=pd.get_dummies(labels)\n",
    "labelsOneHot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 1, 0, 0],\n",
       "        [0, 0, 0, 1, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, 0, 1, 0],\n",
       "        [0, 0, 0, 0, 1, 0],\n",
       "        [0, 0, 0, 1, 0, 0]], dtype=torch.uint8)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ValidLables =torch.tensor(labelsOneHot.values)\n",
    "ValidLables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 3 2 5 4 1 5 3 4 1 1 3 1 2 1 3 4 4 0 3 5 1 5 1 3 2 5 4 3 4 4 1 4 1 1 0 2 4 1 0 0 4 1 0 4 1 2 1 4 3 4 5 0 1 3 1 4 4 4 5 3 1 1 3 3 3 1 4 1 2 4 2 1 0 5 4 3 1 3 1 1 2 1 3 4 4 3 3 1 1 1 2 5 3 3 1 2 1 0 3 0 2 1 4 5 1 5 0 1 1 1 1 4 1 1 1 1 2 1 1 5 1 3 0 3 3 1 4 5 3 4 3 5 3 5 2 3 2 3 3 3 1 4 3 3 3 1 3 3 4 1 5 2 1 5 2 5 2 3 2 3 5 2 4 5 4 2 1 1 3 1 3 1 2 1 4 5 4 5 5 1 5 5 2 2 2 4 1 4 4 0 4 3 2 4 3 2 4 4 1 3 1 3 3 3 2 4 4 3 2 2 1 1 1 1 3 3 4 2 1 4 3 1 3 4 2 2 1 2 2 3 3 2 2 1 2 3 2 1 2 3 5 2 3 3 4 3 5 5 3 2 4 1 1 2 2 1 3 4 5 5 5 3 2 5 2 2 3 3 1 2 1 4 4 4 1 5 1 5 5 4 1 1 4 3 1 1 0 3 1 1 1 1 4 4 1 3 1 2 3 4 5 3 5 0 3 5 3 3 4 4 3 4 2 4 3 5 1 5 3 5 2 0 2 1 1 4 4 1 3 4 2 3 5 4 2 4 3 1 4 1 1 1 1 4 0 2 3 3 2 1 4 3 3 2 1 3 1 2 2 2 4 4 2 2 5 3 3 3 1 4 3 3 3 2 1 5 5 2 1 4 5 2 1 5 3 5 3 5 4 1 1 5 0 4 3 1 2 1 3 4 4 3 5 5 5 1 1 4 3 2 1 4 3 2 4 4 3 4 1 1 2 4 4 1 3 2 1 1 2 3 0 5 3 1 0 5 5 1 1 3 4 4 5 4 5 2 3 3 3 5 2 3 3 3 5 1 2 2 1 2 4 3 3 1 1 3 1 5 3 4 1 4 5 4 3 5 1 3 4 1 0 1 3 2 3 3 3 1 2 1 4 5 1 2 2 3 1 1 2 3 4 4 4 5 4 3 1 1 3 4 0 5 4 2 4 3 1 5 2 1 2 3 5 3 2 3 1 1 1 4 5 4 3 4 3 2 1 0 2 4 2 0 4 0 1 5 1 3 4 2 3 1 2 3 2 1 2 1 4 3 3 1 1 3 5 2 2 3 1 3 3 1 2 1 4 4 3 0 1 1 5 3 3 0 1 3 5 1 1 1 1 5 4 2 5 4 2 5 3 1 2 3 3 5 0 3 4 5 2 2 3 4 3 2 2 2 1 3 3 1 4 1 0 4 1 4 3 2 3 2 1 3 2 4 5 1 5 0 3 2 1 1 1 3 2 1 3 4 2 5 3 2 3 0 3 4 4 5 4 4 1 3 4 5 3 1 5 3 2 0 3 5 3 3 4 4 3 2 5 3 3 5 1 3 1 3 4 1 4 3 5 2 3 4 1 3 5 3 4 5 5 1 1 4 1 2 1 4 1 2 0 3 5 1 5 3 3 4 2 1 4 3 1 3 0 3 2 3 3 1 4 1 3 4 2 4 5 4 4 3 3 1 5 5 0 2 2 4 1 1 1 4 2 0 0 4 1 1 2 4 2 5 4 4 3 2 4 3 3 2 0 2 3 1 2 2 3 2 2 3 3 4 0 3 4 3 2 4 3 1 3 1 1 2 1 5 2 4 4 3 2 1 4 3 1 2 2 4 5 2 3 2 0 1 3 4 1 5 1 3 1 1 3 3 5 3 4 5 3 3 2 1 2 5 3 0 1 1 2 2 3 0 1 3 1 3 1 4 4 4 5 3 1 1 5 0 2 3 4 2 4 1 3 4 0 1 1 2 1 4 3 3 2 1 5 0 4 2 0 4 3 1 1 2 4 3 4 2 5 1 1 2 2 0 1 1 4 4 2 3 1 4 1 1 1 1 3 3 5 4 5 3 3 2 0 0 3 5 2 1 4 5 0 3 3 3 1 3 0 3 4 1 2 4 1 4 2 4 3 2 1 4 0 0 3 3 4 3 2 0 4 0 2 4 2 3 4 1 2 2 3 5 1 3 2 3 2 1 1 2 2 2 4 4 5 4 1 3 3 4 3 0 2 5 1 3 3 3 1 4 4 1 4 1 4 3 4 4 1 1 4 1 1 4 4 1 2 4 4 3 3 3 3 1 1 4 3 2 5 1 0 3 5 2 4 2 4 1 3 3 2 5 2 4 2 1 4 0 1 2 2 4 5 2 3 4 2 4 1 1 3 2 2 5 2 4 4 1 1 0 3 5 1 2 3 4 5 0 2 5 1 2 3 4 3 2 4 5 4 1 2 3 3 0 1 3 1 3 0 1 5 1 4 4 0 5 4 1 1 5 4 3 5 0 4 2 3 1 4 5 1 2 3 4 4 0 4 4 5 1 2 0 4 1 1 4 4 3 1 1 1 2 4 4 1 4 1 5 1 5 1 1 2 3 4 1 3 3 1 1 4 3 3 4 1 2 3 3 1 5 1 5 5 3 3 1 5 1 1 3 1 4 1 2 1 1 3 4 5 5 3 4 3 4 1 3 2 3 1 3 1 1 4 5 4 2 3 3 2 3 0 3 1 1 3 3 4 1 3 1 0 5 4 4 3 2 1 2 3 3 1 3 1 3 1 4 2 1 3 4 3 3 5 1 3 5 1 3 3 2 3 1 1 3 5 5 3 2 5 3 4 1 3 2 3 4 3 4 5 3 2 1 4 3 2 3 2 1 1 3 4 1 0 0 3 2 2 1 0 2 4 3 4 Correct: 594 out of: 1284\n",
      "Accuracy of the network :  46.26168224299065\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "countCorrect0=0\n",
    "countCorrect1=0\n",
    "count0=0\n",
    "count1=0\n",
    "\n",
    "Y=[]  #target\n",
    "Pred=[]  #predicted\n",
    "\n",
    "with torch.no_grad():\n",
    "    for row in range(len(ValidData)):\n",
    "        outputs = net(ValidData[row,:].float())\n",
    "        result=0\n",
    "        total+=1\n",
    "        if outputs[0]<outputs[1]:result=1\n",
    "        if outputs[result]<outputs[2]:result=2\n",
    "        if outputs[result]<outputs[3]:result=3\n",
    "        if outputs[result]<outputs[4]:result=4\n",
    "        if outputs[result]<outputs[5]:result=5\n",
    "        \n",
    "        if labelsOneHot.iloc[row,result]==1: correct+=1\n",
    "        \n",
    "        Y.append(labels.iloc[row])\n",
    "        Pred.append(result)\n",
    "        \n",
    "        print(result, end=' ')\n",
    "        \n",
    "    \n",
    "print('Correct:', correct, 'out of:', total )\n",
    "print('Accuracy of the network : ',( 100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0050,  0.0100,  0.0050,  ...,  0.2808,  1.0107,  1.0078],\n",
       "        [ 0.0000,  0.0000,  0.0000,  ...,  0.1179, -0.3774, -0.5854],\n",
       "        [ 0.0200,  0.0250,  0.0600,  ..., -0.0493, -0.2832,  0.0285],\n",
       "        ...,\n",
       "        [ 0.0100,  0.0050,  0.0250,  ..., -0.5962, -0.7461, -0.4854],\n",
       "        [ 0.2200,  0.0950,  0.0350,  ..., -0.4175, -0.6655, -0.1862],\n",
       "        [ 0.0050,  0.0600,  0.0100,  ..., -0.0349, -0.1351, -0.0563]],\n",
       "       dtype=torch.float64)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the test data\n",
    "\n",
    "TestData=pd.read_excel('testReputation.xlsx' )\n",
    "TestData=TestData.iloc[:,:-2].astype(float)\n",
    "TestData=TestData/200\n",
    "\n",
    "SavesDirectory='./TunedModels/'+model_class+'/'+model_version+\"/Saves/\"\n",
    "TF_Output=pd.read_csv( SavesDirectory+'testOut.tsv', sep='\\t')\n",
    "\n",
    "TestData=pd.concat([TestData,TF_Output], axis=1)\n",
    "\n",
    "\n",
    "TestData=torch.tensor(TestData.values)\n",
    "TestData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1278</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1279</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1280</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1281</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1282</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1283 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0  1  2  3  4  5\n",
       "0     0  0  0  0  1  0\n",
       "1     0  0  0  1  0  0\n",
       "2     0  1  0  0  0  0\n",
       "3     0  0  0  0  0  1\n",
       "4     0  0  0  0  0  1\n",
       "...  .. .. .. .. .. ..\n",
       "1278  0  1  0  0  0  0\n",
       "1279  0  0  0  0  1  0\n",
       "1280  0  0  1  0  0  0\n",
       "1281  1  0  0  0  0  0\n",
       "1282  0  1  0  0  0  0\n",
       "\n",
       "[1283 rows x 6 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels=pd.read_excel('testReputation.xlsx' )\n",
    "\n",
    "labels=labels.iloc[:,-1] \n",
    "labelsOneHot=pd.get_dummies(labels)\n",
    "labelsOneHot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0, 0, 0, 1, 0],\n",
       "        [0, 0, 0, 1, 0, 0],\n",
       "        [0, 1, 0, 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 1, 0, 0, 0],\n",
       "        [1, 0, 0, 0, 0, 0],\n",
       "        [0, 1, 0, 0, 0, 0]], dtype=torch.uint8)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TestLables =torch.tensor(labelsOneHot.values)\n",
    "TestLables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 3 2 2 3 1 4 4 5 4 3 1 1 1 3 3 1 1 1 4 1 4 3 3 1 5 4 4 3 5 1 1 0 3 5 4 5 4 4 4 1 5 5 1 1 3 4 4 1 1 4 4 3 3 1 2 5 5 5 1 1 4 1 3 1 4 3 5 3 4 3 1 2 5 1 1 4 1 1 2 3 1 1 4 1 4 1 4 1 4 1 1 1 1 2 1 3 1 3 2 4 0 3 1 1 1 1 3 1 3 1 3 3 3 1 2 0 3 1 2 2 2 4 3 1 1 1 1 5 3 3 2 1 1 1 0 0 1 2 3 4 3 1 3 3 3 3 3 4 1 0 3 1 3 5 3 4 5 3 3 3 1 3 1 3 5 4 4 3 1 1 3 2 5 1 3 3 3 0 2 5 4 4 1 1 3 0 1 1 5 2 5 5 0 1 1 2 2 3 1 1 4 5 3 4 1 3 5 1 3 2 3 1 1 4 1 2 4 2 2 1 1 3 2 1 4 2 2 3 0 4 1 0 1 1 2 2 0 5 2 2 1 2 2 4 1 2 1 3 3 0 5 3 4 3 3 4 0 4 1 3 1 1 2 0 1 1 4 4 0 3 3 1 2 5 2 5 1 2 4 4 1 3 5 2 3 5 1 4 0 2 4 1 1 1 4 3 4 1 3 1 2 4 4 5 1 2 5 3 3 1 4 1 3 3 4 5 3 3 3 3 4 4 4 1 0 5 1 5 1 5 3 3 3 5 1 1 3 2 1 4 1 4 3 3 5 2 4 1 1 1 0 4 1 4 1 1 3 1 2 3 1 1 1 2 0 3 1 3 1 0 1 5 5 4 3 4 5 2 1 3 1 1 4 1 3 3 3 1 5 5 2 1 1 1 3 3 1 2 4 3 2 0 1 4 5 2 3 3 4 2 2 1 1 2 1 3 5 3 5 2 4 4 1 1 4 4 3 4 3 1 1 3 3 2 4 3 3 2 1 3 4 2 1 3 2 3 2 3 3 1 2 1 3 4 3 4 3 3 1 5 2 3 4 4 3 1 3 2 3 2 4 1 4 3 2 2 1 3 3 2 3 3 1 2 1 2 0 1 1 1 5 5 3 2 1 3 4 3 4 3 4 1 3 4 2 1 2 5 4 3 5 2 3 1 5 3 3 1 5 1 3 2 4 1 5 5 1 3 5 1 0 0 1 1 3 4 1 1 5 4 5 3 2 1 3 0 5 4 1 0 3 3 2 1 2 3 2 2 1 1 5 4 1 0 1 2 4 1 2 4 3 5 0 1 3 3 4 1 4 1 1 3 1 1 4 3 1 4 3 4 1 3 1 1 3 3 2 4 5 2 5 2 4 3 3 3 3 1 4 1 4 4 2 3 2 4 5 3 4 3 3 3 1 2 4 3 5 4 0 1 1 3 5 3 2 3 3 2 2 2 1 3 3 3 4 1 3 3 3 3 2 4 2 4 3 1 5 4 4 5 2 3 5 3 4 4 4 4 0 4 4 5 3 2 3 1 4 5 3 1 5 4 1 3 2 3 3 2 4 2 5 2 4 3 4 4 2 5 0 1 2 4 4 5 3 3 3 1 2 4 4 3 4 3 3 4 1 1 4 1 4 4 4 1 4 3 5 3 1 1 2 1 4 4 3 3 4 0 1 4 4 4 5 3 2 1 0 3 0 3 4 4 3 3 5 4 1 1 3 0 5 1 1 1 3 1 1 4 3 4 5 4 4 1 2 1 5 4 4 3 3 5 2 0 5 2 1 2 4 4 4 5 5 5 3 2 2 5 3 5 4 1 1 5 1 0 2 1 5 1 2 5 4 3 1 5 3 1 4 1 5 3 4 3 3 4 4 4 3 4 3 4 5 2 2 4 5 1 2 4 1 4 3 4 3 4 0 3 5 3 2 2 3 4 4 1 3 1 2 4 5 2 2 2 1 3 3 0 0 4 5 1 0 0 1 3 0 3 5 5 1 2 0 3 3 2 2 3 4 4 2 2 3 3 1 3 2 3 2 1 4 1 2 2 2 5 2 4 5 2 1 4 2 5 4 4 0 0 2 3 1 1 3 3 5 3 2 3 2 2 1 5 2 3 4 4 1 3 1 4 4 3 4 4 3 5 5 2 5 3 3 1 2 2 3 2 1 1 5 0 3 2 3 1 5 5 2 3 1 1 1 1 4 0 4 2 4 4 4 5 2 5 3 4 4 5 1 1 3 4 1 5 4 4 4 1 1 5 3 1 3 5 1 2 3 0 4 5 2 1 1 2 1 3 4 1 3 5 1 4 3 5 4 5 1 3 5 2 1 1 4 5 3 5 4 4 1 4 4 4 3 1 1 4 4 5 1 1 3 1 2 4 3 4 5 3 5 2 3 3 1 4 3 3 2 4 1 2 4 2 3 3 4 4 2 5 5 1 1 2 3 3 4 3 3 1 4 1 3 2 5 4 1 0 2 2 2 2 1 3 3 4 2 1 4 3 1 1 3 5 3 0 2 1 2 2 5 2 1 5 1 3 5 1 2 1 4 1 1 4 5 2 1 5 1 0 5 4 5 5 2 2 3 2 2 3 1 0 3 4 3 1 4 2 4 5 1 4 5 2 4 2 3 2 4 1 5 5 4 2 1 4 1 4 1 0 2 4 1 3 4 1 1 3 0 4 4 4 3 5 1 4 4 1 0 4 1 3 3 3 3 4 1 1 2 1 4 1 1 5 5 3 2 5 1 4 2 3 1 2 1 3 1 1 3 4 3 3 4 3 2 3 2 1 2 2 2 4 3 1 1 4 2 4 3 4 3 3 3 2 2 4 4 1 1 3 3 1 1 3 1 1 2 2 1 3 3 3 5 1 3 1 3 0 1 2 2 4 2 2 0 1 Correct: 618 out of: 1283\n",
      "Accuracy of the network :  48.168355416991425\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "countCorrect0=0\n",
    "countCorrect1=0\n",
    "count0=0\n",
    "count1=0\n",
    "\n",
    "Y=[]  #target\n",
    "Pred=[]  #predicted\n",
    "\n",
    "with torch.no_grad():\n",
    "    for row in range(len(TestData)):\n",
    "        outputs = net(TestData[row,:].float())\n",
    "        result=0\n",
    "        total+=1\n",
    "        if outputs[0]<outputs[1]:result=1\n",
    "        if outputs[result]<outputs[2]:result=2\n",
    "        if outputs[result]<outputs[3]:result=3\n",
    "        if outputs[result]<outputs[4]:result=4\n",
    "        if outputs[result]<outputs[5]:result=5\n",
    "        \n",
    "        if labelsOneHot.iloc[row,result]==1: correct+=1\n",
    "        \n",
    "        Y.append(labels.iloc[row])\n",
    "        Pred.append(result)\n",
    "        \n",
    "        print(result, end=' ')\n",
    "        \n",
    "    \n",
    "print('Correct:', correct, 'out of:', total )\n",
    "print('Accuracy of the network : ',( 100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 42  24   8  14   1   3]\n",
      " [  7 153  33  28  24   5]\n",
      " [  6  45  88  41  23  11]\n",
      " [  0  47  29 130  43  18]\n",
      " [  0  25  24  63 116  21]\n",
      " [  4  30  14  29  45  89]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    " \n",
    "print(metrics.confusion_matrix(Y,Pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Pants       0.71      0.46      0.56        92\n",
      "       False       0.47      0.61      0.53       250\n",
      " Barely-True       0.45      0.41      0.43       214\n",
      "   Hlaf-True       0.43      0.49      0.45       267\n",
      " Mostly-True       0.46      0.47      0.46       249\n",
      "        True       0.61      0.42      0.50       211\n",
      "\n",
      "    accuracy                           0.48      1283\n",
      "   macro avg       0.52      0.48      0.49      1283\n",
      "weighted avg       0.50      0.48      0.48      1283\n",
      "\n"
     ]
    }
   ],
   "source": [
    "target_names = ['Pants', 'False', 'Barely-True','Half-True','Mostly-True','True']\n",
    "\n",
    "print(metrics.classification_report(Y, Pred,target_names =target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
