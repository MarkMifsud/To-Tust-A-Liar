{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we first do the classification using the transformer This is our first classification task.\n",
    "\n",
    "The output classification vector from the transformer is saved to be used by the FCNN This is our second classification task.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing necessary libraries\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import sklearn\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from simpletransformers.classification import ClassificationModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.6554,  0.0366,  1.8789, -0.9590]])\n",
      "tensor([[ 1.5641,  0.5631, -0.9440,  1.1921]])\n",
      "tensor([-0.9079])\n"
     ]
    }
   ],
   "source": [
    "input1 = torch.randn(1,4)\n",
    "input2 = torch.randn(1,4)\n",
    "output = torch.cosine_similarity(input1, input2)\n",
    "print(input1)\n",
    "print(input2)\n",
    "\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the dataset\n",
    "\n",
    "Some pre-processing to the dataset has already been done in preparation for various tests, so this processing is not from scratch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# procedure for getting the data sets and formatting them for the transformer\n",
    " \n",
    "\n",
    "def prepareDataset( filename):\n",
    "     \n",
    "    ReadSet=pd.read_excel(filename )\n",
    "\n",
    "    ReadSet['text']=ReadSet['Statement']\n",
    "    ReadSet['labels']=ReadSet['Label']\n",
    "    \n",
    "    ReadSet=ReadSet.drop(['ID','Label','Statement','Subject','Speaker','Job','From','Affiliation','PantsTotal','NotRealTotal','BarelyTotal','HalfTotal','MostlyTotal','Truths','Context'\n",
    "],axis=1)\n",
    "     \n",
    "    return ReadSet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>It costs more money to put a person on death r...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Charlie Crist \"bizarrely vetoed\" $9.7 million ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>In Massachusetts, half of the primary care doc...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fulton County has successfully reduced the num...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Says he stood up to his own party by voting ag...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10264</th>\n",
       "      <td>Recently Rick Scott closed 30 womens health ca...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10265</th>\n",
       "      <td>Says Charlie Bass supports Paul Ryan plan that...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10266</th>\n",
       "      <td>A report by the US General Accountability Offi...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10267</th>\n",
       "      <td>In the United States, weve had 12 years in a r...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10268</th>\n",
       "      <td>In Virginias Medicaid program, approximately 3...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10269 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  labels\n",
       "0      It costs more money to put a person on death r...       0\n",
       "1      Charlie Crist \"bizarrely vetoed\" $9.7 million ...       3\n",
       "2      In Massachusetts, half of the primary care doc...       4\n",
       "3      Fulton County has successfully reduced the num...       4\n",
       "4      Says he stood up to his own party by voting ag...       5\n",
       "...                                                  ...     ...\n",
       "10264  Recently Rick Scott closed 30 womens health ca...       4\n",
       "10265  Says Charlie Bass supports Paul Ryan plan that...       5\n",
       "10266  A report by the US General Accountability Offi...       3\n",
       "10267  In the United States, weve had 12 years in a r...       1\n",
       "10268  In Virginias Medicaid program, approximately 3...       1\n",
       "\n",
       "[10269 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# preparing the training dataset\n",
    "train=prepareDataset( 'trainRNDtext.xlsx')\n",
    "# and display for inspecting\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The president is brain-dead.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Barack Obama supported keeping troops in Iraq,...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>He's leading by example, refusing contribution...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I'm the first person who really took up the is...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I built that border fence in San Diego...and i...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1279</th>\n",
       "      <td>CNN accidentally aired 30 minutes of pornograp...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1280</th>\n",
       "      <td>President Obamas American Recovery and Reinves...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1281</th>\n",
       "      <td>We (in Illinois) have the fifth-highest tax bu...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1282</th>\n",
       "      <td>Says Donald Trump won more counties than any c...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1283</th>\n",
       "      <td>A recent study found that cities where Uber op...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1284 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  labels\n",
       "0                          The president is brain-dead.       0\n",
       "1     Barack Obama supported keeping troops in Iraq,...       3\n",
       "2     He's leading by example, refusing contribution...       3\n",
       "3     I'm the first person who really took up the is...       4\n",
       "4     I built that border fence in San Diego...and i...       4\n",
       "...                                                 ...     ...\n",
       "1279  CNN accidentally aired 30 minutes of pornograp...       1\n",
       "1280  President Obamas American Recovery and Reinves...       2\n",
       "1281  We (in Illinois) have the fifth-highest tax bu...       4\n",
       "1282  Says Donald Trump won more counties than any c...       4\n",
       "1283  A recent study found that cities where Uber op...       3\n",
       "\n",
       "[1284 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# preparing the evaluation/validation dataset\n",
    "Eval=prepareDataset('valid.xlsx')\n",
    "# and display for inspecting\n",
    "Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>New Mexico was 46th in teacher pay (when he wa...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Barack Obama and Hillary Clinton have changed ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I'll tell you what I can tell this country: If...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tommy Thompson created the first school choice...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fifty-six percent decline in overall crime. A ...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1278</th>\n",
       "      <td>We have trade agreements with 20 countries, an...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1279</th>\n",
       "      <td>On Donald Trumps plan to cut federal funding t...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1280</th>\n",
       "      <td>Black Lives Matter, who are attacking law enfo...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1281</th>\n",
       "      <td>Latina who enthusiastically supported Donald T...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1282</th>\n",
       "      <td>Theres been no conclusive or specific report t...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1283 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  labels\n",
       "0     New Mexico was 46th in teacher pay (when he wa...       4\n",
       "1     Barack Obama and Hillary Clinton have changed ...       3\n",
       "2     I'll tell you what I can tell this country: If...       1\n",
       "3     Tommy Thompson created the first school choice...       5\n",
       "4     Fifty-six percent decline in overall crime. A ...       5\n",
       "...                                                 ...     ...\n",
       "1278  We have trade agreements with 20 countries, an...       1\n",
       "1279  On Donald Trumps plan to cut federal funding t...       4\n",
       "1280  Black Lives Matter, who are attacking law enfo...       2\n",
       "1281  Latina who enthusiastically supported Donald T...       0\n",
       "1282  Theres been no conclusive or specific report t...       1\n",
       "\n",
       "[1283 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# preparing the test set dataset\n",
    "test=prepareDataset('test.xlsx')\n",
    "test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up the transformer for fine tuning\n",
    "\n",
    "This is where changes are done to optimise the model\n",
    "\n",
    "The simpletransformers library is the quickest way to do this at the time of writing. \n",
    "For more information on the settings and their default value go here:\n",
    "https://github.com/ThilinaRajapakse/simpletransformers#default-settings \n",
    "\n",
    "###### Please do read that reference before changing any parameters. Don't try to be a hero!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model variables were set up: \n"
     ]
    }
   ],
   "source": [
    "#Set the model being used here\n",
    "model_class='bert'  # bert or roberta or albert\n",
    "model_version='bert-base-cased' #bert-base-cased, roberta-base, roberta-large, albert-base-v2 OR albert-large-v2\n",
    "\n",
    "\n",
    "output_folder='./TunedModels/'+model_class+'/'+model_version+\"/\"\n",
    "cache_directory= \"./TunedModels/\"+model_class+\"/\"+model_version+\"/\"+\"/cache/\"\n",
    "labels_count=6  # the number of classification classes\n",
    "\n",
    "print('model variables were set up: ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G:\\0 finalThesis\\randomText\n",
      "./TunedModels/bert/bert-base-cased/\n",
      "./TunedModels/bert/bert-base-cased//cache/\n"
     ]
    }
   ],
   "source": [
    "# use this to test if writing to the directories is working\n",
    "\n",
    "import os\n",
    "print(os.getcwd())\n",
    "print(output_folder)\n",
    "print(cache_directory)\n",
    "\n",
    "testWrite=train.head(30)\n",
    " \n",
    "testWrite.to_csv(output_folder+'DeleteThisToo.tsv', sep='\\t')\n",
    "testWrite.to_csv(cache_directory+'DeleteThisToo.tsv', sep='\\t')\n",
    "\n",
    "del(testWrite)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "save_every_steps=1285\n",
    "# assuming training batch size of 8\n",
    "# any number above 1284 saves the model only at every epoch\n",
    "# Saving the model mid training very often will consume disk space fast\n",
    "\n",
    "train_args={\n",
    "    \"output_dir\":output_folder,\n",
    "    \"cache_dir\":cache_directory,\n",
    "    'reprocess_input_data': True,\n",
    "    'overwrite_output_dir': True,\n",
    "    'num_train_epochs': 1,\n",
    "    \"save_steps\": save_every_steps, \n",
    "    \"learning_rate\": 2e-5,\n",
    "    \"train_batch_size\": 64,\n",
    "    \"eval_batch_size\": 8,\n",
    "    \"evaluate_during_training_steps\": 312,\n",
    "    \"max_seq_length\": 64,\n",
    "    \"n_gpu\": 1,\n",
    "}\n",
    "\n",
    "# Create a ClassificationModel\n",
    "model = ClassificationModel(model_class, model_version, num_labels=labels_count, args=train_args) \n",
    "\n",
    "# You can set class weights by using the optional weight argument"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading a saved model (based on above args{})\n",
    "\n",
    "If you stopped training you can continue training from a previously saved check point.\n",
    "The next cell allows you to load a model from any checkpoint.\n",
    "The number of epochs in the train_args{} will be done and continue tuning from your checkpoint.\n",
    "\n",
    "###### HOWEVER\n",
    "It will overwrite previous checkpoints!\n",
    "Example:  If you load an epoch-3 checkpoint, the epoch-1 checkpoint will be overwritten by the 4th epoch and it will be equivalent to a 4th epoch even if you have epoch-1 in the name.\n",
    "###### SO BE CAREFUL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model, please wait...\n",
      "model in use is : ./TunedModels/bert/bert-base-cased/checkpoint-322-epoch-2\n"
     ]
    }
   ],
   "source": [
    "# loading a previously saved model based on this particular Transformer Class and model_name\n",
    "\n",
    "# loading the checkpoint that gave the best result\n",
    "CheckPoint='checkpoint-322-epoch-2'  #epoch 2\n",
    "\n",
    "\n",
    "preSavedCheckpoint=output_folder+CheckPoint\n",
    "\n",
    "print('Loading model, please wait...')\n",
    "model = ClassificationModel( model_class, preSavedCheckpoint, num_labels=labels_count, args=train_args) \n",
    "print('model in use is :', preSavedCheckpoint )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the Transformer\n",
    "\n",
    "Skip the next cell if you want to skip the training and go directly to the evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting to features started. Cache is not used.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4eeed4ef45e94e269f0dc7bc78851aad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=10269.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.\n",
      "\n",
      "Defaults for this optimization level are:\n",
      "enabled                : True\n",
      "opt_level              : O1\n",
      "cast_model_type        : None\n",
      "patch_torch_functions  : True\n",
      "keep_batchnorm_fp32    : None\n",
      "master_weights         : None\n",
      "loss_scale             : dynamic\n",
      "Processing user overrides (additional kwargs that are not None)...\n",
      "After processing overrides, optimization options are:\n",
      "enabled                : True\n",
      "opt_level              : O1\n",
      "cast_model_type        : None\n",
      "patch_torch_functions  : True\n",
      "keep_batchnorm_fp32    : None\n",
      "master_weights         : None\n",
      "loss_scale             : dynamic\n",
      "Warning:  multi_tensor_applier fused unscale kernel is unavailable, possibly because apex was installed without --cuda_ext --cpp_ext. Using Python fallback.  Original ImportError was: ModuleNotFoundError(\"No module named 'amp_C'\")\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0372be07f3a14bf5b9de21c496d7026f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch', max=1.0, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48267aa97ee44444806cb4a8decff07d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Current iteration', max=161.0, style=ProgressStyle(descri…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "Running loss: 1.691436"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mark\\Anaconda3\\envs\\thesis\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:110: UserWarning: Seems like `optimizer.step()` has been overridden after learning rate scheduler initialization. Please, make sure to call `optimizer.step()` before `lr_scheduler.step()`. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\"Seems like `optimizer.step()` has been overridden after learning rate scheduler \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running loss: 1.773723"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mark\\Anaconda3\\envs\\thesis\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:224: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running loss: 1.742038\n",
      "\n",
      "Training of bert model complete. Saved to ./TunedModels/bert/bert-base-cased/.\n",
      "Training time:  0:03:20.744214\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "current_time = datetime.now()\n",
    "model.train_model(train)\n",
    "print(\"Training time: \", datetime.now() - current_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating the training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features loaded from cache at ./TunedModels/bert/bert-base-cased//cache/cached_dev_bert_64_6_10269\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57306e36dd7a4e2ca522feb1e7acc0bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1284.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{'mcc': 0.0026679135646689427, 'acc': 0.2034277923848476, 'eval_loss': 1.7618593526220767}\n",
      "Features loaded from cache at ./TunedModels/bert/bert-base-cased//cache/cached_dev_bert_64_6_1284\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ed70a6ddab440cd988d5a80415732c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=161.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{'mcc': 0.02521111036770863, 'acc': 0.20950155763239875, 'eval_loss': 1.7687166292474876}\n",
      "Features loaded from cache at ./TunedModels/bert/bert-base-cased//cache/cached_dev_bert_64_6_1283\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab8feb32bfab45bdb25bdfd2c7bbe9ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=161.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{'mcc': 0.0043928771367421566, 'acc': 0.2073265783320343, 'eval_loss': 1.7544981322673536}\n",
      "Training Result: 0.2034277923848476\n",
      "Eval Result: 0.20950155763239875\n",
      "Test Set Result: 0.2073265783320343\n"
     ]
    }
   ],
   "source": [
    "TrainResult, TrainModel_outputs, wrong_predictions = model.eval_model(train, acc=sklearn.metrics.accuracy_score)\n",
    "\n",
    "EvalResult, EvalModel_outputs, wrong_predictions = model.eval_model(Eval, acc=sklearn.metrics.accuracy_score)\n",
    "\n",
    "TestResult, TestModel_outputs, wrong_predictions = model.eval_model(test, acc=sklearn.metrics.accuracy_score)\n",
    "\n",
    "print('Training Result:', TrainResult['acc'])\n",
    "#print('Model Out:', TrainModel_outputs)\n",
    "\n",
    "print('Eval Result:', EvalResult['acc'])\n",
    "#print('Model Out:', EvalModel_outputs)\n",
    "\n",
    "print('Test Set Result:', TestResult['acc'])\n",
    "#print('Model Out:', TestModel_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.77490234  0.14990234 -0.01353455  0.20458984  0.1206665  -0.19262695] 3   4 \n",
      "[-0.6801758   0.22827148 -0.00727844  0.2705078   0.14221191 -0.00641251] 3   3 Match 1\n",
      "\n",
      "[-0.7558594   0.265625   -0.22521973  0.14562988  0.00231171 -0.08886719] 1   1 Match 2\n",
      "\n",
      "[-7.1435547e-01  1.8566895e-01 -9.0209961e-02  3.2324219e-01\n",
      "  1.3879395e-01 -4.4822693e-05] 3   5 \n",
      "[-0.6899414   0.20031738  0.07116699  0.44213867  0.03363037  0.00091076] 3   5 \n",
      "[-0.7216797   0.09802246 -0.1206665   0.12695312  0.21435547 -0.04324341] 4   2 \n",
      "[-0.56396484  0.08337402  0.06143188  0.36010742  0.13354492  0.1772461 ] 3   4 \n",
      "[-0.6982422   0.04486084 -0.01837158  0.19506836  0.08428955 -0.04507446] 3   5 \n",
      "[-0.6748047   0.24255371 -0.08416748  0.28125     0.0508728  -0.05773926] 3   4 \n",
      "[-0.7709961   0.24853516 -0.11419678  0.2998047   0.04489136 -0.01384735] 3   5 \n",
      "[-7.0703125e-01  2.3986816e-01 -1.3464355e-01  2.0214844e-01\n",
      "  1.4782715e-01 -1.2516975e-04] 1   5 \n",
      "[-0.74609375  0.19091797 -0.1986084   0.16564941  0.0692749   0.06256104] 1   3 \n",
      "[-0.71972656  0.13684082 -0.17004395  0.12561035  0.29882812  0.02096558] 4   2 \n",
      "[-0.7104492   0.17504883  0.02363586  0.25024414  0.08850098 -0.03921509] 3   1 \n",
      "[-0.67041016  0.20776367 -0.0690918   0.1496582   0.11956787 -0.05700684] 1   4 \n",
      "[-0.72314453  0.20812988 -0.23168945  0.14331055  0.12976074 -0.0668335 ] 1   4 \n",
      "[-6.2890625e-01  1.0644531e-01 -1.5917969e-01  1.8603516e-01\n",
      "  1.5429688e-01 -4.0745735e-04] 3   4 \n",
      "[-0.7080078   0.20373535 -0.07556152  0.2939453   0.04266357 -0.00680923] 3   3 Match 3\n",
      "\n",
      "[-0.6538086   0.14819336 -0.17883301  0.08074951  0.05477905  0.02586365] 1   1 Match 4\n",
      "\n",
      "[-0.76123047  0.18151855 -0.02131653  0.19616699  0.06335449 -0.10083008] 3   1 \n",
      "[-0.79785156  0.25585938 -0.18078613  0.21313477  0.0383606  -0.06451416] 1   1 Match 5\n",
      "\n",
      "[-0.6826172   0.21240234 -0.04983521  0.34570312  0.06652832 -0.02116394] 3   3 Match 6\n",
      "\n",
      "[-0.75634766  0.29101562 -0.10662842  0.1574707   0.09082031 -0.12585449] 1   1 Match 7\n",
      "\n",
      "[-0.72216797  0.0748291  -0.02651978  0.19970703  0.17785645  0.01913452] 3   5 \n",
      "[-0.7211914   0.11364746 -0.0715332   0.22290039  0.15734863 -0.06469727] 3   5 \n",
      "[-0.70751953  0.1385498  -0.14416504  0.11883545  0.14794922 -0.12915039] 4   5 \n",
      "[-0.6982422   0.20666504 -0.02111816  0.30371094  0.00790405 -0.00400543] 3   5 \n",
      "[-0.7661133   0.1652832  -0.13879395  0.22509766  0.06033325 -0.04187012] 3   4 \n",
      "[-0.6196289   0.06408691  0.03225708  0.18859863  0.15600586  0.04153442] 3   5 \n",
      "[-0.74658203  0.07373047  0.0161438   0.12573242  0.2199707  -0.14526367] 4   3 \n",
      "[-0.68896484  0.20373535 -0.13415527  0.25341797  0.17956543 -0.00568008] 3   5 \n",
      "[-0.78125     0.19262695 -0.19335938  0.23010254  0.02888489  0.01081085] 3   2 \n",
      "[-0.71728516  0.23522949 -0.11676025  0.15979004  0.06155396 -0.12231445] 1   0 \n",
      "[-0.72314453  0.15307617 -0.09643555  0.30786133  0.02064514  0.08770752] 3   5 \n",
      "[-0.6191406   0.22436523  0.02709961  0.27026367  0.1772461  -0.04931641] 3   5 \n",
      "[-0.76220703  0.15112305 -0.09399414  0.23083496  0.12524414 -0.07775879] 3   5 \n",
      "[-0.7524414   0.20959473 -0.11877441  0.16455078  0.12841797 -0.10253906] 1   4 \n",
      "[-0.66064453  0.15405273 -0.02537537  0.24279785  0.13903809  0.0017519 ] 3   3 Match 8\n",
      "\n",
      "[-0.6557617   0.24377441 -0.17126465  0.17871094  0.05255127 -0.06021118] 1   3 \n",
      "[-0.72802734  0.15405273 -0.10046387  0.22180176  0.1381836  -0.02503967] 3   5 \n",
      "[-0.6743164   0.18054199 -0.0958252   0.23217773  0.09735107 -0.00349998] 3   5 \n",
      "[-0.70947266  0.06152344 -0.03546143  0.3395996   0.2775879  -0.1192627 ] 3   4 \n",
      "[-0.7763672   0.140625   -0.2512207   0.19262695  0.09674072 -0.05026245] 3   3 Match 9\n",
      "\n",
      "[-0.58496094  0.13354492 -0.11444092  0.1817627   0.21435547  0.04370117] 4   2 \n",
      "[-0.79248047  0.16796875 -0.23486328  0.10424805  0.11651611 -0.13793945] 1   1 Match 10\n",
      "\n",
      "[-0.625       0.11553955 -0.03546143  0.29248047  0.17663574  0.04556274] 3   2 \n",
      "[-0.6303711   0.2175293  -0.10949707  0.28295898  0.19238281 -0.00219536] 3   3 Match 11\n",
      "\n",
      "[-0.7011719   0.07116699 -0.05599976  0.21362305  0.14575195  0.05230713] 3   2 \n",
      "[-0.7475586   0.14575195 -0.08514404  0.2109375   0.18444824 -0.13757324] 3   2 \n",
      "[-0.6635742   0.18408203 -0.1505127   0.13415527  0.16931152 -0.06774902] 1   5 \n",
      "[-0.7182617   0.18310547 -0.00109291  0.1472168   0.12481689 -0.05102539] 1   5 \n",
      "[-0.68359375  0.29248047 -0.06246948  0.27148438  0.04086304 -0.08251953] 1   2 \n",
      "[-0.67529297  0.2763672  -0.08306885  0.23339844  0.1295166   0.01202393] 1   4 \n",
      "[-0.66503906  0.15942383 -0.04812622  0.19018555  0.16711426 -0.00165367] 3   2 \n",
      "[-0.6953125   0.19836426 -0.21032715  0.05303955  0.1072998  -0.10827637] 1   1 Match 12\n",
      "\n",
      "[-0.57373047  0.19763184 -0.00952911  0.20898438  0.15966797  0.00735855] 3   5 \n",
      "[-0.6845703   0.14428711 -0.02156067  0.19506836  0.13708496  0.00974274] 3   5 \n",
      "[-0.6713867   0.16418457 -0.06039429  0.26293945  0.13024902  0.00117207] 3   2 \n",
      "[-0.7602539   0.2705078  -0.24487305  0.25805664  0.00559616 -0.1340332 ] 1   5 \n",
      "[-0.7246094   0.25732422 -0.19506836  0.16845703  0.05340576 -0.12890625] 1   2 \n",
      "[-0.59765625  0.08581543 -0.01316833  0.3010254   0.203125    0.11828613] 3   1 \n",
      "[-0.6352539   0.15698242 -0.00320435  0.23742676  0.26171875  0.01649475] 4   1 \n",
      "[-0.6586914   0.23657227 -0.26708984  0.35913086  0.07110596  0.01319885] 3   3 Match 13\n",
      "\n",
      "[-0.6225586   0.17370605 -0.05233765  0.28295898  0.10284424  0.02349854] 3   5 \n",
      "[-0.70410156  0.19812012 -0.15881348  0.18334961  0.13354492 -0.07531738] 1   0 \n",
      "[-0.6376953   0.25634766 -0.06970215  0.26171875  0.06677246  0.02290344] 3   5 \n",
      "[-0.6308594   0.16369629 -0.09759521  0.16711426  0.11950684 -0.00446701] 3   3 Match 14\n",
      "\n",
      "[-0.81396484  0.20507812 -0.13146973  0.17175293  0.02229309 -0.10961914] 1   4 \n",
      "[-0.63378906  0.16503906 -0.10211182  0.26831055  0.10852051  0.03231812] 3   3 Match 15\n",
      "\n",
      "[-0.6933594   0.17480469 -0.22045898  0.09942627  0.04385376 -0.01327515] 1   1 Match 16\n",
      "\n",
      "[-0.6801758   0.24499512 -0.12609863  0.2685547   0.09008789 -0.0324707 ] 3   5 \n",
      "[-0.6850586   0.11315918 -0.06848145  0.16455078  0.08654785 -0.11865234] 3   1 \n",
      "[-0.67333984  0.1373291  -0.07629395  0.21618652  0.15063477  0.08837891] 3   3 Match 17\n",
      "\n",
      "[-0.7993164   0.11682129 -0.26171875  0.17163086  0.00633621 -0.05773926] 3   5 \n",
      "[-0.7109375   0.25439453 -0.09075928  0.17004395  0.02626038 -0.02859497] 1   4 \n",
      "[-0.625       0.14379883 -0.07434082  0.40551758  0.1315918   0.10040283] 3   1 \n",
      "[-0.5732422   0.1583252   0.02897644  0.265625    0.19335938  0.02542114] 3   4 \n",
      "[-0.640625    0.15625    -0.04669189  0.25219727  0.18164062 -0.03115845] 3   3 Match 18\n",
      "\n",
      "[-6.5527344e-01  1.7077637e-01 -2.0898438e-01  1.0168457e-01\n",
      "  1.5478516e-01  3.2424927e-05] 1   1 Match 19\n",
      "\n",
      "[-0.7260742   0.21459961 -0.11505127  0.1628418   0.13195801  0.01953125] 1   3 \n",
      "[-0.69433594  0.09729004  0.04925537  0.11230469  0.13989258  0.02305603] 4   3 \n",
      "[-0.77246094  0.15441895 -0.05212402  0.2277832   0.13623047 -0.06994629] 3   5 \n",
      "[-0.70458984  0.11938477 -0.04574585  0.19921875  0.09857178 -0.04348755] 3   2 \n",
      "[-0.7709961   0.1159668  -0.14343262  0.234375    0.08087158 -0.01565552] 3   1 \n",
      "[-0.6142578   0.09313965 -0.0411377   0.26049805  0.23413086 -0.05084229] 3   4 \n",
      "[-0.7109375   0.14611816 -0.02696228  0.06738281  0.05557251 -0.04998779] 1   3 \n",
      "[-0.70458984  0.24963379 -0.16479492  0.3239746  -0.05871582 -0.04431152] 3   3 Match 20\n",
      "\n",
      "[-0.6738281   0.08215332 -0.04055786  0.18322754  0.10192871 -0.06274414] 3   3 Match 21\n",
      "\n",
      "[-0.625       0.19665527 -0.1048584   0.16040039  0.22045898 -0.07910156] 4   4 Match 22\n",
      "\n",
      "[-0.59375     0.04083252  0.17272949  0.30371094  0.21936035  0.06155396] 3   5 \n",
      "[-0.79541016  0.23828125 -0.20410156  0.14196777  0.0345459  -0.10876465] 1   4 \n",
      "[-0.6582031   0.19213867 -0.10028076  0.19836426  0.20410156 -0.1928711 ] 4   3 \n",
      "[-0.76660156  0.12451172 -0.11132812  0.13806152  0.12188721 -0.05203247] 3   0 \n",
      "[-7.2656250e-01  1.4709473e-01  5.9204102e-02  2.4035645e-01\n",
      "  8.2855225e-03  2.3734570e-04] 3   1 \n",
      "[-0.5004883   0.03140259  0.14233398  0.42944336  0.20288086  0.17272949] 3   1 \n",
      "[-0.6538086   0.07952881 -0.04574585  0.23474121  0.1262207   0.06555176] 3   1 \n",
      "[-0.85595703  0.12341309 -0.18347168  0.19628906  0.09954834  0.01863098] 3   5 \n",
      "[-0.7348633   0.14282227 -0.13635254  0.0703125   0.1217041  -0.05963135] 1   5 \n",
      "[-0.6904297   0.20947266 -0.15893555  0.27368164  0.02931213 -0.08526611] 3   3 Match 23\n",
      "\n",
      "[-0.640625    0.08526611  0.08880615  0.18188477  0.14648438  0.03808594] 3   1 \n",
      "[-0.69433594  0.2705078  -0.08551025  0.35302734  0.02961731 -0.01957703] 3   4 \n",
      "[-0.5307617   0.1003418  -0.00319099  0.3154297   0.21374512  0.11657715] 3   0 \n",
      "[-0.72021484  0.28735352 -0.15344238  0.26733398  0.02859497 -0.04302979] 1   3 \n",
      "[-0.7207031   0.1862793  -0.1538086   0.24133301  0.05941772 -0.06222534] 3   1 \n",
      "[-0.7290039   0.14074707  0.03292847  0.15759277  0.20361328 -0.06030273] 4   2 \n",
      "[-0.57421875  0.078125    0.06072998  0.27563477  0.16662598  0.08862305] 3   1 \n",
      "[-0.6303711   0.12597656  0.01447296  0.18847656  0.08776855  0.04650879] 3   2 \n",
      "[-0.6635742   0.1484375  -0.05911255  0.23303223  0.12719727 -0.02792358] 3   5 \n",
      "[-0.8022461   0.21252441 -0.03872681  0.20056152  0.09332275 -0.11083984] 1   5 \n",
      "[-0.67285156  0.13891602 -0.01828003  0.2836914   0.10137939  0.03720093] 3   2 \n",
      "[-0.58447266  0.09674072 -0.00481415  0.27124023  0.16625977  0.01829529] 3   0 \n",
      "[-0.5390625   0.07507324  0.09686279  0.27246094  0.18444824  0.12963867] 3   2 \n",
      "[-0.76904297  0.26416016 -0.15234375  0.16064453 -0.00252533 -0.1541748 ] 1   5 \n",
      "[-0.62597656  0.1907959  -0.03527832  0.34838867  0.11071777  0.12536621] 3   4 \n",
      "[-0.6230469   0.11352539 -0.09387207  0.35083008  0.15917969 -0.0982666 ] 3   1 \n",
      "[-0.6274414   0.17687988  0.01261902  0.2590332   0.14611816  0.06268311] 3   0 \n",
      "[-0.69189453  0.15112305 -0.07067871  0.39770508  0.22668457 -0.04608154] 3   5 \n",
      "[-0.6381836   0.15014648 -0.02633667  0.22216797  0.13684082  0.02966309] 3   1 \n",
      "[-0.58203125  0.09954834 -0.00234795  0.20092773  0.26123047  0.02851868] 4   1 \n",
      "[-0.7182617   0.13342285 -0.01313782  0.35107422  0.11712646  0.02966309] 3   3 Match 24\n",
      "\n",
      "[-0.70947266  0.0519104  -0.09844971  0.23059082  0.1821289  -0.09484863] 3   2 \n",
      "[-6.4746094e-01  1.9299316e-01  2.4008751e-04  2.5000000e-01\n",
      "  1.9250488e-01  2.0874023e-02] 3   2 \n",
      "[-0.6328125   0.35180664 -0.05368042  0.44458008 -0.00261688 -0.12695312] 3   4 \n",
      "[-0.70654297  0.18395996 -0.11090088  0.3544922   0.08032227 -0.02709961] 3   4 \n",
      "[-0.5258789   0.08172607  0.01902771  0.27368164  0.21887207  0.06756592] 3   5 \n",
      "[-0.77783203  0.22570801 -0.10168457  0.19042969 -0.02635193  0.03872681] 1   1 Match 25\n",
      "\n",
      "[-0.6826172   0.13085938 -0.11871338  0.37695312  0.07189941  0.12060547] 3   1 \n",
      "[-0.71972656  0.21789551 -0.08782959  0.24145508 -0.02191162 -0.07421875] 3   4 \n",
      "[-0.7402344   0.21801758 -0.08197021  0.2680664   0.05609131 -0.0011816 ] 3   5 \n",
      "[-0.73535156  0.1595459   0.02635193  0.20007324  0.06210327 -0.00791931] 3   1 \n",
      "[-0.7246094   0.12670898 -0.00192451  0.23168945  0.105896    0.04818726] 3   2 \n",
      "[-0.7036133   0.22009277 -0.19714355  0.20043945  0.1895752  -0.12756348] 1   2 \n",
      "[-0.6660156   0.14916992 -0.05407715  0.15136719  0.11279297 -0.06121826] 3   1 \n",
      "[-0.6357422  -0.02172852 -0.0010643   0.3239746   0.28833008  0.00919342] 3   2 \n",
      "[-0.7529297   0.2084961  -0.01560974  0.2770996  -0.00367546 -0.04708862] 3   1 \n",
      "[-0.5830078  -0.01006317 -0.06045532  0.2565918   0.2614746  -0.00350761] 4   2 \n",
      "[-0.6381836   0.28198242 -0.19458008  0.2783203   0.07012939  0.00085258] 1   5 \n",
      "[-0.66064453  0.10913086 -0.0949707   0.22766113  0.20593262 -0.0274353 ] 3   5 \n",
      "[-0.73339844  0.09893799 -0.13256836  0.21569824  0.08239746  0.00576019] 3   2 \n",
      "[-0.7167969   0.14648438 -0.10070801  0.32592773  0.06542969  0.09619141] 3   3 Match 26\n",
      "\n",
      "[-0.6713867   0.11846924 -0.01112366  0.23925781  0.16833496  0.07598877] 3   1 \n",
      "[-0.6411133   0.33496094 -0.03292847  0.4482422  -0.02095032 -0.02464294] 3   2 \n",
      "[-0.6972656   0.07220459 -0.00531387  0.23937988  0.2454834  -0.1126709 ] 4   1 \n",
      "[-0.71240234  0.04638672 -0.00702286  0.21020508  0.17480469  0.01470184] 3   4 \n",
      "[-0.63378906  0.16345215  0.11004639  0.22497559  0.08312988  0.03179932] 3   3 Match 27\n",
      "\n",
      "[-0.65234375  0.15332031 -0.01612854  0.2220459   0.05645752 -0.00911713] 3   4 \n",
      "[-0.66015625  0.18786621 -0.08618164  0.25927734  0.04434204  0.07757568] 3   3 Match 28\n",
      "\n",
      "[-0.76171875  0.04016113 -0.03549194  0.19494629  0.07739258 -0.06195068] 3   3 Match 29\n",
      "\n",
      "[-0.734375    0.17456055 -0.02563477  0.36572266  0.09326172 -0.07263184] 3   5 \n",
      "[-0.6298828   0.09075928 -0.00845337  0.28833008  0.13720703  0.03497314] 3   4 \n",
      "[-0.796875    0.14221191 -0.16601562  0.07305908  0.1463623  -0.17712402] 4   1 \n",
      "[-0.6694336   0.16625977  0.06970215  0.31225586  0.11425781  0.04992676] 3   2 \n",
      "[-0.6665039   0.08233643 -0.07647705  0.16503906  0.26220703 -0.09008789] 4   1 \n",
      "[-0.8027344   0.25634766 -0.16601562  0.24035645  0.00730515 -0.0171051 ] 1   3 \n",
      "[-0.6826172   0.0645752  -0.01184082  0.09545898  0.17321777  0.01565552] 4   2 \n",
      "[-0.609375    0.03659058  0.074646    0.18518066  0.23718262  0.02922058] 4   3 \n",
      "[-0.76660156  0.17236328 -0.04385376  0.37353516  0.06103516  0.00246048] 3   5 \n",
      "[-0.7631836   0.15686035 -0.06439209  0.20812988  0.09924316  0.00245476] 3   4 \n",
      "[-0.6699219   0.09436035 -0.01511383  0.29223633  0.11212158  0.09063721] 3   4 \n",
      "[-0.6894531   0.13195801 -0.03994751  0.31396484  0.09063721  0.04754639] 3   5 \n",
      "[-0.7182617   0.22924805 -0.20117188  0.14245605 -0.04089355 -0.01274109] 1   5 \n",
      "[-0.5913086   0.16723633  0.06854248  0.20007324  0.14001465  0.05487061] 3   1 \n",
      "[-0.67529297  0.07940674 -0.05194092  0.32714844  0.15551758  0.01655579] 3   4 \n",
      "[-0.75146484  0.16821289 -0.17004395  0.3605957   0.10345459 -0.0970459 ] 3   3 Match 30\n",
      "\n",
      "[-0.7548828   0.19604492 -0.1862793   0.08111572  0.09393311 -0.10266113] 1   3 \n",
      "[-0.6777344   0.10424805 -0.01099396  0.31420898  0.10424805 -0.04223633] 3   5 \n",
      "[-0.6635742   0.22998047 -0.10064697  0.27124023  0.0692749  -0.02659607] 3   3 Match 31\n",
      "\n",
      "[-0.65722656  0.1586914  -0.06176758  0.23425293  0.01548004  0.0322876 ] 3   2 \n",
      "[-0.78222656  0.21276855 -0.15258789  0.18603516  0.12103271 -0.20812988] 1   3 \n",
      "[-0.7211914   0.12463379 -0.07104492  0.14331055  0.1928711  -0.10369873] 4   1 \n",
      "[-0.75146484  0.13879395 -0.04180908  0.14001465  0.16503906 -0.03335571] 4   3 \n",
      "[-0.6269531   0.01038361  0.10681152  0.22399902  0.16430664  0.09094238] 3   2 \n",
      "[-0.6948242   0.25512695 -0.2692871   0.26220703  0.05020142 -0.01312256] 3   5 \n",
      "[-0.71484375  0.29638672 -0.08343506  0.36645508  0.01437378 -0.07049561] 3   5 \n",
      "[-0.61376953  0.13745117 -0.0871582   0.3479004   0.16723633  0.01491547] 3   3 Match 32\n",
      "\n",
      "[-0.66748047  0.11676025  0.0018425   0.15771484  0.1743164   0.02957153] 4   5 \n",
      "[-0.72998047  0.06573486  0.01968384  0.25390625  0.13793945 -0.05691528] 3   3 Match 33\n",
      "\n",
      "[-0.65966797  0.0927124   0.01924133  0.20935059  0.15148926  0.06774902] 3   4 \n",
      "[-0.7001953   0.26904297 -0.05325317  0.31469727  0.04071045  0.04525757] 3   1 \n",
      "[-0.7036133   0.29492188 -0.04071045  0.23071289  0.07244873 -0.05688477] 1   2 \n",
      "[-0.71240234  0.18908691 -0.07012939  0.11175537  0.11700439 -0.07751465] 1   5 \n",
      "[-0.71240234  0.26416016 -0.06445312  0.24707031  0.06896973 -0.01004791] 1   3 \n",
      "[-0.69677734  0.14147949 -0.14294434  0.20776367  0.22241211 -0.01707458] 4   3 \n",
      "[-0.7270508   0.29736328 -0.17407227  0.12731934  0.07629395 -0.1282959 ] 1   1 Match 34\n",
      "\n",
      "[-0.75097656  0.14318848 -0.0224762   0.34765625  0.12329102  0.0025177 ] 3   1 \n",
      "[-0.7163086   0.1920166  -0.11541748  0.08935547  0.07922363 -0.06091309] 1   0 \n",
      "[-5.9619141e-01  1.2634277e-01 -6.4270020e-02  1.8444824e-01\n",
      "  1.4416504e-01 -2.4068356e-04] 3   0 \n",
      "[-0.72509766  0.26342773 -0.04953003  0.21533203  0.05429077 -0.09735107] 1   4 \n",
      "[-0.63671875  0.20666504 -0.14929199  0.22705078  0.05029297 -0.03475952] 3   1 \n",
      "[-0.8149414   0.23083496 -0.20422363  0.21447754  0.12695312 -0.03930664] 1   5 \n",
      "[-0.72021484  0.05657959  0.05358887  0.18774414  0.11004639  0.00517273] 3   2 \n",
      "[-0.6455078   0.20788574  0.04968262  0.47583008  0.09020996 -0.08239746] 3   5 \n",
      "[-0.6791992   0.3095703  -0.07250977  0.3269043   0.06182861 -0.02801514] 3   5 \n",
      "[-0.7055664   0.1116333   0.03451538  0.35009766  0.12536621  0.04476929] 3   0 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.45263672  0.10870361  0.02009583  0.5151367   0.20080566  0.16271973] 3   1 \n",
      "[-0.72753906  0.08886719 -0.14135742  0.3166504   0.11328125  0.05487061] 3   1 \n",
      "[-0.75878906  0.24841309 -0.13317871  0.37963867  0.07318115 -0.15625   ] 3   2 \n",
      "[-0.60253906  0.15625    -0.03985596  0.26538086  0.21728516  0.10125732] 3   3 Match 35\n",
      "\n",
      "[-0.6879883   0.1574707  -0.01064301  0.2064209   0.15075684  0.02027893] 3   3 Match 36\n",
      "\n",
      "[-0.75683594  0.1394043  -0.09796143  0.16113281  0.05322266 -0.11401367] 3   1 \n",
      "[-0.7236328   0.14709473 -0.08007812  0.19714355  0.13928223 -0.0125351 ] 3   1 \n",
      "[-0.6503906   0.11743164  0.12060547  0.35546875  0.03845215  0.00421524] 3   2 \n",
      "[-0.7631836   0.07635498 -0.05447388  0.18945312  0.09924316 -0.0993042 ] 3   3 Match 37\n",
      "\n",
      "[-0.6386719   0.12145996  0.02514648  0.34545898  0.11419678  0.08074951] 3   3 Match 38\n",
      "\n",
      "[-0.71777344  0.12792969 -0.0092926   0.3161621   0.17248535 -0.05392456] 3   1 \n",
      "[-0.67626953  0.15649414 -0.1595459   0.20959473  0.20300293 -0.03344727] 3   1 \n",
      "[-0.72753906  0.1484375  -0.11993408  0.1418457   0.15893555  0.02597046] 4   4 Match 39\n",
      "\n",
      "[-0.67285156  0.2064209   0.03756714  0.28344727  0.01544952 -0.0994873 ] 3   5 \n",
      "[-0.7114258   0.19677734 -0.16503906  0.29614258  0.04870605  0.04452515] 3   3 Match 40\n",
      "\n",
      "[-0.65966797  0.06365967  0.05603027  0.35717773  0.15612793 -0.00534058] 3   3 Match 41\n",
      "\n",
      "[-0.7089844   0.1484375  -0.05175781  0.2097168   0.14282227 -0.02700806] 3   1 \n",
      "[-0.74658203  0.13122559 -0.02742004  0.11932373  0.08813477 -0.027771  ] 1   3 \n",
      "[-0.6542969   0.00889587 -0.14282227  0.3149414   0.10552979  0.08721924] 3   3 Match 42\n",
      "\n",
      "[-0.75097656  0.08056641 -0.07904053  0.26538086  0.12841797  0.05511475] 3   0 \n",
      "[-0.7006836  -0.03179932  0.04934692  0.14990234  0.28466797  0.03448486] 4   2 \n",
      "[-0.66552734  0.13342285 -0.00341606  0.23876953  0.20288086 -0.0947876 ] 3   5 \n",
      "[-0.61328125  0.02677917  0.01210022  0.18737793  0.3310547   0.10534668] 4   2 \n",
      "[-0.67041016  0.18041992 -0.00885773  0.4182129   0.05072021  0.00284386] 3   4 \n",
      "[-0.77197266  0.15356445 -0.16540527  0.21813965 -0.00437927 -0.13513184] 3   3 Match 43\n",
      "\n",
      "[-0.8125      0.0546875  -0.17297363  0.19238281  0.3190918  -0.06658936] 4   4 Match 44\n",
      "\n",
      "[-0.71777344  0.18273926 -0.0970459   0.25634766  0.18493652 -0.07720947] 3   4 \n",
      "[-0.7788086   0.19824219 -0.11608887  0.25463867  0.07470703 -0.2614746 ] 3   1 \n",
      "[-0.7680664   0.17736816  0.01649475  0.1697998   0.00936127 -0.14489746] 1   4 \n",
      "[-0.6088867   0.15112305 -0.00743866  0.28344727  0.20581055  0.06695557] 3   2 \n",
      "[-0.6850586   0.07250977 -0.01543427  0.25097656  0.18518066  0.06878662] 3   1 \n",
      "[-0.6191406   0.11090088  0.01829529  0.2421875   0.17150879  0.01426697] 3   2 \n",
      "[-0.75146484  0.12207031 -0.06842041  0.19934082  0.10272217 -0.10253906] 3   3 Match 45\n",
      "\n",
      "[-0.78466797  0.03625488  0.01438141  0.18237305  0.29296875 -0.0692749 ] 4   1 \n",
      "[-0.7792969   0.23071289 -0.03591919  0.29077148  0.04006958 -0.0723877 ] 3   3 Match 46\n",
      "\n",
      "[-0.6308594   0.06439209  0.00131607  0.1842041   0.33496094 -0.01539612] 4   0 \n",
      "[-0.68896484  0.15759277 -0.0385437   0.38598633  0.01038361  0.05148315] 3   3 Match 47\n",
      "\n",
      "[-0.7524414   0.2709961  -0.0723877   0.2763672  -0.00644684 -0.06469727] 3   1 \n",
      "[-0.7128906   0.1394043   0.01998901  0.24243164  0.10412598  0.06622314] 3   0 \n",
      "[-0.74902344  0.16052246 -0.23095703  0.2536621   0.1763916  -0.11523438] 3   0 \n",
      "[-0.7714844   0.12371826 -0.13439941  0.30444336  0.02285767  0.02767944] 3   1 \n",
      "[-0.7294922   0.0486145   0.02146912  0.22741699  0.13476562  0.00177097] 3   3 Match 48\n",
      "\n",
      "[-0.7138672   0.05801392  0.03265381  0.1427002   0.16748047  0.0579834 ] 4   5 \n",
      "[-0.7495117   0.10272217 -0.06222534  0.1842041   0.09558105 -0.14001465] 3   0 \n",
      "[-0.62841797  0.26489258 -0.04794312  0.4086914   0.00987244 -0.02835083] 3   4 \n",
      "[-0.60058594  0.04815674  0.1274414   0.22509766  0.22058105  0.0713501 ] 3   2 \n",
      "[-0.6616211   0.09246826 -0.02340698  0.21923828  0.16418457 -0.001894  ] 3   2 \n",
      "[-0.6738281   0.16223145 -0.02966309  0.2932129   0.13574219 -0.03433228] 3   1 \n",
      "[-0.78125     0.15625    -0.04605103  0.22460938  0.04702759 -0.10455322] 3   3 Match 49\n",
      "\n",
      "[-0.8183594   0.17333984 -0.2220459  -0.04098511  0.11645508 -0.15063477] 1   5 \n",
      "[-0.6713867  -0.01387787  0.02754211  0.24768066  0.18334961  0.00650787] 3   4 \n",
      "[-0.7089844   0.02217102  0.02212524  0.17687988  0.15783691 -0.08642578] 3   1 \n",
      "[-0.74658203  0.03717041 -0.00374031  0.10906982  0.22338867 -0.06945801] 4   0 \n",
      "[-0.6044922   0.06243896 -0.01209259  0.42407227  0.2097168   0.08868408] 3   1 \n",
      "[-0.6694336   0.09411621  0.0328064   0.27075195  0.09686279  0.0423584 ] 3   3 Match 50\n",
      "\n",
      "[-0.6586914   0.1229248  -0.0690918   0.20239258  0.1496582  -0.04837036] 3   2 \n",
      "[-0.6435547   0.16003418  0.01329803  0.20141602  0.18261719 -0.04046631] 3   2 \n",
      "[-0.7470703   0.08666992 -0.07995605  0.17419434  0.20874023 -0.11694336] 4   5 \n",
      "[-0.7651367   0.02697754  0.06671143  0.16479492  0.09020996 -0.08679199] 3   3 Match 51\n",
      "\n",
      "[-0.7114258   0.07440186 -0.09277344  0.26733398  0.13293457  0.04104614] 3   4 \n",
      "[-0.66796875  0.10961914  0.15734863  0.17089844  0.19616699 -0.02645874] 4   1 \n",
      "[-0.6455078   0.11938477  0.04388428  0.16760254  0.12078857 -0.0904541 ] 3   1 \n",
      "[-0.6582031   0.12457275  0.05545044  0.35791016  0.13464355  0.00856018] 3   1 \n",
      "[-0.79003906  0.11236572 -0.15991211  0.11987305  0.18444824 -0.07830811] 4   0 \n",
      "[-0.68115234  0.05603027  0.03945923  0.16369629  0.24475098  0.03631592] 4   4 Match 52\n",
      "\n",
      "[-0.6933594   0.21435547 -0.1484375   0.3022461   0.12054443 -0.0031414 ] 3   1 \n",
      "[-0.67578125  0.05755615  0.0380249   0.1973877   0.18273926 -0.01422119] 3   3 Match 53\n",
      "\n",
      "[-0.7001953   0.15771484 -0.04263306  0.20251465  0.13977051 -0.02845764] 3   1 \n",
      "[-0.79589844  0.24975586 -0.22058105  0.25732422  0.03244019 -0.04806519] 3   1 \n",
      "[-0.6772461   0.1517334  -0.03570557  0.21679688  0.17858887 -0.03701782] 3   3 Match 54\n",
      "\n",
      "[-0.74316406  0.1194458  -0.05224609  0.14465332  0.20056152 -0.15759277] 4   0 \n",
      "[-0.625       0.07446289 -0.07635498  0.2854004   0.2841797   0.00598526] 3   5 \n",
      "[-0.75634766  0.23144531 -0.12536621  0.3154297   0.03056335  0.00152493] 3   0 \n",
      "[-0.72802734  0.1817627   0.01657104  0.26293945  0.10009766 -0.065979  ] 3   3 Match 55\n",
      "\n",
      "[-0.7504883   0.16882324  0.02351379  0.3474121   0.04125977 -0.07092285] 3   2 \n",
      "[-0.58935547  0.05334473  0.11853027  0.19689941  0.2697754  -0.07507324] 4   0 \n",
      "[-0.70458984  0.07330322 -0.00370216  0.25561523  0.14233398  0.06051636] 3   0 \n",
      "[-0.57177734 -0.00457382  0.07092285  0.21594238  0.24975586  0.06347656] 4   4 Match 56\n",
      "\n",
      "[-0.64453125  0.11315918 -0.04333496  0.24157715  0.18322754 -0.01358032] 3   1 \n",
      "[-0.7060547   0.12353516 -0.05673218  0.1697998   0.02455139  0.0063324 ] 3   2 \n",
      "[-0.6748047   0.11761475 -0.20227051  0.2166748   0.19799805 -0.03790283] 3   3 Match 57\n",
      "\n",
      "[-0.6279297   0.08154297  0.02635193  0.20922852  0.19580078  0.0881958 ] 3   2 \n",
      "[-0.625       0.34423828  0.02453613  0.42919922  0.02191162 -0.11767578] 3   5 \n",
      "[-0.73339844  0.16247559 -0.15222168  0.38842773  0.19494629 -0.06903076] 3   3 Match 58\n",
      "\n",
      "[-0.6035156   0.08709717  0.05438232  0.3017578   0.17675781  0.04794312] 3   5 \n",
      "[-0.7314453   0.25732422 -0.0637207   0.31420898  0.05578613 -0.05059814] 3   4 \n",
      "[-0.6689453   0.13439941 -0.0112381   0.30419922  0.13647461 -0.03277588] 3   4 \n",
      "[-0.6977539   0.10546875  0.03915405  0.28710938  0.09741211  0.04833984] 3   1 \n",
      "[-0.65771484  0.05780029  0.04165649  0.22875977  0.17041016  0.0324707 ] 3   4 \n",
      "[-0.7260742   0.07666016  0.05834961  0.18115234  0.10375977 -0.08178711] 3   3 Match 59\n",
      "\n",
      "[-0.5493164   0.18115234  0.05770874  0.27148438  0.18408203  0.06286621] 3   0 \n",
      "[-0.64208984  0.13171387  0.08825684  0.203125    0.15600586 -0.05429077] 3   3 Match 60\n",
      "\n",
      "[-0.7553711   0.1932373   0.00667191  0.24572754  0.11676025 -0.07611084] 3   3 Match 61\n",
      "\n",
      "[-0.7792969   0.09576416 -0.22814941  0.19262695  0.17077637 -0.17419434] 3   3 Match 62\n",
      "\n",
      "[-0.72998047  0.2541504  -0.08209229  0.3010254   0.02445984  0.03259277] 3   4 \n",
      "[-0.60546875  0.09143066  0.03768921  0.39624023  0.17358398  0.17480469] 3   0 \n",
      "[-0.6357422   0.13232422  0.02168274  0.27246094  0.08654785  0.02363586] 3   1 \n",
      "[-0.68652344  0.22851562 -0.04125977  0.4375      0.08166504 -0.09991455] 3   4 \n",
      "[-0.8901367   0.22314453 -0.12792969  0.25048828  0.06152344 -0.13867188] 3   1 \n",
      "[-0.5673828  -0.05752563  0.02857971  0.328125    0.26879883  0.1574707 ] 3   1 \n",
      "[-0.77490234 -0.00079441 -0.02418518  0.24804688  0.21496582 -0.09075928] 3   0 \n",
      "[-0.63964844  0.05819702  0.01041412  0.2388916   0.14294434  0.00536346] 3   2 \n",
      "[-0.6665039   0.07427979 -0.08129883  0.24047852  0.16259766  0.10583496] 3   4 \n",
      "[-0.63720703  0.04296875  0.02474976  0.26708984  0.19116211  0.14929199] 3   1 \n",
      "[-0.69970703  0.20483398 -0.23352051  0.3137207   0.21228027 -0.06518555] 3   2 \n",
      "[-0.6826172   0.16418457 -0.05911255  0.3479004   0.13708496 -0.00841522] 3   4 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.6503906   0.30688477 -0.04089355  0.46728516  0.02493286 -0.12548828] 3   1 \n",
      "[-0.63134766  0.11999512  0.0062027   0.27734375  0.20800781  0.04611206] 3   1 \n",
      "[-0.38427734  0.07696533  0.24206543  0.52978516  0.11010742  0.23254395] 3   3 Match 63\n",
      "\n",
      "[-0.79296875  0.19580078  0.02938843  0.4519043   0.02915955 -0.05627441] 3   5 \n",
      "[-0.71875     0.14941406 -0.0692749   0.20471191  0.06793213 -0.0094223 ] 3   5 \n",
      "[-0.63134766  0.10614014  0.0479126   0.25463867  0.16088867  0.00647736] 3   4 \n",
      "[-0.6801758   0.16125488 -0.00711441  0.21484375  0.11804199  0.01245117] 3   2 \n",
      "[-0.7285156   0.1817627  -0.2277832   0.21679688  0.0276947   0.04437256] 3   5 \n",
      "[-0.8046875   0.1586914  -0.09240723  0.3330078   0.02210999 -0.0604248 ] 3   3 Match 64\n",
      "\n",
      "[-0.64697266  0.08465576 -0.05239868  0.17150879  0.18676758 -0.01115417] 4   4 Match 65\n",
      "\n",
      "[-0.7583008   0.2006836  -0.11181641  0.26708984  0.08123779 -0.03128052] 3   1 \n",
      "[-0.69677734  0.22351074 -0.02770996  0.20825195  0.13391113 -0.15490723] 1   3 \n",
      "[-0.70654297  0.03485107  0.02963257  0.15026855  0.23278809 -0.01916504] 4   1 \n",
      "[-0.65283203  0.13867188 -0.00459671  0.17358398  0.12463379 -0.01924133] 3   4 \n",
      "[-0.62109375  0.11437988 -0.03579712  0.23730469  0.18359375 -0.02589417] 3   0 \n",
      "[-0.60009766  0.2076416  -0.00154305  0.18457031  0.13427734 -0.01452637] 1   5 \n",
      "[-0.7373047   0.2388916  -0.0019207   0.37353516  0.05743408 -0.03120422] 3   5 \n",
      "[-0.7011719   0.08599854  0.02160645  0.2734375   0.10522461 -0.05047607] 3   3 Match 66\n",
      "\n",
      "[-0.67089844  0.1842041  -0.04034424  0.31396484  0.03140259  0.00390434] 3   3 Match 67\n",
      "\n",
      "[-0.67089844  0.09527588 -0.1072998   0.3959961   0.12432861  0.1071167 ] 3   3 Match 68\n",
      "\n",
      "[-0.4555664  -0.01513672  0.14929199  0.31445312  0.21826172  0.14318848] 3   4 \n",
      "[-0.70214844  0.18444824  0.07244873  0.2614746   0.00449371 -0.07794189] 3   4 \n",
      "[-0.69970703  0.12390137 -0.07519531  0.22473145  0.06140137 -0.05337524] 3   2 \n",
      "[-0.5986328   0.08081055  0.02114868  0.51953125  0.19665527  0.11071777] 3   1 \n",
      "[-0.7294922   0.15270996 -0.02296448  0.25146484  0.15966797 -0.00841522] 3   1 \n",
      "[-0.64208984  0.14575195  0.01525116  0.32373047  0.11236572  0.06536865] 3   0 \n",
      "[-0.5410156   0.18945312 -0.02264404  0.33666992  0.23754883  0.00549316] 3   5 \n",
      "[-0.73779297  0.26098633 -0.08966064  0.21594238  0.15185547 -0.05123901] 1   3 \n",
      "[-0.70458984  0.16748047 -0.17285156  0.27368164  0.1282959  -0.05877686] 3   5 \n",
      "[-0.6791992   0.0814209  -0.01373291  0.21008301  0.20715332 -0.01847839] 3   1 \n",
      "[-0.7055664   0.12408447 -0.02494812  0.3125      0.12231445  0.06958008] 3   5 \n",
      "[-0.78466797  0.18273926 -0.17907715  0.11352539  0.05044556 -0.05792236] 1   4 \n",
      "[-0.57958984  0.13232422  0.04003906  0.47875977  0.15344238  0.13085938] 3   3 Match 69\n",
      "\n",
      "[-0.6894531   0.1685791  -0.07452393  0.36010742  0.05395508 -0.00144958] 3   2 \n",
      "[-0.76123047  0.17382812 -0.14453125  0.22424316  0.03167725 -0.08477783] 3   0 \n",
      "[-0.73046875  0.15905762 -0.1743164   0.22192383  0.07415771  0.01288605] 3   1 \n",
      "[-0.6894531   0.18103027 -0.11328125  0.28515625  0.16101074 -0.05728149] 3   5 \n",
      "[-0.7783203   0.1328125  -0.07391357  0.24975586  0.18493652 -0.05667114] 3   3 Match 70\n",
      "\n",
      "[-0.7006836   0.08062744 -0.0096817   0.2680664   0.16357422 -0.04467773] 3   4 \n",
      "[-0.5566406   0.09521484  0.0569458   0.23486328  0.26782227  0.01535034] 4   1 \n",
      "[-0.8222656   0.2388916  -0.19128418  0.17797852  0.03207397 -0.03460693] 1   1 Match 71\n",
      "\n",
      "[-0.71533203  0.20959473 -0.12054443  0.35839844  0.03277588  0.0411377 ] 3   3 Match 72\n",
      "\n",
      "[-0.7739258   0.2133789  -0.09130859  0.27905273  0.0602417  -0.13574219] 3   4 \n",
      "[-0.59814453  0.04296875  0.00329781  0.2052002   0.2524414   0.05810547] 4   1 \n",
      "[-0.6357422   0.13305664  0.01146698  0.33911133  0.10614014  0.1192627 ] 3   3 Match 73\n",
      "\n",
      "[-0.671875    0.2536621  -0.0051651   0.36865234  0.12097168 -0.02706909] 3   5 \n",
      "[-0.6796875   0.13708496 -0.10906982  0.28027344  0.13256836  0.0209198 ] 3   2 \n",
      "[-0.6171875  -0.010849    0.0824585   0.24414062  0.18713379 -0.00888824] 3   3 Match 74\n",
      "\n",
      "[-0.68847656  0.02201843 -0.01751709  0.2668457   0.27026367  0.07788086] 4   3 \n",
      "[-0.6328125   0.17822266 -0.03213501  0.23144531  0.15991211 -0.02537537] 3   2 \n",
      "[-0.7402344   0.20178223 -0.2076416   0.24572754  0.08551025 -0.21984863] 3   3 Match 75\n",
      "\n",
      "[-0.6430664   0.20544434 -0.01791382  0.3479004   0.0993042  -0.04284668] 3   0 \n",
      "[-0.71191406  0.22290039 -0.06585693  0.24682617  0.13989258 -0.0473938 ] 3   4 \n",
      "[-7.4902344e-01  1.2768555e-01  1.6937256e-02  3.2519531e-01\n",
      "  1.3525391e-01  4.3416023e-04] 3   1 \n",
      "[-0.63427734  0.13769531 -0.05319214  0.19567871  0.26049805  0.01171112] 4   3 \n",
      "[-0.5883789   0.1015625   0.03326416  0.15612793  0.22241211  0.03109741] 4   3 \n",
      "[-0.5810547  -0.02574158 -0.01410675  0.40893555  0.3022461   0.08178711] 3   5 \n",
      "[-0.69091797  0.11340332  0.0153656   0.30737305  0.10986328  0.02182007] 3   4 \n",
      "[-0.7583008   0.11804199 -0.07165527  0.3083496   0.1048584   0.03445435] 3   1 \n",
      "[-0.7817383   0.1772461  -0.10852051  0.2475586  -0.01843262 -0.02938843] 3   2 \n",
      "[-0.58154297  0.3515625  -0.00700378  0.52197266  0.04470825 -0.07562256] 3   4 \n",
      "[-0.6621094   0.12414551 -0.04013062  0.23156738  0.07672119  0.00375366] 3   1 \n",
      "[-0.75683594  0.0682373  -0.06665039  0.26123047  0.14855957 -0.11914062] 3   1 \n",
      "[-0.73339844  0.13781738 -0.1854248   0.27905273  0.25585938 -0.12451172] 3   1 \n",
      "[-0.6616211   0.125       0.02293396  0.15759277  0.19702148  0.01242828] 4   2 \n",
      "[-0.73046875  0.09741211  0.02070618  0.23046875  0.16772461 -0.06011963] 3   0 \n",
      "[-0.6176758   0.09802246 -0.02601624  0.2529297   0.1920166   0.00868225] 3   4 \n",
      "[-0.734375    0.06176758 -0.03692627  0.14587402  0.1665039  -0.10778809] 4   1 \n",
      "[-0.68896484  0.20385742 -0.0255127   0.2849121   0.07403564  0.04696655] 3   4 \n",
      "[-0.703125    0.17687988 -0.17675781  0.27416992  0.04421997  0.00452423] 3   1 \n",
      "[-0.82373047  0.22460938 -0.17419434  0.18103027  0.05712891 -0.12286377] 1   0 \n",
      "[-0.78125     0.12121582 -0.24377441  0.3154297   0.16491699  0.00217819] 3   1 \n",
      "[-0.6689453   0.26586914 -0.09075928  0.31933594  0.13049316 -0.09259033] 3   5 \n",
      "[-0.6772461   0.17126465  0.01407623  0.22595215  0.18615723  0.00237656] 3   4 \n",
      "[-0.7470703   0.20385742 -0.02679443  0.3557129   0.02856445 -0.02337646] 3   5 \n",
      "[-0.6855469   0.1628418  -0.02664185  0.21044922  0.03488159  0.00471878] 3   1 \n",
      "[-0.7192383   0.19177246 -0.05007935  0.4086914   0.02734375 -0.00371552] 3   3 Match 76\n",
      "\n",
      "[-0.6298828   0.11273193  0.05810547  0.4609375   0.10015869  0.07440186] 3   2 \n",
      "[-0.6904297   0.09649658 -0.09985352  0.24377441  0.1496582   0.0491333 ] 3   2 \n",
      "[-0.74365234  0.25585938 -0.22387695  0.21777344  0.00837708 -0.12335205] 1   1 Match 77\n",
      "\n",
      "[-0.57470703  0.14416504  0.09118652  0.33935547  0.1505127   0.07940674] 3   4 \n",
      "[-0.73583984  0.23388672 -0.0579834   0.27490234  0.11029053 -0.09033203] 3   1 \n",
      "[-0.7421875   0.12084961  0.00415039  0.31176758  0.0880127   0.01338196] 3   4 \n",
      "[-0.6245117   0.03338623  0.08447266  0.3894043   0.11553955  0.07391357] 3   3 Match 78\n",
      "\n",
      "[-0.79248047  0.12316895 -0.13647461  0.1315918   0.1459961  -0.13171387] 4   3 \n",
      "[-0.69384766  0.17321777 -0.05743408  0.3112793   0.07110596  0.00259781] 3   3 Match 79\n",
      "\n",
      "[-0.6748047   0.19067383 -0.00527954  0.36767578  0.10540771  0.12280273] 3   3 Match 80\n",
      "\n",
      "[-0.74658203  0.22521973 -0.11401367  0.17932129  0.07989502 -0.04385376] 1   2 \n",
      "[-0.69873047  0.18823242  0.00199509  0.34570312  0.08673096 -0.00637817] 3   1 \n",
      "[-0.73339844  0.18774414 -0.03436279  0.15026855  0.07275391 -0.04302979] 1   3 \n",
      "[-0.6669922   0.05081177 -0.00175381  0.33422852  0.1706543   0.08599854] 3   3 Match 81\n",
      "\n",
      "[-0.63378906  0.15124512 -0.00418472  0.24963379  0.14221191  0.1071167 ] 3   1 \n",
      "[-0.6098633  -0.00205231  0.04663086  0.3737793   0.28466797  0.07269287] 3   1 \n",
      "[-0.7758789   0.0994873   0.02156067  0.06463623  0.12597656 -0.09234619] 4   1 \n",
      "[-0.7246094   0.12719727 -0.05291748  0.20178223  0.24414062 -0.04119873] 4   4 Match 82\n",
      "\n",
      "[-0.6147461   0.04037476  0.0496521   0.23730469  0.12939453  0.11425781] 3   3 Match 83\n",
      "\n",
      "[-0.5839844   0.26635742 -0.02389526  0.2927246   0.06274414 -0.03448486] 3   3 Match 84\n",
      "\n",
      "[-0.6972656  -0.02153015 -0.03497314  0.2442627   0.29589844 -0.02731323] 4   1 \n",
      "[-0.73046875  0.18603516 -0.01869202  0.14660645  0.06234741 -0.09161377] 1   4 \n",
      "[-0.6269531   0.2944336  -0.04290771  0.5185547   0.00982666 -0.08282471] 3   4 \n",
      "[-0.69873047 -0.00830841  0.07354736  0.25952148  0.16833496  0.06347656] 3   4 \n",
      "[-0.6933594   0.13146973 -0.0982666   0.2668457   0.11950684  0.03311157] 3   4 \n",
      "[-0.7084961   0.05780029  0.03262329  0.21569824  0.10845947 -0.00527954] 3   0 \n",
      "[-0.6928711   0.06195068  0.10870361  0.23046875  0.14343262 -0.03283691] 3   1 \n",
      "[-0.6791992   0.18664551  0.01708984  0.23608398  0.11083984  0.01021576] 3   4 \n",
      "[-0.61376953  0.09063721  0.01875305  0.27905273  0.16442871  0.05175781] 3   5 \n",
      "[-0.7988281  -0.01763916 -0.16589355  0.20581055  0.19421387 -0.06628418] 3   1 \n",
      "[-0.58447266  0.18554688 -0.05999756  0.39770508  0.06561279  0.10070801] 3   3 Match 85\n",
      "\n",
      "[-0.72998047  0.13964844 -0.03936768  0.20166016  0.09771729 -0.0402832 ] 3   3 Match 86\n",
      "\n",
      "[-0.6694336   0.2010498  -0.11950684  0.2442627   0.0847168  -0.0451355 ] 3   4 \n",
      "[-0.57470703  0.17687988  0.04867554  0.29003906  0.21118164  0.02383423] 3   3 Match 87\n",
      "\n",
      "[-0.6269531   0.10742188  0.03808594  0.2241211   0.1697998   0.03286743] 3   1 \n",
      "[-0.7685547   0.12768555  0.03308105  0.1907959   0.12463379 -0.08099365] 3   4 \n",
      "[-0.72753906  0.28125    -0.06726074  0.33081055  0.07861328 -0.15197754] 3   2 \n",
      "[-0.55126953  0.07446289  0.07806396  0.14855957  0.24975586  0.00391006] 4   0 \n",
      "[-0.7236328   0.19506836 -0.14929199  0.13098145  0.11383057 -0.11907959] 1   1 Match 88\n",
      "\n",
      "[-0.7104492   0.21313477 -0.01966858  0.2927246   0.14929199 -0.05157471] 3   1 \n",
      "[-0.79248047  0.14758301 -0.15820312  0.2709961   0.03369141 -0.00274086] 3   5 \n",
      "[-0.7285156   0.14709473 -0.06106567  0.29541016  0.09069824  0.04458618] 3   4 \n",
      "[-0.76464844  0.38745117 -0.1751709   0.27539062  0.04223633 -0.27783203] 1   4 \n",
      "[-0.56152344  0.03158569  0.11120605  0.1348877   0.3076172  -0.00124931] 4   0 \n",
      "[-0.79296875  0.13195801 -0.10015869  0.18310547  0.18273926 -0.11749268] 3   5 \n",
      "[-0.6801758   0.2536621   0.04724121  0.4675293   0.02818298 -0.01818848] 3   5 \n",
      "[-0.7885742   0.3137207  -0.14221191  0.25952148  0.05566406 -0.10223389] 1   1 Match 89\n",
      "\n",
      "[-0.65966797  0.07421875  0.02310181  0.18530273  0.14929199  0.0198822 ] 3   3 Match 90\n",
      "\n",
      "[-0.60791016  0.19458008  0.03634644  0.26049805  0.05123901 -0.02235413] 3   3 Match 91\n",
      "\n",
      "[-0.70458984  0.20544434 -0.05368042  0.29003906  0.0793457   0.02055359] 3   1 \n",
      "[-0.69384766  0.07580566 -0.00260353  0.31689453  0.1751709   0.08502197] 3   3 Match 92\n",
      "\n",
      "[-0.65185547  0.11114502 -0.04736328  0.33374023  0.12023926  0.00801849] 3   4 \n",
      "[-0.7167969   0.16601562  0.00201988  0.32958984  0.00611877  0.04156494] 3   3 Match 93\n",
      "\n",
      "[-0.73291016  0.15893555 -0.06402588  0.20288086  0.10430908 -0.05834961] 3   5 \n",
      "[-0.65527344  0.09539795  0.01319122  0.17541504  0.22937012 -0.03433228] 4   1 \n",
      "[-0.7631836   0.17053223 -0.03967285  0.21142578  0.12902832 -0.06622314] 3   2 \n",
      "[-0.63720703  0.09179688  0.02046204  0.2932129   0.24853516  0.00068331] 3   4 \n",
      "[-0.52246094  0.04653931  0.11499023  0.2553711   0.26293945  0.06210327] 4   3 \n",
      "[-0.74560547  0.13452148 -0.02302551  0.35888672  0.06451416  0.01901245] 3   2 \n",
      "[-0.64941406  0.17541504 -0.00608444  0.16308594  0.15307617  0.0280304 ] 1   4 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.671875    0.16210938  0.03604126  0.35888672  0.1038208   0.08331299] 3   3 Match 94\n",
      "\n",
      "[-0.6948242   0.18493652 -0.08758545  0.14099121  0.12731934 -0.00766373] 1   4 \n",
      "[-0.7207031   0.27954102 -0.10375977  0.17150879  0.09906006 -0.09680176] 1   0 \n",
      "[-0.7270508   0.2322998  -0.09277344  0.28515625  0.01411438  0.05108643] 3   5 \n",
      "[-0.6899414   0.13708496  0.01421356  0.28564453  0.09735107  0.01939392] 3   5 \n",
      "[-0.60058594  0.18652344  0.04882812  0.2631836   0.15881348  0.01820374] 3   2 \n",
      "[-0.61376953  0.06903076  0.09130859  0.29077148  0.19506836  0.01783752] 3   1 \n",
      "[-0.7832031   0.12280273 -0.0993042   0.24914551  0.18029785  0.03738403] 3   4 \n",
      "[-0.69677734  0.11071777 -0.01889038  0.15454102  0.10308838 -0.03814697] 3   2 \n",
      "[-0.5546875   0.06298828  0.12524414  0.29296875  0.16662598  0.12634277] 3   3 Match 95\n",
      "\n",
      "[-0.64501953  0.03988647  0.04980469  0.21948242  0.1875     -0.01879883] 3   2 \n",
      "[-0.65771484  0.08197021  0.05148315  0.21264648  0.25341797  0.07171631] 4   1 \n",
      "[-0.76953125  0.1772461  -0.14880371  0.17871094  0.11914062 -0.09509277] 3   5 \n",
      "[-0.66503906  0.19177246  0.01702881  0.23803711  0.1394043   0.0508728 ] 3   1 \n",
      "[-0.67529297  0.02441406  0.06292725  0.21813965  0.22497559 -0.01053619] 4   1 \n",
      "[-0.6567383   0.10510254  0.05993652  0.19604492  0.1697998   0.07684326] 3   3 Match 96\n",
      "\n",
      "[-0.64746094  0.03643799  0.0980835   0.18481445  0.15759277  0.05413818] 3   3 Match 97\n",
      "\n",
      "[-0.58935547  0.11828613  0.01083374  0.25195312  0.171875    0.11035156] 3   4 \n",
      "[-0.7426758   0.16711426 -0.07550049  0.30541992  0.06341553  0.12261963] 3   4 \n",
      "[-0.69921875 -0.05422974  0.0581665   0.13305664  0.21166992 -0.05252075] 4   5 \n",
      "[-0.70654297  0.125       0.0319519   0.24719238  0.0824585   0.06427002] 3   3 Match 98\n",
      "\n",
      "[-0.5932617   0.12030029  0.07556152  0.3161621   0.11120605  0.08911133] 3   1 \n",
      "[-0.68603516  0.05181885  0.12335205  0.20324707  0.21496582 -0.02255249] 4   1 \n",
      "[-0.72265625  0.13183594 -0.04849243  0.25708008  0.04415894  0.04519653] 3   5 \n",
      "[-0.59228516  0.07354736  0.09289551  0.21972656  0.22607422  0.05056763] 4   2 \n",
      "[-0.64208984  0.19946289  0.03942871  0.3540039   0.08361816 -0.01664734] 3   3 Match 99\n",
      "\n",
      "[-7.3828125e-01  1.1016846e-01  5.8937073e-03  2.7099609e-01\n",
      "  7.1350098e-02  6.8092346e-04] 3   4 \n",
      "[-0.7573242   0.05541992 -0.0848999   0.19555664  0.10174561 -0.02734375] 3   1 \n",
      "[-0.73535156  0.06402588 -0.05856323  0.29638672  0.11737061 -0.00758362] 3   3 Match 100\n",
      "\n",
      "[-0.6977539   0.03897095  0.06781006  0.17089844  0.15856934 -0.06091309] 3   1 \n",
      "[-0.62353516  0.01940918  0.07366943  0.2208252   0.2836914   0.07348633] 4   3 \n",
      "[-0.5576172   0.08648682  0.10516357  0.2734375   0.17687988  0.09686279] 3   1 \n",
      "[-0.6621094   0.18383789 -0.12103271  0.24914551  0.20678711 -0.05743408] 3   3 Match 101\n",
      "\n",
      "[-0.6123047   0.10656738  0.05206299  0.23327637  0.2322998   0.1352539 ] 3   2 \n",
      "[-0.7260742   0.1895752  -0.01965332  0.22814941  0.08453369  0.00917816] 3   5 \n",
      "[-0.69677734  0.17126465 -0.11560059  0.22753906  0.20043945 -0.12213135] 3   1 \n",
      "[-0.73291016  0.20776367  0.08203125  0.32666016  0.0748291  -0.09338379] 3   3 Match 102\n",
      "\n",
      "[-0.5678711   0.07391357  0.08752441  0.30737305  0.24389648  0.06933594] 3   3 Match 103\n",
      "\n",
      "[-0.70947266  0.1607666  -0.09515381  0.1887207   0.15429688  0.00574112] 3   3 Match 104\n",
      "\n",
      "[-0.7167969   0.16418457 -0.04452515  0.0737915   0.12255859 -0.08703613] 1   3 \n",
      "[-0.703125    0.10913086 -0.05480957  0.28198242  0.13549805  0.0824585 ] 3   4 \n",
      "[-0.74853516  0.12658691  0.00518036  0.16345215  0.22070312 -0.0617981 ] 4   3 \n",
      "[-0.64941406  0.17089844  0.0056076   0.32641602  0.12133789  0.11376953] 3   3 Match 105\n",
      "\n",
      "[-0.6616211   0.15234375  0.02737427  0.23522949  0.12072754 -0.03192139] 3   5 \n",
      "[-7.02636719e-01  2.34741211e-01 -1.16119385e-02  3.94775391e-01\n",
      "  1.89542770e-04  2.95410156e-02] 3   4 \n",
      "[-0.79296875  0.15478516 -0.00281525  0.34106445  0.01657104 -0.01664734] 3   5 \n",
      "[-0.7915039   0.21789551 -0.2919922   0.08782959  0.04223633 -0.07452393] 1   1 Match 106\n",
      "\n",
      "[-0.7368164   0.07116699  0.02175903  0.10327148  0.2010498   0.00985718] 4   2 \n",
      "[-0.6464844   0.19250488 -0.05938721  0.20703125  0.19335938 -0.05496216] 3   4 \n",
      "[-0.6933594   0.04519653 -0.03744507  0.2709961   0.16088867  0.0160675 ] 3   2 \n",
      "[-0.63134766  0.15344238 -0.05514526  0.20080566  0.21520996 -0.06915283] 4   2 \n",
      "[-0.8071289   0.16723633 -0.24291992  0.08221436  0.1472168  -0.07263184] 1   3 \n",
      "[-0.8144531   0.14111328 -0.1796875   0.15356445  0.11810303 -0.05569458] 3   5 \n",
      "[-0.78564453  0.03335571 -0.10308838  0.23132324  0.16247559  0.0227356 ] 3   2 \n",
      "[-0.6899414   0.09069824  0.00632095  0.30444336  0.12915039 -0.0196228 ] 3   0 \n",
      "[-0.77783203  0.10119629 -0.09515381  0.28857422  0.09863281 -0.02636719] 3   4 \n",
      "[-0.68896484  0.10522461 -0.06433105  0.20422363  0.12139893  0.14025879] 3   1 \n",
      "[-0.7294922   0.11065674  0.01960754  0.22338867  0.13867188 -0.04321289] 3   1 \n",
      "[-0.79345703  0.2133789  -0.16333008  0.2298584   0.13806152 -0.03717041] 3   0 \n",
      "[-0.7001953   0.1083374   0.03125     0.31640625  0.10980225  0.1026001 ] 3   3 Match 107\n",
      "\n",
      "[-0.70996094  0.25732422 -0.08013916  0.29101562  0.14660645 -0.12915039] 3   4 \n",
      "[-0.51953125  0.15063477  0.04510498  0.17272949  0.296875    0.0546875 ] 4   0 \n",
      "[-0.65478516  0.21643066 -0.01073456  0.37548828  0.07299805  0.0122757 ] 3   4 \n",
      "[-0.65722656  0.14770508 -0.03479004  0.12976074  0.25732422  0.00637817] 4   3 \n",
      "[-0.71240234  0.11761475 -0.06658936  0.16967773  0.13720703 -0.0496521 ] 3   5 \n",
      "[-0.62060547  0.10668945 -0.02372742  0.31518555  0.22619629  0.08746338] 3   1 \n",
      "[-0.61865234  0.11187744  0.02037048  0.2919922   0.19396973  0.01370239] 3   3 Match 108\n",
      "\n",
      "[-0.7578125   0.17419434 -0.09466553  0.29174805  0.05480957 -0.00652313] 3   5 \n",
      "[-0.7480469   0.31030273 -0.13049316  0.27026367  0.15844727 -0.09143066] 1   3 \n",
      "[-0.63964844  0.00880432  0.05935669  0.19128418  0.1973877   0.05508423] 4   1 \n",
      "[-0.69970703  0.19030762 -0.0350647   0.2734375   0.08239746 -0.00716019] 3   4 \n",
      "[-0.78466797  0.1928711  -0.00253105  0.31420898  0.11279297 -0.10675049] 3   3 Match 109\n",
      "\n",
      "[-0.62060547  0.18408203 -0.03445435  0.2788086   0.09881592 -0.00169659] 3   3 Match 110\n",
      "\n",
      "[-0.77441406  0.18676758 -0.0249176   0.2680664   0.08831787  0.03955078] 3   3 Match 111\n",
      "\n",
      "[-0.7265625   0.28588867 -0.10095215  0.28271484  0.03939819 -0.08050537] 1   5 \n",
      "[-0.7216797   0.04370117 -0.04534912  0.22021484  0.16467285  0.11505127] 3   1 \n",
      "[-0.6953125   0.11419678 -0.08227539  0.18359375  0.21569824  0.03027344] 4   1 \n",
      "[-0.7084961   0.25146484 -0.20141602  0.22583008  0.1373291  -0.09362793] 1   4 \n",
      "[-0.70996094  0.17858887  0.01725769  0.35375977  0.04327393  0.04534912] 3   5 \n",
      "[-0.68310547  0.06573486 -0.01893616  0.15319824  0.22436523  0.01791382] 4   3 \n",
      "[-0.7216797   0.20227051  0.02388     0.31860352  0.08758545  0.08752441] 3   5 \n",
      "[-0.70458984  0.18371582 -0.11700439  0.2310791   0.07904053 -0.02806091] 3   1 \n",
      "[-0.65966797  0.16027832 -0.037323    0.3918457   0.02401733  0.0075264 ] 3   5 \n",
      "[-0.70703125  0.11328125  0.04187012  0.26367188  0.10583496  0.06002808] 3   1 \n",
      "[-0.72509766  0.09484863  0.0411377   0.19689941  0.11523438 -0.0189209 ] 3   3 Match 112\n",
      "\n",
      "[-0.6850586   0.12475586  0.022995    0.20349121  0.11981201 -0.06192017] 3   5 \n",
      "[-0.7807617   0.08953857 -0.05792236  0.10302734  0.13867188 -0.07208252] 4   4 Match 113\n",
      "\n",
      "[-0.6821289   0.1307373  -0.04663086  0.22692871  0.20605469  0.03811646] 3   1 \n",
      "[-0.67578125  0.2548828   0.00652695  0.17822266  0.12054443 -0.1607666 ] 1   5 \n",
      "[-0.6821289   0.13757324  0.01123047  0.20898438  0.13574219 -0.0791626 ] 3   2 \n",
      "[-0.71484375  0.01296234 -0.00874329  0.26708984  0.2565918  -0.0567627 ] 3   3 Match 114\n",
      "\n",
      "[-0.68603516  0.11523438  0.07476807  0.27319336  0.04321289 -0.00210381] 3   3 Match 115\n",
      "\n",
      "[-0.7158203   0.19897461 -0.00230789  0.33251953  0.0513916  -0.03625488] 3   5 \n",
      "[-0.6269531   0.16992188 -0.01550293  0.34985352  0.06018066 -0.01444244] 3   5 \n",
      "[-0.79589844  0.06512451 -0.07910156  0.11657715  0.21044922 -0.10668945] 4   2 \n",
      "[-0.6557617   0.20751953 -0.07086182  0.20568848  0.2368164  -0.01014709] 4   0 \n",
      "[-0.86816406  0.08178711 -0.08361816  0.18225098  0.12597656 -0.06970215] 3   1 \n",
      "[-0.67333984  0.00674438  0.00529099  0.27319336  0.2253418   0.04251099] 3   1 \n",
      "[-0.58984375  0.12768555  0.09545898  0.20214844  0.19116211  0.01442719] 3   3 Match 116\n",
      "\n",
      "[-0.8222656   0.28442383 -0.11639404  0.24133301  0.08728027 -0.09588623] 1   1 Match 117\n",
      "\n",
      "[-0.68847656  0.13806152  0.03845215  0.2980957   0.09667969 -0.05276489] 3   0 \n",
      "[-0.8413086   0.27661133 -0.15527344  0.22131348  0.08483887 -0.19921875] 1   2 \n",
      "[-0.71533203  0.23583984 -0.23413086  0.121521    0.05950928 -0.11700439] 1   5 \n",
      "[-0.6557617   0.0760498  -0.10247803  0.35424805  0.13659668  0.09667969] 3   3 Match 118\n",
      "\n",
      "[-0.64746094  0.18688965 -0.05447388  0.37036133  0.04086304  0.06152344] 3   5 \n",
      "[-0.71728516  0.14038086 -0.03128052  0.3227539   0.0513916   0.03131104] 3   3 Match 119\n",
      "\n",
      "[-0.54785156  0.13598633  0.03610229  0.28125     0.13415527  0.01911926] 3   2 \n",
      "[-0.6333008   0.10839844  0.02549744  0.28979492  0.19689941 -0.0335083 ] 3   1 \n",
      "[-0.7910156   0.18969727 -0.13208008  0.2614746   0.15368652 -0.05178833] 3   3 Match 120\n",
      "\n",
      "[-0.6464844   0.0284729  -0.01013184  0.4567871   0.24023438  0.00164986] 3   0 \n",
      "[-0.63427734  0.03201294  0.03305054  0.33935547  0.16174316 -0.01313782] 3   5 \n",
      "[-0.6791992   0.10717773 -0.00934601  0.3256836   0.10223389  0.02043152] 3   4 \n",
      "[-0.72753906  0.04345703  0.08538818  0.11480713  0.27246094 -0.08197021] 4   2 \n",
      "[-0.7270508   0.09527588 -0.121521    0.14294434  0.21679688 -0.10247803] 4   1 \n",
      "[-0.64208984  0.10150146  0.00547791  0.26953125  0.23364258 -0.06646729] 3   3 Match 121\n",
      "\n",
      "[-0.6015625   0.10748291  0.05639648  0.27001953  0.13879395  0.09033203] 3   1 \n",
      "[-0.73095703  0.1149292  -0.05426025  0.22338867  0.16882324 -0.02894592] 3   1 \n",
      "[-0.6713867   0.22668457 -0.2109375   0.24267578  0.0690918  -0.14208984] 3   2 \n",
      "[-0.6953125  -0.04125977 -0.04330444  0.20715332  0.22460938 -0.05383301] 4   3 \n",
      "[-0.6489258   0.06726074  0.05072021  0.26733398  0.15161133  0.02740479] 3   3 Match 122\n",
      "\n",
      "[-0.6142578   0.09564209  0.02507019  0.23791504  0.28320312  0.08703613] 4   2 \n",
      "[-0.6958008   0.05297852  0.0069809   0.19177246  0.17822266 -0.01005554] 3   2 \n",
      "[-0.67822266  0.09698486  0.00914001  0.20812988  0.3083496  -0.07824707] 4   1 \n",
      "[-0.66748047  0.09637451 -0.15246582  0.27612305  0.25439453  0.00689697] 3   5 \n",
      "[-0.60302734  0.16455078 -0.08996582  0.30810547  0.21484375  0.05096436] 3   5 \n",
      "[-0.6948242   0.12335205  0.03311157  0.2142334   0.13598633 -0.01583862] 3   1 \n",
      "[-0.63183594  0.13220215 -0.06439209  0.22570801  0.27246094 -0.02333069] 4   1 \n",
      "[-0.77685547  0.08947754 -0.00387955  0.18823242  0.17675781 -0.06793213] 3   0 \n",
      "[-0.7167969   0.13342285  0.03662109  0.27978516  0.12194824 -0.01225281] 3   1 \n",
      "[-0.65625     0.14770508  0.00902557  0.26464844  0.15185547 -0.02633667] 3   3 Match 123\n",
      "\n",
      "[-0.78515625  0.0894165   0.0010376   0.26000977  0.06286621  0.02104187] 3   4 \n",
      "[-0.69433594  0.2006836  -0.06677246  0.24133301  0.13171387 -0.04196167] 3   1 \n",
      "[-0.6748047   0.16088867 -0.02375793  0.29052734  0.16369629 -0.02378845] 3   3 Match 124\n",
      "\n",
      "[-0.6225586   0.17053223  0.06246948  0.2142334   0.13830566 -0.01409912] 3   5 \n",
      "[-0.7480469   0.24401855 -0.07592773  0.31347656  0.03460693 -0.04476929] 3   3 Match 125\n",
      "\n",
      "[-0.56933594  0.1430664   0.10198975  0.32983398  0.1307373  -0.03771973] 3   3 Match 126\n",
      "\n",
      "[-0.64501953  0.17456055 -0.03768921  0.2541504   0.16235352  0.04434204] 3   0 \n",
      "[-0.73828125  0.17602539 -0.06112671  0.28125     0.11932373 -0.03463745] 3   1 \n",
      "[-0.6713867   0.06048584  0.05047607  0.30200195  0.1932373   0.0904541 ] 3   2 \n",
      "[-0.68896484  0.06124878  0.04660034  0.328125    0.1348877   0.03051758] 3   2 \n",
      "[-0.5859375   0.12426758 -0.03677368  0.20031738  0.2076416  -0.00751877] 4   4 Match 127\n",
      "\n",
      "[-0.6665039   0.22351074 -0.10760498  0.26000977  0.19445801 -0.01094055] 3   3 Match 128\n",
      "\n",
      "[-0.6767578   0.1965332   0.00364876  0.3317871   0.06774902  0.06100464] 3   4 \n",
      "[-0.7675781   0.03086853 -0.00933838  0.17333984  0.24255371 -0.06591797] 4   2 \n",
      "[-0.78027344  0.08166504 -0.0168457   0.1192627   0.0508728  -0.08740234] 3   2 \n",
      "[-0.6743164   0.14282227  0.04058838  0.34423828  0.11132812  0.03448486] 3   1 \n",
      "[-0.6689453   0.24194336 -0.17443848  0.37402344  0.09729004  0.00465393] 3   0 \n",
      "[-0.7763672   0.07696533 -0.09057617  0.20349121  0.05392456 -0.07275391] 3   1 \n",
      "[-0.70214844  0.22973633 -0.07598877  0.39453125  0.02398682 -0.05932617] 3   1 \n",
      "[-0.6870117   0.10369873 -0.00761795  0.24169922  0.21826172  0.10253906] 3   2 \n",
      "[-0.70751953  0.23400879 -0.01432037  0.3581543   0.05102539 -0.1048584 ] 3   5 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.78222656  0.05328369 -0.01679993  0.3166504   0.09619141 -0.04455566] 3   3 Match 129\n",
      "\n",
      "[-0.61816406  0.24938965 -0.11645508  0.40161133  0.0553894   0.10821533] 3   2 \n",
      "[-0.6298828   0.16345215  0.03004456  0.3227539   0.11871338  0.04937744] 3   2 \n",
      "[-0.67333984  0.08972168 -0.04397583  0.30737305  0.18786621  0.04788208] 3   0 \n",
      "[-0.7910156   0.12756348 -0.05380249  0.2763672   0.07611084 -0.01524353] 3   3 Match 130\n",
      "\n",
      "[-0.77001953  0.05456543 -0.0760498   0.23120117  0.12237549 -0.04110718] 3   2 \n",
      "[-6.8115234e-01  1.7553711e-01 -1.1467934e-04  2.5830078e-01\n",
      "  7.9650879e-02  6.4208984e-02] 3   3 Match 131\n",
      "\n",
      "[-0.6582031   0.07830811  0.06896973  0.16638184  0.25610352 -0.04452515] 4   0 \n",
      "[-0.60253906  0.10772705  0.03863525  0.28198242  0.20178223  0.0423584 ] 3   1 \n",
      "[-0.6533203   0.03158569  0.05209351  0.21154785  0.1607666   0.0116272 ] 3   4 \n",
      "[-0.7036133   0.16357422 -0.05780029  0.26757812  0.08660889 -0.05380249] 3   3 Match 132\n",
      "\n",
      "[-0.6791992   0.17053223 -0.00338173  0.27612305  0.08581543 -0.00407028] 3   1 \n",
      "[-0.65234375  0.20178223  0.01398468  0.33032227  0.10461426  0.08660889] 3   2 \n",
      "[-0.71875     0.20092773 -0.04956055  0.37573242  0.06872559  0.02006531] 3   5 \n",
      "[-0.62597656  0.02804565  0.08428955  0.1850586   0.16845703  0.03326416] 3   2 \n",
      "[-0.6538086   0.15917969 -0.0243988   0.13427734  0.17053223 -0.02926636] 4   4 Match 133\n",
      "\n",
      "[-0.56689453  0.06768799  0.10186768  0.22363281  0.1685791   0.07012939] 3   3 Match 134\n",
      "\n",
      "[-0.60058594  0.14147949 -0.05935669  0.30493164  0.18103027  0.03134155] 3   3 Match 135\n",
      "\n",
      "[-0.6044922   0.15209961  0.03311157  0.16381836  0.21325684  0.04974365] 4   1 \n",
      "[-0.7026367   0.2253418  -0.04116821  0.25195312  0.03915405 -0.03067017] 3   3 Match 136\n",
      "\n",
      "[-0.6484375   0.02653503 -0.00515366  0.27563477  0.21923828  0.01432037] 3   3 Match 137\n",
      "\n",
      "[-0.6015625   0.21105957  0.02584839  0.30297852  0.03201294  0.04251099] 3   4 \n",
      "[-0.69628906  0.13830566 -0.01216888  0.19372559  0.16906738 -0.08129883] 3   1 \n",
      "[-0.59472656  0.06427002  0.11846924  0.24487305  0.15270996  0.09729004] 3   5 \n",
      "[-0.6645508   0.07885742  0.07281494  0.22814941  0.1953125   0.04904175] 3   3 Match 138\n",
      "\n",
      "[-0.6323242   0.18884277 -0.05496216  0.3503418   0.08312988  0.04598999] 3   1 \n",
      "[-0.55029297  0.09460449  0.08648682  0.21582031  0.18896484  0.01747131] 3   4 \n",
      "[-5.9179688e-01  4.9102783e-02  5.1940918e-02  8.5327148e-02\n",
      "  2.7099609e-01  7.7903271e-05] 4   5 \n",
      "[-0.80078125  0.15698242 -0.04873657  0.32739258  0.03552246  0.00364685] 3   5 \n",
      "[-0.703125    0.08172607 -0.00125599  0.16516113  0.06665039 -0.02325439] 3   3 Match 139\n",
      "\n",
      "[-0.67529297  0.26513672  0.03186035  0.3474121   0.07159424 -0.03540039] 3   3 Match 140\n",
      "\n",
      "[-0.62402344  0.10327148 -0.02210999  0.31103516  0.18701172  0.0904541 ] 3   3 Match 141\n",
      "\n",
      "[-0.70751953  0.22937012 -0.01301575  0.22814941  0.00094128 -0.03875732] 1   2 \n",
      "[-0.7470703   0.171875   -0.02032471  0.37426758  0.00688171  0.05859375] 3   4 \n",
      "[-0.67822266  0.16088867 -0.07012939  0.15307617  0.1204834  -0.06085205] 1   5 \n",
      "[-0.7265625   0.20507812 -0.1574707   0.2442627   0.03833008 -0.08074951] 3   1 \n",
      "[-0.79296875  0.17810059 -0.1114502   0.21984863  0.08013916 -0.03860474] 3   2 \n",
      "[-0.7949219   0.07446289 -0.12225342  0.22827148  0.12115479 -0.07086182] 3   4 \n",
      "[-0.68066406  0.21008301 -0.04309082  0.21154785  0.08251953  0.01661682] 3   3 Match 142\n",
      "\n",
      "[-0.77246094  0.15795898 -0.01319885  0.19604492  0.11859131 -0.12768555] 3   5 \n",
      "[-0.7241211   0.26635742 -0.125       0.3059082   0.09906006 -0.0166626 ] 3   0 \n",
      "[-0.5761719   0.03845215  0.1640625   0.14782715  0.2788086  -0.01785278] 4   0 \n",
      "[-0.5966797   0.07305908  0.04382324  0.19824219  0.19702148  0.14709473] 3   1 \n",
      "[-0.60791016  0.02223206  0.08929443  0.24816895  0.22607422 -0.01071167] 3   1 \n",
      "[-0.7089844   0.10821533 -0.02722168  0.23303223  0.19677734  0.00349236] 3   4 \n",
      "[-0.6875      0.359375   -0.09747314  0.37695312  0.00089741 -0.1842041 ] 3   5 \n",
      "[-0.7128906   0.10595703  0.01643372  0.19250488  0.22399902 -0.01571655] 4   0 \n",
      "[-0.65234375  0.14562988 -0.00072098  0.16821289  0.25927734 -0.05160522] 4   4 Match 143\n",
      "\n",
      "[-0.7680664  -0.01443481 -0.04104614  0.2055664   0.07666016 -0.05935669] 3   2 \n",
      "[-0.63671875  0.05950928  0.10882568  0.19165039  0.16040039  0.12097168] 3   4 \n",
      "[-0.62646484  0.1739502  -0.01701355  0.32714844  0.13696289  0.15563965] 3   2 \n",
      "[-0.6689453   0.04968262  0.07122803  0.2939453   0.1776123   0.05160522] 3   2 \n",
      "[-0.7705078   0.29052734 -0.04217529  0.30615234  0.04040527 -0.07641602] 3   2 \n",
      "[-0.71533203  0.07580566  0.02235413  0.18310547  0.1496582  -0.07275391] 3   0 \n",
      "[-0.6201172   0.09790039  0.05484009  0.16796875  0.20141602  0.07458496] 4   2 \n",
      "[-0.73046875  0.22717285 -0.14855957  0.35546875  0.09619141 -0.16821289] 3   2 \n",
      "[-0.6269531   0.20593262 -0.01844788  0.2927246   0.21252441  0.01345825] 3   1 \n",
      "[-0.66503906  0.21716309 -0.03286743  0.17333984  0.11755371 -0.06726074] 1   4 \n",
      "[-0.69921875  0.06188965  0.05502319  0.18811035  0.19567871 -0.03952026] 4   2 \n",
      "[-0.66308594  0.07373047  0.00364685  0.24133301  0.1484375   0.01525116] 3   3 Match 144\n",
      "\n",
      "[-0.7939453   0.03076172 -0.09832764  0.1484375   0.14697266 -0.11779785] 3   3 Match 145\n",
      "\n",
      "[-0.7451172   0.18395996  0.03735352  0.31762695  0.08111572 -0.0375061 ] 3   4 \n",
      "[-0.6328125   0.17895508  0.04495239  0.2019043   0.07250977 -0.00761032] 3   2 \n",
      "[-0.6489258   0.04989624  0.10717773  0.19506836  0.16687012 -0.02662659] 3   2 \n",
      "[-0.6894531   0.1206665  -0.03143311  0.35327148  0.04980469  0.0880127 ] 3   3 Match 146\n",
      "\n",
      "[-0.5410156   0.06280518  0.05517578  0.15515137  0.3173828   0.09057617] 4   2 \n",
      "[-0.70751953  0.16186523  0.08721924  0.24072266  0.14123535 -0.05926514] 3   4 \n",
      "[-0.6503906   0.15588379 -0.02757263  0.23095703  0.19311523  0.05096436] 3   3 Match 147\n",
      "\n",
      "[-0.6538086  -0.05175781  0.08666992  0.15148926  0.34887695  0.01516724] 4   1 \n",
      "[-0.77783203  0.1763916   0.08129883  0.3947754   0.00368309 -0.06201172] 3   5 \n",
      "[-0.75878906  0.19384766 -0.13293457  0.16125488  0.02952576 -0.10778809] 1   3 \n",
      "[-0.703125    0.16223145 -0.02267456  0.2619629   0.02709961  0.02532959] 3   4 \n",
      "[-0.7739258   0.16479492 -0.02589417  0.27856445  0.05767822 -0.07171631] 3   5 \n",
      "[-0.7026367   0.1060791  -0.02947998  0.23486328  0.18676758 -0.08526611] 3   2 \n",
      "[-0.7158203   0.0958252  -0.04309082  0.23205566  0.13452148 -0.04379272] 3   3 Match 148\n",
      "\n",
      "[-0.54052734 -0.00090361  0.10858154  0.27368164  0.27905273  0.01028442] 4   5 \n",
      "[-0.6972656   0.13366699  0.00981903  0.24951172  0.14294434  0.03424072] 3   2 \n",
      "[-0.7998047   0.09161377 -0.00140953  0.28344727  0.13391113 -0.04800415] 3   5 \n",
      "[-0.6850586   0.21618652 -0.05786133  0.35473633  0.03268433  0.00111485] 3   4 \n",
      "[-0.72509766  0.16833496 -0.02087402  0.2841797   0.12115479 -0.05856323] 3   2 \n",
      "[-0.7558594   0.1114502  -0.03396606  0.20141602  0.0838623   0.06793213] 3   3 Match 149\n",
      "\n",
      "[-6.8457031e-01  6.0302734e-02  3.8623810e-04  2.8662109e-01\n",
      "  1.3159180e-01  6.8359375e-02] 3   0 \n",
      "[-0.64160156  0.06738281 -0.01338196  0.35864258  0.13391113  0.07397461] 3   2 \n",
      "[-0.70410156  0.21875    -0.01023865  0.45898438  0.0214386  -0.01445007] 3   5 \n",
      "[-0.6826172   0.24377441 -0.0329895   0.4584961   0.02600098 -0.06530762] 3   5 \n",
      "[-0.67333984  0.21960449 -0.00152111  0.3647461   0.065979   -0.04537964] 3   3 Match 150\n",
      "\n",
      "[-0.6933594   0.12487793  0.04403687  0.2619629   0.11676025 -0.08813477] 3   2 \n",
      "[-0.66308594 -0.01110077  0.03927612  0.25683594  0.20605469  0.01855469] 3   4 \n",
      "[-0.68115234  0.171875   -0.06628418  0.24853516  0.08947754  0.00400162] 3   1 \n",
      "[-0.7475586   0.24414062 -0.11572266  0.32177734  0.07012939 -0.12561035] 3   4 \n",
      "[-0.64746094  0.16308594 -0.00127888  0.30004883  0.03881836  0.0021019 ] 3   3 Match 151\n",
      "\n",
      "[-0.6489258   0.10406494  0.04022217  0.16455078  0.20935059 -0.00674057] 4   3 \n",
      "[-0.67822266  0.10308838 -0.01817322  0.21679688  0.14343262  0.04995728] 3   1 \n",
      "[-0.75683594  0.24401855 -0.0770874   0.28100586  0.0300293  -0.04196167] 3   4 \n",
      "[-0.7246094   0.1463623  -0.02166748  0.3322754   0.09692383 -0.00135708] 3   5 \n",
      "[-0.6738281   0.15356445 -0.07617188  0.24316406  0.17333984  0.03488159] 3   2 \n",
      "[-0.6723633   0.08178711  0.03552246  0.2232666   0.1373291   0.03231812] 3   0 \n",
      "[-0.6699219   0.05285645  0.03363037  0.21716309  0.2130127  -0.02554321] 3   1 \n",
      "[-0.6328125   0.18200684  0.02226257  0.31811523  0.09545898  0.0428772 ] 3   3 Match 152\n",
      "\n",
      "[-0.46923828  0.09075928  0.11755371  0.2770996   0.15368652  0.12646484] 3   3 Match 153\n",
      "\n",
      "[-0.7480469   0.16259766 -0.03488159  0.3774414   0.04406738 -0.00145531] 3   2 \n",
      "[-0.80322266  0.22314453 -0.1574707   0.21679688  0.09191895 -0.01538086] 1   5 \n",
      "[-0.7685547   0.03543091 -0.10644531  0.11700439  0.1907959   0.01759338] 4   2 \n",
      "[-0.77441406  0.12237549  0.01506042  0.26489258  0.07305908 -0.08581543] 3   5 \n",
      "[-0.6201172   0.21313477 -0.09088135  0.29736328  0.21166992  0.05548096] 3   3 Match 154\n",
      "\n",
      "[-0.7504883   0.1809082  -0.05227661  0.24719238  0.10430908 -0.00203133] 3   4 \n",
      "[-0.72802734  0.25048828 -0.16552734  0.33276367 -0.06567383  0.00537491] 3   2 \n",
      "[-0.6660156   0.1899414  -0.01514435  0.36499023  0.04022217 -0.03170776] 3   4 \n",
      "[-0.70166016  0.22106934  0.02514648  0.1850586   0.12457275 -0.11444092] 1   2 \n",
      "[-0.7709961   0.17016602 -0.11364746  0.26171875  0.05856323 -0.13256836] 3   4 \n",
      "[-0.70996094  0.08935547 -0.06365967  0.25341797  0.14453125  0.02168274] 3   4 \n",
      "[-0.7597656   0.15002441 -0.02627563  0.3244629   0.05950928 -0.07525635] 3   0 \n",
      "[-0.7241211   0.09533691 -0.03421021  0.25830078  0.10083008 -0.02867126] 3   2 \n",
      "[-0.7167969   0.0894165  -0.01396942  0.23608398  0.19116211 -0.04104614] 3   5 \n",
      "[-0.75878906  0.14050293  0.03604126  0.37670898  0.07855225  0.02255249] 3   5 \n",
      "[-0.8378906   0.07519531 -0.05032349  0.21875     0.03567505 -0.15515137] 3   2 \n",
      "[-0.57470703  0.11773682  0.10229492  0.20678711  0.25708008  0.00203705] 4   3 \n",
      "[-0.66308594  0.17297363 -0.12304688  0.27319336  0.09515381  0.02001953] 3   1 \n",
      "[-0.6538086   0.22827148 -0.02789307  0.33081055  0.09197998  0.05953979] 3   3 Match 155\n",
      "\n",
      "[-0.64501953  0.18664551  0.06231689  0.2841797   0.12182617  0.00477219] 3   3 Match 156\n",
      "\n",
      "[-0.7836914   0.16271973 -0.12182617  0.19116211 -0.03509521 -0.01085663] 3   0 \n",
      "[-0.7524414   0.19995117 -0.06463623  0.2631836   0.11456299 -0.04760742] 3   2 \n",
      "[-0.734375    0.16784668 -0.06530762  0.34277344  0.05310059  0.09924316] 3   4 \n",
      "[-0.78808594  0.2878418  -0.2220459   0.28637695  0.0010128  -0.01716614] 1   4 \n",
      "[-0.78515625  0.21057129 -0.14855957  0.3022461  -0.00408173 -0.05053711] 3   4 \n",
      "[-0.67871094  0.0390625  -0.01487732  0.3166504   0.0531311   0.05523682] 3   4 \n",
      "[-0.66064453  0.12481689  0.00858307  0.24377441  0.13720703  0.0479126 ] 3   3 Match 157\n",
      "\n",
      "[-0.6591797   0.02668762  0.03793335  0.2590332   0.14477539 -0.00836182] 3   0 \n",
      "[-0.7133789   0.1928711  -0.05001831  0.19677734  0.09539795 -0.04257202] 3   5 \n",
      "[-0.61621094  0.08935547  0.00284195  0.19311523  0.24584961  0.02047729] 4   2 \n",
      "[-0.7270508   0.16699219 -0.13500977  0.265625    0.06860352 -0.07531738] 3   2 \n",
      "[-0.72216797  0.1227417  -0.05975342  0.3449707   0.06549072  0.07525635] 3   4 \n",
      "[-0.7402344   0.18115234 -0.05691528  0.26660156  0.10040283 -0.07086182] 3   1 \n",
      "[-0.7392578   0.13208008 -0.0088501   0.20898438  0.15783691 -0.02651978] 3   4 \n",
      "[-0.7661133   0.14904785 -0.17712402  0.18969727  0.14440918 -0.10943604] 3   3 Match 158\n",
      "\n",
      "[-0.7241211   0.10125732  0.03662109  0.3486328   0.08044434  0.03921509] 3   4 \n",
      "[-0.64404297  0.15673828 -0.08575439  0.265625    0.29125977 -0.0397644 ] 4   5 \n",
      "[-0.75439453  0.07568359  0.03585815  0.27954102  0.1361084  -0.02001953] 3   2 \n",
      "[-0.6772461   0.21020508 -0.06951904  0.32666016  0.14941406 -0.09649658] 3   5 \n",
      "[-0.6713867   0.17785645 -0.08343506  0.30932617  0.04663086  0.08276367] 3   3 Match 159\n",
      "\n",
      "[-0.7011719   0.09661865  0.02430725  0.2166748   0.15332031  0.05963135] 3   3 Match 160\n",
      "\n",
      "[-0.7685547   0.1829834  -0.12536621  0.1373291   0.10369873 -0.03286743] 1   1 Match 161\n",
      "\n",
      "[-0.73828125  0.04968262  0.03973389  0.13464355  0.22351074 -0.08978271] 4   4 Match 162\n",
      "\n",
      "[-0.67871094  0.12866211  0.00598526  0.28881836  0.15283203  0.04934692] 3   2 \n",
      "[-0.5966797   0.01560974  0.05841064  0.21533203  0.23706055 -0.03744507] 4   1 \n",
      "[-0.72802734  0.21350098 -0.15075684  0.18469238  0.1418457  -0.15930176] 1   4 \n",
      "[-0.69921875  0.19360352 -0.06045532  0.2861328   0.12445068  0.01428223] 3   4 \n",
      "[-0.6508789   0.13012695  0.03059387  0.23925781  0.15991211  0.01652527] 3   3 Match 163\n",
      "\n",
      "[-0.7548828   0.18615723 -0.05041504  0.25756836  0.02189636 -0.07043457] 3   3 Match 164\n",
      "\n",
      "[-0.61572266  0.20275879  0.01435852  0.3046875   0.0536499   0.0069809 ] 3   2 \n",
      "[-0.72265625  0.17541504 -0.07128906  0.27905273  0.11480713  0.07183838] 3   0 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.63720703  0.18737793  0.04763794  0.30688477  0.06842041  0.01500702] 3   1 \n",
      "[-0.6269531   0.2163086   0.0546875   0.35473633  0.08630371 -0.08050537] 3   4 \n",
      "[-0.6411133   0.12084961  0.08270264  0.20202637  0.17053223  0.07720947] 3   4 \n",
      "[-0.62402344  0.15991211  0.03616333  0.36572266  0.0970459  -0.03710938] 3   4 \n",
      "[-0.71875     0.0506897  -0.12927246  0.34277344  0.19128418  0.00563431] 3   5 \n",
      "[-0.6977539   0.12304688  0.06292725  0.32958984 -0.01858521  0.09997559] 3   3 Match 165\n",
      "\n",
      "[-0.7104492   0.13476562  0.01072693  0.29345703  0.02441406  0.00744629] 3   2 \n",
      "[-0.7451172   0.12988281 -0.11151123  0.19543457  0.20129395 -0.03686523] 4   5 \n",
      "[-0.69189453  0.11322021 -0.00079775  0.26635742  0.17553711 -0.01832581] 3   0 \n",
      "[-0.71484375  0.15319824  0.12359619  0.28271484  0.13220215 -0.0447998 ] 3   3 Match 166\n",
      "\n",
      "[-0.70654297  0.03460693 -0.09838867  0.2849121   0.26220703 -0.10235596] 3   0 \n",
      "[-0.74121094  0.16723633 -0.03768921  0.2944336   0.09729004 -0.02346802] 3   4 \n",
      "[-0.7211914   0.1751709  -0.04907227  0.3840332  -0.00793457  0.0171814 ] 3   4 \n",
      "[-0.80078125  0.15307617 -0.17602539  0.19750977  0.10351562 -0.03961182] 3   4 \n",
      "[-0.7529297   0.22851562 -0.18041992  0.26538086  0.10882568 -0.05548096] 3   3 Match 167\n",
      "\n",
      "[-0.7504883   0.12017822 -0.04388428  0.24719238  0.06427002  0.01451874] 3   2 \n",
      "[-0.6582031   0.09143066 -0.00577164  0.28076172  0.08618164  0.02546692] 3   5 \n",
      "[-0.68310547  0.08001709 -0.02128601  0.33544922  0.15136719 -0.04251099] 3   5 \n",
      "[-0.6123047   0.11871338 -0.00085735  0.29101562  0.15161133 -0.04437256] 3   1 \n",
      "[-0.578125    0.1694336   0.01130676  0.46166992  0.12213135  0.140625  ] 3   1 \n",
      "[-0.7636719   0.21740723 -0.13354492  0.24487305  0.16564941 -0.00577927] 3   3 Match 168\n",
      "\n",
      "[-0.6850586   0.23522949 -0.0553894   0.45898438  0.05532837  0.0017519 ] 3   2 \n",
      "[-0.734375    0.3022461  -0.1270752   0.4074707   0.06051636 -0.09399414] 3   5 \n",
      "[-0.7416992   0.2644043  -0.02746582  0.28930664  0.04684448 -0.11212158] 3   2 \n",
      "[-0.75097656  0.1206665  -0.14831543  0.29223633  0.10803223 -0.05114746] 3   1 \n",
      "[-0.73535156  0.0904541  -0.17089844  0.31567383  0.19165039 -0.08874512] 3   3 Match 169\n",
      "\n",
      "[-0.60791016  0.0536499   0.1262207   0.26904297  0.12316895  0.01541138] 3   3 Match 170\n",
      "\n",
      "[-0.68652344  0.16577148 -0.06091309  0.15722656  0.14904785 -0.10986328] 1   1 Match 171\n",
      "\n",
      "[-0.7607422   0.22875977 -0.1541748   0.31689453 -0.02824402 -0.0226593 ] 3   3 Match 172\n",
      "\n",
      "[-0.65185547  0.17895508  0.04165649  0.39770508  0.05419922 -0.04916382] 3   4 \n",
      "[-0.62402344  0.09521484  0.00967407  0.2722168   0.17626953  0.08135986] 3   5 \n",
      "[-0.66552734  0.2322998  -0.01315308  0.3149414   0.05474854  0.0053215 ] 3   4 \n",
      "[-0.72216797  0.15991211 -0.00429153  0.25634766  0.09460449 -0.03112793] 3   1 \n",
      "[-0.73095703  0.22741699 -0.06066895  0.3828125   0.02555847  0.00288963] 3   3 Match 173\n",
      "\n",
      "[-0.6665039   0.22363281 -0.13513184  0.31884766  0.04714966  0.02174377] 3   4 \n",
      "[-0.6694336   0.13183594 -0.0880127   0.2644043   0.21655273 -0.06976318] 3   0 \n",
      "[-0.67822266  0.30371094 -0.06951904  0.40014648  0.05584717 -0.14758301] 3   2 \n",
      "[-0.76123047  0.3083496  -0.22070312  0.2607422   0.01166534 -0.06756592] 1   1 Match 174\n",
      "\n",
      "[-0.6972656   0.27905273 -0.1459961   0.14758301  0.16308594 -0.20727539] 1   5 \n",
      "[-0.7236328  -0.04562378  0.13562012  0.18261719  0.20874023 -0.00473022] 4   2 \n",
      "[-0.7158203   0.1484375   0.00676346  0.30126953  0.0880127  -0.05819702] 3   4 \n",
      "[-0.6777344   0.11755371  0.05221558  0.26123047  0.10375977  0.07696533] 3   3 Match 175\n",
      "\n",
      "[-0.6933594   0.12719727 -0.09075928  0.2746582   0.07659912  0.02642822] 3   4 \n",
      "[-0.65722656  0.10070801  0.0292511   0.24365234  0.16662598  0.0447998 ] 3   5 \n",
      "[-0.5864258   0.09570312  0.04376221  0.11499023  0.22106934  0.0279541 ] 4   1 \n",
      "[-0.7109375   0.14685059 -0.00261116  0.33398438  0.22131348  0.03417969] 3   0 \n",
      "[-0.7216797   0.03475952  0.02207947  0.22253418  0.21984863 -0.08319092] 3   2 \n",
      "[-0.73291016  0.1998291  -0.11523438  0.15161133  0.01506805 -0.06378174] 1   2 \n",
      "[-0.734375    0.1418457  -0.06817627  0.22497559  0.08172607 -0.01760864] 3   1 \n",
      "[-0.66308594  0.18359375 -0.02203369  0.26513672  0.12359619  0.01239777] 3   1 \n",
      "[-0.6196289   0.10900879  0.16638184  0.3034668   0.17993164  0.09191895] 3   4 \n",
      "[-0.6640625   0.11413574  0.09136963  0.1694336   0.21765137 -0.08129883] 4   2 \n",
      "[-0.81152344  0.10644531 -0.03369141  0.3232422   0.12646484 -0.07495117] 3   1 \n",
      "[-0.7167969   0.1430664  -0.03829956  0.26586914  0.09112549  0.01766968] 3   5 \n",
      "[-0.6748047   0.03610229  0.02742004  0.25048828  0.1484375   0.01618958] 3   4 \n",
      "[-0.74121094  0.21447754 -0.04953003  0.13928223  0.07794189 -0.09698486] 1   5 \n",
      "[-0.50146484  0.09289551  0.13195801  0.4074707   0.08843994  0.08447266] 3   3 Match 176\n",
      "\n",
      "[-0.625       0.0165863   0.02832031  0.20715332  0.2709961   0.01620483] 4   1 \n",
      "[-0.7675781   0.13537598 -0.09643555  0.32861328  0.0134201   0.01280975] 3   2 \n",
      "[-0.63720703  0.2175293  -0.09002686  0.43066406  0.00776291  0.07165527] 3   2 \n",
      "[-0.7207031   0.19848633 -0.09100342  0.15527344  0.12695312 -0.0793457 ] 1   3 \n",
      "[-7.0507812e-01  2.8833008e-01 -8.5144043e-02  3.4204102e-01\n",
      "  1.0013580e-05 -2.5588989e-02] 3   5 \n",
      "[-0.74316406  0.19299316 -0.04553223  0.31567383  0.11157227 -0.07037354] 3   1 \n",
      "[-0.76953125  0.16052246 -0.19433594  0.1595459  -0.01486206 -0.06106567] 1   3 \n",
      "[-0.66064453  0.04586792  0.03013611  0.25341797  0.25097656 -0.03369141] 3   3 Match 177\n",
      "\n",
      "[-0.7861328   0.17492676 -0.13806152  0.31689453  0.06069946  0.0102005 ] 3   5 \n",
      "[-0.69189453  0.16955566 -0.01316071  0.11920166  0.17224121 -0.05999756] 4   2 \n",
      "[-0.6567383   0.11236572  0.00301743  0.21606445  0.21350098 -0.07159424] 3   1 \n",
      "[-0.6459961   0.23168945 -0.10913086  0.24133301  0.14074707  0.04064941] 3   3 Match 178\n",
      "\n",
      "[-0.60595703  0.09545898  0.01089478  0.37841797  0.19177246  0.01040649] 3   3 Match 179\n",
      "\n",
      "[-0.67626953  0.2454834  -0.04040527  0.36572266  0.13317871 -0.08947754] 3   5 \n",
      "[-0.7089844   0.12182617 -0.1776123   0.34350586  0.18188477  0.08703613] 3   5 \n",
      "[-0.59521484  0.03063965  0.04217529  0.15075684  0.21923828  0.05871582] 4   2 \n",
      "[-0.6767578   0.15368652 -0.0068779   0.37670898  0.03503418  0.05401611] 3   5 \n",
      "[-0.7050781   0.11920166  0.0042572   0.32641602  0.06945801  0.00626755] 3   5 \n",
      "[-0.7841797   0.2479248  -0.26049805  0.04284668  0.02287292 -0.16784668] 1   3 \n",
      "[-0.67089844  0.14221191  0.02836609  0.18286133  0.18579102 -0.01885986] 4   1 \n",
      "[-0.66503906  0.328125   -0.02510071  0.43920898  0.02093506 -0.1303711 ] 3   4 \n",
      "[-0.7265625   0.12188721  0.00123215  0.26489258  0.07220459  0.06097412] 3   3 Match 180\n",
      "\n",
      "[-0.7138672   0.16052246 -0.10083008  0.23425293  0.22753906 -0.14379883] 3   1 \n",
      "[-0.7416992   0.01806641 -0.13769531  0.17419434  0.25952148  0.0148468 ] 4   4 Match 181\n",
      "\n",
      "[-0.8261719   0.01908875 -0.05953979  0.2364502   0.10076904 -0.01081848] 3   1 \n",
      "[-0.703125    0.19091797  0.05392456  0.29223633  0.0847168  -0.08441162] 3   5 \n",
      "[-0.50634766  0.0715332   0.08789062  0.40478516  0.11273193  0.20446777] 3   3 Match 182\n",
      "\n",
      "[-0.70410156  0.17822266  0.04403687  0.20178223  0.12658691 -0.01327515] 3   4 \n",
      "[-0.63134766  0.15270996  0.02375793  0.27929688  0.17614746 -0.05480957] 3   3 Match 183\n",
      "\n",
      "[-0.7236328   0.19177246 -0.05554199  0.25        0.13208008  0.00788879] 3   1 \n",
      "[-0.69091797  0.13830566 -0.03213501  0.33251953  0.12927246 -0.09667969] 3   3 Match 184\n",
      "\n",
      "[-0.79003906  0.13452148 -0.21704102  0.12127686  0.19873047 -0.08465576] 4   4 Match 185\n",
      "\n",
      "[-0.7998047   0.2697754  -0.12585449  0.1352539   0.14025879 -0.0645752 ] 1   4 \n",
      "[-0.6855469   0.13500977 -0.01387024  0.43701172  0.10778809  0.0793457 ] 3   5 \n",
      "[-0.6743164   0.19262695 -0.14379883  0.33935547 -0.00271988 -0.06433105] 3   4 \n",
      "[-0.6376953   0.20385742 -0.06228638  0.34179688  0.08178711  0.04006958] 3   4 \n",
      "[-0.7109375   0.19104004 -0.15893555  0.3071289   0.07061768  0.05953979] 3   5 \n",
      "[-0.7324219   0.28759766 -0.17993164  0.18432617  0.0647583  -0.1138916 ] 1   5 \n",
      "[-0.56103516  0.1270752  -0.04336548  0.33251953  0.21704102  0.13916016] 3   4 \n",
      "[-0.7294922   0.07019043 -0.03007507  0.25805664  0.10040283  0.05404663] 3   5 \n",
      "[-0.6743164   0.1776123  -0.00491333  0.3112793   0.08178711 -0.03111267] 3   4 \n",
      "[-0.6533203   0.18127441 -0.02563477  0.2836914   0.10479736  0.00966644] 3   3 Match 186\n",
      "\n",
      "[-0.6879883   0.00385475  0.02830505  0.14465332  0.3125     -0.02613831] 4   0 \n",
      "[-0.6381836   0.00629807  0.12091064  0.18823242  0.26367188 -0.01161194] 4   2 \n",
      "[-0.72558594  0.1895752  -0.04354858  0.33129883  0.00141716 -0.04214478] 3   4 \n",
      "[-0.89746094  0.16442871 -0.20129395  0.13696289  0.06329346 -0.19262695] 1   4 \n",
      "[-0.6801758   0.14025879 -0.04931641  0.23474121  0.14831543 -0.03256226] 3   2 \n",
      "[-0.6933594   0.12988281 -0.07263184  0.3076172   0.10046387  0.06756592] 3   3 Match 187\n",
      "\n",
      "[-0.76708984  0.14086914 -0.04882812  0.09063721  0.08892822 -0.07476807] 1   5 \n",
      "[-0.56152344  0.01404572  0.11932373  0.24365234  0.23352051  0.029953  ] 3   4 \n",
      "[-0.66796875  0.08636475  0.0385437   0.18017578  0.17358398 -0.03610229] 3   4 \n",
      "[-0.7080078   0.14416504 -0.03048706  0.15197754  0.09588623 -0.04910278] 3   0 \n",
      "[-0.62060547  0.04785156  0.1071167   0.18041992  0.23046875 -0.00737   ] 4   4 Match 188\n",
      "\n",
      "[-0.79833984  0.13720703 -0.11096191  0.28442383  0.06103516 -0.10876465] 3   5 \n",
      "[-0.74560547  0.14794922  0.01364136  0.24499512  0.09881592 -0.01927185] 3   1 \n",
      "[-0.734375    0.14221191  0.03601074  0.30810547  0.12524414 -0.00519943] 3   2 \n",
      "[-0.6855469   0.12512207  0.03863525  0.2548828   0.14660645  0.10552979] 3   2 \n",
      "[-0.7060547   0.16638184 -0.0059433   0.2055664   0.08270264  0.01248169] 3   0 \n",
      "[-0.75390625  0.20397949 -0.16357422  0.21643066  0.17687988 -0.03933716] 3   4 \n",
      "[-0.7104492   0.19030762 -0.1640625   0.26635742  0.04495239 -0.02911377] 3   3 Match 189\n",
      "\n",
      "[-0.61865234  0.18896484  0.03759766  0.36376953  0.15722656 -0.06524658] 3   5 \n",
      "[-0.6982422   0.03726196  0.04522705  0.21350098  0.15539551  0.02908325] 3   2 \n",
      "[-0.6689453   0.25317383 -0.27856445  0.38378906  0.03967285  0.00937653] 3   1 \n",
      "[-0.77001953  0.12347412 -0.15881348  0.14221191  0.06890869 -0.09552002] 3   2 \n",
      "[-0.6479492   0.13842773  0.03930664  0.26879883  0.12768555 -0.0068779 ] 3   4 \n",
      "[-0.72216797  0.1472168  -0.11907959  0.3203125   0.0690918  -0.13830566] 3   5 \n",
      "[-0.7441406   0.11376953 -0.08410645  0.18005371  0.13793945 -0.13415527] 3   5 \n",
      "[-0.7758789   0.22265625 -0.07171631  0.2220459   0.05957031 -0.04067993] 1   1 Match 190\n",
      "\n",
      "[-0.7426758   0.1920166  -0.05587769  0.2578125   0.0390625   0.00722504] 3   3 Match 191\n",
      "\n",
      "[-0.6791992   0.13635254  0.05740356  0.26464844  0.16625977  0.01139832] 3   1 \n",
      "[-0.7192383   0.10571289 -0.12188721  0.18835449  0.14904785 -0.01576233] 3   2 \n",
      "[-0.6796875   0.07580566  0.05563354  0.25146484  0.11065674  0.00725937] 3   3 Match 192\n",
      "\n",
      "[-0.69189453  0.25585938 -0.04187012  0.4038086   0.09631348 -0.00336838] 3   1 \n",
      "[-0.61279297  0.20947266 -0.04681396  0.32128906  0.08575439  0.02430725] 3   0 \n",
      "[-0.74853516  0.17565918 -0.1829834   0.13024902  0.22009277 -0.07543945] 4   5 \n",
      "[-0.7080078   0.20324707 -0.04858398  0.31762695  0.08959961 -0.01028442] 3   5 \n",
      "[-0.8144531   0.2709961  -0.13977051  0.24035645  0.07183838 -0.11309814] 1   1 Match 193\n",
      "\n",
      "[-0.73291016  0.22106934 -0.15429688  0.20629883  0.02180481 -0.07012939] 1   1 Match 194\n",
      "\n",
      "[-0.58251953  0.11206055  0.06130981  0.28344727  0.1965332   0.07769775] 3   0 \n",
      "[-0.65234375  0.17236328 -0.09814453  0.25024414  0.06622314  0.065979  ] 3   1 \n",
      "[-0.74658203  0.09448242  0.03341675  0.32641602  0.12030029 -0.05859375] 3   3 Match 195\n",
      "\n",
      "[-0.65478516  0.0604248  -0.0094986   0.1854248   0.2524414  -0.00390244] 4   0 \n",
      "[-0.7084961   0.15063477  0.00351143  0.2154541   0.07598877  0.00933838] 3   4 \n",
      "[-0.78759766  0.26708984 -0.15930176  0.23095703  0.07489014 -0.14746094] 1   4 \n",
      "[-0.67871094  0.12426758 -0.02006531  0.19213867  0.22497559 -0.06835938] 4   5 \n",
      "[-0.77441406  0.1161499  -0.09606934  0.18774414  0.03765869 -0.13867188] 3   3 Match 196\n",
      "\n",
      "[-0.5488281   0.17993164 -0.02420044  0.35253906  0.13317871  0.08959961] 3   2 \n",
      "[-0.64501953  0.0614624  -0.03546143  0.3166504   0.20117188  0.04876709] 3   0 \n",
      "[-0.703125    0.17199707 -0.01431274  0.21813965  0.1875     -0.09014893] 3   4 \n",
      "[-0.74658203  0.04376221 -0.01934814  0.21166992  0.15783691  0.03024292] 3   2 \n",
      "[-0.68359375  0.09747314 -0.00609589  0.14440918  0.14111328 -0.09735107] 3   2 \n",
      "[-0.7475586   0.04052734 -0.07006836  0.1361084   0.11657715 -0.08050537] 3   2 \n",
      "[-0.7192383   0.07928467  0.01203918  0.15881348  0.14550781 -0.0295105 ] 3   4 \n",
      "[-0.68066406  0.17822266 -0.0947876   0.34033203  0.10351562  0.02394104] 3   5 \n",
      "[-0.734375    0.14123535 -0.04577637  0.28515625  0.10046387 -0.02754211] 3   4 \n",
      "[-0.67089844  0.09954834  0.05209351  0.23010254  0.16149902 -0.03123474] 3   2 \n",
      "[-0.63183594  0.20532227 -0.03872681  0.25976562  0.14807129  0.04281616] 3   4 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.73095703  0.25952148 -0.0609436   0.3046875  -0.06329346  0.02084351] 3   4 \n",
      "[-0.8208008   0.19934082 -0.18371582  0.15014648  0.06817627 -0.0703125 ] 1   2 \n",
      "[-0.7089844   0.16271973 -0.19555664  0.16308594  0.18713379 -0.1348877 ] 4   3 \n",
      "[-0.7128906   0.12927246 -0.03295898  0.22265625  0.10137939 -0.00409317] 3   2 \n",
      "[-0.7817383   0.18688965 -0.11621094  0.09301758  0.1227417  -0.15612793] 1   4 \n",
      "[-0.5415039   0.21679688  0.08502197  0.42211914  0.05297852  0.0057106 ] 3   3 Match 197\n",
      "\n",
      "[-0.78466797  0.20361328 -0.01997375  0.27270508 -0.04766846 -0.10876465] 3   2 \n",
      "[-0.8105469   0.10089111 -0.08886719  0.17492676  0.05639648 -0.11730957] 3   1 \n",
      "[-0.7558594   0.3059082  -0.1541748   0.23303223  0.081604   -0.08947754] 1   4 \n",
      "[-0.68896484  0.24072266 -0.02815247  0.2692871   0.03326416 -0.00141907] 3   0 \n",
      "[-0.7114258   0.14099121 -0.11236572  0.25854492  0.10668945  0.04602051] 3   2 \n",
      "[-0.67871094  0.08209229  0.02636719  0.19250488  0.17944336 -0.0484314 ] 3   3 Match 198\n",
      "\n",
      "[-0.6230469   0.24267578 -0.14550781  0.08068848  0.08972168 -0.11743164] 1   0 \n",
      "[-0.71191406  0.1060791  -0.04922485  0.2388916   0.16601562 -0.08312988] 3   2 \n",
      "[-0.7402344   0.18847656 -0.03979492  0.23779297  0.07843018  0.02215576] 3   1 \n",
      "[-0.78759766  0.20666504 -0.07434082  0.24731445  0.04153442  0.00757599] 3   4 \n",
      "[-0.74853516  0.11413574 -0.01608276  0.19909668  0.05786133 -0.01629639] 3   1 \n",
      "[-0.6777344   0.17626953  0.00323486  0.13964844  0.20629883 -0.08599854] 4   3 \n",
      "[-0.73828125  0.19067383 -0.10797119  0.2697754   0.12854004 -0.00547791] 3   0 \n",
      "[-0.70751953  0.20349121 -0.02503967  0.18041992  0.21582031 -0.11541748] 4   1 \n",
      "[-0.69873047  0.06610107  0.14355469  0.08740234  0.1875     -0.05535889] 4   3 \n",
      "[-0.80566406  0.1907959  -0.07385254  0.2861328   0.03625488 -0.00358391] 3   5 \n",
      "[-0.6591797   0.10101318 -0.01122284  0.29589844  0.12426758  0.05041504] 3   4 \n",
      "[-0.6875      0.20959473 -0.03491211  0.28857422  0.04940796  0.03436279] 3   4 \n",
      "[-0.7602539   0.1965332  -0.14929199  0.2800293   0.08288574  0.00213814] 3   0 \n",
      "[-0.82421875  0.12597656 -0.2763672   0.17492676  0.15270996 -0.06408691] 3   0 \n",
      "[-0.6279297   0.18041992  0.00793457  0.14978027  0.17956543  0.02311707] 1   2 \n",
      "[-0.6738281   0.24060059 -0.0770874   0.35229492  0.07617188  0.01033783] 3   0 \n",
      "[-0.6772461   0.07745361 -0.12445068  0.36523438  0.21569824  0.0340271 ] 3   2 \n",
      "[-0.7133789   0.3088379  -0.09851074  0.44018555 -0.00485992 -0.03820801] 3   1 \n",
      "[-0.8129883   0.13745117 -0.05059814  0.22143555  0.12524414 -0.18383789] 3   3 Match 199\n",
      "\n",
      "[-0.6489258   0.05831909  0.12719727  0.20300293  0.2878418  -0.03308105] 4   3 \n",
      "[-0.76464844  0.21398926 -0.03225708  0.33911133  0.02957153 -0.06292725] 3   5 \n",
      "[-0.61328125  0.08111572  0.03512573  0.20092773  0.20983887  0.0375061 ] 4   3 \n",
      "[-0.77734375  0.03878784 -0.0758667   0.09649658  0.11889648 -0.07836914] 4   1 \n",
      "[-0.6152344   0.14038086  0.00605392  0.22717285  0.24047852 -0.0031414 ] 4   0 \n",
      "[-0.8149414   0.3046875  -0.37231445  0.04718018  0.03170776 -0.19946289] 1   2 \n",
      "[-0.66796875  0.22192383 -0.09741211  0.18896484  0.11993408 -0.08026123] 1   2 \n",
      "[-0.6411133   0.19238281 -0.01586914  0.33032227  0.12854004 -0.0118866 ] 3   1 \n",
      "[-0.72021484  0.18933105 -0.12371826  0.27954102  0.11212158  0.05239868] 3   5 \n",
      "[-0.75341797  0.27978516 -0.18469238  0.2697754   0.0824585  -0.07739258] 1   2 \n",
      "[-0.7265625   0.11022949 -0.00526047  0.25097656  0.17871094 -0.05993652] 3   1 \n",
      "[-0.7319336   0.2998047  -0.1048584   0.30981445  0.03817749 -0.06185913] 3   4 \n",
      "[-0.7392578   0.19555664 -0.03430176  0.27441406  0.04800415 -0.02516174] 3   1 \n",
      "[-0.73828125  0.14648438 -0.20349121  0.17663574 -0.0040741  -0.01229095] 3   1 \n",
      "[-0.6669922   0.16064453  0.0131073   0.22399902  0.14916992  0.09173584] 3   4 \n",
      "[-0.6933594   0.15966797 -0.14099121  0.19165039  0.15039062 -0.03085327] 3   3 Match 200\n",
      "\n",
      "[-0.5859375   0.06204224  0.08660889  0.13708496  0.23205566 -0.02957153] 4   4 Match 201\n",
      "\n",
      "[-0.71435547  0.12792969 -0.00493622  0.3022461   0.140625   -0.09368896] 3   4 \n",
      "[-0.7167969   0.17175293 -0.05960083  0.27905273  0.15466309 -0.00328445] 3   2 \n",
      "[-0.82714844  0.2512207  -0.17993164  0.16955566  0.07452393 -0.18029785] 1   4 \n",
      "[-0.58740234  0.13635254 -0.01834106  0.27319336  0.2052002   0.0274353 ] 3   4 \n",
      "[-0.62109375  0.16821289  0.04122925  0.24072266  0.19750977  0.04403687] 3   4 \n",
      "[-0.7558594   0.28125    -0.04855347  0.35888672 -0.00512314 -0.14282227] 3   5 \n",
      "[-0.7036133   0.35498047 -0.19091797  0.32861328  0.05184937 -0.1776123 ] 1   5 \n",
      "[-0.7036133   0.15478516  0.0723877   0.34814453  0.05871582 -0.04208374] 3   0 \n",
      "[-0.7050781   0.12432861 -0.04772949  0.27807617  0.025177    0.0144577 ] 3   5 \n",
      "[-0.7314453   0.23718262 -0.03692627  0.31323242  0.03747559 -0.04400635] 3   3 Match 202\n",
      "\n",
      "[-0.65185547  0.08880615 -0.0362854   0.33789062  0.13623047  0.06628418] 3   4 \n",
      "[-0.7285156   0.20483398 -0.07867432  0.21130371  0.10772705 -0.01805115] 3   3 Match 203\n",
      "\n",
      "[-0.6401367   0.13806152  0.09008789  0.1965332   0.1595459   0.03231812] 3   3 Match 204\n",
      "\n",
      "[-0.6088867   0.20129395 -0.05194092  0.18664551  0.16455078  0.04473877] 1   4 \n",
      "[-0.6586914   0.10784912  0.09509277  0.22705078  0.07055664  0.05450439] 3   3 Match 205\n",
      "\n",
      "[-0.6933594   0.14208984 -0.00493622  0.33081055  0.07287598  0.05700684] 3   1 \n",
      "[-0.71435547  0.17041016 -0.12280273  0.19714355  0.2421875  -0.06079102] 4   1 \n",
      "[-0.7402344   0.21862793 -0.16674805  0.13305664  0.09326172 -0.10467529] 1   1 Match 206\n",
      "\n",
      "[-0.70751953  0.22167969 -0.09991455  0.30395508  0.15319824 -0.0680542 ] 3   5 \n",
      "[-0.7001953   0.08508301 -0.15100098  0.17919922  0.12512207  0.05200195] 3   0 \n",
      "[-0.7060547   0.08642578  0.09234619  0.21691895  0.14733887 -0.06530762] 3   1 \n",
      "[-0.6665039   0.09326172  0.00915527  0.1072998   0.16174316 -0.02598572] 4   3 \n",
      "[-0.65722656  0.14050293  0.03341675  0.1003418   0.19470215 -0.1206665 ] 4   1 \n",
      "[-0.7475586   0.06039429 -0.10864258  0.24829102  0.24890137 -0.07165527] 4   1 \n",
      "[-0.7973633   0.23571777 -0.12805176  0.15722656  0.0380249  -0.10601807] 1   5 \n",
      "[-0.6508789   0.18554688 -0.07922363  0.26733398  0.10308838 -0.02250671] 3   4 \n",
      "[-0.5957031   0.1673584   0.05606079  0.35742188  0.14733887  0.08728027] 3   2 \n",
      "[-0.6904297   0.17663574 -0.08685303  0.30615234  0.04602051  0.02264404] 3   3 Match 207\n",
      "\n",
      "[-0.69091797  0.18127441 -0.02580261  0.34399414  0.06921387  0.04995728] 3   1 \n",
      "[-0.6640625   0.20410156 -0.12469482  0.23498535  0.11602783 -0.03475952] 3   2 \n",
      "[-0.57910156  0.19689941  0.0296936   0.12475586  0.09613037 -0.06051636] 1   1 Match 208\n",
      "\n",
      "[-0.73779297  0.2878418  -0.2208252   0.24450684  0.0848999  -0.07421875] 1   2 \n",
      "[-0.7294922   0.23242188 -0.04309082  0.22583008  0.14038086 -0.06860352] 1   4 \n",
      "[-0.80615234  0.24304199 -0.19763184  0.1928711   0.13720703 -0.15124512] 1   0 \n",
      "[-0.8095703   0.24523926 -0.08874512  0.2993164   0.0668335  -0.14624023] 3   4 \n",
      "[-0.6347656   0.05032349  0.08306885  0.21472168  0.22253418 -0.00287247] 4   4 Match 209\n",
      "\n",
      "[-0.5576172   0.07373047 -0.0096283   0.32080078  0.2890625   0.03457642] 3   4 \n",
      "[-0.6538086   0.27734375 -0.11224365  0.35131836  0.08081055 -0.06817627] 3   4 \n",
      "[-0.66796875  0.11212158 -0.0025959   0.21899414  0.16516113  0.02334595] 3   5 \n",
      "[-0.69873047  0.15332031 -0.02198792  0.34643555  0.05737305  0.05401611] 3   5 \n",
      "[-0.6328125   0.2076416  -0.04119873  0.21228027  0.17333984  0.0637207 ] 3   2 \n",
      "[-0.7104492   0.19580078 -0.03790283  0.32226562 -0.01181793 -0.02626038] 3   1 \n",
      "[-0.69677734  0.09979248  0.00298882  0.3190918   0.07470703  0.14074707] 3   4 \n",
      "[-0.71484375  0.2565918  -0.1237793   0.3828125   0.0480957  -0.09313965] 3   4 \n",
      "[-0.6401367   0.05535889 -0.06164551  0.30688477  0.12854004  0.01631165] 3   3 Match 210\n",
      "\n",
      "[-0.71777344  0.07971191  0.03057861  0.26416016  0.16625977 -0.05004883] 3   3 Match 211\n",
      "\n",
      "[-0.68310547  0.06738281 -0.06640625  0.34985352  0.19519043  0.00454712] 3   3 Match 212\n",
      "\n",
      "[-0.7583008   0.13085938 -0.05325317  0.23620605  0.04562378 -0.01786804] 3   2 \n",
      "[-0.65771484  0.21533203  0.02307129  0.41577148  0.06408691 -0.02258301] 3   3 Match 213\n",
      "\n",
      "[-0.70166016  0.2286377  -0.1352539   0.21228027 -0.0038929  -0.11999512] 1   3 \n",
      "[-0.6040039   0.13659668 -0.03390503  0.29125977  0.14916992  0.06359863] 3   4 \n",
      "[-0.8041992   0.10083008  0.02906799  0.2265625   0.05993652 -0.09033203] 3   1 \n",
      "[-0.6972656   0.19104004 -0.0513916   0.34228516  0.05712891 -0.00465012] 3   4 \n",
      "[-0.6791992   0.11462402  0.10192871  0.37695312  0.07958984  0.0526123 ] 3   3 Match 214\n",
      "\n",
      "[-0.6298828   0.22131348 -0.0682373   0.35351562  0.11608887  0.01242065] 3   5 \n",
      "[-0.7451172   0.05236816 -0.1484375   0.23474121  0.27294922 -0.00894928] 4   1 \n",
      "[-0.7421875   0.1986084  -0.1137085   0.23266602  0.14501953 -0.02537537] 3   1 \n",
      "[-0.65185547  0.04226685 -0.00073338  0.2878418   0.14428711  0.06027222] 3   5 \n",
      "[-0.6777344   0.10192871  0.04467773  0.28710938  0.14746094  0.13464355] 3   3 Match 215\n",
      "\n",
      "[-0.6074219   0.1484375  -0.00956726  0.39453125  0.09631348  0.04705811] 3   1 \n",
      "[-0.6611328   0.06982422 -0.00372505  0.24536133  0.11462402  0.07086182] 3   2 \n",
      "[-0.765625    0.2734375  -0.09783936  0.33813477  0.00976562 -0.11102295] 3   4 \n",
      "[-0.71484375  0.30297852 -0.11560059  0.2619629   0.04412842 -0.112854  ] 1   1 Match 216\n",
      "\n",
      "[-0.73291016  0.1685791  -0.01305389  0.25585938  0.15844727 -0.02427673] 3   1 \n",
      "[-0.66015625  0.03421021  0.07507324  0.21386719  0.23474121  0.05090332] 4   3 \n",
      "[-0.6333008   0.19238281 -0.05007935  0.27441406  0.0692749   0.01016998] 3   0 \n",
      "[-0.7192383   0.20397949  0.04962158  0.35961914  0.03500366 -0.02059937] 3   1 \n",
      "[-0.7792969   0.24597168 -0.0267334   0.21606445  0.03543091 -0.09033203] 1   5 \n",
      "[-0.64208984  0.2758789  -0.11743164  0.2241211   0.07281494 -0.00086308] 1   2 \n",
      "[-0.61035156 -0.04608154  0.06201172  0.32373047  0.29492188  0.02365112] 3   3 Match 217\n",
      "\n",
      "[-0.6870117   0.10430908  0.01258087  0.19311523  0.20385742 -0.05957031] 4   4 Match 218\n",
      "\n",
      "[-0.73046875  0.15563965 -0.02738953  0.29907227  0.11645508 -0.12127686] 3   2 \n",
      "[-0.80566406  0.20825195 -0.203125    0.26586914  0.0027771  -0.02079773] 3   1 \n",
      "[-0.72802734  0.12054443 -0.07141113  0.23925781  0.19580078 -0.05645752] 3   3 Match 219\n",
      "\n",
      "[-0.60546875  0.10852051  0.09527588  0.20458984  0.19616699  0.0531311 ] 3   4 \n",
      "[-0.68847656  0.12237549 -0.04324341  0.25097656  0.12634277 -0.04727173] 3   1 \n",
      "[-0.7441406   0.19335938 -0.13549805  0.07824707  0.05255127 -0.06402588] 1   3 \n",
      "[-0.7182617   0.08428955 -0.04907227  0.19921875  0.1697998   0.04873657] 3   5 \n",
      "[-0.7636719   0.19812012 -0.2454834   0.16882324 -0.00845337 -0.09399414] 1   1 Match 220\n",
      "\n",
      "[-0.7036133   0.13049316  0.00733948  0.2614746   0.03051758 -0.04614258] 3   1 \n",
      "[-0.69677734  0.21520996  0.05007935  0.2998047   0.05880737 -0.00669479] 3   0 \n",
      "[-0.69189453  0.31274414 -0.15307617  0.2919922   0.12316895 -0.08892822] 1   5 \n",
      "[-0.6508789   0.27148438 -0.01543427  0.32299805  0.01567078 -0.11602783] 3   3 Match 221\n",
      "\n",
      "[-0.62353516  0.0982666   0.04681396  0.27783203  0.10162354  0.00559998] 3   4 \n",
      "[-0.7055664   0.24365234 -0.140625    0.32763672 -0.01818848 -0.06286621] 3   1 \n",
      "[-0.6621094   0.10430908  0.04949951  0.27539062  0.16027832  0.02296448] 3   4 \n",
      "[-0.7416992   0.16601562 -0.07330322  0.25830078  0.11090088 -0.08111572] 3   5 \n",
      "[-0.5576172   0.0406189   0.09033203  0.23327637  0.32373047 -0.05413818] 4   2 \n",
      "[-0.6142578   0.22351074 -0.03393555  0.3720703   0.1439209  -0.04019165] 3   0 \n",
      "[-0.7084961   0.11230469 -0.14929199  0.23498535  0.19299316 -0.06958008] 3   1 \n",
      "[-0.6542969   0.21203613 -0.07250977  0.40673828  0.07019043  0.12261963] 3   4 \n",
      "[-0.6948242   0.18981934 -0.05218506  0.23474121  0.14013672  0.04373169] 3   5 \n",
      "[-0.7138672   0.11914062 -0.0748291   0.30517578  0.24609375  0.02119446] 3   1 \n",
      "[-0.72802734  0.28271484 -0.0713501   0.23352051 -0.01596069 -0.05026245] 1   5 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.57666016  0.14880371  0.02560425  0.2064209   0.18249512  0.0423584 ] 3   3 Match 222\n",
      "\n",
      "[-0.828125    0.17980957 -0.21679688  0.19372559 -0.03515625 -0.04116821] 3   5 \n",
      "[-0.73095703  0.19006348 -0.05233765  0.10784912  0.1295166  -0.10284424] 1   1 Match 223\n",
      "\n",
      "[-0.68310547  0.09979248 -0.06677246  0.31469727  0.25585938 -0.02008057] 3   5 \n",
      "[-0.72998047  0.14025879 -0.02746582  0.32983398  0.15258789  0.01467133] 3   1 \n",
      "[-0.60839844  0.03894043  0.1340332   0.15283203  0.28710938  0.00251579] 4   4 Match 224\n",
      "\n",
      "[-0.69140625  0.17736816 -0.07714844  0.37451172  0.02546692 -0.02749634] 3   2 \n",
      "[-0.734375    0.15075684 -0.04067993  0.28295898  0.28393555 -0.06222534] 4   5 \n",
      "[-0.68115234  0.02230835  0.0199585   0.17858887  0.10290527  0.03903198] 3   1 \n",
      "[-0.70751953  0.22766113 -0.10839844  0.20092773  0.14233398 -0.09466553] 1   5 \n",
      "[-0.69921875  0.19262695 -0.05267334  0.2232666   0.13012695 -0.0758667 ] 3   4 \n",
      "[-0.79296875  0.10247803 -0.15820312  0.24072266  0.06958008 -0.02458191] 3   5 \n",
      "[-0.70947266  0.0713501  -0.02062988  0.18762207  0.21984863 -0.04241943] 4   4 Match 225\n",
      "\n",
      "[-0.74609375  0.11499023 -0.05285645  0.2286377   0.14746094 -0.10906982] 3   1 \n",
      "[-0.6923828   0.09906006  0.04821777  0.33666992  0.05270386  0.00633621] 3   2 \n",
      "[-0.74902344  0.13354492 -0.01421356  0.20874023  0.13952637 -0.03164673] 3   5 \n",
      "[-0.6508789   0.12145996  0.06732178  0.3803711   0.10736084  0.06896973] 3   1 \n",
      "[-0.6586914   0.26757812 -0.10583496  0.35546875  0.06530762  0.08978271] 3   4 \n",
      "[-0.75097656  0.07885742 -0.02706909  0.19165039  0.14538574 -0.01332855] 3   4 \n",
      "[-0.77978516  0.10668945 -0.03540039  0.12322998  0.22045898 -0.07946777] 4   4 Match 226\n",
      "\n",
      "[-0.7060547   0.12609863 -0.04385376  0.2956543   0.065979    0.02653503] 3   5 \n",
      "[-0.6152344   0.11260986  0.05154419  0.24645996  0.21569824  0.00888062] 3   3 Match 227\n",
      "\n",
      "[-0.7680664   0.29638672 -0.05725098  0.33276367  0.09387207 -0.07073975] 3   5 \n",
      "[-0.66259766  0.18310547  0.06433105  0.25097656  0.14990234  0.02290344] 3   4 \n",
      "[-0.61035156  0.08013916  0.12115479  0.27319336  0.2220459   0.00224304] 3   4 \n",
      "[-0.7036133   0.2619629  -0.08630371  0.33447266  0.02932739 -0.03561401] 3   1 \n",
      "[-0.7006836   0.2927246  -0.20092773  0.30322266  0.0140686  -0.1307373 ] 3   0 \n",
      "[-0.7060547   0.25683594 -0.11462402  0.26123047  0.1361084  -0.09552002] 3   4 \n",
      "[-0.6542969   0.2541504  -0.06750488  0.29956055  0.14477539 -0.02346802] 3   3 Match 228\n",
      "\n",
      "[-0.6850586   0.09985352  0.06219482  0.21813965  0.19104004 -0.02468872] 3   3 Match 229\n",
      "\n",
      "[-0.65625     0.14575195 -0.03848267  0.31591797  0.08905029  0.05343628] 3   1 \n",
      "[-0.67529297  0.2524414  -0.02764893  0.39086914  0.06246948 -0.04260254] 3   4 \n",
      "[-7.3583984e-01  2.1130371e-01 -1.2963867e-01  2.3156738e-01\n",
      "  5.0592422e-04  2.7603149e-02] 3   2 \n",
      "[-0.6479492   0.17858887 -0.03295898  0.21154785  0.06228638  0.00516129] 3   3 Match 230\n",
      "\n",
      "[-0.7319336   0.20837402 -0.07415771  0.35839844  0.06134033 -0.01560211] 3   4 \n",
      "[-0.7651367   0.20446777 -0.11413574  0.15209961 -0.07110596 -0.04559326] 1   4 \n",
      "[-0.71728516  0.23144531 -0.14758301  0.40600586 -0.01719666  0.02603149] 3   4 \n",
      "[-0.66308594  0.17419434  0.02909851  0.19628906  0.19567871 -0.02383423] 3   3 Match 231\n",
      "\n",
      "[-0.66845703  0.09222412  0.07232666  0.24206543  0.22399902  0.00507355] 3   4 \n",
      "[-0.61572266  0.19873047 -0.01079559  0.3642578   0.06860352  0.00922394] 3   4 \n",
      "[-0.66503906  0.16088867 -0.05911255  0.3149414   0.14550781  0.03991699] 3   2 \n",
      "[-0.7578125   0.09875488 -0.11053467  0.2775879   0.06506348  0.014328  ] 3   5 \n",
      "[-0.62353516  0.16711426  0.07067871  0.2388916   0.15478516  0.0635376 ] 3   4 \n",
      "[-0.6850586  -0.03381348  0.11004639  0.16088867  0.22473145 -0.00917816] 4   1 \n",
      "[-0.6430664   0.17858887 -0.11206055  0.19177246  0.07446289 -0.04052734] 3   1 \n",
      "[-0.76660156  0.20288086 -0.065979    0.27416992  0.05047607 -0.0042572 ] 3   2 \n",
      "[-0.66015625  0.1673584   0.09405518  0.2783203   0.06433105  0.04672241] 3   5 \n",
      "[-0.7470703   0.13085938 -0.02412415  0.25585938  0.16223145 -0.03884888] 3   3 Match 232\n",
      "\n",
      "[-0.7558594   0.16882324 -0.04162598  0.30395508  0.02622986  0.0177002 ] 3   4 \n",
      "[-0.7597656   0.16833496 -0.0958252   0.23901367  0.07147217  0.037323  ] 3   3 Match 233\n",
      "\n",
      "[-0.6333008   0.11730957  0.09680176  0.23901367  0.1739502   0.04364014] 3   4 \n",
      "[-0.6777344   0.20983887 -0.1282959   0.2763672   0.05178833 -0.01571655] 3   0 \n",
      "[-0.8330078   0.18200684 -0.10852051  0.2290039   0.05276489 -0.1126709 ] 3   3 Match 234\n",
      "\n",
      "[-0.6508789   0.23596191 -0.22277832  0.25878906  0.0637207   0.0333252 ] 3   1 \n",
      "[-0.65966797  0.13012695  0.05737305  0.37060547  0.01977539  0.11352539] 3   4 \n",
      "[-0.7807617   0.20080566 -0.14819336  0.22521973  0.09936523 -0.15966797] 3   4 \n",
      "[-0.76904297  0.2475586  -0.08343506  0.28320312  0.04483032 -0.00336266] 3   4 \n",
      "[-0.6894531   0.27685547 -0.12005615  0.28857422  0.06286621 -0.0173645 ] 3   4 \n",
      "[-0.7421875   0.10113525 -0.06774902  0.15563965  0.1104126  -0.01212311] 3   1 \n",
      "[-0.6743164   0.22387695 -0.06182861  0.1965332   0.05053711  0.06774902] 1   2 \n",
      "[-0.70410156  0.22473145 -0.09490967  0.30200195  0.06811523 -0.01239777] 3   1 \n",
      "[-0.77734375  0.18493652 -0.0881958   0.2166748   0.13232422 -0.10491943] 3   4 \n",
      "[-0.54248047  0.11773682  0.06420898  0.32666016  0.11730957  0.13110352] 3   1 \n",
      "[-0.6455078   0.13012695 -0.10827637  0.29638672  0.21936035 -0.02012634] 3   2 \n",
      "[-0.6665039   0.18188477  0.0362854   0.23986816  0.04367065 -0.04083252] 3   5 \n",
      "[-0.703125    0.16271973  0.0614624   0.35253906  0.05062866  0.01187897] 3   2 \n",
      "[-0.6010742   0.18322754 -0.06091309  0.2401123   0.14538574  0.06817627] 3   3 Match 235\n",
      "\n",
      "[-0.75        0.33398438 -0.19372559  0.32373047 -0.03768921 -0.05343628] 1   4 \n",
      "[-0.6894531   0.10375977  0.01301575  0.18115234  0.14318848  0.00494766] 3   5 \n",
      "[-0.65771484  0.19543457  0.04632568  0.36694336 -0.00131702 -0.04034424] 3   0 \n",
      "[-0.7734375   0.28686523 -0.05609131  0.3330078   0.07336426 -0.14672852] 3   3 Match 236\n",
      "\n",
      "[-0.8027344   0.10516357 -0.13623047  0.12988281  0.15844727 -0.06402588] 4   5 \n",
      "[-0.7314453   0.29174805 -0.17651367  0.35229492 -0.03050232 -0.01681519] 3   2 \n",
      "[-0.81347656  0.11950684 -0.1328125   0.13232422  0.08483887 -0.11785889] 3   3 Match 237\n",
      "\n",
      "[-0.73583984  0.12023926 -0.02238464  0.30493164  0.21679688 -0.04022217] 3   4 \n",
      "[-0.7602539   0.24291992 -0.1026001   0.28051758  0.10113525 -0.00407791] 3   5 \n",
      "[-0.6611328   0.15808105 -0.01542664  0.23791504  0.15454102 -0.0586853 ] 3   3 Match 238\n",
      "\n",
      "[-0.80908203  0.12963867 -0.24963379  0.15661621  0.00201416 -0.08520508] 3   0 \n",
      "[-0.7480469   0.15673828 -0.04229736  0.13879395  0.07525635 -0.07421875] 1   2 \n",
      "[-0.6879883   0.15905762 -0.08850098  0.18334961  0.13769531  0.02157593] 3   1 \n",
      "[-0.8095703   0.1538086  -0.10894775  0.12139893  0.10748291 -0.08636475] 1   2 \n",
      "[-0.64697266  0.04794312 -0.0055809   0.21484375  0.14453125  0.00791931] 3   1 \n",
      "[-0.58447266  0.17016602 -0.00983429  0.15734863  0.24365234 -0.03643799] 4   5 \n",
      "[-0.59716797  0.10229492  0.08349609  0.24584961  0.22290039  0.04165649] 3   2 \n",
      "[-0.7480469   0.16308594 -0.09527588  0.24475098  0.0294342  -0.01300812] 3   0 \n",
      "[-0.73535156  0.3630371  -0.18225098  0.13391113  0.11712646 -0.18615723] 1   2 \n",
      "[-0.6645508   0.06298828 -0.0508728   0.2836914   0.11682129  0.06463623] 3   5 \n",
      "[-0.7270508   0.02870178 -0.00329971  0.18762207  0.12854004 -0.05505371] 3   3 Match 239\n",
      "\n",
      "[-0.83447266  0.11035156 -0.09802246  0.24768066  0.07556152 -0.01878357] 3   5 \n",
      "[-0.5986328   0.10955811  0.01071167  0.28027344  0.20654297  0.0418396 ] 3   1 \n",
      "[-0.7163086   0.2836914  -0.12902832  0.20349121  0.16271973 -0.22265625] 1   1 Match 240\n",
      "\n",
      "[-0.71533203  0.16906738 -0.17053223  0.28271484  0.03677368  0.06225586] 3   5 \n",
      "[-0.7470703   0.25170898 -0.22253418  0.16015625  0.12133789 -0.1784668 ] 1   1 Match 241\n",
      "\n",
      "[-0.7714844   0.14196777 -0.16723633  0.22631836  0.16674805 -0.06872559] 3   1 \n",
      "[-6.9482422e-01  3.4570312e-01 -1.2274170e-01  4.1601562e-01\n",
      "  5.9700012e-04 -5.8837891e-02] 3   3 Match 242\n",
      "\n",
      "[-0.60839844  0.09191895 -0.06433105  0.46899414  0.17041016  0.03140259] 3   4 \n",
      "[-7.5390625e-01  1.6601562e-01 -2.9711914e-01  2.2229004e-01\n",
      "  2.7894974e-04 -1.6174316e-01] 3   3 Match 243\n",
      "\n",
      "[-0.6826172   0.16906738 -0.09283447  0.33203125  0.10406494 -0.06396484] 3   3 Match 244\n",
      "\n",
      "[-0.7548828   0.12463379 -0.14501953  0.1315918   0.19165039 -0.07788086] 4   4 Match 245\n",
      "\n",
      "[-0.6972656   0.05169678 -0.01786804  0.33520508  0.11694336  0.0770874 ] 3   5 \n",
      "[-0.83447266  0.25830078 -0.23498535  0.10754395  0.07330322 -0.13867188] 1   5 \n",
      "[-0.6767578   0.20788574 -0.11853027  0.23400879  0.08325195 -0.05047607] 3   5 \n",
      "[-0.70751953  0.06082153 -0.11260986  0.23046875  0.10913086  0.01467896] 3   2 \n",
      "[-0.5834961   0.13024902  0.00997162  0.39331055  0.0881958   0.07824707] 3   4 \n",
      "[-0.73535156  0.28564453 -0.18652344  0.2401123   0.2244873  -0.20300293] 1   2 \n",
      "[-0.7998047   0.1274414  -0.13623047  0.21325684  0.06665039 -0.02801514] 3   4 \n",
      "[-0.8041992   0.19348145 -0.17297363  0.26049805  0.01661682 -0.03890991] 3   4 \n",
      "[-0.7973633   0.12890625 -0.1307373   0.2783203   0.10919189  0.09350586] 3   2 \n",
      "[-0.62402344  0.10510254 -0.04299927  0.38110352  0.12719727  0.12158203] 3   2 \n",
      "[-0.6279297   0.14489746 -0.00167656  0.26586914  0.15942383  0.05203247] 3   2 \n",
      "[-0.7416992   0.07958984 -0.03244019  0.14880371  0.16491699 -0.0352478 ] 4   2 \n",
      "[-0.7402344   0.09936523 -0.11645508  0.2734375   0.10522461  0.05160522] 3   3 Match 246\n",
      "\n",
      "[-0.68408203  0.16369629 -0.1038208   0.3227539   0.12042236 -0.05096436] 3   4 \n",
      "[-0.6694336   0.17004395 -0.09472656  0.32299805  0.06677246  0.0279541 ] 3   0 \n",
      "[-0.73291016  0.06842041 -0.01269531  0.18493652  0.19018555 -0.01722717] 4   3 \n",
      "[-0.7832031   0.19030762 -0.10400391  0.23413086  0.12091064 -0.02262878] 3   5 \n",
      "[-0.6904297   0.06170654 -0.02432251  0.26513672  0.11395264 -0.03071594] 3   3 Match 247\n",
      "\n",
      "[-7.3388672e-01  6.4025879e-02 -1.5281677e-02  1.9995117e-01\n",
      "  1.8872070e-01 -5.4550171e-04] 3   1 \n",
      "[-0.6816406   0.18908691 -0.0737915   0.21459961  0.15637207  0.0164032 ] 3   4 \n",
      "[-0.66552734  0.04782104  0.06756592  0.10546875  0.21325684 -0.05987549] 4   4 Match 248\n",
      "\n",
      "[-0.7553711   0.15124512  0.05316162  0.36254883  0.0682373  -0.03527832] 3   3 Match 249\n",
      "\n",
      "[-0.6801758   0.23303223 -0.06030273  0.22485352  0.08056641 -0.06524658] 1   5 \n",
      "[-0.7338867   0.11083984 -0.08685303  0.20715332  0.19189453 -0.0703125 ] 3   4 \n",
      "[-0.6176758   0.06176758  0.08001709  0.2565918   0.15478516  0.04919434] 3   4 \n",
      "[-0.7236328   0.13903809  0.06970215  0.19189453  0.06085205 -0.03393555] 3   4 \n",
      "[-0.7392578   0.06848145  0.02651978  0.21984863  0.14575195 -0.0692749 ] 3   2 \n",
      "[-6.6406250e-01  1.4526367e-01 -3.6193848e-02  1.9567871e-01\n",
      "  1.5356445e-01  1.6725063e-04] 3   4 \n",
      "[-0.59375     0.17492676 -0.09216309  0.29882812  0.15478516  0.13269043] 3   2 \n",
      "[-0.6479492   0.3227539  -0.07519531  0.4814453   0.0309906  -0.0925293 ] 3   5 \n",
      "[-0.7290039   0.18127441 -0.00549698  0.28686523  0.08325195 -0.00266075] 3   2 \n",
      "[-0.60839844  0.09326172  0.06896973  0.24328613  0.13464355  0.008255  ] 3   4 \n",
      "[-0.7885742   0.2298584  -0.06585693  0.33422852 -0.00366402  0.07775879] 3   2 \n",
      "[-0.71435547  0.30126953 -0.12487793  0.20678711  0.23388672 -0.13293457] 1   5 \n",
      "[-0.75097656  0.28735352 -0.14453125  0.2915039   0.04315186 -0.11785889] 3   5 \n",
      "[-0.69873047  0.01968384  0.04626465  0.14562988  0.1998291  -0.01241302] 4   2 \n",
      "[-0.79248047  0.19128418 -0.22265625  0.1607666   0.0329895  -0.13317871] 1   0 \n",
      "[-0.77197266  0.1328125  -0.11309814  0.2866211   0.0713501  -0.03753662] 3   1 \n",
      "[-0.8261719   0.20397949 -0.13537598  0.13244629 -0.0016489  -0.10876465] 1   4 \n",
      "[-0.71972656  0.17138672 -0.05548096  0.18969727  0.09240723  0.03948975] 3   2 \n",
      "[-0.71777344  0.15576172 -0.16882324  0.11755371  0.16748047 -0.05541992] 4   4 Match 250\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.78808594  0.13806152 -0.06872559  0.29638672  0.10058594 -0.01937866] 3   2 \n",
      "[-0.6425781   0.13146973 -0.06921387  0.2788086   0.07989502  0.09710693] 3   5 \n",
      "[-0.6435547   0.22680664 -0.01860046  0.22753906  0.07183838 -0.08404541] 3   2 \n",
      "[-0.6464844   0.2142334  -0.0440979   0.4074707   0.05670166  0.08410645] 3   2 \n",
      "[-0.76220703  0.23583984 -0.16906738  0.33935547  0.09643555 -0.04992676] 3   1 \n",
      "[-0.6875      0.07513428 -0.08856201  0.3269043   0.1784668   0.16101074] 3   5 \n",
      "[-0.8041992   0.08172607 -0.08666992  0.24389648  0.07214355 -0.02037048] 3   4 \n",
      "[-0.74902344  0.2331543  -0.15625     0.28027344  0.07806396 -0.03369141] 3   1 \n",
      "[-0.69970703  0.12121582 -0.03845215  0.2052002   0.24914551 -0.04351807] 4   2 \n",
      "[-0.7241211   0.20690918 -0.09802246  0.19372559  0.0904541  -0.0814209 ] 1   3 \n",
      "[-0.66308594  0.02825928  0.05517578  0.29956055  0.23657227  0.06280518] 3   1 \n",
      "[-0.76904297  0.22766113 -0.21862793  0.19445801  0.14172363 -0.12017822] 1   4 \n",
      "[-0.75        0.17138672 -0.1071167   0.11499023  0.04382324 -0.0980835 ] 1   2 \n",
      "[-0.6826172   0.05801392 -0.00968933  0.27490234  0.23999023 -0.05633545] 3   5 \n",
      "[-0.7338867   0.09295654 -0.01777649  0.25927734  0.0982666   0.02372742] 3   5 \n",
      "[-0.69433594  0.14123535 -0.02349854  0.2166748   0.04309082  0.0249176 ] 3   2 \n",
      "[-0.77978516  0.13134766 -0.05706787  0.22998047  0.01863098 -0.0680542 ] 3   2 \n",
      "[-0.73535156  0.1694336  -0.00277901  0.29223633  0.04006958  0.09796143] 3   4 \n",
      "[-0.7680664   0.3269043  -0.11407471  0.3737793   0.016922   -0.14208984] 3   4 \n",
      "[-0.77685547  0.16748047 -0.1965332   0.23620605 -0.08563232 -0.06939697] 3   1 \n",
      "[-0.65185547  0.10754395 -0.09802246  0.26513672  0.15881348 -0.00912476] 3   0 \n",
      "[-0.7080078   0.24279785 -0.0289917   0.33984375  0.08917236 -0.11260986] 3   4 \n",
      "[-0.7089844   0.16345215 -0.08917236  0.16784668  0.1303711  -0.0071106 ] 3   3 Match 251\n",
      "\n",
      "[-0.87353516  0.09356689 -0.16845703  0.1998291  -0.01980591  0.04501343] 3   1 \n",
      "[-0.7558594   0.1694336  -0.01103973  0.25317383  0.05383301 -0.04403687] 3   2 \n",
      "[-7.3144531e-01  1.8078613e-01  6.9570541e-04  2.4682617e-01\n",
      "  8.9294434e-02  4.2144775e-02] 3   3 Match 252\n",
      "\n",
      "[-0.76416016  0.13708496  0.06188965  0.3491211   0.08862305 -0.03591919] 3   3 Match 253\n",
      "\n",
      "[-0.8276367   0.11297607 -0.14172363  0.18200684  0.14416504 -0.00398636] 3   4 \n",
      "[-0.81103516  0.16052246 -0.16931152  0.21777344  0.04089355 -0.04092407] 3   5 \n",
      "[-0.82128906  0.25170898 -0.2319336   0.08355713  0.09820557 -0.13891602] 1   3 \n",
      "[-6.5478516e-01  3.2928467e-02 -3.3020973e-05  2.8759766e-01\n",
      "  1.4526367e-01  1.0064697e-01] 3   2 \n",
      "[-0.70654297  0.03216553  0.03967285  0.21496582  0.20080566 -0.04660034] 3   2 \n",
      "[-0.8623047   0.21240234 -0.17285156  0.23095703  0.03988647 -0.04299927] 3   4 \n",
      "[-0.7788086   0.15649414 -0.10321045  0.20458984  0.0645752  -0.09094238] 3   1 \n",
      "[-0.74365234  0.19836426 -0.08081055  0.29052734  0.140625   -0.13122559] 3   1 \n",
      "[-0.80322266  0.10717773 -0.05233765  0.12731934  0.17541504 -0.02027893] 4   5 \n",
      "[-0.64501953  0.18054199  0.05639648  0.4440918   0.02330017  0.06835938] 3   5 \n",
      "[-0.67333984  0.25683594 -0.08166504  0.37841797  0.13330078  0.08190918] 3   3 Match 254\n",
      "\n",
      "[-0.6904297   0.17834473 -0.12011719  0.29003906  0.20214844  0.02104187] 3   2 \n",
      "[-0.60009766  0.13952637  0.14892578  0.29516602  0.09118652  0.00895691] 3   0 \n",
      "[-0.6254883   0.0848999   0.02708435  0.35351562  0.15649414  0.05581665] 3   3 Match 255\n",
      "\n",
      "[-0.7661133   0.19055176 -0.1171875   0.21081543  0.13012695  0.0164032 ] 3   5 \n",
      "[-0.63134766  0.08074951  0.0586853   0.29907227  0.12854004  0.03326416] 3   4 \n",
      "[-0.7524414   0.18859863 -0.14221191  0.3269043   0.05218506  0.07867432] 3   5 \n",
      "[-0.7270508   0.12780762 -0.05993652  0.28686523  0.2019043  -0.03890991] 3   3 Match 256\n",
      "\n",
      "[-0.7441406   0.09869385 -0.02200317  0.21142578  0.08215332 -0.03491211] 3   2 \n",
      "[-0.5859375   0.15991211 -0.0062561   0.31445312  0.1352539   0.07879639] 3   2 \n",
      "[-0.71777344  0.07104492 -0.01733398  0.31518555  0.05606079  0.04885864] 3   1 \n",
      "[-0.6411133   0.19726562 -0.09057617  0.38452148  0.01669312  0.0255127 ] 3   1 \n",
      "[-0.76953125  0.25927734 -0.18859863  0.234375    0.0619812  -0.01756287] 1   3 \n",
      "[-0.7504883   0.25512695 -0.08361816  0.22937012  0.02636719 -0.04425049] 1   5 \n",
      "[-0.6933594   0.14538574 -0.09216309  0.30541992  0.17749023  0.03158569] 3   4 \n",
      "[-0.7807617   0.22668457 -0.02844238  0.38891602  0.03875732 -0.07104492] 3   0 \n",
      "[-0.71777344  0.0793457   0.04312134  0.25048828  0.22827148 -0.01579285] 3   2 \n",
      "[-0.6928711   0.15405273  0.03723145  0.40795898  0.05999756  0.04623413] 3   5 \n",
      "[-0.75        0.07287598 -0.0269928   0.11981201  0.16931152 -0.04946899] 4   4 Match 257\n",
      "\n",
      "[-0.7397461   0.18554688 -0.19360352  0.14611816  0.09197998 -0.12011719] 1   2 \n",
      "[-0.68066406  0.04910278 -0.0165863   0.16442871  0.1899414  -0.05895996] 4   3 \n",
      "[-0.6401367   0.01361084  0.03289795  0.20825195  0.2290039   0.0914917 ] 4   2 \n",
      "[-0.7783203   0.06243896  0.02124023  0.2783203   0.1583252   0.0243988 ] 3   3 Match 258\n",
      "\n",
      "[-0.6904297   0.08129883 -0.00264931  0.21813965  0.09039307  0.0059166 ] 3   1 \n",
      "[-0.71875     0.24487305 -0.07745361  0.25732422  0.01914978 -0.06860352] 3   2 \n",
      "[-0.6635742   0.16882324 -0.03720093  0.18286133  0.1194458   0.00697327] 3   5 \n",
      "[-0.6875      0.06970215 -0.01852417  0.17248535  0.21386719  0.0118103 ] 4   5 \n",
      "[-0.72802734  0.15441895 -0.00342941  0.09838867  0.13476562 -0.05563354] 1   3 \n",
      "[-0.5551758   0.1920166  -0.01701355  0.3388672   0.24682617  0.02064514] 3   3 Match 259\n",
      "\n",
      "[-0.7792969   0.14501953 -0.19482422  0.20751953  0.07562256 -0.08843994] 3   2 \n",
      "[-0.7138672   0.22155762 -0.09393311  0.17749023  0.11785889 -0.02896118] 1   4 \n",
      "[-0.7866211   0.13696289 -0.0350647   0.28466797  0.15771484 -0.07208252] 3   4 \n",
      "[-0.6826172   0.0925293   0.01757812  0.23022461  0.14892578  0.03890991] 3   3 Match 260\n",
      "\n",
      "[-0.71875     0.11981201 -0.06088257  0.20056152  0.13244629  0.002491  ] 3   1 \n",
      "[-0.61621094  0.1784668  -0.02043152  0.3017578   0.0894165   0.07684326] 3   3 Match 261\n",
      "\n",
      "[-0.6845703   0.10412598  0.02957153  0.15063477  0.10162354  0.02502441] 3   4 \n",
      "[-0.6401367   0.07800293  0.08978271  0.21716309  0.12054443  0.02546692] 3   3 Match 262\n",
      "\n",
      "[-0.63378906  0.08483887  0.07128906  0.26489258  0.2298584   0.00068426] 3   2 \n",
      "[-0.6459961   0.08526611  0.0428772   0.1953125   0.23400879  0.05685425] 4   1 \n",
      "[-0.6850586   0.11224365 -0.11309814  0.08898926  0.1817627  -0.01448822] 4   4 Match 263\n",
      "\n",
      "[-0.6640625   0.12255859  0.01834106  0.26049805  0.1862793  -0.07989502] 3   3 Match 264\n",
      "\n",
      "[-0.80029297  0.22290039  0.00299072  0.31762695 -0.00096941 -0.08349609] 3   4 \n",
      "[-0.6503906   0.09771729  0.07922363  0.23242188  0.22521973  0.03219604] 3   1 \n",
      "[-0.7558594   0.12915039 -0.13244629  0.20800781  0.10247803  0.00395203] 3   2 \n",
      "[-0.7714844   0.10797119 -0.07281494  0.1973877   0.0982666  -0.01593018] 3   2 \n",
      "[-0.68066406  0.14282227 -0.03427124  0.2763672   0.15795898  0.00894928] 3   0 \n",
      "[-0.65527344  0.16955566 -0.05493164  0.32788086  0.09643555  0.02566528] 3   2 \n",
      "[-0.61865234  0.10601807  0.02720642  0.2529297   0.17834473  0.05560303] 3   2 \n",
      "[-0.7524414   0.07086182  0.02766418  0.11584473  0.14428711 -0.05187988] 4   3 \n",
      "[-0.8535156   0.10888672 -0.22497559  0.24353027  0.01818848 -0.04055786] 3   5 \n",
      "[-0.7084961   0.14465332 -0.10766602  0.31201172  0.12347412  0.04901123] 3   4 \n",
      "[-0.7182617   0.12219238 -0.05749512  0.23876953  0.17407227  0.0680542 ] 3   2 \n",
      "[-0.6845703   0.10186768 -0.05343628  0.23205566  0.16418457 -0.08221436] 3   3 Match 265\n",
      "\n",
      "[-0.76123047  0.08105469 -0.07183838  0.14575195  0.22631836  0.01115417] 4   3 \n",
      "[-0.7832031   0.07720947 -0.10992432  0.12902832  0.11407471 -0.01802063] 3   4 \n",
      "[-0.7470703   0.34057617 -0.07751465  0.38427734  0.0491333  -0.11395264] 3   4 \n",
      "[-0.57714844  0.09643555  0.02705383  0.24377441  0.23217773  0.0440979 ] 3   2 \n",
      "[-0.82666016  0.16674805 -0.04034424  0.21582031  0.07666016 -0.13464355] 3   3 Match 266\n",
      "\n",
      "[-0.7392578   0.21411133 -0.09643555  0.25830078  0.09277344 -0.07794189] 3   2 \n",
      "[-0.7084961   0.05239868  0.04168701  0.17553711  0.20568848  0.00924683] 4   5 \n",
      "[-0.82373047  0.16186523 -0.19177246  0.19042969 -0.03942871 -0.04214478] 3   1 \n",
      "[-0.56933594  0.04849243  0.16345215  0.15429688  0.234375   -0.00275993] 4   2 \n",
      "[-0.7011719   0.21875    -0.14880371  0.2631836   0.0413208  -0.04418945] 3   0 \n",
      "[-0.61572266  0.20703125 -0.03875732  0.2578125   0.06842041  0.04733276] 3   0 \n",
      "[-0.7939453   0.30664062 -0.17834473  0.17675781 -0.01048279 -0.10705566] 1   3 \n",
      "[-0.70654297  0.13208008  0.03463745  0.28173828  0.06481934  0.0453186 ] 3   2 \n",
      "[-0.7680664   0.16772461 -0.03713989  0.2709961   0.1282959  -0.07855225] 3   1 \n",
      "[-0.6352539   0.17370605 -0.03182983  0.26953125  0.12902832 -0.06439209] 3   4 \n",
      "[-0.7294922   0.13842773 -0.02967834  0.15026855  0.23205566 -0.00200081] 4   2 \n",
      "[-0.71240234  0.1116333  -0.0880127   0.19543457  0.2709961  -0.01296997] 4   0 \n",
      "[-0.6772461   0.18566895 -0.08001709  0.24108887  0.05963135  0.0014534 ] 3   1 \n",
      "266\n"
     ]
    }
   ],
   "source": [
    "Pred=[]\n",
    "\n",
    "countCorrect=0\n",
    "\n",
    "for row in range(TestModel_outputs.shape[0]):\n",
    "    outputs=TestModel_outputs[row]\n",
    "    #print(test.iloc[row,0])\n",
    "    print(outputs, end=' ')\n",
    "    \n",
    "    result=0\n",
    "    if outputs[0]<outputs[1]:result=1\n",
    "    if outputs[result]<outputs[2]:result=2\n",
    "    if outputs[result]<outputs[3]:result=3\n",
    "    if outputs[result]<outputs[4]:result=4\n",
    "    if outputs[result]<outputs[5]:result=5\n",
    "    Pred.append(result)\n",
    "    print(result, ' ',test.iloc[row,1], end=' ')\n",
    "    if result==test.iloc[row,1]:\n",
    "        countCorrect+=1\n",
    "        print('Match',countCorrect)\n",
    "    print('')\n",
    "\n",
    "print(countCorrect)\n",
    "#Pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0   8   0  68  16   0]\n",
      " [  0  29   0 184  37   0]\n",
      " [  0  23   0 158  33   0]\n",
      " [  0  27   0 211  29   0]\n",
      " [  0  31   0 192  26   0]\n",
      " [  0  32   0 162  17   0]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    " \n",
    "print(metrics.confusion_matrix(test['labels'],Pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Pants       0.00      0.00      0.00        92\n",
      "       False       0.19      0.12      0.14       250\n",
      " Barely-True       0.00      0.00      0.00       214\n",
      "   Hlaf-True       0.22      0.79      0.34       267\n",
      " Mostly-True       0.16      0.10      0.13       249\n",
      "        True       0.00      0.00      0.00       211\n",
      "\n",
      "    accuracy                           0.21      1283\n",
      "   macro avg       0.10      0.17      0.10      1283\n",
      "weighted avg       0.11      0.21      0.12      1283\n",
      "\n"
     ]
    }
   ],
   "source": [
    "target_names = ['Pants', 'False', 'Barely-True','Hlaf-True','Mostly-True','True']\n",
    "\n",
    "print(metrics.classification_report(test['labels'], Pred,target_names =target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving...\n",
      "Saving Complete on 2020-03-24 17:07:11.998394 in: ./TunedModels/bert/bert-base-cased/Saves/\n"
     ]
    }
   ],
   "source": [
    "# saving the output of the models to CSVs\n",
    "#these are 1X6 classification vectors\n",
    "\n",
    "SavesDirectory='./TunedModels/'+model_class+'/'+model_version+\"/Saves/\"\n",
    "print('Saving...')\n",
    "trainOut = pd.DataFrame(data= TrainModel_outputs )\n",
    "trainOut.to_csv(SavesDirectory+'trainOut.tsv', sep='\\t',  index=False)\n",
    "\n",
    "evalOut = pd.DataFrame(data= EvalModel_outputs )\n",
    "evalOut.to_csv(SavesDirectory+'evalOut.tsv', sep='\\t',  index=False)\n",
    "\n",
    "testOut = pd.DataFrame(data= TestModel_outputs )\n",
    "testOut.to_csv(SavesDirectory+'testOut.tsv', sep='\\t',  index=False)\n",
    "\n",
    "print('Saving Complete on',datetime.now() ,'in:', SavesDirectory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "del(model)\n",
    "#del(train,Eval,test)\n",
    "del(trainOut,evalOut,testOut)\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Adding the reputation vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section takes the output results from the transformer used above and uses it together with the speaker's reputation to enhance the classification.\n",
    "\n",
    "Before running this section it is suggested that you halt the program and start running it again from this cell. The neural net will likely have an error caused by some unreleased variable used by thr simple transformers library. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PantsTotal</th>\n",
       "      <th>NotRealTotal</th>\n",
       "      <th>BarelyTotal</th>\n",
       "      <th>HalfTotal</th>\n",
       "      <th>MostlyTotal</th>\n",
       "      <th>Truths</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.005</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.769043</td>\n",
       "      <td>0.343506</td>\n",
       "      <td>-0.256836</td>\n",
       "      <td>0.236328</td>\n",
       "      <td>0.045868</td>\n",
       "      <td>-0.086609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.095</td>\n",
       "      <td>0.160</td>\n",
       "      <td>0.170</td>\n",
       "      <td>0.290</td>\n",
       "      <td>0.165</td>\n",
       "      <td>0.165</td>\n",
       "      <td>-0.765625</td>\n",
       "      <td>0.263672</td>\n",
       "      <td>-0.255615</td>\n",
       "      <td>0.269775</td>\n",
       "      <td>0.039917</td>\n",
       "      <td>-0.247925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.005</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.040</td>\n",
       "      <td>0.010</td>\n",
       "      <td>-0.730957</td>\n",
       "      <td>0.238770</td>\n",
       "      <td>-0.121582</td>\n",
       "      <td>0.258545</td>\n",
       "      <td>-0.003519</td>\n",
       "      <td>-0.049164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.005</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.040</td>\n",
       "      <td>0.010</td>\n",
       "      <td>-0.718262</td>\n",
       "      <td>0.206177</td>\n",
       "      <td>-0.052765</td>\n",
       "      <td>0.122192</td>\n",
       "      <td>0.071106</td>\n",
       "      <td>-0.113708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.035</td>\n",
       "      <td>0.145</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.345</td>\n",
       "      <td>0.380</td>\n",
       "      <td>0.365</td>\n",
       "      <td>-0.744629</td>\n",
       "      <td>0.181030</td>\n",
       "      <td>-0.130371</td>\n",
       "      <td>0.340088</td>\n",
       "      <td>0.073730</td>\n",
       "      <td>-0.026550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10264</th>\n",
       "      <td>0.005</td>\n",
       "      <td>0.030</td>\n",
       "      <td>0.070</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.020</td>\n",
       "      <td>-0.788574</td>\n",
       "      <td>0.282715</td>\n",
       "      <td>-0.115051</td>\n",
       "      <td>0.325439</td>\n",
       "      <td>0.047241</td>\n",
       "      <td>-0.027344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10265</th>\n",
       "      <td>0.055</td>\n",
       "      <td>0.075</td>\n",
       "      <td>0.080</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.035</td>\n",
       "      <td>-0.827148</td>\n",
       "      <td>0.165405</td>\n",
       "      <td>-0.159180</td>\n",
       "      <td>0.254150</td>\n",
       "      <td>0.041229</td>\n",
       "      <td>-0.005600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10266</th>\n",
       "      <td>0.035</td>\n",
       "      <td>0.115</td>\n",
       "      <td>0.140</td>\n",
       "      <td>0.190</td>\n",
       "      <td>0.170</td>\n",
       "      <td>0.075</td>\n",
       "      <td>-0.720215</td>\n",
       "      <td>0.178955</td>\n",
       "      <td>-0.116272</td>\n",
       "      <td>0.205933</td>\n",
       "      <td>0.080505</td>\n",
       "      <td>-0.167114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10267</th>\n",
       "      <td>0.305</td>\n",
       "      <td>0.570</td>\n",
       "      <td>0.315</td>\n",
       "      <td>0.255</td>\n",
       "      <td>0.185</td>\n",
       "      <td>0.070</td>\n",
       "      <td>-0.785645</td>\n",
       "      <td>0.341064</td>\n",
       "      <td>-0.238403</td>\n",
       "      <td>0.160522</td>\n",
       "      <td>0.011398</td>\n",
       "      <td>-0.134644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10268</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.678223</td>\n",
       "      <td>0.252197</td>\n",
       "      <td>-0.175659</td>\n",
       "      <td>0.144897</td>\n",
       "      <td>0.166504</td>\n",
       "      <td>-0.135132</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10269 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       PantsTotal  NotRealTotal  BarelyTotal  HalfTotal  MostlyTotal  Truths  \\\n",
       "0           0.005         0.000        0.000      0.000        0.000   0.000   \n",
       "1           0.095         0.160        0.170      0.290        0.165   0.165   \n",
       "2           0.005         0.010        0.005      0.015        0.040   0.010   \n",
       "3           0.005         0.010        0.005      0.015        0.040   0.010   \n",
       "4           0.035         0.145        0.200      0.345        0.380   0.365   \n",
       "...           ...           ...          ...        ...          ...     ...   \n",
       "10264       0.005         0.030        0.070      0.050        0.050   0.020   \n",
       "10265       0.055         0.075        0.080      0.100        0.050   0.035   \n",
       "10266       0.035         0.115        0.140      0.190        0.170   0.075   \n",
       "10267       0.305         0.570        0.315      0.255        0.185   0.070   \n",
       "10268       0.000         0.005        0.000      0.000        0.000   0.000   \n",
       "\n",
       "              0         1         2         3         4         5  \n",
       "0     -0.769043  0.343506 -0.256836  0.236328  0.045868 -0.086609  \n",
       "1     -0.765625  0.263672 -0.255615  0.269775  0.039917 -0.247925  \n",
       "2     -0.730957  0.238770 -0.121582  0.258545 -0.003519 -0.049164  \n",
       "3     -0.718262  0.206177 -0.052765  0.122192  0.071106 -0.113708  \n",
       "4     -0.744629  0.181030 -0.130371  0.340088  0.073730 -0.026550  \n",
       "...         ...       ...       ...       ...       ...       ...  \n",
       "10264 -0.788574  0.282715 -0.115051  0.325439  0.047241 -0.027344  \n",
       "10265 -0.827148  0.165405 -0.159180  0.254150  0.041229 -0.005600  \n",
       "10266 -0.720215  0.178955 -0.116272  0.205933  0.080505 -0.167114  \n",
       "10267 -0.785645  0.341064 -0.238403  0.160522  0.011398 -0.134644  \n",
       "10268 -0.678223  0.252197 -0.175659  0.144897  0.166504 -0.135132  \n",
       "\n",
       "[10269 rows x 12 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "train=pd.read_excel('trainReputation.xlsx' )\n",
    "train=train.iloc[:,:-2].astype(float)\n",
    "train=train/200  #for scaling\n",
    "#train\n",
    "\n",
    "model_class='bert'  # bert or roberta or albert\n",
    "model_version='bert-base-cased' #bert-base-cased, roberta-base, roberta-large, albert-base-v2 OR albert-large-v2\n",
    "SavesDirectory='./TunedModels/'+model_class+'/'+model_version+\"/Saves/\"\n",
    "TF_Output=pd.read_csv( SavesDirectory+'trainOut.tsv', sep='\\t')\n",
    "\n",
    "train=pd.concat([train,TF_Output], axis=1)\n",
    "\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10264</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10265</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10266</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10267</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10268</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10269 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0  1  2  3  4  5\n",
       "0      1  0  0  0  0  0\n",
       "1      0  0  0  1  0  0\n",
       "2      0  0  0  0  1  0\n",
       "3      0  0  0  0  1  0\n",
       "4      0  0  0  0  0  1\n",
       "...   .. .. .. .. .. ..\n",
       "10264  0  0  0  0  1  0\n",
       "10265  0  0  0  0  0  1\n",
       "10266  0  0  0  1  0  0\n",
       "10267  0  1  0  0  0  0\n",
       "10268  0  1  0  0  0  0\n",
       "\n",
       "[10269 rows x 6 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TrainLables=pd.read_excel('trainReputation.xlsx' )\n",
    "TrainLables=TrainLables.iloc[:,-1] \n",
    "\n",
    "TrainLables=pd.get_dummies(TrainLables)\n",
    "TrainLables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0050,  0.0000,  0.0000,  ...,  0.2363,  0.0459, -0.0866],\n",
       "        [ 0.0950,  0.1600,  0.1700,  ...,  0.2698,  0.0399, -0.2479],\n",
       "        [ 0.0050,  0.0100,  0.0050,  ...,  0.2585, -0.0035, -0.0492],\n",
       "        ...,\n",
       "        [ 0.0350,  0.1150,  0.1400,  ...,  0.2059,  0.0805, -0.1671],\n",
       "        [ 0.3050,  0.5700,  0.3150,  ...,  0.1605,  0.0114, -0.1346],\n",
       "        [ 0.0000,  0.0050,  0.0000,  ...,  0.1449,  0.1665, -0.1351]],\n",
       "       dtype=torch.float64)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input=torch.tensor(train.values)\n",
    "del(train)\n",
    "input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 1., 0., 0.],\n",
       "        [0., 0., 0., 0., 1., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0., 0., 0.],\n",
       "        [0., 1., 0., 0., 0., 0.]], dtype=torch.float64)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets=torch.tensor(TrainLables.astype(float).values)\n",
    "del(TrainLables)\n",
    "targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input size: 12\n",
      "output size: 6\n"
     ]
    }
   ],
   "source": [
    " \n",
    "size= torch.tensor(input[0].size())\n",
    "InputSize=size.item()\n",
    "\n",
    "OutputSize=torch.tensor(targets[0].size()).item()\n",
    "\n",
    "print('input size:', InputSize)\n",
    "print('output size:', OutputSize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Net(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "         \n",
    "        # an affine operation: y = Wx + b\n",
    "        self.fc1 = nn.Linear(InputSize, 24)  # input size\n",
    "        self.fc2 = nn.Linear(24, 12)\n",
    "        self.fc3 = nn.Linear(12, OutputSize)  #classifies 'outputsize' different classes\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.tanh(self.fc1(x))\n",
    "        x = torch.tanh(self.fc2(x)) \n",
    "        x = torch.tanh(self.fc3(x)).double()\n",
    "        return x\n",
    "\n",
    "    \n",
    "\n",
    "#now we use it\n",
    "\n",
    "net = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here we  setup the neural network parameters\n",
    "# pick an optimizer (Simple Gradient Descent)\n",
    "\n",
    "learning_rate = 9e-4\n",
    "criterion = nn.MSELoss()  #computes the loss Function\n",
    "\n",
    "import torch.optim as optim\n",
    "\n",
    "# creating optimizer\n",
    "#optimizer = optim.SGD(net.parameters(), lr=learning_rate)\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor(0.2126, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 0\n",
      "Loss: tensor(0.2098, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1\n",
      "Loss: tensor(0.2071, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2\n",
      "Loss: tensor(0.2044, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3\n",
      "Loss: tensor(0.2019, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4\n",
      "Loss: tensor(0.1993, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5\n",
      "Loss: tensor(0.1969, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6\n",
      "Loss: tensor(0.1945, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7\n",
      "Loss: tensor(0.1921, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8\n",
      "Loss: tensor(0.1899, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 9\n",
      "Loss: tensor(0.1876, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 10\n",
      "Loss: tensor(0.1854, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 11\n",
      "Loss: tensor(0.1833, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 12\n",
      "Loss: tensor(0.1812, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 13\n",
      "Loss: tensor(0.1792, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 14\n",
      "Loss: tensor(0.1773, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 15\n",
      "Loss: tensor(0.1754, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 16\n",
      "Loss: tensor(0.1735, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 17\n",
      "Loss: tensor(0.1717, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 18\n",
      "Loss: tensor(0.1700, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 19\n",
      "Loss: tensor(0.1683, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 20\n",
      "Loss: tensor(0.1667, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 21\n",
      "Loss: tensor(0.1651, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 22\n",
      "Loss: tensor(0.1636, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 23\n",
      "Loss: tensor(0.1622, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 24\n",
      "Loss: tensor(0.1607, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 25\n",
      "Loss: tensor(0.1594, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 26\n",
      "Loss: tensor(0.1580, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 27\n",
      "Loss: tensor(0.1568, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 28\n",
      "Loss: tensor(0.1555, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 29\n",
      "Loss: tensor(0.1543, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 30\n",
      "Loss: tensor(0.1532, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 31\n",
      "Loss: tensor(0.1521, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 32\n",
      "Loss: tensor(0.1510, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 33\n",
      "Loss: tensor(0.1500, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 34\n",
      "Loss: tensor(0.1490, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 35\n",
      "Loss: tensor(0.1481, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 36\n",
      "Loss: tensor(0.1471, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 37\n",
      "Loss: tensor(0.1463, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 38\n",
      "Loss: tensor(0.1455, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 39\n",
      "Loss: tensor(0.1447, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 40\n",
      "Loss: tensor(0.1440, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 41\n",
      "Loss: tensor(0.1433, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 42\n",
      "Loss: tensor(0.1427, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 43\n",
      "Loss: tensor(0.1421, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 44\n",
      "Loss: tensor(0.1415, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 45\n",
      "Loss: tensor(0.1410, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 46\n",
      "Loss: tensor(0.1405, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 47\n",
      "Loss: tensor(0.1401, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 48\n",
      "Loss: tensor(0.1398, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 49\n",
      "Loss: tensor(0.1394, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 50\n",
      "Loss: tensor(0.1391, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 51\n",
      "Loss: tensor(0.1389, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 52\n",
      "Loss: tensor(0.1386, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 53\n",
      "Loss: tensor(0.1385, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 54\n",
      "Loss: tensor(0.1383, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 55\n",
      "Loss: tensor(0.1382, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 56\n",
      "Loss: tensor(0.1380, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 57\n",
      "Loss: tensor(0.1379, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 58\n",
      "Loss: tensor(0.1379, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 59\n",
      "Loss: tensor(0.1378, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 60\n",
      "Loss: tensor(0.1378, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 61\n",
      "Loss: tensor(0.1377, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 62\n",
      "Loss: tensor(0.1377, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 63\n",
      "Loss: tensor(0.1377, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 64\n",
      "Loss: tensor(0.1377, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 65\n",
      "Loss: tensor(0.1377, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 66\n",
      "Loss: tensor(0.1376, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 67\n",
      "Loss: tensor(0.1376, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 68\n",
      "Loss: tensor(0.1376, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 69\n",
      "Loss: tensor(0.1376, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 70\n",
      "Loss: tensor(0.1376, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 71\n",
      "Loss: tensor(0.1376, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 72\n",
      "Loss: tensor(0.1376, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 73\n",
      "Loss: tensor(0.1376, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 74\n",
      "Loss: tensor(0.1376, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 75\n",
      "Loss: tensor(0.1376, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 76\n",
      "Loss: tensor(0.1375, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 77\n",
      "Loss: tensor(0.1375, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 78\n",
      "Loss: tensor(0.1375, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 79\n",
      "Loss: tensor(0.1375, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 80\n",
      "Loss: tensor(0.1375, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 81\n",
      "Loss: tensor(0.1374, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 82\n",
      "Loss: tensor(0.1374, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 83\n",
      "Loss: tensor(0.1374, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 84\n",
      "Loss: tensor(0.1374, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 85\n",
      "Loss: tensor(0.1374, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 86\n",
      "Loss: tensor(0.1373, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 87\n",
      "Loss: tensor(0.1373, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 88\n",
      "Loss: tensor(0.1373, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 89\n",
      "Loss: tensor(0.1373, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 90\n",
      "Loss: tensor(0.1373, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 91\n",
      "Loss: tensor(0.1372, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 92\n",
      "Loss: tensor(0.1372, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 93\n",
      "Loss: tensor(0.1372, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 94\n",
      "Loss: tensor(0.1372, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 95\n",
      "Loss: tensor(0.1372, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 96\n",
      "Loss: tensor(0.1372, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 97\n",
      "Loss: tensor(0.1372, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 98\n",
      "Loss: tensor(0.1371, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 99\n",
      "Loss: tensor(0.1371, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 100\n",
      "Loss: tensor(0.1371, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 101\n",
      "Loss: tensor(0.1371, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 102\n",
      "Loss: tensor(0.1371, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 103\n",
      "Loss: tensor(0.1371, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 104\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor(0.1371, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 105\n",
      "Loss: tensor(0.1371, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 106\n",
      "Loss: tensor(0.1371, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 107\n",
      "Loss: tensor(0.1371, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 108\n",
      "Loss: tensor(0.1370, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 109\n",
      "Loss: tensor(0.1370, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 110\n",
      "Loss: tensor(0.1370, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 111\n",
      "Loss: tensor(0.1370, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 112\n",
      "Loss: tensor(0.1370, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 113\n",
      "Loss: tensor(0.1370, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 114\n",
      "Loss: tensor(0.1370, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 115\n",
      "Loss: tensor(0.1370, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 116\n",
      "Loss: tensor(0.1370, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 117\n",
      "Loss: tensor(0.1370, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 118\n",
      "Loss: tensor(0.1369, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 119\n",
      "Loss: tensor(0.1369, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 120\n",
      "Loss: tensor(0.1369, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 121\n",
      "Loss: tensor(0.1369, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 122\n",
      "Loss: tensor(0.1369, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 123\n",
      "Loss: tensor(0.1369, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 124\n",
      "Loss: tensor(0.1369, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 125\n",
      "Loss: tensor(0.1369, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 126\n",
      "Loss: tensor(0.1369, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 127\n",
      "Loss: tensor(0.1369, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 128\n",
      "Loss: tensor(0.1369, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 129\n",
      "Loss: tensor(0.1368, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 130\n",
      "Loss: tensor(0.1368, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 131\n",
      "Loss: tensor(0.1368, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 132\n",
      "Loss: tensor(0.1368, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 133\n",
      "Loss: tensor(0.1368, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 134\n",
      "Loss: tensor(0.1368, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 135\n",
      "Loss: tensor(0.1368, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 136\n",
      "Loss: tensor(0.1368, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 137\n",
      "Loss: tensor(0.1368, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 138\n",
      "Loss: tensor(0.1368, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 139\n",
      "Loss: tensor(0.1368, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 140\n",
      "Loss: tensor(0.1367, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 141\n",
      "Loss: tensor(0.1367, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 142\n",
      "Loss: tensor(0.1367, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 143\n",
      "Loss: tensor(0.1367, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 144\n",
      "Loss: tensor(0.1367, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 145\n",
      "Loss: tensor(0.1367, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 146\n",
      "Loss: tensor(0.1367, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 147\n",
      "Loss: tensor(0.1367, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 148\n",
      "Loss: tensor(0.1367, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 149\n",
      "Loss: tensor(0.1367, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 150\n",
      "Loss: tensor(0.1367, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 151\n",
      "Loss: tensor(0.1366, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 152\n",
      "Loss: tensor(0.1366, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 153\n",
      "Loss: tensor(0.1366, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 154\n",
      "Loss: tensor(0.1366, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 155\n",
      "Loss: tensor(0.1366, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 156\n",
      "Loss: tensor(0.1366, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 157\n",
      "Loss: tensor(0.1366, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 158\n",
      "Loss: tensor(0.1366, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 159\n",
      "Loss: tensor(0.1366, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 160\n",
      "Loss: tensor(0.1366, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 161\n",
      "Loss: tensor(0.1366, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 162\n",
      "Loss: tensor(0.1366, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 163\n",
      "Loss: tensor(0.1365, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 164\n",
      "Loss: tensor(0.1365, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 165\n",
      "Loss: tensor(0.1365, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 166\n",
      "Loss: tensor(0.1365, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 167\n",
      "Loss: tensor(0.1365, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 168\n",
      "Loss: tensor(0.1365, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 169\n",
      "Loss: tensor(0.1365, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 170\n",
      "Loss: tensor(0.1365, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 171\n",
      "Loss: tensor(0.1365, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 172\n",
      "Loss: tensor(0.1365, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 173\n",
      "Loss: tensor(0.1365, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 174\n",
      "Loss: tensor(0.1365, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 175\n",
      "Loss: tensor(0.1364, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 176\n",
      "Loss: tensor(0.1364, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 177\n",
      "Loss: tensor(0.1364, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 178\n",
      "Loss: tensor(0.1364, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 179\n",
      "Loss: tensor(0.1364, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 180\n",
      "Loss: tensor(0.1364, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 181\n",
      "Loss: tensor(0.1364, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 182\n",
      "Loss: tensor(0.1364, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 183\n",
      "Loss: tensor(0.1364, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 184\n",
      "Loss: tensor(0.1364, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 185\n",
      "Loss: tensor(0.1364, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 186\n",
      "Loss: tensor(0.1364, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 187\n",
      "Loss: tensor(0.1363, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 188\n",
      "Loss: tensor(0.1363, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 189\n",
      "Loss: tensor(0.1363, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 190\n",
      "Loss: tensor(0.1363, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 191\n",
      "Loss: tensor(0.1363, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 192\n",
      "Loss: tensor(0.1363, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 193\n",
      "Loss: tensor(0.1363, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 194\n",
      "Loss: tensor(0.1363, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 195\n",
      "Loss: tensor(0.1363, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 196\n",
      "Loss: tensor(0.1363, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 197\n",
      "Loss: tensor(0.1363, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 198\n",
      "Loss: tensor(0.1363, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 199\n",
      "Loss: tensor(0.1362, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 200\n",
      "Loss: tensor(0.1362, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 201\n",
      "Loss: tensor(0.1362, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 202\n",
      "Loss: tensor(0.1362, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 203\n",
      "Loss: tensor(0.1362, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 204\n",
      "Loss: tensor(0.1362, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 205\n",
      "Loss: tensor(0.1362, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 206\n",
      "Loss: tensor(0.1362, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 207\n",
      "Loss: tensor(0.1362, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 208\n",
      "Loss: tensor(0.1362, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 209\n",
      "Loss: tensor(0.1362, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 210\n",
      "Loss: tensor(0.1362, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 211\n",
      "Loss: tensor(0.1362, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 212\n",
      "Loss: tensor(0.1361, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 213\n",
      "Loss: tensor(0.1361, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 214\n",
      "Loss: tensor(0.1361, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 215\n",
      "Loss: tensor(0.1361, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 216\n",
      "Loss: tensor(0.1361, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 217\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor(0.1361, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 218\n",
      "Loss: tensor(0.1361, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 219\n",
      "Loss: tensor(0.1361, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 220\n",
      "Loss: tensor(0.1361, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 221\n",
      "Loss: tensor(0.1361, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 222\n",
      "Loss: tensor(0.1361, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 223\n",
      "Loss: tensor(0.1361, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 224\n",
      "Loss: tensor(0.1361, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 225\n",
      "Loss: tensor(0.1361, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 226\n",
      "Loss: tensor(0.1360, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 227\n",
      "Loss: tensor(0.1360, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 228\n",
      "Loss: tensor(0.1360, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 229\n",
      "Loss: tensor(0.1360, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 230\n",
      "Loss: tensor(0.1360, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 231\n",
      "Loss: tensor(0.1360, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 232\n",
      "Loss: tensor(0.1360, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 233\n",
      "Loss: tensor(0.1360, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 234\n",
      "Loss: tensor(0.1360, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 235\n",
      "Loss: tensor(0.1360, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 236\n",
      "Loss: tensor(0.1360, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 237\n",
      "Loss: tensor(0.1360, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 238\n",
      "Loss: tensor(0.1360, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 239\n",
      "Loss: tensor(0.1360, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 240\n",
      "Loss: tensor(0.1360, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 241\n",
      "Loss: tensor(0.1360, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 242\n",
      "Loss: tensor(0.1359, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 243\n",
      "Loss: tensor(0.1359, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 244\n",
      "Loss: tensor(0.1359, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 245\n",
      "Loss: tensor(0.1359, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 246\n",
      "Loss: tensor(0.1359, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 247\n",
      "Loss: tensor(0.1359, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 248\n",
      "Loss: tensor(0.1359, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 249\n",
      "Loss: tensor(0.1359, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 250\n",
      "Loss: tensor(0.1359, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 251\n",
      "Loss: tensor(0.1359, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 252\n",
      "Loss: tensor(0.1359, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 253\n",
      "Loss: tensor(0.1359, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 254\n",
      "Loss: tensor(0.1359, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 255\n",
      "Loss: tensor(0.1359, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 256\n",
      "Loss: tensor(0.1359, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 257\n",
      "Loss: tensor(0.1359, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 258\n",
      "Loss: tensor(0.1359, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 259\n",
      "Loss: tensor(0.1359, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 260\n",
      "Loss: tensor(0.1358, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 261\n",
      "Loss: tensor(0.1358, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 262\n",
      "Loss: tensor(0.1358, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 263\n",
      "Loss: tensor(0.1358, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 264\n",
      "Loss: tensor(0.1358, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 265\n",
      "Loss: tensor(0.1358, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 266\n",
      "Loss: tensor(0.1358, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 267\n",
      "Loss: tensor(0.1358, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 268\n",
      "Loss: tensor(0.1358, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 269\n",
      "Loss: tensor(0.1358, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 270\n",
      "Loss: tensor(0.1358, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 271\n",
      "Loss: tensor(0.1358, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 272\n",
      "Loss: tensor(0.1358, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 273\n",
      "Loss: tensor(0.1358, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 274\n",
      "Loss: tensor(0.1358, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 275\n",
      "Loss: tensor(0.1358, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 276\n",
      "Loss: tensor(0.1358, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 277\n",
      "Loss: tensor(0.1358, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 278\n",
      "Loss: tensor(0.1358, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 279\n",
      "Loss: tensor(0.1358, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 280\n",
      "Loss: tensor(0.1358, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 281\n",
      "Loss: tensor(0.1358, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 282\n",
      "Loss: tensor(0.1358, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 283\n",
      "Loss: tensor(0.1357, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 284\n",
      "Loss: tensor(0.1357, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 285\n",
      "Loss: tensor(0.1357, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 286\n",
      "Loss: tensor(0.1357, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 287\n",
      "Loss: tensor(0.1357, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 288\n",
      "Loss: tensor(0.1357, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 289\n",
      "Loss: tensor(0.1357, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 290\n",
      "Loss: tensor(0.1357, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 291\n",
      "Loss: tensor(0.1357, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 292\n",
      "Loss: tensor(0.1357, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 293\n",
      "Loss: tensor(0.1357, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 294\n",
      "Loss: tensor(0.1357, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 295\n",
      "Loss: tensor(0.1357, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 296\n",
      "Loss: tensor(0.1357, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 297\n",
      "Loss: tensor(0.1357, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 298\n",
      "Loss: tensor(0.1357, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 299\n",
      "Loss: tensor(0.1357, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 300\n",
      "Loss: tensor(0.1357, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 301\n",
      "Loss: tensor(0.1357, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 302\n",
      "Loss: tensor(0.1357, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 303\n",
      "Loss: tensor(0.1357, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 304\n",
      "Loss: tensor(0.1357, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 305\n",
      "Loss: tensor(0.1357, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 306\n",
      "Loss: tensor(0.1357, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 307\n",
      "Loss: tensor(0.1357, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 308\n",
      "Loss: tensor(0.1357, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 309\n",
      "Loss: tensor(0.1357, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 310\n",
      "Loss: tensor(0.1357, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 311\n",
      "Loss: tensor(0.1357, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 312\n",
      "Loss: tensor(0.1357, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 313\n",
      "Loss: tensor(0.1357, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 314\n",
      "Loss: tensor(0.1357, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 315\n",
      "Loss: tensor(0.1356, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 316\n",
      "Loss: tensor(0.1356, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 317\n",
      "Loss: tensor(0.1356, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 318\n",
      "Loss: tensor(0.1356, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 319\n",
      "Loss: tensor(0.1356, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 320\n",
      "Loss: tensor(0.1356, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 321\n",
      "Loss: tensor(0.1356, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 322\n",
      "Loss: tensor(0.1356, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 323\n",
      "Loss: tensor(0.1356, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 324\n",
      "Loss: tensor(0.1356, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 325\n",
      "Loss: tensor(0.1356, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 326\n",
      "Loss: tensor(0.1356, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 327\n",
      "Loss: tensor(0.1356, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 328\n",
      "Loss: tensor(0.1356, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 329\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor(0.1356, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 330\n",
      "Loss: tensor(0.1356, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 331\n",
      "Loss: tensor(0.1356, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 332\n",
      "Loss: tensor(0.1356, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 333\n",
      "Loss: tensor(0.1356, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 334\n",
      "Loss: tensor(0.1356, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 335\n",
      "Loss: tensor(0.1356, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 336\n",
      "Loss: tensor(0.1356, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 337\n",
      "Loss: tensor(0.1356, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 338\n",
      "Loss: tensor(0.1356, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 339\n",
      "Loss: tensor(0.1356, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 340\n",
      "Loss: tensor(0.1356, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 341\n",
      "Loss: tensor(0.1356, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 342\n",
      "Loss: tensor(0.1356, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 343\n",
      "Loss: tensor(0.1356, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 344\n",
      "Loss: tensor(0.1356, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 345\n",
      "Loss: tensor(0.1356, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 346\n",
      "Loss: tensor(0.1356, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 347\n",
      "Loss: tensor(0.1356, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 348\n",
      "Loss: tensor(0.1356, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 349\n",
      "Loss: tensor(0.1356, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 350\n",
      "Loss: tensor(0.1356, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 351\n",
      "Loss: tensor(0.1356, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 352\n",
      "Loss: tensor(0.1356, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 353\n",
      "Loss: tensor(0.1356, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 354\n",
      "Loss: tensor(0.1356, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 355\n",
      "Loss: tensor(0.1356, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 356\n",
      "Loss: tensor(0.1356, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 357\n",
      "Loss: tensor(0.1355, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 358\n",
      "Loss: tensor(0.1355, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 359\n",
      "Loss: tensor(0.1355, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 360\n",
      "Loss: tensor(0.1355, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 361\n",
      "Loss: tensor(0.1355, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 362\n",
      "Loss: tensor(0.1355, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 363\n",
      "Loss: tensor(0.1355, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 364\n",
      "Loss: tensor(0.1355, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 365\n",
      "Loss: tensor(0.1355, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 366\n",
      "Loss: tensor(0.1355, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 367\n",
      "Loss: tensor(0.1355, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 368\n",
      "Loss: tensor(0.1355, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 369\n",
      "Loss: tensor(0.1355, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 370\n",
      "Loss: tensor(0.1355, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 371\n",
      "Loss: tensor(0.1355, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 372\n",
      "Loss: tensor(0.1355, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 373\n",
      "Loss: tensor(0.1355, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 374\n",
      "Loss: tensor(0.1355, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 375\n",
      "Loss: tensor(0.1355, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 376\n",
      "Loss: tensor(0.1355, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 377\n",
      "Loss: tensor(0.1355, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 378\n",
      "Loss: tensor(0.1355, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 379\n",
      "Loss: tensor(0.1355, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 380\n",
      "Loss: tensor(0.1355, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 381\n",
      "Loss: tensor(0.1355, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 382\n",
      "Loss: tensor(0.1355, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 383\n",
      "Loss: tensor(0.1355, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 384\n",
      "Loss: tensor(0.1355, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 385\n",
      "Loss: tensor(0.1355, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 386\n",
      "Loss: tensor(0.1355, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 387\n",
      "Loss: tensor(0.1355, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 388\n",
      "Loss: tensor(0.1355, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 389\n",
      "Loss: tensor(0.1355, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 390\n",
      "Loss: tensor(0.1355, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 391\n",
      "Loss: tensor(0.1355, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 392\n",
      "Loss: tensor(0.1355, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 393\n",
      "Loss: tensor(0.1355, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 394\n",
      "Loss: tensor(0.1355, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 395\n",
      "Loss: tensor(0.1355, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 396\n",
      "Loss: tensor(0.1355, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 397\n",
      "Loss: tensor(0.1355, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 398\n",
      "Loss: tensor(0.1355, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 399\n",
      "Loss: tensor(0.1355, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 400\n",
      "Loss: tensor(0.1355, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 401\n",
      "Loss: tensor(0.1355, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 402\n",
      "Loss: tensor(0.1355, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 403\n",
      "Loss: tensor(0.1355, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 404\n",
      "Loss: tensor(0.1355, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 405\n",
      "Loss: tensor(0.1355, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 406\n",
      "Loss: tensor(0.1355, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 407\n",
      "Loss: tensor(0.1354, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 408\n",
      "Loss: tensor(0.1354, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 409\n",
      "Loss: tensor(0.1354, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 410\n",
      "Loss: tensor(0.1354, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 411\n",
      "Loss: tensor(0.1354, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 412\n",
      "Loss: tensor(0.1354, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 413\n",
      "Loss: tensor(0.1354, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 414\n",
      "Loss: tensor(0.1354, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 415\n",
      "Loss: tensor(0.1354, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 416\n",
      "Loss: tensor(0.1354, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 417\n",
      "Loss: tensor(0.1354, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 418\n",
      "Loss: tensor(0.1354, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 419\n",
      "Loss: tensor(0.1354, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 420\n",
      "Loss: tensor(0.1354, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 421\n",
      "Loss: tensor(0.1354, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 422\n",
      "Loss: tensor(0.1354, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 423\n",
      "Loss: tensor(0.1354, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 424\n",
      "Loss: tensor(0.1354, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 425\n",
      "Loss: tensor(0.1354, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 426\n",
      "Loss: tensor(0.1354, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 427\n",
      "Loss: tensor(0.1354, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 428\n",
      "Loss: tensor(0.1354, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 429\n",
      "Loss: tensor(0.1354, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 430\n",
      "Loss: tensor(0.1354, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 431\n",
      "Loss: tensor(0.1354, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 432\n",
      "Loss: tensor(0.1354, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 433\n",
      "Loss: tensor(0.1354, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 434\n",
      "Loss: tensor(0.1354, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 435\n",
      "Loss: tensor(0.1354, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 436\n",
      "Loss: tensor(0.1354, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 437\n",
      "Loss: tensor(0.1354, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 438\n",
      "Loss: tensor(0.1354, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 439\n",
      "Loss: tensor(0.1354, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 440\n",
      "Loss: tensor(0.1354, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 441\n",
      "Loss: tensor(0.1354, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 442\n",
      "Loss: tensor(0.1354, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 443\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor(0.1354, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 444\n",
      "Loss: tensor(0.1354, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 445\n",
      "Loss: tensor(0.1354, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 446\n",
      "Loss: tensor(0.1354, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 447\n",
      "Loss: tensor(0.1354, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 448\n",
      "Loss: tensor(0.1354, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 449\n",
      "Loss: tensor(0.1354, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 450\n",
      "Loss: tensor(0.1354, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 451\n",
      "Loss: tensor(0.1354, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 452\n",
      "Loss: tensor(0.1354, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 453\n",
      "Loss: tensor(0.1354, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 454\n",
      "Loss: tensor(0.1354, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 455\n",
      "Loss: tensor(0.1354, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 456\n",
      "Loss: tensor(0.1354, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 457\n",
      "Loss: tensor(0.1354, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 458\n",
      "Loss: tensor(0.1353, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 459\n",
      "Loss: tensor(0.1353, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 460\n",
      "Loss: tensor(0.1353, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 461\n",
      "Loss: tensor(0.1353, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 462\n",
      "Loss: tensor(0.1353, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 463\n",
      "Loss: tensor(0.1353, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 464\n",
      "Loss: tensor(0.1353, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 465\n",
      "Loss: tensor(0.1353, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 466\n",
      "Loss: tensor(0.1353, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 467\n",
      "Loss: tensor(0.1353, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 468\n",
      "Loss: tensor(0.1353, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 469\n",
      "Loss: tensor(0.1353, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 470\n",
      "Loss: tensor(0.1353, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 471\n",
      "Loss: tensor(0.1353, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 472\n",
      "Loss: tensor(0.1353, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 473\n",
      "Loss: tensor(0.1353, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 474\n",
      "Loss: tensor(0.1353, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 475\n",
      "Loss: tensor(0.1353, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 476\n",
      "Loss: tensor(0.1353, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 477\n",
      "Loss: tensor(0.1353, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 478\n",
      "Loss: tensor(0.1353, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 479\n",
      "Loss: tensor(0.1353, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 480\n",
      "Loss: tensor(0.1353, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 481\n",
      "Loss: tensor(0.1353, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 482\n",
      "Loss: tensor(0.1353, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 483\n",
      "Loss: tensor(0.1353, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 484\n",
      "Loss: tensor(0.1353, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 485\n",
      "Loss: tensor(0.1353, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 486\n",
      "Loss: tensor(0.1353, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 487\n",
      "Loss: tensor(0.1353, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 488\n",
      "Loss: tensor(0.1353, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 489\n",
      "Loss: tensor(0.1353, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 490\n",
      "Loss: tensor(0.1353, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 491\n",
      "Loss: tensor(0.1353, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 492\n",
      "Loss: tensor(0.1353, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 493\n",
      "Loss: tensor(0.1353, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 494\n",
      "Loss: tensor(0.1353, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 495\n",
      "Loss: tensor(0.1353, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 496\n",
      "Loss: tensor(0.1353, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 497\n",
      "Loss: tensor(0.1353, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 498\n",
      "Loss: tensor(0.1353, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 499\n",
      "Loss: tensor(0.1353, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 500\n",
      "Loss: tensor(0.1353, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 501\n",
      "Loss: tensor(0.1353, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 502\n",
      "Loss: tensor(0.1353, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 503\n",
      "Loss: tensor(0.1353, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 504\n",
      "Loss: tensor(0.1353, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 505\n",
      "Loss: tensor(0.1353, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 506\n",
      "Loss: tensor(0.1353, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 507\n",
      "Loss: tensor(0.1353, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 508\n",
      "Loss: tensor(0.1352, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 509\n",
      "Loss: tensor(0.1352, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 510\n",
      "Loss: tensor(0.1352, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 511\n",
      "Loss: tensor(0.1352, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 512\n",
      "Loss: tensor(0.1352, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 513\n",
      "Loss: tensor(0.1352, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 514\n",
      "Loss: tensor(0.1352, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 515\n",
      "Loss: tensor(0.1352, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 516\n",
      "Loss: tensor(0.1352, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 517\n",
      "Loss: tensor(0.1352, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 518\n",
      "Loss: tensor(0.1352, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 519\n",
      "Loss: tensor(0.1352, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 520\n",
      "Loss: tensor(0.1352, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 521\n",
      "Loss: tensor(0.1352, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 522\n",
      "Loss: tensor(0.1352, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 523\n",
      "Loss: tensor(0.1352, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 524\n",
      "Loss: tensor(0.1352, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 525\n",
      "Loss: tensor(0.1352, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 526\n",
      "Loss: tensor(0.1352, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 527\n",
      "Loss: tensor(0.1352, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 528\n",
      "Loss: tensor(0.1352, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 529\n",
      "Loss: tensor(0.1352, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 530\n",
      "Loss: tensor(0.1352, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 531\n",
      "Loss: tensor(0.1352, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 532\n",
      "Loss: tensor(0.1352, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 533\n",
      "Loss: tensor(0.1352, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 534\n",
      "Loss: tensor(0.1352, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 535\n",
      "Loss: tensor(0.1352, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 536\n",
      "Loss: tensor(0.1352, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 537\n",
      "Loss: tensor(0.1352, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 538\n",
      "Loss: tensor(0.1352, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 539\n",
      "Loss: tensor(0.1352, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 540\n",
      "Loss: tensor(0.1352, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 541\n",
      "Loss: tensor(0.1352, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 542\n",
      "Loss: tensor(0.1352, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 543\n",
      "Loss: tensor(0.1352, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 544\n",
      "Loss: tensor(0.1352, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 545\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor(0.1352, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 546\n",
      "Loss: tensor(0.1352, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 547\n",
      "Loss: tensor(0.1352, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 548\n",
      "Loss: tensor(0.1352, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 549\n",
      "Loss: tensor(0.1352, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 550\n",
      "Loss: tensor(0.1352, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 551\n",
      "Loss: tensor(0.1352, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 552\n",
      "Loss: tensor(0.1352, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 553\n",
      "Loss: tensor(0.1352, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 554\n",
      "Loss: tensor(0.1352, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 555\n",
      "Loss: tensor(0.1352, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 556\n",
      "Loss: tensor(0.1351, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 557\n",
      "Loss: tensor(0.1351, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 558\n",
      "Loss: tensor(0.1351, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 559\n",
      "Loss: tensor(0.1351, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 560\n",
      "Loss: tensor(0.1351, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 561\n",
      "Loss: tensor(0.1351, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 562\n",
      "Loss: tensor(0.1351, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 563\n",
      "Loss: tensor(0.1351, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 564\n",
      "Loss: tensor(0.1351, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 565\n",
      "Loss: tensor(0.1351, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 566\n",
      "Loss: tensor(0.1351, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 567\n",
      "Loss: tensor(0.1351, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 568\n",
      "Loss: tensor(0.1351, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 569\n",
      "Loss: tensor(0.1351, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 570\n",
      "Loss: tensor(0.1351, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 571\n",
      "Loss: tensor(0.1351, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 572\n",
      "Loss: tensor(0.1351, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 573\n",
      "Loss: tensor(0.1351, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 574\n",
      "Loss: tensor(0.1351, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 575\n",
      "Loss: tensor(0.1351, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 576\n",
      "Loss: tensor(0.1351, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 577\n",
      "Loss: tensor(0.1351, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 578\n",
      "Loss: tensor(0.1351, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 579\n",
      "Loss: tensor(0.1351, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 580\n",
      "Loss: tensor(0.1351, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 581\n",
      "Loss: tensor(0.1351, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 582\n",
      "Loss: tensor(0.1351, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 583\n",
      "Loss: tensor(0.1351, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 584\n",
      "Loss: tensor(0.1351, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 585\n",
      "Loss: tensor(0.1351, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 586\n",
      "Loss: tensor(0.1351, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 587\n",
      "Loss: tensor(0.1351, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 588\n",
      "Loss: tensor(0.1351, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 589\n",
      "Loss: tensor(0.1351, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 590\n",
      "Loss: tensor(0.1351, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 591\n",
      "Loss: tensor(0.1351, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 592\n",
      "Loss: tensor(0.1351, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 593\n",
      "Loss: tensor(0.1351, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 594\n",
      "Loss: tensor(0.1351, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 595\n",
      "Loss: tensor(0.1351, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 596\n",
      "Loss: tensor(0.1351, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 597\n",
      "Loss: tensor(0.1351, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 598\n",
      "Loss: tensor(0.1351, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 599\n",
      "Loss: tensor(0.1351, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 600\n",
      "Loss: tensor(0.1351, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 601\n",
      "Loss: tensor(0.1351, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 602\n",
      "Loss: tensor(0.1351, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 603\n",
      "Loss: tensor(0.1351, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 604\n",
      "Loss: tensor(0.1351, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 605\n",
      "Loss: tensor(0.1350, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 606\n",
      "Loss: tensor(0.1350, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 607\n",
      "Loss: tensor(0.1350, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 608\n",
      "Loss: tensor(0.1350, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 609\n",
      "Loss: tensor(0.1350, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 610\n",
      "Loss: tensor(0.1350, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 611\n",
      "Loss: tensor(0.1350, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 612\n",
      "Loss: tensor(0.1350, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 613\n",
      "Loss: tensor(0.1350, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 614\n",
      "Loss: tensor(0.1350, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 615\n",
      "Loss: tensor(0.1350, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 616\n",
      "Loss: tensor(0.1350, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 617\n",
      "Loss: tensor(0.1350, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 618\n",
      "Loss: tensor(0.1350, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 619\n",
      "Loss: tensor(0.1350, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 620\n",
      "Loss: tensor(0.1350, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 621\n",
      "Loss: tensor(0.1350, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 622\n",
      "Loss: tensor(0.1350, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 623\n",
      "Loss: tensor(0.1350, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 624\n",
      "Loss: tensor(0.1350, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 625\n",
      "Loss: tensor(0.1350, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 626\n",
      "Loss: tensor(0.1350, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 627\n",
      "Loss: tensor(0.1350, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 628\n",
      "Loss: tensor(0.1350, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 629\n",
      "Loss: tensor(0.1350, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 630\n",
      "Loss: tensor(0.1350, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 631\n",
      "Loss: tensor(0.1350, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 632\n",
      "Loss: tensor(0.1350, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 633\n",
      "Loss: tensor(0.1350, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 634\n",
      "Loss: tensor(0.1350, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 635\n",
      "Loss: tensor(0.1350, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 636\n",
      "Loss: tensor(0.1350, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 637\n",
      "Loss: tensor(0.1350, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 638\n",
      "Loss: tensor(0.1350, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 639\n",
      "Loss: tensor(0.1350, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 640\n",
      "Loss: tensor(0.1350, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 641\n",
      "Loss: tensor(0.1350, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 642\n",
      "Loss: tensor(0.1350, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 643\n",
      "Loss: tensor(0.1350, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 644\n",
      "Loss: tensor(0.1350, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 645\n",
      "Loss: tensor(0.1350, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 646\n",
      "Loss: tensor(0.1350, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 647\n",
      "Loss: tensor(0.1350, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 648\n",
      "Loss: tensor(0.1350, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 649\n",
      "Loss: tensor(0.1350, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 650\n",
      "Loss: tensor(0.1350, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 651\n",
      "Loss: tensor(0.1350, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 652\n",
      "Loss: tensor(0.1350, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 653\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor(0.1350, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 654\n",
      "Loss: tensor(0.1350, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 655\n",
      "Loss: tensor(0.1350, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 656\n",
      "Loss: tensor(0.1350, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 657\n",
      "Loss: tensor(0.1349, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 658\n",
      "Loss: tensor(0.1349, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 659\n",
      "Loss: tensor(0.1349, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 660\n",
      "Loss: tensor(0.1349, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 661\n",
      "Loss: tensor(0.1349, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 662\n",
      "Loss: tensor(0.1349, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 663\n",
      "Loss: tensor(0.1349, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 664\n",
      "Loss: tensor(0.1349, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 665\n",
      "Loss: tensor(0.1349, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 666\n",
      "Loss: tensor(0.1349, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 667\n",
      "Loss: tensor(0.1349, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 668\n",
      "Loss: tensor(0.1349, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 669\n",
      "Loss: tensor(0.1349, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 670\n",
      "Loss: tensor(0.1349, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 671\n",
      "Loss: tensor(0.1349, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 672\n",
      "Loss: tensor(0.1349, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 673\n",
      "Loss: tensor(0.1349, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 674\n",
      "Loss: tensor(0.1349, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 675\n",
      "Loss: tensor(0.1349, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 676\n",
      "Loss: tensor(0.1349, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 677\n",
      "Loss: tensor(0.1349, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 678\n",
      "Loss: tensor(0.1349, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 679\n",
      "Loss: tensor(0.1349, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 680\n",
      "Loss: tensor(0.1349, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 681\n",
      "Loss: tensor(0.1349, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 682\n",
      "Loss: tensor(0.1349, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 683\n",
      "Loss: tensor(0.1349, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 684\n",
      "Loss: tensor(0.1349, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 685\n",
      "Loss: tensor(0.1349, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 686\n",
      "Loss: tensor(0.1349, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 687\n",
      "Loss: tensor(0.1349, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 688\n",
      "Loss: tensor(0.1349, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 689\n",
      "Loss: tensor(0.1349, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 690\n",
      "Loss: tensor(0.1349, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 691\n",
      "Loss: tensor(0.1349, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 692\n",
      "Loss: tensor(0.1349, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 693\n",
      "Loss: tensor(0.1349, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 694\n",
      "Loss: tensor(0.1349, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 695\n",
      "Loss: tensor(0.1349, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 696\n",
      "Loss: tensor(0.1349, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 697\n",
      "Loss: tensor(0.1349, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 698\n",
      "Loss: tensor(0.1349, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 699\n",
      "Loss: tensor(0.1349, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 700\n",
      "Loss: tensor(0.1349, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 701\n",
      "Loss: tensor(0.1349, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 702\n",
      "Loss: tensor(0.1349, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 703\n",
      "Loss: tensor(0.1349, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 704\n",
      "Loss: tensor(0.1349, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 705\n",
      "Loss: tensor(0.1349, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 706\n",
      "Loss: tensor(0.1349, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 707\n",
      "Loss: tensor(0.1349, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 708\n",
      "Loss: tensor(0.1349, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 709\n",
      "Loss: tensor(0.1349, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 710\n",
      "Loss: tensor(0.1349, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 711\n",
      "Loss: tensor(0.1349, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 712\n",
      "Loss: tensor(0.1349, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 713\n",
      "Loss: tensor(0.1349, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 714\n",
      "Loss: tensor(0.1349, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 715\n",
      "Loss: tensor(0.1348, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 716\n",
      "Loss: tensor(0.1348, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 717\n",
      "Loss: tensor(0.1348, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 718\n",
      "Loss: tensor(0.1348, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 719\n",
      "Loss: tensor(0.1348, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 720\n",
      "Loss: tensor(0.1348, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 721\n",
      "Loss: tensor(0.1348, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 722\n",
      "Loss: tensor(0.1348, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 723\n",
      "Loss: tensor(0.1348, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 724\n",
      "Loss: tensor(0.1348, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 725\n",
      "Loss: tensor(0.1348, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 726\n",
      "Loss: tensor(0.1348, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 727\n",
      "Loss: tensor(0.1348, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 728\n",
      "Loss: tensor(0.1348, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 729\n",
      "Loss: tensor(0.1348, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 730\n",
      "Loss: tensor(0.1348, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 731\n",
      "Loss: tensor(0.1348, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 732\n",
      "Loss: tensor(0.1348, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 733\n",
      "Loss: tensor(0.1348, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 734\n",
      "Loss: tensor(0.1348, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 735\n",
      "Loss: tensor(0.1348, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 736\n",
      "Loss: tensor(0.1348, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 737\n",
      "Loss: tensor(0.1348, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 738\n",
      "Loss: tensor(0.1348, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 739\n",
      "Loss: tensor(0.1348, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 740\n",
      "Loss: tensor(0.1348, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 741\n",
      "Loss: tensor(0.1348, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 742\n",
      "Loss: tensor(0.1348, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 743\n",
      "Loss: tensor(0.1348, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 744\n",
      "Loss: tensor(0.1348, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 745\n",
      "Loss: tensor(0.1348, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 746\n",
      "Loss: tensor(0.1348, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 747\n",
      "Loss: tensor(0.1348, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 748\n",
      "Loss: tensor(0.1348, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 749\n",
      "Loss: tensor(0.1348, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 750\n",
      "Loss: tensor(0.1348, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 751\n",
      "Loss: tensor(0.1348, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 752\n",
      "Loss: tensor(0.1348, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 753\n",
      "Loss: tensor(0.1348, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 754\n",
      "Loss: tensor(0.1348, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 755\n",
      "Loss: tensor(0.1348, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 756\n",
      "Loss: tensor(0.1348, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 757\n",
      "Loss: tensor(0.1348, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 758\n",
      "Loss: tensor(0.1348, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 759\n",
      "Loss: tensor(0.1348, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 760\n",
      "Loss: tensor(0.1348, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 761\n",
      "Loss: tensor(0.1348, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 762\n",
      "Loss: tensor(0.1348, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 763\n",
      "Loss: tensor(0.1348, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 764\n",
      "Loss: tensor(0.1348, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 765\n",
      "Loss: tensor(0.1348, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 766\n",
      "Loss: tensor(0.1348, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 767\n",
      "Loss: tensor(0.1348, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 768\n",
      "Loss: tensor(0.1348, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 769\n",
      "Loss: tensor(0.1348, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 770\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor(0.1348, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 771\n",
      "Loss: tensor(0.1348, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 772\n",
      "Loss: tensor(0.1348, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 773\n",
      "Loss: tensor(0.1348, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 774\n",
      "Loss: tensor(0.1348, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 775\n",
      "Loss: tensor(0.1348, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 776\n",
      "Loss: tensor(0.1348, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 777\n",
      "Loss: tensor(0.1348, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 778\n",
      "Loss: tensor(0.1348, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 779\n",
      "Loss: tensor(0.1348, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 780\n",
      "Loss: tensor(0.1348, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 781\n",
      "Loss: tensor(0.1347, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 782\n",
      "Loss: tensor(0.1347, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 783\n",
      "Loss: tensor(0.1347, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 784\n",
      "Loss: tensor(0.1347, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 785\n",
      "Loss: tensor(0.1347, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 786\n",
      "Loss: tensor(0.1347, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 787\n",
      "Loss: tensor(0.1347, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 788\n",
      "Loss: tensor(0.1347, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 789\n",
      "Loss: tensor(0.1347, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 790\n",
      "Loss: tensor(0.1347, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 791\n",
      "Loss: tensor(0.1347, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 792\n",
      "Loss: tensor(0.1347, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 793\n",
      "Loss: tensor(0.1347, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 794\n",
      "Loss: tensor(0.1347, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 795\n",
      "Loss: tensor(0.1347, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 796\n",
      "Loss: tensor(0.1347, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 797\n",
      "Loss: tensor(0.1347, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 798\n",
      "Loss: tensor(0.1347, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 799\n",
      "Loss: tensor(0.1347, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 800\n",
      "Loss: tensor(0.1347, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 801\n",
      "Loss: tensor(0.1347, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 802\n",
      "Loss: tensor(0.1347, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 803\n",
      "Loss: tensor(0.1347, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 804\n",
      "Loss: tensor(0.1347, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 805\n",
      "Loss: tensor(0.1347, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 806\n",
      "Loss: tensor(0.1347, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 807\n",
      "Loss: tensor(0.1347, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 808\n",
      "Loss: tensor(0.1347, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 809\n",
      "Loss: tensor(0.1347, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 810\n",
      "Loss: tensor(0.1347, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 811\n",
      "Loss: tensor(0.1347, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 812\n",
      "Loss: tensor(0.1347, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 813\n",
      "Loss: tensor(0.1347, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 814\n",
      "Loss: tensor(0.1347, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 815\n",
      "Loss: tensor(0.1347, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 816\n",
      "Loss: tensor(0.1347, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 817\n",
      "Loss: tensor(0.1347, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 818\n",
      "Loss: tensor(0.1347, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 819\n",
      "Loss: tensor(0.1347, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 820\n",
      "Loss: tensor(0.1347, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 821\n",
      "Loss: tensor(0.1347, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 822\n",
      "Loss: tensor(0.1347, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 823\n",
      "Loss: tensor(0.1347, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 824\n",
      "Loss: tensor(0.1347, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 825\n",
      "Loss: tensor(0.1347, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 826\n",
      "Loss: tensor(0.1347, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 827\n",
      "Loss: tensor(0.1347, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 828\n",
      "Loss: tensor(0.1347, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 829\n",
      "Loss: tensor(0.1347, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 830\n",
      "Loss: tensor(0.1347, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 831\n",
      "Loss: tensor(0.1347, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 832\n",
      "Loss: tensor(0.1347, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 833\n",
      "Loss: tensor(0.1347, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 834\n",
      "Loss: tensor(0.1347, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 835\n",
      "Loss: tensor(0.1347, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 836\n",
      "Loss: tensor(0.1347, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 837\n",
      "Loss: tensor(0.1347, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 838\n",
      "Loss: tensor(0.1347, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 839\n",
      "Loss: tensor(0.1347, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 840\n",
      "Loss: tensor(0.1347, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 841\n",
      "Loss: tensor(0.1347, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 842\n",
      "Loss: tensor(0.1347, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 843\n",
      "Loss: tensor(0.1347, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 844\n",
      "Loss: tensor(0.1347, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 845\n",
      "Loss: tensor(0.1347, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 846\n",
      "Loss: tensor(0.1347, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 847\n",
      "Loss: tensor(0.1346, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 848\n",
      "Loss: tensor(0.1346, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 849\n",
      "Loss: tensor(0.1346, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 850\n",
      "Loss: tensor(0.1346, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 851\n",
      "Loss: tensor(0.1346, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 852\n",
      "Loss: tensor(0.1346, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 853\n",
      "Loss: tensor(0.1346, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 854\n",
      "Loss: tensor(0.1346, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 855\n",
      "Loss: tensor(0.1346, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 856\n",
      "Loss: tensor(0.1346, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 857\n",
      "Loss: tensor(0.1346, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 858\n",
      "Loss: tensor(0.1346, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 859\n",
      "Loss: tensor(0.1346, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 860\n",
      "Loss: tensor(0.1346, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 861\n",
      "Loss: tensor(0.1346, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 862\n",
      "Loss: tensor(0.1346, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 863\n",
      "Loss: tensor(0.1346, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 864\n",
      "Loss: tensor(0.1346, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 865\n",
      "Loss: tensor(0.1346, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 866\n",
      "Loss: tensor(0.1346, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 867\n",
      "Loss: tensor(0.1346, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 868\n",
      "Loss: tensor(0.1346, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 869\n",
      "Loss: tensor(0.1346, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 870\n",
      "Loss: tensor(0.1346, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 871\n",
      "Loss: tensor(0.1346, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 872\n",
      "Loss: tensor(0.1346, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 873\n",
      "Loss: tensor(0.1346, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 874\n",
      "Loss: tensor(0.1346, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 875\n",
      "Loss: tensor(0.1346, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 876\n",
      "Loss: tensor(0.1346, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 877\n",
      "Loss: tensor(0.1346, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 878\n",
      "Loss: tensor(0.1346, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 879\n",
      "Loss: tensor(0.1346, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 880\n",
      "Loss: tensor(0.1346, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 881\n",
      "Loss: tensor(0.1346, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 882\n",
      "Loss: tensor(0.1346, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 883\n",
      "Loss: tensor(0.1346, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 884\n",
      "Loss: tensor(0.1346, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 885\n",
      "Loss: tensor(0.1346, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 886\n",
      "Loss: tensor(0.1346, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 887\n",
      "Loss: tensor(0.1346, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 888\n",
      "Loss: tensor(0.1346, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 889\n",
      "Loss: tensor(0.1346, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 890\n",
      "Loss: tensor(0.1346, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 891\n",
      "Loss: tensor(0.1346, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 892\n",
      "Loss: tensor(0.1346, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 893\n",
      "Loss: tensor(0.1346, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 894\n",
      "Loss: tensor(0.1346, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 895\n",
      "Loss: tensor(0.1346, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 896\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor(0.1346, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 897\n",
      "Loss: tensor(0.1346, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 898\n",
      "Loss: tensor(0.1346, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 899\n",
      "Loss: tensor(0.1346, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 900\n",
      "Loss: tensor(0.1346, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 901\n",
      "Loss: tensor(0.1346, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 902\n",
      "Loss: tensor(0.1346, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 903\n",
      "Loss: tensor(0.1346, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 904\n",
      "Loss: tensor(0.1346, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 905\n",
      "Loss: tensor(0.1346, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 906\n",
      "Loss: tensor(0.1346, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 907\n",
      "Loss: tensor(0.1345, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 908\n",
      "Loss: tensor(0.1345, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 909\n",
      "Loss: tensor(0.1345, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 910\n",
      "Loss: tensor(0.1345, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 911\n",
      "Loss: tensor(0.1345, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 912\n",
      "Loss: tensor(0.1345, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 913\n",
      "Loss: tensor(0.1345, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 914\n",
      "Loss: tensor(0.1345, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 915\n",
      "Loss: tensor(0.1345, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 916\n",
      "Loss: tensor(0.1345, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 917\n",
      "Loss: tensor(0.1345, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 918\n",
      "Loss: tensor(0.1345, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 919\n",
      "Loss: tensor(0.1345, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 920\n",
      "Loss: tensor(0.1345, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 921\n",
      "Loss: tensor(0.1345, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 922\n",
      "Loss: tensor(0.1345, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 923\n",
      "Loss: tensor(0.1345, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 924\n",
      "Loss: tensor(0.1345, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 925\n",
      "Loss: tensor(0.1345, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 926\n",
      "Loss: tensor(0.1345, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 927\n",
      "Loss: tensor(0.1345, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 928\n",
      "Loss: tensor(0.1345, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 929\n",
      "Loss: tensor(0.1345, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 930\n",
      "Loss: tensor(0.1345, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 931\n",
      "Loss: tensor(0.1345, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 932\n",
      "Loss: tensor(0.1345, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 933\n",
      "Loss: tensor(0.1345, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 934\n",
      "Loss: tensor(0.1345, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 935\n",
      "Loss: tensor(0.1345, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 936\n",
      "Loss: tensor(0.1345, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 937\n",
      "Loss: tensor(0.1345, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 938\n",
      "Loss: tensor(0.1345, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 939\n",
      "Loss: tensor(0.1345, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 940\n",
      "Loss: tensor(0.1345, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 941\n",
      "Loss: tensor(0.1345, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 942\n",
      "Loss: tensor(0.1345, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 943\n",
      "Loss: tensor(0.1345, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 944\n",
      "Loss: tensor(0.1345, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 945\n",
      "Loss: tensor(0.1345, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 946\n",
      "Loss: tensor(0.1345, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 947\n",
      "Loss: tensor(0.1345, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 948\n",
      "Loss: tensor(0.1345, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 949\n",
      "Loss: tensor(0.1345, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 950\n",
      "Loss: tensor(0.1345, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 951\n",
      "Loss: tensor(0.1345, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 952\n",
      "Loss: tensor(0.1345, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 953\n",
      "Loss: tensor(0.1345, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 954\n",
      "Loss: tensor(0.1345, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 955\n",
      "Loss: tensor(0.1345, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 956\n",
      "Loss: tensor(0.1345, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 957\n",
      "Loss: tensor(0.1345, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 958\n",
      "Loss: tensor(0.1344, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 959\n",
      "Loss: tensor(0.1344, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 960\n",
      "Loss: tensor(0.1344, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 961\n",
      "Loss: tensor(0.1344, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 962\n",
      "Loss: tensor(0.1344, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 963\n",
      "Loss: tensor(0.1344, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 964\n",
      "Loss: tensor(0.1344, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 965\n",
      "Loss: tensor(0.1344, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 966\n",
      "Loss: tensor(0.1344, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 967\n",
      "Loss: tensor(0.1344, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 968\n",
      "Loss: tensor(0.1344, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 969\n",
      "Loss: tensor(0.1344, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 970\n",
      "Loss: tensor(0.1344, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 971\n",
      "Loss: tensor(0.1344, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 972\n",
      "Loss: tensor(0.1344, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 973\n",
      "Loss: tensor(0.1344, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 974\n",
      "Loss: tensor(0.1344, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 975\n",
      "Loss: tensor(0.1344, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 976\n",
      "Loss: tensor(0.1344, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 977\n",
      "Loss: tensor(0.1344, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 978\n",
      "Loss: tensor(0.1344, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 979\n",
      "Loss: tensor(0.1344, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 980\n",
      "Loss: tensor(0.1344, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 981\n",
      "Loss: tensor(0.1344, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 982\n",
      "Loss: tensor(0.1344, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 983\n",
      "Loss: tensor(0.1344, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 984\n",
      "Loss: tensor(0.1344, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 985\n",
      "Loss: tensor(0.1344, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 986\n",
      "Loss: tensor(0.1344, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 987\n",
      "Loss: tensor(0.1344, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 988\n",
      "Loss: tensor(0.1344, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 989\n",
      "Loss: tensor(0.1344, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 990\n",
      "Loss: tensor(0.1344, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 991\n",
      "Loss: tensor(0.1344, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 992\n",
      "Loss: tensor(0.1344, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 993\n",
      "Loss: tensor(0.1344, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 994\n",
      "Loss: tensor(0.1344, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 995\n",
      "Loss: tensor(0.1344, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 996\n",
      "Loss: tensor(0.1344, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 997\n",
      "Loss: tensor(0.1344, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 998\n",
      "Loss: tensor(0.1344, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 999\n",
      "Loss: tensor(0.1344, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1000\n",
      "Loss: tensor(0.1344, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1001\n",
      "Loss: tensor(0.1344, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1002\n",
      "Loss: tensor(0.1343, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1003\n",
      "Loss: tensor(0.1343, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1004\n",
      "Loss: tensor(0.1343, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1005\n",
      "Loss: tensor(0.1343, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1006\n",
      "Loss: tensor(0.1343, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1007\n",
      "Loss: tensor(0.1343, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1008\n",
      "Loss: tensor(0.1343, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1009\n",
      "Loss: tensor(0.1343, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1010\n",
      "Loss: tensor(0.1343, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1011\n",
      "Loss: tensor(0.1343, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1012\n",
      "Loss: tensor(0.1343, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1013\n",
      "Loss: tensor(0.1343, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1014\n",
      "Loss: tensor(0.1343, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1015\n",
      "Loss: tensor(0.1343, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1016\n",
      "Loss: tensor(0.1343, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1017\n",
      "Loss: tensor(0.1343, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1018\n",
      "Loss: tensor(0.1343, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1019\n",
      "Loss: tensor(0.1343, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1020\n",
      "Loss: tensor(0.1343, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1021\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor(0.1343, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1022\n",
      "Loss: tensor(0.1343, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1023\n",
      "Loss: tensor(0.1343, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1024\n",
      "Loss: tensor(0.1343, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1025\n",
      "Loss: tensor(0.1343, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1026\n",
      "Loss: tensor(0.1343, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1027\n",
      "Loss: tensor(0.1343, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1028\n",
      "Loss: tensor(0.1343, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1029\n",
      "Loss: tensor(0.1343, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1030\n",
      "Loss: tensor(0.1343, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1031\n",
      "Loss: tensor(0.1343, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1032\n",
      "Loss: tensor(0.1343, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1033\n",
      "Loss: tensor(0.1343, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1034\n",
      "Loss: tensor(0.1343, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1035\n",
      "Loss: tensor(0.1343, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1036\n",
      "Loss: tensor(0.1343, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1037\n",
      "Loss: tensor(0.1343, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1038\n",
      "Loss: tensor(0.1343, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1039\n",
      "Loss: tensor(0.1343, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1040\n",
      "Loss: tensor(0.1343, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1041\n",
      "Loss: tensor(0.1342, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1042\n",
      "Loss: tensor(0.1342, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1043\n",
      "Loss: tensor(0.1342, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1044\n",
      "Loss: tensor(0.1342, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1045\n",
      "Loss: tensor(0.1342, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1046\n",
      "Loss: tensor(0.1342, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1047\n",
      "Loss: tensor(0.1342, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1048\n",
      "Loss: tensor(0.1342, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1049\n",
      "Loss: tensor(0.1342, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1050\n",
      "Loss: tensor(0.1342, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1051\n",
      "Loss: tensor(0.1342, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1052\n",
      "Loss: tensor(0.1342, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1053\n",
      "Loss: tensor(0.1342, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1054\n",
      "Loss: tensor(0.1342, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1055\n",
      "Loss: tensor(0.1342, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1056\n",
      "Loss: tensor(0.1342, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1057\n",
      "Loss: tensor(0.1342, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1058\n",
      "Loss: tensor(0.1342, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1059\n",
      "Loss: tensor(0.1342, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1060\n",
      "Loss: tensor(0.1342, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1061\n",
      "Loss: tensor(0.1342, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1062\n",
      "Loss: tensor(0.1342, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1063\n",
      "Loss: tensor(0.1342, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1064\n",
      "Loss: tensor(0.1342, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1065\n",
      "Loss: tensor(0.1342, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1066\n",
      "Loss: tensor(0.1342, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1067\n",
      "Loss: tensor(0.1342, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1068\n",
      "Loss: tensor(0.1342, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1069\n",
      "Loss: tensor(0.1342, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1070\n",
      "Loss: tensor(0.1342, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1071\n",
      "Loss: tensor(0.1342, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1072\n",
      "Loss: tensor(0.1342, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1073\n",
      "Loss: tensor(0.1342, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1074\n",
      "Loss: tensor(0.1342, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1075\n",
      "Loss: tensor(0.1342, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1076\n",
      "Loss: tensor(0.1342, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1077\n",
      "Loss: tensor(0.1342, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1078\n",
      "Loss: tensor(0.1341, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1079\n",
      "Loss: tensor(0.1341, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1080\n",
      "Loss: tensor(0.1341, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1081\n",
      "Loss: tensor(0.1341, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1082\n",
      "Loss: tensor(0.1341, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1083\n",
      "Loss: tensor(0.1341, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1084\n",
      "Loss: tensor(0.1341, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1085\n",
      "Loss: tensor(0.1341, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1086\n",
      "Loss: tensor(0.1341, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1087\n",
      "Loss: tensor(0.1341, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1088\n",
      "Loss: tensor(0.1341, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1089\n",
      "Loss: tensor(0.1341, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1090\n",
      "Loss: tensor(0.1341, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1091\n",
      "Loss: tensor(0.1341, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1092\n",
      "Loss: tensor(0.1341, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1093\n",
      "Loss: tensor(0.1341, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1094\n",
      "Loss: tensor(0.1341, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1095\n",
      "Loss: tensor(0.1341, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1096\n",
      "Loss: tensor(0.1341, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1097\n",
      "Loss: tensor(0.1341, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1098\n",
      "Loss: tensor(0.1341, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1099\n",
      "Loss: tensor(0.1341, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1100\n",
      "Loss: tensor(0.1341, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1101\n",
      "Loss: tensor(0.1341, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1102\n",
      "Loss: tensor(0.1341, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1103\n",
      "Loss: tensor(0.1341, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1104\n",
      "Loss: tensor(0.1341, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1105\n",
      "Loss: tensor(0.1341, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1106\n",
      "Loss: tensor(0.1341, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1107\n",
      "Loss: tensor(0.1341, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1108\n",
      "Loss: tensor(0.1341, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1109\n",
      "Loss: tensor(0.1341, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1110\n",
      "Loss: tensor(0.1341, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1111\n",
      "Loss: tensor(0.1341, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1112\n",
      "Loss: tensor(0.1341, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1113\n",
      "Loss: tensor(0.1340, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1114\n",
      "Loss: tensor(0.1340, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1115\n",
      "Loss: tensor(0.1340, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1116\n",
      "Loss: tensor(0.1340, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1117\n",
      "Loss: tensor(0.1340, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1118\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor(0.1340, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1119\n",
      "Loss: tensor(0.1340, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1120\n",
      "Loss: tensor(0.1340, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1121\n",
      "Loss: tensor(0.1340, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1122\n",
      "Loss: tensor(0.1340, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1123\n",
      "Loss: tensor(0.1340, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1124\n",
      "Loss: tensor(0.1340, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1125\n",
      "Loss: tensor(0.1340, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1126\n",
      "Loss: tensor(0.1340, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1127\n",
      "Loss: tensor(0.1340, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1128\n",
      "Loss: tensor(0.1340, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1129\n",
      "Loss: tensor(0.1340, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1130\n",
      "Loss: tensor(0.1340, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1131\n",
      "Loss: tensor(0.1340, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1132\n",
      "Loss: tensor(0.1340, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1133\n",
      "Loss: tensor(0.1340, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1134\n",
      "Loss: tensor(0.1340, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1135\n",
      "Loss: tensor(0.1340, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1136\n",
      "Loss: tensor(0.1340, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1137\n",
      "Loss: tensor(0.1340, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1138\n",
      "Loss: tensor(0.1340, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1139\n",
      "Loss: tensor(0.1340, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1140\n",
      "Loss: tensor(0.1340, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1141\n",
      "Loss: tensor(0.1340, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1142\n",
      "Loss: tensor(0.1340, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1143\n",
      "Loss: tensor(0.1340, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1144\n",
      "Loss: tensor(0.1340, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1145\n",
      "Loss: tensor(0.1340, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1146\n",
      "Loss: tensor(0.1340, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1147\n",
      "Loss: tensor(0.1340, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1148\n",
      "Loss: tensor(0.1339, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1149\n",
      "Loss: tensor(0.1339, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1150\n",
      "Loss: tensor(0.1339, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1151\n",
      "Loss: tensor(0.1339, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1152\n",
      "Loss: tensor(0.1339, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1153\n",
      "Loss: tensor(0.1339, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1154\n",
      "Loss: tensor(0.1339, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1155\n",
      "Loss: tensor(0.1339, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1156\n",
      "Loss: tensor(0.1339, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1157\n",
      "Loss: tensor(0.1339, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1158\n",
      "Loss: tensor(0.1339, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1159\n",
      "Loss: tensor(0.1339, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1160\n",
      "Loss: tensor(0.1339, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1161\n",
      "Loss: tensor(0.1339, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1162\n",
      "Loss: tensor(0.1339, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1163\n",
      "Loss: tensor(0.1339, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1164\n",
      "Loss: tensor(0.1339, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1165\n",
      "Loss: tensor(0.1339, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1166\n",
      "Loss: tensor(0.1339, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1167\n",
      "Loss: tensor(0.1339, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1168\n",
      "Loss: tensor(0.1339, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1169\n",
      "Loss: tensor(0.1339, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1170\n",
      "Loss: tensor(0.1339, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1171\n",
      "Loss: tensor(0.1339, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1172\n",
      "Loss: tensor(0.1339, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1173\n",
      "Loss: tensor(0.1339, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1174\n",
      "Loss: tensor(0.1339, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1175\n",
      "Loss: tensor(0.1339, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1176\n",
      "Loss: tensor(0.1339, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1177\n",
      "Loss: tensor(0.1339, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1178\n",
      "Loss: tensor(0.1339, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1179\n",
      "Loss: tensor(0.1339, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1180\n",
      "Loss: tensor(0.1339, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1181\n",
      "Loss: tensor(0.1339, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1182\n",
      "Loss: tensor(0.1339, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1183\n",
      "Loss: tensor(0.1338, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1184\n",
      "Loss: tensor(0.1338, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1185\n",
      "Loss: tensor(0.1338, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1186\n",
      "Loss: tensor(0.1338, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1187\n",
      "Loss: tensor(0.1338, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1188\n",
      "Loss: tensor(0.1338, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1189\n",
      "Loss: tensor(0.1338, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1190\n",
      "Loss: tensor(0.1338, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1191\n",
      "Loss: tensor(0.1338, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1192\n",
      "Loss: tensor(0.1338, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1193\n",
      "Loss: tensor(0.1338, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1194\n",
      "Loss: tensor(0.1338, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1195\n",
      "Loss: tensor(0.1338, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1196\n",
      "Loss: tensor(0.1338, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1197\n",
      "Loss: tensor(0.1338, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1198\n",
      "Loss: tensor(0.1338, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1199\n",
      "Loss: tensor(0.1338, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1200\n",
      "Loss: tensor(0.1338, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1201\n",
      "Loss: tensor(0.1338, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1202\n",
      "Loss: tensor(0.1338, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1203\n",
      "Loss: tensor(0.1338, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1204\n",
      "Loss: tensor(0.1338, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1205\n",
      "Loss: tensor(0.1338, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1206\n",
      "Loss: tensor(0.1338, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1207\n",
      "Loss: tensor(0.1338, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1208\n",
      "Loss: tensor(0.1338, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1209\n",
      "Loss: tensor(0.1338, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1210\n",
      "Loss: tensor(0.1338, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1211\n",
      "Loss: tensor(0.1338, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1212\n",
      "Loss: tensor(0.1338, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1213\n",
      "Loss: tensor(0.1338, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1214\n",
      "Loss: tensor(0.1338, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1215\n",
      "Loss: tensor(0.1338, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1216\n",
      "Loss: tensor(0.1338, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1217\n",
      "Loss: tensor(0.1338, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1218\n",
      "Loss: tensor(0.1338, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1219\n",
      "Loss: tensor(0.1337, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1220\n",
      "Loss: tensor(0.1337, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1221\n",
      "Loss: tensor(0.1337, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1222\n",
      "Loss: tensor(0.1337, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1223\n",
      "Loss: tensor(0.1337, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1224\n",
      "Loss: tensor(0.1337, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1225\n",
      "Loss: tensor(0.1337, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1226\n",
      "Loss: tensor(0.1337, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1227\n",
      "Loss: tensor(0.1337, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1228\n",
      "Loss: tensor(0.1337, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1229\n",
      "Loss: tensor(0.1337, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1230\n",
      "Loss: tensor(0.1337, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1231\n",
      "Loss: tensor(0.1337, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1232\n",
      "Loss: tensor(0.1337, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1233\n",
      "Loss: tensor(0.1337, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1234\n",
      "Loss: tensor(0.1337, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1235\n",
      "Loss: tensor(0.1337, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1236\n",
      "Loss: tensor(0.1337, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1237\n",
      "Loss: tensor(0.1337, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1238\n",
      "Loss: tensor(0.1337, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1239\n",
      "Loss: tensor(0.1337, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1240\n",
      "Loss: tensor(0.1337, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1241\n",
      "Loss: tensor(0.1337, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1242\n",
      "Loss: tensor(0.1337, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1243\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor(0.1337, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1244\n",
      "Loss: tensor(0.1337, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1245\n",
      "Loss: tensor(0.1337, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1246\n",
      "Loss: tensor(0.1337, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1247\n",
      "Loss: tensor(0.1337, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1248\n",
      "Loss: tensor(0.1337, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1249\n",
      "Loss: tensor(0.1337, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1250\n",
      "Loss: tensor(0.1337, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1251\n",
      "Loss: tensor(0.1337, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1252\n",
      "Loss: tensor(0.1337, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1253\n",
      "Loss: tensor(0.1337, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1254\n",
      "Loss: tensor(0.1337, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1255\n",
      "Loss: tensor(0.1337, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1256\n",
      "Loss: tensor(0.1336, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1257\n",
      "Loss: tensor(0.1336, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1258\n",
      "Loss: tensor(0.1336, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1259\n",
      "Loss: tensor(0.1336, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1260\n",
      "Loss: tensor(0.1336, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1261\n",
      "Loss: tensor(0.1336, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1262\n",
      "Loss: tensor(0.1336, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1263\n",
      "Loss: tensor(0.1336, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1264\n",
      "Loss: tensor(0.1336, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1265\n",
      "Loss: tensor(0.1336, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1266\n",
      "Loss: tensor(0.1336, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1267\n",
      "Loss: tensor(0.1336, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1268\n",
      "Loss: tensor(0.1336, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1269\n",
      "Loss: tensor(0.1336, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1270\n",
      "Loss: tensor(0.1336, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1271\n",
      "Loss: tensor(0.1336, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1272\n",
      "Loss: tensor(0.1336, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1273\n",
      "Loss: tensor(0.1336, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1274\n",
      "Loss: tensor(0.1336, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1275\n",
      "Loss: tensor(0.1336, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1276\n",
      "Loss: tensor(0.1336, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1277\n",
      "Loss: tensor(0.1336, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1278\n",
      "Loss: tensor(0.1336, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1279\n",
      "Loss: tensor(0.1336, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1280\n",
      "Loss: tensor(0.1336, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1281\n",
      "Loss: tensor(0.1336, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1282\n",
      "Loss: tensor(0.1336, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1283\n",
      "Loss: tensor(0.1336, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1284\n",
      "Loss: tensor(0.1336, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1285\n",
      "Loss: tensor(0.1336, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1286\n",
      "Loss: tensor(0.1336, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1287\n",
      "Loss: tensor(0.1336, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1288\n",
      "Loss: tensor(0.1336, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1289\n",
      "Loss: tensor(0.1336, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1290\n",
      "Loss: tensor(0.1336, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1291\n",
      "Loss: tensor(0.1336, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1292\n",
      "Loss: tensor(0.1336, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1293\n",
      "Loss: tensor(0.1335, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1294\n",
      "Loss: tensor(0.1335, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1295\n",
      "Loss: tensor(0.1335, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1296\n",
      "Loss: tensor(0.1335, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1297\n",
      "Loss: tensor(0.1335, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1298\n",
      "Loss: tensor(0.1335, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1299\n",
      "Loss: tensor(0.1335, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1300\n",
      "Loss: tensor(0.1335, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1301\n",
      "Loss: tensor(0.1335, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1302\n",
      "Loss: tensor(0.1335, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1303\n",
      "Loss: tensor(0.1335, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1304\n",
      "Loss: tensor(0.1335, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1305\n",
      "Loss: tensor(0.1335, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1306\n",
      "Loss: tensor(0.1335, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1307\n",
      "Loss: tensor(0.1335, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1308\n",
      "Loss: tensor(0.1335, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1309\n",
      "Loss: tensor(0.1335, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1310\n",
      "Loss: tensor(0.1335, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1311\n",
      "Loss: tensor(0.1335, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1312\n",
      "Loss: tensor(0.1335, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1313\n",
      "Loss: tensor(0.1335, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1314\n",
      "Loss: tensor(0.1335, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1315\n",
      "Loss: tensor(0.1335, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1316\n",
      "Loss: tensor(0.1335, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1317\n",
      "Loss: tensor(0.1335, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1318\n",
      "Loss: tensor(0.1335, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1319\n",
      "Loss: tensor(0.1335, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1320\n",
      "Loss: tensor(0.1335, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1321\n",
      "Loss: tensor(0.1335, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1322\n",
      "Loss: tensor(0.1335, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1323\n",
      "Loss: tensor(0.1335, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1324\n",
      "Loss: tensor(0.1335, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1325\n",
      "Loss: tensor(0.1335, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1326\n",
      "Loss: tensor(0.1335, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1327\n",
      "Loss: tensor(0.1335, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1328\n",
      "Loss: tensor(0.1335, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1329\n",
      "Loss: tensor(0.1334, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1330\n",
      "Loss: tensor(0.1334, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1331\n",
      "Loss: tensor(0.1334, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1332\n",
      "Loss: tensor(0.1334, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1333\n",
      "Loss: tensor(0.1334, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1334\n",
      "Loss: tensor(0.1334, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1335\n",
      "Loss: tensor(0.1334, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1336\n",
      "Loss: tensor(0.1334, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1337\n",
      "Loss: tensor(0.1334, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1338\n",
      "Loss: tensor(0.1334, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1339\n",
      "Loss: tensor(0.1334, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1340\n",
      "Loss: tensor(0.1334, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1341\n",
      "Loss: tensor(0.1334, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1342\n",
      "Loss: tensor(0.1334, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1343\n",
      "Loss: tensor(0.1334, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1344\n",
      "Loss: tensor(0.1334, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1345\n",
      "Loss: tensor(0.1334, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1346\n",
      "Loss: tensor(0.1334, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1347\n",
      "Loss: tensor(0.1334, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1348\n",
      "Loss: tensor(0.1334, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1349\n",
      "Loss: tensor(0.1334, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1350\n",
      "Loss: tensor(0.1334, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1351\n",
      "Loss: tensor(0.1334, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1352\n",
      "Loss: tensor(0.1334, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1353\n",
      "Loss: tensor(0.1334, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1354\n",
      "Loss: tensor(0.1334, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1355\n",
      "Loss: tensor(0.1334, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1356\n",
      "Loss: tensor(0.1334, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1357\n",
      "Loss: tensor(0.1334, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1358\n",
      "Loss: tensor(0.1334, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1359\n",
      "Loss: tensor(0.1334, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1360\n",
      "Loss: tensor(0.1334, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1361\n",
      "Loss: tensor(0.1334, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1362\n",
      "Loss: tensor(0.1334, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1363\n",
      "Loss: tensor(0.1334, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1364\n",
      "Loss: tensor(0.1333, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1365\n",
      "Loss: tensor(0.1333, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1366\n",
      "Loss: tensor(0.1333, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1367\n",
      "Loss: tensor(0.1333, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1368\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor(0.1333, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1369\n",
      "Loss: tensor(0.1333, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1370\n",
      "Loss: tensor(0.1333, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1371\n",
      "Loss: tensor(0.1333, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1372\n",
      "Loss: tensor(0.1333, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1373\n",
      "Loss: tensor(0.1333, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1374\n",
      "Loss: tensor(0.1333, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1375\n",
      "Loss: tensor(0.1333, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1376\n",
      "Loss: tensor(0.1333, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1377\n",
      "Loss: tensor(0.1333, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1378\n",
      "Loss: tensor(0.1333, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1379\n",
      "Loss: tensor(0.1333, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1380\n",
      "Loss: tensor(0.1333, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1381\n",
      "Loss: tensor(0.1333, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1382\n",
      "Loss: tensor(0.1333, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1383\n",
      "Loss: tensor(0.1333, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1384\n",
      "Loss: tensor(0.1333, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1385\n",
      "Loss: tensor(0.1333, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1386\n",
      "Loss: tensor(0.1333, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1387\n",
      "Loss: tensor(0.1333, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1388\n",
      "Loss: tensor(0.1333, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1389\n",
      "Loss: tensor(0.1333, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1390\n",
      "Loss: tensor(0.1333, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1391\n",
      "Loss: tensor(0.1333, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1392\n",
      "Loss: tensor(0.1333, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1393\n",
      "Loss: tensor(0.1333, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1394\n",
      "Loss: tensor(0.1333, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1395\n",
      "Loss: tensor(0.1333, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1396\n",
      "Loss: tensor(0.1333, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1397\n",
      "Loss: tensor(0.1333, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1398\n",
      "Loss: tensor(0.1332, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1399\n",
      "Loss: tensor(0.1332, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1400\n",
      "Loss: tensor(0.1332, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1401\n",
      "Loss: tensor(0.1332, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1402\n",
      "Loss: tensor(0.1332, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1403\n",
      "Loss: tensor(0.1332, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1404\n",
      "Loss: tensor(0.1332, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1405\n",
      "Loss: tensor(0.1332, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1406\n",
      "Loss: tensor(0.1332, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1407\n",
      "Loss: tensor(0.1332, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1408\n",
      "Loss: tensor(0.1332, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1409\n",
      "Loss: tensor(0.1332, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1410\n",
      "Loss: tensor(0.1332, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1411\n",
      "Loss: tensor(0.1332, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1412\n",
      "Loss: tensor(0.1332, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1413\n",
      "Loss: tensor(0.1332, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1414\n",
      "Loss: tensor(0.1332, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1415\n",
      "Loss: tensor(0.1332, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1416\n",
      "Loss: tensor(0.1332, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1417\n",
      "Loss: tensor(0.1332, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1418\n",
      "Loss: tensor(0.1332, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1419\n",
      "Loss: tensor(0.1332, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1420\n",
      "Loss: tensor(0.1332, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1421\n",
      "Loss: tensor(0.1332, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1422\n",
      "Loss: tensor(0.1332, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1423\n",
      "Loss: tensor(0.1332, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1424\n",
      "Loss: tensor(0.1332, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1425\n",
      "Loss: tensor(0.1332, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1426\n",
      "Loss: tensor(0.1332, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1427\n",
      "Loss: tensor(0.1332, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1428\n",
      "Loss: tensor(0.1332, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1429\n",
      "Loss: tensor(0.1332, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1430\n",
      "Loss: tensor(0.1332, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1431\n",
      "Loss: tensor(0.1331, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1432\n",
      "Loss: tensor(0.1331, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1433\n",
      "Loss: tensor(0.1331, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1434\n",
      "Loss: tensor(0.1331, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1435\n",
      "Loss: tensor(0.1331, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1436\n",
      "Loss: tensor(0.1331, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1437\n",
      "Loss: tensor(0.1331, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1438\n",
      "Loss: tensor(0.1331, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1439\n",
      "Loss: tensor(0.1331, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1440\n",
      "Loss: tensor(0.1331, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1441\n",
      "Loss: tensor(0.1331, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1442\n",
      "Loss: tensor(0.1331, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1443\n",
      "Loss: tensor(0.1331, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1444\n",
      "Loss: tensor(0.1331, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1445\n",
      "Loss: tensor(0.1331, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1446\n",
      "Loss: tensor(0.1331, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1447\n",
      "Loss: tensor(0.1331, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1448\n",
      "Loss: tensor(0.1331, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1449\n",
      "Loss: tensor(0.1331, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1450\n",
      "Loss: tensor(0.1331, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1451\n",
      "Loss: tensor(0.1331, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1452\n",
      "Loss: tensor(0.1331, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1453\n",
      "Loss: tensor(0.1331, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1454\n",
      "Loss: tensor(0.1331, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1455\n",
      "Loss: tensor(0.1331, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1456\n",
      "Loss: tensor(0.1331, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1457\n",
      "Loss: tensor(0.1331, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1458\n",
      "Loss: tensor(0.1331, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1459\n",
      "Loss: tensor(0.1331, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1460\n",
      "Loss: tensor(0.1331, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1461\n",
      "Loss: tensor(0.1331, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1462\n",
      "Loss: tensor(0.1330, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1463\n",
      "Loss: tensor(0.1330, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1464\n",
      "Loss: tensor(0.1330, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1465\n",
      "Loss: tensor(0.1330, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1466\n",
      "Loss: tensor(0.1330, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1467\n",
      "Loss: tensor(0.1330, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1468\n",
      "Loss: tensor(0.1330, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1469\n",
      "Loss: tensor(0.1330, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1470\n",
      "Loss: tensor(0.1330, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1471\n",
      "Loss: tensor(0.1330, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1472\n",
      "Loss: tensor(0.1330, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1473\n",
      "Loss: tensor(0.1330, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1474\n",
      "Loss: tensor(0.1330, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1475\n",
      "Loss: tensor(0.1330, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1476\n",
      "Loss: tensor(0.1330, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1477\n",
      "Loss: tensor(0.1330, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1478\n",
      "Loss: tensor(0.1330, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1479\n",
      "Loss: tensor(0.1330, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1480\n",
      "Loss: tensor(0.1330, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1481\n",
      "Loss: tensor(0.1330, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1482\n",
      "Loss: tensor(0.1330, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1483\n",
      "Loss: tensor(0.1330, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1484\n",
      "Loss: tensor(0.1330, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1485\n",
      "Loss: tensor(0.1330, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1486\n",
      "Loss: tensor(0.1330, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1487\n",
      "Loss: tensor(0.1330, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1488\n",
      "Loss: tensor(0.1330, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1489\n",
      "Loss: tensor(0.1330, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1490\n",
      "Loss: tensor(0.1330, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1491\n",
      "Loss: tensor(0.1330, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1492\n",
      "Loss: tensor(0.1329, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1493\n",
      "Loss: tensor(0.1329, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1494\n",
      "Loss: tensor(0.1329, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1495\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor(0.1329, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1496\n",
      "Loss: tensor(0.1329, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1497\n",
      "Loss: tensor(0.1329, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1498\n",
      "Loss: tensor(0.1329, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1499\n",
      "Loss: tensor(0.1329, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1500\n",
      "Loss: tensor(0.1329, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1501\n",
      "Loss: tensor(0.1329, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1502\n",
      "Loss: tensor(0.1329, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1503\n",
      "Loss: tensor(0.1329, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1504\n",
      "Loss: tensor(0.1329, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1505\n",
      "Loss: tensor(0.1329, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1506\n",
      "Loss: tensor(0.1329, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1507\n",
      "Loss: tensor(0.1329, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1508\n",
      "Loss: tensor(0.1329, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1509\n",
      "Loss: tensor(0.1329, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1510\n",
      "Loss: tensor(0.1329, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1511\n",
      "Loss: tensor(0.1329, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1512\n",
      "Loss: tensor(0.1329, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1513\n",
      "Loss: tensor(0.1329, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1514\n",
      "Loss: tensor(0.1329, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1515\n",
      "Loss: tensor(0.1329, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1516\n",
      "Loss: tensor(0.1329, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1517\n",
      "Loss: tensor(0.1329, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1518\n",
      "Loss: tensor(0.1329, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1519\n",
      "Loss: tensor(0.1329, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1520\n",
      "Loss: tensor(0.1328, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1521\n",
      "Loss: tensor(0.1328, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1522\n",
      "Loss: tensor(0.1328, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1523\n",
      "Loss: tensor(0.1328, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1524\n",
      "Loss: tensor(0.1328, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1525\n",
      "Loss: tensor(0.1328, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1526\n",
      "Loss: tensor(0.1328, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1527\n",
      "Loss: tensor(0.1328, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1528\n",
      "Loss: tensor(0.1328, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1529\n",
      "Loss: tensor(0.1328, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1530\n",
      "Loss: tensor(0.1328, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1531\n",
      "Loss: tensor(0.1328, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1532\n",
      "Loss: tensor(0.1328, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1533\n",
      "Loss: tensor(0.1328, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1534\n",
      "Loss: tensor(0.1328, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1535\n",
      "Loss: tensor(0.1328, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1536\n",
      "Loss: tensor(0.1328, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1537\n",
      "Loss: tensor(0.1328, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1538\n",
      "Loss: tensor(0.1328, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1539\n",
      "Loss: tensor(0.1328, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1540\n",
      "Loss: tensor(0.1328, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1541\n",
      "Loss: tensor(0.1328, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1542\n",
      "Loss: tensor(0.1328, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1543\n",
      "Loss: tensor(0.1328, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1544\n",
      "Loss: tensor(0.1328, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1545\n",
      "Loss: tensor(0.1328, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1546\n",
      "Loss: tensor(0.1328, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1547\n",
      "Loss: tensor(0.1327, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1548\n",
      "Loss: tensor(0.1327, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1549\n",
      "Loss: tensor(0.1327, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1550\n",
      "Loss: tensor(0.1327, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1551\n",
      "Loss: tensor(0.1327, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1552\n",
      "Loss: tensor(0.1327, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1553\n",
      "Loss: tensor(0.1327, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1554\n",
      "Loss: tensor(0.1327, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1555\n",
      "Loss: tensor(0.1327, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1556\n",
      "Loss: tensor(0.1327, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1557\n",
      "Loss: tensor(0.1327, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1558\n",
      "Loss: tensor(0.1327, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1559\n",
      "Loss: tensor(0.1327, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1560\n",
      "Loss: tensor(0.1327, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1561\n",
      "Loss: tensor(0.1327, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1562\n",
      "Loss: tensor(0.1327, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1563\n",
      "Loss: tensor(0.1327, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1564\n",
      "Loss: tensor(0.1327, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1565\n",
      "Loss: tensor(0.1327, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1566\n",
      "Loss: tensor(0.1327, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1567\n",
      "Loss: tensor(0.1327, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1568\n",
      "Loss: tensor(0.1327, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1569\n",
      "Loss: tensor(0.1327, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1570\n",
      "Loss: tensor(0.1327, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1571\n",
      "Loss: tensor(0.1327, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1572\n",
      "Loss: tensor(0.1326, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1573\n",
      "Loss: tensor(0.1326, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1574\n",
      "Loss: tensor(0.1326, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1575\n",
      "Loss: tensor(0.1326, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1576\n",
      "Loss: tensor(0.1326, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1577\n",
      "Loss: tensor(0.1326, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1578\n",
      "Loss: tensor(0.1326, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1579\n",
      "Loss: tensor(0.1326, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1580\n",
      "Loss: tensor(0.1326, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1581\n",
      "Loss: tensor(0.1326, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1582\n",
      "Loss: tensor(0.1326, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1583\n",
      "Loss: tensor(0.1326, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1584\n",
      "Loss: tensor(0.1326, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1585\n",
      "Loss: tensor(0.1326, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1586\n",
      "Loss: tensor(0.1326, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1587\n",
      "Loss: tensor(0.1326, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1588\n",
      "Loss: tensor(0.1326, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1589\n",
      "Loss: tensor(0.1326, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1590\n",
      "Loss: tensor(0.1326, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1591\n",
      "Loss: tensor(0.1326, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1592\n",
      "Loss: tensor(0.1326, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1593\n",
      "Loss: tensor(0.1326, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1594\n",
      "Loss: tensor(0.1326, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1595\n",
      "Loss: tensor(0.1326, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1596\n",
      "Loss: tensor(0.1325, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1597\n",
      "Loss: tensor(0.1325, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1598\n",
      "Loss: tensor(0.1325, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1599\n",
      "Loss: tensor(0.1325, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1600\n",
      "Loss: tensor(0.1325, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1601\n",
      "Loss: tensor(0.1325, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1602\n",
      "Loss: tensor(0.1325, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1603\n",
      "Loss: tensor(0.1325, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1604\n",
      "Loss: tensor(0.1325, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1605\n",
      "Loss: tensor(0.1325, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1606\n",
      "Loss: tensor(0.1325, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1607\n",
      "Loss: tensor(0.1325, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1608\n",
      "Loss: tensor(0.1325, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1609\n",
      "Loss: tensor(0.1325, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1610\n",
      "Loss: tensor(0.1325, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1611\n",
      "Loss: tensor(0.1325, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1612\n",
      "Loss: tensor(0.1325, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1613\n",
      "Loss: tensor(0.1325, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1614\n",
      "Loss: tensor(0.1325, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1615\n",
      "Loss: tensor(0.1325, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1616\n",
      "Loss: tensor(0.1325, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1617\n",
      "Loss: tensor(0.1325, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1618\n",
      "Loss: tensor(0.1324, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1619\n",
      "Loss: tensor(0.1324, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1620\n",
      "Loss: tensor(0.1324, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1621\n",
      "Loss: tensor(0.1324, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1622\n",
      "Loss: tensor(0.1324, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1623\n",
      "Loss: tensor(0.1324, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1624\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor(0.1324, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1625\n",
      "Loss: tensor(0.1324, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1626\n",
      "Loss: tensor(0.1324, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1627\n",
      "Loss: tensor(0.1324, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1628\n",
      "Loss: tensor(0.1324, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1629\n",
      "Loss: tensor(0.1324, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1630\n",
      "Loss: tensor(0.1324, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1631\n",
      "Loss: tensor(0.1324, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1632\n",
      "Loss: tensor(0.1324, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1633\n",
      "Loss: tensor(0.1324, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1634\n",
      "Loss: tensor(0.1324, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1635\n",
      "Loss: tensor(0.1324, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1636\n",
      "Loss: tensor(0.1324, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1637\n",
      "Loss: tensor(0.1324, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1638\n",
      "Loss: tensor(0.1324, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1639\n",
      "Loss: tensor(0.1323, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1640\n",
      "Loss: tensor(0.1323, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1641\n",
      "Loss: tensor(0.1323, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1642\n",
      "Loss: tensor(0.1323, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1643\n",
      "Loss: tensor(0.1323, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1644\n",
      "Loss: tensor(0.1323, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1645\n",
      "Loss: tensor(0.1323, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1646\n",
      "Loss: tensor(0.1323, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1647\n",
      "Loss: tensor(0.1323, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1648\n",
      "Loss: tensor(0.1323, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1649\n",
      "Loss: tensor(0.1323, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1650\n",
      "Loss: tensor(0.1323, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1651\n",
      "Loss: tensor(0.1323, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1652\n",
      "Loss: tensor(0.1323, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1653\n",
      "Loss: tensor(0.1323, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1654\n",
      "Loss: tensor(0.1323, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1655\n",
      "Loss: tensor(0.1323, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1656\n",
      "Loss: tensor(0.1323, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1657\n",
      "Loss: tensor(0.1323, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1658\n",
      "Loss: tensor(0.1323, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1659\n",
      "Loss: tensor(0.1322, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1660\n",
      "Loss: tensor(0.1322, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1661\n",
      "Loss: tensor(0.1322, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1662\n",
      "Loss: tensor(0.1322, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1663\n",
      "Loss: tensor(0.1322, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1664\n",
      "Loss: tensor(0.1322, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1665\n",
      "Loss: tensor(0.1322, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1666\n",
      "Loss: tensor(0.1322, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1667\n",
      "Loss: tensor(0.1322, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1668\n",
      "Loss: tensor(0.1322, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1669\n",
      "Loss: tensor(0.1322, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1670\n",
      "Loss: tensor(0.1322, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1671\n",
      "Loss: tensor(0.1322, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1672\n",
      "Loss: tensor(0.1322, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1673\n",
      "Loss: tensor(0.1322, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1674\n",
      "Loss: tensor(0.1322, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1675\n",
      "Loss: tensor(0.1322, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1676\n",
      "Loss: tensor(0.1322, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1677\n",
      "Loss: tensor(0.1322, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1678\n",
      "Loss: tensor(0.1322, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1679\n",
      "Loss: tensor(0.1321, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1680\n",
      "Loss: tensor(0.1321, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1681\n",
      "Loss: tensor(0.1321, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1682\n",
      "Loss: tensor(0.1321, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1683\n",
      "Loss: tensor(0.1321, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1684\n",
      "Loss: tensor(0.1321, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1685\n",
      "Loss: tensor(0.1321, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1686\n",
      "Loss: tensor(0.1321, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1687\n",
      "Loss: tensor(0.1321, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1688\n",
      "Loss: tensor(0.1321, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1689\n",
      "Loss: tensor(0.1321, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1690\n",
      "Loss: tensor(0.1321, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1691\n",
      "Loss: tensor(0.1321, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1692\n",
      "Loss: tensor(0.1321, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1693\n",
      "Loss: tensor(0.1321, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1694\n",
      "Loss: tensor(0.1321, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1695\n",
      "Loss: tensor(0.1321, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1696\n",
      "Loss: tensor(0.1321, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1697\n",
      "Loss: tensor(0.1320, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1698\n",
      "Loss: tensor(0.1320, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1699\n",
      "Loss: tensor(0.1320, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1700\n",
      "Loss: tensor(0.1320, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1701\n",
      "Loss: tensor(0.1320, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1702\n",
      "Loss: tensor(0.1320, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1703\n",
      "Loss: tensor(0.1320, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1704\n",
      "Loss: tensor(0.1320, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1705\n",
      "Loss: tensor(0.1320, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1706\n",
      "Loss: tensor(0.1320, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1707\n",
      "Loss: tensor(0.1320, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1708\n",
      "Loss: tensor(0.1320, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1709\n",
      "Loss: tensor(0.1320, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1710\n",
      "Loss: tensor(0.1320, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1711\n",
      "Loss: tensor(0.1320, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1712\n",
      "Loss: tensor(0.1320, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1713\n",
      "Loss: tensor(0.1320, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1714\n",
      "Loss: tensor(0.1320, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1715\n",
      "Loss: tensor(0.1319, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1716\n",
      "Loss: tensor(0.1319, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1717\n",
      "Loss: tensor(0.1319, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1718\n",
      "Loss: tensor(0.1319, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1719\n",
      "Loss: tensor(0.1319, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1720\n",
      "Loss: tensor(0.1319, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1721\n",
      "Loss: tensor(0.1319, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1722\n",
      "Loss: tensor(0.1319, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1723\n",
      "Loss: tensor(0.1319, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1724\n",
      "Loss: tensor(0.1319, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1725\n",
      "Loss: tensor(0.1319, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1726\n",
      "Loss: tensor(0.1319, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1727\n",
      "Loss: tensor(0.1319, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1728\n",
      "Loss: tensor(0.1319, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1729\n",
      "Loss: tensor(0.1319, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1730\n",
      "Loss: tensor(0.1319, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1731\n",
      "Loss: tensor(0.1319, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1732\n",
      "Loss: tensor(0.1318, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1733\n",
      "Loss: tensor(0.1318, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1734\n",
      "Loss: tensor(0.1318, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1735\n",
      "Loss: tensor(0.1318, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1736\n",
      "Loss: tensor(0.1318, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1737\n",
      "Loss: tensor(0.1318, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1738\n",
      "Loss: tensor(0.1318, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1739\n",
      "Loss: tensor(0.1318, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1740\n",
      "Loss: tensor(0.1318, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1741\n",
      "Loss: tensor(0.1318, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1742\n",
      "Loss: tensor(0.1318, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1743\n",
      "Loss: tensor(0.1318, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1744\n",
      "Loss: tensor(0.1318, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1745\n",
      "Loss: tensor(0.1318, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1746\n",
      "Loss: tensor(0.1318, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1747\n",
      "Loss: tensor(0.1318, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1748\n",
      "Loss: tensor(0.1318, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1749\n",
      "Loss: tensor(0.1317, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1750\n",
      "Loss: tensor(0.1317, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1751\n",
      "Loss: tensor(0.1317, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1752\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor(0.1317, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1753\n",
      "Loss: tensor(0.1317, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1754\n",
      "Loss: tensor(0.1317, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1755\n",
      "Loss: tensor(0.1317, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1756\n",
      "Loss: tensor(0.1317, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1757\n",
      "Loss: tensor(0.1317, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1758\n",
      "Loss: tensor(0.1317, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1759\n",
      "Loss: tensor(0.1317, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1760\n",
      "Loss: tensor(0.1317, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1761\n",
      "Loss: tensor(0.1317, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1762\n",
      "Loss: tensor(0.1317, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1763\n",
      "Loss: tensor(0.1317, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1764\n",
      "Loss: tensor(0.1317, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1765\n",
      "Loss: tensor(0.1316, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1766\n",
      "Loss: tensor(0.1316, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1767\n",
      "Loss: tensor(0.1316, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1768\n",
      "Loss: tensor(0.1316, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1769\n",
      "Loss: tensor(0.1316, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1770\n",
      "Loss: tensor(0.1316, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1771\n",
      "Loss: tensor(0.1316, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1772\n",
      "Loss: tensor(0.1316, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1773\n",
      "Loss: tensor(0.1316, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1774\n",
      "Loss: tensor(0.1316, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1775\n",
      "Loss: tensor(0.1316, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1776\n",
      "Loss: tensor(0.1316, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1777\n",
      "Loss: tensor(0.1316, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1778\n",
      "Loss: tensor(0.1316, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1779\n",
      "Loss: tensor(0.1316, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1780\n",
      "Loss: tensor(0.1316, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1781\n",
      "Loss: tensor(0.1315, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1782\n",
      "Loss: tensor(0.1315, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1783\n",
      "Loss: tensor(0.1315, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1784\n",
      "Loss: tensor(0.1315, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1785\n",
      "Loss: tensor(0.1315, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1786\n",
      "Loss: tensor(0.1315, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1787\n",
      "Loss: tensor(0.1315, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1788\n",
      "Loss: tensor(0.1315, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1789\n",
      "Loss: tensor(0.1315, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1790\n",
      "Loss: tensor(0.1315, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1791\n",
      "Loss: tensor(0.1315, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1792\n",
      "Loss: tensor(0.1315, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1793\n",
      "Loss: tensor(0.1315, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1794\n",
      "Loss: tensor(0.1315, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1795\n",
      "Loss: tensor(0.1315, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1796\n",
      "Loss: tensor(0.1315, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1797\n",
      "Loss: tensor(0.1314, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1798\n",
      "Loss: tensor(0.1314, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1799\n",
      "Loss: tensor(0.1314, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1800\n",
      "Loss: tensor(0.1314, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1801\n",
      "Loss: tensor(0.1314, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1802\n",
      "Loss: tensor(0.1314, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1803\n",
      "Loss: tensor(0.1314, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1804\n",
      "Loss: tensor(0.1314, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1805\n",
      "Loss: tensor(0.1314, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1806\n",
      "Loss: tensor(0.1314, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1807\n",
      "Loss: tensor(0.1314, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1808\n",
      "Loss: tensor(0.1314, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1809\n",
      "Loss: tensor(0.1314, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1810\n",
      "Loss: tensor(0.1314, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1811\n",
      "Loss: tensor(0.1314, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1812\n",
      "Loss: tensor(0.1313, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1813\n",
      "Loss: tensor(0.1313, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1814\n",
      "Loss: tensor(0.1313, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1815\n",
      "Loss: tensor(0.1313, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1816\n",
      "Loss: tensor(0.1313, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1817\n",
      "Loss: tensor(0.1313, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1818\n",
      "Loss: tensor(0.1313, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1819\n",
      "Loss: tensor(0.1313, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1820\n",
      "Loss: tensor(0.1313, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1821\n",
      "Loss: tensor(0.1313, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1822\n",
      "Loss: tensor(0.1313, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1823\n",
      "Loss: tensor(0.1313, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1824\n",
      "Loss: tensor(0.1313, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1825\n",
      "Loss: tensor(0.1313, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1826\n",
      "Loss: tensor(0.1313, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1827\n",
      "Loss: tensor(0.1312, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1828\n",
      "Loss: tensor(0.1312, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1829\n",
      "Loss: tensor(0.1312, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1830\n",
      "Loss: tensor(0.1312, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1831\n",
      "Loss: tensor(0.1312, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1832\n",
      "Loss: tensor(0.1312, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1833\n",
      "Loss: tensor(0.1312, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1834\n",
      "Loss: tensor(0.1312, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1835\n",
      "Loss: tensor(0.1312, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1836\n",
      "Loss: tensor(0.1312, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1837\n",
      "Loss: tensor(0.1312, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1838\n",
      "Loss: tensor(0.1312, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1839\n",
      "Loss: tensor(0.1312, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1840\n",
      "Loss: tensor(0.1312, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1841\n",
      "Loss: tensor(0.1311, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1842\n",
      "Loss: tensor(0.1311, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1843\n",
      "Loss: tensor(0.1311, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1844\n",
      "Loss: tensor(0.1311, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1845\n",
      "Loss: tensor(0.1311, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1846\n",
      "Loss: tensor(0.1311, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1847\n",
      "Loss: tensor(0.1311, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1848\n",
      "Loss: tensor(0.1311, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1849\n",
      "Loss: tensor(0.1311, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1850\n",
      "Loss: tensor(0.1311, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1851\n",
      "Loss: tensor(0.1311, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1852\n",
      "Loss: tensor(0.1311, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1853\n",
      "Loss: tensor(0.1311, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1854\n",
      "Loss: tensor(0.1311, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1855\n",
      "Loss: tensor(0.1310, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1856\n",
      "Loss: tensor(0.1310, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1857\n",
      "Loss: tensor(0.1310, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1858\n",
      "Loss: tensor(0.1310, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1859\n",
      "Loss: tensor(0.1310, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1860\n",
      "Loss: tensor(0.1310, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1861\n",
      "Loss: tensor(0.1310, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1862\n",
      "Loss: tensor(0.1310, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1863\n",
      "Loss: tensor(0.1310, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1864\n",
      "Loss: tensor(0.1310, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1865\n",
      "Loss: tensor(0.1310, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1866\n",
      "Loss: tensor(0.1310, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1867\n",
      "Loss: tensor(0.1310, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1868\n",
      "Loss: tensor(0.1310, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1869\n",
      "Loss: tensor(0.1310, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1870\n",
      "Loss: tensor(0.1309, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1871\n",
      "Loss: tensor(0.1309, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1872\n",
      "Loss: tensor(0.1309, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1873\n",
      "Loss: tensor(0.1309, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1874\n",
      "Loss: tensor(0.1309, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1875\n",
      "Loss: tensor(0.1309, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1876\n",
      "Loss: tensor(0.1309, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1877\n",
      "Loss: tensor(0.1309, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1878\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor(0.1309, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1879\n",
      "Loss: tensor(0.1309, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1880\n",
      "Loss: tensor(0.1309, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1881\n",
      "Loss: tensor(0.1309, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1882\n",
      "Loss: tensor(0.1309, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1883\n",
      "Loss: tensor(0.1309, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1884\n",
      "Loss: tensor(0.1308, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1885\n",
      "Loss: tensor(0.1308, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1886\n",
      "Loss: tensor(0.1308, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1887\n",
      "Loss: tensor(0.1308, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1888\n",
      "Loss: tensor(0.1308, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1889\n",
      "Loss: tensor(0.1308, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1890\n",
      "Loss: tensor(0.1308, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1891\n",
      "Loss: tensor(0.1308, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1892\n",
      "Loss: tensor(0.1308, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1893\n",
      "Loss: tensor(0.1308, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1894\n",
      "Loss: tensor(0.1308, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1895\n",
      "Loss: tensor(0.1308, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1896\n",
      "Loss: tensor(0.1308, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1897\n",
      "Loss: tensor(0.1307, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1898\n",
      "Loss: tensor(0.1307, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1899\n",
      "Loss: tensor(0.1307, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1900\n",
      "Loss: tensor(0.1307, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1901\n",
      "Loss: tensor(0.1307, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1902\n",
      "Loss: tensor(0.1307, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1903\n",
      "Loss: tensor(0.1307, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1904\n",
      "Loss: tensor(0.1307, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1905\n",
      "Loss: tensor(0.1307, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1906\n",
      "Loss: tensor(0.1307, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1907\n",
      "Loss: tensor(0.1307, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1908\n",
      "Loss: tensor(0.1307, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1909\n",
      "Loss: tensor(0.1307, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1910\n",
      "Loss: tensor(0.1307, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1911\n",
      "Loss: tensor(0.1306, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1912\n",
      "Loss: tensor(0.1306, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1913\n",
      "Loss: tensor(0.1306, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1914\n",
      "Loss: tensor(0.1306, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1915\n",
      "Loss: tensor(0.1306, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1916\n",
      "Loss: tensor(0.1306, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1917\n",
      "Loss: tensor(0.1306, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1918\n",
      "Loss: tensor(0.1306, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1919\n",
      "Loss: tensor(0.1306, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1920\n",
      "Loss: tensor(0.1306, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1921\n",
      "Loss: tensor(0.1306, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1922\n",
      "Loss: tensor(0.1306, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1923\n",
      "Loss: tensor(0.1306, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1924\n",
      "Loss: tensor(0.1306, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1925\n",
      "Loss: tensor(0.1305, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1926\n",
      "Loss: tensor(0.1305, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1927\n",
      "Loss: tensor(0.1305, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1928\n",
      "Loss: tensor(0.1305, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1929\n",
      "Loss: tensor(0.1305, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1930\n",
      "Loss: tensor(0.1305, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1931\n",
      "Loss: tensor(0.1305, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1932\n",
      "Loss: tensor(0.1305, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1933\n",
      "Loss: tensor(0.1305, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1934\n",
      "Loss: tensor(0.1305, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1935\n",
      "Loss: tensor(0.1305, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1936\n",
      "Loss: tensor(0.1305, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1937\n",
      "Loss: tensor(0.1305, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1938\n",
      "Loss: tensor(0.1304, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1939\n",
      "Loss: tensor(0.1304, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1940\n",
      "Loss: tensor(0.1304, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1941\n",
      "Loss: tensor(0.1304, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1942\n",
      "Loss: tensor(0.1304, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1943\n",
      "Loss: tensor(0.1304, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1944\n",
      "Loss: tensor(0.1304, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1945\n",
      "Loss: tensor(0.1304, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1946\n",
      "Loss: tensor(0.1304, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1947\n",
      "Loss: tensor(0.1304, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1948\n",
      "Loss: tensor(0.1304, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1949\n",
      "Loss: tensor(0.1304, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1950\n",
      "Loss: tensor(0.1304, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1951\n",
      "Loss: tensor(0.1303, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1952\n",
      "Loss: tensor(0.1303, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1953\n",
      "Loss: tensor(0.1303, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1954\n",
      "Loss: tensor(0.1303, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1955\n",
      "Loss: tensor(0.1303, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1956\n",
      "Loss: tensor(0.1303, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1957\n",
      "Loss: tensor(0.1303, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1958\n",
      "Loss: tensor(0.1303, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1959\n",
      "Loss: tensor(0.1303, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1960\n",
      "Loss: tensor(0.1303, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1961\n",
      "Loss: tensor(0.1303, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1962\n",
      "Loss: tensor(0.1303, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1963\n",
      "Loss: tensor(0.1303, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1964\n",
      "Loss: tensor(0.1302, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1965\n",
      "Loss: tensor(0.1302, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1966\n",
      "Loss: tensor(0.1302, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1967\n",
      "Loss: tensor(0.1302, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1968\n",
      "Loss: tensor(0.1302, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1969\n",
      "Loss: tensor(0.1302, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1970\n",
      "Loss: tensor(0.1302, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1971\n",
      "Loss: tensor(0.1302, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1972\n",
      "Loss: tensor(0.1302, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1973\n",
      "Loss: tensor(0.1302, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1974\n",
      "Loss: tensor(0.1302, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1975\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor(0.1302, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1976\n",
      "Loss: tensor(0.1302, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1977\n",
      "Loss: tensor(0.1301, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1978\n",
      "Loss: tensor(0.1301, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1979\n",
      "Loss: tensor(0.1301, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1980\n",
      "Loss: tensor(0.1301, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1981\n",
      "Loss: tensor(0.1301, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1982\n",
      "Loss: tensor(0.1301, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1983\n",
      "Loss: tensor(0.1301, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1984\n",
      "Loss: tensor(0.1301, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1985\n",
      "Loss: tensor(0.1301, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1986\n",
      "Loss: tensor(0.1301, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1987\n",
      "Loss: tensor(0.1301, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1988\n",
      "Loss: tensor(0.1301, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1989\n",
      "Loss: tensor(0.1301, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1990\n",
      "Loss: tensor(0.1300, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1991\n",
      "Loss: tensor(0.1300, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1992\n",
      "Loss: tensor(0.1300, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1993\n",
      "Loss: tensor(0.1300, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1994\n",
      "Loss: tensor(0.1300, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1995\n",
      "Loss: tensor(0.1300, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1996\n",
      "Loss: tensor(0.1300, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1997\n",
      "Loss: tensor(0.1300, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1998\n",
      "Loss: tensor(0.1300, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1999\n",
      "Loss: tensor(0.1300, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2000\n",
      "Loss: tensor(0.1300, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2001\n",
      "Loss: tensor(0.1300, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2002\n",
      "Loss: tensor(0.1299, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2003\n",
      "Loss: tensor(0.1299, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2004\n",
      "Loss: tensor(0.1299, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2005\n",
      "Loss: tensor(0.1299, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2006\n",
      "Loss: tensor(0.1299, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2007\n",
      "Loss: tensor(0.1299, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2008\n",
      "Loss: tensor(0.1299, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2009\n",
      "Loss: tensor(0.1299, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2010\n",
      "Loss: tensor(0.1299, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2011\n",
      "Loss: tensor(0.1299, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2012\n",
      "Loss: tensor(0.1299, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2013\n",
      "Loss: tensor(0.1299, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2014\n",
      "Loss: tensor(0.1298, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2015\n",
      "Loss: tensor(0.1298, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2016\n",
      "Loss: tensor(0.1298, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2017\n",
      "Loss: tensor(0.1298, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2018\n",
      "Loss: tensor(0.1298, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2019\n",
      "Loss: tensor(0.1298, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2020\n",
      "Loss: tensor(0.1298, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2021\n",
      "Loss: tensor(0.1298, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2022\n",
      "Loss: tensor(0.1298, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2023\n",
      "Loss: tensor(0.1298, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2024\n",
      "Loss: tensor(0.1298, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2025\n",
      "Loss: tensor(0.1298, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2026\n",
      "Loss: tensor(0.1297, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2027\n",
      "Loss: tensor(0.1297, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2028\n",
      "Loss: tensor(0.1297, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2029\n",
      "Loss: tensor(0.1297, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2030\n",
      "Loss: tensor(0.1297, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2031\n",
      "Loss: tensor(0.1297, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2032\n",
      "Loss: tensor(0.1297, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2033\n",
      "Loss: tensor(0.1297, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2034\n",
      "Loss: tensor(0.1297, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2035\n",
      "Loss: tensor(0.1297, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2036\n",
      "Loss: tensor(0.1297, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2037\n",
      "Loss: tensor(0.1297, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2038\n",
      "Loss: tensor(0.1296, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2039\n",
      "Loss: tensor(0.1296, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2040\n",
      "Loss: tensor(0.1296, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2041\n",
      "Loss: tensor(0.1296, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2042\n",
      "Loss: tensor(0.1296, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2043\n",
      "Loss: tensor(0.1296, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2044\n",
      "Loss: tensor(0.1296, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2045\n",
      "Loss: tensor(0.1296, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2046\n",
      "Loss: tensor(0.1296, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2047\n",
      "Loss: tensor(0.1296, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2048\n",
      "Loss: tensor(0.1296, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2049\n",
      "Loss: tensor(0.1295, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2050\n",
      "Loss: tensor(0.1295, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2051\n",
      "Loss: tensor(0.1295, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2052\n",
      "Loss: tensor(0.1295, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2053\n",
      "Loss: tensor(0.1295, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2054\n",
      "Loss: tensor(0.1295, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2055\n",
      "Loss: tensor(0.1295, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2056\n",
      "Loss: tensor(0.1295, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2057\n",
      "Loss: tensor(0.1295, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2058\n",
      "Loss: tensor(0.1295, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2059\n",
      "Loss: tensor(0.1295, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2060\n",
      "Loss: tensor(0.1295, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2061\n",
      "Loss: tensor(0.1294, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2062\n",
      "Loss: tensor(0.1294, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2063\n",
      "Loss: tensor(0.1294, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2064\n",
      "Loss: tensor(0.1294, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2065\n",
      "Loss: tensor(0.1294, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2066\n",
      "Loss: tensor(0.1294, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2067\n",
      "Loss: tensor(0.1294, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2068\n",
      "Loss: tensor(0.1294, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2069\n",
      "Loss: tensor(0.1294, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2070\n",
      "Loss: tensor(0.1294, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2071\n",
      "Loss: tensor(0.1293, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2072\n",
      "Loss: tensor(0.1293, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2073\n",
      "Loss: tensor(0.1293, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2074\n",
      "Loss: tensor(0.1293, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2075\n",
      "Loss: tensor(0.1293, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2076\n",
      "Loss: tensor(0.1293, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2077\n",
      "Loss: tensor(0.1293, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2078\n",
      "Loss: tensor(0.1293, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2079\n",
      "Loss: tensor(0.1293, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2080\n",
      "Loss: tensor(0.1293, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2081\n",
      "Loss: tensor(0.1293, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2082\n",
      "Loss: tensor(0.1292, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2083\n",
      "Loss: tensor(0.1292, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2084\n",
      "Loss: tensor(0.1292, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2085\n",
      "Loss: tensor(0.1292, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2086\n",
      "Loss: tensor(0.1292, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2087\n",
      "Loss: tensor(0.1292, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2088\n",
      "Loss: tensor(0.1292, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2089\n",
      "Loss: tensor(0.1292, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2090\n",
      "Loss: tensor(0.1292, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2091\n",
      "Loss: tensor(0.1292, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2092\n",
      "Loss: tensor(0.1291, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2093\n",
      "Loss: tensor(0.1291, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2094\n",
      "Loss: tensor(0.1291, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2095\n",
      "Loss: tensor(0.1291, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2096\n",
      "Loss: tensor(0.1291, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2097\n",
      "Loss: tensor(0.1291, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2098\n",
      "Loss: tensor(0.1291, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2099\n",
      "Loss: tensor(0.1291, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2100\n",
      "Loss: tensor(0.1291, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2101\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor(0.1291, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2102\n",
      "Loss: tensor(0.1290, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2103\n",
      "Loss: tensor(0.1290, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2104\n",
      "Loss: tensor(0.1290, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2105\n",
      "Loss: tensor(0.1290, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2106\n",
      "Loss: tensor(0.1290, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2107\n",
      "Loss: tensor(0.1290, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2108\n",
      "Loss: tensor(0.1290, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2109\n",
      "Loss: tensor(0.1290, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2110\n",
      "Loss: tensor(0.1290, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2111\n",
      "Loss: tensor(0.1290, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2112\n",
      "Loss: tensor(0.1289, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2113\n",
      "Loss: tensor(0.1289, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2114\n",
      "Loss: tensor(0.1289, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2115\n",
      "Loss: tensor(0.1289, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2116\n",
      "Loss: tensor(0.1289, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2117\n",
      "Loss: tensor(0.1289, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2118\n",
      "Loss: tensor(0.1289, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2119\n",
      "Loss: tensor(0.1289, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2120\n",
      "Loss: tensor(0.1289, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2121\n",
      "Loss: tensor(0.1289, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2122\n",
      "Loss: tensor(0.1288, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2123\n",
      "Loss: tensor(0.1288, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2124\n",
      "Loss: tensor(0.1288, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2125\n",
      "Loss: tensor(0.1288, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2126\n",
      "Loss: tensor(0.1288, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2127\n",
      "Loss: tensor(0.1288, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2128\n",
      "Loss: tensor(0.1288, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2129\n",
      "Loss: tensor(0.1288, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2130\n",
      "Loss: tensor(0.1288, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2131\n",
      "Loss: tensor(0.1287, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2132\n",
      "Loss: tensor(0.1287, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2133\n",
      "Loss: tensor(0.1287, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2134\n",
      "Loss: tensor(0.1287, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2135\n",
      "Loss: tensor(0.1287, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2136\n",
      "Loss: tensor(0.1287, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2137\n",
      "Loss: tensor(0.1287, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2138\n",
      "Loss: tensor(0.1287, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2139\n",
      "Loss: tensor(0.1287, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2140\n",
      "Loss: tensor(0.1286, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2141\n",
      "Loss: tensor(0.1286, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2142\n",
      "Loss: tensor(0.1286, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2143\n",
      "Loss: tensor(0.1286, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2144\n",
      "Loss: tensor(0.1286, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2145\n",
      "Loss: tensor(0.1286, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2146\n",
      "Loss: tensor(0.1286, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2147\n",
      "Loss: tensor(0.1286, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2148\n",
      "Loss: tensor(0.1286, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2149\n",
      "Loss: tensor(0.1285, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2150\n",
      "Loss: tensor(0.1285, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2151\n",
      "Loss: tensor(0.1285, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2152\n",
      "Loss: tensor(0.1285, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2153\n",
      "Loss: tensor(0.1285, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2154\n",
      "Loss: tensor(0.1285, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2155\n",
      "Loss: tensor(0.1285, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2156\n",
      "Loss: tensor(0.1285, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2157\n",
      "Loss: tensor(0.1285, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2158\n",
      "Loss: tensor(0.1284, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2159\n",
      "Loss: tensor(0.1284, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2160\n",
      "Loss: tensor(0.1284, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2161\n",
      "Loss: tensor(0.1284, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2162\n",
      "Loss: tensor(0.1284, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2163\n",
      "Loss: tensor(0.1284, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2164\n",
      "Loss: tensor(0.1284, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2165\n",
      "Loss: tensor(0.1284, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2166\n",
      "Loss: tensor(0.1283, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2167\n",
      "Loss: tensor(0.1283, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2168\n",
      "Loss: tensor(0.1283, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2169\n",
      "Loss: tensor(0.1283, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2170\n",
      "Loss: tensor(0.1283, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2171\n",
      "Loss: tensor(0.1283, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2172\n",
      "Loss: tensor(0.1283, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2173\n",
      "Loss: tensor(0.1283, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2174\n",
      "Loss: tensor(0.1282, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2175\n",
      "Loss: tensor(0.1282, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2176\n",
      "Loss: tensor(0.1282, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2177\n",
      "Loss: tensor(0.1282, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2178\n",
      "Loss: tensor(0.1282, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2179\n",
      "Loss: tensor(0.1282, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2180\n",
      "Loss: tensor(0.1282, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2181\n",
      "Loss: tensor(0.1282, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2182\n",
      "Loss: tensor(0.1281, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2183\n",
      "Loss: tensor(0.1281, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2184\n",
      "Loss: tensor(0.1281, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2185\n",
      "Loss: tensor(0.1281, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2186\n",
      "Loss: tensor(0.1281, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2187\n",
      "Loss: tensor(0.1281, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2188\n",
      "Loss: tensor(0.1281, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2189\n",
      "Loss: tensor(0.1281, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2190\n",
      "Loss: tensor(0.1280, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2191\n",
      "Loss: tensor(0.1280, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2192\n",
      "Loss: tensor(0.1280, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2193\n",
      "Loss: tensor(0.1280, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2194\n",
      "Loss: tensor(0.1280, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2195\n",
      "Loss: tensor(0.1280, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2196\n",
      "Loss: tensor(0.1280, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2197\n",
      "Loss: tensor(0.1280, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2198\n",
      "Loss: tensor(0.1279, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2199\n",
      "Loss: tensor(0.1279, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2200\n",
      "Loss: tensor(0.1279, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2201\n",
      "Loss: tensor(0.1279, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2202\n",
      "Loss: tensor(0.1279, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2203\n",
      "Loss: tensor(0.1279, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2204\n",
      "Loss: tensor(0.1279, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2205\n",
      "Loss: tensor(0.1279, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2206\n",
      "Loss: tensor(0.1278, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2207\n",
      "Loss: tensor(0.1278, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2208\n",
      "Loss: tensor(0.1278, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2209\n",
      "Loss: tensor(0.1278, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2210\n",
      "Loss: tensor(0.1278, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2211\n",
      "Loss: tensor(0.1278, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2212\n",
      "Loss: tensor(0.1278, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2213\n",
      "Loss: tensor(0.1278, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2214\n",
      "Loss: tensor(0.1277, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2215\n",
      "Loss: tensor(0.1277, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2216\n",
      "Loss: tensor(0.1277, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2217\n",
      "Loss: tensor(0.1277, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2218\n",
      "Loss: tensor(0.1277, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2219\n",
      "Loss: tensor(0.1277, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2220\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor(0.1277, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2221\n",
      "Loss: tensor(0.1276, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2222\n",
      "Loss: tensor(0.1276, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2223\n",
      "Loss: tensor(0.1276, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2224\n",
      "Loss: tensor(0.1276, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2225\n",
      "Loss: tensor(0.1276, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2226\n",
      "Loss: tensor(0.1276, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2227\n",
      "Loss: tensor(0.1276, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2228\n",
      "Loss: tensor(0.1275, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2229\n",
      "Loss: tensor(0.1275, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2230\n",
      "Loss: tensor(0.1275, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2231\n",
      "Loss: tensor(0.1275, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2232\n",
      "Loss: tensor(0.1275, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2233\n",
      "Loss: tensor(0.1275, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2234\n",
      "Loss: tensor(0.1275, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2235\n",
      "Loss: tensor(0.1275, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2236\n",
      "Loss: tensor(0.1274, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2237\n",
      "Loss: tensor(0.1274, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2238\n",
      "Loss: tensor(0.1274, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2239\n",
      "Loss: tensor(0.1274, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2240\n",
      "Loss: tensor(0.1274, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2241\n",
      "Loss: tensor(0.1274, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2242\n",
      "Loss: tensor(0.1274, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2243\n",
      "Loss: tensor(0.1273, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2244\n",
      "Loss: tensor(0.1273, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2245\n",
      "Loss: tensor(0.1273, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2246\n",
      "Loss: tensor(0.1273, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2247\n",
      "Loss: tensor(0.1273, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2248\n",
      "Loss: tensor(0.1273, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2249\n",
      "Loss: tensor(0.1273, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2250\n",
      "Loss: tensor(0.1272, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2251\n",
      "Loss: tensor(0.1272, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2252\n",
      "Loss: tensor(0.1272, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2253\n",
      "Loss: tensor(0.1272, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2254\n",
      "Loss: tensor(0.1272, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2255\n",
      "Loss: tensor(0.1272, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2256\n",
      "Loss: tensor(0.1272, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2257\n",
      "Loss: tensor(0.1271, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2258\n",
      "Loss: tensor(0.1271, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2259\n",
      "Loss: tensor(0.1271, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2260\n",
      "Loss: tensor(0.1271, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2261\n",
      "Loss: tensor(0.1271, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2262\n",
      "Loss: tensor(0.1271, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2263\n",
      "Loss: tensor(0.1271, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2264\n",
      "Loss: tensor(0.1270, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2265\n",
      "Loss: tensor(0.1270, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2266\n",
      "Loss: tensor(0.1270, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2267\n",
      "Loss: tensor(0.1270, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2268\n",
      "Loss: tensor(0.1270, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2269\n",
      "Loss: tensor(0.1270, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2270\n",
      "Loss: tensor(0.1270, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2271\n",
      "Loss: tensor(0.1269, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2272\n",
      "Loss: tensor(0.1269, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2273\n",
      "Loss: tensor(0.1269, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2274\n",
      "Loss: tensor(0.1269, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2275\n",
      "Loss: tensor(0.1269, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2276\n",
      "Loss: tensor(0.1269, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2277\n",
      "Loss: tensor(0.1268, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2278\n",
      "Loss: tensor(0.1268, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2279\n",
      "Loss: tensor(0.1268, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2280\n",
      "Loss: tensor(0.1268, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2281\n",
      "Loss: tensor(0.1268, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2282\n",
      "Loss: tensor(0.1268, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2283\n",
      "Loss: tensor(0.1268, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2284\n",
      "Loss: tensor(0.1267, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2285\n",
      "Loss: tensor(0.1267, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2286\n",
      "Loss: tensor(0.1267, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2287\n",
      "Loss: tensor(0.1267, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2288\n",
      "Loss: tensor(0.1267, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2289\n",
      "Loss: tensor(0.1267, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2290\n",
      "Loss: tensor(0.1267, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2291\n",
      "Loss: tensor(0.1266, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2292\n",
      "Loss: tensor(0.1266, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2293\n",
      "Loss: tensor(0.1266, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2294\n",
      "Loss: tensor(0.1266, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2295\n",
      "Loss: tensor(0.1266, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2296\n",
      "Loss: tensor(0.1266, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2297\n",
      "Loss: tensor(0.1266, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2298\n",
      "Loss: tensor(0.1265, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2299\n",
      "Loss: tensor(0.1265, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2300\n",
      "Loss: tensor(0.1265, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2301\n",
      "Loss: tensor(0.1265, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2302\n",
      "Loss: tensor(0.1265, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2303\n",
      "Loss: tensor(0.1265, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2304\n",
      "Loss: tensor(0.1264, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2305\n",
      "Loss: tensor(0.1264, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2306\n",
      "Loss: tensor(0.1264, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2307\n",
      "Loss: tensor(0.1264, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2308\n",
      "Loss: tensor(0.1264, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2309\n",
      "Loss: tensor(0.1264, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2310\n",
      "Loss: tensor(0.1263, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2311\n",
      "Loss: tensor(0.1263, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2312\n",
      "Loss: tensor(0.1263, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2313\n",
      "Loss: tensor(0.1263, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2314\n",
      "Loss: tensor(0.1263, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2315\n",
      "Loss: tensor(0.1263, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2316\n",
      "Loss: tensor(0.1263, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2317\n",
      "Loss: tensor(0.1262, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2318\n",
      "Loss: tensor(0.1262, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2319\n",
      "Loss: tensor(0.1262, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2320\n",
      "Loss: tensor(0.1262, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2321\n",
      "Loss: tensor(0.1262, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2322\n",
      "Loss: tensor(0.1262, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2323\n",
      "Loss: tensor(0.1261, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2324\n",
      "Loss: tensor(0.1261, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2325\n",
      "Loss: tensor(0.1261, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2326\n",
      "Loss: tensor(0.1261, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2327\n",
      "Loss: tensor(0.1261, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2328\n",
      "Loss: tensor(0.1261, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2329\n",
      "Loss: tensor(0.1261, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2330\n",
      "Loss: tensor(0.1260, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2331\n",
      "Loss: tensor(0.1260, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2332\n",
      "Loss: tensor(0.1260, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2333\n",
      "Loss: tensor(0.1260, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2334\n",
      "Loss: tensor(0.1260, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2335\n",
      "Loss: tensor(0.1260, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2336\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2337\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2338\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2339\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2340\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2341\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2342\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2343\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2344\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2345\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2346\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2347\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2348\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2349\n",
      "Loss: tensor(0.1257, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2350\n",
      "Loss: tensor(0.1257, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2351\n",
      "Loss: tensor(0.1257, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2352\n",
      "Loss: tensor(0.1257, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2353\n",
      "Loss: tensor(0.1257, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2354\n",
      "Loss: tensor(0.1257, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2355\n",
      "Loss: tensor(0.1256, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2356\n",
      "Loss: tensor(0.1256, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2357\n",
      "Loss: tensor(0.1256, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2358\n",
      "Loss: tensor(0.1256, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2359\n",
      "Loss: tensor(0.1256, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2360\n",
      "Loss: tensor(0.1256, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2361\n",
      "Loss: tensor(0.1255, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2362\n",
      "Loss: tensor(0.1255, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2363\n",
      "Loss: tensor(0.1255, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2364\n",
      "Loss: tensor(0.1255, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2365\n",
      "Loss: tensor(0.1255, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2366\n",
      "Loss: tensor(0.1255, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2367\n",
      "Loss: tensor(0.1254, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2368\n",
      "Loss: tensor(0.1254, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2369\n",
      "Loss: tensor(0.1254, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2370\n",
      "Loss: tensor(0.1254, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2371\n",
      "Loss: tensor(0.1254, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2372\n",
      "Loss: tensor(0.1254, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2373\n",
      "Loss: tensor(0.1253, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2374\n",
      "Loss: tensor(0.1253, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2375\n",
      "Loss: tensor(0.1253, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2376\n",
      "Loss: tensor(0.1253, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2377\n",
      "Loss: tensor(0.1253, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2378\n",
      "Loss: tensor(0.1253, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2379\n",
      "Loss: tensor(0.1253, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2380\n",
      "Loss: tensor(0.1252, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2381\n",
      "Loss: tensor(0.1252, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2382\n",
      "Loss: tensor(0.1252, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2383\n",
      "Loss: tensor(0.1252, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2384\n",
      "Loss: tensor(0.1252, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2385\n",
      "Loss: tensor(0.1252, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2386\n",
      "Loss: tensor(0.1251, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2387\n",
      "Loss: tensor(0.1251, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2388\n",
      "Loss: tensor(0.1251, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2389\n",
      "Loss: tensor(0.1251, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2390\n",
      "Loss: tensor(0.1251, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2391\n",
      "Loss: tensor(0.1251, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2392\n",
      "Loss: tensor(0.1250, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2393\n",
      "Loss: tensor(0.1250, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2394\n",
      "Loss: tensor(0.1250, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2395\n",
      "Loss: tensor(0.1250, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2396\n",
      "Loss: tensor(0.1250, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2397\n",
      "Loss: tensor(0.1250, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2398\n",
      "Loss: tensor(0.1249, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2399\n",
      "Loss: tensor(0.1249, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2400\n",
      "Loss: tensor(0.1249, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2401\n",
      "Loss: tensor(0.1249, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2402\n",
      "Loss: tensor(0.1249, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2403\n",
      "Loss: tensor(0.1249, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2404\n",
      "Loss: tensor(0.1248, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2405\n",
      "Loss: tensor(0.1248, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2406\n",
      "Loss: tensor(0.1248, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2407\n",
      "Loss: tensor(0.1248, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2408\n",
      "Loss: tensor(0.1248, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2409\n",
      "Loss: tensor(0.1248, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2410\n",
      "Loss: tensor(0.1247, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2411\n",
      "Loss: tensor(0.1247, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2412\n",
      "Loss: tensor(0.1247, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2413\n",
      "Loss: tensor(0.1247, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2414\n",
      "Loss: tensor(0.1247, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2415\n",
      "Loss: tensor(0.1247, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2416\n",
      "Loss: tensor(0.1246, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2417\n",
      "Loss: tensor(0.1246, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2418\n",
      "Loss: tensor(0.1246, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2419\n",
      "Loss: tensor(0.1246, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2420\n",
      "Loss: tensor(0.1246, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2421\n",
      "Loss: tensor(0.1246, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2422\n",
      "Loss: tensor(0.1245, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2423\n",
      "Loss: tensor(0.1245, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2424\n",
      "Loss: tensor(0.1245, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2425\n",
      "Loss: tensor(0.1245, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2426\n",
      "Loss: tensor(0.1245, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2427\n",
      "Loss: tensor(0.1245, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2428\n",
      "Loss: tensor(0.1244, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2429\n",
      "Loss: tensor(0.1244, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2430\n",
      "Loss: tensor(0.1244, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2431\n",
      "Loss: tensor(0.1244, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2432\n",
      "Loss: tensor(0.1244, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2433\n",
      "Loss: tensor(0.1244, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2434\n",
      "Loss: tensor(0.1243, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2435\n",
      "Loss: tensor(0.1243, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2436\n",
      "Loss: tensor(0.1243, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2437\n",
      "Loss: tensor(0.1243, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2438\n",
      "Loss: tensor(0.1243, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2439\n",
      "Loss: tensor(0.1243, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2440\n",
      "Loss: tensor(0.1242, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2441\n",
      "Loss: tensor(0.1242, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2442\n",
      "Loss: tensor(0.1242, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2443\n",
      "Loss: tensor(0.1242, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2444\n",
      "Loss: tensor(0.1242, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2445\n",
      "Loss: tensor(0.1242, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2446\n",
      "Loss: tensor(0.1241, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2447\n",
      "Loss: tensor(0.1241, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2448\n",
      "Loss: tensor(0.1241, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2449\n",
      "Loss: tensor(0.1241, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2450\n",
      "Loss: tensor(0.1241, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2451\n",
      "Loss: tensor(0.1241, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2452\n",
      "Loss: tensor(0.1240, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2453\n",
      "Loss: tensor(0.1240, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2454\n",
      "Loss: tensor(0.1240, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2455\n",
      "Loss: tensor(0.1240, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2456\n",
      "Loss: tensor(0.1240, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2457\n",
      "Loss: tensor(0.1240, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2458\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor(0.1239, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2459\n",
      "Loss: tensor(0.1239, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2460\n",
      "Loss: tensor(0.1239, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2461\n",
      "Loss: tensor(0.1239, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2462\n",
      "Loss: tensor(0.1239, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2463\n",
      "Loss: tensor(0.1239, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2464\n",
      "Loss: tensor(0.1238, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2465\n",
      "Loss: tensor(0.1238, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2466\n",
      "Loss: tensor(0.1238, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2467\n",
      "Loss: tensor(0.1238, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2468\n",
      "Loss: tensor(0.1238, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2469\n",
      "Loss: tensor(0.1238, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2470\n",
      "Loss: tensor(0.1237, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2471\n",
      "Loss: tensor(0.1237, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2472\n",
      "Loss: tensor(0.1237, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2473\n",
      "Loss: tensor(0.1237, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2474\n",
      "Loss: tensor(0.1237, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2475\n",
      "Loss: tensor(0.1237, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2476\n",
      "Loss: tensor(0.1236, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2477\n",
      "Loss: tensor(0.1236, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2478\n",
      "Loss: tensor(0.1236, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2479\n",
      "Loss: tensor(0.1236, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2480\n",
      "Loss: tensor(0.1236, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2481\n",
      "Loss: tensor(0.1236, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2482\n",
      "Loss: tensor(0.1235, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2483\n",
      "Loss: tensor(0.1235, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2484\n",
      "Loss: tensor(0.1235, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2485\n",
      "Loss: tensor(0.1235, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2486\n",
      "Loss: tensor(0.1235, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2487\n",
      "Loss: tensor(0.1235, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2488\n",
      "Loss: tensor(0.1234, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2489\n",
      "Loss: tensor(0.1234, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2490\n",
      "Loss: tensor(0.1234, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2491\n",
      "Loss: tensor(0.1234, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2492\n",
      "Loss: tensor(0.1234, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2493\n",
      "Loss: tensor(0.1234, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2494\n",
      "Loss: tensor(0.1233, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2495\n",
      "Loss: tensor(0.1233, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2496\n",
      "Loss: tensor(0.1233, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2497\n",
      "Loss: tensor(0.1233, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2498\n",
      "Loss: tensor(0.1233, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2499\n",
      "Loss: tensor(0.1232, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2500\n",
      "Loss: tensor(0.1232, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2501\n",
      "Loss: tensor(0.1232, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2502\n",
      "Loss: tensor(0.1232, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2503\n",
      "Loss: tensor(0.1232, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2504\n",
      "Loss: tensor(0.1232, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2505\n",
      "Loss: tensor(0.1231, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2506\n",
      "Loss: tensor(0.1231, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2507\n",
      "Loss: tensor(0.1231, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2508\n",
      "Loss: tensor(0.1231, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2509\n",
      "Loss: tensor(0.1231, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2510\n",
      "Loss: tensor(0.1231, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2511\n",
      "Loss: tensor(0.1230, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2512\n",
      "Loss: tensor(0.1230, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2513\n",
      "Loss: tensor(0.1230, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2514\n",
      "Loss: tensor(0.1230, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2515\n",
      "Loss: tensor(0.1230, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2516\n",
      "Loss: tensor(0.1230, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2517\n",
      "Loss: tensor(0.1229, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2518\n",
      "Loss: tensor(0.1229, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2519\n",
      "Loss: tensor(0.1229, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2520\n",
      "Loss: tensor(0.1229, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2521\n",
      "Loss: tensor(0.1229, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2522\n",
      "Loss: tensor(0.1229, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2523\n",
      "Loss: tensor(0.1228, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2524\n",
      "Loss: tensor(0.1228, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2525\n",
      "Loss: tensor(0.1228, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2526\n",
      "Loss: tensor(0.1228, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2527\n",
      "Loss: tensor(0.1228, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2528\n",
      "Loss: tensor(0.1228, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2529\n",
      "Loss: tensor(0.1227, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2530\n",
      "Loss: tensor(0.1227, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2531\n",
      "Loss: tensor(0.1227, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2532\n",
      "Loss: tensor(0.1227, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2533\n",
      "Loss: tensor(0.1227, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2534\n",
      "Loss: tensor(0.1227, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2535\n",
      "Loss: tensor(0.1226, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2536\n",
      "Loss: tensor(0.1226, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2537\n",
      "Loss: tensor(0.1226, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2538\n",
      "Loss: tensor(0.1226, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2539\n",
      "Loss: tensor(0.1226, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2540\n",
      "Loss: tensor(0.1225, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2541\n",
      "Loss: tensor(0.1225, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2542\n",
      "Loss: tensor(0.1225, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2543\n",
      "Loss: tensor(0.1225, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2544\n",
      "Loss: tensor(0.1225, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2545\n",
      "Loss: tensor(0.1225, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2546\n",
      "Loss: tensor(0.1224, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2547\n",
      "Loss: tensor(0.1224, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2548\n",
      "Loss: tensor(0.1224, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2549\n",
      "Loss: tensor(0.1224, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2550\n",
      "Loss: tensor(0.1224, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2551\n",
      "Loss: tensor(0.1224, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2552\n",
      "Loss: tensor(0.1223, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2553\n",
      "Loss: tensor(0.1223, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2554\n",
      "Loss: tensor(0.1223, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2555\n",
      "Loss: tensor(0.1223, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2556\n",
      "Loss: tensor(0.1223, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2557\n",
      "Loss: tensor(0.1223, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2558\n",
      "Loss: tensor(0.1222, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2559\n",
      "Loss: tensor(0.1222, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2560\n",
      "Loss: tensor(0.1222, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2561\n",
      "Loss: tensor(0.1222, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2562\n",
      "Loss: tensor(0.1222, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2563\n",
      "Loss: tensor(0.1222, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2564\n",
      "Loss: tensor(0.1221, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2565\n",
      "Loss: tensor(0.1221, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2566\n",
      "Loss: tensor(0.1221, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2567\n",
      "Loss: tensor(0.1221, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2568\n",
      "Loss: tensor(0.1221, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2569\n",
      "Loss: tensor(0.1221, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2570\n",
      "Loss: tensor(0.1220, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2571\n",
      "Loss: tensor(0.1220, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2572\n",
      "Loss: tensor(0.1220, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2573\n",
      "Loss: tensor(0.1220, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2574\n",
      "Loss: tensor(0.1220, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2575\n",
      "Loss: tensor(0.1220, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2576\n",
      "Loss: tensor(0.1219, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2577\n",
      "Loss: tensor(0.1219, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2578\n",
      "Loss: tensor(0.1219, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2579\n",
      "Loss: tensor(0.1219, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2580\n",
      "Loss: tensor(0.1219, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2581\n",
      "Loss: tensor(0.1218, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2582\n",
      "Loss: tensor(0.1218, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2583\n",
      "Loss: tensor(0.1218, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2584\n",
      "Loss: tensor(0.1218, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2585\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor(0.1218, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2586\n",
      "Loss: tensor(0.1218, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2587\n",
      "Loss: tensor(0.1217, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2588\n",
      "Loss: tensor(0.1217, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2589\n",
      "Loss: tensor(0.1217, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2590\n",
      "Loss: tensor(0.1217, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2591\n",
      "Loss: tensor(0.1217, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2592\n",
      "Loss: tensor(0.1217, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2593\n",
      "Loss: tensor(0.1216, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2594\n",
      "Loss: tensor(0.1216, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2595\n",
      "Loss: tensor(0.1216, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2596\n",
      "Loss: tensor(0.1216, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2597\n",
      "Loss: tensor(0.1216, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2598\n",
      "Loss: tensor(0.1216, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2599\n",
      "Loss: tensor(0.1215, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2600\n",
      "Loss: tensor(0.1215, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2601\n",
      "Loss: tensor(0.1215, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2602\n",
      "Loss: tensor(0.1215, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2603\n",
      "Loss: tensor(0.1215, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2604\n",
      "Loss: tensor(0.1215, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2605\n",
      "Loss: tensor(0.1215, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2606\n",
      "Loss: tensor(0.1214, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2607\n",
      "Loss: tensor(0.1214, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2608\n",
      "Loss: tensor(0.1214, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2609\n",
      "Loss: tensor(0.1214, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2610\n",
      "Loss: tensor(0.1214, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2611\n",
      "Loss: tensor(0.1213, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2612\n",
      "Loss: tensor(0.1213, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2613\n",
      "Loss: tensor(0.1213, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2614\n",
      "Loss: tensor(0.1213, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2615\n",
      "Loss: tensor(0.1213, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2616\n",
      "Loss: tensor(0.1213, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2617\n",
      "Loss: tensor(0.1212, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2618\n",
      "Loss: tensor(0.1212, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2619\n",
      "Loss: tensor(0.1212, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2620\n",
      "Loss: tensor(0.1212, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2621\n",
      "Loss: tensor(0.1212, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2622\n",
      "Loss: tensor(0.1211, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2623\n",
      "Loss: tensor(0.1211, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2624\n",
      "Loss: tensor(0.1211, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2625\n",
      "Loss: tensor(0.1211, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2626\n",
      "Loss: tensor(0.1211, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2627\n",
      "Loss: tensor(0.1211, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2628\n",
      "Loss: tensor(0.1210, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2629\n",
      "Loss: tensor(0.1210, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2630\n",
      "Loss: tensor(0.1210, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2631\n",
      "Loss: tensor(0.1210, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2632\n",
      "Loss: tensor(0.1210, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2633\n",
      "Loss: tensor(0.1210, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2634\n",
      "Loss: tensor(0.1209, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2635\n",
      "Loss: tensor(0.1209, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2636\n",
      "Loss: tensor(0.1209, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2637\n",
      "Loss: tensor(0.1209, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2638\n",
      "Loss: tensor(0.1209, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2639\n",
      "Loss: tensor(0.1209, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2640\n",
      "Loss: tensor(0.1208, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2641\n",
      "Loss: tensor(0.1208, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2642\n",
      "Loss: tensor(0.1208, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2643\n",
      "Loss: tensor(0.1208, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2644\n",
      "Loss: tensor(0.1208, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2645\n",
      "Loss: tensor(0.1208, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2646\n",
      "Loss: tensor(0.1207, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2647\n",
      "Loss: tensor(0.1207, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2648\n",
      "Loss: tensor(0.1207, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2649\n",
      "Loss: tensor(0.1207, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2650\n",
      "Loss: tensor(0.1207, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2651\n",
      "Loss: tensor(0.1207, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2652\n",
      "Loss: tensor(0.1206, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2653\n",
      "Loss: tensor(0.1206, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2654\n",
      "Loss: tensor(0.1206, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2655\n",
      "Loss: tensor(0.1206, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2656\n",
      "Loss: tensor(0.1206, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2657\n",
      "Loss: tensor(0.1206, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2658\n",
      "Loss: tensor(0.1206, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2659\n",
      "Loss: tensor(0.1205, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2660\n",
      "Loss: tensor(0.1205, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2661\n",
      "Loss: tensor(0.1205, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2662\n",
      "Loss: tensor(0.1205, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2663\n",
      "Loss: tensor(0.1205, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2664\n",
      "Loss: tensor(0.1204, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2665\n",
      "Loss: tensor(0.1204, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2666\n",
      "Loss: tensor(0.1204, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2667\n",
      "Loss: tensor(0.1204, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2668\n",
      "Loss: tensor(0.1204, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2669\n",
      "Loss: tensor(0.1204, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2670\n",
      "Loss: tensor(0.1203, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2671\n",
      "Loss: tensor(0.1203, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2672\n",
      "Loss: tensor(0.1203, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2673\n",
      "Loss: tensor(0.1203, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2674\n",
      "Loss: tensor(0.1203, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2675\n",
      "Loss: tensor(0.1203, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2676\n",
      "Loss: tensor(0.1202, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2677\n",
      "Loss: tensor(0.1202, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2678\n",
      "Loss: tensor(0.1202, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2679\n",
      "Loss: tensor(0.1202, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2680\n",
      "Loss: tensor(0.1202, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2681\n",
      "Loss: tensor(0.1202, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2682\n",
      "Loss: tensor(0.1201, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2683\n",
      "Loss: tensor(0.1201, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2684\n",
      "Loss: tensor(0.1201, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2685\n",
      "Loss: tensor(0.1201, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2686\n",
      "Loss: tensor(0.1201, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2687\n",
      "Loss: tensor(0.1201, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2688\n",
      "Loss: tensor(0.1200, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2689\n",
      "Loss: tensor(0.1200, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2690\n",
      "Loss: tensor(0.1200, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2691\n",
      "Loss: tensor(0.1200, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2692\n",
      "Loss: tensor(0.1200, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2693\n",
      "Loss: tensor(0.1200, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2694\n",
      "Loss: tensor(0.1199, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2695\n",
      "Loss: tensor(0.1199, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2696\n",
      "Loss: tensor(0.1199, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2697\n",
      "Loss: tensor(0.1199, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2698\n",
      "Loss: tensor(0.1199, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2699\n",
      "Loss: tensor(0.1199, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2700\n",
      "Loss: tensor(0.1198, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2701\n",
      "Loss: tensor(0.1198, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2702\n",
      "Loss: tensor(0.1198, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2703\n",
      "Loss: tensor(0.1198, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2704\n",
      "Loss: tensor(0.1198, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2705\n",
      "Loss: tensor(0.1198, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2706\n",
      "Loss: tensor(0.1197, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2707\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor(0.1197, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2708\n",
      "Loss: tensor(0.1197, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2709\n",
      "Loss: tensor(0.1197, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2710\n",
      "Loss: tensor(0.1197, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2711\n",
      "Loss: tensor(0.1197, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2712\n",
      "Loss: tensor(0.1196, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2713\n",
      "Loss: tensor(0.1196, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2714\n",
      "Loss: tensor(0.1196, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2715\n",
      "Loss: tensor(0.1196, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2716\n",
      "Loss: tensor(0.1196, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2717\n",
      "Loss: tensor(0.1196, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2718\n",
      "Loss: tensor(0.1195, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2719\n",
      "Loss: tensor(0.1195, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2720\n",
      "Loss: tensor(0.1195, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2721\n",
      "Loss: tensor(0.1195, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2722\n",
      "Loss: tensor(0.1195, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2723\n",
      "Loss: tensor(0.1195, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2724\n",
      "Loss: tensor(0.1194, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2725\n",
      "Loss: tensor(0.1194, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2726\n",
      "Loss: tensor(0.1194, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2727\n",
      "Loss: tensor(0.1194, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2728\n",
      "Loss: tensor(0.1194, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2729\n",
      "Loss: tensor(0.1194, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2730\n",
      "Loss: tensor(0.1193, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2731\n",
      "Loss: tensor(0.1193, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2732\n",
      "Loss: tensor(0.1193, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2733\n",
      "Loss: tensor(0.1193, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2734\n",
      "Loss: tensor(0.1193, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2735\n",
      "Loss: tensor(0.1193, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2736\n",
      "Loss: tensor(0.1192, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2737\n",
      "Loss: tensor(0.1192, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2738\n",
      "Loss: tensor(0.1192, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2739\n",
      "Loss: tensor(0.1192, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2740\n",
      "Loss: tensor(0.1192, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2741\n",
      "Loss: tensor(0.1192, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2742\n",
      "Loss: tensor(0.1191, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2743\n",
      "Loss: tensor(0.1191, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2744\n",
      "Loss: tensor(0.1191, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2745\n",
      "Loss: tensor(0.1191, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2746\n",
      "Loss: tensor(0.1191, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2747\n",
      "Loss: tensor(0.1191, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2748\n",
      "Loss: tensor(0.1190, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2749\n",
      "Loss: tensor(0.1190, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2750\n",
      "Loss: tensor(0.1190, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2751\n",
      "Loss: tensor(0.1190, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2752\n",
      "Loss: tensor(0.1190, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2753\n",
      "Loss: tensor(0.1190, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2754\n",
      "Loss: tensor(0.1189, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2755\n",
      "Loss: tensor(0.1189, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2756\n",
      "Loss: tensor(0.1189, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2757\n",
      "Loss: tensor(0.1189, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2758\n",
      "Loss: tensor(0.1189, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2759\n",
      "Loss: tensor(0.1189, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2760\n",
      "Loss: tensor(0.1189, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2761\n",
      "Loss: tensor(0.1188, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2762\n",
      "Loss: tensor(0.1188, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2763\n",
      "Loss: tensor(0.1188, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2764\n",
      "Loss: tensor(0.1188, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2765\n",
      "Loss: tensor(0.1188, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2766\n",
      "Loss: tensor(0.1187, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2767\n",
      "Loss: tensor(0.1187, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2768\n",
      "Loss: tensor(0.1187, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2769\n",
      "Loss: tensor(0.1187, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2770\n",
      "Loss: tensor(0.1187, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2771\n",
      "Loss: tensor(0.1187, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2772\n",
      "Loss: tensor(0.1187, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2773\n",
      "Loss: tensor(0.1186, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2774\n",
      "Loss: tensor(0.1186, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2775\n",
      "Loss: tensor(0.1186, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2776\n",
      "Loss: tensor(0.1186, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2777\n",
      "Loss: tensor(0.1186, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2778\n",
      "Loss: tensor(0.1185, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2779\n",
      "Loss: tensor(0.1185, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2780\n",
      "Loss: tensor(0.1185, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2781\n",
      "Loss: tensor(0.1185, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2782\n",
      "Loss: tensor(0.1185, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2783\n",
      "Loss: tensor(0.1185, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2784\n",
      "Loss: tensor(0.1184, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2785\n",
      "Loss: tensor(0.1184, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2786\n",
      "Loss: tensor(0.1184, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2787\n",
      "Loss: tensor(0.1184, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2788\n",
      "Loss: tensor(0.1184, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2789\n",
      "Loss: tensor(0.1184, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2790\n",
      "Loss: tensor(0.1184, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2791\n",
      "Loss: tensor(0.1183, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2792\n",
      "Loss: tensor(0.1183, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2793\n",
      "Loss: tensor(0.1183, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2794\n",
      "Loss: tensor(0.1183, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2795\n",
      "Loss: tensor(0.1183, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2796\n",
      "Loss: tensor(0.1183, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2797\n",
      "Loss: tensor(0.1182, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2798\n",
      "Loss: tensor(0.1182, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2799\n",
      "Loss: tensor(0.1182, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2800\n",
      "Loss: tensor(0.1182, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2801\n",
      "Loss: tensor(0.1182, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2802\n",
      "Loss: tensor(0.1182, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2803\n",
      "Loss: tensor(0.1182, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2804\n",
      "Loss: tensor(0.1181, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2805\n",
      "Loss: tensor(0.1181, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2806\n",
      "Loss: tensor(0.1181, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2807\n",
      "Loss: tensor(0.1181, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2808\n",
      "Loss: tensor(0.1181, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2809\n",
      "Loss: tensor(0.1181, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2810\n",
      "Loss: tensor(0.1180, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2811\n",
      "Loss: tensor(0.1180, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2812\n",
      "Loss: tensor(0.1180, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2813\n",
      "Loss: tensor(0.1180, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2814\n",
      "Loss: tensor(0.1180, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2815\n",
      "Loss: tensor(0.1179, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2816\n",
      "Loss: tensor(0.1179, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2817\n",
      "Loss: tensor(0.1179, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2818\n",
      "Loss: tensor(0.1179, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2819\n",
      "Loss: tensor(0.1179, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2820\n",
      "Loss: tensor(0.1179, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2821\n",
      "Loss: tensor(0.1179, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2822\n",
      "Loss: tensor(0.1178, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2823\n",
      "Loss: tensor(0.1178, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2824\n",
      "Loss: tensor(0.1178, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2825\n",
      "Loss: tensor(0.1178, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2826\n",
      "Loss: tensor(0.1178, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2827\n",
      "Loss: tensor(0.1178, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2828\n",
      "Loss: tensor(0.1177, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2829\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor(0.1177, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2830\n",
      "Loss: tensor(0.1177, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2831\n",
      "Loss: tensor(0.1177, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2832\n",
      "Loss: tensor(0.1177, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2833\n",
      "Loss: tensor(0.1177, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2834\n",
      "Loss: tensor(0.1176, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2835\n",
      "Loss: tensor(0.1176, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2836\n",
      "Loss: tensor(0.1176, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2837\n",
      "Loss: tensor(0.1176, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2838\n",
      "Loss: tensor(0.1176, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2839\n",
      "Loss: tensor(0.1176, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2840\n",
      "Loss: tensor(0.1175, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2841\n",
      "Loss: tensor(0.1175, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2842\n",
      "Loss: tensor(0.1175, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2843\n",
      "Loss: tensor(0.1175, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2844\n",
      "Loss: tensor(0.1175, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2845\n",
      "Loss: tensor(0.1175, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2846\n",
      "Loss: tensor(0.1175, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2847\n",
      "Loss: tensor(0.1174, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2848\n",
      "Loss: tensor(0.1174, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2849\n",
      "Loss: tensor(0.1174, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2850\n",
      "Loss: tensor(0.1174, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2851\n",
      "Loss: tensor(0.1174, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2852\n",
      "Loss: tensor(0.1174, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2853\n",
      "Loss: tensor(0.1173, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2854\n",
      "Loss: tensor(0.1173, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2855\n",
      "Loss: tensor(0.1173, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2856\n",
      "Loss: tensor(0.1173, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2857\n",
      "Loss: tensor(0.1173, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2858\n",
      "Loss: tensor(0.1173, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2859\n",
      "Loss: tensor(0.1172, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2860\n",
      "Loss: tensor(0.1172, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2861\n",
      "Loss: tensor(0.1172, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2862\n",
      "Loss: tensor(0.1172, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2863\n",
      "Loss: tensor(0.1172, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2864\n",
      "Loss: tensor(0.1172, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2865\n",
      "Loss: tensor(0.1171, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2866\n",
      "Loss: tensor(0.1171, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2867\n",
      "Loss: tensor(0.1171, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2868\n",
      "Loss: tensor(0.1171, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2869\n",
      "Loss: tensor(0.1171, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2870\n",
      "Loss: tensor(0.1171, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2871\n",
      "Loss: tensor(0.1171, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2872\n",
      "Loss: tensor(0.1170, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2873\n",
      "Loss: tensor(0.1170, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2874\n",
      "Loss: tensor(0.1170, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2875\n",
      "Loss: tensor(0.1170, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2876\n",
      "Loss: tensor(0.1170, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2877\n",
      "Loss: tensor(0.1170, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2878\n",
      "Loss: tensor(0.1169, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2879\n",
      "Loss: tensor(0.1169, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2880\n",
      "Loss: tensor(0.1169, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2881\n",
      "Loss: tensor(0.1169, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2882\n",
      "Loss: tensor(0.1169, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2883\n",
      "Loss: tensor(0.1169, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2884\n",
      "Loss: tensor(0.1168, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2885\n",
      "Loss: tensor(0.1168, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2886\n",
      "Loss: tensor(0.1168, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2887\n",
      "Loss: tensor(0.1168, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2888\n",
      "Loss: tensor(0.1168, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2889\n",
      "Loss: tensor(0.1168, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2890\n",
      "Loss: tensor(0.1168, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2891\n",
      "Loss: tensor(0.1167, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2892\n",
      "Loss: tensor(0.1167, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2893\n",
      "Loss: tensor(0.1167, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2894\n",
      "Loss: tensor(0.1167, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2895\n",
      "Loss: tensor(0.1167, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2896\n",
      "Loss: tensor(0.1167, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2897\n",
      "Loss: tensor(0.1166, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2898\n",
      "Loss: tensor(0.1166, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2899\n",
      "Loss: tensor(0.1166, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2900\n",
      "Loss: tensor(0.1166, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2901\n",
      "Loss: tensor(0.1166, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2902\n",
      "Loss: tensor(0.1166, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2903\n",
      "Loss: tensor(0.1165, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2904\n",
      "Loss: tensor(0.1165, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2905\n",
      "Loss: tensor(0.1165, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2906\n",
      "Loss: tensor(0.1165, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2907\n",
      "Loss: tensor(0.1165, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2908\n",
      "Loss: tensor(0.1165, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2909\n",
      "Loss: tensor(0.1165, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2910\n",
      "Loss: tensor(0.1164, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2911\n",
      "Loss: tensor(0.1164, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2912\n",
      "Loss: tensor(0.1164, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2913\n",
      "Loss: tensor(0.1164, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2914\n",
      "Loss: tensor(0.1164, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2915\n",
      "Loss: tensor(0.1164, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2916\n",
      "Loss: tensor(0.1163, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2917\n",
      "Loss: tensor(0.1163, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2918\n",
      "Loss: tensor(0.1163, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2919\n",
      "Loss: tensor(0.1163, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2920\n",
      "Loss: tensor(0.1163, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2921\n",
      "Loss: tensor(0.1163, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2922\n",
      "Loss: tensor(0.1163, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2923\n",
      "Loss: tensor(0.1163, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2924\n",
      "Loss: tensor(0.1162, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2925\n",
      "Loss: tensor(0.1162, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2926\n",
      "Loss: tensor(0.1162, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2927\n",
      "Loss: tensor(0.1162, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2928\n",
      "Loss: tensor(0.1162, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2929\n",
      "Loss: tensor(0.1162, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2930\n",
      "Loss: tensor(0.1161, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2931\n",
      "Loss: tensor(0.1161, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2932\n",
      "Loss: tensor(0.1161, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2933\n",
      "Loss: tensor(0.1161, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2934\n",
      "Loss: tensor(0.1161, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2935\n",
      "Loss: tensor(0.1161, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2936\n",
      "Loss: tensor(0.1160, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2937\n",
      "Loss: tensor(0.1160, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2938\n",
      "Loss: tensor(0.1160, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2939\n",
      "Loss: tensor(0.1160, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2940\n",
      "Loss: tensor(0.1160, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2941\n",
      "Loss: tensor(0.1160, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2942\n",
      "Loss: tensor(0.1159, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2943\n",
      "Loss: tensor(0.1159, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2944\n",
      "Loss: tensor(0.1159, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2945\n",
      "Loss: tensor(0.1159, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2946\n",
      "Loss: tensor(0.1159, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2947\n",
      "Loss: tensor(0.1159, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2948\n",
      "Loss: tensor(0.1159, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2949\n",
      "Loss: tensor(0.1158, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2950\n",
      "Loss: tensor(0.1158, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2951\n",
      "Loss: tensor(0.1158, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2952\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor(0.1158, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2953\n",
      "Loss: tensor(0.1158, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2954\n",
      "Loss: tensor(0.1158, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2955\n",
      "Loss: tensor(0.1157, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2956\n",
      "Loss: tensor(0.1157, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2957\n",
      "Loss: tensor(0.1157, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2958\n",
      "Loss: tensor(0.1157, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2959\n",
      "Loss: tensor(0.1157, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2960\n",
      "Loss: tensor(0.1157, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2961\n",
      "Loss: tensor(0.1157, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2962\n",
      "Loss: tensor(0.1156, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2963\n",
      "Loss: tensor(0.1156, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2964\n",
      "Loss: tensor(0.1156, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2965\n",
      "Loss: tensor(0.1156, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2966\n",
      "Loss: tensor(0.1156, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2967\n",
      "Loss: tensor(0.1156, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2968\n",
      "Loss: tensor(0.1155, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2969\n",
      "Loss: tensor(0.1155, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2970\n",
      "Loss: tensor(0.1155, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2971\n",
      "Loss: tensor(0.1155, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2972\n",
      "Loss: tensor(0.1155, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2973\n",
      "Loss: tensor(0.1155, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2974\n",
      "Loss: tensor(0.1155, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2975\n",
      "Loss: tensor(0.1154, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2976\n",
      "Loss: tensor(0.1154, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2977\n",
      "Loss: tensor(0.1154, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2978\n",
      "Loss: tensor(0.1154, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2979\n",
      "Loss: tensor(0.1154, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2980\n",
      "Loss: tensor(0.1154, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2981\n",
      "Loss: tensor(0.1154, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2982\n",
      "Loss: tensor(0.1153, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2983\n",
      "Loss: tensor(0.1153, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2984\n",
      "Loss: tensor(0.1153, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2985\n",
      "Loss: tensor(0.1153, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2986\n",
      "Loss: tensor(0.1153, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2987\n",
      "Loss: tensor(0.1153, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2988\n",
      "Loss: tensor(0.1152, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2989\n",
      "Loss: tensor(0.1152, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2990\n",
      "Loss: tensor(0.1152, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2991\n",
      "Loss: tensor(0.1152, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2992\n",
      "Loss: tensor(0.1152, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2993\n",
      "Loss: tensor(0.1152, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2994\n",
      "Loss: tensor(0.1152, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2995\n",
      "Loss: tensor(0.1151, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2996\n",
      "Loss: tensor(0.1151, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2997\n",
      "Loss: tensor(0.1151, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2998\n",
      "Loss: tensor(0.1151, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2999\n",
      "Loss: tensor(0.1151, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3000\n",
      "Loss: tensor(0.1151, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3001\n",
      "Loss: tensor(0.1151, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3002\n",
      "Loss: tensor(0.1151, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3003\n",
      "Loss: tensor(0.1151, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3004\n",
      "Loss: tensor(0.1150, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3005\n",
      "Loss: tensor(0.1150, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3006\n",
      "Loss: tensor(0.1150, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3007\n",
      "Loss: tensor(0.1150, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3008\n",
      "Loss: tensor(0.1150, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3009\n",
      "Loss: tensor(0.1149, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3010\n",
      "Loss: tensor(0.1149, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3011\n",
      "Loss: tensor(0.1149, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3012\n",
      "Loss: tensor(0.1149, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3013\n",
      "Loss: tensor(0.1149, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3014\n",
      "Loss: tensor(0.1149, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3015\n",
      "Loss: tensor(0.1148, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3016\n",
      "Loss: tensor(0.1148, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3017\n",
      "Loss: tensor(0.1148, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3018\n",
      "Loss: tensor(0.1148, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3019\n",
      "Loss: tensor(0.1148, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3020\n",
      "Loss: tensor(0.1148, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3021\n",
      "Loss: tensor(0.1148, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3022\n",
      "Loss: tensor(0.1147, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3023\n",
      "Loss: tensor(0.1147, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3024\n",
      "Loss: tensor(0.1147, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3025\n",
      "Loss: tensor(0.1147, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3026\n",
      "Loss: tensor(0.1147, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3027\n",
      "Loss: tensor(0.1147, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3028\n",
      "Loss: tensor(0.1147, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3029\n",
      "Loss: tensor(0.1146, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3030\n",
      "Loss: tensor(0.1146, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3031\n",
      "Loss: tensor(0.1146, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3032\n",
      "Loss: tensor(0.1146, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3033\n",
      "Loss: tensor(0.1146, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3034\n",
      "Loss: tensor(0.1146, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3035\n",
      "Loss: tensor(0.1146, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3036\n",
      "Loss: tensor(0.1145, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3037\n",
      "Loss: tensor(0.1145, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3038\n",
      "Loss: tensor(0.1145, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3039\n",
      "Loss: tensor(0.1145, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3040\n",
      "Loss: tensor(0.1145, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3041\n",
      "Loss: tensor(0.1145, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3042\n",
      "Loss: tensor(0.1145, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3043\n",
      "Loss: tensor(0.1144, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3044\n",
      "Loss: tensor(0.1144, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3045\n",
      "Loss: tensor(0.1144, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3046\n",
      "Loss: tensor(0.1144, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3047\n",
      "Loss: tensor(0.1144, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3048\n",
      "Loss: tensor(0.1144, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3049\n",
      "Loss: tensor(0.1144, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3050\n",
      "Loss: tensor(0.1143, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3051\n",
      "Loss: tensor(0.1143, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3052\n",
      "Loss: tensor(0.1143, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3053\n",
      "Loss: tensor(0.1143, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3054\n",
      "Loss: tensor(0.1143, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3055\n",
      "Loss: tensor(0.1143, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3056\n",
      "Loss: tensor(0.1143, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3057\n",
      "Loss: tensor(0.1142, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3058\n",
      "Loss: tensor(0.1142, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3059\n",
      "Loss: tensor(0.1142, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3060\n",
      "Loss: tensor(0.1142, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3061\n",
      "Loss: tensor(0.1142, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3062\n",
      "Loss: tensor(0.1142, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3063\n",
      "Loss: tensor(0.1142, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3064\n",
      "Loss: tensor(0.1141, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3065\n",
      "Loss: tensor(0.1141, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3066\n",
      "Loss: tensor(0.1141, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3067\n",
      "Loss: tensor(0.1141, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3068\n",
      "Loss: tensor(0.1141, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3069\n",
      "Loss: tensor(0.1141, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3070\n",
      "Loss: tensor(0.1141, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3071\n",
      "Loss: tensor(0.1140, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3072\n",
      "Loss: tensor(0.1140, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3073\n",
      "Loss: tensor(0.1140, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3074\n",
      "Loss: tensor(0.1140, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3075\n",
      "Loss: tensor(0.1140, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3076\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor(0.1140, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3077\n",
      "Loss: tensor(0.1140, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3078\n",
      "Loss: tensor(0.1139, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3079\n",
      "Loss: tensor(0.1139, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3080\n",
      "Loss: tensor(0.1139, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3081\n",
      "Loss: tensor(0.1139, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3082\n",
      "Loss: tensor(0.1139, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3083\n",
      "Loss: tensor(0.1139, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3084\n",
      "Loss: tensor(0.1139, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3085\n",
      "Loss: tensor(0.1138, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3086\n",
      "Loss: tensor(0.1138, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3087\n",
      "Loss: tensor(0.1138, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3088\n",
      "Loss: tensor(0.1138, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3089\n",
      "Loss: tensor(0.1138, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3090\n",
      "Loss: tensor(0.1138, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3091\n",
      "Loss: tensor(0.1138, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3092\n",
      "Loss: tensor(0.1138, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3093\n",
      "Loss: tensor(0.1137, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3094\n",
      "Loss: tensor(0.1137, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3095\n",
      "Loss: tensor(0.1137, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3096\n",
      "Loss: tensor(0.1137, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3097\n",
      "Loss: tensor(0.1137, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3098\n",
      "Loss: tensor(0.1137, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3099\n",
      "Loss: tensor(0.1137, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3100\n",
      "Loss: tensor(0.1136, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3101\n",
      "Loss: tensor(0.1136, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3102\n",
      "Loss: tensor(0.1136, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3103\n",
      "Loss: tensor(0.1136, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3104\n",
      "Loss: tensor(0.1136, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3105\n",
      "Loss: tensor(0.1136, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3106\n",
      "Loss: tensor(0.1136, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3107\n",
      "Loss: tensor(0.1135, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3108\n",
      "Loss: tensor(0.1135, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3109\n",
      "Loss: tensor(0.1135, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3110\n",
      "Loss: tensor(0.1135, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3111\n",
      "Loss: tensor(0.1135, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3112\n",
      "Loss: tensor(0.1135, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3113\n",
      "Loss: tensor(0.1135, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3114\n",
      "Loss: tensor(0.1134, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3115\n",
      "Loss: tensor(0.1134, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3116\n",
      "Loss: tensor(0.1134, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3117\n",
      "Loss: tensor(0.1134, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3118\n",
      "Loss: tensor(0.1134, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3119\n",
      "Loss: tensor(0.1134, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3120\n",
      "Loss: tensor(0.1134, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3121\n",
      "Loss: tensor(0.1133, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3122\n",
      "Loss: tensor(0.1133, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3123\n",
      "Loss: tensor(0.1133, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3124\n",
      "Loss: tensor(0.1133, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3125\n",
      "Loss: tensor(0.1133, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3126\n",
      "Loss: tensor(0.1133, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3127\n",
      "Loss: tensor(0.1133, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3128\n",
      "Loss: tensor(0.1133, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3129\n",
      "Loss: tensor(0.1132, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3130\n",
      "Loss: tensor(0.1132, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3131\n",
      "Loss: tensor(0.1132, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3132\n",
      "Loss: tensor(0.1132, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3133\n",
      "Loss: tensor(0.1132, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3134\n",
      "Loss: tensor(0.1132, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3135\n",
      "Loss: tensor(0.1132, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3136\n",
      "Loss: tensor(0.1131, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3137\n",
      "Loss: tensor(0.1131, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3138\n",
      "Loss: tensor(0.1131, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3139\n",
      "Loss: tensor(0.1131, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3140\n",
      "Loss: tensor(0.1131, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3141\n",
      "Loss: tensor(0.1131, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3142\n",
      "Loss: tensor(0.1131, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3143\n",
      "Loss: tensor(0.1131, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3144\n",
      "Loss: tensor(0.1130, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3145\n",
      "Loss: tensor(0.1130, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3146\n",
      "Loss: tensor(0.1130, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3147\n",
      "Loss: tensor(0.1130, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3148\n",
      "Loss: tensor(0.1130, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3149\n",
      "Loss: tensor(0.1130, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3150\n",
      "Loss: tensor(0.1130, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3151\n",
      "Loss: tensor(0.1129, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3152\n",
      "Loss: tensor(0.1129, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3153\n",
      "Loss: tensor(0.1129, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3154\n",
      "Loss: tensor(0.1129, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3155\n",
      "Loss: tensor(0.1129, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3156\n",
      "Loss: tensor(0.1129, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3157\n",
      "Loss: tensor(0.1129, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3158\n",
      "Loss: tensor(0.1129, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3159\n",
      "Loss: tensor(0.1128, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3160\n",
      "Loss: tensor(0.1128, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3161\n",
      "Loss: tensor(0.1128, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3162\n",
      "Loss: tensor(0.1128, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3163\n",
      "Loss: tensor(0.1128, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3164\n",
      "Loss: tensor(0.1128, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3165\n",
      "Loss: tensor(0.1128, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3166\n",
      "Loss: tensor(0.1127, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3167\n",
      "Loss: tensor(0.1127, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3168\n",
      "Loss: tensor(0.1127, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3169\n",
      "Loss: tensor(0.1127, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3170\n",
      "Loss: tensor(0.1127, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3171\n",
      "Loss: tensor(0.1127, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3172\n",
      "Loss: tensor(0.1127, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3173\n",
      "Loss: tensor(0.1127, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3174\n",
      "Loss: tensor(0.1126, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3175\n",
      "Loss: tensor(0.1126, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3176\n",
      "Loss: tensor(0.1126, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3177\n",
      "Loss: tensor(0.1126, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3178\n",
      "Loss: tensor(0.1126, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3179\n",
      "Loss: tensor(0.1126, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3180\n",
      "Loss: tensor(0.1126, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3181\n",
      "Loss: tensor(0.1126, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3182\n",
      "Loss: tensor(0.1125, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3183\n",
      "Loss: tensor(0.1125, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3184\n",
      "Loss: tensor(0.1125, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3185\n",
      "Loss: tensor(0.1125, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3186\n",
      "Loss: tensor(0.1125, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3187\n",
      "Loss: tensor(0.1125, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3188\n",
      "Loss: tensor(0.1125, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3189\n",
      "Loss: tensor(0.1125, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3190\n",
      "Loss: tensor(0.1124, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3191\n",
      "Loss: tensor(0.1124, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3192\n",
      "Loss: tensor(0.1124, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3193\n",
      "Loss: tensor(0.1124, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3194\n",
      "Loss: tensor(0.1124, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3195\n",
      "Loss: tensor(0.1124, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3196\n",
      "Loss: tensor(0.1124, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3197\n",
      "Loss: tensor(0.1124, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3198\n",
      "Loss: tensor(0.1123, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3199\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor(0.1123, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3200\n",
      "Loss: tensor(0.1123, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3201\n",
      "Loss: tensor(0.1123, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3202\n",
      "Loss: tensor(0.1123, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3203\n",
      "Loss: tensor(0.1123, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3204\n",
      "Loss: tensor(0.1123, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3205\n",
      "Loss: tensor(0.1123, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3206\n",
      "Loss: tensor(0.1122, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3207\n",
      "Loss: tensor(0.1122, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3208\n",
      "Loss: tensor(0.1122, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3209\n",
      "Loss: tensor(0.1122, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3210\n",
      "Loss: tensor(0.1122, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3211\n",
      "Loss: tensor(0.1122, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3212\n",
      "Loss: tensor(0.1122, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3213\n",
      "Loss: tensor(0.1122, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3214\n",
      "Loss: tensor(0.1121, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3215\n",
      "Loss: tensor(0.1121, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3216\n",
      "Loss: tensor(0.1121, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3217\n",
      "Loss: tensor(0.1121, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3218\n",
      "Loss: tensor(0.1121, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3219\n",
      "Loss: tensor(0.1121, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3220\n",
      "Loss: tensor(0.1121, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3221\n",
      "Loss: tensor(0.1121, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3222\n",
      "Loss: tensor(0.1120, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3223\n",
      "Loss: tensor(0.1120, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3224\n",
      "Loss: tensor(0.1120, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3225\n",
      "Loss: tensor(0.1120, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3226\n",
      "Loss: tensor(0.1120, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3227\n",
      "Loss: tensor(0.1120, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3228\n",
      "Loss: tensor(0.1120, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3229\n",
      "Loss: tensor(0.1120, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3230\n",
      "Loss: tensor(0.1119, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3231\n",
      "Loss: tensor(0.1119, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3232\n",
      "Loss: tensor(0.1119, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3233\n",
      "Loss: tensor(0.1119, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3234\n",
      "Loss: tensor(0.1119, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3235\n",
      "Loss: tensor(0.1119, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3236\n",
      "Loss: tensor(0.1119, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3237\n",
      "Loss: tensor(0.1119, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3238\n",
      "Loss: tensor(0.1118, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3239\n",
      "Loss: tensor(0.1118, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3240\n",
      "Loss: tensor(0.1118, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3241\n",
      "Loss: tensor(0.1118, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3242\n",
      "Loss: tensor(0.1118, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3243\n",
      "Loss: tensor(0.1118, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3244\n",
      "Loss: tensor(0.1118, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3245\n",
      "Loss: tensor(0.1118, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3246\n",
      "Loss: tensor(0.1117, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3247\n",
      "Loss: tensor(0.1117, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3248\n",
      "Loss: tensor(0.1117, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3249\n",
      "Loss: tensor(0.1117, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3250\n",
      "Loss: tensor(0.1117, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3251\n",
      "Loss: tensor(0.1117, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3252\n",
      "Loss: tensor(0.1117, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3253\n",
      "Loss: tensor(0.1117, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3254\n",
      "Loss: tensor(0.1117, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3255\n",
      "Loss: tensor(0.1116, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3256\n",
      "Loss: tensor(0.1116, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3257\n",
      "Loss: tensor(0.1116, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3258\n",
      "Loss: tensor(0.1116, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3259\n",
      "Loss: tensor(0.1116, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3260\n",
      "Loss: tensor(0.1116, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3261\n",
      "Loss: tensor(0.1116, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3262\n",
      "Loss: tensor(0.1116, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3263\n",
      "Loss: tensor(0.1115, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3264\n",
      "Loss: tensor(0.1115, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3265\n",
      "Loss: tensor(0.1115, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3266\n",
      "Loss: tensor(0.1115, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3267\n",
      "Loss: tensor(0.1115, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3268\n",
      "Loss: tensor(0.1115, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3269\n",
      "Loss: tensor(0.1115, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3270\n",
      "Loss: tensor(0.1115, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3271\n",
      "Loss: tensor(0.1115, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3272\n",
      "Loss: tensor(0.1114, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3273\n",
      "Loss: tensor(0.1114, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3274\n",
      "Loss: tensor(0.1114, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3275\n",
      "Loss: tensor(0.1114, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3276\n",
      "Loss: tensor(0.1114, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3277\n",
      "Loss: tensor(0.1114, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3278\n",
      "Loss: tensor(0.1114, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3279\n",
      "Loss: tensor(0.1114, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3280\n",
      "Loss: tensor(0.1114, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3281\n",
      "Loss: tensor(0.1113, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3282\n",
      "Loss: tensor(0.1113, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3283\n",
      "Loss: tensor(0.1113, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3284\n",
      "Loss: tensor(0.1113, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3285\n",
      "Loss: tensor(0.1113, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3286\n",
      "Loss: tensor(0.1113, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3287\n",
      "Loss: tensor(0.1113, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3288\n",
      "Loss: tensor(0.1113, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3289\n",
      "Loss: tensor(0.1112, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3290\n",
      "Loss: tensor(0.1112, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3291\n",
      "Loss: tensor(0.1112, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3292\n",
      "Loss: tensor(0.1112, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3293\n",
      "Loss: tensor(0.1112, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3294\n",
      "Loss: tensor(0.1112, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3295\n",
      "Loss: tensor(0.1112, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3296\n",
      "Loss: tensor(0.1112, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3297\n",
      "Loss: tensor(0.1112, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3298\n",
      "Loss: tensor(0.1111, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3299\n",
      "Loss: tensor(0.1111, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3300\n",
      "Loss: tensor(0.1111, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3301\n",
      "Loss: tensor(0.1111, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3302\n",
      "Loss: tensor(0.1111, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3303\n",
      "Loss: tensor(0.1111, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3304\n",
      "Loss: tensor(0.1111, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3305\n",
      "Loss: tensor(0.1111, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3306\n",
      "Loss: tensor(0.1111, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3307\n",
      "Loss: tensor(0.1110, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3308\n",
      "Loss: tensor(0.1110, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3309\n",
      "Loss: tensor(0.1110, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3310\n",
      "Loss: tensor(0.1110, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3311\n",
      "Loss: tensor(0.1110, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3312\n",
      "Loss: tensor(0.1110, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3313\n",
      "Loss: tensor(0.1110, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3314\n",
      "Loss: tensor(0.1110, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3315\n",
      "Loss: tensor(0.1110, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3316\n",
      "Loss: tensor(0.1109, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3317\n",
      "Loss: tensor(0.1109, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3318\n",
      "Loss: tensor(0.1109, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3319\n",
      "Loss: tensor(0.1109, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3320\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor(0.1109, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3321\n",
      "Loss: tensor(0.1109, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3322\n",
      "Loss: tensor(0.1109, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3323\n",
      "Loss: tensor(0.1109, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3324\n",
      "Loss: tensor(0.1109, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3325\n",
      "Loss: tensor(0.1108, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3326\n",
      "Loss: tensor(0.1108, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3327\n",
      "Loss: tensor(0.1108, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3328\n",
      "Loss: tensor(0.1108, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3329\n",
      "Loss: tensor(0.1108, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3330\n",
      "Loss: tensor(0.1108, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3331\n",
      "Loss: tensor(0.1108, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3332\n",
      "Loss: tensor(0.1108, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3333\n",
      "Loss: tensor(0.1108, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3334\n",
      "Loss: tensor(0.1108, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3335\n",
      "Loss: tensor(0.1107, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3336\n",
      "Loss: tensor(0.1107, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3337\n",
      "Loss: tensor(0.1107, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3338\n",
      "Loss: tensor(0.1107, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3339\n",
      "Loss: tensor(0.1107, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3340\n",
      "Loss: tensor(0.1107, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3341\n",
      "Loss: tensor(0.1107, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3342\n",
      "Loss: tensor(0.1107, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3343\n",
      "Loss: tensor(0.1107, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3344\n",
      "Loss: tensor(0.1106, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3345\n",
      "Loss: tensor(0.1106, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3346\n",
      "Loss: tensor(0.1106, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3347\n",
      "Loss: tensor(0.1106, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3348\n",
      "Loss: tensor(0.1106, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3349\n",
      "Loss: tensor(0.1106, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3350\n",
      "Loss: tensor(0.1106, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3351\n",
      "Loss: tensor(0.1106, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3352\n",
      "Loss: tensor(0.1106, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3353\n",
      "Loss: tensor(0.1105, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3354\n",
      "Loss: tensor(0.1105, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3355\n",
      "Loss: tensor(0.1105, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3356\n",
      "Loss: tensor(0.1105, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3357\n",
      "Loss: tensor(0.1105, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3358\n",
      "Loss: tensor(0.1105, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3359\n",
      "Loss: tensor(0.1105, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3360\n",
      "Loss: tensor(0.1105, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3361\n",
      "Loss: tensor(0.1105, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3362\n",
      "Loss: tensor(0.1105, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3363\n",
      "Loss: tensor(0.1104, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3364\n",
      "Loss: tensor(0.1104, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3365\n",
      "Loss: tensor(0.1104, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3366\n",
      "Loss: tensor(0.1104, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3367\n",
      "Loss: tensor(0.1104, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3368\n",
      "Loss: tensor(0.1104, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3369\n",
      "Loss: tensor(0.1104, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3370\n",
      "Loss: tensor(0.1104, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3371\n",
      "Loss: tensor(0.1104, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3372\n",
      "Loss: tensor(0.1103, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3373\n",
      "Loss: tensor(0.1103, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3374\n",
      "Loss: tensor(0.1103, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3375\n",
      "Loss: tensor(0.1103, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3376\n",
      "Loss: tensor(0.1103, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3377\n",
      "Loss: tensor(0.1103, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3378\n",
      "Loss: tensor(0.1103, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3379\n",
      "Loss: tensor(0.1103, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3380\n",
      "Loss: tensor(0.1103, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3381\n",
      "Loss: tensor(0.1103, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3382\n",
      "Loss: tensor(0.1102, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3383\n",
      "Loss: tensor(0.1102, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3384\n",
      "Loss: tensor(0.1102, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3385\n",
      "Loss: tensor(0.1102, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3386\n",
      "Loss: tensor(0.1102, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3387\n",
      "Loss: tensor(0.1102, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3388\n",
      "Loss: tensor(0.1102, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3389\n",
      "Loss: tensor(0.1102, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3390\n",
      "Loss: tensor(0.1102, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3391\n",
      "Loss: tensor(0.1102, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3392\n",
      "Loss: tensor(0.1101, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3393\n",
      "Loss: tensor(0.1101, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3394\n",
      "Loss: tensor(0.1101, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3395\n",
      "Loss: tensor(0.1101, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3396\n",
      "Loss: tensor(0.1101, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3397\n",
      "Loss: tensor(0.1101, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3398\n",
      "Loss: tensor(0.1101, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3399\n",
      "Loss: tensor(0.1101, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3400\n",
      "Loss: tensor(0.1101, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3401\n",
      "Loss: tensor(0.1101, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3402\n",
      "Loss: tensor(0.1100, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3403\n",
      "Loss: tensor(0.1100, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3404\n",
      "Loss: tensor(0.1100, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3405\n",
      "Loss: tensor(0.1100, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3406\n",
      "Loss: tensor(0.1100, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3407\n",
      "Loss: tensor(0.1100, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3408\n",
      "Loss: tensor(0.1100, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3409\n",
      "Loss: tensor(0.1100, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3410\n",
      "Loss: tensor(0.1100, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3411\n",
      "Loss: tensor(0.1100, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3412\n",
      "Loss: tensor(0.1100, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3413\n",
      "Loss: tensor(0.1099, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3414\n",
      "Loss: tensor(0.1099, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3415\n",
      "Loss: tensor(0.1099, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3416\n",
      "Loss: tensor(0.1099, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3417\n",
      "Loss: tensor(0.1099, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3418\n",
      "Loss: tensor(0.1099, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3419\n",
      "Loss: tensor(0.1099, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3420\n",
      "Loss: tensor(0.1099, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3421\n",
      "Loss: tensor(0.1099, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3422\n",
      "Loss: tensor(0.1099, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3423\n",
      "Loss: tensor(0.1098, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3424\n",
      "Loss: tensor(0.1098, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3425\n",
      "Loss: tensor(0.1098, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3426\n",
      "Loss: tensor(0.1098, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3427\n",
      "Loss: tensor(0.1098, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3428\n",
      "Loss: tensor(0.1098, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3429\n",
      "Loss: tensor(0.1098, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3430\n",
      "Loss: tensor(0.1098, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3431\n",
      "Loss: tensor(0.1098, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3432\n",
      "Loss: tensor(0.1098, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3433\n",
      "Loss: tensor(0.1098, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3434\n",
      "Loss: tensor(0.1097, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3435\n",
      "Loss: tensor(0.1097, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3436\n",
      "Loss: tensor(0.1097, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3437\n",
      "Loss: tensor(0.1097, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3438\n",
      "Loss: tensor(0.1097, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3439\n",
      "Loss: tensor(0.1097, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3440\n",
      "Loss: tensor(0.1097, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3441\n",
      "Loss: tensor(0.1097, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3442\n",
      "Loss: tensor(0.1097, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3443\n",
      "Loss: tensor(0.1097, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3444\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor(0.1096, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3445\n",
      "Loss: tensor(0.1096, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3446\n",
      "Loss: tensor(0.1096, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3447\n",
      "Loss: tensor(0.1096, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3448\n",
      "Loss: tensor(0.1096, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3449\n",
      "Loss: tensor(0.1096, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3450\n",
      "Loss: tensor(0.1096, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3451\n",
      "Loss: tensor(0.1096, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3452\n",
      "Loss: tensor(0.1096, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3453\n",
      "Loss: tensor(0.1096, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3454\n",
      "Loss: tensor(0.1096, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3455\n",
      "Loss: tensor(0.1095, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3456\n",
      "Loss: tensor(0.1095, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3457\n",
      "Loss: tensor(0.1095, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3458\n",
      "Loss: tensor(0.1095, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3459\n",
      "Loss: tensor(0.1095, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3460\n",
      "Loss: tensor(0.1095, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3461\n",
      "Loss: tensor(0.1095, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3462\n",
      "Loss: tensor(0.1095, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3463\n",
      "Loss: tensor(0.1095, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3464\n",
      "Loss: tensor(0.1095, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3465\n",
      "Loss: tensor(0.1095, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3466\n",
      "Loss: tensor(0.1094, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3467\n",
      "Loss: tensor(0.1094, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3468\n",
      "Loss: tensor(0.1094, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3469\n",
      "Loss: tensor(0.1094, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3470\n",
      "Loss: tensor(0.1094, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3471\n",
      "Loss: tensor(0.1094, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3472\n",
      "Loss: tensor(0.1094, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3473\n",
      "Loss: tensor(0.1094, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3474\n",
      "Loss: tensor(0.1094, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3475\n",
      "Loss: tensor(0.1094, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3476\n",
      "Loss: tensor(0.1094, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3477\n",
      "Loss: tensor(0.1093, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3478\n",
      "Loss: tensor(0.1093, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3479\n",
      "Loss: tensor(0.1093, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3480\n",
      "Loss: tensor(0.1093, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3481\n",
      "Loss: tensor(0.1093, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3482\n",
      "Loss: tensor(0.1093, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3483\n",
      "Loss: tensor(0.1093, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3484\n",
      "Loss: tensor(0.1093, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3485\n",
      "Loss: tensor(0.1093, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3486\n",
      "Loss: tensor(0.1093, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3487\n",
      "Loss: tensor(0.1093, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3488\n",
      "Loss: tensor(0.1092, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3489\n",
      "Loss: tensor(0.1092, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3490\n",
      "Loss: tensor(0.1092, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3491\n",
      "Loss: tensor(0.1092, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3492\n",
      "Loss: tensor(0.1092, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3493\n",
      "Loss: tensor(0.1092, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3494\n",
      "Loss: tensor(0.1092, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3495\n",
      "Loss: tensor(0.1092, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3496\n",
      "Loss: tensor(0.1092, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3497\n",
      "Loss: tensor(0.1092, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3498\n",
      "Loss: tensor(0.1092, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3499\n",
      "Loss: tensor(0.1092, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3500\n",
      "Loss: tensor(0.1091, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3501\n",
      "Loss: tensor(0.1091, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3502\n",
      "Loss: tensor(0.1091, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3503\n",
      "Loss: tensor(0.1091, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3504\n",
      "Loss: tensor(0.1091, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3505\n",
      "Loss: tensor(0.1091, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3506\n",
      "Loss: tensor(0.1091, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3507\n",
      "Loss: tensor(0.1091, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3508\n",
      "Loss: tensor(0.1091, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3509\n",
      "Loss: tensor(0.1091, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3510\n",
      "Loss: tensor(0.1091, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3511\n",
      "Loss: tensor(0.1090, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3512\n",
      "Loss: tensor(0.1090, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3513\n",
      "Loss: tensor(0.1090, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3514\n",
      "Loss: tensor(0.1090, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3515\n",
      "Loss: tensor(0.1090, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3516\n",
      "Loss: tensor(0.1090, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3517\n",
      "Loss: tensor(0.1090, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3518\n",
      "Loss: tensor(0.1090, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3519\n",
      "Loss: tensor(0.1090, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3520\n",
      "Loss: tensor(0.1090, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3521\n",
      "Loss: tensor(0.1090, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3522\n",
      "Loss: tensor(0.1090, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3523\n",
      "Loss: tensor(0.1089, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3524\n",
      "Loss: tensor(0.1089, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3525\n",
      "Loss: tensor(0.1089, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3526\n",
      "Loss: tensor(0.1089, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3527\n",
      "Loss: tensor(0.1089, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3528\n",
      "Loss: tensor(0.1089, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3529\n",
      "Loss: tensor(0.1089, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3530\n",
      "Loss: tensor(0.1089, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3531\n",
      "Loss: tensor(0.1089, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3532\n",
      "Loss: tensor(0.1089, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3533\n",
      "Loss: tensor(0.1089, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3534\n",
      "Loss: tensor(0.1089, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3535\n",
      "Loss: tensor(0.1089, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3536\n",
      "Loss: tensor(0.1089, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3537\n",
      "Loss: tensor(0.1088, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3538\n",
      "Loss: tensor(0.1088, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3539\n",
      "Loss: tensor(0.1088, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3540\n",
      "Loss: tensor(0.1088, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3541\n",
      "Loss: tensor(0.1088, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3542\n",
      "Loss: tensor(0.1088, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3543\n",
      "Loss: tensor(0.1088, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3544\n",
      "Loss: tensor(0.1088, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3545\n",
      "Loss: tensor(0.1088, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3546\n",
      "Loss: tensor(0.1088, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3547\n",
      "Loss: tensor(0.1088, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3548\n",
      "Loss: tensor(0.1087, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3549\n",
      "Loss: tensor(0.1087, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3550\n",
      "Loss: tensor(0.1087, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3551\n",
      "Loss: tensor(0.1087, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3552\n",
      "Loss: tensor(0.1087, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3553\n",
      "Loss: tensor(0.1087, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3554\n",
      "Loss: tensor(0.1087, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3555\n",
      "Loss: tensor(0.1087, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3556\n",
      "Loss: tensor(0.1087, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3557\n",
      "Loss: tensor(0.1087, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3558\n",
      "Loss: tensor(0.1087, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3559\n",
      "Loss: tensor(0.1087, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3560\n",
      "Loss: tensor(0.1086, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3561\n",
      "Loss: tensor(0.1086, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3562\n",
      "Loss: tensor(0.1086, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3563\n",
      "Loss: tensor(0.1086, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3564\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor(0.1086, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3565\n",
      "Loss: tensor(0.1086, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3566\n",
      "Loss: tensor(0.1086, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3567\n",
      "Loss: tensor(0.1086, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3568\n",
      "Loss: tensor(0.1086, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3569\n",
      "Loss: tensor(0.1086, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3570\n",
      "Loss: tensor(0.1086, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3571\n",
      "Loss: tensor(0.1086, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3572\n",
      "Loss: tensor(0.1086, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3573\n",
      "Loss: tensor(0.1085, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3574\n",
      "Loss: tensor(0.1085, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3575\n",
      "Loss: tensor(0.1085, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3576\n",
      "Loss: tensor(0.1085, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3577\n",
      "Loss: tensor(0.1085, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3578\n",
      "Loss: tensor(0.1085, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3579\n",
      "Loss: tensor(0.1085, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3580\n",
      "Loss: tensor(0.1085, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3581\n",
      "Loss: tensor(0.1085, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3582\n",
      "Loss: tensor(0.1085, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3583\n",
      "Loss: tensor(0.1085, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3584\n",
      "Loss: tensor(0.1085, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3585\n",
      "Loss: tensor(0.1085, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3586\n",
      "Loss: tensor(0.1084, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3587\n",
      "Loss: tensor(0.1084, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3588\n",
      "Loss: tensor(0.1084, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3589\n",
      "Loss: tensor(0.1084, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3590\n",
      "Loss: tensor(0.1084, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3591\n",
      "Loss: tensor(0.1084, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3592\n",
      "Loss: tensor(0.1084, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3593\n",
      "Loss: tensor(0.1084, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3594\n",
      "Loss: tensor(0.1084, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3595\n",
      "Loss: tensor(0.1084, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3596\n",
      "Loss: tensor(0.1084, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3597\n",
      "Loss: tensor(0.1084, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3598\n",
      "Loss: tensor(0.1084, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3599\n",
      "Loss: tensor(0.1083, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3600\n",
      "Loss: tensor(0.1083, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3601\n",
      "Loss: tensor(0.1083, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3602\n",
      "Loss: tensor(0.1083, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3603\n",
      "Loss: tensor(0.1083, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3604\n",
      "Loss: tensor(0.1083, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3605\n",
      "Loss: tensor(0.1083, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3606\n",
      "Loss: tensor(0.1083, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3607\n",
      "Loss: tensor(0.1083, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3608\n",
      "Loss: tensor(0.1083, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3609\n",
      "Loss: tensor(0.1083, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3610\n",
      "Loss: tensor(0.1083, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3611\n",
      "Loss: tensor(0.1083, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3612\n",
      "Loss: tensor(0.1082, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3613\n",
      "Loss: tensor(0.1082, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3614\n",
      "Loss: tensor(0.1082, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3615\n",
      "Loss: tensor(0.1082, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3616\n",
      "Loss: tensor(0.1082, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3617\n",
      "Loss: tensor(0.1082, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3618\n",
      "Loss: tensor(0.1082, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3619\n",
      "Loss: tensor(0.1082, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3620\n",
      "Loss: tensor(0.1082, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3621\n",
      "Loss: tensor(0.1082, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3622\n",
      "Loss: tensor(0.1082, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3623\n",
      "Loss: tensor(0.1082, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3624\n",
      "Loss: tensor(0.1082, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3625\n",
      "Loss: tensor(0.1082, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3626\n",
      "Loss: tensor(0.1081, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3627\n",
      "Loss: tensor(0.1081, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3628\n",
      "Loss: tensor(0.1081, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3629\n",
      "Loss: tensor(0.1081, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3630\n",
      "Loss: tensor(0.1081, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3631\n",
      "Loss: tensor(0.1081, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3632\n",
      "Loss: tensor(0.1081, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3633\n",
      "Loss: tensor(0.1081, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3634\n",
      "Loss: tensor(0.1081, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3635\n",
      "Loss: tensor(0.1081, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3636\n",
      "Loss: tensor(0.1081, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3637\n",
      "Loss: tensor(0.1081, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3638\n",
      "Loss: tensor(0.1081, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3639\n",
      "Loss: tensor(0.1081, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3640\n",
      "Loss: tensor(0.1080, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3641\n",
      "Loss: tensor(0.1080, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3642\n",
      "Loss: tensor(0.1080, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3643\n",
      "Loss: tensor(0.1080, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3644\n",
      "Loss: tensor(0.1080, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3645\n",
      "Loss: tensor(0.1080, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3646\n",
      "Loss: tensor(0.1080, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3647\n",
      "Loss: tensor(0.1080, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3648\n",
      "Loss: tensor(0.1080, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3649\n",
      "Loss: tensor(0.1080, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3650\n",
      "Loss: tensor(0.1080, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3651\n",
      "Loss: tensor(0.1080, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3652\n",
      "Loss: tensor(0.1080, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3653\n",
      "Loss: tensor(0.1079, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3654\n",
      "Loss: tensor(0.1079, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3655\n",
      "Loss: tensor(0.1079, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3656\n",
      "Loss: tensor(0.1079, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3657\n",
      "Loss: tensor(0.1079, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3658\n",
      "Loss: tensor(0.1079, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3659\n",
      "Loss: tensor(0.1079, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3660\n",
      "Loss: tensor(0.1079, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3661\n",
      "Loss: tensor(0.1079, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3662\n",
      "Loss: tensor(0.1079, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3663\n",
      "Loss: tensor(0.1079, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3664\n",
      "Loss: tensor(0.1079, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3665\n",
      "Loss: tensor(0.1079, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3666\n",
      "Loss: tensor(0.1079, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3667\n",
      "Loss: tensor(0.1079, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3668\n",
      "Loss: tensor(0.1078, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3669\n",
      "Loss: tensor(0.1078, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3670\n",
      "Loss: tensor(0.1078, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3671\n",
      "Loss: tensor(0.1078, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3672\n",
      "Loss: tensor(0.1078, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3673\n",
      "Loss: tensor(0.1078, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3674\n",
      "Loss: tensor(0.1078, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3675\n",
      "Loss: tensor(0.1078, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3676\n",
      "Loss: tensor(0.1078, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3677\n",
      "Loss: tensor(0.1078, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3678\n",
      "Loss: tensor(0.1078, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3679\n",
      "Loss: tensor(0.1078, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3680\n",
      "Loss: tensor(0.1078, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3681\n",
      "Loss: tensor(0.1078, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3682\n",
      "Loss: tensor(0.1078, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3683\n",
      "Loss: tensor(0.1077, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3684\n",
      "Loss: tensor(0.1077, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3685\n",
      "Loss: tensor(0.1077, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3686\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor(0.1077, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3687\n",
      "Loss: tensor(0.1077, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3688\n",
      "Loss: tensor(0.1077, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3689\n",
      "Loss: tensor(0.1077, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3690\n",
      "Loss: tensor(0.1077, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3691\n",
      "Loss: tensor(0.1077, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3692\n",
      "Loss: tensor(0.1077, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3693\n",
      "Loss: tensor(0.1077, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3694\n",
      "Loss: tensor(0.1077, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3695\n",
      "Loss: tensor(0.1077, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3696\n",
      "Loss: tensor(0.1077, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3697\n",
      "Loss: tensor(0.1076, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3698\n",
      "Loss: tensor(0.1076, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3699\n",
      "Loss: tensor(0.1076, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3700\n",
      "Loss: tensor(0.1076, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3701\n",
      "Loss: tensor(0.1076, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3702\n",
      "Loss: tensor(0.1076, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3703\n",
      "Loss: tensor(0.1076, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3704\n",
      "Loss: tensor(0.1076, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3705\n",
      "Loss: tensor(0.1076, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3706\n",
      "Loss: tensor(0.1076, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3707\n",
      "Loss: tensor(0.1076, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3708\n",
      "Loss: tensor(0.1076, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3709\n",
      "Loss: tensor(0.1076, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3710\n",
      "Loss: tensor(0.1076, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3711\n",
      "Loss: tensor(0.1076, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3712\n",
      "Loss: tensor(0.1075, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3713\n",
      "Loss: tensor(0.1075, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3714\n",
      "Loss: tensor(0.1075, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3715\n",
      "Loss: tensor(0.1075, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3716\n",
      "Loss: tensor(0.1075, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3717\n",
      "Loss: tensor(0.1075, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3718\n",
      "Loss: tensor(0.1075, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3719\n",
      "Loss: tensor(0.1075, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3720\n",
      "Loss: tensor(0.1075, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3721\n",
      "Loss: tensor(0.1075, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3722\n",
      "Loss: tensor(0.1075, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3723\n",
      "Loss: tensor(0.1075, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3724\n",
      "Loss: tensor(0.1075, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3725\n",
      "Loss: tensor(0.1075, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3726\n",
      "Loss: tensor(0.1075, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3727\n",
      "Loss: tensor(0.1074, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3728\n",
      "Loss: tensor(0.1074, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3729\n",
      "Loss: tensor(0.1074, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3730\n",
      "Loss: tensor(0.1074, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3731\n",
      "Loss: tensor(0.1074, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3732\n",
      "Loss: tensor(0.1074, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3733\n",
      "Loss: tensor(0.1074, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3734\n",
      "Loss: tensor(0.1074, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3735\n",
      "Loss: tensor(0.1074, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3736\n",
      "Loss: tensor(0.1074, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3737\n",
      "Loss: tensor(0.1074, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3738\n",
      "Loss: tensor(0.1074, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3739\n",
      "Loss: tensor(0.1074, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3740\n",
      "Loss: tensor(0.1074, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3741\n",
      "Loss: tensor(0.1074, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3742\n",
      "Loss: tensor(0.1074, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3743\n",
      "Loss: tensor(0.1073, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3744\n",
      "Loss: tensor(0.1073, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3745\n",
      "Loss: tensor(0.1073, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3746\n",
      "Loss: tensor(0.1073, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3747\n",
      "Loss: tensor(0.1073, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3748\n",
      "Loss: tensor(0.1073, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3749\n",
      "Loss: tensor(0.1073, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3750\n",
      "Loss: tensor(0.1073, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3751\n",
      "Loss: tensor(0.1073, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3752\n",
      "Loss: tensor(0.1073, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3753\n",
      "Loss: tensor(0.1073, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3754\n",
      "Loss: tensor(0.1073, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3755\n",
      "Loss: tensor(0.1073, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3756\n",
      "Loss: tensor(0.1073, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3757\n",
      "Loss: tensor(0.1073, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3758\n",
      "Loss: tensor(0.1073, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3759\n",
      "Loss: tensor(0.1072, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3760\n",
      "Loss: tensor(0.1072, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3761\n",
      "Loss: tensor(0.1072, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3762\n",
      "Loss: tensor(0.1072, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3763\n",
      "Loss: tensor(0.1072, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3764\n",
      "Loss: tensor(0.1072, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3765\n",
      "Loss: tensor(0.1072, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3766\n",
      "Loss: tensor(0.1072, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3767\n",
      "Loss: tensor(0.1072, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3768\n",
      "Loss: tensor(0.1072, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3769\n",
      "Loss: tensor(0.1072, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3770\n",
      "Loss: tensor(0.1072, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3771\n",
      "Loss: tensor(0.1072, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3772\n",
      "Loss: tensor(0.1072, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3773\n",
      "Loss: tensor(0.1072, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3774\n",
      "Loss: tensor(0.1072, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3775\n",
      "Loss: tensor(0.1072, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3776\n",
      "Loss: tensor(0.1071, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3777\n",
      "Loss: tensor(0.1071, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3778\n",
      "Loss: tensor(0.1071, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3779\n",
      "Loss: tensor(0.1071, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3780\n",
      "Loss: tensor(0.1071, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3781\n",
      "Loss: tensor(0.1071, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3782\n",
      "Loss: tensor(0.1071, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3783\n",
      "Loss: tensor(0.1071, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3784\n",
      "Loss: tensor(0.1071, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3785\n",
      "Loss: tensor(0.1071, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3786\n",
      "Loss: tensor(0.1071, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3787\n",
      "Loss: tensor(0.1071, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3788\n",
      "Loss: tensor(0.1071, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3789\n",
      "Loss: tensor(0.1071, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3790\n",
      "Loss: tensor(0.1071, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3791\n",
      "Loss: tensor(0.1070, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3792\n",
      "Loss: tensor(0.1070, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3793\n",
      "Loss: tensor(0.1070, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3794\n",
      "Loss: tensor(0.1070, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3795\n",
      "Loss: tensor(0.1070, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3796\n",
      "Loss: tensor(0.1070, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3797\n",
      "Loss: tensor(0.1070, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3798\n",
      "Loss: tensor(0.1070, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3799\n",
      "Loss: tensor(0.1070, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3800\n",
      "Loss: tensor(0.1070, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3801\n",
      "Loss: tensor(0.1070, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3802\n",
      "Loss: tensor(0.1070, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3803\n",
      "Loss: tensor(0.1070, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3804\n",
      "Loss: tensor(0.1070, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3805\n",
      "Loss: tensor(0.1070, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3806\n",
      "Loss: tensor(0.1070, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3807\n",
      "Loss: tensor(0.1070, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3808\n",
      "Loss: tensor(0.1069, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3809\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor(0.1069, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3810\n",
      "Loss: tensor(0.1069, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3811\n",
      "Loss: tensor(0.1069, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3812\n",
      "Loss: tensor(0.1069, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3813\n",
      "Loss: tensor(0.1069, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3814\n",
      "Loss: tensor(0.1069, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3815\n",
      "Loss: tensor(0.1069, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3816\n",
      "Loss: tensor(0.1069, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3817\n",
      "Loss: tensor(0.1069, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3818\n",
      "Loss: tensor(0.1069, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3819\n",
      "Loss: tensor(0.1069, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3820\n",
      "Loss: tensor(0.1069, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3821\n",
      "Loss: tensor(0.1069, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3822\n",
      "Loss: tensor(0.1069, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3823\n",
      "Loss: tensor(0.1069, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3824\n",
      "Loss: tensor(0.1069, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3825\n",
      "Loss: tensor(0.1068, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3826\n",
      "Loss: tensor(0.1068, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3827\n",
      "Loss: tensor(0.1068, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3828\n",
      "Loss: tensor(0.1068, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3829\n",
      "Loss: tensor(0.1068, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3830\n",
      "Loss: tensor(0.1068, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3831\n",
      "Loss: tensor(0.1068, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3832\n",
      "Loss: tensor(0.1068, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3833\n",
      "Loss: tensor(0.1068, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3834\n",
      "Loss: tensor(0.1068, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3835\n",
      "Loss: tensor(0.1068, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3836\n",
      "Loss: tensor(0.1068, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3837\n",
      "Loss: tensor(0.1068, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3838\n",
      "Loss: tensor(0.1068, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3839\n",
      "Loss: tensor(0.1068, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3840\n",
      "Loss: tensor(0.1068, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3841\n",
      "Loss: tensor(0.1068, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3842\n",
      "Loss: tensor(0.1068, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3843\n",
      "Loss: tensor(0.1067, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3844\n",
      "Loss: tensor(0.1067, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3845\n",
      "Loss: tensor(0.1067, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3846\n",
      "Loss: tensor(0.1067, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3847\n",
      "Loss: tensor(0.1067, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3848\n",
      "Loss: tensor(0.1067, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3849\n",
      "Loss: tensor(0.1067, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3850\n",
      "Loss: tensor(0.1067, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3851\n",
      "Loss: tensor(0.1067, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3852\n",
      "Loss: tensor(0.1067, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3853\n",
      "Loss: tensor(0.1067, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3854\n",
      "Loss: tensor(0.1067, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3855\n",
      "Loss: tensor(0.1067, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3856\n",
      "Loss: tensor(0.1067, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3857\n",
      "Loss: tensor(0.1067, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3858\n",
      "Loss: tensor(0.1067, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3859\n",
      "Loss: tensor(0.1067, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3860\n",
      "Loss: tensor(0.1067, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3861\n",
      "Loss: tensor(0.1066, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3862\n",
      "Loss: tensor(0.1066, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3863\n",
      "Loss: tensor(0.1066, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3864\n",
      "Loss: tensor(0.1066, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3865\n",
      "Loss: tensor(0.1066, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3866\n",
      "Loss: tensor(0.1066, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3867\n",
      "Loss: tensor(0.1066, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3868\n",
      "Loss: tensor(0.1066, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3869\n",
      "Loss: tensor(0.1066, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3870\n",
      "Loss: tensor(0.1066, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3871\n",
      "Loss: tensor(0.1066, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3872\n",
      "Loss: tensor(0.1066, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3873\n",
      "Loss: tensor(0.1066, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3874\n",
      "Loss: tensor(0.1066, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3875\n",
      "Loss: tensor(0.1066, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3876\n",
      "Loss: tensor(0.1066, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3877\n",
      "Loss: tensor(0.1066, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3878\n",
      "Loss: tensor(0.1065, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3879\n",
      "Loss: tensor(0.1065, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3880\n",
      "Loss: tensor(0.1065, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3881\n",
      "Loss: tensor(0.1065, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3882\n",
      "Loss: tensor(0.1065, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3883\n",
      "Loss: tensor(0.1065, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3884\n",
      "Loss: tensor(0.1065, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3885\n",
      "Loss: tensor(0.1065, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3886\n",
      "Loss: tensor(0.1065, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3887\n",
      "Loss: tensor(0.1065, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3888\n",
      "Loss: tensor(0.1065, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3889\n",
      "Loss: tensor(0.1065, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3890\n",
      "Loss: tensor(0.1065, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3891\n",
      "Loss: tensor(0.1065, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3892\n",
      "Loss: tensor(0.1065, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3893\n",
      "Loss: tensor(0.1065, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3894\n",
      "Loss: tensor(0.1065, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3895\n",
      "Loss: tensor(0.1065, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3896\n",
      "Loss: tensor(0.1064, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3897\n",
      "Loss: tensor(0.1064, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3898\n",
      "Loss: tensor(0.1064, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3899\n",
      "Loss: tensor(0.1064, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3900\n",
      "Loss: tensor(0.1064, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3901\n",
      "Loss: tensor(0.1064, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3902\n",
      "Loss: tensor(0.1064, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3903\n",
      "Loss: tensor(0.1064, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3904\n",
      "Loss: tensor(0.1064, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3905\n",
      "Loss: tensor(0.1064, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3906\n",
      "Loss: tensor(0.1064, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3907\n",
      "Loss: tensor(0.1064, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3908\n",
      "Loss: tensor(0.1064, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3909\n",
      "Loss: tensor(0.1064, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3910\n",
      "Loss: tensor(0.1064, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3911\n",
      "Loss: tensor(0.1064, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3912\n",
      "Loss: tensor(0.1064, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3913\n",
      "Loss: tensor(0.1064, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3914\n",
      "Loss: tensor(0.1064, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3915\n",
      "Loss: tensor(0.1063, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3916\n",
      "Loss: tensor(0.1063, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3917\n",
      "Loss: tensor(0.1063, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3918\n",
      "Loss: tensor(0.1063, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3919\n",
      "Loss: tensor(0.1063, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3920\n",
      "Loss: tensor(0.1063, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3921\n",
      "Loss: tensor(0.1063, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3922\n",
      "Loss: tensor(0.1063, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3923\n",
      "Loss: tensor(0.1063, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3924\n",
      "Loss: tensor(0.1063, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3925\n",
      "Loss: tensor(0.1063, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3926\n",
      "Loss: tensor(0.1063, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3927\n",
      "Loss: tensor(0.1063, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3928\n",
      "Loss: tensor(0.1063, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3929\n",
      "Loss: tensor(0.1063, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3930\n",
      "Loss: tensor(0.1063, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3931\n",
      "Loss: tensor(0.1063, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3932\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor(0.1063, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3933\n",
      "Loss: tensor(0.1063, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3934\n",
      "Loss: tensor(0.1062, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3935\n",
      "Loss: tensor(0.1062, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3936\n",
      "Loss: tensor(0.1062, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3937\n",
      "Loss: tensor(0.1062, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3938\n",
      "Loss: tensor(0.1062, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3939\n",
      "Loss: tensor(0.1062, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3940\n",
      "Loss: tensor(0.1062, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3941\n",
      "Loss: tensor(0.1062, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3942\n",
      "Loss: tensor(0.1062, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3943\n",
      "Loss: tensor(0.1062, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3944\n",
      "Loss: tensor(0.1062, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3945\n",
      "Loss: tensor(0.1062, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3946\n",
      "Loss: tensor(0.1062, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3947\n",
      "Loss: tensor(0.1062, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3948\n",
      "Loss: tensor(0.1062, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3949\n",
      "Loss: tensor(0.1062, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3950\n",
      "Loss: tensor(0.1062, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3951\n",
      "Loss: tensor(0.1062, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3952\n",
      "Loss: tensor(0.1062, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3953\n",
      "Loss: tensor(0.1062, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3954\n",
      "Loss: tensor(0.1061, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3955\n",
      "Loss: tensor(0.1061, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3956\n",
      "Loss: tensor(0.1061, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3957\n",
      "Loss: tensor(0.1061, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3958\n",
      "Loss: tensor(0.1061, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3959\n",
      "Loss: tensor(0.1061, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3960\n",
      "Loss: tensor(0.1061, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3961\n",
      "Loss: tensor(0.1061, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3962\n",
      "Loss: tensor(0.1061, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3963\n",
      "Loss: tensor(0.1061, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3964\n",
      "Loss: tensor(0.1061, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3965\n",
      "Loss: tensor(0.1061, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3966\n",
      "Loss: tensor(0.1061, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3967\n",
      "Loss: tensor(0.1061, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3968\n",
      "Loss: tensor(0.1061, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3969\n",
      "Loss: tensor(0.1061, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3970\n",
      "Loss: tensor(0.1061, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3971\n",
      "Loss: tensor(0.1061, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3972\n",
      "Loss: tensor(0.1061, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3973\n",
      "Loss: tensor(0.1060, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3974\n",
      "Loss: tensor(0.1060, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3975\n",
      "Loss: tensor(0.1060, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3976\n",
      "Loss: tensor(0.1060, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3977\n",
      "Loss: tensor(0.1060, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3978\n",
      "Loss: tensor(0.1060, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3979\n",
      "Loss: tensor(0.1060, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3980\n",
      "Loss: tensor(0.1060, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3981\n",
      "Loss: tensor(0.1060, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3982\n",
      "Loss: tensor(0.1060, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3983\n",
      "Loss: tensor(0.1060, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3984\n",
      "Loss: tensor(0.1060, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3985\n",
      "Loss: tensor(0.1060, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3986\n",
      "Loss: tensor(0.1060, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3987\n",
      "Loss: tensor(0.1060, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3988\n",
      "Loss: tensor(0.1060, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3989\n",
      "Loss: tensor(0.1060, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3990\n",
      "Loss: tensor(0.1060, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3991\n",
      "Loss: tensor(0.1060, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3992\n",
      "Loss: tensor(0.1060, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3993\n",
      "Loss: tensor(0.1060, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3994\n",
      "Loss: tensor(0.1059, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3995\n",
      "Loss: tensor(0.1059, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3996\n",
      "Loss: tensor(0.1059, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3997\n",
      "Loss: tensor(0.1059, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3998\n",
      "Loss: tensor(0.1059, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3999\n",
      "Loss: tensor(0.1059, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4000\n",
      "Loss: tensor(0.1059, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4001\n",
      "Loss: tensor(0.1059, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4002\n",
      "Loss: tensor(0.1059, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4003\n",
      "Loss: tensor(0.1059, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4004\n",
      "Loss: tensor(0.1059, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4005\n",
      "Loss: tensor(0.1059, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4006\n",
      "Loss: tensor(0.1059, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4007\n",
      "Loss: tensor(0.1059, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4008\n",
      "Loss: tensor(0.1059, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4009\n",
      "Loss: tensor(0.1059, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4010\n",
      "Loss: tensor(0.1059, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4011\n",
      "Loss: tensor(0.1059, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4012\n",
      "Loss: tensor(0.1059, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4013\n",
      "Loss: tensor(0.1059, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4014\n",
      "Loss: tensor(0.1059, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4015\n",
      "Loss: tensor(0.1059, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4016\n",
      "Loss: tensor(0.1058, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4017\n",
      "Loss: tensor(0.1058, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4018\n",
      "Loss: tensor(0.1058, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4019\n",
      "Loss: tensor(0.1058, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4020\n",
      "Loss: tensor(0.1058, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4021\n",
      "Loss: tensor(0.1058, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4022\n",
      "Loss: tensor(0.1058, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4023\n",
      "Loss: tensor(0.1058, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4024\n",
      "Loss: tensor(0.1058, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4025\n",
      "Loss: tensor(0.1058, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4026\n",
      "Loss: tensor(0.1058, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4027\n",
      "Loss: tensor(0.1058, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4028\n",
      "Loss: tensor(0.1058, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4029\n",
      "Loss: tensor(0.1058, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4030\n",
      "Loss: tensor(0.1058, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4031\n",
      "Loss: tensor(0.1058, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4032\n",
      "Loss: tensor(0.1058, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4033\n",
      "Loss: tensor(0.1058, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4034\n",
      "Loss: tensor(0.1058, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4035\n",
      "Loss: tensor(0.1058, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4036\n",
      "Loss: tensor(0.1057, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4037\n",
      "Loss: tensor(0.1057, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4038\n",
      "Loss: tensor(0.1057, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4039\n",
      "Loss: tensor(0.1057, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4040\n",
      "Loss: tensor(0.1057, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4041\n",
      "Loss: tensor(0.1057, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4042\n",
      "Loss: tensor(0.1057, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4043\n",
      "Loss: tensor(0.1057, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4044\n",
      "Loss: tensor(0.1057, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4045\n",
      "Loss: tensor(0.1057, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4046\n",
      "Loss: tensor(0.1057, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4047\n",
      "Loss: tensor(0.1057, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4048\n",
      "Loss: tensor(0.1057, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4049\n",
      "Loss: tensor(0.1057, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4050\n",
      "Loss: tensor(0.1057, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4051\n",
      "Loss: tensor(0.1057, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4052\n",
      "Loss: tensor(0.1057, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4053\n",
      "Loss: tensor(0.1057, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4054\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor(0.1057, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4055\n",
      "Loss: tensor(0.1057, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4056\n",
      "Loss: tensor(0.1057, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4057\n",
      "Loss: tensor(0.1056, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4058\n",
      "Loss: tensor(0.1056, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4059\n",
      "Loss: tensor(0.1056, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4060\n",
      "Loss: tensor(0.1056, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4061\n",
      "Loss: tensor(0.1056, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4062\n",
      "Loss: tensor(0.1056, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4063\n",
      "Loss: tensor(0.1056, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4064\n",
      "Loss: tensor(0.1056, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4065\n",
      "Loss: tensor(0.1056, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4066\n",
      "Loss: tensor(0.1056, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4067\n",
      "Loss: tensor(0.1056, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4068\n",
      "Loss: tensor(0.1056, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4069\n",
      "Loss: tensor(0.1056, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4070\n",
      "Loss: tensor(0.1056, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4071\n",
      "Loss: tensor(0.1056, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4072\n",
      "Loss: tensor(0.1056, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4073\n",
      "Loss: tensor(0.1056, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4074\n",
      "Loss: tensor(0.1056, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4075\n",
      "Loss: tensor(0.1056, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4076\n",
      "Loss: tensor(0.1056, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4077\n",
      "Loss: tensor(0.1056, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4078\n",
      "Loss: tensor(0.1056, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4079\n",
      "Loss: tensor(0.1055, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4080\n",
      "Loss: tensor(0.1055, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4081\n",
      "Loss: tensor(0.1055, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4082\n",
      "Loss: tensor(0.1055, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4083\n",
      "Loss: tensor(0.1055, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4084\n",
      "Loss: tensor(0.1055, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4085\n",
      "Loss: tensor(0.1055, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4086\n",
      "Loss: tensor(0.1055, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4087\n",
      "Loss: tensor(0.1055, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4088\n",
      "Loss: tensor(0.1055, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4089\n",
      "Loss: tensor(0.1055, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4090\n",
      "Loss: tensor(0.1055, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4091\n",
      "Loss: tensor(0.1055, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4092\n",
      "Loss: tensor(0.1055, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4093\n",
      "Loss: tensor(0.1055, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4094\n",
      "Loss: tensor(0.1055, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4095\n",
      "Loss: tensor(0.1055, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4096\n",
      "Loss: tensor(0.1055, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4097\n",
      "Loss: tensor(0.1055, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4098\n",
      "Loss: tensor(0.1055, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4099\n",
      "Loss: tensor(0.1055, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4100\n",
      "Loss: tensor(0.1055, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4101\n",
      "Loss: tensor(0.1055, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4102\n",
      "Loss: tensor(0.1055, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4103\n",
      "Loss: tensor(0.1055, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4104\n",
      "Loss: tensor(0.1054, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4105\n",
      "Loss: tensor(0.1054, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4106\n",
      "Loss: tensor(0.1054, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4107\n",
      "Loss: tensor(0.1054, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4108\n",
      "Loss: tensor(0.1054, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4109\n",
      "Loss: tensor(0.1054, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4110\n",
      "Loss: tensor(0.1054, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4111\n",
      "Loss: tensor(0.1054, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4112\n",
      "Loss: tensor(0.1054, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4113\n",
      "Loss: tensor(0.1054, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4114\n",
      "Loss: tensor(0.1054, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4115\n",
      "Loss: tensor(0.1054, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4116\n",
      "Loss: tensor(0.1054, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4117\n",
      "Loss: tensor(0.1054, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4118\n",
      "Loss: tensor(0.1054, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4119\n",
      "Loss: tensor(0.1054, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4120\n",
      "Loss: tensor(0.1054, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4121\n",
      "Loss: tensor(0.1054, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4122\n",
      "Loss: tensor(0.1054, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4123\n",
      "Loss: tensor(0.1054, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4124\n",
      "Loss: tensor(0.1054, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4125\n",
      "Loss: tensor(0.1053, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4126\n",
      "Loss: tensor(0.1053, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4127\n",
      "Loss: tensor(0.1053, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4128\n",
      "Loss: tensor(0.1053, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4129\n",
      "Loss: tensor(0.1053, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4130\n",
      "Loss: tensor(0.1053, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4131\n",
      "Loss: tensor(0.1053, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4132\n",
      "Loss: tensor(0.1053, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4133\n",
      "Loss: tensor(0.1053, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4134\n",
      "Loss: tensor(0.1053, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4135\n",
      "Loss: tensor(0.1053, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4136\n",
      "Loss: tensor(0.1053, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4137\n",
      "Loss: tensor(0.1053, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4138\n",
      "Loss: tensor(0.1053, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4139\n",
      "Loss: tensor(0.1053, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4140\n",
      "Loss: tensor(0.1053, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4141\n",
      "Loss: tensor(0.1053, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4142\n",
      "Loss: tensor(0.1053, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4143\n",
      "Loss: tensor(0.1053, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4144\n",
      "Loss: tensor(0.1053, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4145\n",
      "Loss: tensor(0.1053, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4146\n",
      "Loss: tensor(0.1053, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4147\n",
      "Loss: tensor(0.1053, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4148\n",
      "Loss: tensor(0.1053, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4149\n",
      "Loss: tensor(0.1052, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4150\n",
      "Loss: tensor(0.1052, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4151\n",
      "Loss: tensor(0.1052, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4152\n",
      "Loss: tensor(0.1052, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4153\n",
      "Loss: tensor(0.1052, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4154\n",
      "Loss: tensor(0.1052, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4155\n",
      "Loss: tensor(0.1052, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4156\n",
      "Loss: tensor(0.1052, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4157\n",
      "Loss: tensor(0.1052, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4158\n",
      "Loss: tensor(0.1052, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4159\n",
      "Loss: tensor(0.1052, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4160\n",
      "Loss: tensor(0.1052, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4161\n",
      "Loss: tensor(0.1052, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4162\n",
      "Loss: tensor(0.1052, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4163\n",
      "Loss: tensor(0.1052, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4164\n",
      "Loss: tensor(0.1052, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4165\n",
      "Loss: tensor(0.1052, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4166\n",
      "Loss: tensor(0.1052, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4167\n",
      "Loss: tensor(0.1052, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4168\n",
      "Loss: tensor(0.1052, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4169\n",
      "Loss: tensor(0.1052, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4170\n",
      "Loss: tensor(0.1052, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4171\n",
      "Loss: tensor(0.1052, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4172\n",
      "Loss: tensor(0.1052, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4173\n",
      "Loss: tensor(0.1051, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4174\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor(0.1051, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4175\n",
      "Loss: tensor(0.1051, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4176\n",
      "Loss: tensor(0.1051, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4177\n",
      "Loss: tensor(0.1051, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4178\n",
      "Loss: tensor(0.1051, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4179\n",
      "Loss: tensor(0.1051, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4180\n",
      "Loss: tensor(0.1051, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4181\n",
      "Loss: tensor(0.1051, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4182\n",
      "Loss: tensor(0.1051, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4183\n",
      "Loss: tensor(0.1051, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4184\n",
      "Loss: tensor(0.1051, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4185\n",
      "Loss: tensor(0.1051, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4186\n",
      "Loss: tensor(0.1051, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4187\n",
      "Loss: tensor(0.1051, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4188\n",
      "Loss: tensor(0.1051, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4189\n",
      "Loss: tensor(0.1051, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4190\n",
      "Loss: tensor(0.1051, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4191\n",
      "Loss: tensor(0.1051, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4192\n",
      "Loss: tensor(0.1051, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4193\n",
      "Loss: tensor(0.1051, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4194\n",
      "Loss: tensor(0.1051, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4195\n",
      "Loss: tensor(0.1051, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4196\n",
      "Loss: tensor(0.1051, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4197\n",
      "Loss: tensor(0.1051, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4198\n",
      "Loss: tensor(0.1051, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4199\n",
      "Loss: tensor(0.1051, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4200\n",
      "Loss: tensor(0.1051, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4201\n",
      "Loss: tensor(0.1051, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4202\n",
      "Loss: tensor(0.1050, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4203\n",
      "Loss: tensor(0.1050, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4204\n",
      "Loss: tensor(0.1050, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4205\n",
      "Loss: tensor(0.1050, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4206\n",
      "Loss: tensor(0.1050, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4207\n",
      "Loss: tensor(0.1050, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4208\n",
      "Loss: tensor(0.1050, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4209\n",
      "Loss: tensor(0.1050, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4210\n",
      "Loss: tensor(0.1050, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4211\n",
      "Loss: tensor(0.1050, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4212\n",
      "Loss: tensor(0.1050, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4213\n",
      "Loss: tensor(0.1050, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4214\n",
      "Loss: tensor(0.1050, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4215\n",
      "Loss: tensor(0.1050, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4216\n",
      "Loss: tensor(0.1050, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4217\n",
      "Loss: tensor(0.1050, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4218\n",
      "Loss: tensor(0.1050, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4219\n",
      "Loss: tensor(0.1050, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4220\n",
      "Loss: tensor(0.1050, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4221\n",
      "Loss: tensor(0.1050, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4222\n",
      "Loss: tensor(0.1050, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4223\n",
      "Loss: tensor(0.1050, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4224\n",
      "Loss: tensor(0.1049, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4225\n",
      "Loss: tensor(0.1049, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4226\n",
      "Loss: tensor(0.1049, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4227\n",
      "Loss: tensor(0.1049, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4228\n",
      "Loss: tensor(0.1049, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4229\n",
      "Loss: tensor(0.1049, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4230\n",
      "Loss: tensor(0.1049, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4231\n",
      "Loss: tensor(0.1049, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4232\n",
      "Loss: tensor(0.1049, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4233\n",
      "Loss: tensor(0.1049, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4234\n",
      "Loss: tensor(0.1049, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4235\n",
      "Loss: tensor(0.1049, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4236\n",
      "Loss: tensor(0.1049, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4237\n",
      "Loss: tensor(0.1049, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4238\n",
      "Loss: tensor(0.1049, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4239\n",
      "Loss: tensor(0.1049, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4240\n",
      "Loss: tensor(0.1049, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4241\n",
      "Loss: tensor(0.1049, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4242\n",
      "Loss: tensor(0.1049, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4243\n",
      "Loss: tensor(0.1049, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4244\n",
      "Loss: tensor(0.1049, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4245\n",
      "Loss: tensor(0.1049, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4246\n",
      "Loss: tensor(0.1049, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4247\n",
      "Loss: tensor(0.1049, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4248\n",
      "Loss: tensor(0.1049, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4249\n",
      "Loss: tensor(0.1049, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4250\n",
      "Loss: tensor(0.1048, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4251\n",
      "Loss: tensor(0.1048, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4252\n",
      "Loss: tensor(0.1048, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4253\n",
      "Loss: tensor(0.1048, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4254\n",
      "Loss: tensor(0.1048, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4255\n",
      "Loss: tensor(0.1048, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4256\n",
      "Loss: tensor(0.1048, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4257\n",
      "Loss: tensor(0.1048, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4258\n",
      "Loss: tensor(0.1048, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4259\n",
      "Loss: tensor(0.1048, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4260\n",
      "Loss: tensor(0.1048, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4261\n",
      "Loss: tensor(0.1048, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4262\n",
      "Loss: tensor(0.1048, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4263\n",
      "Loss: tensor(0.1048, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4264\n",
      "Loss: tensor(0.1048, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4265\n",
      "Loss: tensor(0.1048, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4266\n",
      "Loss: tensor(0.1048, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4267\n",
      "Loss: tensor(0.1048, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4268\n",
      "Loss: tensor(0.1048, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4269\n",
      "Loss: tensor(0.1048, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4270\n",
      "Loss: tensor(0.1048, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4271\n",
      "Loss: tensor(0.1048, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4272\n",
      "Loss: tensor(0.1048, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4273\n",
      "Loss: tensor(0.1048, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4274\n",
      "Loss: tensor(0.1048, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4275\n",
      "Loss: tensor(0.1048, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4276\n",
      "Loss: tensor(0.1048, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4277\n",
      "Loss: tensor(0.1048, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4278\n",
      "Loss: tensor(0.1048, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4279\n",
      "Loss: tensor(0.1048, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4280\n",
      "Loss: tensor(0.1047, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4281\n",
      "Loss: tensor(0.1047, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4282\n",
      "Loss: tensor(0.1047, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4283\n",
      "Loss: tensor(0.1047, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4284\n",
      "Loss: tensor(0.1047, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4285\n",
      "Loss: tensor(0.1047, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4286\n",
      "Loss: tensor(0.1047, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4287\n",
      "Loss: tensor(0.1047, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4288\n",
      "Loss: tensor(0.1047, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4289\n",
      "Loss: tensor(0.1047, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4290\n",
      "Loss: tensor(0.1047, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4291\n",
      "Loss: tensor(0.1047, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4292\n",
      "Loss: tensor(0.1047, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4293\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor(0.1047, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4294\n",
      "Loss: tensor(0.1047, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4295\n",
      "Loss: tensor(0.1047, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4296\n",
      "Loss: tensor(0.1047, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4297\n",
      "Loss: tensor(0.1047, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4298\n",
      "Loss: tensor(0.1047, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4299\n",
      "Loss: tensor(0.1047, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4300\n",
      "Loss: tensor(0.1047, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4301\n",
      "Loss: tensor(0.1047, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4302\n",
      "Loss: tensor(0.1047, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4303\n",
      "Loss: tensor(0.1047, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4304\n",
      "Loss: tensor(0.1046, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4305\n",
      "Loss: tensor(0.1046, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4306\n",
      "Loss: tensor(0.1046, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4307\n",
      "Loss: tensor(0.1046, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4308\n",
      "Loss: tensor(0.1046, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4309\n",
      "Loss: tensor(0.1046, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4310\n",
      "Loss: tensor(0.1046, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4311\n",
      "Loss: tensor(0.1046, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4312\n",
      "Loss: tensor(0.1046, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4313\n",
      "Loss: tensor(0.1046, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4314\n",
      "Loss: tensor(0.1046, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4315\n",
      "Loss: tensor(0.1046, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4316\n",
      "Loss: tensor(0.1046, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4317\n",
      "Loss: tensor(0.1046, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4318\n",
      "Loss: tensor(0.1046, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4319\n",
      "Loss: tensor(0.1046, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4320\n",
      "Loss: tensor(0.1046, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4321\n",
      "Loss: tensor(0.1046, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4322\n",
      "Loss: tensor(0.1046, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4323\n",
      "Loss: tensor(0.1046, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4324\n",
      "Loss: tensor(0.1046, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4325\n",
      "Loss: tensor(0.1046, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4326\n",
      "Loss: tensor(0.1046, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4327\n",
      "Loss: tensor(0.1046, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4328\n",
      "Loss: tensor(0.1046, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4329\n",
      "Loss: tensor(0.1046, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4330\n",
      "Loss: tensor(0.1046, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4331\n",
      "Loss: tensor(0.1046, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4332\n",
      "Loss: tensor(0.1045, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4333\n",
      "Loss: tensor(0.1045, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4334\n",
      "Loss: tensor(0.1045, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4335\n",
      "Loss: tensor(0.1045, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4336\n",
      "Loss: tensor(0.1045, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4337\n",
      "Loss: tensor(0.1045, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4338\n",
      "Loss: tensor(0.1045, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4339\n",
      "Loss: tensor(0.1045, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4340\n",
      "Loss: tensor(0.1045, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4341\n",
      "Loss: tensor(0.1045, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4342\n",
      "Loss: tensor(0.1045, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4343\n",
      "Loss: tensor(0.1045, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4344\n",
      "Loss: tensor(0.1045, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4345\n",
      "Loss: tensor(0.1045, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4346\n",
      "Loss: tensor(0.1045, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4347\n",
      "Loss: tensor(0.1045, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4348\n",
      "Loss: tensor(0.1045, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4349\n",
      "Loss: tensor(0.1045, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4350\n",
      "Loss: tensor(0.1045, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4351\n",
      "Loss: tensor(0.1045, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4352\n",
      "Loss: tensor(0.1045, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4353\n",
      "Loss: tensor(0.1045, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4354\n",
      "Loss: tensor(0.1045, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4355\n",
      "Loss: tensor(0.1045, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4356\n",
      "Loss: tensor(0.1045, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4357\n",
      "Loss: tensor(0.1045, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4358\n",
      "Loss: tensor(0.1045, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4359\n",
      "Loss: tensor(0.1045, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4360\n",
      "Loss: tensor(0.1045, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4361\n",
      "Loss: tensor(0.1044, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4362\n",
      "Loss: tensor(0.1044, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4363\n",
      "Loss: tensor(0.1044, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4364\n",
      "Loss: tensor(0.1044, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4365\n",
      "Loss: tensor(0.1044, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4366\n",
      "Loss: tensor(0.1044, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4367\n",
      "Loss: tensor(0.1044, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4368\n",
      "Loss: tensor(0.1044, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4369\n",
      "Loss: tensor(0.1044, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4370\n",
      "Loss: tensor(0.1044, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4371\n",
      "Loss: tensor(0.1044, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4372\n",
      "Loss: tensor(0.1044, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4373\n",
      "Loss: tensor(0.1044, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4374\n",
      "Loss: tensor(0.1044, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4375\n",
      "Loss: tensor(0.1044, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4376\n",
      "Loss: tensor(0.1044, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4377\n",
      "Loss: tensor(0.1044, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4378\n",
      "Loss: tensor(0.1044, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4379\n",
      "Loss: tensor(0.1044, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4380\n",
      "Loss: tensor(0.1044, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4381\n",
      "Loss: tensor(0.1044, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4382\n",
      "Loss: tensor(0.1044, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4383\n",
      "Loss: tensor(0.1044, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4384\n",
      "Loss: tensor(0.1044, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4385\n",
      "Loss: tensor(0.1044, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4386\n",
      "Loss: tensor(0.1044, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4387\n",
      "Loss: tensor(0.1044, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4388\n",
      "Loss: tensor(0.1044, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4389\n",
      "Loss: tensor(0.1044, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4390\n",
      "Loss: tensor(0.1044, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4391\n",
      "Loss: tensor(0.1043, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4392\n",
      "Loss: tensor(0.1043, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4393\n",
      "Loss: tensor(0.1043, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4394\n",
      "Loss: tensor(0.1043, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4395\n",
      "Loss: tensor(0.1043, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4396\n",
      "Loss: tensor(0.1043, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4397\n",
      "Loss: tensor(0.1043, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4398\n",
      "Loss: tensor(0.1043, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4399\n",
      "Loss: tensor(0.1043, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4400\n",
      "Loss: tensor(0.1043, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4401\n",
      "Loss: tensor(0.1043, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4402\n",
      "Loss: tensor(0.1043, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4403\n",
      "Loss: tensor(0.1043, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4404\n",
      "Loss: tensor(0.1043, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4405\n",
      "Loss: tensor(0.1043, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4406\n",
      "Loss: tensor(0.1043, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4407\n",
      "Loss: tensor(0.1043, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4408\n",
      "Loss: tensor(0.1043, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4409\n",
      "Loss: tensor(0.1043, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4410\n",
      "Loss: tensor(0.1043, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4411\n",
      "Loss: tensor(0.1043, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4412\n",
      "Loss: tensor(0.1043, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4413\n",
      "Loss: tensor(0.1043, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4414\n",
      "Loss: tensor(0.1043, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4415\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor(0.1043, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4416\n",
      "Loss: tensor(0.1043, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4417\n",
      "Loss: tensor(0.1043, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4418\n",
      "Loss: tensor(0.1043, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4419\n",
      "Loss: tensor(0.1043, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4420\n",
      "Loss: tensor(0.1043, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4421\n",
      "Loss: tensor(0.1043, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4422\n",
      "Loss: tensor(0.1042, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4423\n",
      "Loss: tensor(0.1042, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4424\n",
      "Loss: tensor(0.1042, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4425\n",
      "Loss: tensor(0.1042, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4426\n",
      "Loss: tensor(0.1042, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4427\n",
      "Loss: tensor(0.1042, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4428\n",
      "Loss: tensor(0.1042, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4429\n",
      "Loss: tensor(0.1042, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4430\n",
      "Loss: tensor(0.1042, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4431\n",
      "Loss: tensor(0.1042, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4432\n",
      "Loss: tensor(0.1042, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4433\n",
      "Loss: tensor(0.1042, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4434\n",
      "Loss: tensor(0.1042, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4435\n",
      "Loss: tensor(0.1042, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4436\n",
      "Loss: tensor(0.1042, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4437\n",
      "Loss: tensor(0.1042, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4438\n",
      "Loss: tensor(0.1042, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4439\n",
      "Loss: tensor(0.1042, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4440\n",
      "Loss: tensor(0.1042, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4441\n",
      "Loss: tensor(0.1042, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4442\n",
      "Loss: tensor(0.1042, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4443\n",
      "Loss: tensor(0.1042, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4444\n",
      "Loss: tensor(0.1042, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4445\n",
      "Loss: tensor(0.1042, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4446\n",
      "Loss: tensor(0.1042, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4447\n",
      "Loss: tensor(0.1042, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4448\n",
      "Loss: tensor(0.1042, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4449\n",
      "Loss: tensor(0.1042, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4450\n",
      "Loss: tensor(0.1042, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4451\n",
      "Loss: tensor(0.1042, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4452\n",
      "Loss: tensor(0.1041, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4453\n",
      "Loss: tensor(0.1041, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4454\n",
      "Loss: tensor(0.1041, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4455\n",
      "Loss: tensor(0.1041, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4456\n",
      "Loss: tensor(0.1041, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4457\n",
      "Loss: tensor(0.1041, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4458\n",
      "Loss: tensor(0.1041, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4459\n",
      "Loss: tensor(0.1041, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4460\n",
      "Loss: tensor(0.1041, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4461\n",
      "Loss: tensor(0.1041, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4462\n",
      "Loss: tensor(0.1041, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4463\n",
      "Loss: tensor(0.1041, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4464\n",
      "Loss: tensor(0.1041, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4465\n",
      "Loss: tensor(0.1041, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4466\n",
      "Loss: tensor(0.1041, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4467\n",
      "Loss: tensor(0.1041, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4468\n",
      "Loss: tensor(0.1041, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4469\n",
      "Loss: tensor(0.1041, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4470\n",
      "Loss: tensor(0.1041, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4471\n",
      "Loss: tensor(0.1041, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4472\n",
      "Loss: tensor(0.1041, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4473\n",
      "Loss: tensor(0.1041, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4474\n",
      "Loss: tensor(0.1041, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4475\n",
      "Loss: tensor(0.1041, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4476\n",
      "Loss: tensor(0.1041, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4477\n",
      "Loss: tensor(0.1041, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4478\n",
      "Loss: tensor(0.1041, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4479\n",
      "Loss: tensor(0.1041, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4480\n",
      "Loss: tensor(0.1041, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4481\n",
      "Loss: tensor(0.1041, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4482\n",
      "Loss: tensor(0.1041, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4483\n",
      "Loss: tensor(0.1041, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4484\n",
      "Loss: tensor(0.1041, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4485\n",
      "Loss: tensor(0.1041, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4486\n",
      "Loss: tensor(0.1041, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4487\n",
      "Loss: tensor(0.1041, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4488\n",
      "Loss: tensor(0.1040, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4489\n",
      "Loss: tensor(0.1040, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4490\n",
      "Loss: tensor(0.1040, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4491\n",
      "Loss: tensor(0.1040, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4492\n",
      "Loss: tensor(0.1040, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4493\n",
      "Loss: tensor(0.1040, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4494\n",
      "Loss: tensor(0.1040, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4495\n",
      "Loss: tensor(0.1040, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4496\n",
      "Loss: tensor(0.1040, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4497\n",
      "Loss: tensor(0.1040, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4498\n",
      "Loss: tensor(0.1040, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4499\n",
      "Loss: tensor(0.1040, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4500\n",
      "Loss: tensor(0.1040, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4501\n",
      "Loss: tensor(0.1040, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4502\n",
      "Loss: tensor(0.1040, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4503\n",
      "Loss: tensor(0.1040, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4504\n",
      "Loss: tensor(0.1040, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4505\n",
      "Loss: tensor(0.1040, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4506\n",
      "Loss: tensor(0.1040, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4507\n",
      "Loss: tensor(0.1040, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4508\n",
      "Loss: tensor(0.1040, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4509\n",
      "Loss: tensor(0.1040, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4510\n",
      "Loss: tensor(0.1040, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4511\n",
      "Loss: tensor(0.1040, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4512\n",
      "Loss: tensor(0.1040, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4513\n",
      "Loss: tensor(0.1040, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4514\n",
      "Loss: tensor(0.1040, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4515\n",
      "Loss: tensor(0.1040, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4516\n",
      "Loss: tensor(0.1040, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4517\n",
      "Loss: tensor(0.1040, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4518\n",
      "Loss: tensor(0.1039, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4519\n",
      "Loss: tensor(0.1039, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4520\n",
      "Loss: tensor(0.1039, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4521\n",
      "Loss: tensor(0.1039, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4522\n",
      "Loss: tensor(0.1039, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4523\n",
      "Loss: tensor(0.1039, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4524\n",
      "Loss: tensor(0.1039, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4525\n",
      "Loss: tensor(0.1039, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4526\n",
      "Loss: tensor(0.1039, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4527\n",
      "Loss: tensor(0.1039, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4528\n",
      "Loss: tensor(0.1039, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4529\n",
      "Loss: tensor(0.1039, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4530\n",
      "Loss: tensor(0.1039, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4531\n",
      "Loss: tensor(0.1039, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4532\n",
      "Loss: tensor(0.1039, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4533\n",
      "Loss: tensor(0.1039, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4534\n",
      "Loss: tensor(0.1039, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4535\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor(0.1039, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4536\n",
      "Loss: tensor(0.1039, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4537\n",
      "Loss: tensor(0.1039, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4538\n",
      "Loss: tensor(0.1039, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4539\n",
      "Loss: tensor(0.1039, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4540\n",
      "Loss: tensor(0.1039, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4541\n",
      "Loss: tensor(0.1039, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4542\n",
      "Loss: tensor(0.1039, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4543\n",
      "Loss: tensor(0.1039, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4544\n",
      "Loss: tensor(0.1039, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4545\n",
      "Loss: tensor(0.1039, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4546\n",
      "Loss: tensor(0.1039, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4547\n",
      "Loss: tensor(0.1039, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4548\n",
      "Loss: tensor(0.1039, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4549\n",
      "Loss: tensor(0.1039, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4550\n",
      "Loss: tensor(0.1039, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4551\n",
      "Loss: tensor(0.1039, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4552\n",
      "Loss: tensor(0.1038, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4553\n",
      "Loss: tensor(0.1038, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4554\n",
      "Loss: tensor(0.1038, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4555\n",
      "Loss: tensor(0.1038, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4556\n",
      "Loss: tensor(0.1038, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4557\n",
      "Loss: tensor(0.1038, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4558\n",
      "Loss: tensor(0.1038, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4559\n",
      "Loss: tensor(0.1038, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4560\n",
      "Loss: tensor(0.1038, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4561\n",
      "Loss: tensor(0.1038, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4562\n",
      "Loss: tensor(0.1038, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4563\n",
      "Loss: tensor(0.1038, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4564\n",
      "Loss: tensor(0.1038, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4565\n",
      "Loss: tensor(0.1038, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4566\n",
      "Loss: tensor(0.1038, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4567\n",
      "Loss: tensor(0.1038, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4568\n",
      "Loss: tensor(0.1038, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4569\n",
      "Loss: tensor(0.1038, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4570\n",
      "Loss: tensor(0.1038, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4571\n",
      "Loss: tensor(0.1038, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4572\n",
      "Loss: tensor(0.1038, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4573\n",
      "Loss: tensor(0.1038, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4574\n",
      "Loss: tensor(0.1038, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4575\n",
      "Loss: tensor(0.1038, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4576\n",
      "Loss: tensor(0.1038, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4577\n",
      "Loss: tensor(0.1038, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4578\n",
      "Loss: tensor(0.1038, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4579\n",
      "Loss: tensor(0.1038, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4580\n",
      "Loss: tensor(0.1038, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4581\n",
      "Loss: tensor(0.1038, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4582\n",
      "Loss: tensor(0.1038, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4583\n",
      "Loss: tensor(0.1038, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4584\n",
      "Loss: tensor(0.1038, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4585\n",
      "Loss: tensor(0.1038, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4586\n",
      "Loss: tensor(0.1038, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4587\n",
      "Loss: tensor(0.1038, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4588\n",
      "Loss: tensor(0.1038, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4589\n",
      "Loss: tensor(0.1038, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4590\n",
      "Loss: tensor(0.1037, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4591\n",
      "Loss: tensor(0.1037, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4592\n",
      "Loss: tensor(0.1037, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4593\n",
      "Loss: tensor(0.1037, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4594\n",
      "Loss: tensor(0.1037, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4595\n",
      "Loss: tensor(0.1037, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4596\n",
      "Loss: tensor(0.1037, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4597\n",
      "Loss: tensor(0.1037, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4598\n",
      "Loss: tensor(0.1037, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4599\n",
      "Loss: tensor(0.1037, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4600\n",
      "Loss: tensor(0.1037, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4601\n",
      "Loss: tensor(0.1037, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4602\n",
      "Loss: tensor(0.1037, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4603\n",
      "Loss: tensor(0.1037, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4604\n",
      "Loss: tensor(0.1037, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4605\n",
      "Loss: tensor(0.1037, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4606\n",
      "Loss: tensor(0.1037, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4607\n",
      "Loss: tensor(0.1037, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4608\n",
      "Loss: tensor(0.1037, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4609\n",
      "Loss: tensor(0.1037, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4610\n",
      "Loss: tensor(0.1037, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4611\n",
      "Loss: tensor(0.1037, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4612\n",
      "Loss: tensor(0.1037, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4613\n",
      "Loss: tensor(0.1037, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4614\n",
      "Loss: tensor(0.1037, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4615\n",
      "Loss: tensor(0.1037, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4616\n",
      "Loss: tensor(0.1037, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4617\n",
      "Loss: tensor(0.1037, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4618\n",
      "Loss: tensor(0.1037, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4619\n",
      "Loss: tensor(0.1037, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4620\n",
      "Loss: tensor(0.1037, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4621\n",
      "Loss: tensor(0.1037, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4622\n",
      "Loss: tensor(0.1037, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4623\n",
      "Loss: tensor(0.1036, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4624\n",
      "Loss: tensor(0.1036, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4625\n",
      "Loss: tensor(0.1036, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4626\n",
      "Loss: tensor(0.1036, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4627\n",
      "Loss: tensor(0.1036, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4628\n",
      "Loss: tensor(0.1036, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4629\n",
      "Loss: tensor(0.1036, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4630\n",
      "Loss: tensor(0.1036, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4631\n",
      "Loss: tensor(0.1036, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4632\n",
      "Loss: tensor(0.1036, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4633\n",
      "Loss: tensor(0.1036, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4634\n",
      "Loss: tensor(0.1036, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4635\n",
      "Loss: tensor(0.1036, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4636\n",
      "Loss: tensor(0.1036, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4637\n",
      "Loss: tensor(0.1036, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4638\n",
      "Loss: tensor(0.1036, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4639\n",
      "Loss: tensor(0.1036, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4640\n",
      "Loss: tensor(0.1036, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4641\n",
      "Loss: tensor(0.1036, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4642\n",
      "Loss: tensor(0.1036, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4643\n",
      "Loss: tensor(0.1036, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4644\n",
      "Loss: tensor(0.1036, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4645\n",
      "Loss: tensor(0.1036, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4646\n",
      "Loss: tensor(0.1036, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4647\n",
      "Loss: tensor(0.1036, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4648\n",
      "Loss: tensor(0.1036, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4649\n",
      "Loss: tensor(0.1036, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4650\n",
      "Loss: tensor(0.1036, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4651\n",
      "Loss: tensor(0.1036, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4652\n",
      "Loss: tensor(0.1036, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4653\n",
      "Loss: tensor(0.1036, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4654\n",
      "Loss: tensor(0.1036, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4655\n",
      "Loss: tensor(0.1036, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4656\n",
      "Loss: tensor(0.1036, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4657\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor(0.1036, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4658\n",
      "Loss: tensor(0.1036, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4659\n",
      "Loss: tensor(0.1036, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4660\n",
      "Loss: tensor(0.1035, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4661\n",
      "Loss: tensor(0.1035, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4662\n",
      "Loss: tensor(0.1035, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4663\n",
      "Loss: tensor(0.1035, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4664\n",
      "Loss: tensor(0.1035, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4665\n",
      "Loss: tensor(0.1035, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4666\n",
      "Loss: tensor(0.1035, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4667\n",
      "Loss: tensor(0.1035, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4668\n",
      "Loss: tensor(0.1035, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4669\n",
      "Loss: tensor(0.1035, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4670\n",
      "Loss: tensor(0.1035, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4671\n",
      "Loss: tensor(0.1035, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4672\n",
      "Loss: tensor(0.1035, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4673\n",
      "Loss: tensor(0.1035, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4674\n",
      "Loss: tensor(0.1035, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4675\n",
      "Loss: tensor(0.1035, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4676\n",
      "Loss: tensor(0.1035, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4677\n",
      "Loss: tensor(0.1035, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4678\n",
      "Loss: tensor(0.1035, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4679\n",
      "Loss: tensor(0.1035, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4680\n",
      "Loss: tensor(0.1035, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4681\n",
      "Loss: tensor(0.1035, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4682\n",
      "Loss: tensor(0.1035, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4683\n",
      "Loss: tensor(0.1035, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4684\n",
      "Loss: tensor(0.1035, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4685\n",
      "Loss: tensor(0.1035, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4686\n",
      "Loss: tensor(0.1035, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4687\n",
      "Loss: tensor(0.1035, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4688\n",
      "Loss: tensor(0.1035, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4689\n",
      "Loss: tensor(0.1035, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4690\n",
      "Loss: tensor(0.1035, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4691\n",
      "Loss: tensor(0.1035, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4692\n",
      "Loss: tensor(0.1035, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4693\n",
      "Loss: tensor(0.1035, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4694\n",
      "Loss: tensor(0.1035, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4695\n",
      "Loss: tensor(0.1035, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4696\n",
      "Loss: tensor(0.1035, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4697\n",
      "Loss: tensor(0.1035, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4698\n",
      "Loss: tensor(0.1035, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4699\n",
      "Loss: tensor(0.1035, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4700\n",
      "Loss: tensor(0.1035, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4701\n",
      "Loss: tensor(0.1034, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4702\n",
      "Loss: tensor(0.1034, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4703\n",
      "Loss: tensor(0.1034, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4704\n",
      "Loss: tensor(0.1034, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4705\n",
      "Loss: tensor(0.1034, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4706\n",
      "Loss: tensor(0.1034, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4707\n",
      "Loss: tensor(0.1034, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4708\n",
      "Loss: tensor(0.1034, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4709\n",
      "Loss: tensor(0.1034, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4710\n",
      "Loss: tensor(0.1034, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4711\n",
      "Loss: tensor(0.1034, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4712\n",
      "Loss: tensor(0.1034, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4713\n",
      "Loss: tensor(0.1034, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4714\n",
      "Loss: tensor(0.1034, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4715\n",
      "Loss: tensor(0.1034, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4716\n",
      "Loss: tensor(0.1034, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4717\n",
      "Loss: tensor(0.1034, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4718\n",
      "Loss: tensor(0.1034, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4719\n",
      "Loss: tensor(0.1034, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4720\n",
      "Loss: tensor(0.1034, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4721\n",
      "Loss: tensor(0.1034, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4722\n",
      "Loss: tensor(0.1034, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4723\n",
      "Loss: tensor(0.1034, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4724\n",
      "Loss: tensor(0.1034, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4725\n",
      "Loss: tensor(0.1034, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4726\n",
      "Loss: tensor(0.1034, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4727\n",
      "Loss: tensor(0.1034, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4728\n",
      "Loss: tensor(0.1034, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4729\n",
      "Loss: tensor(0.1034, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4730\n",
      "Loss: tensor(0.1034, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4731\n",
      "Loss: tensor(0.1034, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4732\n",
      "Loss: tensor(0.1034, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4733\n",
      "Loss: tensor(0.1034, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4734\n",
      "Loss: tensor(0.1034, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4735\n",
      "Loss: tensor(0.1034, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4736\n",
      "Loss: tensor(0.1034, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4737\n",
      "Loss: tensor(0.1034, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4738\n",
      "Loss: tensor(0.1033, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4739\n",
      "Loss: tensor(0.1033, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4740\n",
      "Loss: tensor(0.1033, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4741\n",
      "Loss: tensor(0.1033, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4742\n",
      "Loss: tensor(0.1033, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4743\n",
      "Loss: tensor(0.1033, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4744\n",
      "Loss: tensor(0.1033, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4745\n",
      "Loss: tensor(0.1033, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4746\n",
      "Loss: tensor(0.1033, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4747\n",
      "Loss: tensor(0.1033, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4748\n",
      "Loss: tensor(0.1033, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4749\n",
      "Loss: tensor(0.1033, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4750\n",
      "Loss: tensor(0.1033, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4751\n",
      "Loss: tensor(0.1033, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4752\n",
      "Loss: tensor(0.1033, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4753\n",
      "Loss: tensor(0.1033, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4754\n",
      "Loss: tensor(0.1033, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4755\n",
      "Loss: tensor(0.1033, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4756\n",
      "Loss: tensor(0.1033, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4757\n",
      "Loss: tensor(0.1033, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4758\n",
      "Loss: tensor(0.1033, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4759\n",
      "Loss: tensor(0.1033, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4760\n",
      "Loss: tensor(0.1033, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4761\n",
      "Loss: tensor(0.1033, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4762\n",
      "Loss: tensor(0.1033, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4763\n",
      "Loss: tensor(0.1033, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4764\n",
      "Loss: tensor(0.1033, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4765\n",
      "Loss: tensor(0.1033, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4766\n",
      "Loss: tensor(0.1033, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4767\n",
      "Loss: tensor(0.1033, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4768\n",
      "Loss: tensor(0.1033, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4769\n",
      "Loss: tensor(0.1033, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4770\n",
      "Loss: tensor(0.1033, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4771\n",
      "Loss: tensor(0.1033, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4772\n",
      "Loss: tensor(0.1033, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4773\n",
      "Loss: tensor(0.1033, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4774\n",
      "Loss: tensor(0.1033, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4775\n",
      "Loss: tensor(0.1033, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4776\n",
      "Loss: tensor(0.1033, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4777\n",
      "Loss: tensor(0.1033, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4778\n",
      "Loss: tensor(0.1033, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4779\n",
      "Loss: tensor(0.1033, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4780\n",
      "Loss: tensor(0.1033, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4781\n",
      "Loss: tensor(0.1033, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4782\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor(0.1033, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4783\n",
      "Loss: tensor(0.1033, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4784\n",
      "Loss: tensor(0.1033, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4785\n",
      "Loss: tensor(0.1033, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4786\n",
      "Loss: tensor(0.1033, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4787\n",
      "Loss: tensor(0.1033, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4788\n",
      "Loss: tensor(0.1032, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4789\n",
      "Loss: tensor(0.1032, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4790\n",
      "Loss: tensor(0.1032, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4791\n",
      "Loss: tensor(0.1032, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4792\n",
      "Loss: tensor(0.1032, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4793\n",
      "Loss: tensor(0.1032, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4794\n",
      "Loss: tensor(0.1032, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4795\n",
      "Loss: tensor(0.1032, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4796\n",
      "Loss: tensor(0.1032, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4797\n",
      "Loss: tensor(0.1032, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4798\n",
      "Loss: tensor(0.1032, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4799\n",
      "Loss: tensor(0.1032, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4800\n",
      "Loss: tensor(0.1032, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4801\n",
      "Loss: tensor(0.1032, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4802\n",
      "Loss: tensor(0.1032, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4803\n",
      "Loss: tensor(0.1032, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4804\n",
      "Loss: tensor(0.1032, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4805\n",
      "Loss: tensor(0.1032, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4806\n",
      "Loss: tensor(0.1032, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4807\n",
      "Loss: tensor(0.1032, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4808\n",
      "Loss: tensor(0.1032, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4809\n",
      "Loss: tensor(0.1032, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4810\n",
      "Loss: tensor(0.1032, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4811\n",
      "Loss: tensor(0.1032, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4812\n",
      "Loss: tensor(0.1032, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4813\n",
      "Loss: tensor(0.1032, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4814\n",
      "Loss: tensor(0.1032, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4815\n",
      "Loss: tensor(0.1032, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4816\n",
      "Loss: tensor(0.1032, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4817\n",
      "Loss: tensor(0.1032, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4818\n",
      "Loss: tensor(0.1032, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4819\n",
      "Loss: tensor(0.1032, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4820\n",
      "Loss: tensor(0.1032, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4821\n",
      "Loss: tensor(0.1032, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4822\n",
      "Loss: tensor(0.1031, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4823\n",
      "Loss: tensor(0.1031, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4824\n",
      "Loss: tensor(0.1031, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4825\n",
      "Loss: tensor(0.1031, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4826\n",
      "Loss: tensor(0.1031, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4827\n",
      "Loss: tensor(0.1031, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4828\n",
      "Loss: tensor(0.1031, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4829\n",
      "Loss: tensor(0.1031, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4830\n",
      "Loss: tensor(0.1031, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4831\n",
      "Loss: tensor(0.1031, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4832\n",
      "Loss: tensor(0.1031, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4833\n",
      "Loss: tensor(0.1031, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4834\n",
      "Loss: tensor(0.1031, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4835\n",
      "Loss: tensor(0.1031, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4836\n",
      "Loss: tensor(0.1031, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4837\n",
      "Loss: tensor(0.1031, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4838\n",
      "Loss: tensor(0.1031, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4839\n",
      "Loss: tensor(0.1031, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4840\n",
      "Loss: tensor(0.1031, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4841\n",
      "Loss: tensor(0.1031, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4842\n",
      "Loss: tensor(0.1031, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4843\n",
      "Loss: tensor(0.1031, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4844\n",
      "Loss: tensor(0.1031, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4845\n",
      "Loss: tensor(0.1031, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4846\n",
      "Loss: tensor(0.1031, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4847\n",
      "Loss: tensor(0.1031, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4848\n",
      "Loss: tensor(0.1031, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4849\n",
      "Loss: tensor(0.1031, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4850\n",
      "Loss: tensor(0.1031, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4851\n",
      "Loss: tensor(0.1031, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4852\n",
      "Loss: tensor(0.1031, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4853\n",
      "Loss: tensor(0.1031, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4854\n",
      "Loss: tensor(0.1031, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4855\n",
      "Loss: tensor(0.1031, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4856\n",
      "Loss: tensor(0.1031, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4857\n",
      "Loss: tensor(0.1031, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4858\n",
      "Loss: tensor(0.1031, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4859\n",
      "Loss: tensor(0.1031, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4860\n",
      "Loss: tensor(0.1031, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4861\n",
      "Loss: tensor(0.1031, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4862\n",
      "Loss: tensor(0.1031, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4863\n",
      "Loss: tensor(0.1031, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4864\n",
      "Loss: tensor(0.1031, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4865\n",
      "Loss: tensor(0.1031, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4866\n",
      "Loss: tensor(0.1031, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4867\n",
      "Loss: tensor(0.1030, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4868\n",
      "Loss: tensor(0.1030, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4869\n",
      "Loss: tensor(0.1030, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4870\n",
      "Loss: tensor(0.1030, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4871\n",
      "Loss: tensor(0.1030, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4872\n",
      "Loss: tensor(0.1030, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4873\n",
      "Loss: tensor(0.1030, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4874\n",
      "Loss: tensor(0.1030, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4875\n",
      "Loss: tensor(0.1030, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4876\n",
      "Loss: tensor(0.1030, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4877\n",
      "Loss: tensor(0.1030, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4878\n",
      "Loss: tensor(0.1030, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4879\n",
      "Loss: tensor(0.1030, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4880\n",
      "Loss: tensor(0.1030, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4881\n",
      "Loss: tensor(0.1030, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4882\n",
      "Loss: tensor(0.1030, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4883\n",
      "Loss: tensor(0.1030, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4884\n",
      "Loss: tensor(0.1030, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4885\n",
      "Loss: tensor(0.1030, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4886\n",
      "Loss: tensor(0.1030, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4887\n",
      "Loss: tensor(0.1030, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4888\n",
      "Loss: tensor(0.1030, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4889\n",
      "Loss: tensor(0.1030, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4890\n",
      "Loss: tensor(0.1030, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4891\n",
      "Loss: tensor(0.1030, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4892\n",
      "Loss: tensor(0.1030, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4893\n",
      "Loss: tensor(0.1030, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4894\n",
      "Loss: tensor(0.1030, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4895\n",
      "Loss: tensor(0.1030, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4896\n",
      "Loss: tensor(0.1030, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4897\n",
      "Loss: tensor(0.1030, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4898\n",
      "Loss: tensor(0.1030, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4899\n",
      "Loss: tensor(0.1030, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4900\n",
      "Loss: tensor(0.1030, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4901\n",
      "Loss: tensor(0.1030, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4902\n",
      "Loss: tensor(0.1030, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4903\n",
      "Loss: tensor(0.1030, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4904\n",
      "Loss: tensor(0.1030, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4905\n",
      "Loss: tensor(0.1030, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4906\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor(0.1030, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4907\n",
      "Loss: tensor(0.1030, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4908\n",
      "Loss: tensor(0.1030, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4909\n",
      "Loss: tensor(0.1030, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4910\n",
      "Loss: tensor(0.1030, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4911\n",
      "Loss: tensor(0.1030, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4912\n",
      "Loss: tensor(0.1029, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4913\n",
      "Loss: tensor(0.1029, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4914\n",
      "Loss: tensor(0.1029, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4915\n",
      "Loss: tensor(0.1029, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4916\n",
      "Loss: tensor(0.1029, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4917\n",
      "Loss: tensor(0.1029, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4918\n",
      "Loss: tensor(0.1029, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4919\n",
      "Loss: tensor(0.1029, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4920\n",
      "Loss: tensor(0.1029, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4921\n",
      "Loss: tensor(0.1029, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4922\n",
      "Loss: tensor(0.1029, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4923\n",
      "Loss: tensor(0.1029, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4924\n",
      "Loss: tensor(0.1029, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4925\n",
      "Loss: tensor(0.1029, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4926\n",
      "Loss: tensor(0.1029, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4927\n",
      "Loss: tensor(0.1029, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4928\n",
      "Loss: tensor(0.1029, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4929\n",
      "Loss: tensor(0.1029, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4930\n",
      "Loss: tensor(0.1029, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4931\n",
      "Loss: tensor(0.1029, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4932\n",
      "Loss: tensor(0.1029, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4933\n",
      "Loss: tensor(0.1029, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4934\n",
      "Loss: tensor(0.1029, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4935\n",
      "Loss: tensor(0.1029, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4936\n",
      "Loss: tensor(0.1029, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4937\n",
      "Loss: tensor(0.1029, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4938\n",
      "Loss: tensor(0.1029, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4939\n",
      "Loss: tensor(0.1029, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4940\n",
      "Loss: tensor(0.1029, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4941\n",
      "Loss: tensor(0.1029, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4942\n",
      "Loss: tensor(0.1029, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4943\n",
      "Loss: tensor(0.1029, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4944\n",
      "Loss: tensor(0.1029, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4945\n",
      "Loss: tensor(0.1029, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4946\n",
      "Loss: tensor(0.1029, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4947\n",
      "Loss: tensor(0.1029, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4948\n",
      "Loss: tensor(0.1029, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4949\n",
      "Loss: tensor(0.1029, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4950\n",
      "Loss: tensor(0.1029, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4951\n",
      "Loss: tensor(0.1029, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4952\n",
      "Loss: tensor(0.1029, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4953\n",
      "Loss: tensor(0.1029, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4954\n",
      "Loss: tensor(0.1029, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4955\n",
      "Loss: tensor(0.1029, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4956\n",
      "Loss: tensor(0.1029, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4957\n",
      "Loss: tensor(0.1029, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4958\n",
      "Loss: tensor(0.1029, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4959\n",
      "Loss: tensor(0.1029, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4960\n",
      "Loss: tensor(0.1028, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4961\n",
      "Loss: tensor(0.1028, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4962\n",
      "Loss: tensor(0.1028, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4963\n",
      "Loss: tensor(0.1028, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4964\n",
      "Loss: tensor(0.1028, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4965\n",
      "Loss: tensor(0.1028, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4966\n",
      "Loss: tensor(0.1028, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4967\n",
      "Loss: tensor(0.1028, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4968\n",
      "Loss: tensor(0.1028, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4969\n",
      "Loss: tensor(0.1028, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4970\n",
      "Loss: tensor(0.1028, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4971\n",
      "Loss: tensor(0.1028, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4972\n",
      "Loss: tensor(0.1028, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4973\n",
      "Loss: tensor(0.1028, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4974\n",
      "Loss: tensor(0.1028, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4975\n",
      "Loss: tensor(0.1028, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4976\n",
      "Loss: tensor(0.1028, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4977\n",
      "Loss: tensor(0.1028, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4978\n",
      "Loss: tensor(0.1028, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4979\n",
      "Loss: tensor(0.1028, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4980\n",
      "Loss: tensor(0.1028, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4981\n",
      "Loss: tensor(0.1028, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4982\n",
      "Loss: tensor(0.1028, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4983\n",
      "Loss: tensor(0.1028, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4984\n",
      "Loss: tensor(0.1028, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4985\n",
      "Loss: tensor(0.1028, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4986\n",
      "Loss: tensor(0.1028, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4987\n",
      "Loss: tensor(0.1028, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4988\n",
      "Loss: tensor(0.1028, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4989\n",
      "Loss: tensor(0.1028, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4990\n",
      "Loss: tensor(0.1028, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4991\n",
      "Loss: tensor(0.1028, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4992\n",
      "Loss: tensor(0.1028, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4993\n",
      "Loss: tensor(0.1028, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4994\n",
      "Loss: tensor(0.1028, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4995\n",
      "Loss: tensor(0.1028, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4996\n",
      "Loss: tensor(0.1028, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4997\n",
      "Loss: tensor(0.1028, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4998\n",
      "Loss: tensor(0.1028, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4999\n",
      "Loss: tensor(0.1028, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5000\n",
      "Loss: tensor(0.1028, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5001\n",
      "Loss: tensor(0.1028, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5002\n",
      "Loss: tensor(0.1028, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5003\n",
      "Loss: tensor(0.1028, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5004\n",
      "Loss: tensor(0.1028, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5005\n",
      "Loss: tensor(0.1028, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5006\n",
      "Loss: tensor(0.1028, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5007\n",
      "Loss: tensor(0.1028, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5008\n",
      "Loss: tensor(0.1028, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5009\n",
      "Loss: tensor(0.1028, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5010\n",
      "Loss: tensor(0.1027, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5011\n",
      "Loss: tensor(0.1027, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5012\n",
      "Loss: tensor(0.1027, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5013\n",
      "Loss: tensor(0.1027, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5014\n",
      "Loss: tensor(0.1027, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5015\n",
      "Loss: tensor(0.1027, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5016\n",
      "Loss: tensor(0.1027, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5017\n",
      "Loss: tensor(0.1027, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5018\n",
      "Loss: tensor(0.1027, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5019\n",
      "Loss: tensor(0.1027, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5020\n",
      "Loss: tensor(0.1027, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5021\n",
      "Loss: tensor(0.1027, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5022\n",
      "Loss: tensor(0.1027, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5023\n",
      "Loss: tensor(0.1027, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5024\n",
      "Loss: tensor(0.1027, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5025\n",
      "Loss: tensor(0.1027, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5026\n",
      "Loss: tensor(0.1027, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5027\n",
      "Loss: tensor(0.1027, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5028\n",
      "Loss: tensor(0.1027, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5029\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor(0.1027, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5030\n",
      "Loss: tensor(0.1027, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5031\n",
      "Loss: tensor(0.1027, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5032\n",
      "Loss: tensor(0.1027, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5033\n",
      "Loss: tensor(0.1027, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5034\n",
      "Loss: tensor(0.1027, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5035\n",
      "Loss: tensor(0.1027, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5036\n",
      "Loss: tensor(0.1027, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5037\n",
      "Loss: tensor(0.1027, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5038\n",
      "Loss: tensor(0.1027, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5039\n",
      "Loss: tensor(0.1027, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5040\n",
      "Loss: tensor(0.1027, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5041\n",
      "Loss: tensor(0.1027, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5042\n",
      "Loss: tensor(0.1027, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5043\n",
      "Loss: tensor(0.1027, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5044\n",
      "Loss: tensor(0.1027, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5045\n",
      "Loss: tensor(0.1027, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5046\n",
      "Loss: tensor(0.1027, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5047\n",
      "Loss: tensor(0.1027, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5048\n",
      "Loss: tensor(0.1027, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5049\n",
      "Loss: tensor(0.1027, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5050\n",
      "Loss: tensor(0.1027, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5051\n",
      "Loss: tensor(0.1027, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5052\n",
      "Loss: tensor(0.1027, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5053\n",
      "Loss: tensor(0.1027, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5054\n",
      "Loss: tensor(0.1027, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5055\n",
      "Loss: tensor(0.1027, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5056\n",
      "Loss: tensor(0.1027, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5057\n",
      "Loss: tensor(0.1027, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5058\n",
      "Loss: tensor(0.1027, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5059\n",
      "Loss: tensor(0.1027, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5060\n",
      "Loss: tensor(0.1027, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5061\n",
      "Loss: tensor(0.1027, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5062\n",
      "Loss: tensor(0.1027, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5063\n",
      "Loss: tensor(0.1026, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5064\n",
      "Loss: tensor(0.1026, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5065\n",
      "Loss: tensor(0.1026, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5066\n",
      "Loss: tensor(0.1026, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5067\n",
      "Loss: tensor(0.1026, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5068\n",
      "Loss: tensor(0.1026, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5069\n",
      "Loss: tensor(0.1026, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5070\n",
      "Loss: tensor(0.1026, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5071\n",
      "Loss: tensor(0.1026, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5072\n",
      "Loss: tensor(0.1026, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5073\n",
      "Loss: tensor(0.1026, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5074\n",
      "Loss: tensor(0.1026, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5075\n",
      "Loss: tensor(0.1026, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5076\n",
      "Loss: tensor(0.1026, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5077\n",
      "Loss: tensor(0.1026, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5078\n",
      "Loss: tensor(0.1026, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5079\n",
      "Loss: tensor(0.1026, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5080\n",
      "Loss: tensor(0.1026, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5081\n",
      "Loss: tensor(0.1026, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5082\n",
      "Loss: tensor(0.1026, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5083\n",
      "Loss: tensor(0.1026, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5084\n",
      "Loss: tensor(0.1026, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5085\n",
      "Loss: tensor(0.1026, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5086\n",
      "Loss: tensor(0.1026, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5087\n",
      "Loss: tensor(0.1026, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5088\n",
      "Loss: tensor(0.1026, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5089\n",
      "Loss: tensor(0.1026, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5090\n",
      "Loss: tensor(0.1026, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5091\n",
      "Loss: tensor(0.1026, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5092\n",
      "Loss: tensor(0.1026, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5093\n",
      "Loss: tensor(0.1026, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5094\n",
      "Loss: tensor(0.1026, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5095\n",
      "Loss: tensor(0.1026, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5096\n",
      "Loss: tensor(0.1026, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5097\n",
      "Loss: tensor(0.1026, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5098\n",
      "Loss: tensor(0.1026, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5099\n",
      "Loss: tensor(0.1026, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5100\n",
      "Loss: tensor(0.1026, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5101\n",
      "Loss: tensor(0.1026, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5102\n",
      "Loss: tensor(0.1026, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5103\n",
      "Loss: tensor(0.1026, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5104\n",
      "Loss: tensor(0.1026, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5105\n",
      "Loss: tensor(0.1026, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5106\n",
      "Loss: tensor(0.1026, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5107\n",
      "Loss: tensor(0.1026, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5108\n",
      "Loss: tensor(0.1026, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5109\n",
      "Loss: tensor(0.1026, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5110\n",
      "Loss: tensor(0.1026, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5111\n",
      "Loss: tensor(0.1026, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5112\n",
      "Loss: tensor(0.1026, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5113\n",
      "Loss: tensor(0.1026, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5114\n",
      "Loss: tensor(0.1026, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5115\n",
      "Loss: tensor(0.1026, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5116\n",
      "Loss: tensor(0.1026, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5117\n",
      "Loss: tensor(0.1025, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5118\n",
      "Loss: tensor(0.1025, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5119\n",
      "Loss: tensor(0.1025, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5120\n",
      "Loss: tensor(0.1025, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5121\n",
      "Loss: tensor(0.1025, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5122\n",
      "Loss: tensor(0.1025, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5123\n",
      "Loss: tensor(0.1025, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5124\n",
      "Loss: tensor(0.1025, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5125\n",
      "Loss: tensor(0.1025, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5126\n",
      "Loss: tensor(0.1025, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5127\n",
      "Loss: tensor(0.1025, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5128\n",
      "Loss: tensor(0.1025, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5129\n",
      "Loss: tensor(0.1025, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5130\n",
      "Loss: tensor(0.1025, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5131\n",
      "Loss: tensor(0.1025, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5132\n",
      "Loss: tensor(0.1025, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5133\n",
      "Loss: tensor(0.1025, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5134\n",
      "Loss: tensor(0.1025, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5135\n",
      "Loss: tensor(0.1025, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5136\n",
      "Loss: tensor(0.1025, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5137\n",
      "Loss: tensor(0.1025, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5138\n",
      "Loss: tensor(0.1025, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5139\n",
      "Loss: tensor(0.1025, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5140\n",
      "Loss: tensor(0.1025, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5141\n",
      "Loss: tensor(0.1025, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5142\n",
      "Loss: tensor(0.1025, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5143\n",
      "Loss: tensor(0.1025, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5144\n",
      "Loss: tensor(0.1025, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5145\n",
      "Loss: tensor(0.1025, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5146\n",
      "Loss: tensor(0.1025, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5147\n",
      "Loss: tensor(0.1025, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5148\n",
      "Loss: tensor(0.1025, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5149\n",
      "Loss: tensor(0.1025, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor(0.1025, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5151\n",
      "Loss: tensor(0.1025, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5152\n",
      "Loss: tensor(0.1025, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5153\n",
      "Loss: tensor(0.1025, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5154\n",
      "Loss: tensor(0.1025, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5155\n",
      "Loss: tensor(0.1025, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5156\n",
      "Loss: tensor(0.1025, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5157\n",
      "Loss: tensor(0.1025, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5158\n",
      "Loss: tensor(0.1025, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5159\n",
      "Loss: tensor(0.1025, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5160\n",
      "Loss: tensor(0.1025, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5161\n",
      "Loss: tensor(0.1025, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5162\n",
      "Loss: tensor(0.1025, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5163\n",
      "Loss: tensor(0.1025, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5164\n",
      "Loss: tensor(0.1025, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5165\n",
      "Loss: tensor(0.1025, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5166\n",
      "Loss: tensor(0.1025, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5167\n",
      "Loss: tensor(0.1025, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5168\n",
      "Loss: tensor(0.1025, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5169\n",
      "Loss: tensor(0.1025, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5170\n",
      "Loss: tensor(0.1025, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5171\n",
      "Loss: tensor(0.1025, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5172\n",
      "Loss: tensor(0.1024, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5173\n",
      "Loss: tensor(0.1024, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5174\n",
      "Loss: tensor(0.1024, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5175\n",
      "Loss: tensor(0.1024, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5176\n",
      "Loss: tensor(0.1024, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5177\n",
      "Loss: tensor(0.1024, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5178\n",
      "Loss: tensor(0.1024, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5179\n",
      "Loss: tensor(0.1024, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5180\n",
      "Loss: tensor(0.1024, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5181\n",
      "Loss: tensor(0.1024, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5182\n",
      "Loss: tensor(0.1024, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5183\n",
      "Loss: tensor(0.1024, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5184\n",
      "Loss: tensor(0.1024, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5185\n",
      "Loss: tensor(0.1024, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5186\n",
      "Loss: tensor(0.1024, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5187\n",
      "Loss: tensor(0.1024, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5188\n",
      "Loss: tensor(0.1024, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5189\n",
      "Loss: tensor(0.1024, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5190\n",
      "Loss: tensor(0.1024, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5191\n",
      "Loss: tensor(0.1024, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5192\n",
      "Loss: tensor(0.1024, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5193\n",
      "Loss: tensor(0.1024, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5194\n",
      "Loss: tensor(0.1024, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5195\n",
      "Loss: tensor(0.1024, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5196\n",
      "Loss: tensor(0.1024, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5197\n",
      "Loss: tensor(0.1024, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5198\n",
      "Loss: tensor(0.1024, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5199\n",
      "Loss: tensor(0.1024, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5200\n",
      "Loss: tensor(0.1024, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5201\n",
      "Loss: tensor(0.1024, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5202\n",
      "Loss: tensor(0.1024, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5203\n",
      "Loss: tensor(0.1024, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5204\n",
      "Loss: tensor(0.1024, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5205\n",
      "Loss: tensor(0.1024, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5206\n",
      "Loss: tensor(0.1024, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5207\n",
      "Loss: tensor(0.1024, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5208\n",
      "Loss: tensor(0.1024, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5209\n",
      "Loss: tensor(0.1024, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5210\n",
      "Loss: tensor(0.1024, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5211\n",
      "Loss: tensor(0.1024, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5212\n",
      "Loss: tensor(0.1024, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5213\n",
      "Loss: tensor(0.1024, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5214\n",
      "Loss: tensor(0.1024, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5215\n",
      "Loss: tensor(0.1024, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5216\n",
      "Loss: tensor(0.1024, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5217\n",
      "Loss: tensor(0.1024, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5218\n",
      "Loss: tensor(0.1024, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5219\n",
      "Loss: tensor(0.1024, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5220\n",
      "Loss: tensor(0.1024, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5221\n",
      "Loss: tensor(0.1024, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5222\n",
      "Loss: tensor(0.1024, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5223\n",
      "Loss: tensor(0.1024, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5224\n",
      "Loss: tensor(0.1024, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5225\n",
      "Loss: tensor(0.1024, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5226\n",
      "Loss: tensor(0.1024, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5227\n",
      "Loss: tensor(0.1024, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5228\n",
      "Loss: tensor(0.1024, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5229\n",
      "Loss: tensor(0.1024, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5230\n",
      "Loss: tensor(0.1024, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5231\n",
      "Loss: tensor(0.1023, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5232\n",
      "Loss: tensor(0.1023, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5233\n",
      "Loss: tensor(0.1023, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5234\n",
      "Loss: tensor(0.1023, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5235\n",
      "Loss: tensor(0.1023, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5236\n",
      "Loss: tensor(0.1023, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5237\n",
      "Loss: tensor(0.1023, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5238\n",
      "Loss: tensor(0.1023, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5239\n",
      "Loss: tensor(0.1023, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5240\n",
      "Loss: tensor(0.1023, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5241\n",
      "Loss: tensor(0.1023, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5242\n",
      "Loss: tensor(0.1023, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5243\n",
      "Loss: tensor(0.1023, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5244\n",
      "Loss: tensor(0.1023, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5245\n",
      "Loss: tensor(0.1023, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5246\n",
      "Loss: tensor(0.1023, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5247\n",
      "Loss: tensor(0.1023, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5248\n",
      "Loss: tensor(0.1023, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5249\n",
      "Loss: tensor(0.1023, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5250\n",
      "Loss: tensor(0.1023, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5251\n",
      "Loss: tensor(0.1023, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5252\n",
      "Loss: tensor(0.1023, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5253\n",
      "Loss: tensor(0.1023, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5254\n",
      "Loss: tensor(0.1023, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5255\n",
      "Loss: tensor(0.1023, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5256\n",
      "Loss: tensor(0.1023, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5257\n",
      "Loss: tensor(0.1023, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5258\n",
      "Loss: tensor(0.1023, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5259\n",
      "Loss: tensor(0.1023, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5260\n",
      "Loss: tensor(0.1023, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5261\n",
      "Loss: tensor(0.1023, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5262\n",
      "Loss: tensor(0.1023, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5263\n",
      "Loss: tensor(0.1023, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5264\n",
      "Loss: tensor(0.1023, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5265\n",
      "Loss: tensor(0.1023, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5266\n",
      "Loss: tensor(0.1023, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5267\n",
      "Loss: tensor(0.1023, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5268\n",
      "Loss: tensor(0.1023, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5269\n",
      "Loss: tensor(0.1023, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5270\n",
      "Loss: tensor(0.1023, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5271\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor(0.1023, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5272\n",
      "Loss: tensor(0.1023, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5273\n",
      "Loss: tensor(0.1023, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5274\n",
      "Loss: tensor(0.1023, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5275\n",
      "Loss: tensor(0.1023, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5276\n",
      "Loss: tensor(0.1023, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5277\n",
      "Loss: tensor(0.1023, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5278\n",
      "Loss: tensor(0.1023, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5279\n",
      "Loss: tensor(0.1023, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5280\n",
      "Loss: tensor(0.1023, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5281\n",
      "Loss: tensor(0.1023, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5282\n",
      "Loss: tensor(0.1023, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5283\n",
      "Loss: tensor(0.1023, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5284\n",
      "Loss: tensor(0.1023, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5285\n",
      "Loss: tensor(0.1023, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5286\n",
      "Loss: tensor(0.1023, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5287\n",
      "Loss: tensor(0.1023, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5288\n",
      "Loss: tensor(0.1023, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5289\n",
      "Loss: tensor(0.1023, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5290\n",
      "Loss: tensor(0.1023, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5291\n",
      "Loss: tensor(0.1023, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5292\n",
      "Loss: tensor(0.1023, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5293\n",
      "Loss: tensor(0.1023, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5294\n",
      "Loss: tensor(0.1023, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5295\n",
      "Loss: tensor(0.1023, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5296\n",
      "Loss: tensor(0.1023, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5297\n",
      "Loss: tensor(0.1022, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5298\n",
      "Loss: tensor(0.1022, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5299\n",
      "Loss: tensor(0.1022, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5300\n",
      "Loss: tensor(0.1022, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5301\n",
      "Loss: tensor(0.1022, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5302\n",
      "Loss: tensor(0.1022, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5303\n",
      "Loss: tensor(0.1022, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5304\n",
      "Loss: tensor(0.1022, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5305\n",
      "Loss: tensor(0.1022, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5306\n",
      "Loss: tensor(0.1022, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5307\n",
      "Loss: tensor(0.1022, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5308\n",
      "Loss: tensor(0.1022, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5309\n",
      "Loss: tensor(0.1022, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5310\n",
      "Loss: tensor(0.1022, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5311\n",
      "Loss: tensor(0.1022, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5312\n",
      "Loss: tensor(0.1022, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5313\n",
      "Loss: tensor(0.1022, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5314\n",
      "Loss: tensor(0.1022, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5315\n",
      "Loss: tensor(0.1022, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5316\n",
      "Loss: tensor(0.1022, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5317\n",
      "Loss: tensor(0.1022, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5318\n",
      "Loss: tensor(0.1022, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5319\n",
      "Loss: tensor(0.1022, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5320\n",
      "Loss: tensor(0.1022, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5321\n",
      "Loss: tensor(0.1022, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5322\n",
      "Loss: tensor(0.1022, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5323\n",
      "Loss: tensor(0.1022, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5324\n",
      "Loss: tensor(0.1022, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5325\n",
      "Loss: tensor(0.1022, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5326\n",
      "Loss: tensor(0.1022, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5327\n",
      "Loss: tensor(0.1022, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5328\n",
      "Loss: tensor(0.1022, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5329\n",
      "Loss: tensor(0.1022, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5330\n",
      "Loss: tensor(0.1022, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5331\n",
      "Loss: tensor(0.1022, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5332\n",
      "Loss: tensor(0.1022, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5333\n",
      "Loss: tensor(0.1022, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5334\n",
      "Loss: tensor(0.1022, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5335\n",
      "Loss: tensor(0.1022, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5336\n",
      "Loss: tensor(0.1022, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5337\n",
      "Loss: tensor(0.1022, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5338\n",
      "Loss: tensor(0.1022, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5339\n",
      "Loss: tensor(0.1022, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5340\n",
      "Loss: tensor(0.1022, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5341\n",
      "Loss: tensor(0.1022, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5342\n",
      "Loss: tensor(0.1022, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5343\n",
      "Loss: tensor(0.1022, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5344\n",
      "Loss: tensor(0.1022, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5345\n",
      "Loss: tensor(0.1022, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5346\n",
      "Loss: tensor(0.1022, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5347\n",
      "Loss: tensor(0.1022, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5348\n",
      "Loss: tensor(0.1022, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5349\n",
      "Loss: tensor(0.1022, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5350\n",
      "Loss: tensor(0.1022, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5351\n",
      "Loss: tensor(0.1022, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5352\n",
      "Loss: tensor(0.1022, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5353\n",
      "Loss: tensor(0.1022, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5354\n",
      "Loss: tensor(0.1022, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5355\n",
      "Loss: tensor(0.1022, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5356\n",
      "Loss: tensor(0.1021, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5357\n",
      "Loss: tensor(0.1021, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5358\n",
      "Loss: tensor(0.1021, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5359\n",
      "Loss: tensor(0.1021, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5360\n",
      "Loss: tensor(0.1021, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5361\n",
      "Loss: tensor(0.1021, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5362\n",
      "Loss: tensor(0.1021, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5363\n",
      "Loss: tensor(0.1021, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5364\n",
      "Loss: tensor(0.1021, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5365\n",
      "Loss: tensor(0.1021, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5366\n",
      "Loss: tensor(0.1021, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5367\n",
      "Loss: tensor(0.1021, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5368\n",
      "Loss: tensor(0.1021, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5369\n",
      "Loss: tensor(0.1021, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5370\n",
      "Loss: tensor(0.1021, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5371\n",
      "Loss: tensor(0.1021, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5372\n",
      "Loss: tensor(0.1021, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5373\n",
      "Loss: tensor(0.1021, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5374\n",
      "Loss: tensor(0.1021, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5375\n",
      "Loss: tensor(0.1021, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5376\n",
      "Loss: tensor(0.1021, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5377\n",
      "Loss: tensor(0.1021, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5378\n",
      "Loss: tensor(0.1021, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5379\n",
      "Loss: tensor(0.1021, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5380\n",
      "Loss: tensor(0.1021, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5381\n",
      "Loss: tensor(0.1021, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5382\n",
      "Loss: tensor(0.1021, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5383\n",
      "Loss: tensor(0.1021, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5384\n",
      "Loss: tensor(0.1021, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5385\n",
      "Loss: tensor(0.1021, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5386\n",
      "Loss: tensor(0.1021, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5387\n",
      "Loss: tensor(0.1021, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5388\n",
      "Loss: tensor(0.1021, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5389\n",
      "Loss: tensor(0.1021, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5390\n",
      "Loss: tensor(0.1021, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5391\n",
      "Loss: tensor(0.1021, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5392\n",
      "Loss: tensor(0.1021, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5393\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor(0.1021, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5394\n",
      "Loss: tensor(0.1021, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5395\n",
      "Loss: tensor(0.1021, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5396\n",
      "Loss: tensor(0.1021, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5397\n",
      "Loss: tensor(0.1021, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5398\n",
      "Loss: tensor(0.1021, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5399\n",
      "Loss: tensor(0.1021, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5400\n",
      "Loss: tensor(0.1021, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5401\n",
      "Loss: tensor(0.1021, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5402\n",
      "Loss: tensor(0.1021, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5403\n",
      "Loss: tensor(0.1021, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5404\n",
      "Loss: tensor(0.1021, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5405\n",
      "Loss: tensor(0.1021, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5406\n",
      "Loss: tensor(0.1021, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5407\n",
      "Loss: tensor(0.1021, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5408\n",
      "Loss: tensor(0.1021, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5409\n",
      "Loss: tensor(0.1021, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5410\n",
      "Loss: tensor(0.1021, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5411\n",
      "Loss: tensor(0.1021, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5412\n",
      "Loss: tensor(0.1021, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5413\n",
      "Loss: tensor(0.1021, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5414\n",
      "Loss: tensor(0.1021, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5415\n",
      "Loss: tensor(0.1021, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5416\n",
      "Loss: tensor(0.1021, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5417\n",
      "Loss: tensor(0.1021, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5418\n",
      "Loss: tensor(0.1021, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5419\n",
      "Loss: tensor(0.1021, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5420\n",
      "Loss: tensor(0.1021, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5421\n",
      "Loss: tensor(0.1021, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5422\n",
      "Loss: tensor(0.1021, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5423\n",
      "Loss: tensor(0.1020, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5424\n",
      "Loss: tensor(0.1020, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5425\n",
      "Loss: tensor(0.1020, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5426\n",
      "Loss: tensor(0.1020, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5427\n",
      "Loss: tensor(0.1020, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5428\n",
      "Loss: tensor(0.1020, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5429\n",
      "Loss: tensor(0.1020, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5430\n",
      "Loss: tensor(0.1020, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5431\n",
      "Loss: tensor(0.1020, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5432\n",
      "Loss: tensor(0.1020, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5433\n",
      "Loss: tensor(0.1020, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5434\n",
      "Loss: tensor(0.1020, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5435\n",
      "Loss: tensor(0.1020, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5436\n",
      "Loss: tensor(0.1020, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5437\n",
      "Loss: tensor(0.1020, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5438\n",
      "Loss: tensor(0.1020, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5439\n",
      "Loss: tensor(0.1020, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5440\n",
      "Loss: tensor(0.1020, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5441\n",
      "Loss: tensor(0.1020, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5442\n",
      "Loss: tensor(0.1020, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5443\n",
      "Loss: tensor(0.1020, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5444\n",
      "Loss: tensor(0.1020, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5445\n",
      "Loss: tensor(0.1020, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5446\n",
      "Loss: tensor(0.1020, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5447\n",
      "Loss: tensor(0.1020, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5448\n",
      "Loss: tensor(0.1020, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5449\n",
      "Loss: tensor(0.1020, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5450\n",
      "Loss: tensor(0.1020, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5451\n",
      "Loss: tensor(0.1020, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5452\n",
      "Loss: tensor(0.1020, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5453\n",
      "Loss: tensor(0.1020, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5454\n",
      "Loss: tensor(0.1020, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5455\n",
      "Loss: tensor(0.1020, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5456\n",
      "Loss: tensor(0.1020, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5457\n",
      "Loss: tensor(0.1020, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5458\n",
      "Loss: tensor(0.1020, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5459\n",
      "Loss: tensor(0.1020, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5460\n",
      "Loss: tensor(0.1020, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5461\n",
      "Loss: tensor(0.1020, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5462\n",
      "Loss: tensor(0.1020, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5463\n",
      "Loss: tensor(0.1020, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5464\n",
      "Loss: tensor(0.1020, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5465\n",
      "Loss: tensor(0.1020, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5466\n",
      "Loss: tensor(0.1020, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5467\n",
      "Loss: tensor(0.1020, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5468\n",
      "Loss: tensor(0.1020, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5469\n",
      "Loss: tensor(0.1020, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5470\n",
      "Loss: tensor(0.1020, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5471\n",
      "Loss: tensor(0.1020, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5472\n",
      "Loss: tensor(0.1020, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5473\n",
      "Loss: tensor(0.1020, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5474\n",
      "Loss: tensor(0.1020, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5475\n",
      "Loss: tensor(0.1020, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5476\n",
      "Loss: tensor(0.1020, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5477\n",
      "Loss: tensor(0.1020, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5478\n",
      "Loss: tensor(0.1020, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5479\n",
      "Loss: tensor(0.1020, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5480\n",
      "Loss: tensor(0.1020, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5481\n",
      "Loss: tensor(0.1020, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5482\n",
      "Loss: tensor(0.1020, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5483\n",
      "Loss: tensor(0.1020, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5484\n",
      "Loss: tensor(0.1020, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5485\n",
      "Loss: tensor(0.1020, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5486\n",
      "Loss: tensor(0.1020, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5487\n",
      "Loss: tensor(0.1020, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5488\n",
      "Loss: tensor(0.1020, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5489\n",
      "Loss: tensor(0.1020, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5490\n",
      "Loss: tensor(0.1020, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5491\n",
      "Loss: tensor(0.1020, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5492\n",
      "Loss: tensor(0.1020, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5493\n",
      "Loss: tensor(0.1020, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5494\n",
      "Loss: tensor(0.1020, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5495\n",
      "Loss: tensor(0.1019, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5496\n",
      "Loss: tensor(0.1019, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5497\n",
      "Loss: tensor(0.1019, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5498\n",
      "Loss: tensor(0.1019, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5499\n",
      "Loss: tensor(0.1019, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5500\n",
      "Loss: tensor(0.1019, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5501\n",
      "Loss: tensor(0.1019, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5502\n",
      "Loss: tensor(0.1019, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5503\n",
      "Loss: tensor(0.1019, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5504\n",
      "Loss: tensor(0.1019, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5505\n",
      "Loss: tensor(0.1019, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5506\n",
      "Loss: tensor(0.1019, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5507\n",
      "Loss: tensor(0.1019, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5508\n",
      "Loss: tensor(0.1019, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5509\n",
      "Loss: tensor(0.1019, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5510\n",
      "Loss: tensor(0.1019, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5511\n",
      "Loss: tensor(0.1019, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5512\n",
      "Loss: tensor(0.1019, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5513\n",
      "Loss: tensor(0.1019, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5514\n",
      "Loss: tensor(0.1019, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5515\n",
      "Loss: tensor(0.1019, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5516\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor(0.1019, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5517\n",
      "Loss: tensor(0.1019, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5518\n",
      "Loss: tensor(0.1019, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5519\n",
      "Loss: tensor(0.1019, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5520\n",
      "Loss: tensor(0.1019, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5521\n",
      "Loss: tensor(0.1019, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5522\n",
      "Loss: tensor(0.1019, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5523\n",
      "Loss: tensor(0.1019, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5524\n",
      "Loss: tensor(0.1019, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5525\n",
      "Loss: tensor(0.1019, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5526\n",
      "Loss: tensor(0.1019, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5527\n",
      "Loss: tensor(0.1019, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5528\n",
      "Loss: tensor(0.1019, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5529\n",
      "Loss: tensor(0.1019, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5530\n",
      "Loss: tensor(0.1019, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5531\n",
      "Loss: tensor(0.1019, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5532\n",
      "Loss: tensor(0.1019, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5533\n",
      "Loss: tensor(0.1019, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5534\n",
      "Loss: tensor(0.1019, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5535\n",
      "Loss: tensor(0.1019, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5536\n",
      "Loss: tensor(0.1019, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5537\n",
      "Loss: tensor(0.1019, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5538\n",
      "Loss: tensor(0.1019, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5539\n",
      "Loss: tensor(0.1019, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5540\n",
      "Loss: tensor(0.1019, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5541\n",
      "Loss: tensor(0.1019, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5542\n",
      "Loss: tensor(0.1019, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5543\n",
      "Loss: tensor(0.1019, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5544\n",
      "Loss: tensor(0.1019, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5545\n",
      "Loss: tensor(0.1019, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5546\n",
      "Loss: tensor(0.1019, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5547\n",
      "Loss: tensor(0.1019, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5548\n",
      "Loss: tensor(0.1019, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5549\n",
      "Loss: tensor(0.1019, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5550\n",
      "Loss: tensor(0.1019, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5551\n",
      "Loss: tensor(0.1019, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5552\n",
      "Loss: tensor(0.1019, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5553\n",
      "Loss: tensor(0.1019, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5554\n",
      "Loss: tensor(0.1019, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5555\n",
      "Loss: tensor(0.1019, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5556\n",
      "Loss: tensor(0.1019, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5557\n",
      "Loss: tensor(0.1019, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5558\n",
      "Loss: tensor(0.1019, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5559\n",
      "Loss: tensor(0.1019, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5560\n",
      "Loss: tensor(0.1019, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5561\n",
      "Loss: tensor(0.1019, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5562\n",
      "Loss: tensor(0.1019, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5563\n",
      "Loss: tensor(0.1019, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5564\n",
      "Loss: tensor(0.1019, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5565\n",
      "Loss: tensor(0.1019, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5566\n",
      "Loss: tensor(0.1019, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5567\n",
      "Loss: tensor(0.1019, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5568\n",
      "Loss: tensor(0.1019, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5569\n",
      "Loss: tensor(0.1019, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5570\n",
      "Loss: tensor(0.1018, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5571\n",
      "Loss: tensor(0.1018, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5572\n",
      "Loss: tensor(0.1018, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5573\n",
      "Loss: tensor(0.1018, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5574\n",
      "Loss: tensor(0.1018, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5575\n",
      "Loss: tensor(0.1018, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5576\n",
      "Loss: tensor(0.1018, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5577\n",
      "Loss: tensor(0.1018, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5578\n",
      "Loss: tensor(0.1018, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5579\n",
      "Loss: tensor(0.1018, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5580\n",
      "Loss: tensor(0.1018, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5581\n",
      "Loss: tensor(0.1018, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5582\n",
      "Loss: tensor(0.1018, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5583\n",
      "Loss: tensor(0.1018, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5584\n",
      "Loss: tensor(0.1018, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5585\n",
      "Loss: tensor(0.1018, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5586\n",
      "Loss: tensor(0.1018, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5587\n",
      "Loss: tensor(0.1018, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5588\n",
      "Loss: tensor(0.1018, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5589\n",
      "Loss: tensor(0.1018, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5590\n",
      "Loss: tensor(0.1018, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5591\n",
      "Loss: tensor(0.1018, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5592\n",
      "Loss: tensor(0.1018, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5593\n",
      "Loss: tensor(0.1018, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5594\n",
      "Loss: tensor(0.1018, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5595\n",
      "Loss: tensor(0.1018, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5596\n",
      "Loss: tensor(0.1018, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5597\n",
      "Loss: tensor(0.1018, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5598\n",
      "Loss: tensor(0.1018, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5599\n",
      "Loss: tensor(0.1018, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5600\n",
      "Loss: tensor(0.1018, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5601\n",
      "Loss: tensor(0.1018, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5602\n",
      "Loss: tensor(0.1018, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5603\n",
      "Loss: tensor(0.1018, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5604\n",
      "Loss: tensor(0.1018, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5605\n",
      "Loss: tensor(0.1018, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5606\n",
      "Loss: tensor(0.1018, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5607\n",
      "Loss: tensor(0.1018, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5608\n",
      "Loss: tensor(0.1018, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5609\n",
      "Loss: tensor(0.1018, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5610\n",
      "Loss: tensor(0.1018, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5611\n",
      "Loss: tensor(0.1018, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5612\n",
      "Loss: tensor(0.1018, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5613\n",
      "Loss: tensor(0.1018, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5614\n",
      "Loss: tensor(0.1018, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5615\n",
      "Loss: tensor(0.1018, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5616\n",
      "Loss: tensor(0.1018, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5617\n",
      "Loss: tensor(0.1018, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5618\n",
      "Loss: tensor(0.1018, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5619\n",
      "Loss: tensor(0.1018, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5620\n",
      "Loss: tensor(0.1018, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5621\n",
      "Loss: tensor(0.1018, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5622\n",
      "Loss: tensor(0.1018, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5623\n",
      "Loss: tensor(0.1018, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5624\n",
      "Loss: tensor(0.1018, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5625\n",
      "Loss: tensor(0.1018, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5626\n",
      "Loss: tensor(0.1018, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5627\n",
      "Loss: tensor(0.1018, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5628\n",
      "Loss: tensor(0.1018, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5629\n",
      "Loss: tensor(0.1018, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5630\n",
      "Loss: tensor(0.1018, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5631\n",
      "Loss: tensor(0.1018, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5632\n",
      "Loss: tensor(0.1018, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5633\n",
      "Loss: tensor(0.1018, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5634\n",
      "Loss: tensor(0.1018, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5635\n",
      "Loss: tensor(0.1018, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5636\n",
      "Loss: tensor(0.1018, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5637\n",
      "Loss: tensor(0.1018, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5638\n",
      "Loss: tensor(0.1018, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5639\n",
      "Loss: tensor(0.1018, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5640\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor(0.1018, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5641\n",
      "Loss: tensor(0.1018, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5642\n",
      "Loss: tensor(0.1018, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5643\n",
      "Loss: tensor(0.1018, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5644\n",
      "Loss: tensor(0.1018, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5645\n",
      "Loss: tensor(0.1018, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5646\n",
      "Loss: tensor(0.1018, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5647\n",
      "Loss: tensor(0.1018, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5648\n",
      "Loss: tensor(0.1018, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5649\n",
      "Loss: tensor(0.1017, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5650\n",
      "Loss: tensor(0.1017, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5651\n",
      "Loss: tensor(0.1017, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5652\n",
      "Loss: tensor(0.1017, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5653\n",
      "Loss: tensor(0.1017, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5654\n",
      "Loss: tensor(0.1017, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5655\n",
      "Loss: tensor(0.1017, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5656\n",
      "Loss: tensor(0.1017, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5657\n",
      "Loss: tensor(0.1017, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5658\n",
      "Loss: tensor(0.1017, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5659\n",
      "Loss: tensor(0.1017, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5660\n",
      "Loss: tensor(0.1017, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5661\n",
      "Loss: tensor(0.1017, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5662\n",
      "Loss: tensor(0.1017, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5663\n",
      "Loss: tensor(0.1017, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5664\n",
      "Loss: tensor(0.1017, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5665\n",
      "Loss: tensor(0.1017, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5666\n",
      "Loss: tensor(0.1017, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5667\n",
      "Loss: tensor(0.1017, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5668\n",
      "Loss: tensor(0.1017, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5669\n",
      "Loss: tensor(0.1017, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5670\n",
      "Loss: tensor(0.1017, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5671\n",
      "Loss: tensor(0.1017, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5672\n",
      "Loss: tensor(0.1017, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5673\n",
      "Loss: tensor(0.1017, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5674\n",
      "Loss: tensor(0.1017, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5675\n",
      "Loss: tensor(0.1017, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5676\n",
      "Loss: tensor(0.1017, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5677\n",
      "Loss: tensor(0.1017, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5678\n",
      "Loss: tensor(0.1017, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5679\n",
      "Loss: tensor(0.1017, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5680\n",
      "Loss: tensor(0.1017, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5681\n",
      "Loss: tensor(0.1017, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5682\n",
      "Loss: tensor(0.1017, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5683\n",
      "Loss: tensor(0.1017, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5684\n",
      "Loss: tensor(0.1017, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5685\n",
      "Loss: tensor(0.1017, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5686\n",
      "Loss: tensor(0.1017, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5687\n",
      "Loss: tensor(0.1017, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5688\n",
      "Loss: tensor(0.1017, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5689\n",
      "Loss: tensor(0.1017, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5690\n",
      "Loss: tensor(0.1017, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5691\n",
      "Loss: tensor(0.1017, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5692\n",
      "Loss: tensor(0.1017, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5693\n",
      "Loss: tensor(0.1017, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5694\n",
      "Loss: tensor(0.1017, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5695\n",
      "Loss: tensor(0.1017, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5696\n",
      "Loss: tensor(0.1017, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5697\n",
      "Loss: tensor(0.1017, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5698\n",
      "Loss: tensor(0.1017, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5699\n",
      "Loss: tensor(0.1017, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5700\n",
      "Loss: tensor(0.1017, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5701\n",
      "Loss: tensor(0.1017, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5702\n",
      "Loss: tensor(0.1017, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5703\n",
      "Loss: tensor(0.1017, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5704\n",
      "Loss: tensor(0.1017, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5705\n",
      "Loss: tensor(0.1017, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5706\n",
      "Loss: tensor(0.1017, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5707\n",
      "Loss: tensor(0.1017, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5708\n",
      "Loss: tensor(0.1017, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5709\n",
      "Loss: tensor(0.1017, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5710\n",
      "Loss: tensor(0.1017, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5711\n",
      "Loss: tensor(0.1017, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5712\n",
      "Loss: tensor(0.1017, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5713\n",
      "Loss: tensor(0.1017, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5714\n",
      "Loss: tensor(0.1017, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5715\n",
      "Loss: tensor(0.1017, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5716\n",
      "Loss: tensor(0.1017, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5717\n",
      "Loss: tensor(0.1017, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5718\n",
      "Loss: tensor(0.1017, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5719\n",
      "Loss: tensor(0.1017, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5720\n",
      "Loss: tensor(0.1017, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5721\n",
      "Loss: tensor(0.1017, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5722\n",
      "Loss: tensor(0.1017, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5723\n",
      "Loss: tensor(0.1017, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5724\n",
      "Loss: tensor(0.1017, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5725\n",
      "Loss: tensor(0.1017, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5726\n",
      "Loss: tensor(0.1017, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5727\n",
      "Loss: tensor(0.1017, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5728\n",
      "Loss: tensor(0.1017, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5729\n",
      "Loss: tensor(0.1017, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5730\n",
      "Loss: tensor(0.1017, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5731\n",
      "Loss: tensor(0.1017, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5732\n",
      "Loss: tensor(0.1017, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5733\n",
      "Loss: tensor(0.1017, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5734\n",
      "Loss: tensor(0.1016, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5735\n",
      "Loss: tensor(0.1016, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5736\n",
      "Loss: tensor(0.1016, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5737\n",
      "Loss: tensor(0.1016, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5738\n",
      "Loss: tensor(0.1016, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5739\n",
      "Loss: tensor(0.1016, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5740\n",
      "Loss: tensor(0.1016, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5741\n",
      "Loss: tensor(0.1016, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5742\n",
      "Loss: tensor(0.1016, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5743\n",
      "Loss: tensor(0.1016, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5744\n",
      "Loss: tensor(0.1016, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5745\n",
      "Loss: tensor(0.1016, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5746\n",
      "Loss: tensor(0.1016, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5747\n",
      "Loss: tensor(0.1016, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5748\n",
      "Loss: tensor(0.1016, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5749\n",
      "Loss: tensor(0.1016, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5750\n",
      "Loss: tensor(0.1016, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5751\n",
      "Loss: tensor(0.1016, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5752\n",
      "Loss: tensor(0.1016, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5753\n",
      "Loss: tensor(0.1016, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5754\n",
      "Loss: tensor(0.1016, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5755\n",
      "Loss: tensor(0.1016, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5756\n",
      "Loss: tensor(0.1016, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5757\n",
      "Loss: tensor(0.1016, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5758\n",
      "Loss: tensor(0.1016, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5759\n",
      "Loss: tensor(0.1016, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5760\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor(0.1016, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5761\n",
      "Loss: tensor(0.1016, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5762\n",
      "Loss: tensor(0.1016, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5763\n",
      "Loss: tensor(0.1016, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5764\n",
      "Loss: tensor(0.1016, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5765\n",
      "Loss: tensor(0.1016, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5766\n",
      "Loss: tensor(0.1016, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5767\n",
      "Loss: tensor(0.1016, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5768\n",
      "Loss: tensor(0.1016, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5769\n",
      "Loss: tensor(0.1016, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5770\n",
      "Loss: tensor(0.1016, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5771\n",
      "Loss: tensor(0.1016, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5772\n",
      "Loss: tensor(0.1016, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5773\n",
      "Loss: tensor(0.1016, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5774\n",
      "Loss: tensor(0.1016, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5775\n",
      "Loss: tensor(0.1016, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5776\n",
      "Loss: tensor(0.1016, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5777\n",
      "Loss: tensor(0.1016, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5778\n",
      "Loss: tensor(0.1016, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5779\n",
      "Loss: tensor(0.1016, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5780\n",
      "Loss: tensor(0.1016, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5781\n",
      "Loss: tensor(0.1016, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5782\n",
      "Loss: tensor(0.1016, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5783\n",
      "Loss: tensor(0.1016, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5784\n",
      "Loss: tensor(0.1016, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5785\n",
      "Loss: tensor(0.1016, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5786\n",
      "Loss: tensor(0.1016, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5787\n",
      "Loss: tensor(0.1016, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5788\n",
      "Loss: tensor(0.1016, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5789\n",
      "Loss: tensor(0.1016, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5790\n",
      "Loss: tensor(0.1016, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5791\n",
      "Loss: tensor(0.1016, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5792\n",
      "Loss: tensor(0.1016, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5793\n",
      "Loss: tensor(0.1016, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5794\n",
      "Loss: tensor(0.1016, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5795\n",
      "Loss: tensor(0.1016, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5796\n",
      "Loss: tensor(0.1016, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5797\n",
      "Loss: tensor(0.1016, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5798\n",
      "Loss: tensor(0.1016, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5799\n",
      "Loss: tensor(0.1016, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5800\n",
      "Loss: tensor(0.1016, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5801\n",
      "Loss: tensor(0.1016, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5802\n",
      "Loss: tensor(0.1016, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5803\n",
      "Loss: tensor(0.1016, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5804\n",
      "Loss: tensor(0.1016, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5805\n",
      "Loss: tensor(0.1016, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5806\n",
      "Loss: tensor(0.1016, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5807\n",
      "Loss: tensor(0.1016, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5808\n",
      "Loss: tensor(0.1016, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5809\n",
      "Loss: tensor(0.1016, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5810\n",
      "Loss: tensor(0.1016, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5811\n",
      "Loss: tensor(0.1016, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5812\n",
      "Loss: tensor(0.1016, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5813\n",
      "Loss: tensor(0.1016, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5814\n",
      "Loss: tensor(0.1016, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5815\n",
      "Loss: tensor(0.1016, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5816\n",
      "Loss: tensor(0.1016, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5817\n",
      "Loss: tensor(0.1016, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5818\n",
      "Loss: tensor(0.1016, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5819\n",
      "Loss: tensor(0.1016, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5820\n",
      "Loss: tensor(0.1016, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5821\n",
      "Loss: tensor(0.1016, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5822\n",
      "Loss: tensor(0.1016, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5823\n",
      "Loss: tensor(0.1016, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5824\n",
      "Loss: tensor(0.1015, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5825\n",
      "Loss: tensor(0.1015, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5826\n",
      "Loss: tensor(0.1015, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5827\n",
      "Loss: tensor(0.1015, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5828\n",
      "Loss: tensor(0.1015, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5829\n",
      "Loss: tensor(0.1015, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5830\n",
      "Loss: tensor(0.1015, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5831\n",
      "Loss: tensor(0.1015, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5832\n",
      "Loss: tensor(0.1015, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5833\n",
      "Loss: tensor(0.1015, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5834\n",
      "Loss: tensor(0.1015, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5835\n",
      "Loss: tensor(0.1015, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5836\n",
      "Loss: tensor(0.1015, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5837\n",
      "Loss: tensor(0.1015, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5838\n",
      "Loss: tensor(0.1015, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5839\n",
      "Loss: tensor(0.1015, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5840\n",
      "Loss: tensor(0.1015, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5841\n",
      "Loss: tensor(0.1015, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5842\n",
      "Loss: tensor(0.1015, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5843\n",
      "Loss: tensor(0.1015, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5844\n",
      "Loss: tensor(0.1015, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5845\n",
      "Loss: tensor(0.1015, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5846\n",
      "Loss: tensor(0.1015, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5847\n",
      "Loss: tensor(0.1015, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5848\n",
      "Loss: tensor(0.1015, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5849\n",
      "Loss: tensor(0.1015, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5850\n",
      "Loss: tensor(0.1015, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5851\n",
      "Loss: tensor(0.1015, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5852\n",
      "Loss: tensor(0.1015, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5853\n",
      "Loss: tensor(0.1015, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5854\n",
      "Loss: tensor(0.1015, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5855\n",
      "Loss: tensor(0.1015, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5856\n",
      "Loss: tensor(0.1015, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5857\n",
      "Loss: tensor(0.1015, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5858\n",
      "Loss: tensor(0.1015, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5859\n",
      "Loss: tensor(0.1015, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5860\n",
      "Loss: tensor(0.1015, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5861\n",
      "Loss: tensor(0.1015, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5862\n",
      "Loss: tensor(0.1015, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5863\n",
      "Loss: tensor(0.1015, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5864\n",
      "Loss: tensor(0.1015, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5865\n",
      "Loss: tensor(0.1015, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5866\n",
      "Loss: tensor(0.1015, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5867\n",
      "Loss: tensor(0.1015, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5868\n",
      "Loss: tensor(0.1015, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5869\n",
      "Loss: tensor(0.1015, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5870\n",
      "Loss: tensor(0.1015, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5871\n",
      "Loss: tensor(0.1015, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5872\n",
      "Loss: tensor(0.1015, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5873\n",
      "Loss: tensor(0.1015, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5874\n",
      "Loss: tensor(0.1015, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5875\n",
      "Loss: tensor(0.1015, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5876\n",
      "Loss: tensor(0.1015, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5877\n",
      "Loss: tensor(0.1015, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5878\n",
      "Loss: tensor(0.1015, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5879\n",
      "Loss: tensor(0.1015, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5880\n",
      "Loss: tensor(0.1015, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5881\n",
      "Loss: tensor(0.1015, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5882\n",
      "Loss: tensor(0.1015, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5883\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor(0.1015, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5884\n",
      "Loss: tensor(0.1015, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5885\n",
      "Loss: tensor(0.1015, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5886\n",
      "Loss: tensor(0.1015, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5887\n",
      "Loss: tensor(0.1015, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5888\n",
      "Loss: tensor(0.1015, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5889\n",
      "Loss: tensor(0.1015, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5890\n",
      "Loss: tensor(0.1015, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5891\n",
      "Loss: tensor(0.1015, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5892\n",
      "Loss: tensor(0.1015, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5893\n",
      "Loss: tensor(0.1015, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5894\n",
      "Loss: tensor(0.1015, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5895\n",
      "Loss: tensor(0.1015, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5896\n",
      "Loss: tensor(0.1015, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5897\n",
      "Loss: tensor(0.1015, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5898\n",
      "Loss: tensor(0.1015, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5899\n",
      "Loss: tensor(0.1015, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5900\n",
      "Loss: tensor(0.1015, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5901\n",
      "Loss: tensor(0.1015, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5902\n",
      "Loss: tensor(0.1015, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5903\n",
      "Loss: tensor(0.1015, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5904\n",
      "Loss: tensor(0.1015, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5905\n",
      "Loss: tensor(0.1015, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5906\n",
      "Loss: tensor(0.1015, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5907\n",
      "Loss: tensor(0.1015, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5908\n",
      "Loss: tensor(0.1015, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5909\n",
      "Loss: tensor(0.1015, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5910\n",
      "Loss: tensor(0.1015, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5911\n",
      "Loss: tensor(0.1015, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5912\n",
      "Loss: tensor(0.1015, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5913\n",
      "Loss: tensor(0.1015, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5914\n",
      "Loss: tensor(0.1015, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5915\n",
      "Loss: tensor(0.1015, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5916\n",
      "Loss: tensor(0.1015, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5917\n",
      "Loss: tensor(0.1015, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5918\n",
      "Loss: tensor(0.1015, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5919\n",
      "Loss: tensor(0.1015, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5920\n",
      "Loss: tensor(0.1015, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5921\n",
      "Loss: tensor(0.1014, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5922\n",
      "Loss: tensor(0.1014, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5923\n",
      "Loss: tensor(0.1014, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5924\n",
      "Loss: tensor(0.1014, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5925\n",
      "Loss: tensor(0.1014, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5926\n",
      "Loss: tensor(0.1014, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5927\n",
      "Loss: tensor(0.1014, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5928\n",
      "Loss: tensor(0.1014, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5929\n",
      "Loss: tensor(0.1014, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5930\n",
      "Loss: tensor(0.1014, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5931\n",
      "Loss: tensor(0.1014, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5932\n",
      "Loss: tensor(0.1014, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5933\n",
      "Loss: tensor(0.1014, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5934\n",
      "Loss: tensor(0.1014, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5935\n",
      "Loss: tensor(0.1014, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5936\n",
      "Loss: tensor(0.1014, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5937\n",
      "Loss: tensor(0.1014, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5938\n",
      "Loss: tensor(0.1014, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5939\n",
      "Loss: tensor(0.1014, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5940\n",
      "Loss: tensor(0.1014, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5941\n",
      "Loss: tensor(0.1014, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5942\n",
      "Loss: tensor(0.1014, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5943\n",
      "Loss: tensor(0.1014, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5944\n",
      "Loss: tensor(0.1014, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5945\n",
      "Loss: tensor(0.1014, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5946\n",
      "Loss: tensor(0.1014, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5947\n",
      "Loss: tensor(0.1014, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5948\n",
      "Loss: tensor(0.1014, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5949\n",
      "Loss: tensor(0.1014, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5950\n",
      "Loss: tensor(0.1014, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5951\n",
      "Loss: tensor(0.1014, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5952\n",
      "Loss: tensor(0.1014, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5953\n",
      "Loss: tensor(0.1014, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5954\n",
      "Loss: tensor(0.1014, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5955\n",
      "Loss: tensor(0.1014, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5956\n",
      "Loss: tensor(0.1014, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5957\n",
      "Loss: tensor(0.1014, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5958\n",
      "Loss: tensor(0.1014, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5959\n",
      "Loss: tensor(0.1014, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5960\n",
      "Loss: tensor(0.1014, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5961\n",
      "Loss: tensor(0.1014, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5962\n",
      "Loss: tensor(0.1014, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5963\n",
      "Loss: tensor(0.1014, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5964\n",
      "Loss: tensor(0.1014, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5965\n",
      "Loss: tensor(0.1014, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5966\n",
      "Loss: tensor(0.1014, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5967\n",
      "Loss: tensor(0.1014, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5968\n",
      "Loss: tensor(0.1014, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5969\n",
      "Loss: tensor(0.1014, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5970\n",
      "Loss: tensor(0.1014, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5971\n",
      "Loss: tensor(0.1014, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5972\n",
      "Loss: tensor(0.1014, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5973\n",
      "Loss: tensor(0.1014, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5974\n",
      "Loss: tensor(0.1014, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5975\n",
      "Loss: tensor(0.1014, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5976\n",
      "Loss: tensor(0.1014, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5977\n",
      "Loss: tensor(0.1014, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5978\n",
      "Loss: tensor(0.1014, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5979\n",
      "Loss: tensor(0.1014, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5980\n",
      "Loss: tensor(0.1014, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5981\n",
      "Loss: tensor(0.1014, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5982\n",
      "Loss: tensor(0.1014, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5983\n",
      "Loss: tensor(0.1014, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5984\n",
      "Loss: tensor(0.1014, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5985\n",
      "Loss: tensor(0.1014, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5986\n",
      "Loss: tensor(0.1014, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5987\n",
      "Loss: tensor(0.1014, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5988\n",
      "Loss: tensor(0.1014, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5989\n",
      "Loss: tensor(0.1014, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5990\n",
      "Loss: tensor(0.1014, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5991\n",
      "Loss: tensor(0.1014, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5992\n",
      "Loss: tensor(0.1014, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5993\n",
      "Loss: tensor(0.1014, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5994\n",
      "Loss: tensor(0.1014, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5995\n",
      "Loss: tensor(0.1014, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5996\n",
      "Loss: tensor(0.1014, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5997\n",
      "Loss: tensor(0.1014, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5998\n",
      "Loss: tensor(0.1014, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5999\n",
      "Loss: tensor(0.1014, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6000\n",
      "Loss: tensor(0.1014, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6001\n",
      "Loss: tensor(0.1014, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6002\n",
      "Loss: tensor(0.1014, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6003\n",
      "Loss: tensor(0.1014, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6004\n",
      "Loss: tensor(0.1014, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6005\n",
      "Loss: tensor(0.1014, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6006\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor(0.1014, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6007\n",
      "Loss: tensor(0.1014, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6008\n",
      "Loss: tensor(0.1014, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6009\n",
      "Loss: tensor(0.1014, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6010\n",
      "Loss: tensor(0.1014, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6011\n",
      "Loss: tensor(0.1014, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6012\n",
      "Loss: tensor(0.1014, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6013\n",
      "Loss: tensor(0.1014, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6014\n",
      "Loss: tensor(0.1014, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6015\n",
      "Loss: tensor(0.1014, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6016\n",
      "Loss: tensor(0.1014, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6017\n",
      "Loss: tensor(0.1014, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6018\n",
      "Loss: tensor(0.1014, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6019\n",
      "Loss: tensor(0.1014, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6020\n",
      "Loss: tensor(0.1014, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6021\n",
      "Loss: tensor(0.1014, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6022\n",
      "Loss: tensor(0.1014, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6023\n",
      "Loss: tensor(0.1014, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6024\n",
      "Loss: tensor(0.1014, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6025\n",
      "Loss: tensor(0.1013, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6026\n",
      "Loss: tensor(0.1013, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6027\n",
      "Loss: tensor(0.1013, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6028\n",
      "Loss: tensor(0.1013, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6029\n",
      "Loss: tensor(0.1013, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6030\n",
      "Loss: tensor(0.1013, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6031\n",
      "Loss: tensor(0.1013, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6032\n",
      "Loss: tensor(0.1013, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6033\n",
      "Loss: tensor(0.1013, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6034\n",
      "Loss: tensor(0.1013, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6035\n",
      "Loss: tensor(0.1013, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6036\n",
      "Loss: tensor(0.1013, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6037\n",
      "Loss: tensor(0.1013, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6038\n",
      "Loss: tensor(0.1013, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6039\n",
      "Loss: tensor(0.1013, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6040\n",
      "Loss: tensor(0.1013, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6041\n",
      "Loss: tensor(0.1013, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6042\n",
      "Loss: tensor(0.1013, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6043\n",
      "Loss: tensor(0.1013, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6044\n",
      "Loss: tensor(0.1013, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6045\n",
      "Loss: tensor(0.1013, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6046\n",
      "Loss: tensor(0.1013, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6047\n",
      "Loss: tensor(0.1013, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6048\n",
      "Loss: tensor(0.1013, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6049\n",
      "Loss: tensor(0.1013, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6050\n",
      "Loss: tensor(0.1013, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6051\n",
      "Loss: tensor(0.1013, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6052\n",
      "Loss: tensor(0.1013, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6053\n",
      "Loss: tensor(0.1013, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6054\n",
      "Loss: tensor(0.1013, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6055\n",
      "Loss: tensor(0.1013, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6056\n",
      "Loss: tensor(0.1013, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6057\n",
      "Loss: tensor(0.1013, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6058\n",
      "Loss: tensor(0.1013, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6059\n",
      "Loss: tensor(0.1013, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6060\n",
      "Loss: tensor(0.1013, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6061\n",
      "Loss: tensor(0.1013, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6062\n",
      "Loss: tensor(0.1013, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6063\n",
      "Loss: tensor(0.1013, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6064\n",
      "Loss: tensor(0.1013, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6065\n",
      "Loss: tensor(0.1013, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6066\n",
      "Loss: tensor(0.1013, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6067\n",
      "Loss: tensor(0.1013, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6068\n",
      "Loss: tensor(0.1013, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6069\n",
      "Loss: tensor(0.1013, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6070\n",
      "Loss: tensor(0.1013, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6071\n",
      "Loss: tensor(0.1013, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6072\n",
      "Loss: tensor(0.1013, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6073\n",
      "Loss: tensor(0.1013, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6074\n",
      "Loss: tensor(0.1013, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6075\n",
      "Loss: tensor(0.1013, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6076\n",
      "Loss: tensor(0.1013, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6077\n",
      "Loss: tensor(0.1013, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6078\n",
      "Loss: tensor(0.1013, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6079\n",
      "Loss: tensor(0.1013, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6080\n",
      "Loss: tensor(0.1013, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6081\n",
      "Loss: tensor(0.1013, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6082\n",
      "Loss: tensor(0.1013, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6083\n",
      "Loss: tensor(0.1013, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6084\n",
      "Loss: tensor(0.1013, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6085\n",
      "Loss: tensor(0.1013, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6086\n",
      "Loss: tensor(0.1013, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6087\n",
      "Loss: tensor(0.1013, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6088\n",
      "Loss: tensor(0.1013, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6089\n",
      "Loss: tensor(0.1013, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6090\n",
      "Loss: tensor(0.1013, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6091\n",
      "Loss: tensor(0.1013, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6092\n",
      "Loss: tensor(0.1013, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6093\n",
      "Loss: tensor(0.1013, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6094\n",
      "Loss: tensor(0.1013, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6095\n",
      "Loss: tensor(0.1013, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6096\n",
      "Loss: tensor(0.1013, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6097\n",
      "Loss: tensor(0.1013, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6098\n",
      "Loss: tensor(0.1013, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6099\n",
      "Loss: tensor(0.1013, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6100\n",
      "Loss: tensor(0.1013, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6101\n",
      "Loss: tensor(0.1013, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6102\n",
      "Loss: tensor(0.1013, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6103\n",
      "Loss: tensor(0.1013, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6104\n",
      "Loss: tensor(0.1013, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6105\n",
      "Loss: tensor(0.1013, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6106\n",
      "Loss: tensor(0.1013, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6107\n",
      "Loss: tensor(0.1013, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6108\n",
      "Loss: tensor(0.1013, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6109\n",
      "Loss: tensor(0.1013, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6110\n",
      "Loss: tensor(0.1013, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6111\n",
      "Loss: tensor(0.1013, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6112\n",
      "Loss: tensor(0.1013, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6113\n",
      "Loss: tensor(0.1013, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6114\n",
      "Loss: tensor(0.1013, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6115\n",
      "Loss: tensor(0.1013, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6116\n",
      "Loss: tensor(0.1013, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6117\n",
      "Loss: tensor(0.1013, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6118\n",
      "Loss: tensor(0.1013, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6119\n",
      "Loss: tensor(0.1013, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6120\n",
      "Loss: tensor(0.1013, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6121\n",
      "Loss: tensor(0.1013, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6122\n",
      "Loss: tensor(0.1013, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6123\n",
      "Loss: tensor(0.1013, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6124\n",
      "Loss: tensor(0.1013, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6125\n",
      "Loss: tensor(0.1013, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6126\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor(0.1013, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6127\n",
      "Loss: tensor(0.1013, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6128\n",
      "Loss: tensor(0.1013, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6129\n",
      "Loss: tensor(0.1013, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6130\n",
      "Loss: tensor(0.1013, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6131\n",
      "Loss: tensor(0.1013, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6132\n",
      "Loss: tensor(0.1013, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6133\n",
      "Loss: tensor(0.1013, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6134\n",
      "Loss: tensor(0.1013, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6135\n",
      "Loss: tensor(0.1013, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6136\n",
      "Loss: tensor(0.1013, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6137\n",
      "Loss: tensor(0.1012, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6138\n",
      "Loss: tensor(0.1012, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6139\n",
      "Loss: tensor(0.1012, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6140\n",
      "Loss: tensor(0.1012, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6141\n",
      "Loss: tensor(0.1012, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6142\n",
      "Loss: tensor(0.1012, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6143\n",
      "Loss: tensor(0.1012, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6144\n",
      "Loss: tensor(0.1012, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6145\n",
      "Loss: tensor(0.1012, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6146\n",
      "Loss: tensor(0.1012, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6147\n",
      "Loss: tensor(0.1012, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6148\n",
      "Loss: tensor(0.1012, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6149\n",
      "Loss: tensor(0.1012, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6150\n",
      "Loss: tensor(0.1012, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6151\n",
      "Loss: tensor(0.1012, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6152\n",
      "Loss: tensor(0.1012, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6153\n",
      "Loss: tensor(0.1012, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6154\n",
      "Loss: tensor(0.1012, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6155\n",
      "Loss: tensor(0.1012, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6156\n",
      "Loss: tensor(0.1013, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6157\n",
      "Loss: tensor(0.1013, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6158\n",
      "Loss: tensor(0.1013, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6159\n",
      "Loss: tensor(0.1013, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6160\n",
      "Loss: tensor(0.1013, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6161\n",
      "Loss: tensor(0.1012, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6162\n",
      "Loss: tensor(0.1012, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6163\n",
      "Loss: tensor(0.1012, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6164\n",
      "Loss: tensor(0.1012, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6165\n",
      "Loss: tensor(0.1012, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6166\n",
      "Loss: tensor(0.1012, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6167\n",
      "Loss: tensor(0.1012, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6168\n",
      "Loss: tensor(0.1012, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6169\n",
      "Loss: tensor(0.1012, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6170\n",
      "Loss: tensor(0.1012, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6171\n",
      "Loss: tensor(0.1012, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6172\n",
      "Loss: tensor(0.1012, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6173\n",
      "Loss: tensor(0.1012, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6174\n",
      "Loss: tensor(0.1012, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6175\n",
      "Loss: tensor(0.1012, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6176\n",
      "Loss: tensor(0.1012, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6177\n",
      "Loss: tensor(0.1012, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6178\n",
      "Loss: tensor(0.1012, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6179\n",
      "Loss: tensor(0.1012, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6180\n",
      "Loss: tensor(0.1012, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6181\n",
      "Loss: tensor(0.1012, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6182\n",
      "Loss: tensor(0.1012, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6183\n",
      "Loss: tensor(0.1012, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6184\n",
      "Loss: tensor(0.1012, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6185\n",
      "Loss: tensor(0.1012, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6186\n",
      "Loss: tensor(0.1012, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6187\n",
      "Loss: tensor(0.1012, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6188\n",
      "Loss: tensor(0.1012, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6189\n",
      "Loss: tensor(0.1012, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6190\n",
      "Loss: tensor(0.1012, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6191\n",
      "Loss: tensor(0.1012, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6192\n",
      "Loss: tensor(0.1012, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6193\n",
      "Loss: tensor(0.1012, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6194\n",
      "Loss: tensor(0.1012, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6195\n",
      "Loss: tensor(0.1012, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6196\n",
      "Loss: tensor(0.1012, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6197\n",
      "Loss: tensor(0.1012, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6198\n",
      "Loss: tensor(0.1012, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6199\n",
      "Loss: tensor(0.1012, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6200\n",
      "Loss: tensor(0.1012, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6201\n",
      "Loss: tensor(0.1012, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6202\n",
      "Loss: tensor(0.1012, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6203\n",
      "Loss: tensor(0.1012, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6204\n",
      "Loss: tensor(0.1012, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6205\n",
      "Loss: tensor(0.1012, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6206\n",
      "Loss: tensor(0.1012, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6207\n",
      "Loss: tensor(0.1012, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6208\n",
      "Loss: tensor(0.1012, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6209\n",
      "Loss: tensor(0.1012, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6210\n",
      "Loss: tensor(0.1012, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6211\n",
      "Loss: tensor(0.1012, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6212\n",
      "Loss: tensor(0.1012, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6213\n",
      "Loss: tensor(0.1012, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6214\n",
      "Loss: tensor(0.1012, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6215\n",
      "Loss: tensor(0.1012, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6216\n",
      "Loss: tensor(0.1012, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6217\n",
      "Loss: tensor(0.1012, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6218\n",
      "Loss: tensor(0.1012, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6219\n",
      "Loss: tensor(0.1012, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6220\n",
      "Loss: tensor(0.1012, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6221\n",
      "Loss: tensor(0.1012, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6222\n",
      "Loss: tensor(0.1012, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6223\n",
      "Loss: tensor(0.1012, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6224\n",
      "Loss: tensor(0.1012, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6225\n",
      "Loss: tensor(0.1012, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6226\n",
      "Loss: tensor(0.1012, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6227\n",
      "Loss: tensor(0.1012, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6228\n",
      "Loss: tensor(0.1012, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6229\n",
      "Loss: tensor(0.1012, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6230\n",
      "Loss: tensor(0.1012, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6231\n",
      "Loss: tensor(0.1012, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6232\n",
      "Loss: tensor(0.1012, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6233\n",
      "Loss: tensor(0.1012, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6234\n",
      "Loss: tensor(0.1012, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6235\n",
      "Loss: tensor(0.1012, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6236\n",
      "Loss: tensor(0.1012, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6237\n",
      "Loss: tensor(0.1012, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6238\n",
      "Loss: tensor(0.1012, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6239\n",
      "Loss: tensor(0.1012, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6240\n",
      "Loss: tensor(0.1012, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6241\n",
      "Loss: tensor(0.1012, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6242\n",
      "Loss: tensor(0.1012, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6243\n",
      "Loss: tensor(0.1012, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6244\n",
      "Loss: tensor(0.1012, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6245\n",
      "Loss: tensor(0.1012, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6246\n",
      "Loss: tensor(0.1012, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6247\n",
      "Loss: tensor(0.1012, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6248\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor(0.1012, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6249\n",
      "Loss: tensor(0.1012, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6250\n",
      "Loss: tensor(0.1012, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6251\n",
      "Loss: tensor(0.1012, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6252\n",
      "Loss: tensor(0.1012, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6253\n",
      "Loss: tensor(0.1012, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6254\n",
      "Loss: tensor(0.1012, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6255\n",
      "Loss: tensor(0.1012, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6256\n",
      "Loss: tensor(0.1012, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6257\n",
      "Loss: tensor(0.1012, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6258\n",
      "Loss: tensor(0.1012, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6259\n",
      "Loss: tensor(0.1012, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6260\n",
      "Loss: tensor(0.1012, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6261\n",
      "Loss: tensor(0.1012, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6262\n",
      "Loss: tensor(0.1012, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6263\n",
      "Loss: tensor(0.1011, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6264\n",
      "Loss: tensor(0.1011, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6265\n",
      "Loss: tensor(0.1011, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6266\n",
      "Loss: tensor(0.1011, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6267\n",
      "Loss: tensor(0.1011, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6268\n",
      "Loss: tensor(0.1011, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6269\n",
      "Loss: tensor(0.1011, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6270\n",
      "Loss: tensor(0.1011, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6271\n",
      "Loss: tensor(0.1011, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6272\n",
      "Loss: tensor(0.1011, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6273\n",
      "Loss: tensor(0.1011, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6274\n",
      "Loss: tensor(0.1011, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6275\n",
      "Loss: tensor(0.1011, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6276\n",
      "Loss: tensor(0.1011, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6277\n",
      "Loss: tensor(0.1011, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6278\n",
      "Loss: tensor(0.1011, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6279\n",
      "Loss: tensor(0.1011, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6280\n",
      "Loss: tensor(0.1011, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6281\n",
      "Loss: tensor(0.1011, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6282\n",
      "Loss: tensor(0.1011, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6283\n",
      "Loss: tensor(0.1011, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6284\n",
      "Loss: tensor(0.1011, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6285\n",
      "Loss: tensor(0.1011, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6286\n",
      "Loss: tensor(0.1011, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6287\n",
      "Loss: tensor(0.1011, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6288\n",
      "Loss: tensor(0.1011, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6289\n",
      "Loss: tensor(0.1011, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6290\n",
      "Loss: tensor(0.1011, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6291\n",
      "Loss: tensor(0.1011, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6292\n",
      "Loss: tensor(0.1011, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6293\n",
      "Loss: tensor(0.1011, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6294\n",
      "Loss: tensor(0.1011, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6295\n",
      "Loss: tensor(0.1011, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6296\n",
      "Loss: tensor(0.1011, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6297\n",
      "Loss: tensor(0.1011, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6298\n",
      "Loss: tensor(0.1011, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6299\n",
      "Loss: tensor(0.1011, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6300\n",
      "Loss: tensor(0.1011, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6301\n",
      "Loss: tensor(0.1011, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6302\n",
      "Loss: tensor(0.1011, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6303\n",
      "Loss: tensor(0.1011, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6304\n",
      "Loss: tensor(0.1011, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6305\n",
      "Loss: tensor(0.1011, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6306\n",
      "Loss: tensor(0.1011, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6307\n",
      "Loss: tensor(0.1011, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6308\n",
      "Loss: tensor(0.1011, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6309\n",
      "Loss: tensor(0.1011, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6310\n",
      "Loss: tensor(0.1011, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6311\n",
      "Loss: tensor(0.1011, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6312\n",
      "Loss: tensor(0.1011, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6313\n",
      "Loss: tensor(0.1011, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6314\n",
      "Loss: tensor(0.1011, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6315\n",
      "Loss: tensor(0.1011, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6316\n",
      "Loss: tensor(0.1011, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6317\n",
      "Loss: tensor(0.1011, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6318\n",
      "Loss: tensor(0.1011, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6319\n",
      "Loss: tensor(0.1011, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6320\n",
      "Loss: tensor(0.1011, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6321\n",
      "Loss: tensor(0.1011, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6322\n",
      "Loss: tensor(0.1011, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6323\n",
      "Loss: tensor(0.1011, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6324\n",
      "Loss: tensor(0.1011, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6325\n",
      "Loss: tensor(0.1011, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6326\n",
      "Loss: tensor(0.1011, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6327\n",
      "Loss: tensor(0.1011, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6328\n",
      "Loss: tensor(0.1011, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6329\n",
      "Loss: tensor(0.1011, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6330\n",
      "Loss: tensor(0.1011, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6331\n",
      "Loss: tensor(0.1011, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6332\n",
      "Loss: tensor(0.1011, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6333\n",
      "Loss: tensor(0.1011, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6334\n",
      "Loss: tensor(0.1011, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6335\n",
      "Loss: tensor(0.1011, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6336\n",
      "Loss: tensor(0.1011, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6337\n",
      "Loss: tensor(0.1011, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6338\n",
      "Loss: tensor(0.1011, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6339\n",
      "Loss: tensor(0.1011, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6340\n",
      "Loss: tensor(0.1011, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6341\n",
      "Loss: tensor(0.1011, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6342\n",
      "Loss: tensor(0.1011, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6343\n",
      "Loss: tensor(0.1011, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6344\n",
      "Loss: tensor(0.1011, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6345\n",
      "Loss: tensor(0.1011, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6346\n",
      "Loss: tensor(0.1011, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6347\n",
      "Loss: tensor(0.1011, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6348\n",
      "Loss: tensor(0.1011, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6349\n",
      "Loss: tensor(0.1011, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6350\n",
      "Loss: tensor(0.1011, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6351\n",
      "Loss: tensor(0.1011, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6352\n",
      "Loss: tensor(0.1011, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6353\n",
      "Loss: tensor(0.1011, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6354\n",
      "Loss: tensor(0.1011, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6355\n",
      "Loss: tensor(0.1011, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6356\n",
      "Loss: tensor(0.1011, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6357\n",
      "Loss: tensor(0.1011, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6358\n",
      "Loss: tensor(0.1011, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6359\n",
      "Loss: tensor(0.1011, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6360\n",
      "Loss: tensor(0.1011, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6361\n",
      "Loss: tensor(0.1011, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6362\n",
      "Loss: tensor(0.1011, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6363\n",
      "Loss: tensor(0.1011, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6364\n",
      "Loss: tensor(0.1011, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6365\n",
      "Loss: tensor(0.1011, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6366\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor(0.1011, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6367\n",
      "Loss: tensor(0.1011, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6368\n",
      "Loss: tensor(0.1011, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6369\n",
      "Loss: tensor(0.1011, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6370\n",
      "Loss: tensor(0.1011, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6371\n",
      "Loss: tensor(0.1011, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6372\n",
      "Loss: tensor(0.1011, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6373\n",
      "Loss: tensor(0.1011, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6374\n",
      "Loss: tensor(0.1011, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6375\n",
      "Loss: tensor(0.1011, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6376\n",
      "Loss: tensor(0.1011, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6377\n",
      "Loss: tensor(0.1011, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6378\n",
      "Loss: tensor(0.1011, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6379\n",
      "Loss: tensor(0.1011, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6380\n",
      "Loss: tensor(0.1011, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6381\n",
      "Loss: tensor(0.1011, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6382\n",
      "Loss: tensor(0.1011, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6383\n",
      "Loss: tensor(0.1011, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6384\n",
      "Loss: tensor(0.1011, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6385\n",
      "Loss: tensor(0.1011, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6386\n",
      "Loss: tensor(0.1011, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6387\n",
      "Loss: tensor(0.1011, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6388\n",
      "Loss: tensor(0.1011, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6389\n",
      "Loss: tensor(0.1011, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6390\n",
      "Loss: tensor(0.1011, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6391\n",
      "Loss: tensor(0.1011, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6392\n",
      "Loss: tensor(0.1011, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6393\n",
      "Loss: tensor(0.1011, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6394\n",
      "Loss: tensor(0.1011, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6395\n",
      "Loss: tensor(0.1011, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6396\n",
      "Loss: tensor(0.1011, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6397\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6398\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6399\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6400\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6401\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6402\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6403\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6404\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6405\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6406\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6407\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6408\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6409\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6410\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6411\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6412\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6413\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6414\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6415\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6416\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6417\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6418\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6419\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6420\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6421\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6422\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6423\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6424\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6425\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6426\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6427\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6428\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6429\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6430\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6431\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6432\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6433\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6434\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6435\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6436\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6437\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6438\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6439\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6440\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6441\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6442\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6443\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6444\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6445\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6446\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6447\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6448\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6449\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6450\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6451\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6452\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6453\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6454\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6455\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6456\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6457\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6458\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6459\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6460\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6461\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6462\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6463\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6464\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6465\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6466\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6467\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6468\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6469\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6470\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6471\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6472\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6473\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6474\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6475\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6476\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6477\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6478\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6479\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6480\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6481\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6482\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6483\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6484\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6485\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6486\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6487\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6488\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6489\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6490\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6491\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6492\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6493\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6494\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6495\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6496\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6497\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6498\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6499\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6500\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6501\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6502\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6503\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6504\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6505\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6506\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6507\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6508\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6509\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6510\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6511\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6512\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6513\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6514\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6515\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6516\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6517\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6518\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6519\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6520\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6521\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6522\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6523\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6524\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6525\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6526\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6527\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6528\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6529\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6530\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6531\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6532\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6533\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6534\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6535\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6536\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6537\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6538\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6539\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6540\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6541\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6542\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6543\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6544\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6545\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6546\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6547\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6548\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6549\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6550\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6551\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6552\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6553\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6554\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6555\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6556\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6557\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6558\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6559\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6560\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6561\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6562\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6563\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6564\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6565\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6566\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6567\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6568\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6569\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6570\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6571\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6572\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6573\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6574\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6575\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6576\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6577\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6578\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6579\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6580\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6581\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6582\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6583\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6584\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6585\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6586\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6587\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6588\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6589\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6590\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6591\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6592\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6593\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6594\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6595\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6596\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6597\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6598\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6599\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6600\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6601\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6602\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6603\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6604\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6605\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6606\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6607\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6608\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6609\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6610\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6611\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6612\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6613\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6614\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6615\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6616\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6617\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6618\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6619\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6620\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6621\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6622\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6623\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6624\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6625\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6626\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6627\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6628\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6629\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6630\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6631\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6632\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6633\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6634\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6635\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6636\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6637\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6638\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6639\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6640\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6641\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6642\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6643\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6644\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6645\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6646\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6647\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6648\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6649\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6650\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6651\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6652\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6653\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6654\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6655\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6656\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6657\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6658\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6659\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6660\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6661\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6662\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6663\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6664\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6665\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6666\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6667\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6668\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6669\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6670\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6671\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6672\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6673\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6674\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6675\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6676\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6677\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6678\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6679\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6680\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6681\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6682\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6683\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6684\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6685\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6686\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6687\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6688\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6689\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6690\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6691\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6692\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6693\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6694\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6695\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6696\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6697\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6698\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6699\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6700\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6701\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6702\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6703\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6704\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6705\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6706\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6707\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6708\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6709\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6710\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6711\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6712\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6713\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6714\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6715\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6716\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6717\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6718\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6719\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6720\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6721\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6722\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6723\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6724\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6725\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6726\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6727\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6728\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6729\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6730\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6731\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6732\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6733\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6734\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6735\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6736\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6737\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6738\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6739\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6740\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6741\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6742\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6743\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6744\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6745\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6746\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6747\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6748\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6749\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6750\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6751\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6752\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6753\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6754\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6755\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6756\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6757\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6758\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6759\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6760\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6761\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6762\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6763\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6764\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6765\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6766\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6767\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6768\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6769\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6770\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6771\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6772\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6773\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6774\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6775\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6776\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6777\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6778\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6779\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6780\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6781\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6782\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6783\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6784\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6785\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6786\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6787\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6788\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6789\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6790\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6791\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6792\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6793\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6794\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6795\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6796\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6797\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6798\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6799\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6800\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6801\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6802\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6803\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6804\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6805\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6806\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6807\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6808\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6809\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6810\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6811\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6812\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6813\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6814\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6815\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6816\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6817\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6818\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6819\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6820\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6821\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6822\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6823\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6824\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6825\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6826\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6827\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6828\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6829\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6830\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6831\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6832\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6833\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6834\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6835\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6836\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6837\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6838\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6839\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6840\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6841\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6842\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6843\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6844\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6845\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6846\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6847\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6848\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6849\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6850\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6851\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6852\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6853\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6854\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6855\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6856\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6857\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6858\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6859\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6860\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6861\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6862\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6863\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6864\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6865\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6866\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6867\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6868\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6869\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6870\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6871\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6872\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6873\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6874\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6875\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6876\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6877\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6878\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6879\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6880\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6881\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6882\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6883\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6884\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6885\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6886\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6887\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6888\n",
      "Loss: tensor(0.1007, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6889\n",
      "Loss: tensor(0.1007, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6890\n",
      "Loss: tensor(0.1007, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6891\n",
      "Loss: tensor(0.1007, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6892\n",
      "Loss: tensor(0.1007, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6893\n",
      "Loss: tensor(0.1007, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6894\n",
      "Loss: tensor(0.1007, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6895\n",
      "Loss: tensor(0.1007, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6896\n",
      "Loss: tensor(0.1007, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6897\n",
      "Loss: tensor(0.1007, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6898\n",
      "Loss: tensor(0.1007, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6899\n",
      "Loss: tensor(0.1007, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6900\n",
      "Loss: tensor(0.1007, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6901\n",
      "Loss: tensor(0.1007, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6902\n",
      "Loss: tensor(0.1007, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6903\n",
      "Loss: tensor(0.1007, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6904\n",
      "Loss: tensor(0.1007, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6905\n",
      "Loss: tensor(0.1007, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6906\n",
      "Loss: tensor(0.1007, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6907\n",
      "Loss: tensor(0.1007, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6908\n",
      "Loss: tensor(0.1007, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6909\n",
      "Loss: tensor(0.1007, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6910\n",
      "Loss: tensor(0.1007, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6911\n",
      "Loss: tensor(0.1007, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6912\n",
      "Loss: tensor(0.1007, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6913\n",
      "Loss: tensor(0.1007, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6914\n",
      "Loss: tensor(0.1007, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6915\n",
      "Loss: tensor(0.1007, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6916\n",
      "Loss: tensor(0.1007, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6917\n",
      "Loss: tensor(0.1007, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6918\n",
      "Loss: tensor(0.1007, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6919\n",
      "Loss: tensor(0.1007, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6920\n",
      "Loss: tensor(0.1007, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6921\n",
      "Loss: tensor(0.1007, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6922\n",
      "Loss: tensor(0.1007, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6923\n",
      "Loss: tensor(0.1007, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6924\n",
      "Loss: tensor(0.1007, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6925\n",
      "Loss: tensor(0.1007, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6926\n",
      "Loss: tensor(0.1007, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6927\n",
      "Loss: tensor(0.1007, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6928\n",
      "Loss: tensor(0.1007, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6929\n",
      "Loss: tensor(0.1007, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6930\n",
      "Loss: tensor(0.1007, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6931\n",
      "Loss: tensor(0.1007, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6932\n",
      "Loss: tensor(0.1007, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6933\n",
      "Loss: tensor(0.1007, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6934\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6935\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6936\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6937\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6938\n",
      "Loss: tensor(0.1007, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6939\n",
      "Loss: tensor(0.1007, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6940\n",
      "Loss: tensor(0.1007, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6941\n",
      "Loss: tensor(0.1007, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6942\n",
      "Loss: tensor(0.1007, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6943\n",
      "Loss: tensor(0.1007, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6944\n",
      "Loss: tensor(0.1007, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6945\n",
      "Loss: tensor(0.1007, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6946\n",
      "Loss: tensor(0.1007, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6947\n",
      "Loss: tensor(0.1007, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6948\n",
      "Loss: tensor(0.1007, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6949\n",
      "Loss: tensor(0.1007, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6950\n",
      "Loss: tensor(0.1007, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6951\n",
      "Loss: tensor(0.1007, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6952\n",
      "Loss: tensor(0.1007, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6953\n",
      "Loss: tensor(0.1007, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6954\n",
      "Loss: tensor(0.1007, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6955\n",
      "Loss: tensor(0.1007, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6956\n",
      "Loss: tensor(0.1007, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6957\n",
      "Loss: tensor(0.1007, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6958\n",
      "Loss: tensor(0.1007, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6959\n",
      "Loss: tensor(0.1007, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6960\n",
      "Loss: tensor(0.1007, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6961\n",
      "Loss: tensor(0.1007, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6962\n",
      "Loss: tensor(0.1007, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6963\n",
      "Loss: tensor(0.1007, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6964\n",
      "Loss: tensor(0.1007, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6965\n",
      "Loss: tensor(0.1007, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6966\n",
      "Loss: tensor(0.1007, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6967\n",
      "Loss: tensor(0.1007, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6968\n",
      "Loss: tensor(0.1007, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6969\n",
      "Loss: tensor(0.1007, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6970\n",
      "Loss: tensor(0.1007, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6971\n",
      "Loss: tensor(0.1007, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6972\n",
      "Loss: tensor(0.1007, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6973\n",
      "Loss: tensor(0.1007, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6974\n",
      "Loss: tensor(0.1007, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6975\n",
      "Loss: tensor(0.1007, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6976\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor(0.1007, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6977\n",
      "Loss: tensor(0.1007, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6978\n",
      "Loss: tensor(0.1007, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6979\n",
      "Loss: tensor(0.1007, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6980\n",
      "Loss: tensor(0.1007, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6981\n",
      "Loss: tensor(0.1007, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6982\n",
      "Loss: tensor(0.1007, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6983\n",
      "Loss: tensor(0.1007, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6984\n",
      "Loss: tensor(0.1007, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6985\n",
      "Loss: tensor(0.1007, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6986\n",
      "Loss: tensor(0.1007, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6987\n",
      "Loss: tensor(0.1007, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6988\n",
      "Loss: tensor(0.1007, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6989\n",
      "Loss: tensor(0.1007, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6990\n",
      "Loss: tensor(0.1007, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6991\n",
      "Loss: tensor(0.1007, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6992\n",
      "Loss: tensor(0.1007, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6993\n",
      "Loss: tensor(0.1007, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6994\n",
      "Loss: tensor(0.1007, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6995\n",
      "Loss: tensor(0.1007, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6996\n",
      "Loss: tensor(0.1007, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6997\n",
      "Loss: tensor(0.1007, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6998\n",
      "Loss: tensor(0.1007, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6999\n",
      "Loss: tensor(0.1007, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7000\n",
      "Loss: tensor(0.1007, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7001\n",
      "Loss: tensor(0.1007, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7002\n",
      "Loss: tensor(0.1007, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7003\n",
      "Loss: tensor(0.1007, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7004\n",
      "Loss: tensor(0.1007, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7005\n",
      "Loss: tensor(0.1007, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7006\n",
      "Loss: tensor(0.1007, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7007\n",
      "Loss: tensor(0.1007, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7008\n",
      "Loss: tensor(0.1007, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7009\n",
      "Loss: tensor(0.1007, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7010\n",
      "Loss: tensor(0.1007, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7011\n",
      "Loss: tensor(0.1007, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7012\n",
      "Loss: tensor(0.1007, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7013\n",
      "Loss: tensor(0.1007, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7014\n",
      "Loss: tensor(0.1007, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7015\n",
      "Loss: tensor(0.1007, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7016\n",
      "Loss: tensor(0.1007, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7017\n",
      "Loss: tensor(0.1007, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7018\n",
      "Loss: tensor(0.1007, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7019\n",
      "Loss: tensor(0.1007, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7020\n",
      "Loss: tensor(0.1007, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7021\n",
      "Loss: tensor(0.1007, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7022\n",
      "Loss: tensor(0.1007, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7023\n",
      "Loss: tensor(0.1007, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7024\n",
      "Loss: tensor(0.1007, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7025\n",
      "Loss: tensor(0.1007, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7026\n",
      "Loss: tensor(0.1007, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7027\n",
      "Loss: tensor(0.1007, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7028\n",
      "Loss: tensor(0.1007, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7029\n",
      "Loss: tensor(0.1007, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7030\n",
      "Loss: tensor(0.1007, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7031\n",
      "Loss: tensor(0.1007, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7032\n",
      "Loss: tensor(0.1007, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7033\n",
      "Loss: tensor(0.1007, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7034\n",
      "Loss: tensor(0.1007, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7035\n",
      "Loss: tensor(0.1007, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7036\n",
      "Loss: tensor(0.1007, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7037\n",
      "Loss: tensor(0.1007, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7038\n",
      "Loss: tensor(0.1007, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7039\n",
      "Loss: tensor(0.1007, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7040\n",
      "Loss: tensor(0.1007, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7041\n",
      "Loss: tensor(0.1007, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7042\n",
      "Loss: tensor(0.1007, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7043\n",
      "Loss: tensor(0.1007, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7044\n",
      "Loss: tensor(0.1007, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7045\n",
      "Loss: tensor(0.1007, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7046\n",
      "Loss: tensor(0.1007, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7047\n",
      "Loss: tensor(0.1007, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7048\n",
      "Loss: tensor(0.1007, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7049\n",
      "Loss: tensor(0.1007, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7050\n",
      "Loss: tensor(0.1007, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7051\n",
      "Loss: tensor(0.1007, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7052\n",
      "Loss: tensor(0.1007, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7053\n",
      "Loss: tensor(0.1007, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7054\n",
      "Loss: tensor(0.1007, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7055\n",
      "Loss: tensor(0.1007, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7056\n",
      "Loss: tensor(0.1007, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7057\n",
      "Loss: tensor(0.1007, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7058\n",
      "Loss: tensor(0.1007, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7059\n",
      "Loss: tensor(0.1007, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7060\n",
      "Loss: tensor(0.1007, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7061\n",
      "Loss: tensor(0.1007, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7062\n",
      "Loss: tensor(0.1007, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7063\n",
      "Loss: tensor(0.1007, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7064\n",
      "Loss: tensor(0.1007, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7065\n",
      "Loss: tensor(0.1007, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7066\n",
      "Loss: tensor(0.1007, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7067\n",
      "Loss: tensor(0.1007, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7068\n",
      "Loss: tensor(0.1007, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7069\n",
      "Loss: tensor(0.1007, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7070\n",
      "Loss: tensor(0.1007, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7071\n",
      "Loss: tensor(0.1007, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7072\n",
      "Loss: tensor(0.1007, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7073\n",
      "Loss: tensor(0.1007, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7074\n",
      "Loss: tensor(0.1007, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7075\n",
      "Loss: tensor(0.1007, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7076\n",
      "Loss: tensor(0.1007, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7077\n",
      "Loss: tensor(0.1007, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7078\n",
      "Loss: tensor(0.1007, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7079\n",
      "Loss: tensor(0.1007, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7080\n",
      "Loss: tensor(0.1007, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7081\n",
      "Loss: tensor(0.1007, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7082\n",
      "Loss: tensor(0.1007, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7083\n",
      "Loss: tensor(0.1007, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7084\n",
      "Loss: tensor(0.1007, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7085\n",
      "Loss: tensor(0.1007, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7086\n",
      "Loss: tensor(0.1007, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7087\n",
      "Loss: tensor(0.1007, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7088\n",
      "Loss: tensor(0.1007, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7089\n",
      "Loss: tensor(0.1007, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7090\n",
      "Loss: tensor(0.1007, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7091\n",
      "Loss: tensor(0.1007, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7092\n",
      "Loss: tensor(0.1007, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7093\n",
      "Loss: tensor(0.1007, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7094\n",
      "Loss: tensor(0.1006, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7095\n",
      "Loss: tensor(0.1006, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7096\n",
      "Loss: tensor(0.1006, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7097\n",
      "Loss: tensor(0.1006, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7098\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor(0.1006, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7099\n",
      "Loss: tensor(0.1006, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7100\n",
      "Loss: tensor(0.1006, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7101\n",
      "Loss: tensor(0.1006, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7102\n",
      "Loss: tensor(0.1006, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7103\n",
      "Loss: tensor(0.1006, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7104\n",
      "Loss: tensor(0.1006, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7105\n",
      "Loss: tensor(0.1006, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7106\n",
      "Loss: tensor(0.1006, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7107\n",
      "Loss: tensor(0.1006, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7108\n",
      "Loss: tensor(0.1006, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7109\n",
      "Loss: tensor(0.1006, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7110\n",
      "Loss: tensor(0.1006, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7111\n",
      "Loss: tensor(0.1006, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7112\n",
      "Loss: tensor(0.1006, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7113\n",
      "Loss: tensor(0.1006, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7114\n",
      "Loss: tensor(0.1006, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7115\n",
      "Loss: tensor(0.1006, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7116\n",
      "Loss: tensor(0.1006, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7117\n",
      "Loss: tensor(0.1006, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7118\n",
      "Loss: tensor(0.1006, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7119\n",
      "Loss: tensor(0.1006, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7120\n",
      "Loss: tensor(0.1006, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7121\n",
      "Loss: tensor(0.1006, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7122\n",
      "Loss: tensor(0.1006, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7123\n",
      "Loss: tensor(0.1006, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7124\n",
      "Loss: tensor(0.1006, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7125\n",
      "Loss: tensor(0.1006, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7126\n",
      "Loss: tensor(0.1006, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7127\n",
      "Loss: tensor(0.1006, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7128\n",
      "Loss: tensor(0.1007, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7129\n",
      "Loss: tensor(0.1007, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7130\n",
      "Loss: tensor(0.1007, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7131\n",
      "Loss: tensor(0.1007, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7132\n",
      "Loss: tensor(0.1007, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7133\n",
      "Loss: tensor(0.1006, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7134\n",
      "Loss: tensor(0.1006, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7135\n",
      "Loss: tensor(0.1006, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7136\n",
      "Loss: tensor(0.1006, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7137\n",
      "Loss: tensor(0.1006, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7138\n",
      "Loss: tensor(0.1006, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7139\n",
      "Loss: tensor(0.1006, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7140\n",
      "Loss: tensor(0.1006, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7141\n",
      "Loss: tensor(0.1006, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7142\n",
      "Loss: tensor(0.1006, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7143\n",
      "Loss: tensor(0.1006, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7144\n",
      "Loss: tensor(0.1006, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7145\n",
      "Loss: tensor(0.1006, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7146\n",
      "Loss: tensor(0.1006, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7147\n",
      "Loss: tensor(0.1006, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7148\n",
      "Loss: tensor(0.1006, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7149\n",
      "Loss: tensor(0.1006, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7150\n",
      "Loss: tensor(0.1006, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7151\n",
      "Loss: tensor(0.1006, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7152\n",
      "Loss: tensor(0.1006, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7153\n",
      "Loss: tensor(0.1006, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7154\n",
      "Loss: tensor(0.1006, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7155\n",
      "Loss: tensor(0.1006, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7156\n",
      "Loss: tensor(0.1006, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7157\n",
      "Loss: tensor(0.1006, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7158\n",
      "Loss: tensor(0.1006, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7159\n",
      "Loss: tensor(0.1006, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7160\n",
      "Loss: tensor(0.1006, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7161\n",
      "Loss: tensor(0.1006, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7162\n",
      "Loss: tensor(0.1006, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7163\n",
      "Loss: tensor(0.1006, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7164\n",
      "Loss: tensor(0.1006, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7165\n",
      "Loss: tensor(0.1006, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7166\n",
      "Loss: tensor(0.1006, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7167\n",
      "Loss: tensor(0.1006, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7168\n",
      "Loss: tensor(0.1006, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7169\n",
      "Loss: tensor(0.1006, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7170\n",
      "Loss: tensor(0.1006, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7171\n",
      "Loss: tensor(0.1006, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7172\n",
      "Loss: tensor(0.1006, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7173\n",
      "Loss: tensor(0.1006, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7174\n",
      "Loss: tensor(0.1006, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7175\n",
      "Loss: tensor(0.1006, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7176\n",
      "Loss: tensor(0.1006, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7177\n",
      "Loss: tensor(0.1006, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7178\n",
      "Loss: tensor(0.1006, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7179\n",
      "Loss: tensor(0.1006, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7180\n",
      "Loss: tensor(0.1006, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7181\n",
      "Loss: tensor(0.1006, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7182\n",
      "Loss: tensor(0.1006, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7183\n",
      "Loss: tensor(0.1006, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7184\n",
      "Loss: tensor(0.1006, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7185\n",
      "Loss: tensor(0.1006, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7186\n",
      "Loss: tensor(0.1006, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7187\n",
      "Loss: tensor(0.1006, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7188\n",
      "Loss: tensor(0.1006, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7189\n",
      "Loss: tensor(0.1006, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7190\n",
      "Loss: tensor(0.1006, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7191\n",
      "Loss: tensor(0.1006, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7192\n",
      "Loss: tensor(0.1006, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7193\n",
      "Loss: tensor(0.1006, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7194\n",
      "Loss: tensor(0.1006, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7195\n",
      "Loss: tensor(0.1006, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7196\n",
      "Loss: tensor(0.1006, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7197\n",
      "Loss: tensor(0.1006, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7198\n",
      "Loss: tensor(0.1006, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7199\n",
      "Loss: tensor(0.1006, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7200\n",
      "Loss: tensor(0.1006, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7201\n",
      "Loss: tensor(0.1006, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7202\n",
      "Loss: tensor(0.1006, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7203\n",
      "Loss: tensor(0.1006, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7204\n",
      "Loss: tensor(0.1006, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7205\n",
      "Loss: tensor(0.1006, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7206\n",
      "Loss: tensor(0.1006, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7207\n",
      "Loss: tensor(0.1006, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7208\n",
      "Loss: tensor(0.1006, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7209\n",
      "Loss: tensor(0.1006, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7210\n",
      "Loss: tensor(0.1006, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7211\n",
      "Loss: tensor(0.1006, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7212\n",
      "Loss: tensor(0.1006, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7213\n",
      "Loss: tensor(0.1006, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7214\n",
      "Loss: tensor(0.1006, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7215\n",
      "Loss: tensor(0.1006, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7216\n",
      "Loss: tensor(0.1006, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7217\n",
      "Loss: tensor(0.1006, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7218\n",
      "Loss: tensor(0.1006, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7219\n",
      "Loss: tensor(0.1006, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7220\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor(0.1006, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7221\n",
      "Loss: tensor(0.1006, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7222\n",
      "Loss: tensor(0.1006, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7223\n",
      "Loss: tensor(0.1006, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7224\n",
      "Loss: tensor(0.1006, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7225\n",
      "Loss: tensor(0.1006, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7226\n",
      "Loss: tensor(0.1006, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7227\n",
      "Loss: tensor(0.1006, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7228\n",
      "Loss: tensor(0.1006, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7229\n",
      "Loss: tensor(0.1006, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7230\n",
      "Loss: tensor(0.1006, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7231\n",
      "Loss: tensor(0.1006, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7232\n",
      "Loss: tensor(0.1006, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7233\n",
      "Loss: tensor(0.1006, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7234\n",
      "Loss: tensor(0.1006, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7235\n",
      "Loss: tensor(0.1006, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7236\n",
      "Loss: tensor(0.1006, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7237\n",
      "Loss: tensor(0.1006, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7238\n",
      "Loss: tensor(0.1006, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7239\n",
      "Loss: tensor(0.1006, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7240\n",
      "Loss: tensor(0.1006, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7241\n",
      "Loss: tensor(0.1006, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7242\n",
      "Loss: tensor(0.1006, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7243\n",
      "Loss: tensor(0.1006, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7244\n",
      "Loss: tensor(0.1006, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7245\n",
      "Loss: tensor(0.1006, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7246\n",
      "Loss: tensor(0.1006, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7247\n",
      "Loss: tensor(0.1006, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7248\n",
      "Loss: tensor(0.1006, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7249\n",
      "Loss: tensor(0.1006, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7250\n",
      "Loss: tensor(0.1006, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7251\n",
      "Loss: tensor(0.1006, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7252\n",
      "Loss: tensor(0.1006, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7253\n",
      "Loss: tensor(0.1006, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7254\n",
      "Loss: tensor(0.1006, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7255\n",
      "Loss: tensor(0.1006, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7256\n",
      "Loss: tensor(0.1006, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7257\n",
      "Loss: tensor(0.1006, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7258\n",
      "Loss: tensor(0.1006, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7259\n",
      "Loss: tensor(0.1006, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7260\n",
      "Loss: tensor(0.1006, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7261\n",
      "Loss: tensor(0.1006, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7262\n",
      "Loss: tensor(0.1006, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7263\n",
      "Loss: tensor(0.1006, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7264\n",
      "Loss: tensor(0.1006, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7265\n",
      "Loss: tensor(0.1006, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7266\n",
      "Loss: tensor(0.1006, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7267\n",
      "Loss: tensor(0.1006, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7268\n",
      "Loss: tensor(0.1006, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7269\n",
      "Loss: tensor(0.1006, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7270\n",
      "Loss: tensor(0.1006, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7271\n",
      "Loss: tensor(0.1006, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7272\n",
      "Loss: tensor(0.1006, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7273\n",
      "Loss: tensor(0.1006, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7274\n",
      "Loss: tensor(0.1006, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7275\n",
      "Loss: tensor(0.1006, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7276\n",
      "Loss: tensor(0.1006, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7277\n",
      "Loss: tensor(0.1006, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7278\n",
      "Loss: tensor(0.1006, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7279\n",
      "Loss: tensor(0.1006, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7280\n",
      "Loss: tensor(0.1006, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7281\n",
      "Loss: tensor(0.1006, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7282\n",
      "Loss: tensor(0.1006, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7283\n",
      "Loss: tensor(0.1006, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7284\n",
      "Loss: tensor(0.1006, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7285\n",
      "Loss: tensor(0.1006, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7286\n",
      "Loss: tensor(0.1006, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7287\n",
      "Loss: tensor(0.1006, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7288\n",
      "Loss: tensor(0.1006, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7289\n",
      "Loss: tensor(0.1006, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7290\n",
      "Loss: tensor(0.1006, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7291\n",
      "Loss: tensor(0.1006, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7292\n",
      "Loss: tensor(0.1006, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7293\n",
      "Loss: tensor(0.1006, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7294\n",
      "Loss: tensor(0.1006, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7295\n",
      "Loss: tensor(0.1006, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7296\n",
      "Loss: tensor(0.1006, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7297\n",
      "Loss: tensor(0.1006, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7298\n",
      "Loss: tensor(0.1006, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7299\n",
      "Loss: tensor(0.1006, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7300\n",
      "Loss: tensor(0.1006, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7301\n",
      "Loss: tensor(0.1006, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7302\n",
      "Loss: tensor(0.1006, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7303\n",
      "Loss: tensor(0.1006, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7304\n",
      "Loss: tensor(0.1006, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7305\n",
      "Loss: tensor(0.1006, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7306\n",
      "Loss: tensor(0.1006, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7307\n",
      "Loss: tensor(0.1006, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7308\n",
      "Loss: tensor(0.1006, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7309\n",
      "Loss: tensor(0.1006, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7310\n",
      "Loss: tensor(0.1006, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7311\n",
      "Loss: tensor(0.1006, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7312\n",
      "Loss: tensor(0.1006, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7313\n",
      "Loss: tensor(0.1006, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7314\n",
      "Loss: tensor(0.1006, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7315\n",
      "Loss: tensor(0.1006, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7316\n",
      "Loss: tensor(0.1006, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7317\n",
      "Loss: tensor(0.1006, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7318\n",
      "Loss: tensor(0.1006, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7319\n",
      "Loss: tensor(0.1006, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7320\n",
      "Loss: tensor(0.1006, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7321\n",
      "Loss: tensor(0.1006, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7322\n",
      "Loss: tensor(0.1006, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7323\n",
      "Loss: tensor(0.1006, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7324\n",
      "Loss: tensor(0.1006, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7325\n",
      "Loss: tensor(0.1006, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7326\n",
      "Loss: tensor(0.1006, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7327\n",
      "Loss: tensor(0.1006, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7328\n",
      "Loss: tensor(0.1006, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7329\n",
      "Loss: tensor(0.1006, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7330\n",
      "Loss: tensor(0.1006, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7331\n",
      "Loss: tensor(0.1006, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7332\n",
      "Loss: tensor(0.1006, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7333\n",
      "Loss: tensor(0.1006, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7334\n",
      "Loss: tensor(0.1005, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7335\n",
      "Loss: tensor(0.1005, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7336\n",
      "Loss: tensor(0.1005, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7337\n",
      "Loss: tensor(0.1006, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7338\n",
      "Loss: tensor(0.1006, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7339\n",
      "Loss: tensor(0.1006, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7340\n",
      "Loss: tensor(0.1005, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7341\n",
      "Loss: tensor(0.1005, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7342\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor(0.1005, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7343\n",
      "Loss: tensor(0.1005, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7344\n",
      "Loss: tensor(0.1005, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7345\n",
      "Loss: tensor(0.1005, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7346\n",
      "Loss: tensor(0.1005, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7347\n",
      "Loss: tensor(0.1005, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7348\n",
      "Loss: tensor(0.1005, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7349\n",
      "Loss: tensor(0.1005, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7350\n",
      "Loss: tensor(0.1005, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7351\n",
      "Loss: tensor(0.1005, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7352\n",
      "Loss: tensor(0.1005, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7353\n",
      "Loss: tensor(0.1005, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7354\n",
      "Loss: tensor(0.1005, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7355\n",
      "Loss: tensor(0.1005, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7356\n",
      "Loss: tensor(0.1005, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7357\n",
      "Loss: tensor(0.1005, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7358\n",
      "Loss: tensor(0.1005, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7359\n",
      "Loss: tensor(0.1005, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7360\n",
      "Loss: tensor(0.1005, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7361\n",
      "Loss: tensor(0.1005, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7362\n",
      "Loss: tensor(0.1005, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7363\n",
      "Loss: tensor(0.1005, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7364\n",
      "Loss: tensor(0.1005, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7365\n",
      "Loss: tensor(0.1005, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7366\n",
      "Loss: tensor(0.1005, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7367\n",
      "Loss: tensor(0.1005, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7368\n",
      "Loss: tensor(0.1005, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7369\n",
      "Loss: tensor(0.1005, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7370\n",
      "Loss: tensor(0.1005, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7371\n",
      "Loss: tensor(0.1005, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7372\n",
      "Loss: tensor(0.1005, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7373\n",
      "Loss: tensor(0.1005, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7374\n",
      "Loss: tensor(0.1005, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7375\n",
      "Loss: tensor(0.1005, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7376\n",
      "Loss: tensor(0.1005, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7377\n",
      "Loss: tensor(0.1005, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7378\n",
      "Loss: tensor(0.1005, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7379\n",
      "Loss: tensor(0.1005, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7380\n",
      "Loss: tensor(0.1005, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7381\n",
      "Loss: tensor(0.1005, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7382\n",
      "Loss: tensor(0.1005, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7383\n",
      "Loss: tensor(0.1005, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7384\n",
      "Loss: tensor(0.1005, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7385\n",
      "Loss: tensor(0.1005, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7386\n",
      "Loss: tensor(0.1005, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7387\n",
      "Loss: tensor(0.1005, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7388\n",
      "Loss: tensor(0.1005, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7389\n",
      "Loss: tensor(0.1005, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7390\n",
      "Loss: tensor(0.1005, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7391\n",
      "Loss: tensor(0.1005, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7392\n",
      "Loss: tensor(0.1005, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7393\n",
      "Loss: tensor(0.1005, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7394\n",
      "Loss: tensor(0.1005, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7395\n",
      "Loss: tensor(0.1005, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7396\n",
      "Loss: tensor(0.1005, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7397\n",
      "Loss: tensor(0.1005, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7398\n",
      "Loss: tensor(0.1005, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7399\n",
      "Loss: tensor(0.1005, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7400\n",
      "Loss: tensor(0.1005, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7401\n",
      "Loss: tensor(0.1005, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7402\n",
      "Loss: tensor(0.1005, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7403\n",
      "Loss: tensor(0.1005, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7404\n",
      "Loss: tensor(0.1005, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7405\n",
      "Loss: tensor(0.1005, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7406\n",
      "Loss: tensor(0.1005, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7407\n",
      "Loss: tensor(0.1005, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7408\n",
      "Loss: tensor(0.1005, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7409\n",
      "Loss: tensor(0.1005, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7410\n",
      "Loss: tensor(0.1005, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7411\n",
      "Loss: tensor(0.1005, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7412\n",
      "Loss: tensor(0.1005, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7413\n",
      "Loss: tensor(0.1005, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7414\n",
      "Loss: tensor(0.1005, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7415\n",
      "Loss: tensor(0.1005, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7416\n",
      "Loss: tensor(0.1005, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7417\n",
      "Loss: tensor(0.1005, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7418\n",
      "Loss: tensor(0.1005, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7419\n",
      "Loss: tensor(0.1005, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7420\n",
      "Loss: tensor(0.1005, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7421\n",
      "Loss: tensor(0.1005, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7422\n",
      "Loss: tensor(0.1005, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7423\n",
      "Loss: tensor(0.1005, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7424\n",
      "Loss: tensor(0.1005, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7425\n",
      "Loss: tensor(0.1005, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7426\n",
      "Loss: tensor(0.1005, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7427\n",
      "Loss: tensor(0.1005, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7428\n",
      "Loss: tensor(0.1005, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7429\n",
      "Loss: tensor(0.1005, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7430\n",
      "Loss: tensor(0.1005, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7431\n",
      "Loss: tensor(0.1005, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7432\n",
      "Loss: tensor(0.1005, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7433\n",
      "Loss: tensor(0.1005, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7434\n",
      "Loss: tensor(0.1005, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7435\n",
      "Loss: tensor(0.1005, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7436\n",
      "Loss: tensor(0.1005, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7437\n",
      "Loss: tensor(0.1005, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7438\n",
      "Loss: tensor(0.1005, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7439\n",
      "Loss: tensor(0.1005, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7440\n",
      "Loss: tensor(0.1005, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7441\n",
      "Loss: tensor(0.1005, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7442\n",
      "Loss: tensor(0.1005, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7443\n",
      "Loss: tensor(0.1005, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7444\n",
      "Loss: tensor(0.1005, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7445\n",
      "Loss: tensor(0.1005, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7446\n",
      "Loss: tensor(0.1005, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7447\n",
      "Loss: tensor(0.1005, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7448\n",
      "Loss: tensor(0.1005, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7449\n",
      "Loss: tensor(0.1005, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7450\n",
      "Loss: tensor(0.1005, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7451\n",
      "Loss: tensor(0.1005, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7452\n",
      "Loss: tensor(0.1005, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7453\n",
      "Loss: tensor(0.1005, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7454\n",
      "Loss: tensor(0.1005, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7455\n",
      "Loss: tensor(0.1005, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7456\n",
      "Loss: tensor(0.1005, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7457\n",
      "Loss: tensor(0.1005, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7458\n",
      "Loss: tensor(0.1005, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7459\n",
      "Loss: tensor(0.1005, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7460\n",
      "Loss: tensor(0.1005, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7461\n",
      "Loss: tensor(0.1005, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7462\n",
      "Loss: tensor(0.1005, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7463\n",
      "Loss: tensor(0.1005, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7464\n",
      "Loss: tensor(0.1005, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7465\n",
      "Loss: tensor(0.1005, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7466\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor(0.1005, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7467\n",
      "Loss: tensor(0.1005, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7468\n",
      "Loss: tensor(0.1005, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7469\n",
      "Loss: tensor(0.1005, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7470\n",
      "Loss: tensor(0.1005, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7471\n",
      "Loss: tensor(0.1005, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7472\n",
      "Loss: tensor(0.1005, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7473\n",
      "Loss: tensor(0.1005, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7474\n",
      "Loss: tensor(0.1005, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7475\n",
      "Loss: tensor(0.1005, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7476\n",
      "Loss: tensor(0.1005, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7477\n",
      "Loss: tensor(0.1005, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7478\n",
      "Loss: tensor(0.1005, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7479\n",
      "Loss: tensor(0.1005, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7480\n",
      "Loss: tensor(0.1005, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7481\n",
      "Loss: tensor(0.1005, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7482\n",
      "Loss: tensor(0.1005, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7483\n",
      "Loss: tensor(0.1005, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7484\n",
      "Loss: tensor(0.1005, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7485\n",
      "Loss: tensor(0.1005, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7486\n",
      "Loss: tensor(0.1005, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7487\n",
      "Loss: tensor(0.1005, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7488\n",
      "Loss: tensor(0.1005, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7489\n",
      "Loss: tensor(0.1005, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7490\n",
      "Loss: tensor(0.1005, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7491\n",
      "Loss: tensor(0.1005, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7492\n",
      "Loss: tensor(0.1005, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7493\n",
      "Loss: tensor(0.1005, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7494\n",
      "Loss: tensor(0.1005, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7495\n",
      "Loss: tensor(0.1005, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7496\n",
      "Loss: tensor(0.1005, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7497\n",
      "Loss: tensor(0.1005, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7498\n",
      "Loss: tensor(0.1005, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7499\n",
      "Loss: tensor(0.1005, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7500\n",
      "Loss: tensor(0.1005, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7501\n",
      "Loss: tensor(0.1005, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7502\n",
      "Loss: tensor(0.1005, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7503\n",
      "Loss: tensor(0.1005, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7504\n",
      "Loss: tensor(0.1005, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7505\n",
      "Loss: tensor(0.1005, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7506\n",
      "Loss: tensor(0.1005, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7507\n",
      "Loss: tensor(0.1005, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7508\n",
      "Loss: tensor(0.1005, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7509\n",
      "Loss: tensor(0.1005, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7510\n",
      "Loss: tensor(0.1005, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7511\n",
      "Loss: tensor(0.1005, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7512\n",
      "Loss: tensor(0.1005, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7513\n",
      "Loss: tensor(0.1005, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7514\n",
      "Loss: tensor(0.1005, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7515\n",
      "Loss: tensor(0.1005, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7516\n",
      "Loss: tensor(0.1005, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7517\n",
      "Loss: tensor(0.1005, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7518\n",
      "Loss: tensor(0.1005, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7519\n",
      "Loss: tensor(0.1005, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7520\n",
      "Loss: tensor(0.1005, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7521\n",
      "Loss: tensor(0.1005, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7522\n",
      "Loss: tensor(0.1005, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7523\n",
      "Loss: tensor(0.1005, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7524\n",
      "Loss: tensor(0.1005, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7525\n",
      "Loss: tensor(0.1005, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7526\n",
      "Loss: tensor(0.1005, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7527\n",
      "Loss: tensor(0.1005, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7528\n",
      "Loss: tensor(0.1005, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7529\n",
      "Loss: tensor(0.1005, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7530\n",
      "Loss: tensor(0.1005, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7531\n",
      "Loss: tensor(0.1005, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7532\n",
      "Loss: tensor(0.1005, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7533\n",
      "Loss: tensor(0.1005, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7534\n",
      "Loss: tensor(0.1005, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7535\n",
      "Loss: tensor(0.1005, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7536\n",
      "Loss: tensor(0.1005, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7537\n",
      "Loss: tensor(0.1005, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7538\n",
      "Loss: tensor(0.1005, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7539\n",
      "Loss: tensor(0.1005, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7540\n",
      "Loss: tensor(0.1005, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7541\n",
      "Loss: tensor(0.1005, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7542\n",
      "Loss: tensor(0.1005, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7543\n",
      "Loss: tensor(0.1005, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7544\n",
      "Loss: tensor(0.1005, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7545\n",
      "Loss: tensor(0.1005, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7546\n",
      "Loss: tensor(0.1005, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7547\n",
      "Loss: tensor(0.1005, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7548\n",
      "Loss: tensor(0.1005, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7549\n",
      "Loss: tensor(0.1005, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7550\n",
      "Loss: tensor(0.1005, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7551\n",
      "Loss: tensor(0.1005, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7552\n",
      "Loss: tensor(0.1005, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7553\n",
      "Loss: tensor(0.1005, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7554\n",
      "Loss: tensor(0.1005, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7555\n",
      "Loss: tensor(0.1005, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7556\n",
      "Loss: tensor(0.1005, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7557\n",
      "Loss: tensor(0.1005, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7558\n",
      "Loss: tensor(0.1005, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7559\n",
      "Loss: tensor(0.1005, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7560\n",
      "Loss: tensor(0.1005, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7561\n",
      "Loss: tensor(0.1005, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7562\n",
      "Loss: tensor(0.1005, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7563\n",
      "Loss: tensor(0.1005, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7564\n",
      "Loss: tensor(0.1005, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7565\n",
      "Loss: tensor(0.1005, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7566\n",
      "Loss: tensor(0.1005, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7567\n",
      "Loss: tensor(0.1005, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7568\n",
      "Loss: tensor(0.1005, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7569\n",
      "Loss: tensor(0.1005, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7570\n",
      "Loss: tensor(0.1005, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7571\n",
      "Loss: tensor(0.1005, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7572\n",
      "Loss: tensor(0.1005, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7573\n",
      "Loss: tensor(0.1005, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7574\n",
      "Loss: tensor(0.1005, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7575\n",
      "Loss: tensor(0.1005, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7576\n",
      "Loss: tensor(0.1005, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7577\n",
      "Loss: tensor(0.1005, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7578\n",
      "Loss: tensor(0.1005, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7579\n",
      "Loss: tensor(0.1005, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7580\n",
      "Loss: tensor(0.1005, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7581\n",
      "Loss: tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7582\n",
      "Loss: tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7583\n",
      "Loss: tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7584\n",
      "Loss: tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7585\n",
      "Loss: tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7586\n",
      "Loss: tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7587\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7588\n",
      "Loss: tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7589\n",
      "Loss: tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7590\n",
      "Loss: tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7591\n",
      "Loss: tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7592\n",
      "Loss: tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7593\n",
      "Loss: tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7594\n",
      "Loss: tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7595\n",
      "Loss: tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7596\n",
      "Loss: tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7597\n",
      "Loss: tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7598\n",
      "Loss: tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7599\n",
      "Loss: tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7600\n",
      "Loss: tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7601\n",
      "Loss: tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7602\n",
      "Loss: tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7603\n",
      "Loss: tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7604\n",
      "Loss: tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7605\n",
      "Loss: tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7606\n",
      "Loss: tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7607\n",
      "Loss: tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7608\n",
      "Loss: tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7609\n",
      "Loss: tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7610\n",
      "Loss: tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7611\n",
      "Loss: tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7612\n",
      "Loss: tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7613\n",
      "Loss: tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7614\n",
      "Loss: tensor(0.1005, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7615\n",
      "Loss: tensor(0.1005, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7616\n",
      "Loss: tensor(0.1005, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7617\n",
      "Loss: tensor(0.1005, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7618\n",
      "Loss: tensor(0.1005, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7619\n",
      "Loss: tensor(0.1005, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7620\n",
      "Loss: tensor(0.1005, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7621\n",
      "Loss: tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7622\n",
      "Loss: tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7623\n",
      "Loss: tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7624\n",
      "Loss: tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7625\n",
      "Loss: tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7626\n",
      "Loss: tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7627\n",
      "Loss: tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7628\n",
      "Loss: tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7629\n",
      "Loss: tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7630\n",
      "Loss: tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7631\n",
      "Loss: tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7632\n",
      "Loss: tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7633\n",
      "Loss: tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7634\n",
      "Loss: tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7635\n",
      "Loss: tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7636\n",
      "Loss: tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7637\n",
      "Loss: tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7638\n",
      "Loss: tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7639\n",
      "Loss: tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7640\n",
      "Loss: tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7641\n",
      "Loss: tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7642\n",
      "Loss: tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7643\n",
      "Loss: tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7644\n",
      "Loss: tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7645\n",
      "Loss: tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7646\n",
      "Loss: tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7647\n",
      "Loss: tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7648\n",
      "Loss: tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7649\n",
      "Loss: tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7650\n",
      "Loss: tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7651\n",
      "Loss: tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7652\n",
      "Loss: tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7653\n",
      "Loss: tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7654\n",
      "Loss: tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7655\n",
      "Loss: tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7656\n",
      "Loss: tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7657\n",
      "Loss: tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7658\n",
      "Loss: tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7659\n",
      "Loss: tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7660\n",
      "Loss: tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7661\n",
      "Loss: tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7662\n",
      "Loss: tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7663\n",
      "Loss: tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7664\n",
      "Loss: tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7665\n",
      "Loss: tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7666\n",
      "Loss: tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7667\n",
      "Loss: tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7668\n",
      "Loss: tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7669\n",
      "Loss: tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7670\n",
      "Loss: tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7671\n",
      "Loss: tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7672\n",
      "Loss: tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7673\n",
      "Loss: tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7674\n",
      "Loss: tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7675\n",
      "Loss: tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7676\n",
      "Loss: tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7677\n",
      "Loss: tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7678\n",
      "Loss: tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7679\n",
      "Loss: tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7680\n",
      "Loss: tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7681\n",
      "Loss: tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7682\n",
      "Loss: tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7683\n",
      "Loss: tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7684\n",
      "Loss: tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7685\n",
      "Loss: tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7686\n",
      "Loss: tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7687\n",
      "Loss: tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7688\n",
      "Loss: tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7689\n",
      "Loss: tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7690\n",
      "Loss: tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7691\n",
      "Loss: tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7692\n",
      "Loss: tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7693\n",
      "Loss: tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7694\n",
      "Loss: tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7695\n",
      "Loss: tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7696\n",
      "Loss: tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7697\n",
      "Loss: tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7698\n",
      "Loss: tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7699\n",
      "Loss: tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7700\n",
      "Loss: tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7701\n",
      "Loss: tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7702\n",
      "Loss: tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7703\n",
      "Loss: tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7704\n",
      "Loss: tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7705\n",
      "Loss: tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7706\n",
      "Loss: tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7707\n",
      "Loss: tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7708\n",
      "Loss: tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7709\n",
      "Loss: tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7710\n",
      "Loss: tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7711\n",
      "Loss: tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7712\n",
      "Loss: tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7713\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7714\n",
      "Loss: tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7715\n",
      "Loss: tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7716\n",
      "Loss: tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7717\n",
      "Loss: tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7718\n",
      "Loss: tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7719\n",
      "Loss: tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7720\n",
      "Loss: tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7721\n",
      "Loss: tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7722\n",
      "Loss: tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7723\n",
      "Loss: tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7724\n",
      "Loss: tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7725\n",
      "Loss: tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7726\n",
      "Loss: tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7727\n",
      "Loss: tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7728\n",
      "Loss: tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7729\n",
      "Loss: tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7730\n",
      "Loss: tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7731\n",
      "Loss: tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7732\n",
      "Loss: tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7733\n",
      "Loss: tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7734\n",
      "Loss: tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7735\n",
      "Loss: tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7736\n",
      "Loss: tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7737\n",
      "Loss: tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7738\n",
      "Loss: tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7739\n",
      "Loss: tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7740\n",
      "Loss: tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7741\n",
      "Loss: tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7742\n",
      "Loss: tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7743\n",
      "Loss: tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7744\n",
      "Loss: tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7745\n",
      "Loss: tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7746\n",
      "Loss: tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7747\n",
      "Loss: tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7748\n",
      "Loss: tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7749\n",
      "Loss: tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7750\n",
      "Loss: tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7751\n",
      "Loss: tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7752\n",
      "Loss: tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7753\n",
      "Loss: tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7754\n",
      "Loss: tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7755\n",
      "Loss: tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7756\n",
      "Loss: tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7757\n",
      "Loss: tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7758\n",
      "Loss: tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7759\n",
      "Loss: tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7760\n",
      "Loss: tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7761\n",
      "Loss: tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7762\n",
      "Loss: tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7763\n",
      "Loss: tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7764\n",
      "Loss: tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7765\n",
      "Loss: tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7766\n",
      "Loss: tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7767\n",
      "Loss: tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7768\n",
      "Loss: tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7769\n",
      "Loss: tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7770\n",
      "Loss: tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7771\n",
      "Loss: tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7772\n",
      "Loss: tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7773\n",
      "Loss: tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7774\n",
      "Loss: tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7775\n",
      "Loss: tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7776\n",
      "Loss: tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7777\n",
      "Loss: tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7778\n",
      "Loss: tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7779\n",
      "Loss: tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7780\n",
      "Loss: tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7781\n",
      "Loss: tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7782\n",
      "Loss: tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7783\n",
      "Loss: tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7784\n",
      "Loss: tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7785\n",
      "Loss: tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7786\n",
      "Loss: tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7787\n",
      "Loss: tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7788\n",
      "Loss: tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7789\n",
      "Loss: tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7790\n",
      "Loss: tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7791\n",
      "Loss: tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7792\n",
      "Loss: tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7793\n",
      "Loss: tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7794\n",
      "Loss: tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7795\n",
      "Loss: tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7796\n",
      "Loss: tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7797\n",
      "Loss: tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7798\n",
      "Loss: tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7799\n",
      "Loss: tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7800\n",
      "Loss: tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7801\n",
      "Loss: tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7802\n",
      "Loss: tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7803\n",
      "Loss: tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7804\n",
      "Loss: tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7805\n",
      "Loss: tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7806\n",
      "Loss: tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7807\n",
      "Loss: tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7808\n",
      "Loss: tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7809\n",
      "Loss: tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7810\n",
      "Loss: tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7811\n",
      "Loss: tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7812\n",
      "Loss: tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7813\n",
      "Loss: tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7814\n",
      "Loss: tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7815\n",
      "Loss: tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7816\n",
      "Loss: tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7817\n",
      "Loss: tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7818\n",
      "Loss: tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7819\n",
      "Loss: tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7820\n",
      "Loss: tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7821\n",
      "Loss: tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7822\n",
      "Loss: tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7823\n",
      "Loss: tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7824\n",
      "Loss: tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7825\n",
      "Loss: tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7826\n",
      "Loss: tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7827\n",
      "Loss: tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7828\n",
      "Loss: tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7829\n",
      "Loss: tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7830\n",
      "Loss: tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7831\n",
      "Loss: tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7832\n",
      "Loss: tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7833\n",
      "Loss: tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7834\n",
      "Loss: tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7835\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7836\n",
      "Loss: tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7837\n",
      "Loss: tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7838\n",
      "Loss: tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7839\n",
      "Loss: tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7840\n",
      "Loss: tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7841\n",
      "Loss: tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7842\n",
      "Loss: tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7843\n",
      "Loss: tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7844\n",
      "Loss: tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7845\n",
      "Loss: tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7846\n",
      "Loss: tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7847\n",
      "Loss: tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7848\n",
      "Loss: tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7849\n",
      "Loss: tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7850\n",
      "Loss: tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7851\n",
      "Loss: tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7852\n",
      "Loss: tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7853\n",
      "Loss: tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7854\n",
      "Loss: tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7855\n",
      "Loss: tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7856\n",
      "Loss: tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7857\n",
      "Loss: tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7858\n",
      "Loss: tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7859\n",
      "Loss: tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7860\n",
      "Loss: tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7861\n",
      "Loss: tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7862\n",
      "Loss: tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7863\n",
      "Loss: tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7864\n",
      "Loss: tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7865\n",
      "Loss: tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7866\n",
      "Loss: tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7867\n",
      "Loss: tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7868\n",
      "Loss: tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7869\n",
      "Loss: tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7870\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7871\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7872\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7873\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7874\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7875\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7876\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7877\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7878\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7879\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7880\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7881\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7882\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7883\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7884\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7885\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7886\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7887\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7888\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7889\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7890\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7891\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7892\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7893\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7894\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7895\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7896\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7897\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7898\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7899\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7900\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7901\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7902\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7903\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7904\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7905\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7906\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7907\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7908\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7909\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7910\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7911\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7912\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7913\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7914\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7915\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7916\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7917\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7918\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7919\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7920\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7921\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7922\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7923\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7924\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7925\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7926\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7927\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7928\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7929\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7930\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7931\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7932\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7933\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7934\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7935\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7936\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7937\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7938\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7939\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7940\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7941\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7942\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7943\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7944\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7945\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7946\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7947\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7948\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7949\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7950\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7951\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7952\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7953\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7954\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7955\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7956\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7957\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7958\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7959\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7960\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7961\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7962\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7963\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7964\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7965\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7966\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7967\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7968\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7969\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7970\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7971\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7972\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7973\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7974\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7975\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7976\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7977\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7978\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7979\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7980\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7981\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7982\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7983\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7984\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7985\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7986\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7987\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7988\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7989\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7990\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7991\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7992\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7993\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7994\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7995\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7996\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7997\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7998\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7999\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8000\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8001\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8002\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8003\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8004\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8005\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8006\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8007\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8008\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8009\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8010\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8011\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8012\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8013\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8014\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8015\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8016\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8017\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8018\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8019\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8020\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8021\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8022\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8023\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8024\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8025\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8026\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8027\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8028\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8029\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8030\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8031\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8032\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8033\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8034\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8035\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8036\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8037\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8038\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8039\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8040\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8041\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8042\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8043\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8044\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8045\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8046\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8047\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8048\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8049\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8050\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8051\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8052\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8053\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8054\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8055\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8056\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8057\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8058\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8059\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8060\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8061\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8062\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8063\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8064\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8065\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8066\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8067\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8068\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8069\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8070\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8071\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8072\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8073\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8074\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8075\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8076\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8077\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8078\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8079\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8080\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8081\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8082\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8083\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8084\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8085\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8086\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8087\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8088\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8089\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8090\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8091\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8092\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8093\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8094\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8095\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8096\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8097\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8098\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8099\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8100\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8101\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8102\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8103\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8104\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8105\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8106\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8107\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8108\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8109\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8110\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8111\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8112\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8113\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8114\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8115\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8116\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8117\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8118\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8119\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8120\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8121\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8122\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8123\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8124\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8125\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8126\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8127\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8128\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8129\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8130\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8131\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8132\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8133\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8134\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8135\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8136\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8137\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8138\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8139\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8140\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8141\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8142\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8143\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8144\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8145\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8146\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8147\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8148\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8149\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8150\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8151\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8152\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8153\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8154\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8155\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8156\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8157\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8158\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8159\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8160\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8161\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8162\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8163\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8164\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8165\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8166\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8167\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8168\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8169\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8170\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8171\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8172\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8173\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8174\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8175\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8176\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8177\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8178\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8179\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8180\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8181\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8182\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8183\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8184\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8185\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8186\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8187\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8188\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8189\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8190\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8191\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8192\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8193\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8194\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8195\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8196\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8197\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8198\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8199\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8200\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8201\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8202\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8203\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8204\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8205\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8206\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8207\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8208\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8209\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8210\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8211\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8212\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8213\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8214\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8215\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8216\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8217\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8218\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8219\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8220\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8221\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8222\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8223\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8224\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8225\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8226\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8227\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8228\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8229\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8230\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8231\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8232\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8233\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8234\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8235\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8236\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8237\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8238\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8239\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8240\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8241\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8242\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8243\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8244\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8245\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8246\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8247\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8248\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8249\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8250\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8251\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8252\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8253\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8254\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8255\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8256\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8257\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8258\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8259\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8260\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8261\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8262\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8263\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8264\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8265\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8266\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8267\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8268\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8269\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8270\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8271\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8272\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8273\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8274\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8275\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8276\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8277\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8278\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8279\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8280\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8281\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8282\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8283\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8284\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8285\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8286\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8287\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8288\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8289\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8290\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8291\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8292\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8293\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8294\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8295\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8296\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8297\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8298\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8299\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8300\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8301\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8302\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8303\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8304\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8305\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8306\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8307\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8308\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8309\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8310\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8311\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8312\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8313\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8314\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8315\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8316\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8317\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8318\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8319\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8320\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8321\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8322\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8323\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8324\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8325\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8326\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8327\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8328\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8329\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8330\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8331\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8332\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8333\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8334\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8335\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8336\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8337\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8338\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8339\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8340\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8341\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8342\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8343\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8344\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8345\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8346\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8347\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8348\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8349\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8350\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8351\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8352\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8353\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8354\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8355\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8356\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8357\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8358\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8359\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8360\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8361\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8362\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8363\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8364\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8365\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8366\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8367\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8368\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8369\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8370\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8371\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8372\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8373\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8374\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8375\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8376\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8377\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8378\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8379\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8380\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8381\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8382\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8383\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8384\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8385\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8386\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8387\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8388\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8389\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8390\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8391\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8392\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8393\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8394\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8395\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8396\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8397\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8398\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8399\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8400\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8401\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8402\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8403\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8404\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8405\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8406\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8407\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8408\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8409\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8410\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8411\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8412\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8413\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8414\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8415\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8416\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8417\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8418\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8419\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8420\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8421\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8422\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8423\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8424\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8425\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8426\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8427\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8428\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8429\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8430\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8431\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8432\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8433\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8434\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8435\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8436\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8437\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8438\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8439\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8440\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8441\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8442\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8443\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8444\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8445\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8446\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8447\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8448\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8449\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8450\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8451\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8452\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8453\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8454\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8455\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8456\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8457\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8458\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8459\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8460\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8461\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8462\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8463\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8464\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8465\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8466\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8467\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8468\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8469\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8470\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8471\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8472\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8473\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8474\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8475\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8476\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8477\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8478\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8479\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8480\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8481\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8482\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8483\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8484\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8485\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8486\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8487\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8488\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8489\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8490\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8491\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8492\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8493\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8494\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8495\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8496\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8497\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8498\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8499\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(500):  \n",
    "        \n",
    "    optimizer.zero_grad()   # zero the gradient buffers\n",
    "    output = net(input.float())\n",
    "\n",
    "    loss = criterion(output, targets)\n",
    "    print('Loss:', loss, ' at epoch:', epoch)\n",
    "\n",
    "    loss.backward()  #backprop\n",
    "    optimizer.step()    # Does the update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the FCNN model\n",
    "\n",
    "stage='NNetwork6Way/'\n",
    "SavesDirectory='./TunedModels/'+model_class+'/'+model_version+\"/\"+stage\n",
    "PATH = SavesDirectory+' name of saved model here .pth'\n",
    "\n",
    "torch.save(net.state_dict(), PATH)\n",
    "\n",
    "# more on saving pytorch networks: https://pytorch.org/docs/stable/notes/serialization.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load previously saved FCNN model \n",
    "\n",
    "stage='NNetwork6Way/'\n",
    "SavesDirectory='./TunedModels/'+model_class+'/'+model_version+\"/\"+stage\n",
    "PATH = SavesDirectory+'Tanh_MSE_adam4271.pth'\n",
    "\n",
    "net = Net()\n",
    "net.load_state_dict(torch.load(PATH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the test data\n",
    "\n",
    "TestData=pd.read_excel('testReputation.xlsx' )\n",
    "TestData=TestData.iloc[:,:-2].astype(float)\n",
    "TestData=TestData/200\n",
    "\n",
    "SavesDirectory='./TunedModels/'+model_class+'/'+model_version+\"/Saves/\"\n",
    "TF_Output=pd.read_csv( SavesDirectory+'testOut.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0050,  0.0100,  0.0050,  ...,  0.2046,  0.1207, -0.1926],\n",
       "        [ 0.0000,  0.0000,  0.0000,  ...,  0.2705,  0.1422, -0.0064],\n",
       "        [ 0.0200,  0.0250,  0.0600,  ...,  0.1456,  0.0023, -0.0889],\n",
       "        ...,\n",
       "        [ 0.0100,  0.0050,  0.0250,  ...,  0.1503,  0.2321, -0.0020],\n",
       "        [ 0.2200,  0.0950,  0.0350,  ...,  0.1954,  0.2710, -0.0130],\n",
       "        [ 0.0050,  0.0600,  0.0100,  ...,  0.2411,  0.0596,  0.0015]],\n",
       "       dtype=torch.float64)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "TestData=pd.concat([TestData,TF_Output], axis=1)\n",
    "TestData=torch.tensor(TestData.values)\n",
    "TestData\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1278</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1279</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1280</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1281</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1282</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1283 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0  1  2  3  4  5\n",
       "0     0  0  0  0  1  0\n",
       "1     0  0  0  1  0  0\n",
       "2     0  1  0  0  0  0\n",
       "3     0  0  0  0  0  1\n",
       "4     0  0  0  0  0  1\n",
       "...  .. .. .. .. .. ..\n",
       "1278  0  1  0  0  0  0\n",
       "1279  0  0  0  0  1  0\n",
       "1280  0  0  1  0  0  0\n",
       "1281  1  0  0  0  0  0\n",
       "1282  0  1  0  0  0  0\n",
       "\n",
       "[1283 rows x 6 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels=pd.read_excel('testReputation.xlsx' )\n",
    "labels=labels.iloc[:,-1] \n",
    "labelsOneHot=pd.get_dummies(labels)\n",
    "labelsOneHot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0, 0, 0, 1, 0],\n",
       "        [0, 0, 0, 1, 0, 0],\n",
       "        [0, 1, 0, 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 1, 0, 0, 0],\n",
       "        [1, 0, 0, 0, 0, 0],\n",
       "        [0, 1, 0, 0, 0, 0]], dtype=torch.uint8)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TestLables =torch.tensor(labelsOneHot.values)\n",
    "TestLables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 4 2 1 5 1 4 4 5 5 4 3 3 5 3 3 1 3 1 4 4 5 3 5 5 4 5 4 5 5 4 1 0 3 5 5 5 5 4 5 1 4 4 1 4 5 3 5 5 4 5 5 5 3 1 5 5 5 4 3 5 5 4 3 1 5 3 3 5 4 1 5 5 4 1 1 5 5 4 5 5 1 1 4 1 5 4 5 1 5 4 4 3 1 5 5 4 1 3 4 5 0 3 3 3 1 1 3 5 3 1 3 3 3 1 1 0 5 1 2 3 4 4 3 1 4 1 4 5 3 3 2 3 4 5 2 0 4 2 1 4 3 4 3 3 5 5 3 4 3 0 3 1 3 5 3 4 5 1 3 3 1 4 4 1 5 4 3 3 1 1 5 5 5 3 1 3 4 0 2 1 4 4 4 1 3 1 4 4 3 5 5 5 0 1 3 2 2 3 1 1 4 5 3 4 3 3 5 1 3 3 4 4 1 5 1 2 3 3 1 4 4 5 5 1 5 3 2 3 0 5 1 0 1 1 4 4 0 4 2 2 1 2 4 4 4 2 1 3 3 0 4 4 1 3 3 5 0 4 1 3 1 4 2 0 3 1 3 4 2 3 5 1 2 5 2 5 1 2 5 2 1 5 5 5 5 3 1 5 0 4 5 4 4 1 1 3 5 5 3 1 5 5 3 5 3 2 5 3 4 1 3 1 4 0 4 5 3 3 3 4 4 5 1 3 0 5 1 5 5 1 3 3 3 5 1 1 3 3 1 4 2 3 4 3 5 1 5 5 3 3 0 4 1 4 1 1 3 1 2 1 1 1 1 1 0 4 5 3 1 0 1 5 5 5 3 3 5 0 1 3 1 4 4 3 3 3 4 1 5 4 2 5 1 2 5 3 4 3 4 5 3 0 5 5 5 2 3 1 3 4 2 4 1 4 4 1 5 3 2 3 4 4 1 1 3 4 3 4 3 5 1 1 5 4 5 3 5 4 1 5 5 0 1 3 1 3 1 1 3 1 5 1 1 4 3 5 5 1 1 5 1 3 4 5 3 1 3 1 3 5 4 1 0 3 3 3 1 3 3 2 3 3 3 4 1 2 4 3 1 1 3 5 3 4 3 5 4 3 4 3 4 1 3 5 2 5 0 5 4 1 5 1 1 4 5 4 3 1 5 5 3 3 1 1 4 5 3 1 5 1 0 3 1 1 5 3 1 3 5 2 5 5 4 1 3 0 5 3 1 1 3 1 2 3 5 5 2 2 1 3 5 4 1 0 1 3 4 1 4 4 3 5 0 2 3 3 4 3 4 1 5 1 1 2 3 3 3 5 3 5 2 3 2 1 4 1 5 5 3 5 5 2 4 1 3 4 3 4 4 1 5 5 1 5 5 4 5 4 4 2 3 3 1 2 4 5 4 0 0 1 2 3 4 0 4 4 5 2 2 2 3 3 3 3 4 4 1 3 2 3 2 3 2 4 4 1 5 3 5 5 2 4 5 3 4 4 3 4 0 4 5 5 3 3 4 1 4 3 3 5 4 4 4 4 2 3 3 2 4 2 5 3 5 3 4 4 4 0 0 5 2 4 4 4 3 3 5 1 2 4 4 3 4 3 5 4 4 4 4 1 4 4 4 5 4 5 5 3 4 5 2 1 4 4 3 3 5 1 1 3 4 4 5 4 2 4 0 5 0 3 4 4 3 4 5 4 3 1 3 2 5 1 4 1 5 1 1 4 4 2 5 4 4 2 2 1 5 4 4 4 3 5 2 0 5 2 1 2 4 4 1 5 4 5 3 1 2 5 3 4 4 1 1 5 1 0 2 3 5 4 4 5 4 3 1 4 5 0 4 1 5 3 5 3 5 3 4 3 4 4 4 5 5 4 4 4 5 4 2 5 4 3 5 5 3 4 0 3 5 0 3 3 0 4 4 3 3 0 5 4 4 5 1 1 1 3 3 0 0 4 5 0 4 0 1 5 0 1 4 5 1 1 1 4 4 5 4 3 4 4 2 1 5 4 4 3 4 3 2 4 4 1 2 2 1 5 2 4 5 4 0 4 2 4 4 4 0 0 2 3 3 1 3 3 5 3 2 1 2 2 1 5 4 1 3 3 1 1 2 4 4 1 4 4 3 5 3 0 5 3 3 1 4 3 3 2 4 5 5 0 3 3 3 5 5 4 2 3 1 4 1 0 4 0 4 4 4 4 4 5 2 5 5 4 4 5 1 5 3 2 2 1 4 5 4 4 1 5 5 1 4 5 1 1 3 0 3 1 2 3 4 2 3 3 4 1 3 5 4 5 0 5 3 5 1 4 3 4 0 4 4 5 1 5 4 4 1 4 4 4 3 4 1 4 4 4 3 0 1 1 0 4 3 4 5 4 4 0 4 2 0 4 4 1 0 2 1 2 4 3 3 3 4 4 0 1 5 1 4 0 3 3 4 3 5 1 5 2 5 4 5 4 1 0 2 4 1 2 1 4 4 4 2 0 4 2 1 1 4 5 3 0 2 1 2 2 5 2 1 3 5 5 4 1 2 3 2 3 1 4 5 2 2 3 1 1 5 5 4 5 2 1 3 2 4 3 4 0 3 5 3 1 4 2 5 5 5 4 4 2 4 3 2 2 4 1 4 5 4 3 1 4 1 4 1 0 2 4 1 5 4 1 1 3 0 2 5 4 5 1 1 4 4 1 0 4 3 3 3 1 1 4 4 1 2 4 3 1 1 5 5 4 2 0 1 4 4 5 1 2 1 1 5 1 4 4 1 5 5 4 2 3 2 1 0 2 2 5 3 5 1 5 1 5 3 4 3 4 3 2 4 3 4 1 5 4 1 3 4 3 1 1 2 2 4 4 1 3 3 1 5 1 4 0 0 0 2 4 4 3 0 1 Correct: 582 out of: 1283\n",
      "Accuracy of the network :  45.362431800467654\n"
     ]
    }
   ],
   "source": [
    " correct = 0\n",
    "total = 0\n",
    "\n",
    "\n",
    "Y=[]  #target\n",
    "Pred=[]  #predicted\n",
    "\n",
    "with torch.no_grad():\n",
    "    for row in range(len(TestData)):\n",
    "        outputs = net(TestData[row,:].float())\n",
    "        result=0\n",
    "        total+=1\n",
    "        if outputs[0]<outputs[1]:result=1\n",
    "        if outputs[result]<outputs[2]:result=2\n",
    "        if outputs[result]<outputs[3]:result=3\n",
    "        if outputs[result]<outputs[4]:result=4\n",
    "        if outputs[result]<outputs[5]:result=5\n",
    "        \n",
    "        if labelsOneHot.iloc[row,result]==1: correct+=1\n",
    "        \n",
    "        Y.append(result)\n",
    "        Pred.append(labels.iloc[row])\n",
    "        \n",
    "        print(result, end=' ')\n",
    "        \n",
    "       \n",
    "print('Correct:', correct, 'out of:', total )\n",
    "print('Accuracy of the network : ',( 100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 49  13   8   2   3   3]\n",
      " [ 21 120  33  35  17  21]\n",
      " [  4  22  61  15  11   7]\n",
      " [ 11  27  43 116  47  22]\n",
      " [  4  40  37  47 133  55]\n",
      " [  3  28  32  52  38 103]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics \n",
    "print(metrics.confusion_matrix(Y,Pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Pants       0.53      0.63      0.58        78\n",
      "       False       0.48      0.49      0.48       247\n",
      " Barely-True       0.29      0.51      0.37       120\n",
      "   Half-True       0.43      0.44      0.44       266\n",
      " Mostly-True       0.53      0.42      0.47       316\n",
      "        True       0.49      0.40      0.44       256\n",
      "\n",
      "    accuracy                           0.45      1283\n",
      "   macro avg       0.46      0.48      0.46      1283\n",
      "weighted avg       0.47      0.45      0.46      1283\n",
      "\n"
     ]
    }
   ],
   "source": [
    "target_names = ['Pants', 'False', 'Barely-True','Half-True','Mostly-True','True']\n",
    "\n",
    "print(metrics.classification_report(Y, Pred,target_names =target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
