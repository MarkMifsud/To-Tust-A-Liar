{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we first do the classification using the transformer This is our first classification task.\n",
    "\n",
    "The output classification vector from the transformer is saved to be used by the FCNN This is our second classification task.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing necessary libraries\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import sklearn\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from simpletransformers.classification import ClassificationModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the dataset\n",
    "\n",
    "Some pre-processing to the dataset has already been done in preparation for various tests, so this processing is not from scratch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# procedure for getting the data sets and formatting them for the transformer\n",
    " \n",
    "\n",
    "def prepareDataset( filename):\n",
    "     \n",
    "    ReadSet=pd.read_excel(filename )\n",
    "\n",
    "    ReadSet['text']=ReadSet['Statement']\n",
    "    ReadSet['labels']=ReadSet['Label']\n",
    "    \n",
    "    ReadSet=ReadSet.drop(['ID','Label','Statement','Subject','Speaker','Job','From','Affiliation','PantsTotal','NotRealTotal','BarelyTotal','HalfTotal','MostlyTotal','Truths','Context'\n",
    "],axis=1)\n",
    "     \n",
    "    return ReadSet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>It costs more money to put a person on death r...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Charlie Crist \"bizarrely vetoed\" $9.7 million ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>In Massachusetts, half of the primary care doc...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fulton County has successfully reduced the num...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Says he stood up to his own party by voting ag...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10264</th>\n",
       "      <td>Recently Rick Scott closed 30 womens health ca...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10265</th>\n",
       "      <td>Says Charlie Bass supports Paul Ryan plan that...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10266</th>\n",
       "      <td>A report by the US General Accountability Offi...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10267</th>\n",
       "      <td>In the United States, weve had 12 years in a r...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10268</th>\n",
       "      <td>In Virginias Medicaid program, approximately 3...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10269 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  labels\n",
       "0      It costs more money to put a person on death r...       0\n",
       "1      Charlie Crist \"bizarrely vetoed\" $9.7 million ...       3\n",
       "2      In Massachusetts, half of the primary care doc...       4\n",
       "3      Fulton County has successfully reduced the num...       4\n",
       "4      Says he stood up to his own party by voting ag...       5\n",
       "...                                                  ...     ...\n",
       "10264  Recently Rick Scott closed 30 womens health ca...       4\n",
       "10265  Says Charlie Bass supports Paul Ryan plan that...       5\n",
       "10266  A report by the US General Accountability Offi...       3\n",
       "10267  In the United States, weve had 12 years in a r...       1\n",
       "10268  In Virginias Medicaid program, approximately 3...       1\n",
       "\n",
       "[10269 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# preparing the training dataset\n",
    "train=prepareDataset( 'trainRNDtext.xlsx')\n",
    "# and display for inspecting\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The president is brain-dead.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Barack Obama supported keeping troops in Iraq,...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>He's leading by example, refusing contribution...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I'm the first person who really took up the is...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I built that border fence in San Diego...and i...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1279</th>\n",
       "      <td>CNN accidentally aired 30 minutes of pornograp...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1280</th>\n",
       "      <td>President Obamas American Recovery and Reinves...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1281</th>\n",
       "      <td>We (in Illinois) have the fifth-highest tax bu...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1282</th>\n",
       "      <td>Says Donald Trump won more counties than any c...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1283</th>\n",
       "      <td>A recent study found that cities where Uber op...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1284 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  labels\n",
       "0                          The president is brain-dead.       0\n",
       "1     Barack Obama supported keeping troops in Iraq,...       3\n",
       "2     He's leading by example, refusing contribution...       3\n",
       "3     I'm the first person who really took up the is...       4\n",
       "4     I built that border fence in San Diego...and i...       4\n",
       "...                                                 ...     ...\n",
       "1279  CNN accidentally aired 30 minutes of pornograp...       1\n",
       "1280  President Obamas American Recovery and Reinves...       2\n",
       "1281  We (in Illinois) have the fifth-highest tax bu...       4\n",
       "1282  Says Donald Trump won more counties than any c...       4\n",
       "1283  A recent study found that cities where Uber op...       3\n",
       "\n",
       "[1284 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# preparing the evaluation/validation dataset\n",
    "Eval=prepareDataset('valid.xlsx')\n",
    "# and display for inspecting\n",
    "Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>New Mexico was 46th in teacher pay (when he wa...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Barack Obama and Hillary Clinton have changed ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I'll tell you what I can tell this country: If...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tommy Thompson created the first school choice...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fifty-six percent decline in overall crime. A ...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1278</th>\n",
       "      <td>We have trade agreements with 20 countries, an...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1279</th>\n",
       "      <td>On Donald Trumps plan to cut federal funding t...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1280</th>\n",
       "      <td>Black Lives Matter, who are attacking law enfo...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1281</th>\n",
       "      <td>Latina who enthusiastically supported Donald T...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1282</th>\n",
       "      <td>Theres been no conclusive or specific report t...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1283 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  labels\n",
       "0     New Mexico was 46th in teacher pay (when he wa...       4\n",
       "1     Barack Obama and Hillary Clinton have changed ...       3\n",
       "2     I'll tell you what I can tell this country: If...       1\n",
       "3     Tommy Thompson created the first school choice...       5\n",
       "4     Fifty-six percent decline in overall crime. A ...       5\n",
       "...                                                 ...     ...\n",
       "1278  We have trade agreements with 20 countries, an...       1\n",
       "1279  On Donald Trumps plan to cut federal funding t...       4\n",
       "1280  Black Lives Matter, who are attacking law enfo...       2\n",
       "1281  Latina who enthusiastically supported Donald T...       0\n",
       "1282  Theres been no conclusive or specific report t...       1\n",
       "\n",
       "[1283 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# preparing the test set dataset\n",
    "test=prepareDataset('test.xlsx')\n",
    "test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up the transformer for fine tuning\n",
    "\n",
    "This is where changes are done to optimise the model\n",
    "\n",
    "The simpletransformers library is the quickest way to do this at the time of writing. \n",
    "For more information on the settings and their default value go here:\n",
    "https://github.com/ThilinaRajapakse/simpletransformers#default-settings \n",
    "\n",
    "###### Please do read that reference before changing any parameters. Don't try to be a hero!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model variables were set up: \n"
     ]
    }
   ],
   "source": [
    "#Set the model being used here\n",
    "model_class='roberta'  # bert or roberta or albert\n",
    "model_version='roberta-large' #bert-base-cased, roberta-base, roberta-large, albert-base-v2 OR albert-large-v2\n",
    "\n",
    "\n",
    "output_folder='./TunedModels/'+model_class+'/'+model_version+\"/\"\n",
    "cache_directory= \"./TunedModels/\"+model_class+\"/\"+model_version+\"/\"+\"/cache/\"\n",
    "labels_count=6  # the number of classification classes\n",
    "\n",
    "print('model variables were set up: ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G:\\0 finalThesis\\randomised LIAR\n",
      "./TunedModels/roberta/roberta-large/\n",
      "./TunedModels/roberta/roberta-large//cache/\n"
     ]
    }
   ],
   "source": [
    "# use this to test if writing to the directories is working\n",
    "\n",
    "import os\n",
    "print(os.getcwd())\n",
    "print(output_folder)\n",
    "print(cache_directory)\n",
    "\n",
    "testWrite=train.head(30)\n",
    " \n",
    "testWrite.to_csv(output_folder+'DeleteThisToo.tsv', sep='\\t')\n",
    "testWrite.to_csv(cache_directory+'DeleteThisToo.tsv', sep='\\t')\n",
    "\n",
    "del(testWrite)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "save_every_steps=1285\n",
    "# assuming training batch size of 8\n",
    "# any number above 1284 saves the model only at every epoch\n",
    "# Saving the model mid training very often will consume disk space fast\n",
    "\n",
    "train_args={\n",
    "    \"output_dir\":output_folder,\n",
    "    \"cache_dir\":cache_directory,\n",
    "    'reprocess_input_data': True,\n",
    "    'overwrite_output_dir': True,\n",
    "    'num_train_epochs': 2,\n",
    "    \"save_steps\": save_every_steps, \n",
    "    \"learning_rate\": 2e-5,\n",
    "    \"train_batch_size\": 64,\n",
    "    \"eval_batch_size\": 32,\n",
    "    \"adam_epsilon\": 1e-8,\n",
    "    \"evaluate_during_training_steps\": 5,\n",
    "    \"max_seq_length\": 64,\n",
    "    \"n_gpu\": 1,\n",
    "}\n",
    "\n",
    "# Create a ClassificationModel\n",
    "model = ClassificationModel(model_class, model_version, num_labels=labels_count, args=train_args) \n",
    "\n",
    "# You can set class weights by using the optional weight argument"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading a saved model (based on above args{})\n",
    "\n",
    "If you stopped training you can continue training from a previously saved check point.\n",
    "The next cell allows you to load a model from any checkpoint.\n",
    "The number of epochs in the train_args{} will be done and continue tuning from your checkpoint.\n",
    "\n",
    "###### HOWEVER\n",
    "It will overwrite previous checkpoints!\n",
    "Example:  If you load an epoch-3 checkpoint, the epoch-1 checkpoint will be overwritten by the 4th epoch and it will be equivalent to a 4th epoch even if you have epoch-1 in the name.\n",
    "###### SO BE CAREFUL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model, please wait...\n",
      "model in use is : ./TunedModels/roberta/roberta-large/checkpoint-161-epoch-1\n"
     ]
    }
   ],
   "source": [
    "# loading a previously saved model based on this particular Transformer Class and model_name\n",
    "\n",
    "# loading the checkpoint that gave the best result\n",
    "CheckPoint='checkpoint-161-epoch-1'\n",
    "\n",
    "\n",
    "preSavedCheckpoint=output_folder+CheckPoint\n",
    "\n",
    "print('Loading model, please wait...')\n",
    "model = ClassificationModel( model_class, preSavedCheckpoint, num_labels=labels_count, args=train_args) \n",
    "print('model in use is :', preSavedCheckpoint )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the Transformer\n",
    "\n",
    "Skip the next cell if you want to skip the training and go directly to the evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting to features started. Cache is not used.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "145f9da4a68e4acfb21fac648b79a9ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=10269.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.\n",
      "\n",
      "Defaults for this optimization level are:\n",
      "enabled                : True\n",
      "opt_level              : O1\n",
      "cast_model_type        : None\n",
      "patch_torch_functions  : True\n",
      "keep_batchnorm_fp32    : None\n",
      "master_weights         : None\n",
      "loss_scale             : dynamic\n",
      "Processing user overrides (additional kwargs that are not None)...\n",
      "After processing overrides, optimization options are:\n",
      "enabled                : True\n",
      "opt_level              : O1\n",
      "cast_model_type        : None\n",
      "patch_torch_functions  : True\n",
      "keep_batchnorm_fp32    : None\n",
      "master_weights         : None\n",
      "loss_scale             : dynamic\n",
      "Warning:  multi_tensor_applier fused unscale kernel is unavailable, possibly because apex was installed without --cuda_ext --cpp_ext. Using Python fallback.  Original ImportError was: ModuleNotFoundError(\"No module named 'amp_C'\")\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a82b47b8cc9c4a1da11a99a1cb728047",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch', max=1.0, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b6201949d9540968a714df856dff619",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Current iteration', max=161.0, style=ProgressStyle(descri…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "Running loss: 1.908411"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mark\\Anaconda3\\envs\\thesis\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:110: UserWarning: Seems like `optimizer.step()` has been overridden after learning rate scheduler initialization. Please, make sure to call `optimizer.step()` before `lr_scheduler.step()`. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\"Seems like `optimizer.step()` has been overridden after learning rate scheduler \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running loss: 1.746816"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mark\\Anaconda3\\envs\\thesis\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:224: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running loss: 1.724902Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n",
      "Running loss: 1.791989Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 16384.0\n",
      "Running loss: 1.768177\n",
      "\n",
      "Training of roberta model complete. Saved to ./TunedModels/roberta/roberta-large/.\n",
      "Training time:  0:06:20.064507\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "current_time = datetime.now()\n",
    "model.train_model(train)\n",
    "print(\"Training time: \", datetime.now() - current_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating the training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting to features started. Cache is not used.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3723bfd51c2c43489bc0448dc7d95962",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=10269.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cbb864ceaf2041579e258960a597f2aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=321.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{'mcc': 0.0, 'acc': 0.20673872821112085, 'eval_loss': 1.7572507394065737}\n",
      "Converting to features started. Cache is not used.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mark\\Anaconda3\\envs\\thesis\\lib\\site-packages\\sklearn\\metrics\\_classification.py:900: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb1b6baa640e4583af3a9b5e5927cf4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1284.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "800019115d1b4b3f9da3f68761db712d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=41.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{'mcc': 0.0, 'acc': 0.19314641744548286, 'eval_loss': 1.7617364336804646}\n",
      "Training Result: 0.20673872821112085\n",
      "Eval Result: 0.19314641744548286\n"
     ]
    }
   ],
   "source": [
    "TrainResult, TrainModel_outputs, wrong_predictions = model.eval_model(train, acc=sklearn.metrics.accuracy_score)\n",
    "\n",
    "EvalResult, EvalModel_outputs, wrong_predictions = model.eval_model(Eval, acc=sklearn.metrics.accuracy_score)\n",
    "\n",
    "print('Training Result:', TrainResult['acc'])\n",
    "#print('Model Out:', TrainModel_outputs)\n",
    "\n",
    "print('Eval Result:', EvalResult['acc'])\n",
    "#print('Model Out:', EvalModel_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting to features started. Cache is not used.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8187de8656ec4f54a9e4dab153f1a1f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1283.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f4767680ab74910b5ea297dc31557ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=41.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{'mcc': 0.0, 'acc': 0.20810600155884645, 'eval_loss': 1.7547448495539224}\n",
      "Test Set Result: 0.20810600155884645\n"
     ]
    }
   ],
   "source": [
    "TestResult, TestModel_outputs, wrong_predictions = model.eval_model(test, acc=sklearn.metrics.accuracy_score)\n",
    "\n",
    "print('Test Set Result:', TestResult['acc'])\n",
    "#print('Model Out:', TestModel_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.39040914  0.40200126  0.24867666  0.42444533  0.41281685  0.27566487] 3   4 \n",
      "[-0.38886827  0.40101492  0.24948558  0.424803    0.41199383  0.27589822] 3   3 Match 1\n",
      "\n",
      "[-0.3894064   0.40107957  0.25028643  0.4247478   0.41295147  0.27733898] 3   1 \n",
      "[-0.38468385  0.40366676  0.2479518   0.42206803  0.4155267   0.2709958 ] 3   5 \n",
      "[-0.3854295   0.4041398   0.2526069   0.4260064   0.40980104  0.2734852 ] 3   5 \n",
      "[-0.3898314   0.4000115   0.25128624  0.42474115  0.41295296  0.2784948 ] 3   2 \n",
      "[-0.38361967  0.40368387  0.25381744  0.4260768   0.4118292   0.266943  ] 3   4 \n",
      "[-0.39467618  0.40561178  0.2630738   0.44795558  0.4086764   0.26985192] 3   5 \n",
      "[-0.38973576  0.4002939   0.25049987  0.42466965  0.413418    0.27672222] 3   4 \n",
      "[-0.39275095  0.40184826  0.25502577  0.42651135  0.41224512  0.27486882] 3   5 \n",
      "[-0.390017    0.40485656  0.26304975  0.4488423   0.4101394   0.2681123 ] 3   5 \n",
      "[-0.39090496  0.40205324  0.25188005  0.4248508   0.41400698  0.27542573] 3   3 Match 2\n",
      "\n",
      "[-0.3957557   0.4070298   0.26041833  0.4341767   0.40846476  0.26549324] 3   2 \n",
      "[-0.38968045  0.40158546  0.24919704  0.42476273  0.41189232  0.27517238] 3   1 \n",
      "[-0.3892603   0.40135285  0.24898094  0.42466024  0.41176903  0.27631027] 3   4 \n",
      "[-0.38996     0.40164223  0.24821928  0.42524484  0.41296777  0.27547586] 3   4 \n",
      "[-0.38228074  0.4037347   0.2566225   0.4399815   0.40419132  0.26885453] 3   4 \n",
      "[-0.38899076  0.40145394  0.24756077  0.42321962  0.41392115  0.275872  ] 3   3 Match 3\n",
      "\n",
      "[-0.3855533   0.40368953  0.25606245  0.4305021   0.41046408  0.26664913] 3   1 \n",
      "[-0.39084372  0.40292183  0.25104937  0.42469716  0.41118905  0.27614802] 3   1 \n",
      "[-0.3883223   0.4014642   0.24840942  0.42372346  0.41360933  0.2759311 ] 3   1 \n",
      "[-0.39067712  0.40264064  0.2529557   0.425607    0.41182286  0.27508125] 3   3 Match 4\n",
      "\n",
      "[-0.38944578  0.40329486  0.25367138  0.42737803  0.41072083  0.27610892] 3   1 \n",
      "[-0.38713852  0.40167803  0.2505905   0.4254758   0.41150668  0.2737106 ] 3   5 \n",
      "[-0.38983494  0.4000206   0.25206694  0.42654815  0.4122701   0.2774075 ] 3   5 \n",
      "[-0.3862806   0.40333673  0.25390694  0.42832723  0.41100118  0.26607972] 3   5 \n",
      "[-0.39386135  0.4023666   0.26222104  0.4306852   0.40880144  0.27489653] 3   5 \n",
      "[-0.39034268  0.40089267  0.25459412  0.42790654  0.41239324  0.27524045] 3   4 \n",
      "[-0.38998616  0.4011534   0.24899778  0.42282435  0.41413733  0.27524963] 3   5 \n",
      "[-0.39035958  0.40053713  0.24974295  0.42354548  0.41399074  0.27570638] 3   3 Match 5\n",
      "\n",
      "[-0.38496333  0.40392405  0.2520682   0.428249    0.4109018   0.26692444] 3   5 \n",
      "[-0.3894871   0.40239662  0.25115266  0.42397806  0.4106779   0.2733734 ] 3   2 \n",
      "[-0.38900897  0.40197384  0.24805635  0.4246155   0.41213745  0.27591515] 3   0 \n",
      "[-0.38618517  0.402012    0.24797428  0.42524529  0.41107082  0.27959937] 3   5 \n",
      "[-0.38991192  0.40154868  0.2507588   0.4243976   0.41242686  0.27593577] 3   5 \n",
      "[-0.3820365   0.4020721   0.24611825  0.42091733  0.41405565  0.27146187] 3   5 \n",
      "[-0.38889402  0.403611    0.2523574   0.42809543  0.40868774  0.27396265] 3   4 \n",
      "[-0.38625038  0.40362605  0.2528349   0.42809853  0.41272688  0.2668165 ] 3   3 Match 6\n",
      "\n",
      "[-0.38546228  0.4035278   0.25125542  0.42742017  0.41279     0.26626584] 3   3 Match 7\n",
      "\n",
      "[-0.4010952   0.40219802  0.2602458   0.4299094   0.41084653  0.27481183] 3   5 \n",
      "[-0.39061144  0.4024591   0.24709752  0.42318642  0.41413933  0.27558514] 3   5 \n",
      "[-0.3970983   0.40183067  0.2580118   0.42514908  0.4126948   0.27566192] 3   4 \n",
      "[-0.3888572   0.40054747  0.24872872  0.4237558   0.4132054   0.27584225] 3   3 Match 8\n",
      "\n",
      "[-0.38580123  0.40378606  0.25086534  0.42710653  0.41303986  0.2661671 ] 3   2 \n",
      "[-0.39015347  0.4013501   0.250181    0.4238467   0.41248354  0.2754282 ] 3   1 \n",
      "[-0.38782814  0.40266284  0.25685602  0.4344785   0.41061103  0.26637062] 3   2 \n",
      "[-0.39545786  0.40149784  0.256928    0.4256377   0.41337952  0.27841377] 3   3 Match 9\n",
      "\n",
      "[-0.39044905  0.40119407  0.24957648  0.42456365  0.41173017  0.2760475 ] 3   2 \n",
      "[-0.39046085  0.4005377   0.24897453  0.42348307  0.4146319   0.27632532] 3   2 \n",
      "[-0.38511366  0.40399274  0.25078914  0.42573303  0.41357616  0.26620412] 3   5 \n",
      "[-0.3843258   0.40398642  0.25133696  0.42724863  0.4112977   0.26589572] 3   5 \n",
      "[-0.38868064  0.40139416  0.24848121  0.42243454  0.41432518  0.2762535 ] 3   2 \n",
      "[-0.39028904  0.4006415   0.250435    0.42435065  0.41306067  0.2760547 ] 3   4 \n",
      "[-0.38753062  0.40177986  0.24789342  0.425811    0.4114735   0.2754707 ] 3   2 \n",
      "[-0.38410002  0.40339142  0.2581928   0.44416404  0.40526235  0.26908794] 3   1 \n",
      "[-0.38424337  0.40442073  0.25308177  0.42853197  0.41043788  0.26635033] 3   5 \n",
      "[-0.39056468  0.4029484   0.2535419   0.4282364   0.4103878   0.2764476 ] 3   5 \n",
      "[-0.38564768  0.40195012  0.24700648  0.4266374   0.4101803   0.2763848 ] 3   2 \n",
      "[-0.3990829   0.40005296  0.2591046   0.42660913  0.41328347  0.2768428 ] 3   5 \n",
      "[-0.38473547  0.40416816  0.25198784  0.42941082  0.41055655  0.26640436] 3   2 \n",
      "[-0.3889316   0.4017536   0.24953783  0.42325497  0.4116991   0.27493963] 3   1 \n",
      "[-0.39139512  0.40125602  0.25047633  0.4246115   0.4133216   0.2752086 ] 3   1 \n",
      "[-0.40003997  0.39798823  0.25612876  0.42383242  0.41344172  0.27323845] 3   3 Match 10\n",
      "\n",
      "[-0.38582292  0.40367085  0.25134942  0.42696953  0.41216928  0.26794136] 3   5 \n",
      "[-0.38687336  0.40253264  0.25151405  0.42718807  0.41319144  0.2668291 ] 3   0 \n",
      "[-0.3922514   0.40179777  0.25319788  0.42555693  0.41100568  0.27448848] 3   5 \n",
      "[-0.3841524   0.40478328  0.25236434  0.4281511   0.41150907  0.26561114] 3   3 Match 11\n",
      "\n",
      "[-0.3899933   0.40136272  0.24894652  0.4242222   0.41223583  0.27629247] 3   4 \n",
      "[-0.38707495  0.40209866  0.2472578   0.4272742   0.41030964  0.27590382] 3   3 Match 12\n",
      "\n",
      "[-0.38580275  0.40384346  0.26230577  0.4450423   0.40512416  0.26942077] 3   1 \n",
      "[-0.38516915  0.40427074  0.25935844  0.44149506  0.40361327  0.26896328] 3   5 \n",
      "[-0.39219385  0.40232122  0.2545503   0.4262021   0.41226858  0.27392927] 3   1 \n",
      "[-0.38965327  0.40163884  0.24855843  0.42406455  0.41258022  0.27583653] 3   3 Match 13\n",
      "\n",
      "[-0.3918289   0.4031525   0.25514948  0.42614618  0.41145054  0.27684504] 3   5 \n",
      "[-0.38925564  0.40077937  0.24827817  0.4245487   0.41362655  0.27552786] 3   4 \n",
      "[-0.3911429   0.4006252   0.2519393   0.426546    0.41148528  0.2766203 ] 3   1 \n",
      "[-0.38504267  0.40272966  0.25417498  0.4274925   0.41134468  0.26585594] 3   4 \n",
      "[-0.3910002   0.40294012  0.255353    0.42951563  0.40991572  0.27728692] 3   3 Match 14\n",
      "\n",
      "[-0.38351667  0.40580872  0.25451306  0.43622923  0.40906337  0.26793915] 3   1 \n",
      "[-0.39125824  0.4086468   0.26024905  0.44527087  0.40913165  0.2690251 ] 3   3 Match 15\n",
      "\n",
      "[-0.3883282   0.40223613  0.24994591  0.42529184  0.41168535  0.27517277] 3   3 Match 16\n",
      "\n",
      "[-0.3894853   0.40198416  0.25037402  0.42490157  0.41157544  0.27629447] 3   5 \n",
      "[-0.38878405  0.40107843  0.24880937  0.42404595  0.41339487  0.27515557] 3   2 \n",
      "[-0.38896093  0.401523    0.25109565  0.42755583  0.4092762   0.27616373] 3   1 \n",
      "[-0.3905425   0.40133604  0.24959317  0.42454082  0.4126453   0.27674457] 3   4 \n",
      "[-0.38717532  0.40164587  0.24852198  0.42292094  0.41441864  0.27381006] 3   3 Match 17\n",
      "\n",
      "[-0.38554305  0.40340924  0.2522969   0.4277469   0.41160703  0.26662531] 3   3 Match 18\n",
      "\n",
      "[-0.3798701   0.4032731   0.2430346   0.41987586  0.41553345  0.27008584] 3   3 Match 19\n",
      "\n",
      "[-0.3879965   0.4023953   0.24977282  0.42470068  0.41105846  0.2760919 ] 3   4 \n",
      "[-0.38962668  0.4025747   0.2525467   0.42625085  0.4125129   0.27506495] 3   5 \n",
      "[-0.39790452  0.4058161   0.25758368  0.42704767  0.41271192  0.27671197] 3   4 \n",
      "[-0.39348757  0.40220994  0.25361228  0.4242634   0.4130415   0.2760882 ] 3   3 Match 20\n",
      "\n",
      "[-0.38938043  0.4027507   0.24893588  0.42473802  0.4115254   0.27673498] 3   0 \n",
      "[-0.39094394  0.40124005  0.2517844   0.4245403   0.41212517  0.2760908 ] 3   1 \n",
      "[-0.38710028  0.40166396  0.24851912  0.4230908   0.41305935  0.27350667] 3   1 \n",
      "[-0.38860613  0.40072516  0.2495335   0.4244244   0.41239953  0.2773626 ] 3   1 \n",
      "[-0.39058876  0.4015572   0.24911204  0.4227514   0.4122552   0.27506572] 3   5 \n",
      "[-0.38959503  0.40196145  0.24806699  0.4233597   0.4132403   0.27539733] 3   5 \n",
      "[-0.3932305   0.40230367  0.25693837  0.42763102  0.40803447  0.27558422] 3   3 Match 21\n",
      "\n",
      "[-0.3885759   0.40284133  0.25272077  0.42640534  0.4094431   0.27653274] 3   1 \n",
      "[-0.3934043   0.40097994  0.25128284  0.42411548  0.41171488  0.2781051 ] 3   4 \n",
      "[-0.38888878  0.40062964  0.24914262  0.42270577  0.4126399   0.2745251 ] 3   0 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.3899753   0.40085983  0.24855804  0.4226682   0.41407442  0.2755294 ] 3   3 Match 22\n",
      "\n",
      "[-0.3896599   0.4002874   0.25669554  0.42745098  0.41052085  0.278352  ] 3   1 \n",
      "[-0.4074776   0.4026168   0.2603365   0.43077227  0.41716078  0.27361193] 3   2 \n",
      "[-0.39188808  0.4001316   0.25055316  0.42326123  0.41665345  0.27163976] 3   1 \n",
      "[-0.3892339   0.40103334  0.24878317  0.42414173  0.41279462  0.27640352] 3   2 \n",
      "[-0.39948407  0.40440065  0.25878832  0.42499015  0.41212332  0.27623627] 3   5 \n",
      "[-0.3882276   0.4022407   0.2482219   0.42347455  0.41241625  0.2750851 ] 3   5 \n",
      "[-0.38964945  0.40119725  0.2485567   0.42437357  0.4128534   0.27537912] 3   2 \n",
      "[-0.3908342   0.40113655  0.25041717  0.42416644  0.41269898  0.2767628 ] 3   0 \n",
      "[-0.40097114  0.4033477   0.26147726  0.42578235  0.4114603   0.2736933 ] 3   2 \n",
      "[-0.38972852  0.40112883  0.24853042  0.4224306   0.4139987   0.27583054] 3   5 \n",
      "[-0.3952877   0.39979395  0.25690505  0.42688632  0.41201     0.2761032 ] 3   4 \n",
      "[-0.39669424  0.40435785  0.26398152  0.43079403  0.41006798  0.27306107] 3   1 \n",
      "[-0.3890847   0.40271997  0.24959964  0.4215921   0.41355607  0.27375793] 3   0 \n",
      "[-0.38883525  0.40181625  0.24879801  0.42514417  0.4114368   0.27528578] 3   5 \n",
      "[-0.38842905  0.40136504  0.25121012  0.42479193  0.41040772  0.2763982 ] 3   1 \n",
      "[-0.38673598  0.40315622  0.25191054  0.42697227  0.41303322  0.26701084] 3   1 \n",
      "[-0.38526016  0.40239322  0.24948594  0.42252067  0.41478634  0.27376392] 3   3 Match 23\n",
      "\n",
      "[-0.3877675   0.4016001   0.25111315  0.4257514   0.4128742   0.27611154] 3   2 \n",
      "[-0.38901645  0.40072286  0.24880317  0.4240606   0.412757    0.27552286] 3   2 \n",
      "[-0.38755125  0.40361828  0.25028864  0.42548117  0.4108425   0.2760454 ] 3   4 \n",
      "[-0.38926744  0.4021703   0.24814641  0.42289534  0.4139089   0.27552715] 3   4 \n",
      "[-0.3853559   0.40335214  0.253929    0.429197    0.4102972   0.26684913] 3   5 \n",
      "[-0.39044565  0.40021208  0.24893942  0.4238406   0.41455397  0.27652287] 3   1 \n",
      "[-0.3902076   0.4007164   0.24897519  0.42353365  0.41317105  0.27509454] 3   1 \n",
      "[-0.38658708  0.40324965  0.2523739   0.42794994  0.41237977  0.26769096] 3   4 \n",
      "[-0.39068648  0.4031178   0.25130057  0.4259513   0.41196063  0.2750381 ] 3   5 \n",
      "[-0.38911957  0.40180114  0.24931473  0.42362535  0.41341525  0.27585408] 3   1 \n",
      "[-0.39683476  0.40207607  0.25435942  0.42666525  0.4114086   0.27702576] 3   2 \n",
      "[-0.38644186  0.40310735  0.2509529   0.4262959   0.41433913  0.26686123] 3   2 \n",
      "[-0.38703436  0.40357006  0.25242487  0.42729315  0.41224024  0.26579058] 3   1 \n",
      "[-0.38111183  0.40322828  0.2461251   0.42338642  0.4127877   0.27043942] 3   2 \n",
      "[-0.38904706  0.40157983  0.24829534  0.42496523  0.41261086  0.27571043] 3   1 \n",
      "[-0.38569793  0.40346307  0.25471509  0.42843655  0.41207498  0.2655565 ] 3   2 \n",
      "[-0.38325065  0.40367812  0.2554709   0.43655995  0.40688092  0.2693615 ] 3   5 \n",
      "[-0.3866504   0.40236136  0.2478083   0.424966    0.4109371   0.27593437] 3   5 \n",
      "[-0.4071204   0.40551874  0.26082614  0.42600593  0.41268477  0.27460966] 3   2 \n",
      "[-0.38859236  0.40133488  0.24971107  0.4255181   0.4109809   0.27595857] 3   3 Match 24\n",
      "\n",
      "[-0.3856567   0.40257415  0.2523003   0.4267155   0.4115444   0.2674787 ] 3   1 \n",
      "[-0.38783565  0.40246338  0.24699661  0.42339876  0.41274038  0.27617136] 3   2 \n",
      "[-0.3895551   0.3997906   0.25580063  0.42883602  0.40779138  0.28026265] 3   1 \n",
      "[-0.40144414  0.40644386  0.2587399   0.4207646   0.41224092  0.27382842] 3   4 \n",
      "[-0.386799    0.40151104  0.24702308  0.422103    0.4121248   0.2774127 ] 3   3 Match 25\n",
      "\n",
      "[-0.38897803  0.40153742  0.25135642  0.4252124   0.41116092  0.27713054] 3   4 \n",
      "[-0.3979892   0.4043825   0.267921    0.43263924  0.41060716  0.26830608] 3   3 Match 26\n",
      "\n",
      "[-0.38881356  0.40128422  0.25001338  0.42575368  0.41156688  0.27608612] 3   3 Match 27\n",
      "\n",
      "[-0.39010113  0.40162995  0.2515385   0.42639342  0.40911743  0.27619192] 3   5 \n",
      "[-0.3873785   0.4023512   0.24677262  0.4241629   0.41201538  0.27541614] 3   4 \n",
      "[-0.39546645  0.40842015  0.26484698  0.44260433  0.409913    0.2664838 ] 3   1 \n",
      "[-0.38575616  0.40165678  0.25042573  0.42412576  0.41197675  0.2753655 ] 3   2 \n",
      "[-0.3891542   0.4010495   0.2503623   0.42364976  0.41318205  0.27654585] 3   1 \n",
      "[-0.39763123  0.40148145  0.2575887   0.42726296  0.41219294  0.27653787] 3   3 Match 28\n",
      "\n",
      "[-0.38649786  0.40190235  0.24745849  0.42401966  0.41280746  0.2732265 ] 3   2 \n",
      "[-0.38914806  0.40084806  0.2518399   0.42447025  0.41195217  0.2769458 ] 3   3 Match 29\n",
      "\n",
      "[-0.39043415  0.4010399   0.24910751  0.42303035  0.4134483   0.2768375 ] 3   5 \n",
      "[-0.38539737  0.40373963  0.24916923  0.42247766  0.41224226  0.27628568] 3   4 \n",
      "[-0.38977563  0.40109357  0.25049153  0.42486057  0.4110613   0.2764798 ] 3   4 \n",
      "[-0.38772014  0.40313703  0.2480197   0.42467642  0.41152307  0.27566245] 3   5 \n",
      "[-0.38378003  0.40494785  0.2516641   0.43176237  0.4100892   0.2682442 ] 3   5 \n",
      "[-0.38812676  0.4013059   0.2490499   0.4238602   0.41308564  0.27641043] 3   1 \n",
      "[-0.38638544  0.40194052  0.25358894  0.42578483  0.41189456  0.2750299 ] 3   4 \n",
      "[-0.39091608  0.40006334  0.25277457  0.4220608   0.41242653  0.27517837] 3   3 Match 30\n",
      "\n",
      "[-0.39083347  0.40119302  0.24862036  0.42343983  0.4142968   0.2757279 ] 3   3 Match 31\n",
      "\n",
      "[-0.38595515  0.4033937   0.25272468  0.42762908  0.41178834  0.2657873 ] 3   5 \n",
      "[-0.390178    0.4003834   0.24945483  0.42422214  0.41196018  0.27512667] 3   3 Match 32\n",
      "\n",
      "[-0.3947742   0.40287465  0.25708422  0.4253722   0.41194344  0.27756053] 3   2 \n",
      "[-0.39443013  0.4036961   0.2571703   0.42936102  0.4079567   0.27640513] 3   3 Match 33\n",
      "\n",
      "[-0.38639864  0.40617293  0.25907114  0.44165233  0.40792513  0.2678067 ] 3   1 \n",
      "[-0.38828218  0.4020046   0.24818751  0.4249756   0.41166463  0.27558523] 3   3 Match 34\n",
      "\n",
      "[-0.39010066  0.4012028   0.25481132  0.4276084   0.40838417  0.28032014] 3   2 \n",
      "[-0.38633996  0.40267813  0.24909633  0.42522314  0.41077057  0.27711973] 3   5 \n",
      "[-0.39611593  0.40415537  0.25861815  0.4275463   0.40913475  0.27668184] 3   5 \n",
      "[-0.3878926   0.39967364  0.25825608  0.42602232  0.4042884   0.28020307] 3   3 Match 35\n",
      "\n",
      "[-0.38876     0.40170896  0.24885526  0.42382768  0.41264227  0.2759649 ] 3   5 \n",
      "[-0.3884027   0.4027093   0.2479136   0.42415798  0.41204205  0.27534303] 3   3 Match 36\n",
      "\n",
      "[-0.3891648   0.40134293  0.24789363  0.42221552  0.41388157  0.27551186] 3   4 \n",
      "[-0.38963467  0.40124977  0.24924731  0.4231432   0.41410917  0.2755255 ] 3   1 \n",
      "[-0.39234877  0.40174797  0.2521316   0.42311624  0.41236907  0.27621526] 3   2 \n",
      "[-0.3896479   0.4018891   0.24780336  0.42330012  0.41391832  0.27539536] 3   5 \n",
      "[-0.3884145   0.40172702  0.24961278  0.42360935  0.4133308   0.27635738] 3   3 Match 37\n",
      "\n",
      "[-0.38957298  0.40189484  0.24969116  0.423812    0.4109735   0.27689722] 3   3 Match 38\n",
      "\n",
      "[-0.38671976  0.40319288  0.25009686  0.424983    0.41205016  0.2744539 ] 3   1 \n",
      "[-0.38882867  0.40138948  0.24890652  0.424127    0.4122994   0.27498117] 3   1 \n",
      "[-0.38872156  0.40291303  0.2513769   0.42388916  0.41062817  0.27578208] 3   0 \n",
      "[-0.38999307  0.40102884  0.24883494  0.42377695  0.41323683  0.2759708 ] 3   0 \n",
      "[-0.3857051   0.40140718  0.25099173  0.4297539   0.408453    0.27667746] 3   4 \n",
      "[-0.38885745  0.40441528  0.25613174  0.42812964  0.41176724  0.2670076 ] 3   1 \n",
      "[-0.3888989   0.40118816  0.24996236  0.4229578   0.41366723  0.2759042 ] 3   5 \n",
      "[-0.39069137  0.39990658  0.25549486  0.42736763  0.4095704   0.28025484] 3   2 \n",
      "[-0.3906502   0.4033022   0.25022653  0.42598835  0.4129743   0.27678916] 3   5 \n",
      "[-0.3911166   0.40207678  0.25028953  0.42471188  0.4121708   0.27578506] 3   5 \n",
      "[-0.3774491   0.4035863   0.25279903  0.43743593  0.40493268  0.27001318] 3   0 \n",
      "[-0.38366678  0.40317824  0.25018027  0.42412013  0.41096294  0.2722134 ] 3   1 \n",
      "[-0.4052155   0.40102124  0.25965416  0.42342225  0.4172358   0.2737443 ] 3   1 \n",
      "[-0.38776505  0.40199256  0.24784693  0.42414016  0.40944344  0.27461928] 3   2 \n",
      "[-0.38882095  0.40175992  0.25119242  0.4255205   0.41166645  0.27563354] 3   3 Match 39\n",
      "\n",
      "[-0.38730234  0.40255362  0.24830079  0.425763    0.41072878  0.27655992] 3   3 Match 40\n",
      "\n",
      "[-0.38893253  0.40282547  0.24940613  0.4249033   0.411871    0.2743295 ] 3   1 \n",
      "[-0.3916322   0.3998619   0.25333628  0.42697674  0.41151366  0.2764585 ] 3   1 \n",
      "[-0.389643    0.40177566  0.24959686  0.42262965  0.4132914   0.27615848] 3   2 \n",
      "[-0.3899727   0.4017383   0.25021267  0.42265984  0.41292942  0.27585873] 3   3 Match 41\n",
      "\n",
      "[-0.38883346  0.40150487  0.25426847  0.42613694  0.4100679   0.27638173] 3   3 Match 42\n",
      "\n",
      "[-0.38443115  0.40319473  0.25084245  0.42441806  0.41278055  0.27077648] 3   1 \n",
      "[-0.39232752  0.40282708  0.2516441   0.42346945  0.4137684   0.2738701 ] 3   1 \n",
      "[-0.38985562  0.40102178  0.25225982  0.4222572   0.41292834  0.2742437 ] 3   4 \n",
      "[-0.3916103   0.40227264  0.24972895  0.42262903  0.41360742  0.27637455] 3   5 \n",
      "[-0.3892465   0.40060142  0.24889642  0.4232997   0.41413388  0.27689496] 3   3 Match 43\n",
      "\n",
      "[-0.38663644  0.40230238  0.25059885  0.4217253   0.4138344   0.27129817] 3   3 Match 44\n",
      "\n",
      "[-0.38701367  0.4017559   0.2489616   0.42688286  0.41076753  0.2754075 ] 3   1 \n",
      "[-0.38675198  0.4021304   0.24620655  0.4243004   0.41215402  0.27583945] 3   3 Match 45\n",
      "\n",
      "[-0.38925758  0.40163246  0.2492306   0.42458263  0.41247535  0.2763056 ] 3   3 Match 46\n",
      "\n",
      "[-0.39125222  0.40057233  0.2553788   0.4262481   0.40974972  0.27509165] 3   0 \n",
      "[-0.38931966  0.4021747   0.24790472  0.42421642  0.4124697   0.27576277] 3   2 \n",
      "[-0.3875783   0.40101153  0.24853244  0.42392096  0.4132108   0.27613896] 3   5 \n",
      "[-0.38469124  0.40432408  0.25199008  0.42747867  0.410148    0.26625666] 3   2 \n",
      "[-0.39353406  0.40124667  0.25017232  0.42618194  0.41330996  0.2758455 ] 3   4 \n",
      "[-0.38969767  0.4020255   0.2498971   0.42512447  0.4109124   0.27607876] 3   3 Match 47\n",
      "\n",
      "[-0.39005888  0.40090007  0.24973407  0.42524743  0.41136324  0.2754703 ] 3   4 \n",
      "[-0.3968855   0.4010248   0.2536129   0.42599398  0.41400108  0.2736602 ] 3   4 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.38701835  0.40347973  0.2544971   0.42820475  0.40984276  0.26626304] 3   1 \n",
      "[-0.38903728  0.40084237  0.24824607  0.42248327  0.4139321   0.2758487 ] 3   4 \n",
      "[-0.389975    0.40140226  0.25050333  0.42435786  0.41202885  0.27569017] 3   2 \n",
      "[-0.38982952  0.4007052   0.2483936   0.42323276  0.41411322  0.27602395] 3   1 \n",
      "[-0.38916472  0.39953277  0.2521504   0.424979    0.41126582  0.27836385] 3   2 \n",
      "[-0.3898474   0.40158844  0.25303057  0.42524722  0.4103985   0.27597925] 3   3 Match 48\n",
      "\n",
      "[-0.38716304  0.40137658  0.25003448  0.42822638  0.41007388  0.27696785] 3   1 \n",
      "[-0.39083153  0.40101516  0.24921721  0.42357934  0.4135654   0.27683   ] 3   3 Match 49\n",
      "\n",
      "[-0.38902068  0.40214235  0.2576603   0.4261552   0.40830383  0.27782252] 3   0 \n",
      "[-0.38949138  0.4019279   0.25249255  0.4252542   0.41146794  0.27518967] 3   3 Match 50\n",
      "\n",
      "[-0.3900968   0.40105164  0.25103775  0.42616144  0.41095254  0.27701166] 3   1 \n",
      "[-0.38704282  0.40194795  0.24815449  0.42423534  0.41182578  0.2738463 ] 3   0 \n",
      "[-0.38768297  0.4001945   0.24909818  0.42489117  0.4138141   0.2766422 ] 3   0 \n",
      "[-0.39228195  0.4012555   0.25341222  0.42602053  0.41187805  0.27660915] 3   1 \n",
      "[-0.39353123  0.4038329   0.2536105   0.4271053   0.41353256  0.2741517 ] 3   3 Match 51\n",
      "\n",
      "[-0.39030373  0.4006931   0.25103852  0.4244906   0.4110591   0.2760169 ] 3   5 \n",
      "[-0.389644    0.4024629   0.25130397  0.42598394  0.41050136  0.275493  ] 3   0 \n",
      "[-0.38939315  0.4022645   0.24746498  0.42462894  0.41258338  0.27611786] 3   4 \n",
      "[-0.3920935   0.401641    0.25314164  0.42402136  0.41341853  0.27384144] 3   2 \n",
      "[-0.3899104   0.401382    0.25232875  0.42550275  0.41001996  0.27669114] 3   2 \n",
      "[-0.3892604   0.4019885   0.25074396  0.42483202  0.41159242  0.27575466] 3   1 \n",
      "[-0.3890388   0.40071312  0.25112697  0.42365327  0.41158032  0.27489948] 3   3 Match 52\n",
      "\n",
      "[-0.38862956  0.40169013  0.24805728  0.42438304  0.41137704  0.27607197] 3   5 \n",
      "[-0.38727042  0.4015999   0.25020674  0.42710415  0.4099951   0.27712297] 3   4 \n",
      "[-0.39186063  0.39966628  0.2571009   0.42630744  0.41027772  0.27501076] 3   1 \n",
      "[-0.38960272  0.40159482  0.2505069   0.42515647  0.41065574  0.27519628] 3   0 \n",
      "[-0.39837858  0.40245882  0.25514752  0.42578867  0.4136425   0.2747706 ] 3   1 \n",
      "[-0.38911214  0.40106723  0.25005051  0.42344636  0.4127455   0.27655873] 3   3 Match 53\n",
      "\n",
      "[-0.38638282  0.40361342  0.2519885   0.42606667  0.41257888  0.2667454 ] 3   2 \n",
      "[-0.3876527   0.4016206   0.24950358  0.42607412  0.41087407  0.276702  ] 3   2 \n",
      "[-0.3895163   0.4013049   0.24829814  0.4250741   0.4126849   0.27560437] 3   5 \n",
      "[-0.39307946  0.4027032   0.25342205  0.42715237  0.41159385  0.27458355] 3   3 Match 54\n",
      "\n",
      "[-0.38568276  0.40216583  0.25079364  0.42302307  0.41397223  0.27218965] 3   4 \n",
      "[-0.38773906  0.40150014  0.24869367  0.4247111   0.41206747  0.2759808 ] 3   1 \n",
      "[-0.38740614  0.400722    0.25470743  0.4260786   0.40874243  0.27688804] 3   1 \n",
      "[-0.39372447  0.40303886  0.25078872  0.42381474  0.41237822  0.27559435] 3   1 \n",
      "[-0.38877118  0.40223157  0.24980453  0.4266395   0.4102592   0.27677116] 3   0 \n",
      "[-0.38955176  0.4012021   0.24858758  0.42306325  0.4133958   0.27648917] 3   4 \n",
      "[-0.38947374  0.4046602   0.25756192  0.42891082  0.413813    0.2651527 ] 3   1 \n",
      "[-0.38744277  0.4016088   0.25068006  0.42273062  0.41385165  0.27257663] 3   3 Match 55\n",
      "\n",
      "[-0.38838685  0.40176105  0.24846217  0.42413017  0.41242948  0.27511925] 3   1 \n",
      "[-0.38912183  0.40202785  0.25613853  0.42781404  0.409268    0.27690998] 3   1 \n",
      "[-0.39024428  0.40203482  0.2519589   0.42386374  0.41200897  0.27673107] 3   3 Match 56\n",
      "\n",
      "[-0.3893564   0.40167654  0.250819    0.4263122   0.4097823   0.275252  ] 3   0 \n",
      "[-0.38748965  0.40074986  0.2511438   0.42538372  0.41180545  0.27766293] 3   5 \n",
      "[-0.40371123  0.4053548   0.26352754  0.42887112  0.41889927  0.2740054 ] 3   0 \n",
      "[-0.39183712  0.40025645  0.25703067  0.42630538  0.4107352   0.27790862] 3   3 Match 57\n",
      "\n",
      "[-0.39266163  0.40132213  0.25495687  0.42435452  0.411119    0.27690873] 3   2 \n",
      "[-0.38801166  0.4015655   0.24853158  0.42531767  0.41119185  0.2757605 ] 3   0 \n",
      "[-0.388196    0.40141466  0.24807552  0.42419282  0.4119951   0.2749348 ] 3   0 \n",
      "[-0.39205107  0.40285778  0.25896397  0.4303149   0.41100055  0.27162972] 3   4 \n",
      "[-0.38857758  0.40160728  0.24940202  0.423916    0.4115546   0.27621675] 3   1 \n",
      "[-0.3904434   0.4023638   0.25044596  0.42493397  0.41306487  0.27387193] 3   2 \n",
      "[-0.38627008  0.4018116   0.24920288  0.4260945   0.4112161   0.27493772] 3   3 Match 58\n",
      "\n",
      "[-0.38848954  0.4006728   0.24881056  0.42340377  0.41373378  0.27567416] 3   2 \n",
      "[-0.38996348  0.40162697  0.24831173  0.42405692  0.413482    0.27652785] 3   5 \n",
      "[-0.38838416  0.40121475  0.25037584  0.42516866  0.40874335  0.27641395] 3   3 Match 59\n",
      "\n",
      "[-0.38880944  0.4003256   0.24899974  0.42388147  0.41301003  0.27637133] 3   5 \n",
      "[-0.3885986   0.40149632  0.2479325   0.42489132  0.41179034  0.27628604] 3   4 \n",
      "[-0.3898368   0.40098172  0.24860558  0.422703    0.4144581   0.27514997] 3   4 \n",
      "[-0.3893227   0.4011162   0.24949506  0.42486736  0.41219157  0.27606547] 3   1 \n",
      "[-0.39417782  0.40156856  0.2565645   0.42741463  0.410261    0.2767965 ] 3   4 \n",
      "[-0.39155102  0.40025538  0.2531599   0.42473286  0.41141012  0.27648193] 3   3 Match 60\n",
      "\n",
      "[-0.38742998  0.4021627   0.25117704  0.424471    0.41097566  0.27782005] 3   0 \n",
      "[-0.38834387  0.40119788  0.24842498  0.42341495  0.41181114  0.27512813] 3   3 Match 61\n",
      "\n",
      "[-0.3900863   0.40048614  0.25372496  0.4253578   0.41053775  0.27711913] 3   3 Match 62\n",
      "\n",
      "[-0.38636768  0.40242955  0.24760374  0.42378697  0.4122217   0.2746508 ] 3   3 Match 63\n",
      "\n",
      "[-0.39047232  0.40242398  0.2559447   0.42748293  0.40903035  0.27536866] 3   4 \n",
      "[-0.38743475  0.40301222  0.24803272  0.42488268  0.41092405  0.2763199 ] 3   0 \n",
      "[-0.4003732   0.40094906  0.2626756   0.42894167  0.41332793  0.27372256] 3   1 \n",
      "[-0.38906723  0.4015799   0.2487117   0.42359743  0.41293392  0.27610284] 3   4 \n",
      "[-0.39027706  0.40179846  0.24849841  0.42423704  0.4121574   0.2772353 ] 3   1 \n",
      "[-0.3877316   0.40243012  0.24807552  0.4220008   0.41260764  0.27426758] 3   1 \n",
      "[-0.38913426  0.3999501   0.24882379  0.42415422  0.4129552   0.2759973 ] 3   0 \n",
      "[-0.38867903  0.40117395  0.2491717   0.42352644  0.41452622  0.27594233] 3   2 \n",
      "[-0.39516222  0.40194204  0.2518335   0.42475447  0.41305792  0.27796936] 3   4 \n",
      "[-0.38933805  0.4002891   0.2487422   0.42321482  0.41263545  0.27679798] 3   1 \n",
      "[-0.38861057  0.4012427   0.24938837  0.42379317  0.41336155  0.27609488] 3   2 \n",
      "[-0.38981843  0.40176886  0.24917734  0.4235837   0.41281065  0.27543825] 3   4 \n",
      "[-0.38980043  0.40187848  0.25012538  0.4235027   0.41205916  0.27561498] 3   1 \n",
      "[-0.39393246  0.39842668  0.25731522  0.43001327  0.40938944  0.27564988] 3   1 \n",
      "[-0.38916865  0.40125978  0.24878791  0.42398575  0.4129314   0.2759727 ] 3   3 Match 64\n",
      "\n",
      "[-0.38956285  0.40246484  0.25217706  0.42752323  0.41013446  0.2761623 ] 3   5 \n",
      "[-0.38489145  0.40236515  0.24577674  0.42130062  0.41495475  0.27221555] 3   5 \n",
      "[-0.38527244  0.40316153  0.24857306  0.42348704  0.41340294  0.2718833 ] 3   4 \n",
      "[-0.38692886  0.40181077  0.2494562   0.42709136  0.40981328  0.27570432] 3   2 \n",
      "[-0.39005885  0.40140656  0.24794     0.42274973  0.41349626  0.27560002] 3   5 \n",
      "[-0.39115056  0.40168446  0.2519467   0.4252571   0.412284    0.27711877] 3   3 Match 65\n",
      "\n",
      "[-0.38825482  0.40149462  0.248997    0.42581412  0.4105454   0.27624992] 3   4 \n",
      "[-0.3903853   0.40148038  0.24918276  0.42368975  0.412976    0.27718988] 3   1 \n",
      "[-0.3918287   0.40182847  0.25076455  0.42531604  0.4132577   0.27547356] 3   3 Match 66\n",
      "\n",
      "[-0.38958827  0.4011752   0.24790299  0.42315343  0.41415912  0.2752375 ] 3   1 \n",
      "[-0.39031726  0.40122548  0.2507737   0.42421928  0.41378596  0.2748525 ] 3   4 \n",
      "[-0.3863361   0.40058386  0.25268784  0.4268139   0.41111183  0.27765703] 3   0 \n",
      "[-0.38837853  0.40173784  0.2509437   0.42475775  0.4119073   0.2758097 ] 3   5 \n",
      "[-0.38978696  0.40083712  0.24817768  0.42392507  0.4140888   0.27679107] 3   5 \n",
      "[-0.38762543  0.40126514  0.2505375   0.42538732  0.4104722   0.27572668] 3   3 Match 67\n",
      "\n",
      "[-0.39287847  0.40037778  0.25586966  0.42688     0.4094506   0.2768864 ] 3   3 Match 68\n",
      "\n",
      "[-0.3889683   0.40038624  0.24913552  0.42347303  0.4138028   0.27701876] 3   3 Match 69\n",
      "\n",
      "[-0.38957053  0.401017    0.2493988   0.4237608   0.41260433  0.2759071 ] 3   4 \n",
      "[-0.39206004  0.40244395  0.2564229   0.42549786  0.4127784   0.2736389 ] 3   4 \n",
      "[-0.3854983   0.4026921   0.24757239  0.4223433   0.41342288  0.27297685] 3   2 \n",
      "[-0.38867334  0.40208593  0.24958536  0.42557824  0.41193238  0.27560988] 3   1 \n",
      "[-0.3897228   0.4006843   0.24913263  0.42439678  0.41295803  0.2760777 ] 3   1 \n",
      "[-0.38849396  0.40176564  0.24984208  0.42424124  0.41174066  0.27518874] 3   0 \n",
      "[-0.3884224   0.4024636   0.24879238  0.42521498  0.41161367  0.2761134 ] 3   5 \n",
      "[-0.38981086  0.40151775  0.24855384  0.42388517  0.4132977   0.27569434] 3   3 Match 70\n",
      "\n",
      "[-0.39035946  0.4016366   0.24986693  0.42362967  0.4141529   0.27577117] 3   5 \n",
      "[-0.38941193  0.40026426  0.24872443  0.42381653  0.41306338  0.2762953 ] 3   1 \n",
      "[-0.39725664  0.40059304  0.2580121   0.4260215   0.40986696  0.27469027] 3   5 \n",
      "[-0.38590565  0.40226784  0.25208458  0.4269972   0.41350973  0.26713386] 3   4 \n",
      "[-0.3860577   0.40065312  0.25135896  0.4276165   0.41105124  0.27731258] 3   3 Match 71\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.38920754  0.40183836  0.24847332  0.42478067  0.41115388  0.27539286] 3   2 \n",
      "[-0.38966542  0.4016369   0.24946564  0.4235708   0.41302207  0.27614152] 3   0 \n",
      "[-0.38803968  0.4020791   0.2509413   0.42685312  0.40939793  0.27606213] 3   1 \n",
      "[-0.38983896  0.40142676  0.24971786  0.4239848   0.4134041   0.27584743] 3   5 \n",
      "[-0.39326066  0.4037739   0.25860706  0.43137577  0.40997288  0.26596168] 3   3 Match 72\n",
      "\n",
      "[-0.39036328  0.40157056  0.25230855  0.42422205  0.41053948  0.27626997] 3   4 \n",
      "[-0.38883469  0.40095812  0.24943146  0.42386785  0.41327834  0.27643332] 3   1 \n",
      "[-0.3884418   0.4008937   0.25361612  0.42642036  0.40954062  0.27704403] 3   1 \n",
      "[-0.38922328  0.40182748  0.24785689  0.4234108   0.4124063   0.2767184 ] 3   3 Match 73\n",
      "\n",
      "[-0.38972324  0.400168    0.250428    0.4239537   0.4129301   0.27674755] 3   4 \n",
      "[-0.38943744  0.4009508   0.2487914   0.42312175  0.41333234  0.27573523] 3   1 \n",
      "[-0.38649386  0.40142775  0.24974892  0.42337552  0.4121493   0.2732185 ] 3   3 Match 74\n",
      "\n",
      "[-0.38989675  0.4025335   0.25207323  0.42486605  0.41366225  0.2735238 ] 3   5 \n",
      "[-0.3850618   0.403795    0.25132653  0.42590183  0.40849882  0.2714631 ] 3   2 \n",
      "[-0.38434744  0.40420994  0.25204903  0.42234203  0.41143355  0.27164719] 3   3 Match 75\n",
      "\n",
      "[-0.38828126  0.40165114  0.25061622  0.42488104  0.4111415   0.27548382] 3   3 Match 76\n",
      "\n",
      "[-0.3827001   0.40263677  0.24456546  0.4206974   0.41445258  0.27229387] 3   2 \n",
      "[-0.39251152  0.40405583  0.2555119   0.42833394  0.4105178   0.27223518] 3   3 Match 77\n",
      "\n",
      "[-0.38934293  0.40105116  0.24975947  0.42311037  0.4135038   0.27625152] 3   0 \n",
      "[-0.38779116  0.40175396  0.25435182  0.42725223  0.40947917  0.2765532 ] 3   4 \n",
      "[-0.3894965   0.40142843  0.2527382   0.42704776  0.4095837   0.27685562] 3   1 \n",
      "[-0.38898894  0.4019635   0.24856642  0.4238747   0.41328308  0.27604762] 3   3 Match 78\n",
      "\n",
      "[-0.38781172  0.40058565  0.25395674  0.4263771   0.41013092  0.2752481 ] 3   3 Match 79\n",
      "\n",
      "[-0.38875785  0.40173322  0.24852487  0.4247805   0.4110708   0.2764715 ] 3   5 \n",
      "[-0.39509565  0.40214613  0.25561634  0.42352563  0.41275376  0.27474463] 3   4 \n",
      "[-0.38908693  0.40157273  0.24779293  0.42494744  0.41184875  0.27536038] 3   1 \n",
      "[-0.3904274   0.40126452  0.24849924  0.42326874  0.4138844   0.2761551 ] 3   2 \n",
      "[-0.39043188  0.40201244  0.2516819   0.42417097  0.4112577   0.27581695] 3   4 \n",
      "[-0.39479154  0.4013644   0.25919622  0.42939878  0.4082628   0.27559936] 3   1 \n",
      "[-0.39076185  0.40027118  0.24983594  0.42250505  0.41354874  0.27728063] 3   1 \n",
      "[-0.39709967  0.3988737   0.25611314  0.42425293  0.4119814   0.27441198] 3   1 \n",
      "[-0.3890616   0.40129375  0.24917987  0.4241822   0.4117561   0.27494213] 3   2 \n",
      "[-0.3881157   0.40117884  0.25213757  0.4251392   0.41261408  0.27351215] 3   0 \n",
      "[-0.3891278   0.4013196   0.24823415  0.42423013  0.4130469   0.2751415 ] 3   4 \n",
      "[-0.38952494  0.40173426  0.24829185  0.4237977   0.41266602  0.27484804] 3   1 \n",
      "[-0.38964367  0.40168297  0.25264308  0.42731476  0.40981734  0.27687877] 3   4 \n",
      "[-0.3877622   0.40112954  0.24914333  0.42381594  0.41308558  0.27554652] 3   1 \n",
      "[-0.3913386   0.40323955  0.25303558  0.42684716  0.41094837  0.27397612] 3   0 \n",
      "[-0.39412728  0.40206698  0.26246813  0.43027163  0.40707126  0.27382168] 3   1 \n",
      "[-0.38903072  0.40126857  0.24716723  0.4235477   0.414162    0.27571586] 3   5 \n",
      "[-0.38742268  0.4022248   0.25175047  0.4259044   0.40960443  0.2746205 ] 3   4 \n",
      "[-0.39621416  0.40155852  0.25594714  0.42631444  0.41272688  0.27483755] 3   5 \n",
      "[-0.39039293  0.4021485   0.25166664  0.42669803  0.41019633  0.27536577] 3   1 \n",
      "[-0.3884945   0.40216404  0.25135344  0.42534643  0.41198298  0.27624863] 3   3 Match 80\n",
      "\n",
      "[-0.38969728  0.40186688  0.25462902  0.42684022  0.40966058  0.2767832 ] 3   2 \n",
      "[-0.3889637   0.4012237   0.24901268  0.42398363  0.41383442  0.2764776 ] 3   2 \n",
      "[-0.3920588   0.40178308  0.25282848  0.4251213   0.41221723  0.27509773] 3   1 \n",
      "[-0.3888464   0.4022229   0.2507275   0.42312315  0.4120393   0.27811462] 3   4 \n",
      "[-0.39303458  0.40521544  0.25484797  0.42748156  0.4128263   0.2769567 ] 3   1 \n",
      "[-0.3890452   0.40134904  0.2495453   0.4246187   0.4117326   0.27633667] 3   4 \n",
      "[-0.3890385   0.40073523  0.2500351   0.42413178  0.4127462   0.27723894] 3   3 Match 81\n",
      "\n",
      "[-0.38902384  0.4018485   0.24929589  0.42501006  0.4110365   0.27561724] 3   3 Match 82\n",
      "\n",
      "[-0.39732438  0.40106523  0.25859445  0.42471337  0.413532    0.27281344] 3   3 Match 83\n",
      "\n",
      "[-0.38746852  0.40169773  0.25127187  0.42440516  0.41074902  0.27592635] 3   3 Match 84\n",
      "\n",
      "[-0.38984782  0.40205103  0.2544239   0.42773747  0.4114789   0.27534956] 3   2 \n",
      "[-0.38881326  0.4011822   0.2479473   0.42375982  0.41388747  0.27672547] 3   1 \n",
      "[-0.39333147  0.40105587  0.25208622  0.42441088  0.41332406  0.27675572] 3   3 Match 85\n",
      "\n",
      "[-0.39123657  0.40038103  0.250238    0.42310223  0.41359147  0.27532908] 3   3 Match 86\n",
      "\n",
      "[-0.38821658  0.40135947  0.25072733  0.42626902  0.41006172  0.27701864] 3   1 \n",
      "[-0.38807136  0.4003948   0.25157607  0.4250328   0.40942556  0.2736294 ] 3   1 \n",
      "[-0.39089662  0.40455946  0.25329646  0.4284717   0.4103113   0.27354458] 3   1 \n",
      "[-0.38955933  0.40095928  0.25130764  0.42491826  0.41291797  0.27503067] 3   4 \n",
      "[-0.39462984  0.40036494  0.25489187  0.42419136  0.4130199   0.2771768 ] 3   3 Match 87\n",
      "\n",
      "[-0.3892861   0.40042305  0.24880767  0.42276773  0.4139227   0.2761942 ] 3   3 Match 88\n",
      "\n",
      "[-0.38320768  0.40430114  0.25154683  0.42995274  0.40983117  0.26741672] 3   1 \n",
      "[-0.3892917   0.4006891   0.24923918  0.42298892  0.41295105  0.27574775] 3   4 \n",
      "[-0.3889406   0.40161306  0.24803978  0.4249838   0.4122193   0.2755731 ] 3   4 \n",
      "[-0.38492072  0.40172988  0.2502764   0.42433763  0.41385326  0.27297032] 3   4 \n",
      "[-0.38686877  0.40336278  0.25538257  0.4284052   0.41032594  0.26598072] 3   4 \n",
      "[-0.389186    0.40513855  0.25391135  0.43061015  0.41162384  0.27429706] 3   0 \n",
      "[-0.3876451   0.4008829   0.25309768  0.4273487   0.40846974  0.27610755] 3   1 \n",
      "[-0.3914275   0.4005863   0.2512544   0.4243494   0.41278955  0.2768189 ] 3   4 \n",
      "[-0.3955713   0.40121493  0.25619665  0.42548725  0.41261756  0.2752902 ] 3   5 \n",
      "[-0.38977617  0.4007516   0.24915817  0.4236003   0.41325918  0.27684498] 3   1 \n",
      "[-0.38801536  0.40108457  0.24768528  0.41943857  0.41358057  0.27361408] 3   3 Match 89\n",
      "\n",
      "[-0.3943978   0.40178233  0.25386602  0.42588454  0.4114026   0.2754613 ] 3   3 Match 90\n",
      "\n",
      "[-0.38991797  0.40067887  0.25113043  0.42595214  0.41275585  0.27716863] 3   4 \n",
      "[-0.38331118  0.40174615  0.2516746   0.42666623  0.40991443  0.2724516 ] 3   3 Match 91\n",
      "\n",
      "[-0.3952826   0.40349042  0.2564289   0.42808026  0.41153935  0.27261636] 3   1 \n",
      "[-0.386096    0.40123338  0.24697706  0.42588973  0.410862    0.27649835] 3   4 \n",
      "[-0.3921613   0.40053156  0.25130585  0.42438582  0.41216233  0.27609518] 3   2 \n",
      "[-0.39395195  0.40328354  0.25383228  0.42711413  0.41315973  0.27524728] 3   0 \n",
      "[-0.39072663  0.4028404   0.25076172  0.42697686  0.41186842  0.27323171] 3   1 \n",
      "[-0.39082965  0.40029085  0.2525753   0.42776543  0.409536    0.27699563] 3   1 \n",
      "[-0.38990897  0.40054587  0.24860922  0.42317683  0.41483933  0.27682844] 3   5 \n",
      "[-0.38806087  0.40015554  0.25333604  0.42673668  0.41020507  0.27643776] 3   4 \n",
      "[-0.38636154  0.40341517  0.24636889  0.42628157  0.41101208  0.27667332] 3   4 \n",
      "[-0.3849415   0.40189815  0.24843493  0.42380187  0.4123173   0.27378637] 3   0 \n",
      "[-0.38381875  0.40404248  0.24576283  0.42050618  0.41578203  0.2698161 ] 3   5 \n",
      "[-0.38924396  0.40067026  0.24996158  0.4254036   0.4129727   0.27714798] 3   5 \n",
      "[-0.3870181   0.40142393  0.24919572  0.42621368  0.41048095  0.27741626] 3   1 \n",
      "[-0.3857687   0.40207994  0.24800518  0.42567596  0.41130245  0.27534273] 3   3 Match 92\n",
      "\n",
      "[-0.38491905  0.40285844  0.25061908  0.42374876  0.41188785  0.2728369 ] 3   3 Match 93\n",
      "\n",
      "[-0.38846514  0.4018897   0.2500361   0.42522565  0.41076726  0.27587008] 3   1 \n",
      "[-0.3920052   0.4013347   0.25258303  0.4232922   0.4127526   0.27434936] 3   3 Match 94\n",
      "\n",
      "[-0.38770682  0.40107903  0.24971077  0.42481002  0.41397136  0.27630794] 3   4 \n",
      "[-0.39305595  0.40324375  0.25858942  0.42779264  0.4081117   0.27868935] 3   3 Match 95\n",
      "\n",
      "[-0.38926592  0.402102    0.24804029  0.42452583  0.4124682   0.27602252] 3   5 \n",
      "[-0.38776705  0.4009705   0.25334895  0.4259433   0.41104463  0.27774552] 3   1 \n",
      "[-0.39096442  0.4030379   0.2510591   0.42588836  0.41154802  0.2741209 ] 3   2 \n",
      "[-0.38973662  0.40150523  0.24840298  0.4235243   0.41330698  0.2755785 ] 3   4 \n",
      "[-0.38960218  0.40147132  0.25243694  0.42588407  0.410618    0.27645573] 3   3 Match 96\n",
      "\n",
      "[-0.39364952  0.40186813  0.25548676  0.42684165  0.41157156  0.2756253 ] 3   2 \n",
      "[-0.39030057  0.40189973  0.24846372  0.4230025   0.4129651   0.2764132 ] 3   4 \n",
      "[-0.39309365  0.40268403  0.25266603  0.4257011   0.41272146  0.27496392] 3   3 Match 97\n",
      "\n",
      "[-0.38864756  0.40116763  0.2481268   0.42400876  0.41319844  0.2754846 ] 3   4 \n",
      "[-0.38819543  0.40101856  0.25033912  0.4254277   0.41093683  0.27692842] 3   0 \n",
      "[-0.3897675   0.40130728  0.25571212  0.427439    0.4091645   0.27847007] 3   5 \n",
      "[-0.38665718  0.40034026  0.2518867   0.4258242   0.4107474   0.27776   ] 3   5 \n",
      "[-0.38922876  0.40284503  0.25508153  0.430867    0.40897644  0.2742896 ] 3   2 \n",
      "[-0.38150555  0.40329048  0.24967143  0.4249102   0.41165483  0.27113417] 3   1 \n",
      "[-0.38982198  0.40013808  0.25278994  0.42768446  0.4099489   0.2768355 ] 3   4 \n",
      "[-0.38881314  0.4015322   0.25052565  0.42480925  0.41119075  0.27526996] 3   2 \n",
      "[-0.39539185  0.39957452  0.26023495  0.4258009   0.40924633  0.27691644] 3   3 Match 98\n",
      "\n",
      "[-0.39114755  0.40122142  0.2522461   0.42469972  0.41202137  0.27417213] 3   2 \n",
      "[-0.38729227  0.40184936  0.24824798  0.42517874  0.41178173  0.27540556] 3   1 \n",
      "[-0.3889217   0.4008963   0.24809062  0.4233085   0.41370896  0.2758436 ] 3   5 \n",
      "[-0.3887522   0.40144938  0.24849534  0.42396793  0.41276422  0.27568272] 3   1 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.38912472  0.40132242  0.24888939  0.42398146  0.41231555  0.27542531] 3   1 \n",
      "[-0.39082903  0.39913017  0.25223216  0.4234225   0.41256964  0.2766271 ] 3   3 Match 99\n",
      "\n",
      "[-0.39540434  0.40390775  0.25746885  0.4298588   0.41129044  0.27368546] 3   3 Match 100\n",
      "\n",
      "[-0.38828695  0.4014331   0.2501482   0.42160448  0.41283458  0.2754612 ] 3   4 \n",
      "[-0.3854636   0.4024039   0.24660918  0.42105272  0.41426322  0.2750524 ] 3   4 \n",
      "[-0.39003497  0.4004015   0.25068897  0.42479822  0.41216925  0.27606934] 3   5 \n",
      "[-0.393023    0.40056303  0.25453916  0.4240813   0.4115683   0.27802438] 3   3 Match 101\n",
      "\n",
      "[-0.39352882  0.4007529   0.2544823   0.42361864  0.4128962   0.27770868] 3   1 \n",
      "[-0.38819903  0.40195972  0.24853954  0.4253151   0.4114531   0.27597445] 3   1 \n",
      "[-0.39981082  0.40089774  0.25788465  0.43152955  0.41350672  0.27432334] 3   5 \n",
      "[-0.38668597  0.40197533  0.2506152   0.42570022  0.410245    0.27627978] 3   2 \n",
      "[-0.38959104  0.40141508  0.25072402  0.42417702  0.4115455   0.27582246] 3   3 Match 102\n",
      "\n",
      "[-0.38948828  0.4014151   0.24967834  0.42323402  0.41273937  0.2763595 ] 3   4 \n",
      "[-0.38873276  0.40157902  0.24986324  0.42305323  0.4116484   0.2766612 ] 3   1 \n",
      "[-0.3895214   0.40155682  0.24881712  0.42276344  0.41242462  0.2753155 ] 3   3 Match 103\n",
      "\n",
      "[-0.38923788  0.4010355   0.2505701   0.42494825  0.41304785  0.276669  ] 3   1 \n",
      "[-0.39851326  0.40170443  0.2546908   0.4269999   0.41368905  0.27449632] 3   3 Match 104\n",
      "\n",
      "[-0.39194065  0.40055913  0.2530526   0.4250092   0.4127285   0.27391294] 3   1 \n",
      "[-0.38986284  0.40104744  0.24970135  0.42272392  0.41321957  0.27571872] 3   3 Match 105\n",
      "\n",
      "[-0.38799798  0.40124857  0.24918097  0.42488298  0.41156322  0.27674577] 3   2 \n",
      "[-0.38785946  0.40160614  0.24819058  0.42462546  0.411901    0.27624562] 3   5 \n",
      "[-0.39000311  0.40110373  0.24900243  0.42462906  0.41299242  0.2762277 ] 3   1 \n",
      "[-0.38895184  0.4016912   0.24825948  0.4240829   0.4129487   0.2762341 ] 3   3 Match 106\n",
      "\n",
      "[-0.39455664  0.4018791   0.26143104  0.4304546   0.40912244  0.27579567] 3   3 Match 107\n",
      "\n",
      "[-0.38912725  0.40123838  0.24936777  0.42471203  0.41139165  0.27506432] 3   3 Match 108\n",
      "\n",
      "[-0.38866088  0.40113184  0.257525    0.432728    0.40722498  0.2756987 ] 3   3 Match 109\n",
      "\n",
      "[-0.3885074   0.40180746  0.24834928  0.42387202  0.41221872  0.27591658] 3   4 \n",
      "[-0.38802817  0.40194193  0.25091323  0.4256384   0.41056845  0.27566448] 3   3 Match 110\n",
      "\n",
      "[-0.38985956  0.40264672  0.25048462  0.42430058  0.41214576  0.27576634] 3   3 Match 111\n",
      "\n",
      "[-0.3898782   0.40236285  0.2504561   0.42495432  0.41162246  0.27462867] 3   5 \n",
      "[-0.3904493   0.40128127  0.250372    0.4251955   0.4118948   0.2767825 ] 3   4 \n",
      "[-0.3893466   0.40313363  0.25443503  0.4275137   0.40936142  0.27549562] 3   5 \n",
      "[-0.3889141   0.40241832  0.247543    0.42274612  0.413317    0.27526036] 3   1 \n",
      "[-0.3880547   0.40148678  0.24899355  0.42326996  0.41206044  0.27521574] 3   2 \n",
      "[-0.39593965  0.40335953  0.25714687  0.42679763  0.414247    0.27713916] 3   4 \n",
      "[-0.3890158   0.40201572  0.2517298   0.4237208   0.41195148  0.27582455] 3   2 \n",
      "[-0.38803786  0.40030733  0.2523921   0.42524275  0.40977722  0.27531812] 3   2 \n",
      "[-0.39115545  0.40081468  0.25196922  0.42623407  0.4119805   0.2758324 ] 3   3 Match 112\n",
      "\n",
      "[-0.39128596  0.40002924  0.25062996  0.42472067  0.412701    0.27575308] 3   5 \n",
      "[-0.387701    0.401641    0.24745843  0.4249507   0.4123085   0.27583036] 3   2 \n",
      "[-0.3884341   0.40028498  0.2513689   0.42551067  0.41101596  0.27671212] 3   0 \n",
      "[-0.4042749   0.40650442  0.2582079   0.42519104  0.41070884  0.27618954] 3   4 \n",
      "[-0.395118    0.40247923  0.256265    0.42925507  0.4110973   0.2751557 ] 3   1 \n",
      "[-0.3875847   0.40162545  0.24959213  0.42510068  0.41147473  0.27597165] 3   1 \n",
      "[-0.38810894  0.40230674  0.24901372  0.42491093  0.41107967  0.2751617 ] 3   0 \n",
      "[-0.39032358  0.40050587  0.25370154  0.42464873  0.41278392  0.27747837] 3   3 Match 113\n",
      "\n",
      "[-0.3904151   0.3999344   0.25071165  0.42503685  0.41301262  0.27671483] 3   4 \n",
      "[-0.38794634  0.4016898   0.25090793  0.42505577  0.40993154  0.27580252] 3   0 \n",
      "[-0.38932547  0.40118024  0.24935171  0.42421207  0.41352305  0.27672708] 3   4 \n",
      "[-0.3897214   0.40090358  0.24995852  0.42595476  0.41160244  0.27596757] 3   3 Match 114\n",
      "\n",
      "[-0.38119733  0.40413815  0.24469498  0.42140475  0.41401082  0.27008975] 3   5 \n",
      "[-0.3892012   0.40165818  0.24847236  0.42448655  0.41253197  0.2758864 ] 3   1 \n",
      "[-0.3908661   0.40252054  0.25110868  0.42519027  0.4114077   0.2751882 ] 3   3 Match 115\n",
      "\n",
      "[-0.39254925  0.4015284   0.2517284   0.42562884  0.41223773  0.27617717] 3   5 \n",
      "[-0.3885831   0.40153497  0.24834484  0.42449093  0.41233033  0.2766039 ] 3   3 Match 116\n",
      "\n",
      "[-0.3864094   0.40165633  0.24527004  0.42467836  0.41225395  0.27612618] 3   1 \n",
      "[-0.3913236   0.39998168  0.2526416   0.425559    0.4127897   0.2766225 ] 3   4 \n",
      "[-0.38611358  0.4026552   0.24964926  0.42901522  0.4080309   0.27476943] 3   3 Match 117\n",
      "\n",
      "[-0.3922763   0.40033582  0.2605554   0.42873982  0.40780616  0.27264968] 3   3 Match 118\n",
      "\n",
      "[-0.38768664  0.4018502   0.24739012  0.42354396  0.41316098  0.27578413] 3   3 Match 119\n",
      "\n",
      "[-0.39046034  0.40137494  0.24903426  0.42279327  0.41463202  0.27634186] 3   5 \n",
      "[-0.39557147  0.40149277  0.25117743  0.42314067  0.4138181   0.27359235] 3   1 \n",
      "[-0.3874834   0.40189925  0.24775317  0.424615    0.41173512  0.275906  ] 3   1 \n",
      "[-0.39019865  0.40182158  0.24938938  0.42229682  0.41398603  0.2753547 ] 3   4 \n",
      "[-0.38897276  0.4014732   0.24984708  0.42423072  0.41284806  0.27668962] 3   5 \n",
      "[-0.3854019   0.4028273   0.2559396   0.4272868   0.41122878  0.26716238] 3   3 Match 120\n",
      "\n",
      "[-0.38705108  0.40178114  0.2479797   0.42589793  0.41171694  0.2764664 ] 3   5 \n",
      "[-0.3959306   0.4035345   0.2580812   0.43372598  0.41048595  0.274131  ] 3   1 \n",
      "[-0.39029905  0.4013974   0.24900165  0.42330584  0.41429576  0.27591762] 3   5 \n",
      "[-0.38677374  0.401321    0.25579253  0.42652777  0.40574282  0.27777064] 3   1 \n",
      "[-0.38680637  0.4025922   0.25075105  0.42652187  0.40994564  0.27625626] 3   3 Match 121\n",
      "\n",
      "[-0.38985845  0.40193263  0.25056702  0.42463946  0.41206583  0.27460676] 3   5 \n",
      "[-0.38895124  0.40169385  0.24263078  0.42088994  0.41562527  0.27582684] 3   4 \n",
      "[-0.38627416  0.4034235   0.25310862  0.42821145  0.41151273  0.2669818 ] 3   1 \n",
      "[-0.38800386  0.40198317  0.24796373  0.42355487  0.41175076  0.27568486] 3   5 \n",
      "[-0.39607465  0.4009637   0.25247648  0.4231536   0.41470322  0.2743517 ] 3   2 \n",
      "[-0.38992083  0.4013965   0.25001937  0.42637396  0.41052356  0.2757627 ] 3   3 Match 122\n",
      "\n",
      "[-0.39299804  0.39936927  0.25359228  0.42482778  0.41219652  0.2766021 ] 3   3 Match 123\n",
      "\n",
      "[-0.39552248  0.40258622  0.2578328   0.42491555  0.41030934  0.27557543] 3   5 \n",
      "[-0.38857022  0.40044573  0.25242218  0.42644215  0.4130783   0.27700046] 3   5 \n",
      "[-0.38784093  0.40178758  0.248454    0.42433628  0.41133156  0.27598312] 3   2 \n",
      "[-0.3892134   0.4013901   0.24903709  0.42427665  0.41290194  0.27554727] 3   0 \n",
      "[-0.39794195  0.40028155  0.25897887  0.4307063   0.40873656  0.27411565] 3   1 \n",
      "[-0.38844007  0.40075302  0.24791011  0.424154    0.41213772  0.27511925] 3   1 \n",
      "[-0.39141893  0.4001553   0.25236142  0.42534742  0.41228527  0.2769869 ] 3   3 Match 124\n",
      "\n",
      "[-0.38949978  0.40097764  0.25209823  0.42529166  0.41086122  0.27822363] 3   1 \n",
      "[-0.3946768   0.4016252   0.2509218   0.42341885  0.4134265   0.27419135] 3   0 \n",
      "[-0.38830775  0.40254682  0.24836543  0.424359    0.41181153  0.2758604 ] 3   2 \n",
      "[-0.38564232  0.40313667  0.24646327  0.42483565  0.4119636   0.27413687] 3   5 \n",
      "[-0.38674223  0.4015934   0.2507113   0.42803288  0.40859222  0.2769749 ] 3   3 Match 125\n",
      "\n",
      "[-0.39339963  0.40226382  0.25228295  0.4235695   0.41289094  0.27517048] 3   5 \n",
      "[-0.3890327   0.40133405  0.2497395   0.4248838   0.41154855  0.27650863] 3   3 Match 126\n",
      "\n",
      "[-0.38899088  0.40097284  0.25086743  0.42409307  0.4128915   0.27739596] 3   2 \n",
      "[-0.39035946  0.4005841   0.250363    0.4251134   0.41239542  0.27673757] 3   1 \n",
      "[-0.38805956  0.40169275  0.24782968  0.42517304  0.41163164  0.27587193] 3   3 Match 127\n",
      "\n",
      "[-0.38947207  0.40159035  0.24968529  0.42382535  0.41253302  0.27461052] 3   0 \n",
      "[-0.39447308  0.40119532  0.25683448  0.42851415  0.41256276  0.2753988 ] 3   5 \n",
      "[-0.39927343  0.40020096  0.2609348   0.42829287  0.4109575   0.2759463 ] 3   4 \n",
      "[-0.39120772  0.4010987   0.25138494  0.42420986  0.4121443   0.27640447] 3   2 \n",
      "[-0.38977814  0.40186158  0.24865624  0.42349026  0.41256052  0.27585858] 3   1 \n",
      "[-0.39055392  0.4013154   0.25073186  0.4239222   0.4121844   0.2760534 ] 3   3 Match 128\n",
      "\n",
      "[-0.38851     0.40062934  0.2514233   0.42459235  0.41099903  0.27732545] 3   1 \n",
      "[-0.38559964  0.40374756  0.25275597  0.42878816  0.41087234  0.26606777] 3   1 \n",
      "[-0.38967752  0.400801    0.25089785  0.42569694  0.41067737  0.27387276] 3   2 \n",
      "[-0.39205572  0.40078574  0.25558236  0.42659906  0.41103202  0.27711782] 3   3 Match 129\n",
      "\n",
      "[-0.38832927  0.40053117  0.24844599  0.42330864  0.41412148  0.27548996] 3   3 Match 130\n",
      "\n",
      "[-0.38800624  0.40177932  0.24950862  0.42526636  0.41110942  0.27688736] 3   2 \n",
      "[-0.38584435  0.40427935  0.2540782   0.43477878  0.4084591   0.267365  ] 3   2 \n",
      "[-0.38883772  0.40167654  0.25089663  0.425035    0.4108986   0.27623457] 3   1 \n",
      "[-0.38723418  0.40141508  0.2561821   0.42578813  0.40908092  0.2670166 ] 3   5 \n",
      "[-0.39034426  0.4009003   0.25472268  0.42721045  0.41074985  0.2775772 ] 3   5 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.39011267  0.40053636  0.25219545  0.42576644  0.4104263   0.27698946] 3   1 \n",
      "[-0.39019445  0.40085173  0.24918744  0.42349377  0.4138037   0.27609733] 3   1 \n",
      "[-0.39094633  0.4028657   0.25082222  0.42744496  0.41338694  0.27282152] 3   0 \n",
      "[-0.38893408  0.4003696   0.2492167   0.42386082  0.41327736  0.2765179 ] 3   1 \n",
      "[-0.38984135  0.40057793  0.2492621   0.42369512  0.41381693  0.2766786 ] 3   3 Match 131\n",
      "\n",
      "[-0.3914905   0.4028566   0.2572035   0.42614785  0.41064367  0.2760377 ] 3   4 \n",
      "[-0.3939096   0.40149307  0.25204238  0.42551926  0.41468933  0.27571142] 3   1 \n",
      "[-0.38685095  0.40127757  0.24893484  0.42501086  0.41004294  0.27640212] 3   3 Match 132\n",
      "\n",
      "[-0.38139752  0.40298638  0.2453002   0.421384    0.41409767  0.27097398] 3   5 \n",
      "[-0.38984132  0.4005998   0.24835321  0.42329615  0.41400558  0.27634293] 3   3 Match 133\n",
      "\n",
      "[-0.38985598  0.4009111   0.24991     0.4224817   0.41425306  0.27602386] 3   3 Match 134\n",
      "\n",
      "[-0.38358262  0.40254912  0.24687728  0.42178413  0.41406637  0.2726361 ] 3   0 \n",
      "[-0.38991654  0.4009137   0.25050133  0.42364094  0.41303208  0.27592623] 3   1 \n",
      "[-0.4025201   0.40280327  0.26836374  0.43031082  0.41009325  0.2787024 ] 3   2 \n",
      "[-0.39224797  0.4008323   0.2595095   0.42783573  0.41131735  0.2753106 ] 3   2 \n",
      "[-0.3865049   0.40320677  0.2494643   0.42383346  0.41223064  0.2743491 ] 3   4 \n",
      "[-0.3868964   0.40190974  0.24705228  0.4248036   0.41144451  0.2759113 ] 3   3 Match 135\n",
      "\n",
      "[-0.39028665  0.40398502  0.2525083   0.4247053   0.41613245  0.2707515 ] 3   4 \n",
      "[-0.38898736  0.40131027  0.24984875  0.42542547  0.4112291   0.27514988] 3   2 \n",
      "[-0.3902181   0.4031833   0.2532008   0.42396075  0.41506687  0.2711216 ] 3   2 \n",
      "[-0.38502613  0.40374947  0.25132734  0.4244201   0.4116642   0.27059308] 3   1 \n",
      "[-0.38800654  0.40311658  0.24784899  0.42390352  0.4121936   0.27578244] 3   0 \n",
      "[-0.39206982  0.40078154  0.25268832  0.42489886  0.4128573   0.27487746] 3   1 \n",
      "[-0.38966042  0.40141088  0.24917945  0.42431965  0.41287157  0.2773056 ] 3   1 \n",
      "[-0.39637896  0.40037954  0.2540651   0.4248899   0.4134621   0.2747446 ] 3   2 \n",
      "[-0.38504362  0.40188918  0.24805123  0.4228871   0.41286024  0.2749575 ] 3   5 \n",
      "[-0.39000028  0.40185067  0.24882719  0.42392242  0.41259465  0.27624944] 3   3 Match 136\n",
      "\n",
      "[-0.38967425  0.40235206  0.2494365   0.42249995  0.41326344  0.27646586] 3   2 \n",
      "[-0.39095718  0.40118194  0.25558028  0.4267881   0.40927657  0.27801415] 3   2 \n",
      "[-0.38748866  0.4011473   0.24763986  0.42540675  0.41090947  0.27565113] 3   0 \n",
      "[-0.3949678   0.4018901   0.25427523  0.4251418   0.4128759   0.27417055] 3   3 Match 137\n",
      "\n",
      "[-0.3858041   0.40024322  0.2504709   0.42577314  0.41118017  0.27800956] 3   2 \n",
      "[-0.3873036   0.4019962   0.24968082  0.424592    0.41120845  0.27526745] 3   3 Match 138\n",
      "\n",
      "[-0.38907707  0.40114462  0.24745628  0.4231254   0.41383463  0.27616444] 3   0 \n",
      "[-0.38977712  0.40097874  0.2495341   0.42350754  0.41313982  0.27616194] 3   1 \n",
      "[-0.38695925  0.40131587  0.2501516   0.4271029   0.40886098  0.2764512 ] 3   4 \n",
      "[-0.38930696  0.4005677   0.2510824   0.42446065  0.41226092  0.27773616] 3   3 Match 139\n",
      "\n",
      "[-0.38652343  0.4015318   0.2522625   0.4236832   0.41086918  0.27618802] 3   1 \n",
      "[-0.39014423  0.40127623  0.25392392  0.42462963  0.4119219   0.27558586] 3   2 \n",
      "[-0.38995707  0.40217817  0.25323528  0.4252544   0.41094944  0.27710798] 3   5 \n",
      "[-0.38901335  0.40085065  0.24988386  0.42491248  0.41269305  0.2759282 ] 3   2 \n",
      "[-0.40223646  0.40645322  0.25837052  0.43178755  0.41428238  0.27245697] 3   4 \n",
      "[-0.38756382  0.4019124   0.2500473   0.42356881  0.4135777   0.27479652] 3   3 Match 140\n",
      "\n",
      "[-0.38883635  0.4017432   0.2498486   0.422858    0.41268015  0.27592558] 3   3 Match 141\n",
      "\n",
      "[-0.38880497  0.4007062   0.25044194  0.42395288  0.41315857  0.27682576] 3   1 \n",
      "[-0.38809925  0.40159518  0.24774975  0.42332402  0.41297135  0.27483314] 3   3 Match 142\n",
      "\n",
      "[-0.38830328  0.40201578  0.24929005  0.425447    0.41084465  0.27589166] 3   3 Match 143\n",
      "\n",
      "[-0.38925034  0.40038466  0.25174525  0.4258613   0.41255364  0.2771853 ] 3   4 \n",
      "[-0.39026713  0.40123573  0.250344    0.4245058   0.4116958   0.27718917] 3   1 \n",
      "[-0.3904946   0.40013576  0.25148717  0.42317235  0.41275203  0.27620047] 3   5 \n",
      "[-0.38997358  0.4015863   0.24873465  0.4229171   0.41349003  0.2754042 ] 3   3 Match 144\n",
      "\n",
      "[-0.38998246  0.40006056  0.25103223  0.4247782   0.41308558  0.2770616 ] 3   1 \n",
      "[-0.38961917  0.40070966  0.24859259  0.423743    0.41369525  0.27587008] 3   4 \n",
      "[-0.3896014   0.40143898  0.24932018  0.42456466  0.412215    0.27600145] 3   5 \n",
      "[-0.39054382  0.40197676  0.25171366  0.4261242   0.41139087  0.2777367 ] 3   5 \n",
      "[-0.39025676  0.40079546  0.2505364   0.42359525  0.41338682  0.27610508] 3   3 Match 145\n",
      "\n",
      "[-0.3891067   0.40083963  0.24859071  0.4233949   0.41317597  0.2770321 ] 3   3 Match 146\n",
      "\n",
      "[-0.389122    0.40082625  0.2490361   0.42332587  0.41341197  0.27573293] 3   3 Match 147\n",
      "\n",
      "[-0.39029032  0.40105298  0.24797568  0.42358324  0.41391268  0.27597708] 3   2 \n",
      "[-0.39023593  0.4003186   0.24858984  0.42426106  0.41362628  0.27585968] 3   4 \n",
      "[-0.38874707  0.40144667  0.25000665  0.42480952  0.41149232  0.27599165] 3   5 \n",
      "[-0.38956392  0.4015736   0.2485641   0.42445335  0.4124805   0.27561828] 3   1 \n",
      "[-0.4006171   0.40161657  0.2601038   0.42511898  0.41177934  0.278608  ] 3   2 \n",
      "[-0.38897437  0.40149397  0.24809745  0.42443678  0.4128822   0.27593333] 3   4 \n",
      "[-0.38732186  0.4019852   0.24715838  0.4261626   0.41092464  0.2767564 ] 3   3 Match 148\n",
      "\n",
      "[-0.39129043  0.4012704   0.25143826  0.42522395  0.41218436  0.2768138 ] 3   5 \n",
      "[-0.392117    0.40101627  0.25411996  0.42663965  0.41174653  0.27815074] 3   0 \n",
      "[-0.39210454  0.40315545  0.25562614  0.42618006  0.41168538  0.27054822] 3   0 \n",
      "[-0.38104597  0.40266237  0.25133267  0.43232504  0.4045094   0.27772823] 3   1 \n",
      "[-0.3872667   0.4020467   0.25306842  0.42622292  0.4121447   0.26745576] 3   1 \n",
      "[-0.3931061   0.40428466  0.25276533  0.4260191   0.41338736  0.27302966] 3   4 \n",
      "[-0.39004844  0.40070534  0.24795863  0.42388007  0.41345602  0.27646512] 3   5 \n",
      "[-0.39096326  0.4007203   0.25151435  0.4244203   0.41239476  0.27614078] 3   0 \n",
      "[-0.3884878   0.4017713   0.24989536  0.42353964  0.41334888  0.275318  ] 3   4 \n",
      "[-0.38789672  0.40194988  0.24866739  0.4261914   0.41151792  0.27623507] 3   2 \n",
      "[-0.38860804  0.40080363  0.2480979   0.42342937  0.41318697  0.27656952] 3   4 \n",
      "[-0.38783878  0.4005707   0.24916944  0.42324156  0.41235718  0.27762875] 3   2 \n",
      "[-0.38776875  0.4014116   0.24788207  0.422666    0.4126214   0.2754852 ] 3   2 \n",
      "[-0.3880624   0.40282264  0.2515264   0.4272965   0.4097199   0.27634886] 3   2 \n",
      "[-0.38933352  0.40082768  0.24996635  0.42364034  0.41239592  0.27531233] 3   0 \n",
      "[-0.38997683  0.40214673  0.24980599  0.43005309  0.41326517  0.27439746] 3   2 \n",
      "[-0.39020815  0.40215713  0.24898297  0.42244974  0.41455275  0.2756968 ] 3   2 \n",
      "[-0.40023315  0.4049194   0.26727912  0.42957535  0.41083175  0.2737419 ] 3   1 \n",
      "[-0.38864815  0.40255958  0.2531695   0.42495158  0.41118702  0.27478924] 3   4 \n",
      "[-0.38704383  0.40107167  0.24979532  0.42780763  0.4096748   0.2771617 ] 3   2 \n",
      "[-0.38674226  0.40210935  0.2539646   0.42650792  0.41106507  0.27292255] 3   3 Match 149\n",
      "\n",
      "[-0.39006266  0.40140495  0.25021222  0.42569497  0.41091594  0.27639034] 3   3 Match 150\n",
      "\n",
      "[-0.38915822  0.40247965  0.25283036  0.42298838  0.4098213   0.2714911 ] 3   4 \n",
      "[-0.3886163   0.4015444   0.25024053  0.4264923   0.4108717   0.276085  ] 3   2 \n",
      "[-0.38905114  0.4009301   0.25179377  0.4246606   0.40946275  0.27647498] 3   2 \n",
      "[-0.38943613  0.40210694  0.2487602   0.42383334  0.41276258  0.27625778] 3   3 Match 151\n",
      "\n",
      "[-0.38674843  0.40063974  0.25118732  0.427075    0.4089956   0.27595234] 3   2 \n",
      "[-0.3887393   0.4030384   0.25672123  0.4294792   0.40818313  0.27518302] 3   4 \n",
      "[-0.38935453  0.40088248  0.25282192  0.4251087   0.41048676  0.27491584] 3   3 Match 152\n",
      "\n",
      "[-0.38916153  0.40090194  0.24880025  0.42378396  0.41255116  0.27495658] 3   1 \n",
      "[-0.39522418  0.4015396   0.25279337  0.42560586  0.4135723   0.27635637] 3   5 \n",
      "[-0.38936794  0.40156874  0.25163135  0.4244549   0.41078252  0.2765635 ] 3   3 Match 153\n",
      "\n",
      "[-0.39443892  0.40180978  0.25579733  0.42643824  0.4120678   0.2758765 ] 3   4 \n",
      "[-0.3893453   0.4006626   0.25263286  0.42545786  0.4106782   0.27866936] 3   5 \n",
      "[-0.3881926   0.40235028  0.2510933   0.42632398  0.409352    0.27681395] 3   2 \n",
      "[-0.3902381   0.40220827  0.2557937   0.4288118   0.41034704  0.27434257] 3   3 Match 154\n",
      "\n",
      "[-0.38747036  0.40053147  0.2522336   0.4249967   0.4121515   0.2755404 ] 3   5 \n",
      "[-0.3886109   0.40144587  0.25116056  0.42523447  0.4102617   0.27435333] 3   2 \n",
      "[-0.3898958   0.40212247  0.25533974  0.42903826  0.40859127  0.27592435] 3   5 \n",
      "[-0.3962609   0.40150467  0.25307125  0.42705965  0.41409016  0.2799313 ] 3   4 \n",
      "[-0.38954625  0.401595    0.25124487  0.42478627  0.41051066  0.27741644] 3   2 \n",
      "[-0.3886488   0.40293726  0.24753892  0.4242084   0.41146606  0.2754268 ] 3   3 Match 155\n",
      "\n",
      "[-0.389811    0.3993433   0.2586261   0.42736694  0.41113928  0.27656174] 3   0 \n",
      "[-0.38929343  0.4017238   0.24875638  0.4231496   0.41322464  0.27522957] 3   2 \n",
      "[-0.3906135   0.40101093  0.24902695  0.4233254   0.4138574   0.2762591 ] 3   5 \n",
      "[-0.38716474  0.40197268  0.24673596  0.42485955  0.41079473  0.27650318] 3   5 \n",
      "[-0.38985562  0.4006009   0.24956992  0.42436236  0.41370857  0.27629602] 3   3 Match 156\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.3935634   0.4013354   0.2524794   0.42674723  0.41210675  0.27579093] 3   2 \n",
      "[-0.38922974  0.40018848  0.24919719  0.423855    0.4141416   0.27631524] 3   4 \n",
      "[-0.3887152   0.40125787  0.24894646  0.42402253  0.413437    0.2770795 ] 3   1 \n",
      "[-0.3898268   0.40135136  0.24928197  0.4238211   0.41276896  0.27576914] 3   4 \n",
      "[-0.3881405   0.4021667   0.2508164   0.42433214  0.4111107   0.2741894 ] 3   3 Match 157\n",
      "\n",
      "[-0.39896396  0.40025634  0.2607265   0.4267858   0.4129572   0.2760831 ] 3   3 Match 158\n",
      "\n",
      "[-0.38862413  0.40020713  0.24809465  0.42398518  0.4138568   0.2767599 ] 3   1 \n",
      "[-0.38835597  0.40064093  0.24841002  0.42405096  0.41416663  0.27650985] 3   4 \n",
      "[-0.38547072  0.40328646  0.25052103  0.42430237  0.4119205   0.27206367] 3   5 \n",
      "[-0.3900069   0.40175384  0.24868289  0.42324814  0.41375107  0.27598315] 3   2 \n",
      "[-0.3946938   0.40085506  0.25259537  0.4243776   0.41339934  0.2761461 ] 3   0 \n",
      "[-0.3887987   0.40180314  0.24913716  0.42385095  0.4124328   0.27464637] 3   1 \n",
      "[-0.39378545  0.40166882  0.25695032  0.4259772   0.41282204  0.27224067] 3   3 Match 159\n",
      "\n",
      "[-0.38760507  0.40209344  0.24871024  0.42485547  0.41125205  0.27561274] 3   3 Match 160\n",
      "\n",
      "[-0.39177865  0.4005788   0.25273177  0.42411605  0.41312966  0.2761482 ] 3   2 \n",
      "[-0.39183146  0.40216133  0.25236338  0.42339537  0.4133312   0.27545726] 3   5 \n",
      "[-0.3893778   0.4009935   0.24793589  0.42425     0.41205364  0.27542913] 3   2 \n",
      "[-0.38888785  0.4022831   0.25211194  0.4241911   0.41120398  0.27748016] 3   5 \n",
      "[-0.39063781  0.40043873  0.24866062  0.4229146   0.41349292  0.2759539 ] 3   3 Match 161\n",
      "\n",
      "[-0.38800967  0.4017715   0.24900839  0.4242015   0.4111247   0.27619794] 3   4 \n",
      "[-0.38863915  0.40221566  0.24878636  0.4246904   0.41172034  0.27527004] 3   2 \n",
      "[-0.39816877  0.4036398   0.25952017  0.42668578  0.4130891   0.27556607] 3   4 \n",
      "[-0.3875395   0.40230396  0.24736914  0.42412642  0.41176462  0.2758315 ] 3   2 \n",
      "[-0.39239377  0.40107405  0.25503722  0.42455688  0.41053045  0.27648884] 3   4 \n",
      "[-0.39205652  0.40129948  0.25468317  0.4268196   0.41103217  0.27642936] 3   4 \n",
      "[-0.3905173   0.4003682   0.25307485  0.42468897  0.4103025   0.27760434] 3   0 \n",
      "[-0.38723102  0.40169412  0.2462807   0.42499363  0.412013    0.27570924] 3   2 \n",
      "[-0.390068    0.40158054  0.25023654  0.42421484  0.4117765   0.27566615] 3   5 \n",
      "[-0.39096385  0.40098178  0.25229865  0.42481607  0.41318163  0.2766473 ] 3   5 \n",
      "[-0.387964    0.40075943  0.24748582  0.4251221   0.4115342   0.27618447] 3   2 \n",
      "[-0.38932407  0.4014811   0.25043824  0.4245791   0.41265988  0.27585262] 3   3 Match 162\n",
      "\n",
      "[-0.389511    0.40199882  0.24811766  0.42433533  0.41232774  0.2760456 ] 3   1 \n",
      "[-0.38674694  0.4018291   0.253571    0.42510888  0.41047838  0.2746079 ] 3   3 Match 163\n",
      "\n",
      "[-0.38808656  0.40112486  0.2551513   0.42534062  0.40911084  0.27550375] 3   3 Match 164\n",
      "\n",
      "[-0.38926166  0.40103167  0.2507303   0.42444974  0.41190797  0.27643564] 3   0 \n",
      "[-0.3877384   0.40211144  0.24905494  0.4246553   0.4109569   0.27652285] 3   2 \n",
      "[-0.3897851   0.40102097  0.24841699  0.42421886  0.4126251   0.27630675] 3   4 \n",
      "[-0.39116517  0.40140614  0.252112    0.42280766  0.41421527  0.27572313] 3   4 \n",
      "[-0.38843054  0.40005007  0.24933848  0.42409465  0.4131751   0.27784666] 3   4 \n",
      "[-0.3891571   0.4011942   0.25255537  0.4254279   0.41366976  0.2744329 ] 3   4 \n",
      "[-0.38811052  0.4007446   0.2491149   0.42468268  0.41364643  0.2766444 ] 3   3 Match 165\n",
      "\n",
      "[-0.38903922  0.40007684  0.25036156  0.42408347  0.41309795  0.27689654] 3   0 \n",
      "[-0.38846064  0.40212482  0.24786445  0.42397463  0.4123036   0.27643386] 3   5 \n",
      "[-0.383247    0.40204683  0.24307871  0.41910192  0.41680652  0.27143317] 3   2 \n",
      "[-0.38981116  0.4009981   0.25061896  0.42484048  0.41315186  0.27664623] 3   2 \n",
      "[-0.3935864   0.4007784   0.25408024  0.42667544  0.41051465  0.27927616] 3   4 \n",
      "[-0.38877347  0.40213603  0.2529522   0.4244235   0.41139916  0.27670163] 3   1 \n",
      "[-0.3902504   0.40103754  0.24956831  0.4230025   0.41264838  0.27650306] 3   4 \n",
      "[-0.38949025  0.40055117  0.24889126  0.42397347  0.41348204  0.27620712] 3   3 Match 166\n",
      "\n",
      "[-0.3877357   0.4018232   0.25268775  0.42691836  0.409782    0.2763008 ] 3   4 \n",
      "[-0.39275852  0.4030268   0.25530347  0.42675647  0.41100404  0.27452978] 3   5 \n",
      "[-0.38879633  0.4010938   0.24812454  0.4238864   0.41195622  0.27590674] 3   2 \n",
      "[-0.38719603  0.40099382  0.2510882   0.42668453  0.408852    0.27579978] 3   5 \n",
      "[-0.38571244  0.40283415  0.2494852   0.42191085  0.41410094  0.27203885] 3   3 Match 167\n",
      "\n",
      "[-0.38885084  0.40084052  0.24941546  0.4235219   0.41289276  0.27539232] 3   3 Match 168\n",
      "\n",
      "[-0.3894193   0.40143907  0.24972501  0.4250013   0.41102418  0.27614516] 3   1 \n",
      "[-0.3880964   0.39952165  0.25029024  0.42568547  0.4112517   0.2768339 ] 3   4 \n",
      "[-0.3878178   0.4001874   0.2507182   0.4252685   0.4120429   0.27697596] 3   2 \n",
      "[-0.39157808  0.40152863  0.25321135  0.42573372  0.411486    0.27617568] 3   1 \n",
      "[-0.39159247  0.40248218  0.25635928  0.4281257   0.4102772   0.27341503] 3   4 \n",
      "[-0.38971713  0.4018603   0.24977723  0.42553848  0.41120282  0.2762408 ] 3   4 \n",
      "[-0.39296165  0.40127084  0.25575802  0.42563784  0.41094008  0.27549434] 3   3 Match 169\n",
      "\n",
      "[-0.39074457  0.40196183  0.25190705  0.42481658  0.41069338  0.27725375] 3   3 Match 170\n",
      "\n",
      "[-0.3875145   0.40050265  0.25008097  0.42474365  0.41271836  0.27650657] 3   2 \n",
      "[-0.387285    0.4015606   0.2492584   0.42541942  0.41152194  0.27647114] 3   0 \n",
      "[-0.38481173  0.4033489   0.25461254  0.42936066  0.40980807  0.26944825] 3   1 \n",
      "[-0.39788365  0.3994298   0.25942114  0.42975563  0.41183978  0.2806526 ] 3   4 \n",
      "[-0.39528042  0.4024327   0.2653462   0.43130055  0.4107865   0.27526268] 3   4 \n",
      "[-0.39696538  0.40471283  0.2576711   0.4247431   0.41237244  0.27398887] 3   4 \n",
      "[-0.3899598   0.4009548   0.2503235   0.4261526   0.41128764  0.2749595 ] 3   5 \n",
      "[-0.38896966  0.4021076   0.24672571  0.4210221   0.41364405  0.27752906] 3   3 Match 171\n",
      "\n",
      "[-0.3893808   0.401519    0.2491754   0.42438534  0.41386285  0.2761043 ] 3   2 \n",
      "[-0.3901398   0.4012074   0.2502154   0.42371473  0.41445562  0.27668   ] 3   5 \n",
      "[-0.38770053  0.4011019   0.24935761  0.42381066  0.41340292  0.27585626] 3   0 \n",
      "[-0.39111048  0.40237507  0.25274438  0.42314324  0.41226345  0.2751216 ] 3   3 Match 172\n",
      "\n",
      "[-0.38999176  0.40122086  0.24949542  0.42257413  0.4133208   0.27529553] 3   0 \n",
      "[-0.39027715  0.40199798  0.2506595   0.42478463  0.41246447  0.27643412] 3   4 \n",
      "[-0.38853282  0.4013192   0.24800709  0.42364916  0.4139594   0.27679744] 3   4 \n",
      "[-0.40059292  0.40350255  0.25851414  0.42451724  0.4115789   0.27282143] 3   4 \n",
      "[-0.388447    0.402206    0.24788189  0.42372546  0.41187936  0.27531907] 3   3 Match 173\n",
      "\n",
      "[-0.3878674   0.40136445  0.25079304  0.42371285  0.41201216  0.2758417 ] 3   2 \n",
      "[-0.3882655   0.40129203  0.25378248  0.42749187  0.41184103  0.27523088] 3   5 \n",
      "[-0.38857996  0.40082288  0.249147    0.42342612  0.41318768  0.2764208 ] 3   5 \n",
      "[-0.38901228  0.40102285  0.2506717   0.42405275  0.4140373   0.27584162] 3   1 \n",
      "[-0.3888339   0.40061188  0.25215417  0.42530742  0.41068769  0.2775846 ] 3   1 \n",
      "[-0.3887925   0.40230805  0.24691954  0.42473677  0.41255385  0.27549762] 3   3 Match 174\n",
      "\n",
      "[-0.3933643   0.40153742  0.25667033  0.42800978  0.40921882  0.2741991 ] 3   2 \n",
      "[-0.38994762  0.40124542  0.25071943  0.42397118  0.41126835  0.2768664 ] 3   5 \n",
      "[-0.39362863  0.40210536  0.25591123  0.42550156  0.41466713  0.27315456] 3   2 \n",
      "[-0.39048612  0.40072238  0.24990052  0.42408058  0.41266987  0.27508616] 3   1 \n",
      "[-0.3836114   0.40300602  0.25149605  0.42529032  0.41224965  0.27319476] 3   3 Match 175\n",
      "\n",
      "[-0.38946357  0.4034508   0.25200063  0.423027    0.41418812  0.27191237] 3   3 Match 176\n",
      "\n",
      "[-0.38740546  0.40180212  0.24875537  0.42527285  0.41122785  0.27576667] 3   1 \n",
      "[-0.38908142  0.4009521   0.24901259  0.422875    0.41354313  0.2770962 ] 3   3 Match 177\n",
      "\n",
      "[-0.39156508  0.4028218   0.2572895   0.4263847   0.41002846  0.2745842 ] 3   4 \n",
      "[-0.3890011   0.4011812   0.2490789   0.42364538  0.41318306  0.27492553] 3   5 \n",
      "[-0.3913284   0.40112147  0.25879937  0.43067685  0.4089461   0.27623102] 3   4 \n",
      "[-0.3882264   0.40369722  0.25505838  0.42659506  0.41102475  0.27566263] 3   1 \n",
      "[-0.39044285  0.40040752  0.25243008  0.42514402  0.41229102  0.2771092 ] 3   3 Match 178\n",
      "\n",
      "[-0.38794398  0.40239584  0.24650142  0.42413792  0.41269472  0.2751468 ] 3   4 \n",
      "[-0.38740396  0.40188837  0.24798062  0.42662877  0.41030738  0.27673185] 3   0 \n",
      "[-0.38971028  0.40133458  0.24907774  0.4237974   0.41327932  0.27677256] 3   2 \n",
      "[-0.38887286  0.40203342  0.2468957   0.42376724  0.4135664   0.27543846] 3   1 \n",
      "[-0.38636893  0.4020772   0.24889114  0.42760223  0.40959322  0.2763301 ] 3   5 \n",
      "[-0.38739786  0.40150303  0.24868596  0.4227171   0.4131907   0.274168  ] 3   2 \n",
      "[-0.38768464  0.40166453  0.2527896   0.4230865   0.41064367  0.27278644] 3   4 \n",
      "[-0.3877834   0.40163106  0.24811798  0.42415825  0.4123792   0.27565652] 3   3 Match 179\n",
      "\n",
      "[-0.38810238  0.40037695  0.24898794  0.4245169   0.41366446  0.2774351 ] 3   4 \n",
      "[-0.38454705  0.40186897  0.2568433   0.43865946  0.40750456  0.2704672 ] 3   5 \n",
      "[-0.3888117   0.40178025  0.24754137  0.42395377  0.41352066  0.27583838] 3   1 \n",
      "[-0.3927683   0.40140927  0.25461367  0.4257365   0.4085403   0.27716184] 3   0 \n",
      "[-0.3891341   0.4003317   0.24835816  0.4238004   0.413865    0.2757929 ] 3   2 \n",
      "[-0.38932684  0.4006585   0.2518454   0.42607817  0.4122893   0.2771654 ] 3   2 \n",
      "[-0.389446    0.4014551   0.24933842  0.42371604  0.41299775  0.27665493] 3   1 \n",
      "[-0.3902526   0.40008247  0.25057915  0.42490292  0.41241422  0.2769602 ] 3   1 \n",
      "[-0.39125872  0.3999855   0.25286472  0.4264352   0.41094196  0.27613646] 3   4 \n",
      "[-0.38974464  0.40120554  0.2496356   0.42435095  0.4134983   0.27556467] 3   2 \n",
      "[-0.39021254  0.4012646   0.25227824  0.42408082  0.41058877  0.27663964] 3   1 \n",
      "[-0.38925427  0.40112916  0.2490299   0.42299268  0.4136575   0.27614918] 3   5 \n",
      "[-0.39143854  0.4018696   0.25017515  0.42488393  0.4132894   0.27612355] 3   4 \n",
      "[-0.38918135  0.40124816  0.25283524  0.42429474  0.41203764  0.27668276] 3   5 \n",
      "[-0.3887614   0.40020353  0.24995011  0.42431358  0.4126718   0.27752993] 3   3 Match 180\n",
      "\n",
      "[-0.3889294   0.40208894  0.2518076   0.42528716  0.41113922  0.2752324 ] 3   1 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.38982671  0.4007115   0.25105518  0.42555752  0.41166666  0.27683434] 3   2 \n",
      "[-0.38853258  0.40037847  0.25106665  0.4249452   0.4120942   0.277658  ] 3   2 \n",
      "[-0.39101228  0.40212595  0.2500815   0.42619926  0.41056886  0.2755557 ] 3   3 Match 181\n",
      "\n",
      "[-0.3893627   0.40280858  0.24875703  0.4255798   0.41111976  0.27701616] 3   5 \n",
      "[-0.3902392   0.40083024  0.24999508  0.4240507   0.41151315  0.276648  ] 3   1 \n",
      "[-0.38352814  0.40255144  0.24653229  0.4220446   0.41443947  0.27118307] 3   3 Match 182\n",
      "\n",
      "[-0.3929552   0.40318394  0.2523989   0.42660612  0.4121103   0.27359638] 3   3 Match 183\n",
      "\n",
      "[-0.39052153  0.40197325  0.24937978  0.42335218  0.4125215   0.27561373] 3   5 \n",
      "[-0.38617098  0.40342468  0.24795884  0.42648652  0.4105975   0.2767031 ] 3   2 \n",
      "[-0.38977242  0.40071797  0.24914137  0.42411205  0.41379425  0.27586782] 3   1 \n",
      "[-0.3894163   0.4016489   0.2493214   0.42356858  0.41248235  0.2760751 ] 3   3 Match 184\n",
      "\n",
      "[-0.3887801   0.40211433  0.24856016  0.42453444  0.4119362   0.27600145] 3   3 Match 185\n",
      "\n",
      "[-0.38683388  0.40226498  0.24860069  0.4249066   0.40986514  0.27529892] 3   5 \n",
      "[-0.39012724  0.40164083  0.24842444  0.42346254  0.4142275   0.275514  ] 3   5 \n",
      "[-0.38594934  0.40294755  0.24590436  0.4237235   0.41169974  0.27563295] 3   2 \n",
      "[-0.38846356  0.40274966  0.25391212  0.42638478  0.41124916  0.2742723 ] 3   5 \n",
      "[-0.39524275  0.40256986  0.25319108  0.4255584   0.41416335  0.27729082] 3   5 \n",
      "[-0.38629282  0.40387323  0.25121215  0.4271126   0.41021943  0.27344316] 3   3 Match 186\n",
      "\n",
      "[-0.38544676  0.40180767  0.25029513  0.42367035  0.41332048  0.27121893] 3   1 \n",
      "[-0.39157462  0.40368488  0.2553772   0.428418    0.410216    0.27530384] 3   4 \n",
      "[-0.38866124  0.40168327  0.25009683  0.42380854  0.41280994  0.27626818] 3   3 Match 187\n",
      "\n",
      "[-0.38991427  0.40142205  0.24859759  0.4234495   0.4128756   0.27654693] 3   1 \n",
      "[-0.3858465   0.40320396  0.25024983  0.42512605  0.41264862  0.2643036 ] 3   4 \n",
      "[-0.3940211   0.40089816  0.2513723   0.42493     0.41407698  0.2745239 ] 3   1 \n",
      "[-0.39333552  0.40239283  0.25508833  0.42565817  0.41332912  0.27555096] 3   5 \n",
      "[-0.39501995  0.40131792  0.26077867  0.42669848  0.4125403   0.27440125] 3   3 Match 188\n",
      "\n",
      "[-0.38776648  0.40185782  0.25020733  0.4250542   0.4124291   0.27653262] 3   4 \n",
      "[-0.38507965  0.40139562  0.24848047  0.42070705  0.4134473   0.27330494] 3   3 Match 189\n",
      "\n",
      "[-0.38843787  0.4017493   0.24959403  0.4236686   0.41200912  0.27568644] 3   1 \n",
      "[-0.39039576  0.40107107  0.2527281   0.4266185   0.41045496  0.27711278] 3   3 Match 190\n",
      "\n",
      "[-0.38806203  0.4027157   0.24833941  0.42452827  0.41330206  0.27429968] 3   4 \n",
      "[-0.3911714   0.402898    0.25296757  0.42717025  0.410403    0.27704975] 3   4 \n",
      "[-0.38852143  0.40117142  0.24832544  0.42487034  0.41095236  0.27658772] 3   5 \n",
      "[-0.38677195  0.40274048  0.24596053  0.42429265  0.41206717  0.27674553] 3   4 \n",
      "[-0.39047042  0.40121752  0.25361034  0.425694    0.41173342  0.27675235] 3   4 \n",
      "[-0.38976884  0.40060467  0.24924546  0.42390507  0.4143477   0.2767363 ] 3   5 \n",
      "[-0.38812536  0.40039763  0.24890813  0.4239594   0.41381443  0.27601847] 3   5 \n",
      "[-0.38725558  0.39985132  0.2489723   0.42384532  0.4130821   0.2774348 ] 3   4 \n",
      "[-0.38918886  0.40235502  0.25140914  0.42280233  0.4124579   0.27461523] 3   5 \n",
      "[-0.3894608   0.40141022  0.25076738  0.42434928  0.41277468  0.27681193] 3   4 \n",
      "[-0.391356    0.40177768  0.25110802  0.42418194  0.41264397  0.27743402] 3   3 Match 191\n",
      "\n",
      "[-0.38693064  0.40165982  0.24706435  0.42583287  0.4115665   0.27598074] 3   0 \n",
      "[-0.38944298  0.4008338   0.25014415  0.4239888   0.41280264  0.27552256] 3   2 \n",
      "[-0.38983515  0.40123674  0.24891672  0.42321682  0.41423526  0.27604085] 3   4 \n",
      "[-0.38988185  0.402587    0.24853286  0.42522374  0.41173378  0.2758489 ] 3   4 \n",
      "[-0.39592466  0.4020867   0.2555359   0.42515308  0.4118231   0.27321315] 3   2 \n",
      "[-0.38874373  0.4007606   0.24961084  0.42420724  0.41348377  0.27649853] 3   3 Match 192\n",
      "\n",
      "[-0.39135084  0.4032529   0.25658575  0.42825812  0.4083914   0.2752547 ] 3   5 \n",
      "[-0.3874017   0.4018712   0.25070226  0.42494354  0.41079012  0.27555007] 3   4 \n",
      "[-0.38907436  0.4007598   0.24895665  0.42311338  0.4127222   0.2756107 ] 3   4 \n",
      "[-0.38488865  0.40112385  0.24687377  0.42015666  0.41568556  0.27263042] 3   0 \n",
      "[-0.389375    0.40153953  0.24829715  0.4249226   0.4120184   0.27690434] 3   4 \n",
      "[-0.38737738  0.40209803  0.24659541  0.42366114  0.41213533  0.27629942] 3   5 \n",
      "[-0.38668907  0.40223554  0.25068924  0.4249423   0.41335773  0.27380508] 3   1 \n",
      "[-0.39107886  0.40156108  0.25196096  0.4220533   0.41510937  0.27404842] 3   2 \n",
      "[-0.3921576   0.40033916  0.25312096  0.42538804  0.41209733  0.2761053 ] 3   2 \n",
      "[-0.38846713  0.4015599   0.2540218   0.42572528  0.4098638   0.2775806 ] 3   0 \n",
      "[-0.391105    0.39970288  0.2585572   0.42906708  0.40507063  0.2761237 ] 3   4 \n",
      "[-0.40672684  0.40148112  0.26696894  0.42900997  0.41251716  0.28407392] 3   3 Match 193\n",
      "\n",
      "[-0.38582343  0.40188372  0.25285992  0.4319801   0.4067696   0.27589098] 3   5 \n",
      "[-0.38908175  0.4014452   0.24731317  0.42394677  0.41336226  0.27626392] 3   2 \n",
      "[-0.38862672  0.40296483  0.25344977  0.43462637  0.40941334  0.2762688 ] 3   1 \n",
      "[-0.39220607  0.40213913  0.2558471   0.42588758  0.40871227  0.276157  ] 3   2 \n",
      "[-0.3851659   0.4024313   0.24669611  0.42098907  0.41416654  0.2748371 ] 3   4 \n",
      "[-0.38944075  0.40206438  0.24779457  0.42457682  0.41221604  0.27547097] 3   5 \n",
      "[-0.38604465  0.4018838   0.248575    0.42726436  0.41022032  0.27545273] 3   5 \n",
      "[-0.39130735  0.3991706   0.25465772  0.426034    0.41003013  0.27789727] 3   1 \n",
      "[-0.38753065  0.40070614  0.24893653  0.42428696  0.41326067  0.2775708 ] 3   3 Match 194\n",
      "\n",
      "[-0.3873511   0.40148607  0.24905425  0.42452058  0.41115606  0.27477074] 3   1 \n",
      "[-0.39037234  0.40151742  0.25212875  0.4266627   0.41082245  0.27543777] 3   2 \n",
      "[-0.38930115  0.4013489   0.25338086  0.42443234  0.41128987  0.2764924 ] 3   3 Match 195\n",
      "\n",
      "[-0.38787776  0.40061665  0.25460544  0.42737094  0.40994996  0.27627555] 3   1 \n",
      "[-0.38240868  0.40376198  0.24810693  0.42387152  0.4119646   0.2710858 ] 3   0 \n",
      "[-0.3898843   0.40084255  0.24872687  0.4232713   0.41397935  0.27572665] 3   5 \n",
      "[-0.3885824   0.40121347  0.24861196  0.42396966  0.41447946  0.2760149 ] 3   5 \n",
      "[-0.39023802  0.40188274  0.2479591   0.42344987  0.4133634   0.27548575] 3   1 \n",
      "[-0.3910744   0.4018877   0.25032756  0.4252566   0.41110823  0.27560648] 3   1 \n",
      "[-0.38995036  0.40115017  0.24996334  0.42376792  0.41198802  0.2759092 ] 3   0 \n",
      "[-0.38766712  0.40213963  0.2492303   0.42436567  0.41037646  0.27546084] 3   1 \n",
      "[-0.39134628  0.40207636  0.2507128   0.4238924   0.41184005  0.2743375 ] 3   3 Match 196\n",
      "\n",
      "[-0.38778853  0.40188074  0.24835786  0.4244413   0.41212797  0.27523163] 3   0 \n",
      "[-0.38659912  0.40196684  0.24775055  0.42146802  0.41347384  0.27435592] 3   4 \n",
      "[-0.38897762  0.4008119   0.25280163  0.42425     0.41266108  0.27634636] 3   4 \n",
      "[-0.38805082  0.40244177  0.24890104  0.42524353  0.41062757  0.27592415] 3   5 \n",
      "[-0.39728886  0.40068063  0.25571972  0.42574868  0.41383526  0.27699298] 3   3 Match 197\n",
      "\n",
      "[-0.3899277   0.40187857  0.2495754   0.42471644  0.4117607   0.27634755] 3   2 \n",
      "[-0.39070177  0.39924383  0.25560316  0.42904294  0.41074944  0.27716076] 3   0 \n",
      "[-0.3900467   0.4016661   0.25021768  0.42468846  0.41269705  0.27611095] 3   4 \n",
      "[-0.3989231   0.40391147  0.26465648  0.42902076  0.41411093  0.27294272] 3   2 \n",
      "[-0.3886925   0.40199548  0.2485989   0.42313513  0.4130202   0.27344483] 3   2 \n",
      "[-0.38888484  0.40221986  0.24822822  0.42446965  0.41265506  0.2752993 ] 3   2 \n",
      "[-0.38812408  0.40091908  0.2476336   0.4248413   0.41251895  0.27580333] 3   4 \n",
      "[-0.3869672   0.40349728  0.24980915  0.42543232  0.41082433  0.2752544 ] 3   5 \n",
      "[-0.38651186  0.39991963  0.24980578  0.42526323  0.41261697  0.27720484] 3   4 \n",
      "[-0.38880652  0.4012125   0.24850833  0.42389002  0.4119274   0.27561817] 3   2 \n",
      "[-0.38727272  0.40176383  0.2487581   0.424743    0.411384    0.27572477] 3   4 \n",
      "[-0.38306963  0.40292734  0.24552715  0.421519    0.4148275   0.27188355] 3   4 \n",
      "[-0.39826632  0.40400282  0.25873196  0.42881355  0.41596642  0.27499115] 3   2 \n",
      "[-0.38872302  0.4015371   0.24876544  0.4247712   0.41177675  0.2750089 ] 3   3 Match 198\n",
      "\n",
      "[-0.3888361   0.4010055   0.24887803  0.42235327  0.41420123  0.27577442] 3   2 \n",
      "[-0.3921172   0.40261677  0.2545965   0.42485675  0.41293147  0.27408606] 3   4 \n",
      "[-0.38876197  0.4018759   0.24905571  0.42317912  0.41355303  0.2766327 ] 3   3 Match 199\n",
      "\n",
      "[-0.388646    0.40124738  0.24795362  0.42329234  0.4132699   0.27650347] 3   2 \n",
      "[-0.3883499   0.40203106  0.2488192   0.42501712  0.41223913  0.27557606] 3   1 \n",
      "[-0.39005083  0.4016685   0.24911681  0.42392993  0.41325787  0.27650735] 3   4 \n",
      "[-0.38938656  0.40028816  0.24847096  0.42349598  0.4134453   0.27653936] 3   0 \n",
      "[-0.38717204  0.40182793  0.24766204  0.4262909   0.4109167   0.27533418] 3   2 \n",
      "[-0.39284936  0.40006945  0.25338998  0.42548603  0.4124757   0.27612793] 3   3 Match 200\n",
      "\n",
      "[-0.38879114  0.40086073  0.24943653  0.42308033  0.41246304  0.27574787] 3   0 \n",
      "[-0.39206216  0.40189785  0.25186154  0.42586905  0.41250733  0.27534732] 3   2 \n",
      "[-0.38914073  0.40132797  0.24961987  0.4244229   0.41233388  0.27549934] 3   1 \n",
      "[-0.39578393  0.39968857  0.25517303  0.42550522  0.41319752  0.2804743 ] 3   4 \n",
      "[-0.3928738   0.40192991  0.25373432  0.42469147  0.41321123  0.2747788 ] 3   1 \n",
      "[-0.3827431   0.40409508  0.2515392   0.4304773   0.40577844  0.27733484] 3   3 Match 201\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.39001235  0.40123755  0.24966964  0.42589846  0.41184977  0.27545932] 3   0 \n",
      "[-0.38998717  0.40096274  0.24862424  0.42295444  0.41430712  0.27521285] 3   1 \n",
      "[-0.3920279   0.40454695  0.2519864   0.42872807  0.41272134  0.2742652 ] 3   3 Match 202\n",
      "\n",
      "[-0.38894212  0.40065342  0.24763927  0.42361665  0.4136021   0.2743207 ] 3   5 \n",
      "[-0.38963416  0.40234846  0.24940667  0.42428678  0.4115178   0.2763678 ] 3   4 \n",
      "[-0.39024967  0.4005214   0.25110722  0.42328677  0.4129822   0.2766541 ] 3   4 \n",
      "[-0.39118135  0.40263128  0.250085    0.42363942  0.41256088  0.27701297] 3   0 \n",
      "[-0.38945004  0.40120792  0.24898186  0.42456535  0.4127835   0.27654848] 3   0 \n",
      "[-0.38574296  0.40359017  0.25300136  0.4282177   0.40977028  0.27510673] 3   2 \n",
      "[-0.38964906  0.39981052  0.2503352   0.42497453  0.41228312  0.27661166] 3   0 \n",
      "[-0.38895112  0.4014118   0.24778974  0.42372903  0.41183636  0.27699164] 3   2 \n",
      "[-0.39021176  0.40100336  0.2488721   0.42334694  0.41314495  0.27623892] 3   1 \n",
      "[-0.39025137  0.4010556   0.24925044  0.42347816  0.4139096   0.27467665] 3   3 Match 203\n",
      "\n",
      "[-0.39468506  0.40334472  0.25418493  0.4266667   0.414061    0.27393857] 3   3 Match 204\n",
      "\n",
      "[-0.38962024  0.40092966  0.24877778  0.4230066   0.41334957  0.27745035] 3   5 \n",
      "[-0.3879577   0.40156984  0.24878523  0.42344144  0.41261673  0.27505827] 3   3 Match 205\n",
      "\n",
      "[-0.3901767   0.40105125  0.25246015  0.42739317  0.41022697  0.27560398] 3   1 \n",
      "[-0.38795742  0.39926392  0.24935848  0.42394948  0.41281483  0.27652377] 3   0 \n",
      "[-0.39808047  0.40440285  0.2533364   0.42692837  0.41491815  0.27437952] 3   2 \n",
      "[-0.39110798  0.40219167  0.2521626   0.42478228  0.41128197  0.27635312] 3   2 \n",
      "[-0.38630185  0.4023581   0.25008783  0.42497775  0.4105904   0.27487954] 3   1 \n",
      "[-0.3885748   0.40143776  0.24841511  0.42351902  0.412909    0.27570823] 3   5 \n",
      "[-0.3896209   0.4017385   0.24780348  0.4228128   0.41385055  0.2777652 ] 3   2 \n",
      "[-0.38722813  0.4016265   0.24907902  0.42564806  0.4106523   0.27528366] 3   1 \n",
      "[-0.40383852  0.40060824  0.26573065  0.42858726  0.41322222  0.27923518] 3   4 \n",
      "[-0.38889706  0.40144482  0.24818334  0.4235039   0.41282898  0.27503914] 3   1 \n",
      "[-0.39020324  0.40174124  0.24914655  0.4239126   0.4130448   0.2759556 ] 3   1 \n",
      "[-0.38753596  0.40034318  0.25060353  0.42639396  0.41055027  0.27554944] 3   4 \n",
      "[-0.3895888   0.40045878  0.25011536  0.42488533  0.41252306  0.27564305] 3   3 Match 206\n",
      "\n",
      "[-0.3838571   0.40332058  0.25048435  0.42388272  0.41258872  0.27114275] 3   4 \n",
      "[-0.3883203   0.4002053   0.2545654   0.42739886  0.41105604  0.27565846] 3   4 \n",
      "[-0.38817555  0.40223294  0.24822953  0.42464393  0.4119753   0.27527052] 3   2 \n",
      "[-0.39143997  0.40116617  0.25243396  0.42701334  0.41017243  0.27629906] 3   4 \n",
      "[-0.38766533  0.40169758  0.25032467  0.42433316  0.41297522  0.27380148] 3   4 \n",
      "[-0.3933862   0.40084314  0.25673914  0.4256086   0.4135491   0.2738309 ] 3   4 \n",
      "[-0.38912198  0.40185675  0.25144115  0.42577597  0.4113004   0.27664736] 3   5 \n",
      "[-0.3880586   0.40252256  0.25153604  0.4318762   0.4072438   0.27642804] 3   5 \n",
      "[-0.38964292  0.40136343  0.25550196  0.42541456  0.41006866  0.27530098] 3   0 \n",
      "[-0.39438653  0.3996541   0.25603074  0.42796916  0.41272253  0.27207306] 3   5 \n",
      "[-0.38995188  0.40036157  0.25265285  0.42509905  0.41130856  0.2765066 ] 3   3 Match 207\n",
      "\n",
      "[-0.38935655  0.40043843  0.25421607  0.42446646  0.4108748   0.27671528] 3   4 \n",
      "[-0.38872516  0.40170312  0.24914968  0.4246383   0.41191864  0.2756015 ] 3   3 Match 208\n",
      "\n",
      "[-0.38861915  0.4019847   0.25082082  0.42475906  0.41230133  0.27355173] 3   3 Match 209\n",
      "\n",
      "[-0.38994384  0.40047747  0.25044492  0.4238329   0.41387835  0.27567562] 3   4 \n",
      "[-0.3897838   0.40037122  0.24990243  0.4238563   0.41263077  0.27645662] 3   3 Match 210\n",
      "\n",
      "[-0.38931432  0.40122417  0.25068292  0.4243416   0.41123092  0.27534968] 3   1 \n",
      "[-0.38758558  0.40303025  0.24895489  0.4242123   0.41114253  0.27436188] 3   1 \n",
      "[-0.3894265   0.40051     0.2517297   0.42630234  0.40943936  0.27666047] 3   1 \n",
      "[-0.39019972  0.40187666  0.25636396  0.42705446  0.40815315  0.275414  ] 3   5 \n",
      "[-0.38997608  0.40100905  0.2488549   0.42434013  0.4133116   0.27618805] 3   0 \n",
      "[-0.38895133  0.4011708   0.24853846  0.42294756  0.4135886   0.27630302] 3   1 \n",
      "[-0.38737926  0.40191662  0.24817437  0.42585284  0.41054517  0.27600354] 3   3 Match 211\n",
      "\n",
      "[-0.3899843   0.40136847  0.24914959  0.42351174  0.41378045  0.27554893] 3   1 \n",
      "[-0.38158876  0.40204757  0.25449458  0.43810734  0.4029881   0.2693515 ] 3   1 \n",
      "[-0.38962728  0.40226206  0.24837095  0.42413095  0.41201696  0.27614635] 3   5 \n",
      "[-0.38832435  0.4005713   0.2512029   0.424993    0.41199675  0.27661029] 3   4 \n",
      "[-0.38839692  0.40152642  0.24896094  0.42396894  0.41185355  0.27624333] 3   2 \n",
      "[-0.39257663  0.40290552  0.2522739   0.42530677  0.41191882  0.27643207] 3   3 Match 212\n",
      "\n",
      "[-0.39003956  0.40139094  0.25072628  0.42452332  0.41165408  0.27678412] 3   1 \n",
      "[-0.38958567  0.40077275  0.24956834  0.42441073  0.4135843   0.2767357 ] 3   2 \n",
      "[-0.38968524  0.4014946   0.2505549   0.42353776  0.41309828  0.27554268] 3   1 \n",
      "[-0.38596866  0.40156484  0.25188926  0.42880228  0.40968743  0.27540267] 3   2 \n",
      "[-0.38655388  0.40142298  0.2503178   0.4228332   0.4132971   0.27335724] 3   4 \n",
      "[-0.38779655  0.40280282  0.25312302  0.42662302  0.41196057  0.26659083] 3   0 \n",
      "[-0.3903787   0.40235808  0.2511215   0.42502978  0.41192403  0.27515343] 3   4 \n",
      "[-0.3884086   0.40138462  0.24897462  0.4239053   0.4118485   0.2755764 ] 3   4 \n",
      "[-0.38863814  0.39948025  0.24926165  0.42330006  0.41386506  0.27623698] 3   4 \n",
      "[-0.3921557   0.40306842  0.2574445   0.42633536  0.41197947  0.27261332] 3   4 \n",
      "[-0.38812333  0.4009606   0.25317624  0.42514494  0.41133606  0.27870512] 3   5 \n",
      "[-0.38915002  0.4010434   0.24817017  0.42271408  0.41418275  0.27580407] 3   5 \n",
      "[-0.38758337  0.4016044   0.24761075  0.42509094  0.4113966   0.27712306] 3   2 \n",
      "[-0.38973165  0.40195614  0.24917325  0.42378348  0.41349232  0.2754954 ] 3   1 \n",
      "[-0.38895673  0.40241653  0.2490136   0.42467526  0.41137746  0.27587098] 3   4 \n",
      "[-0.39042458  0.40220147  0.2476809   0.4227852   0.4137167   0.27557904] 3   4 \n",
      "[-0.38766876  0.40203398  0.24948457  0.42460105  0.41276935  0.27555057] 3   3 Match 213\n",
      "\n",
      "[-0.39888048  0.40160477  0.25849104  0.42656726  0.41235343  0.2743037 ] 3   3 Match 214\n",
      "\n",
      "[-0.38842893  0.40063524  0.24853715  0.42348847  0.41317597  0.2761947 ] 3   3 Match 215\n",
      "\n",
      "[-0.39580864  0.40187627  0.25374043  0.42536724  0.41200686  0.2768466 ] 3   2 \n",
      "[-0.3898545   0.40081212  0.25028768  0.42519578  0.4118663   0.27612236] 3   3 Match 216\n",
      "\n",
      "[-0.38883433  0.40099064  0.2483967   0.42329368  0.41421336  0.27594128] 3   3 Match 217\n",
      "\n",
      "[-0.38802832  0.40217167  0.24701291  0.42398506  0.41270816  0.275323  ] 3   4 \n",
      "[-0.40448886  0.4054655   0.2647986   0.42854914  0.41254932  0.2742461 ] 3   1 \n",
      "[-0.39481783  0.40288037  0.2561054   0.42654818  0.41153082  0.2758525 ] 3   4 \n",
      "[-0.38823238  0.4022262   0.25378522  0.42693967  0.4113157   0.27607548] 3   3 Match 218\n",
      "\n",
      "[-0.38803875  0.399827    0.2503974   0.42498955  0.4124995   0.27770832] 3   5 \n",
      "[-0.38722625  0.4041753   0.25463918  0.42803946  0.41122228  0.26425713] 3   1 \n",
      "[-0.3931589   0.40051118  0.2545857   0.4254988   0.4145697   0.2751864 ] 3   1 \n",
      "[-0.39080614  0.40252313  0.25130185  0.42463532  0.41215518  0.27520245] 3   5 \n",
      "[-0.38916966  0.4019411   0.25402233  0.4266442   0.40924877  0.27443722] 3   3 Match 219\n",
      "\n",
      "[-0.3876012   0.40172115  0.25023162  0.42283475  0.41295162  0.27499834] 3   1 \n",
      "[-0.3898951   0.3999781   0.25015533  0.42402774  0.41290674  0.27593708] 3   2 \n",
      "[-0.3899008   0.40192536  0.24841976  0.4223176   0.41394377  0.27532217] 3   4 \n",
      "[-0.3862753   0.40467823  0.24988243  0.425387    0.41281566  0.2725205 ] 3   1 \n",
      "[-0.3873449   0.40155646  0.24808857  0.42378053  0.41149816  0.2755784 ] 3   1 \n",
      "[-0.3899852   0.40117908  0.25006136  0.42439663  0.41262466  0.27595058] 3   3 Match 220\n",
      "\n",
      "[-0.3800663   0.40353534  0.24450114  0.4218563   0.41387844  0.2707188 ] 3   0 \n",
      "[-0.3913604   0.401344    0.25100204  0.42468405  0.41253927  0.27524334] 3   1 \n",
      "[-0.3889833   0.40253568  0.24787423  0.42476     0.41208628  0.27595165] 3   5 \n",
      "[-0.38965818  0.40142193  0.2482301   0.42309517  0.4137149   0.27542174] 3   2 \n",
      "[-0.38351768  0.40181845  0.25035152  0.42259216  0.41192445  0.27029893] 3   3 Match 221\n",
      "\n",
      "[-0.3890819   0.40110743  0.24943611  0.42354885  0.4134274   0.27547333] 3   4 \n",
      "[-0.39589554  0.4038635   0.25734815  0.4268052   0.4110832   0.27841944] 3   2 \n",
      "[-0.39101934  0.4007902   0.25487348  0.42513725  0.41188926  0.27641997] 3   1 \n",
      "[-0.38858297  0.40123233  0.24867082  0.4238788   0.41301996  0.27574548] 3   3 Match 222\n",
      "\n",
      "[-0.3899218   0.401707    0.25073484  0.42399642  0.4138401   0.2757188 ] 3   4 \n",
      "[-0.38955855  0.4007007   0.24875727  0.42371568  0.4137012   0.27595502] 3   1 \n",
      "[-0.38838622  0.40159535  0.25158295  0.42566147  0.4106299   0.27541542] 3   3 Match 223\n",
      "\n",
      "[-0.38965425  0.40132576  0.24883583  0.4234876   0.4132981   0.27538404] 3   5 \n",
      "[-0.39578444  0.40335828  0.2542599   0.42717767  0.4139969   0.27291858] 3   1 \n",
      "[-0.38800246  0.4017396   0.25276121  0.42854077  0.408414    0.27473354] 3   1 \n",
      "[-0.38892764  0.40112734  0.247655    0.42260984  0.41458637  0.27511203] 3   0 \n",
      "[-0.38958707  0.4019794   0.24951491  0.42530802  0.4115251   0.27574578] 3   5 \n",
      "[-0.3898896   0.4018308   0.25106123  0.42443982  0.41097063  0.27716   ] 3   3 Match 224\n",
      "\n",
      "[-0.3868047   0.40114382  0.25104472  0.42343634  0.41185367  0.27544445] 3   4 \n",
      "[-0.38899463  0.40094802  0.24778917  0.42353576  0.41381964  0.27679858] 3   1 \n",
      "[-0.38904378  0.3998666   0.2498872   0.42313716  0.41449156  0.2768576 ] 3   4 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.3935848   0.3991648   0.25317553  0.42565417  0.41148365  0.27758527] 3   5 \n",
      "[-0.38675153  0.40106368  0.24952999  0.4246585   0.41261044  0.27696294] 3   2 \n",
      "[-0.38826263  0.40188104  0.25072914  0.42490262  0.41062915  0.27603087] 3   0 \n",
      "[-0.38836995  0.40125462  0.25031224  0.42205366  0.41255975  0.276327  ] 3   1 \n",
      "[-0.4054398   0.40248278  0.26937607  0.42757323  0.41196015  0.2775217 ] 3   4 \n",
      "[-0.38772228  0.4024996   0.2510586   0.4229035   0.41343385  0.2745574 ] 3   5 \n",
      "[-0.39015847  0.4011482   0.2522498   0.4253159   0.41173068  0.27602047] 3   1 \n",
      "[-0.39109293  0.40149093  0.25612718  0.42607078  0.41057763  0.27845514] 3   5 \n",
      "[-0.3890913   0.40047362  0.24844185  0.42347565  0.41300392  0.27620974] 3   3 Match 225\n",
      "\n",
      "[-0.3840959   0.40266743  0.25958386  0.4413211   0.40496188  0.26832363] 3   5 \n",
      "[-0.3893227   0.40195072  0.24926028  0.42474848  0.4117812   0.27575985] 3   1 \n",
      "[-0.39013678  0.40070087  0.24984217  0.42363718  0.41401297  0.27643782] 3   5 \n",
      "[-0.3875856   0.40190172  0.249138    0.42494422  0.41063935  0.2768786 ] 3   1 \n",
      "[-0.3884583   0.40150914  0.24929616  0.4245878   0.41161305  0.27598232] 3   4 \n",
      "[-0.39049846  0.40181693  0.24912563  0.4240314   0.41281426  0.27589774] 3   2 \n",
      "[-0.38633645  0.40143058  0.24894363  0.42600533  0.4107663   0.27534458] 3   5 \n",
      "[-0.38768306  0.4022578   0.24809107  0.42495397  0.41165972  0.27475807] 3   1 \n",
      "[-0.38964593  0.40103385  0.24878702  0.42378435  0.41315466  0.27692083] 3   5 \n",
      "[-0.3901464   0.40104118  0.24928066  0.42299163  0.41424614  0.27580824] 3   4 \n",
      "[-0.39409673  0.402303    0.25351152  0.42433292  0.41290966  0.27578774] 3   5 \n",
      "[-0.38728112  0.40186834  0.24843091  0.42529315  0.41168153  0.2760714 ] 3   4 \n",
      "[-0.387868    0.40204462  0.2507553   0.42410037  0.4129188   0.2727819 ] 3   1 \n",
      "[-0.38784325  0.40133205  0.24948776  0.4233604   0.41205716  0.27716354] 3   2 \n",
      "[-0.39967132  0.40508544  0.25550538  0.4262006   0.41570154  0.2727479 ] 3   5 \n",
      "[-0.38807103  0.39979205  0.25119063  0.42498717  0.41205382  0.27774727] 3   1 \n",
      "[-0.38900465  0.4022162   0.24831417  0.42396173  0.41349933  0.275094  ] 3   4 \n",
      "[-0.38942888  0.40228364  0.2541696   0.42862466  0.4106362   0.27461332] 3   4 \n",
      "[-0.3894899   0.40079153  0.24907967  0.424858    0.4116689   0.276199  ] 3   4 \n",
      "[-0.38958687  0.4010902   0.24978659  0.4245153   0.41284657  0.27657425] 3   5 \n",
      "[-0.38859373  0.40008697  0.2510131   0.42549142  0.412608    0.27581304] 3   3 Match 226\n",
      "\n",
      "[-0.3945853   0.40335554  0.2588231   0.4282569   0.414126    0.2740631 ] 3   5 \n",
      "[-0.38831887  0.40191805  0.2491492   0.42543703  0.41127372  0.2774254 ] 3   4 \n",
      "[-0.38870126  0.4001797   0.2493734   0.4234896   0.41410363  0.27636808] 3   4 \n",
      "[-0.3907881   0.4008887   0.24946457  0.42386708  0.41388503  0.2770172 ] 3   1 \n",
      "[-0.38629055  0.40297604  0.24718028  0.4256446   0.41109344  0.27548933] 3   0 \n",
      "[-0.39012915  0.40229878  0.24837786  0.42427734  0.4130472   0.27625728] 3   4 \n",
      "[-0.38841277  0.40225932  0.247159    0.42435965  0.41270745  0.275259  ] 3   3 Match 227\n",
      "\n",
      "[-0.38917592  0.4022961   0.25140014  0.42651144  0.4100347   0.2749844 ] 3   3 Match 228\n",
      "\n",
      "[-0.38942793  0.40156922  0.24927029  0.42389432  0.4142669   0.2757569 ] 3   1 \n",
      "[-0.39017972  0.40065998  0.24870947  0.42276862  0.4135107   0.27648965] 3   4 \n",
      "[-0.3877837   0.40154058  0.24747172  0.42504928  0.41139606  0.2755768 ] 3   2 \n",
      "[-0.38865605  0.40140375  0.24886888  0.4245245   0.41242957  0.2755683 ] 3   3 Match 229\n",
      "\n",
      "[-0.38919944  0.40058523  0.2487753   0.42386     0.41356382  0.27655306] 3   4 \n",
      "[-0.38869712  0.4007321   0.24896356  0.4238018   0.4131263   0.27782574] 3   4 \n",
      "[-0.38909304  0.4006067   0.24888545  0.42380768  0.41393468  0.2756252 ] 3   4 \n",
      "[-0.38739586  0.40193245  0.24811998  0.42656198  0.41119686  0.27668002] 3   3 Match 230\n",
      "\n",
      "[-0.3877207   0.40151823  0.2521914   0.42678344  0.40959612  0.27598727] 3   4 \n",
      "[-0.3843565   0.40266693  0.2487995   0.4234049   0.4139683   0.27134672] 3   4 \n",
      "[-0.3903088   0.40091684  0.25075403  0.4248236   0.41238275  0.27554506] 3   2 \n",
      "[-0.38923     0.40000755  0.2509495   0.42608818  0.41044113  0.2765685 ] 3   5 \n",
      "[-0.38998842  0.40286204  0.2519122   0.4300797   0.41035575  0.27418843] 3   4 \n",
      "[-0.38873622  0.40206966  0.24858952  0.4237342   0.41324967  0.27543396] 3   1 \n",
      "[-0.38724142  0.40105048  0.24932042  0.42392364  0.41307718  0.27499261] 3   1 \n",
      "[-0.39299768  0.40250087  0.2519032   0.4259914   0.41296193  0.27622047] 3   2 \n",
      "[-0.39089903  0.40127376  0.25390556  0.42533478  0.41180852  0.2737538 ] 3   5 \n",
      "[-0.38838935  0.40106297  0.25132254  0.42467093  0.411578    0.2774289 ] 3   3 Match 231\n",
      "\n",
      "[-0.3893314   0.40208626  0.2559323   0.4276947   0.41014823  0.27546325] 3   4 \n",
      "[-0.39007062  0.40023565  0.24852803  0.42365882  0.4137182   0.27664176] 3   3 Match 232\n",
      "\n",
      "[-0.38985214  0.39999798  0.25315282  0.42592305  0.41080305  0.27594241] 3   4 \n",
      "[-0.39064795  0.40097678  0.25015303  0.4242209   0.41272444  0.27511227] 3   0 \n",
      "[-0.39418924  0.40135217  0.25512674  0.42832997  0.41158065  0.27484193] 3   3 Match 233\n",
      "\n",
      "[-0.38915205  0.40184388  0.2487193   0.42419818  0.41230032  0.27530244] 3   1 \n",
      "[-0.4050923   0.40666714  0.269492    0.43297634  0.41150266  0.2759347 ] 3   4 \n",
      "[-0.38691753  0.40264428  0.24977946  0.4234672   0.41310388  0.2721118 ] 3   4 \n",
      "[-0.3881476   0.40133697  0.25510636  0.4286225   0.40883332  0.27628407] 3   4 \n",
      "[-0.38790405  0.40080136  0.25366166  0.4272982   0.40895867  0.27807066] 3   4 \n",
      "[-0.3907979   0.4018911   0.2512425   0.42437467  0.41068026  0.27559885] 3   1 \n",
      "[-0.39555082  0.39958566  0.25826028  0.42418715  0.41085178  0.27766415] 3   2 \n",
      "[-0.38967717  0.4008608   0.24868786  0.4240528   0.41325244  0.27662295] 3   1 \n",
      "[-0.3878934   0.40228236  0.24925444  0.42685473  0.41009694  0.27688268] 3   4 \n",
      "[-0.3869248   0.4027365   0.25207967  0.42318717  0.41126615  0.2728419 ] 3   1 \n",
      "[-0.3881422  0.4012758  0.2487944  0.4239705  0.4127379  0.2753825] 3   2 \n",
      "[-0.38880682  0.40216857  0.24879575  0.42535862  0.41107664  0.27660885] 3   5 \n",
      "[-0.3903122   0.40067393  0.24958342  0.4234916   0.41254747  0.27677283] 3   2 \n",
      "[-0.389459    0.40092334  0.249594    0.4228394   0.41400546  0.27637738] 3   3 Match 234\n",
      "\n",
      "[-0.39099818  0.4016923   0.25334218  0.42756632  0.41016605  0.27939004] 3   4 \n",
      "[-0.3880928   0.40129456  0.2529712   0.42674044  0.4096928   0.276343  ] 3   5 \n",
      "[-0.39005202  0.40128583  0.24969015  0.42373642  0.4128212   0.27648783] 3   0 \n",
      "[-0.40029514  0.40538985  0.2594792   0.43333524  0.41126415  0.27513158] 3   3 Match 235\n",
      "\n",
      "[-0.3915039   0.40087005  0.25252408  0.4256522   0.4126766   0.27744657] 3   5 \n",
      "[-0.40217403  0.40698075  0.2601261   0.42953858  0.41097224  0.2731241 ] 3   2 \n",
      "[-0.39187017  0.40171814  0.2512817   0.42587253  0.41117898  0.27579126] 3   3 Match 236\n",
      "\n",
      "[-0.38887298  0.4014182   0.24917865  0.4244813   0.41346622  0.2748659 ] 3   4 \n",
      "[-0.39058414  0.4010894   0.25561318  0.43109643  0.4106748   0.2752627 ] 3   5 \n",
      "[-0.39024535  0.40061015  0.2491867   0.4241918   0.4142688   0.27631512] 3   3 Match 237\n",
      "\n",
      "[-0.39150032  0.40035897  0.2521078   0.42615452  0.41145164  0.2763916 ] 3   0 \n",
      "[-0.3893922   0.40265375  0.25309983  0.42655358  0.4109953   0.27505377] 3   2 \n",
      "[-0.3898846   0.40090296  0.25079617  0.42367038  0.41389135  0.27505064] 3   1 \n",
      "[-0.38994783  0.4014864   0.2496815   0.42310995  0.41244188  0.2758784 ] 3   2 \n",
      "[-0.39184237  0.40209103  0.2511137   0.4249252   0.41397256  0.2746687 ] 3   1 \n",
      "[-0.387856    0.40198973  0.24953714  0.42453155  0.41184896  0.2754882 ] 3   5 \n",
      "[-0.38940445  0.40082222  0.24907067  0.4234197   0.41340315  0.27622104] 3   2 \n",
      "[-0.3925842   0.40074936  0.25278762  0.4249743   0.4130339   0.27564242] 3   0 \n",
      "[-0.38936293  0.40200222  0.24891824  0.42431775  0.4129572   0.276103  ] 3   2 \n",
      "[-0.3960501   0.40084666  0.25470102  0.42490223  0.41133386  0.27631778] 3   5 \n",
      "[-0.39409557  0.40005705  0.25979856  0.43127108  0.40709627  0.2810639 ] 3   3 Match 238\n",
      "\n",
      "[-0.40314782  0.4054388   0.26526845  0.441155    0.41574824  0.26458138] 3   5 \n",
      "[-0.38625225  0.40192404  0.24899366  0.42236346  0.41347292  0.27441764] 3   1 \n",
      "[-0.3886628   0.4007439   0.251154    0.42516044  0.41230923  0.2750866 ] 3   1 \n",
      "[-0.38917506  0.40097672  0.25102082  0.42693126  0.40892377  0.2764645 ] 3   5 \n",
      "[-0.38796937  0.40204096  0.24686605  0.4233224   0.41350496  0.27500692] 3   1 \n",
      "[-0.3892057   0.40213528  0.2580505   0.4294105   0.41057417  0.26535252] 3   1 \n",
      "[-0.39561325  0.4044018   0.26509276  0.437704    0.40600967  0.2683952 ] 3   3 Match 239\n",
      "\n",
      "[-0.39002937  0.4017991   0.25455934  0.42626855  0.4120455   0.27564076] 3   4 \n",
      "[-0.39860263  0.4060618   0.27982402  0.4439147   0.40281752  0.2625095 ] 3   3 Match 240\n",
      "\n",
      "[-0.38960925  0.40091673  0.2506465   0.42421922  0.4119051   0.27542463] 3   3 Match 241\n",
      "\n",
      "[-0.39074305  0.401138    0.250177    0.42349574  0.41299912  0.27600032] 3   4 \n",
      "[-0.38947847  0.4022196   0.24848494  0.42475325  0.41250002  0.27629164] 3   5 \n",
      "[-0.38249147  0.4035427   0.25094828  0.4305034   0.40592068  0.27504346] 3   5 \n",
      "[-0.38734198  0.3999166   0.2510768   0.4264522   0.41257304  0.27682018] 3   5 \n",
      "[-0.40094197  0.40013725  0.2623312   0.42873216  0.4093867   0.28236043] 3   2 \n",
      "[-0.3877939   0.40136623  0.2510214   0.42571795  0.41247976  0.27651036] 3   4 \n",
      "[-0.39062682  0.40229613  0.253566    0.42814532  0.40975457  0.274421  ] 3   2 \n",
      "[-0.3923869   0.40409702  0.25799063  0.428055    0.4101082   0.2762775 ] 3   4 \n",
      "[-0.3894339   0.40175655  0.24886605  0.42524275  0.41126812  0.275318  ] 3   4 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.38621172  0.40367767  0.25356674  0.42678756  0.4120887   0.26670545] 3   2 \n",
      "[-0.3956816   0.40122074  0.25798118  0.43029985  0.4094344   0.27510965] 3   2 \n",
      "[-0.38841546  0.401475    0.2483623   0.42463496  0.4122329   0.2761319 ] 3   2 \n",
      "[-0.39001414  0.40152174  0.25319734  0.4265112   0.4114896   0.27504084] 3   2 \n",
      "[-0.39236403  0.4009266   0.25331035  0.42759848  0.4092696   0.2775128 ] 3   3 Match 242\n",
      "\n",
      "[-0.3907447   0.40127885  0.25100598  0.42556903  0.4116531   0.27647758] 3   4 \n",
      "[-0.3879404   0.40185308  0.24764457  0.42443934  0.41210166  0.27578363] 3   0 \n",
      "[-0.3960924   0.40451705  0.2522404   0.426805    0.41471574  0.27295342] 3   3 Match 243\n",
      "\n",
      "[-0.38954484  0.4003014   0.24877188  0.42390394  0.41282913  0.27530771] 3   5 \n",
      "[-0.38930452  0.4000927   0.25086245  0.42525992  0.41180775  0.27759704] 3   3 Match 244\n",
      "\n",
      "[-0.38919324  0.4007437   0.25364056  0.4270336   0.41190717  0.27476606] 3   1 \n",
      "[-0.39380288  0.40182644  0.25663784  0.43226075  0.41278678  0.27452084] 3   4 \n",
      "[-0.38122272  0.4031525   0.24555716  0.42164987  0.41321495  0.27137968] 3   4 \n",
      "[-0.3904215   0.4013578   0.25549513  0.42637745  0.40893653  0.2771122 ] 3   3 Match 245\n",
      "\n",
      "[-0.38919824  0.40088218  0.25036168  0.4237126   0.41376826  0.27749437] 3   5 \n",
      "[-0.3932445   0.40315554  0.2537398   0.42511687  0.41259903  0.2750876 ] 3   4 \n",
      "[-0.38679594  0.40097207  0.25133684  0.42410472  0.41193336  0.275928  ] 3   4 \n",
      "[-0.3890342   0.40334836  0.2523254   0.4234189   0.41117266  0.27626613] 3   4 \n",
      "[-0.3909817   0.40154204  0.25033912  0.42403996  0.4128083   0.27523887] 3   2 \n",
      "[-0.3866626   0.40225253  0.2482607   0.42507383  0.411754    0.27569032] 3   4 \n",
      "[-0.38925764  0.40089244  0.24831     0.42444482  0.41274104  0.27663127] 3   2 \n",
      "[-0.39127865  0.40025437  0.24994984  0.42492947  0.41388777  0.27770713] 3   5 \n",
      "[-0.39042795  0.4009843   0.24979466  0.4242602   0.41163465  0.2766203 ] 3   2 \n",
      "[-0.3873378   0.40219057  0.24810001  0.42531332  0.41129202  0.27667093] 3   4 \n",
      "[-0.38996002  0.40095252  0.24866208  0.42391694  0.41260985  0.27687344] 3   2 \n",
      "[-0.389806    0.40057123  0.25017118  0.4239264   0.41249973  0.27642706] 3   5 \n",
      "[-0.39022073  0.40189967  0.24790949  0.42366752  0.4139946   0.27632627] 3   5 \n",
      "[-0.39212227  0.4014565   0.25263944  0.42511576  0.41138116  0.2755291 ] 3   2 \n",
      "[-0.3961977   0.40403202  0.25738153  0.42556527  0.41257194  0.27467713] 3   0 \n",
      "[-0.39090776  0.4006843   0.2532799   0.42605785  0.41042703  0.2770015 ] 3   1 \n",
      "[-0.38913992  0.40058264  0.24936154  0.42396706  0.41195753  0.2760332 ] 3   4 \n",
      "[-0.3925482   0.4036834   0.25269222  0.42480457  0.4117884   0.27388206] 3   2 \n",
      "[-0.3954405   0.4017985   0.25688204  0.4269105   0.41179848  0.27488858] 3   4 \n",
      "[-0.39068735  0.40091914  0.25131908  0.42442298  0.41319272  0.27662057] 3   2 \n",
      "[-0.38659018  0.40184316  0.24741998  0.4258174   0.41049096  0.2761892 ] 3   5 \n",
      "[-0.38767472  0.4008947   0.2526616   0.42471746  0.41133773  0.27618557] 3   2 \n",
      "[-0.39718878  0.40212816  0.25588414  0.42295742  0.4162303   0.27441746] 3   2 \n",
      "[-0.38904822  0.40109998  0.24800414  0.42420867  0.41189402  0.27546003] 3   1 \n",
      "[-0.38938206  0.4021641   0.24951774  0.42282385  0.41304448  0.27706575] 3   5 \n",
      "[-0.38885355  0.40185338  0.24793842  0.42303416  0.41319168  0.2754631 ] 3   4 \n",
      "[-0.3907504   0.4014043   0.24951348  0.42368546  0.41351667  0.2758797 ] 3   1 \n",
      "[-0.38972065  0.40094075  0.24936628  0.42412326  0.41327032  0.27570003] 3   2 \n",
      "[-0.39179495  0.40123037  0.2523478   0.42470875  0.41237363  0.27485305] 3   3 Match 246\n",
      "\n",
      "[-0.39081064  0.40384808  0.25294116  0.4278266   0.41199452  0.2736429 ] 3   1 \n",
      "[-0.3866061   0.40112242  0.25065866  0.42697045  0.4091538   0.2763952 ] 3   4 \n",
      "[-0.3868226   0.4005854   0.24891981  0.4237231   0.41308728  0.2751349 ] 3   2 \n",
      "[-0.38373488  0.40310222  0.24754992  0.42220846  0.41330954  0.27151117] 3   5 \n",
      "[-0.38893116  0.40126815  0.24998567  0.4245899   0.4117216   0.2746668 ] 3   5 \n",
      "[-0.38718337  0.40289122  0.253842    0.42481273  0.41151115  0.27182117] 3   2 \n",
      "[-0.3896892   0.40153593  0.25062534  0.42405224  0.41183704  0.2753953 ] 3   2 \n",
      "[-0.38588274  0.40195274  0.25191     0.4269568   0.41142002  0.27363202] 3   4 \n",
      "[-0.3953296   0.4015099   0.25426272  0.42426583  0.4120356   0.27533716] 3   4 \n",
      "[-0.3938604   0.40160522  0.25363407  0.4242694   0.4132986   0.27572548] 3   1 \n",
      "[-0.38846397  0.40072212  0.25177655  0.4248838   0.4105161   0.2779737 ] 3   0 \n",
      "[-0.39218238  0.4013837   0.25194648  0.4249141   0.4123713   0.2753691 ] 3   4 \n",
      "[-0.39589608  0.40194297  0.25381204  0.4253298   0.41427732  0.27365324] 3   3 Match 247\n",
      "\n",
      "[-0.38976753  0.4017207   0.24779364  0.4227503   0.4131341   0.2757056 ] 3   1 \n",
      "[-0.38692683  0.40322536  0.2529775   0.42801163  0.40947437  0.26670685] 3   2 \n",
      "[-0.38719827  0.40151706  0.25085118  0.42517203  0.41109154  0.27435604] 3   3 Match 248\n",
      "\n",
      "[-0.39071995  0.40323746  0.25407252  0.4244565   0.412057    0.27342483] 3   3 Match 249\n",
      "\n",
      "[-0.38913488  0.40164807  0.24774626  0.42303157  0.4132028   0.2758694 ] 3   4 \n",
      "[-0.39092302  0.40166664  0.25103047  0.42513272  0.41152322  0.27627864] 3   5 \n",
      "[-0.39060175  0.4004084   0.25329033  0.4237106   0.4117034   0.27616233] 3   3 Match 250\n",
      "\n",
      "[-0.38725758  0.40275374  0.25330973  0.42487183  0.41138762  0.27273867] 3   2 \n",
      "[-0.38911465  0.40084812  0.24901542  0.42401692  0.4137014   0.27579787] 3   2 \n",
      "[-0.39086318  0.40179443  0.2522854   0.42433912  0.41230923  0.27642104] 3   4 \n",
      "[-0.392734    0.40227807  0.25243208  0.424141    0.41099134  0.27407232] 3   1 \n",
      "[-0.3897416   0.40121618  0.25252432  0.427146    0.41076365  0.2764409 ] 3   1 \n",
      "[-0.3881507   0.40310237  0.25050023  0.42802003  0.41178012  0.2754208 ] 3   5 \n",
      "[-0.38925323  0.403903    0.25489098  0.42500567  0.41142988  0.2737479 ] 3   5 \n",
      "[-0.38900328  0.40084693  0.24939087  0.42403153  0.41347736  0.27637324] 3   3 Match 251\n",
      "\n",
      "[-0.39167202  0.40199348  0.2516705   0.42719245  0.41021994  0.27578637] 3   2 \n",
      "[-0.38993105  0.40154326  0.2495395   0.42451787  0.41346708  0.27639565] 3   0 \n",
      "[-0.38884717  0.40035102  0.2497074   0.42372838  0.4139803   0.27703714] 3   3 Match 252\n",
      "\n",
      "[-0.3883071   0.40293348  0.24646488  0.4239951   0.41235328  0.27573454] 3   5 \n",
      "[-0.38943535  0.4015329   0.24864104  0.423106    0.41323614  0.27610388] 3   4 \n",
      "[-0.38887084  0.40133658  0.24861649  0.42417502  0.41198796  0.2767348 ] 3   5 \n",
      "[-0.3883577   0.40092257  0.24817726  0.4251191   0.41192684  0.27521232] 3   3 Match 253\n",
      "\n",
      "[-0.39032942  0.40169257  0.24999651  0.42385218  0.41229713  0.27587909] 3   2 \n",
      "[-0.3873033   0.40111196  0.24946824  0.42496136  0.41055283  0.27529863] 3   2 \n",
      "[-0.38947362  0.40083784  0.25315747  0.42657134  0.40969148  0.27927646] 3   1 \n",
      "[-0.38919586  0.40038612  0.24895653  0.42282975  0.41310796  0.277193  ] 3   1 \n",
      "[-0.39022875  0.40068567  0.2501385   0.42415363  0.41365907  0.27674654] 3   3 Match 254\n",
      "\n",
      "[-0.39078176  0.40103891  0.24972638  0.42347237  0.41330403  0.27576375] 3   5 \n",
      "[-0.3850124   0.40162146  0.25418535  0.42972407  0.40867522  0.27190197] 3   4 \n",
      "[-0.39227235  0.40034837  0.25507182  0.4280273   0.41088435  0.27741525] 3   0 \n",
      "[-0.3931253   0.39979708  0.2534173   0.42455122  0.4132311   0.27699968] 3   2 \n",
      "[-0.38663742  0.40201372  0.25157258  0.4234256   0.41319707  0.2734501 ] 3   5 \n",
      "[-0.3908374   0.40090638  0.24943948  0.42310694  0.41452596  0.27558538] 3   4 \n",
      "[-0.3920794   0.40211368  0.25163195  0.42471105  0.41288495  0.27463815] 3   2 \n",
      "[-0.4023866   0.40690696  0.26768416  0.43609694  0.411311    0.26006365] 3   3 Match 255\n",
      "\n",
      "[-0.3964944   0.40055692  0.25489685  0.42640117  0.4141009   0.27494422] 3   2 \n",
      "[-0.39048555  0.4015423   0.25205347  0.42620745  0.41031003  0.27655295] 3   3 Match 256\n",
      "\n",
      "[-0.3888418   0.4026203   0.24927169  0.42525372  0.4116555   0.2758048 ] 3   1 \n",
      "[-0.38991994  0.40064338  0.2512295   0.42506427  0.4106971   0.27657536] 3   2 \n",
      "[-0.39241835  0.39924037  0.25750455  0.42512366  0.41347703  0.2769769 ] 3   5 \n",
      "[-0.3888593   0.40076557  0.2501268   0.4237125   0.41363692  0.27569762] 3   5 \n",
      "[-0.38866097  0.4012424   0.24762273  0.42465633  0.41218734  0.27644986] 3   3 Match 257\n",
      "\n",
      "[-0.38856736  0.40149987  0.2482585   0.42489645  0.4113223   0.2761133 ] 3   3 Match 258\n",
      "\n",
      "[-0.3908878   0.40273196  0.25779876  0.42768303  0.4099433   0.27224863] 3   2 \n",
      "[-0.39118123  0.4025156   0.25184104  0.42723694  0.41156352  0.2744709 ] 3   4 \n",
      "[-0.39431894  0.40157217  0.2546939   0.42375386  0.41342658  0.27383396] 3   4 \n",
      "[-0.38431087  0.40319094  0.25763264  0.44028828  0.40613678  0.26871824] 3   3 Match 259\n",
      "\n",
      "[-0.38790506  0.40197146  0.24701384  0.4242313   0.4123393   0.27532616] 3   1 \n",
      "[-0.3945469   0.40093234  0.25441456  0.424877    0.41283226  0.27558613] 3   3 Match 260\n",
      "\n",
      "[-0.41164482  0.40090698  0.26220492  0.42917633  0.41977027  0.27016836] 3   4 \n",
      "[-0.38540858  0.4023651   0.24585184  0.42178962  0.4141832   0.27448604] 3   3 Match 261\n",
      "\n",
      "[-0.39033702  0.4007197   0.2500963   0.42400572  0.41267538  0.27556115] 3   2 \n",
      "[-0.3910586   0.4022112   0.25220755  0.4249079   0.41102606  0.27491298] 3   1 \n",
      "[-0.3898437   0.40155292  0.24857673  0.42318103  0.41425794  0.27625537] 3   4 \n",
      "[-0.38926327  0.4011737   0.2492305   0.42333153  0.41346535  0.27621266] 3   3 Match 262\n",
      "\n",
      "[-0.38806486  0.4024037   0.2557389   0.42974252  0.4096208   0.2804826 ] 3   4 \n",
      "[-0.38922969  0.40366137  0.2593779   0.43255314  0.41040984  0.26561266] 3   1 \n",
      "[-0.38922527  0.40133828  0.24842042  0.42488757  0.41075838  0.27591258] 3   2 \n",
      "[-0.38675234  0.40404946  0.25207093  0.4289207   0.4108076   0.26655772] 3   2 \n",
      "[-0.3904625   0.40079316  0.25376788  0.42662013  0.40956804  0.2747836 ] 3   0 \n",
      "[-0.3844395   0.4018611   0.2473495   0.42228943  0.41273332  0.27378365] 3   2 \n",
      "[-0.38898826  0.4022531   0.24888423  0.425665    0.4116149   0.27632126] 3   2 \n",
      "[-0.38798434  0.40247858  0.24929672  0.42580765  0.41124916  0.2750273 ] 3   3 Match 263\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[-0.38992992  0.40187538  0.25016192  0.42645147  0.41004723  0.2759774 ] 3   5 \n",
      "[-0.38801056  0.4021594   0.24855137  0.4259359   0.4106775   0.27667713] 3   4 \n",
      "[-0.38816038  0.3998224   0.2501224   0.4244728   0.41290775  0.27625003] 3   2 \n",
      "[-0.38967144  0.40199092  0.24952582  0.42371058  0.4134113   0.2745158 ] 3   3 Match 264\n",
      "\n",
      "[-0.38763824  0.40224293  0.24741003  0.42487383  0.41201884  0.27651846] 3   3 Match 265\n",
      "\n",
      "[-0.38847893  0.40144873  0.24867252  0.42359427  0.41259766  0.27422798] 3   4 \n",
      "[-0.38867983  0.40178478  0.2492539   0.424385    0.41159588  0.27547997] 3   4 \n",
      "[-0.38720357  0.40120044  0.2512594   0.424108    0.41275933  0.2752414 ] 3   2 \n",
      "[-0.38991785  0.40111327  0.2485547   0.42365697  0.4129778   0.27630997] 3   3 Match 266\n",
      "\n",
      "[-0.38914272  0.4012555   0.25267455  0.42430913  0.4129459   0.2755441 ] 3   2 \n",
      "[-0.38928157  0.4028841   0.24988887  0.42529985  0.41184056  0.2751394 ] 3   5 \n",
      "[-0.3880192   0.4023207   0.24670476  0.42387342  0.41186023  0.27608955] 3   1 \n",
      "[-0.40230292  0.40138242  0.25930744  0.42498463  0.41661432  0.26959684] 3   2 \n",
      "[-0.38752657  0.40165153  0.24834147  0.42597234  0.41139206  0.27596718] 3   0 \n",
      "[-0.38914672  0.4021045   0.24908921  0.42319626  0.41298398  0.27623433] 3   0 \n",
      "[-0.38916194  0.4022936   0.24892318  0.42636803  0.41181442  0.27609456] 3   3 Match 267\n",
      "\n",
      "[-0.38797104  0.4003951   0.24915469  0.42321756  0.4128423   0.27739015] 3   2 \n",
      "[-0.39722458  0.40254527  0.25709587  0.4285794   0.41365284  0.27903935] 3   1 \n",
      "[-0.38729966  0.4004183   0.25132424  0.4251988   0.41148946  0.2764883 ] 3   4 \n",
      "[-0.3881232   0.40079814  0.2510635   0.42268562  0.41286647  0.2742695 ] 3   2 \n",
      "[-0.38908374  0.4016381   0.2525418   0.42663208  0.41018546  0.27560082] 3   0 \n",
      "[-0.39089593  0.40056086  0.2516621   0.42625114  0.41010666  0.27601823] 3   1 \n",
      "267\n"
     ]
    }
   ],
   "source": [
    "Pred=[]\n",
    "\n",
    "countCorrect=0\n",
    "\n",
    "for row in range(TestModel_outputs.shape[0]):\n",
    "    outputs=TestModel_outputs[row]\n",
    "    #print(test.iloc[row,0])\n",
    "    print(outputs, end=' ')\n",
    "    \n",
    "    result=0\n",
    "    if outputs[0]<outputs[1]:result=1\n",
    "    if outputs[result]<outputs[2]:result=2\n",
    "    if outputs[result]<outputs[3]:result=3\n",
    "    if outputs[result]<outputs[4]:result=4\n",
    "    if outputs[result]<outputs[5]:result=5\n",
    "    Pred.append(result)\n",
    "    print(result, ' ',test.iloc[row,1], end=' ')\n",
    "    if result==test.iloc[row,1]:\n",
    "        countCorrect+=1\n",
    "        print('Match',countCorrect)\n",
    "    print('')\n",
    "\n",
    "print(countCorrect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0   0   0  92   0   0]\n",
      " [  0   0   0 250   0   0]\n",
      " [  0   0   0 214   0   0]\n",
      " [  0   0   0 267   0   0]\n",
      " [  0   0   0 249   0   0]\n",
      " [  0   0   0 211   0   0]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "print(metrics.confusion_matrix(test['labels'],Pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Pants       0.00      0.00      0.00        92\n",
      "       False       0.00      0.00      0.00       250\n",
      " Barely-True       0.00      0.00      0.00       214\n",
      "   Hlaf-True       0.21      1.00      0.34       267\n",
      " Mostly-True       0.00      0.00      0.00       249\n",
      "        True       0.00      0.00      0.00       211\n",
      "\n",
      "    accuracy                           0.21      1283\n",
      "   macro avg       0.03      0.17      0.06      1283\n",
      "weighted avg       0.04      0.21      0.07      1283\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mark\\Anaconda3\\envs\\thesis\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "target_names = ['Pants', 'False', 'Barely-True','Hlaf-True','Mostly-True','True']\n",
    "\n",
    "print(metrics.classification_report(test['labels'], Pred,target_names =target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving...\n",
      "Saving Complete on 2020-08-19 15:18:14.696782 in: ./TunedModels/roberta/roberta-large/Saves/\n"
     ]
    }
   ],
   "source": [
    "# saving the output of the models to CSVs\n",
    "#these are 1X6 classification vectors\n",
    "\n",
    "SavesDirectory='./TunedModels/'+model_class+'/'+model_version+\"/Saves/\"\n",
    "print('Saving...')\n",
    "trainOut = pd.DataFrame(data= TrainModel_outputs )\n",
    "trainOut.to_csv(SavesDirectory+'trainOut.tsv', sep='\\t',  index=False)\n",
    "\n",
    "evalOut = pd.DataFrame(data= EvalModel_outputs )\n",
    "evalOut.to_csv(SavesDirectory+'evalOut.tsv', sep='\\t',  index=False)\n",
    "\n",
    "testOut = pd.DataFrame(data= TestModel_outputs )\n",
    "testOut.to_csv(SavesDirectory+'testOut.tsv', sep='\\t',  index=False)\n",
    "\n",
    "print('Saving Complete on',datetime.now() ,'in:', SavesDirectory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "del(model)\n",
    "#del(train,Eval,test)\n",
    "del(trainOut,evalOut,testOut)\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Adding the reputation vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section takes the output results from the transformer used above and uses it together with the speaker's reputation to enhance the classification.\n",
    "\n",
    "Before running this section it is suggested that you halt the program and start running it again from this cell. The neural net will likely have an error caused by some unreleased variable used by thr simple transformers library. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PantsTotal</th>\n",
       "      <th>NotRealTotal</th>\n",
       "      <th>BarelyTotal</th>\n",
       "      <th>HalfTotal</th>\n",
       "      <th>MostlyTotal</th>\n",
       "      <th>Truths</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.005</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.387377</td>\n",
       "      <td>0.400232</td>\n",
       "      <td>0.249287</td>\n",
       "      <td>0.425540</td>\n",
       "      <td>0.413897</td>\n",
       "      <td>0.277364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.095</td>\n",
       "      <td>0.160</td>\n",
       "      <td>0.170</td>\n",
       "      <td>0.290</td>\n",
       "      <td>0.165</td>\n",
       "      <td>0.165</td>\n",
       "      <td>-0.388868</td>\n",
       "      <td>0.401241</td>\n",
       "      <td>0.248872</td>\n",
       "      <td>0.422384</td>\n",
       "      <td>0.414152</td>\n",
       "      <td>0.275785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.005</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.040</td>\n",
       "      <td>0.010</td>\n",
       "      <td>-0.389275</td>\n",
       "      <td>0.401526</td>\n",
       "      <td>0.248285</td>\n",
       "      <td>0.423318</td>\n",
       "      <td>0.413382</td>\n",
       "      <td>0.275590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.005</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.040</td>\n",
       "      <td>0.010</td>\n",
       "      <td>-0.389653</td>\n",
       "      <td>0.401985</td>\n",
       "      <td>0.249432</td>\n",
       "      <td>0.422432</td>\n",
       "      <td>0.413908</td>\n",
       "      <td>0.275714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.035</td>\n",
       "      <td>0.145</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.345</td>\n",
       "      <td>0.380</td>\n",
       "      <td>0.365</td>\n",
       "      <td>-0.390197</td>\n",
       "      <td>0.401123</td>\n",
       "      <td>0.249028</td>\n",
       "      <td>0.424097</td>\n",
       "      <td>0.413163</td>\n",
       "      <td>0.275274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10264</th>\n",
       "      <td>0.005</td>\n",
       "      <td>0.030</td>\n",
       "      <td>0.070</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.020</td>\n",
       "      <td>-0.388905</td>\n",
       "      <td>0.401978</td>\n",
       "      <td>0.248246</td>\n",
       "      <td>0.424185</td>\n",
       "      <td>0.411216</td>\n",
       "      <td>0.275639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10265</th>\n",
       "      <td>0.055</td>\n",
       "      <td>0.075</td>\n",
       "      <td>0.080</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.035</td>\n",
       "      <td>-0.390886</td>\n",
       "      <td>0.401707</td>\n",
       "      <td>0.255645</td>\n",
       "      <td>0.426733</td>\n",
       "      <td>0.411876</td>\n",
       "      <td>0.274773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10266</th>\n",
       "      <td>0.035</td>\n",
       "      <td>0.115</td>\n",
       "      <td>0.140</td>\n",
       "      <td>0.190</td>\n",
       "      <td>0.170</td>\n",
       "      <td>0.075</td>\n",
       "      <td>-0.388285</td>\n",
       "      <td>0.400249</td>\n",
       "      <td>0.250624</td>\n",
       "      <td>0.424685</td>\n",
       "      <td>0.412110</td>\n",
       "      <td>0.277521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10267</th>\n",
       "      <td>0.305</td>\n",
       "      <td>0.570</td>\n",
       "      <td>0.315</td>\n",
       "      <td>0.255</td>\n",
       "      <td>0.185</td>\n",
       "      <td>0.070</td>\n",
       "      <td>-0.390006</td>\n",
       "      <td>0.401340</td>\n",
       "      <td>0.250346</td>\n",
       "      <td>0.424074</td>\n",
       "      <td>0.412756</td>\n",
       "      <td>0.276400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10268</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.389647</td>\n",
       "      <td>0.402977</td>\n",
       "      <td>0.258667</td>\n",
       "      <td>0.427827</td>\n",
       "      <td>0.411792</td>\n",
       "      <td>0.272054</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10269 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       PantsTotal  NotRealTotal  BarelyTotal  HalfTotal  MostlyTotal  Truths  \\\n",
       "0           0.005         0.000        0.000      0.000        0.000   0.000   \n",
       "1           0.095         0.160        0.170      0.290        0.165   0.165   \n",
       "2           0.005         0.010        0.005      0.015        0.040   0.010   \n",
       "3           0.005         0.010        0.005      0.015        0.040   0.010   \n",
       "4           0.035         0.145        0.200      0.345        0.380   0.365   \n",
       "...           ...           ...          ...        ...          ...     ...   \n",
       "10264       0.005         0.030        0.070      0.050        0.050   0.020   \n",
       "10265       0.055         0.075        0.080      0.100        0.050   0.035   \n",
       "10266       0.035         0.115        0.140      0.190        0.170   0.075   \n",
       "10267       0.305         0.570        0.315      0.255        0.185   0.070   \n",
       "10268       0.000         0.005        0.000      0.000        0.000   0.000   \n",
       "\n",
       "              0         1         2         3         4         5  \n",
       "0     -0.387377  0.400232  0.249287  0.425540  0.413897  0.277364  \n",
       "1     -0.388868  0.401241  0.248872  0.422384  0.414152  0.275785  \n",
       "2     -0.389275  0.401526  0.248285  0.423318  0.413382  0.275590  \n",
       "3     -0.389653  0.401985  0.249432  0.422432  0.413908  0.275714  \n",
       "4     -0.390197  0.401123  0.249028  0.424097  0.413163  0.275274  \n",
       "...         ...       ...       ...       ...       ...       ...  \n",
       "10264 -0.388905  0.401978  0.248246  0.424185  0.411216  0.275639  \n",
       "10265 -0.390886  0.401707  0.255645  0.426733  0.411876  0.274773  \n",
       "10266 -0.388285  0.400249  0.250624  0.424685  0.412110  0.277521  \n",
       "10267 -0.390006  0.401340  0.250346  0.424074  0.412756  0.276400  \n",
       "10268 -0.389647  0.402977  0.258667  0.427827  0.411792  0.272054  \n",
       "\n",
       "[10269 rows x 12 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "train=pd.read_excel('trainReputation.xlsx' )\n",
    "train=train.iloc[:,:-2].astype(float)\n",
    "train=train/200  #for scaling\n",
    "#train\n",
    "\n",
    "model_class='roberta'  # bert or roberta or albert\n",
    "model_version='roberta-large' #bert-base-cased, roberta-base, roberta-large, albert-base-v2 OR albert-large-v2\n",
    "\n",
    "SavesDirectory='./TunedModels/'+model_class+'/'+model_version+\"/Saves/\"\n",
    "TF_Output=pd.read_csv( SavesDirectory+'trainOut.tsv', sep='\\t')\n",
    "\n",
    "train=pd.concat([train,TF_Output], axis=1)\n",
    "\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10264</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10265</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10266</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10267</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10268</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10269 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0  1  2  3  4  5\n",
       "0      1  0  0  0  0  0\n",
       "1      0  0  0  1  0  0\n",
       "2      0  0  0  0  1  0\n",
       "3      0  0  0  0  1  0\n",
       "4      0  0  0  0  0  1\n",
       "...   .. .. .. .. .. ..\n",
       "10264  0  0  0  0  1  0\n",
       "10265  0  0  0  0  0  1\n",
       "10266  0  0  0  1  0  0\n",
       "10267  0  1  0  0  0  0\n",
       "10268  0  1  0  0  0  0\n",
       "\n",
       "[10269 rows x 6 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TrainLables=pd.read_excel('trainReputation.xlsx' )\n",
    "TrainLables=TrainLables.iloc[:,-1] \n",
    "\n",
    "TrainLables=pd.get_dummies(TrainLables)\n",
    "TrainLables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0050, 0.0000, 0.0000,  ..., 0.4255, 0.4139, 0.2774],\n",
       "        [0.0950, 0.1600, 0.1700,  ..., 0.4224, 0.4142, 0.2758],\n",
       "        [0.0050, 0.0100, 0.0050,  ..., 0.4233, 0.4134, 0.2756],\n",
       "        ...,\n",
       "        [0.0350, 0.1150, 0.1400,  ..., 0.4247, 0.4121, 0.2775],\n",
       "        [0.3050, 0.5700, 0.3150,  ..., 0.4241, 0.4128, 0.2764],\n",
       "        [0.0000, 0.0050, 0.0000,  ..., 0.4278, 0.4118, 0.2721]],\n",
       "       dtype=torch.float64)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input=torch.tensor(train.values)\n",
    "del(train)\n",
    "input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 1., 0., 0.],\n",
       "        [0., 0., 0., 0., 1., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0., 0., 0.],\n",
       "        [0., 1., 0., 0., 0., 0.]], dtype=torch.float64)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets=torch.tensor(TrainLables.astype(float).values)\n",
    "del(TrainLables)\n",
    "targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input size: 12\n",
      "output size: 6\n"
     ]
    }
   ],
   "source": [
    " \n",
    "size= torch.tensor(input[0].size())\n",
    "InputSize=size.item()\n",
    "\n",
    "OutputSize=torch.tensor(targets[0].size()).item()\n",
    "\n",
    "print('input size:', InputSize)\n",
    "print('output size:', OutputSize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Net(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "         \n",
    "        # an affine operation: y = Wx + b\n",
    "        self.fc1 = nn.Linear(InputSize, 24)  # input size \n",
    "        self.fc2 = nn.Linear(24, 12)\n",
    "        self.fc3 = nn.Linear(12, OutputSize)  #classifies 'outputsize' different classes\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.tanh(self.fc1(x))\n",
    "        x = torch.tanh(self.fc2(x)) \n",
    "        x = torch.tanh(self.fc3(x)).double()\n",
    "        return x\n",
    "\n",
    "    \n",
    "\n",
    "#now we use it\n",
    "\n",
    "net = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### here we  setup the neural network parameters\n",
    "# pick an optimizer (Simple Gradient Descent)\n",
    "\n",
    "learning_rate = 9e-4\n",
    "criterion = nn.MSELoss()  #computes the loss Function\n",
    "\n",
    "import torch.optim as optim\n",
    "\n",
    "# creating optimizer\n",
    "#optimizer = optim.SGD(net.parameters(), lr=learning_rate)\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor(0.2403, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 0\n",
      "Loss: tensor(0.2355, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1\n",
      "Loss: tensor(0.2309, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2\n",
      "Loss: tensor(0.2265, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3\n",
      "Loss: tensor(0.2221, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4\n",
      "Loss: tensor(0.2179, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5\n",
      "Loss: tensor(0.2138, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6\n",
      "Loss: tensor(0.2099, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7\n",
      "Loss: tensor(0.2060, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8\n",
      "Loss: tensor(0.2023, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 9\n",
      "Loss: tensor(0.1988, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 10\n",
      "Loss: tensor(0.1953, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 11\n",
      "Loss: tensor(0.1920, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 12\n",
      "Loss: tensor(0.1888, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 13\n",
      "Loss: tensor(0.1858, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 14\n",
      "Loss: tensor(0.1829, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 15\n",
      "Loss: tensor(0.1801, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 16\n",
      "Loss: tensor(0.1775, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 17\n",
      "Loss: tensor(0.1749, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 18\n",
      "Loss: tensor(0.1726, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 19\n",
      "Loss: tensor(0.1703, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 20\n",
      "Loss: tensor(0.1682, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 21\n",
      "Loss: tensor(0.1662, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 22\n",
      "Loss: tensor(0.1643, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 23\n",
      "Loss: tensor(0.1625, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 24\n",
      "Loss: tensor(0.1609, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 25\n",
      "Loss: tensor(0.1593, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 26\n",
      "Loss: tensor(0.1579, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 27\n",
      "Loss: tensor(0.1565, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 28\n",
      "Loss: tensor(0.1553, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 29\n",
      "Loss: tensor(0.1541, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 30\n",
      "Loss: tensor(0.1530, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 31\n",
      "Loss: tensor(0.1520, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 32\n",
      "Loss: tensor(0.1510, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 33\n",
      "Loss: tensor(0.1501, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 34\n",
      "Loss: tensor(0.1493, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 35\n",
      "Loss: tensor(0.1485, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 36\n",
      "Loss: tensor(0.1478, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 37\n",
      "Loss: tensor(0.1471, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 38\n",
      "Loss: tensor(0.1465, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 39\n",
      "Loss: tensor(0.1459, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 40\n",
      "Loss: tensor(0.1453, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 41\n",
      "Loss: tensor(0.1448, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 42\n",
      "Loss: tensor(0.1442, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 43\n",
      "Loss: tensor(0.1438, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 44\n",
      "Loss: tensor(0.1433, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 45\n",
      "Loss: tensor(0.1429, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 46\n",
      "Loss: tensor(0.1425, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 47\n",
      "Loss: tensor(0.1421, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 48\n",
      "Loss: tensor(0.1417, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 49\n",
      "Loss: tensor(0.1414, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 50\n",
      "Loss: tensor(0.1410, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 51\n",
      "Loss: tensor(0.1407, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 52\n",
      "Loss: tensor(0.1404, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 53\n",
      "Loss: tensor(0.1401, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 54\n",
      "Loss: tensor(0.1399, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 55\n",
      "Loss: tensor(0.1396, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 56\n",
      "Loss: tensor(0.1394, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 57\n",
      "Loss: tensor(0.1392, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 58\n",
      "Loss: tensor(0.1390, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 59\n",
      "Loss: tensor(0.1389, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 60\n",
      "Loss: tensor(0.1387, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 61\n",
      "Loss: tensor(0.1386, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 62\n",
      "Loss: tensor(0.1384, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 63\n",
      "Loss: tensor(0.1383, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 64\n",
      "Loss: tensor(0.1382, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 65\n",
      "Loss: tensor(0.1381, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 66\n",
      "Loss: tensor(0.1380, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 67\n",
      "Loss: tensor(0.1379, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 68\n",
      "Loss: tensor(0.1379, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 69\n",
      "Loss: tensor(0.1378, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 70\n",
      "Loss: tensor(0.1377, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 71\n",
      "Loss: tensor(0.1377, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 72\n",
      "Loss: tensor(0.1376, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 73\n",
      "Loss: tensor(0.1376, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 74\n",
      "Loss: tensor(0.1375, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 75\n",
      "Loss: tensor(0.1375, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 76\n",
      "Loss: tensor(0.1375, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 77\n",
      "Loss: tensor(0.1374, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 78\n",
      "Loss: tensor(0.1374, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 79\n",
      "Loss: tensor(0.1374, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 80\n",
      "Loss: tensor(0.1373, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 81\n",
      "Loss: tensor(0.1373, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 82\n",
      "Loss: tensor(0.1373, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 83\n",
      "Loss: tensor(0.1373, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 84\n",
      "Loss: tensor(0.1372, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 85\n",
      "Loss: tensor(0.1372, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 86\n",
      "Loss: tensor(0.1372, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 87\n",
      "Loss: tensor(0.1372, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 88\n",
      "Loss: tensor(0.1372, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 89\n",
      "Loss: tensor(0.1371, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 90\n",
      "Loss: tensor(0.1371, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 91\n",
      "Loss: tensor(0.1371, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 92\n",
      "Loss: tensor(0.1371, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 93\n",
      "Loss: tensor(0.1371, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 94\n",
      "Loss: tensor(0.1371, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 95\n",
      "Loss: tensor(0.1371, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 96\n",
      "Loss: tensor(0.1370, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 97\n",
      "Loss: tensor(0.1370, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 98\n",
      "Loss: tensor(0.1370, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 99\n",
      "Loss: tensor(0.1370, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 100\n",
      "Loss: tensor(0.1370, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 101\n",
      "Loss: tensor(0.1370, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 102\n",
      "Loss: tensor(0.1370, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 103\n",
      "Loss: tensor(0.1370, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 104\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor(0.1370, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 105\n",
      "Loss: tensor(0.1370, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 106\n",
      "Loss: tensor(0.1370, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 107\n",
      "Loss: tensor(0.1370, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 108\n",
      "Loss: tensor(0.1369, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 109\n",
      "Loss: tensor(0.1369, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 110\n",
      "Loss: tensor(0.1369, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 111\n",
      "Loss: tensor(0.1369, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 112\n",
      "Loss: tensor(0.1369, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 113\n",
      "Loss: tensor(0.1369, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 114\n",
      "Loss: tensor(0.1369, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 115\n",
      "Loss: tensor(0.1369, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 116\n",
      "Loss: tensor(0.1369, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 117\n",
      "Loss: tensor(0.1369, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 118\n",
      "Loss: tensor(0.1369, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 119\n",
      "Loss: tensor(0.1369, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 120\n",
      "Loss: tensor(0.1369, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 121\n",
      "Loss: tensor(0.1369, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 122\n",
      "Loss: tensor(0.1369, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 123\n",
      "Loss: tensor(0.1369, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 124\n",
      "Loss: tensor(0.1369, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 125\n",
      "Loss: tensor(0.1368, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 126\n",
      "Loss: tensor(0.1368, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 127\n",
      "Loss: tensor(0.1368, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 128\n",
      "Loss: tensor(0.1368, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 129\n",
      "Loss: tensor(0.1368, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 130\n",
      "Loss: tensor(0.1368, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 131\n",
      "Loss: tensor(0.1368, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 132\n",
      "Loss: tensor(0.1368, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 133\n",
      "Loss: tensor(0.1368, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 134\n",
      "Loss: tensor(0.1368, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 135\n",
      "Loss: tensor(0.1368, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 136\n",
      "Loss: tensor(0.1368, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 137\n",
      "Loss: tensor(0.1368, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 138\n",
      "Loss: tensor(0.1368, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 139\n",
      "Loss: tensor(0.1368, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 140\n",
      "Loss: tensor(0.1368, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 141\n",
      "Loss: tensor(0.1368, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 142\n",
      "Loss: tensor(0.1368, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 143\n",
      "Loss: tensor(0.1368, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 144\n",
      "Loss: tensor(0.1367, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 145\n",
      "Loss: tensor(0.1367, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 146\n",
      "Loss: tensor(0.1367, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 147\n",
      "Loss: tensor(0.1367, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 148\n",
      "Loss: tensor(0.1367, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 149\n",
      "Loss: tensor(0.1367, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 150\n",
      "Loss: tensor(0.1367, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 151\n",
      "Loss: tensor(0.1367, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 152\n",
      "Loss: tensor(0.1367, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 153\n",
      "Loss: tensor(0.1367, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 154\n",
      "Loss: tensor(0.1367, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 155\n",
      "Loss: tensor(0.1367, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 156\n",
      "Loss: tensor(0.1367, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 157\n",
      "Loss: tensor(0.1367, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 158\n",
      "Loss: tensor(0.1367, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 159\n",
      "Loss: tensor(0.1367, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 160\n",
      "Loss: tensor(0.1367, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 161\n",
      "Loss: tensor(0.1367, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 162\n",
      "Loss: tensor(0.1366, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 163\n",
      "Loss: tensor(0.1366, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 164\n",
      "Loss: tensor(0.1366, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 165\n",
      "Loss: tensor(0.1366, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 166\n",
      "Loss: tensor(0.1366, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 167\n",
      "Loss: tensor(0.1366, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 168\n",
      "Loss: tensor(0.1366, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 169\n",
      "Loss: tensor(0.1366, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 170\n",
      "Loss: tensor(0.1366, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 171\n",
      "Loss: tensor(0.1366, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 172\n",
      "Loss: tensor(0.1366, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 173\n",
      "Loss: tensor(0.1366, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 174\n",
      "Loss: tensor(0.1366, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 175\n",
      "Loss: tensor(0.1366, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 176\n",
      "Loss: tensor(0.1366, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 177\n",
      "Loss: tensor(0.1366, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 178\n",
      "Loss: tensor(0.1366, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 179\n",
      "Loss: tensor(0.1366, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 180\n",
      "Loss: tensor(0.1365, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 181\n",
      "Loss: tensor(0.1365, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 182\n",
      "Loss: tensor(0.1365, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 183\n",
      "Loss: tensor(0.1365, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 184\n",
      "Loss: tensor(0.1365, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 185\n",
      "Loss: tensor(0.1365, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 186\n",
      "Loss: tensor(0.1365, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 187\n",
      "Loss: tensor(0.1365, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 188\n",
      "Loss: tensor(0.1365, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 189\n",
      "Loss: tensor(0.1365, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 190\n",
      "Loss: tensor(0.1365, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 191\n",
      "Loss: tensor(0.1365, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 192\n",
      "Loss: tensor(0.1365, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 193\n",
      "Loss: tensor(0.1365, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 194\n",
      "Loss: tensor(0.1365, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 195\n",
      "Loss: tensor(0.1365, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 196\n",
      "Loss: tensor(0.1365, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 197\n",
      "Loss: tensor(0.1364, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 198\n",
      "Loss: tensor(0.1364, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 199\n",
      "Loss: tensor(0.1364, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 200\n",
      "Loss: tensor(0.1364, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 201\n",
      "Loss: tensor(0.1364, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 202\n",
      "Loss: tensor(0.1364, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 203\n",
      "Loss: tensor(0.1364, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 204\n",
      "Loss: tensor(0.1364, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 205\n",
      "Loss: tensor(0.1364, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 206\n",
      "Loss: tensor(0.1364, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 207\n",
      "Loss: tensor(0.1364, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 208\n",
      "Loss: tensor(0.1364, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 209\n",
      "Loss: tensor(0.1364, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 210\n",
      "Loss: tensor(0.1364, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 211\n",
      "Loss: tensor(0.1364, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 212\n",
      "Loss: tensor(0.1364, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 213\n",
      "Loss: tensor(0.1364, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 214\n",
      "Loss: tensor(0.1363, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 215\n",
      "Loss: tensor(0.1363, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 216\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor(0.1363, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 217\n",
      "Loss: tensor(0.1363, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 218\n",
      "Loss: tensor(0.1363, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 219\n",
      "Loss: tensor(0.1363, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 220\n",
      "Loss: tensor(0.1363, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 221\n",
      "Loss: tensor(0.1363, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 222\n",
      "Loss: tensor(0.1363, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 223\n",
      "Loss: tensor(0.1363, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 224\n",
      "Loss: tensor(0.1363, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 225\n",
      "Loss: tensor(0.1363, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 226\n",
      "Loss: tensor(0.1363, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 227\n",
      "Loss: tensor(0.1363, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 228\n",
      "Loss: tensor(0.1363, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 229\n",
      "Loss: tensor(0.1363, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 230\n",
      "Loss: tensor(0.1362, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 231\n",
      "Loss: tensor(0.1362, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 232\n",
      "Loss: tensor(0.1362, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 233\n",
      "Loss: tensor(0.1362, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 234\n",
      "Loss: tensor(0.1362, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 235\n",
      "Loss: tensor(0.1362, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 236\n",
      "Loss: tensor(0.1362, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 237\n",
      "Loss: tensor(0.1362, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 238\n",
      "Loss: tensor(0.1362, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 239\n",
      "Loss: tensor(0.1362, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 240\n",
      "Loss: tensor(0.1362, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 241\n",
      "Loss: tensor(0.1362, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 242\n",
      "Loss: tensor(0.1362, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 243\n",
      "Loss: tensor(0.1362, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 244\n",
      "Loss: tensor(0.1362, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 245\n",
      "Loss: tensor(0.1362, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 246\n",
      "Loss: tensor(0.1362, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 247\n",
      "Loss: tensor(0.1361, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 248\n",
      "Loss: tensor(0.1361, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 249\n",
      "Loss: tensor(0.1361, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 250\n",
      "Loss: tensor(0.1361, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 251\n",
      "Loss: tensor(0.1361, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 252\n",
      "Loss: tensor(0.1361, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 253\n",
      "Loss: tensor(0.1361, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 254\n",
      "Loss: tensor(0.1361, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 255\n",
      "Loss: tensor(0.1361, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 256\n",
      "Loss: tensor(0.1361, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 257\n",
      "Loss: tensor(0.1361, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 258\n",
      "Loss: tensor(0.1361, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 259\n",
      "Loss: tensor(0.1361, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 260\n",
      "Loss: tensor(0.1361, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 261\n",
      "Loss: tensor(0.1361, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 262\n",
      "Loss: tensor(0.1361, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 263\n",
      "Loss: tensor(0.1361, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 264\n",
      "Loss: tensor(0.1360, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 265\n",
      "Loss: tensor(0.1360, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 266\n",
      "Loss: tensor(0.1360, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 267\n",
      "Loss: tensor(0.1360, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 268\n",
      "Loss: tensor(0.1360, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 269\n",
      "Loss: tensor(0.1360, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 270\n",
      "Loss: tensor(0.1360, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 271\n",
      "Loss: tensor(0.1360, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 272\n",
      "Loss: tensor(0.1360, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 273\n",
      "Loss: tensor(0.1360, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 274\n",
      "Loss: tensor(0.1360, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 275\n",
      "Loss: tensor(0.1360, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 276\n",
      "Loss: tensor(0.1360, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 277\n",
      "Loss: tensor(0.1360, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 278\n",
      "Loss: tensor(0.1360, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 279\n",
      "Loss: tensor(0.1360, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 280\n",
      "Loss: tensor(0.1360, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 281\n",
      "Loss: tensor(0.1359, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 282\n",
      "Loss: tensor(0.1359, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 283\n",
      "Loss: tensor(0.1359, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 284\n",
      "Loss: tensor(0.1359, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 285\n",
      "Loss: tensor(0.1359, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 286\n",
      "Loss: tensor(0.1359, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 287\n",
      "Loss: tensor(0.1359, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 288\n",
      "Loss: tensor(0.1359, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 289\n",
      "Loss: tensor(0.1359, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 290\n",
      "Loss: tensor(0.1359, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 291\n",
      "Loss: tensor(0.1359, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 292\n",
      "Loss: tensor(0.1359, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 293\n",
      "Loss: tensor(0.1359, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 294\n",
      "Loss: tensor(0.1359, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 295\n",
      "Loss: tensor(0.1359, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 296\n",
      "Loss: tensor(0.1359, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 297\n",
      "Loss: tensor(0.1359, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 298\n",
      "Loss: tensor(0.1359, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 299\n",
      "Loss: tensor(0.1359, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 300\n",
      "Loss: tensor(0.1359, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 301\n",
      "Loss: tensor(0.1358, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 302\n",
      "Loss: tensor(0.1358, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 303\n",
      "Loss: tensor(0.1358, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 304\n",
      "Loss: tensor(0.1358, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 305\n",
      "Loss: tensor(0.1358, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 306\n",
      "Loss: tensor(0.1358, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 307\n",
      "Loss: tensor(0.1358, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 308\n",
      "Loss: tensor(0.1358, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 309\n",
      "Loss: tensor(0.1358, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 310\n",
      "Loss: tensor(0.1358, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 311\n",
      "Loss: tensor(0.1358, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 312\n",
      "Loss: tensor(0.1358, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 313\n",
      "Loss: tensor(0.1358, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 314\n",
      "Loss: tensor(0.1358, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 315\n",
      "Loss: tensor(0.1358, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 316\n",
      "Loss: tensor(0.1358, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 317\n",
      "Loss: tensor(0.1358, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 318\n",
      "Loss: tensor(0.1358, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 319\n",
      "Loss: tensor(0.1358, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 320\n",
      "Loss: tensor(0.1358, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 321\n",
      "Loss: tensor(0.1358, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 322\n",
      "Loss: tensor(0.1358, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 323\n",
      "Loss: tensor(0.1357, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 324\n",
      "Loss: tensor(0.1357, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 325\n",
      "Loss: tensor(0.1357, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 326\n",
      "Loss: tensor(0.1357, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 327\n",
      "Loss: tensor(0.1357, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 328\n",
      "Loss: tensor(0.1357, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 329\n",
      "Loss: tensor(0.1357, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 330\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor(0.1357, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 331\n",
      "Loss: tensor(0.1357, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 332\n",
      "Loss: tensor(0.1357, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 333\n",
      "Loss: tensor(0.1357, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 334\n",
      "Loss: tensor(0.1357, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 335\n",
      "Loss: tensor(0.1357, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 336\n",
      "Loss: tensor(0.1357, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 337\n",
      "Loss: tensor(0.1357, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 338\n",
      "Loss: tensor(0.1357, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 339\n",
      "Loss: tensor(0.1357, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 340\n",
      "Loss: tensor(0.1357, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 341\n",
      "Loss: tensor(0.1357, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 342\n",
      "Loss: tensor(0.1357, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 343\n",
      "Loss: tensor(0.1357, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 344\n",
      "Loss: tensor(0.1357, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 345\n",
      "Loss: tensor(0.1357, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 346\n",
      "Loss: tensor(0.1357, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 347\n",
      "Loss: tensor(0.1357, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 348\n",
      "Loss: tensor(0.1357, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 349\n",
      "Loss: tensor(0.1357, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 350\n",
      "Loss: tensor(0.1357, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 351\n",
      "Loss: tensor(0.1357, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 352\n",
      "Loss: tensor(0.1356, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 353\n",
      "Loss: tensor(0.1356, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 354\n",
      "Loss: tensor(0.1356, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 355\n",
      "Loss: tensor(0.1356, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 356\n",
      "Loss: tensor(0.1356, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 357\n",
      "Loss: tensor(0.1356, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 358\n",
      "Loss: tensor(0.1356, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 359\n",
      "Loss: tensor(0.1356, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 360\n",
      "Loss: tensor(0.1356, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 361\n",
      "Loss: tensor(0.1356, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 362\n",
      "Loss: tensor(0.1356, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 363\n",
      "Loss: tensor(0.1356, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 364\n",
      "Loss: tensor(0.1356, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 365\n",
      "Loss: tensor(0.1356, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 366\n",
      "Loss: tensor(0.1356, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 367\n",
      "Loss: tensor(0.1356, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 368\n",
      "Loss: tensor(0.1356, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 369\n",
      "Loss: tensor(0.1356, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 370\n",
      "Loss: tensor(0.1356, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 371\n",
      "Loss: tensor(0.1356, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 372\n",
      "Loss: tensor(0.1356, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 373\n",
      "Loss: tensor(0.1356, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 374\n",
      "Loss: tensor(0.1356, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 375\n",
      "Loss: tensor(0.1356, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 376\n",
      "Loss: tensor(0.1356, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 377\n",
      "Loss: tensor(0.1356, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 378\n",
      "Loss: tensor(0.1356, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 379\n",
      "Loss: tensor(0.1356, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 380\n",
      "Loss: tensor(0.1356, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 381\n",
      "Loss: tensor(0.1356, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 382\n",
      "Loss: tensor(0.1356, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 383\n",
      "Loss: tensor(0.1356, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 384\n",
      "Loss: tensor(0.1356, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 385\n",
      "Loss: tensor(0.1356, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 386\n",
      "Loss: tensor(0.1356, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 387\n",
      "Loss: tensor(0.1356, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 388\n",
      "Loss: tensor(0.1356, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 389\n",
      "Loss: tensor(0.1356, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 390\n",
      "Loss: tensor(0.1356, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 391\n",
      "Loss: tensor(0.1356, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 392\n",
      "Loss: tensor(0.1356, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 393\n",
      "Loss: tensor(0.1356, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 394\n",
      "Loss: tensor(0.1356, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 395\n",
      "Loss: tensor(0.1356, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 396\n",
      "Loss: tensor(0.1356, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 397\n",
      "Loss: tensor(0.1356, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 398\n",
      "Loss: tensor(0.1356, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 399\n",
      "Loss: tensor(0.1355, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 400\n",
      "Loss: tensor(0.1355, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 401\n",
      "Loss: tensor(0.1355, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 402\n",
      "Loss: tensor(0.1355, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 403\n",
      "Loss: tensor(0.1355, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 404\n",
      "Loss: tensor(0.1355, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 405\n",
      "Loss: tensor(0.1355, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 406\n",
      "Loss: tensor(0.1355, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 407\n",
      "Loss: tensor(0.1355, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 408\n",
      "Loss: tensor(0.1355, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 409\n",
      "Loss: tensor(0.1355, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 410\n",
      "Loss: tensor(0.1355, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 411\n",
      "Loss: tensor(0.1355, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 412\n",
      "Loss: tensor(0.1355, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 413\n",
      "Loss: tensor(0.1355, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 414\n",
      "Loss: tensor(0.1355, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 415\n",
      "Loss: tensor(0.1355, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 416\n",
      "Loss: tensor(0.1355, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 417\n",
      "Loss: tensor(0.1355, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 418\n",
      "Loss: tensor(0.1355, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 419\n",
      "Loss: tensor(0.1355, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 420\n",
      "Loss: tensor(0.1355, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 421\n",
      "Loss: tensor(0.1355, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 422\n",
      "Loss: tensor(0.1355, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 423\n",
      "Loss: tensor(0.1355, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 424\n",
      "Loss: tensor(0.1355, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 425\n",
      "Loss: tensor(0.1355, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 426\n",
      "Loss: tensor(0.1355, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 427\n",
      "Loss: tensor(0.1355, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 428\n",
      "Loss: tensor(0.1355, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 429\n",
      "Loss: tensor(0.1355, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 430\n",
      "Loss: tensor(0.1355, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 431\n",
      "Loss: tensor(0.1355, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 432\n",
      "Loss: tensor(0.1355, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 433\n",
      "Loss: tensor(0.1355, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 434\n",
      "Loss: tensor(0.1355, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 435\n",
      "Loss: tensor(0.1355, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 436\n",
      "Loss: tensor(0.1355, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 437\n",
      "Loss: tensor(0.1355, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 438\n",
      "Loss: tensor(0.1355, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 439\n",
      "Loss: tensor(0.1355, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 440\n",
      "Loss: tensor(0.1355, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 441\n",
      "Loss: tensor(0.1355, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 442\n",
      "Loss: tensor(0.1355, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 443\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor(0.1355, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 444\n",
      "Loss: tensor(0.1355, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 445\n",
      "Loss: tensor(0.1355, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 446\n",
      "Loss: tensor(0.1355, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 447\n",
      "Loss: tensor(0.1355, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 448\n",
      "Loss: tensor(0.1355, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 449\n",
      "Loss: tensor(0.1355, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 450\n",
      "Loss: tensor(0.1355, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 451\n",
      "Loss: tensor(0.1355, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 452\n",
      "Loss: tensor(0.1355, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 453\n",
      "Loss: tensor(0.1355, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 454\n",
      "Loss: tensor(0.1355, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 455\n",
      "Loss: tensor(0.1355, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 456\n",
      "Loss: tensor(0.1355, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 457\n",
      "Loss: tensor(0.1355, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 458\n",
      "Loss: tensor(0.1355, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 459\n",
      "Loss: tensor(0.1355, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 460\n",
      "Loss: tensor(0.1355, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 461\n",
      "Loss: tensor(0.1355, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 462\n",
      "Loss: tensor(0.1355, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 463\n",
      "Loss: tensor(0.1355, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 464\n",
      "Loss: tensor(0.1355, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 465\n",
      "Loss: tensor(0.1355, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 466\n",
      "Loss: tensor(0.1355, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 467\n",
      "Loss: tensor(0.1355, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 468\n",
      "Loss: tensor(0.1355, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 469\n",
      "Loss: tensor(0.1355, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 470\n",
      "Loss: tensor(0.1355, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 471\n",
      "Loss: tensor(0.1355, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 472\n",
      "Loss: tensor(0.1355, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 473\n",
      "Loss: tensor(0.1355, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 474\n",
      "Loss: tensor(0.1355, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 475\n",
      "Loss: tensor(0.1355, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 476\n",
      "Loss: tensor(0.1354, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 477\n",
      "Loss: tensor(0.1354, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 478\n",
      "Loss: tensor(0.1354, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 479\n",
      "Loss: tensor(0.1354, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 480\n",
      "Loss: tensor(0.1354, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 481\n",
      "Loss: tensor(0.1354, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 482\n",
      "Loss: tensor(0.1354, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 483\n",
      "Loss: tensor(0.1354, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 484\n",
      "Loss: tensor(0.1354, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 485\n",
      "Loss: tensor(0.1354, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 486\n",
      "Loss: tensor(0.1354, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 487\n",
      "Loss: tensor(0.1354, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 488\n",
      "Loss: tensor(0.1354, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 489\n",
      "Loss: tensor(0.1354, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 490\n",
      "Loss: tensor(0.1354, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 491\n",
      "Loss: tensor(0.1354, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 492\n",
      "Loss: tensor(0.1354, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 493\n",
      "Loss: tensor(0.1354, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 494\n",
      "Loss: tensor(0.1354, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 495\n",
      "Loss: tensor(0.1354, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 496\n",
      "Loss: tensor(0.1354, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 497\n",
      "Loss: tensor(0.1354, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 498\n",
      "Loss: tensor(0.1354, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 499\n",
      "Loss: tensor(0.1354, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 500\n",
      "Loss: tensor(0.1354, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 501\n",
      "Loss: tensor(0.1354, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 502\n",
      "Loss: tensor(0.1354, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 503\n",
      "Loss: tensor(0.1354, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 504\n",
      "Loss: tensor(0.1354, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 505\n",
      "Loss: tensor(0.1354, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 506\n",
      "Loss: tensor(0.1354, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 507\n",
      "Loss: tensor(0.1354, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 508\n",
      "Loss: tensor(0.1354, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 509\n",
      "Loss: tensor(0.1354, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 510\n",
      "Loss: tensor(0.1354, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 511\n",
      "Loss: tensor(0.1354, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 512\n",
      "Loss: tensor(0.1354, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 513\n",
      "Loss: tensor(0.1354, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 514\n",
      "Loss: tensor(0.1354, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 515\n",
      "Loss: tensor(0.1354, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 516\n",
      "Loss: tensor(0.1354, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 517\n",
      "Loss: tensor(0.1354, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 518\n",
      "Loss: tensor(0.1354, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 519\n",
      "Loss: tensor(0.1354, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 520\n",
      "Loss: tensor(0.1354, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 521\n",
      "Loss: tensor(0.1354, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 522\n",
      "Loss: tensor(0.1354, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 523\n",
      "Loss: tensor(0.1354, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 524\n",
      "Loss: tensor(0.1354, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 525\n",
      "Loss: tensor(0.1354, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 526\n",
      "Loss: tensor(0.1354, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 527\n",
      "Loss: tensor(0.1354, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 528\n",
      "Loss: tensor(0.1354, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 529\n",
      "Loss: tensor(0.1354, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 530\n",
      "Loss: tensor(0.1354, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 531\n",
      "Loss: tensor(0.1354, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 532\n",
      "Loss: tensor(0.1354, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 533\n",
      "Loss: tensor(0.1354, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 534\n",
      "Loss: tensor(0.1354, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 535\n",
      "Loss: tensor(0.1354, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 536\n",
      "Loss: tensor(0.1354, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 537\n",
      "Loss: tensor(0.1354, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 538\n",
      "Loss: tensor(0.1354, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 539\n",
      "Loss: tensor(0.1354, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 540\n",
      "Loss: tensor(0.1354, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 541\n",
      "Loss: tensor(0.1354, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 542\n",
      "Loss: tensor(0.1354, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 543\n",
      "Loss: tensor(0.1354, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 544\n",
      "Loss: tensor(0.1354, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 545\n",
      "Loss: tensor(0.1354, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 546\n",
      "Loss: tensor(0.1354, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 547\n",
      "Loss: tensor(0.1354, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 548\n",
      "Loss: tensor(0.1354, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 549\n",
      "Loss: tensor(0.1354, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 550\n",
      "Loss: tensor(0.1354, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 551\n",
      "Loss: tensor(0.1354, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 552\n",
      "Loss: tensor(0.1354, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 553\n",
      "Loss: tensor(0.1354, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 554\n",
      "Loss: tensor(0.1354, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 555\n",
      "Loss: tensor(0.1354, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 556\n",
      "Loss: tensor(0.1354, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 557\n",
      "Loss: tensor(0.1353, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 558\n",
      "Loss: tensor(0.1353, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 559\n",
      "Loss: tensor(0.1353, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 560\n",
      "Loss: tensor(0.1353, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 561\n",
      "Loss: tensor(0.1353, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 562\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor(0.1353, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 563\n",
      "Loss: tensor(0.1353, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 564\n",
      "Loss: tensor(0.1353, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 565\n",
      "Loss: tensor(0.1353, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 566\n",
      "Loss: tensor(0.1353, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 567\n",
      "Loss: tensor(0.1353, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 568\n",
      "Loss: tensor(0.1353, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 569\n",
      "Loss: tensor(0.1353, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 570\n",
      "Loss: tensor(0.1353, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 571\n",
      "Loss: tensor(0.1353, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 572\n",
      "Loss: tensor(0.1353, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 573\n",
      "Loss: tensor(0.1353, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 574\n",
      "Loss: tensor(0.1353, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 575\n",
      "Loss: tensor(0.1353, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 576\n",
      "Loss: tensor(0.1353, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 577\n",
      "Loss: tensor(0.1353, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 578\n",
      "Loss: tensor(0.1353, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 579\n",
      "Loss: tensor(0.1353, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 580\n",
      "Loss: tensor(0.1353, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 581\n",
      "Loss: tensor(0.1353, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 582\n",
      "Loss: tensor(0.1353, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 583\n",
      "Loss: tensor(0.1353, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 584\n",
      "Loss: tensor(0.1353, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 585\n",
      "Loss: tensor(0.1353, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 586\n",
      "Loss: tensor(0.1353, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 587\n",
      "Loss: tensor(0.1353, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 588\n",
      "Loss: tensor(0.1353, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 589\n",
      "Loss: tensor(0.1353, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 590\n",
      "Loss: tensor(0.1353, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 591\n",
      "Loss: tensor(0.1353, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 592\n",
      "Loss: tensor(0.1353, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 593\n",
      "Loss: tensor(0.1353, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 594\n",
      "Loss: tensor(0.1353, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 595\n",
      "Loss: tensor(0.1353, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 596\n",
      "Loss: tensor(0.1353, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 597\n",
      "Loss: tensor(0.1353, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 598\n",
      "Loss: tensor(0.1353, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 599\n",
      "Loss: tensor(0.1353, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 600\n",
      "Loss: tensor(0.1353, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 601\n",
      "Loss: tensor(0.1353, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 602\n",
      "Loss: tensor(0.1353, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 603\n",
      "Loss: tensor(0.1353, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 604\n",
      "Loss: tensor(0.1353, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 605\n",
      "Loss: tensor(0.1353, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 606\n",
      "Loss: tensor(0.1353, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 607\n",
      "Loss: tensor(0.1353, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 608\n",
      "Loss: tensor(0.1353, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 609\n",
      "Loss: tensor(0.1353, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 610\n",
      "Loss: tensor(0.1353, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 611\n",
      "Loss: tensor(0.1353, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 612\n",
      "Loss: tensor(0.1353, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 613\n",
      "Loss: tensor(0.1353, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 614\n",
      "Loss: tensor(0.1353, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 615\n",
      "Loss: tensor(0.1353, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 616\n",
      "Loss: tensor(0.1353, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 617\n",
      "Loss: tensor(0.1353, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 618\n",
      "Loss: tensor(0.1353, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 619\n",
      "Loss: tensor(0.1353, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 620\n",
      "Loss: tensor(0.1353, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 621\n",
      "Loss: tensor(0.1353, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 622\n",
      "Loss: tensor(0.1353, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 623\n",
      "Loss: tensor(0.1353, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 624\n",
      "Loss: tensor(0.1353, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 625\n",
      "Loss: tensor(0.1353, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 626\n",
      "Loss: tensor(0.1353, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 627\n",
      "Loss: tensor(0.1353, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 628\n",
      "Loss: tensor(0.1353, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 629\n",
      "Loss: tensor(0.1353, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 630\n",
      "Loss: tensor(0.1353, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 631\n",
      "Loss: tensor(0.1353, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 632\n",
      "Loss: tensor(0.1353, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 633\n",
      "Loss: tensor(0.1353, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 634\n",
      "Loss: tensor(0.1352, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 635\n",
      "Loss: tensor(0.1352, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 636\n",
      "Loss: tensor(0.1352, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 637\n",
      "Loss: tensor(0.1352, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 638\n",
      "Loss: tensor(0.1352, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 639\n",
      "Loss: tensor(0.1352, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 640\n",
      "Loss: tensor(0.1352, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 641\n",
      "Loss: tensor(0.1352, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 642\n",
      "Loss: tensor(0.1352, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 643\n",
      "Loss: tensor(0.1352, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 644\n",
      "Loss: tensor(0.1352, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 645\n",
      "Loss: tensor(0.1352, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 646\n",
      "Loss: tensor(0.1352, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 647\n",
      "Loss: tensor(0.1352, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 648\n",
      "Loss: tensor(0.1352, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 649\n",
      "Loss: tensor(0.1352, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 650\n",
      "Loss: tensor(0.1352, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 651\n",
      "Loss: tensor(0.1352, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 652\n",
      "Loss: tensor(0.1352, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 653\n",
      "Loss: tensor(0.1352, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 654\n",
      "Loss: tensor(0.1352, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 655\n",
      "Loss: tensor(0.1352, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 656\n",
      "Loss: tensor(0.1352, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 657\n",
      "Loss: tensor(0.1352, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 658\n",
      "Loss: tensor(0.1352, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 659\n",
      "Loss: tensor(0.1352, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 660\n",
      "Loss: tensor(0.1352, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 661\n",
      "Loss: tensor(0.1352, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 662\n",
      "Loss: tensor(0.1352, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 663\n",
      "Loss: tensor(0.1352, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 664\n",
      "Loss: tensor(0.1352, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 665\n",
      "Loss: tensor(0.1352, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 666\n",
      "Loss: tensor(0.1352, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 667\n",
      "Loss: tensor(0.1352, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 668\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor(0.1352, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 669\n",
      "Loss: tensor(0.1352, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 670\n",
      "Loss: tensor(0.1352, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 671\n",
      "Loss: tensor(0.1352, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 672\n",
      "Loss: tensor(0.1352, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 673\n",
      "Loss: tensor(0.1352, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 674\n",
      "Loss: tensor(0.1352, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 675\n",
      "Loss: tensor(0.1352, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 676\n",
      "Loss: tensor(0.1352, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 677\n",
      "Loss: tensor(0.1352, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 678\n",
      "Loss: tensor(0.1352, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 679\n",
      "Loss: tensor(0.1352, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 680\n",
      "Loss: tensor(0.1352, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 681\n",
      "Loss: tensor(0.1352, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 682\n",
      "Loss: tensor(0.1352, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 683\n",
      "Loss: tensor(0.1352, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 684\n",
      "Loss: tensor(0.1352, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 685\n",
      "Loss: tensor(0.1352, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 686\n",
      "Loss: tensor(0.1352, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 687\n",
      "Loss: tensor(0.1352, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 688\n",
      "Loss: tensor(0.1352, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 689\n",
      "Loss: tensor(0.1352, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 690\n",
      "Loss: tensor(0.1352, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 691\n",
      "Loss: tensor(0.1352, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 692\n",
      "Loss: tensor(0.1352, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 693\n",
      "Loss: tensor(0.1352, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 694\n",
      "Loss: tensor(0.1352, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 695\n",
      "Loss: tensor(0.1352, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 696\n",
      "Loss: tensor(0.1352, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 697\n",
      "Loss: tensor(0.1352, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 698\n",
      "Loss: tensor(0.1352, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 699\n",
      "Loss: tensor(0.1352, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 700\n",
      "Loss: tensor(0.1352, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 701\n",
      "Loss: tensor(0.1352, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 702\n",
      "Loss: tensor(0.1352, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 703\n",
      "Loss: tensor(0.1352, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 704\n",
      "Loss: tensor(0.1352, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 705\n",
      "Loss: tensor(0.1352, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 706\n",
      "Loss: tensor(0.1352, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 707\n",
      "Loss: tensor(0.1352, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 708\n",
      "Loss: tensor(0.1352, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 709\n",
      "Loss: tensor(0.1352, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 710\n",
      "Loss: tensor(0.1352, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 711\n",
      "Loss: tensor(0.1351, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 712\n",
      "Loss: tensor(0.1351, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 713\n",
      "Loss: tensor(0.1351, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 714\n",
      "Loss: tensor(0.1351, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 715\n",
      "Loss: tensor(0.1351, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 716\n",
      "Loss: tensor(0.1351, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 717\n",
      "Loss: tensor(0.1351, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 718\n",
      "Loss: tensor(0.1351, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 719\n",
      "Loss: tensor(0.1351, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 720\n",
      "Loss: tensor(0.1351, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 721\n",
      "Loss: tensor(0.1351, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 722\n",
      "Loss: tensor(0.1351, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 723\n",
      "Loss: tensor(0.1351, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 724\n",
      "Loss: tensor(0.1351, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 725\n",
      "Loss: tensor(0.1351, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 726\n",
      "Loss: tensor(0.1351, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 727\n",
      "Loss: tensor(0.1351, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 728\n",
      "Loss: tensor(0.1351, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 729\n",
      "Loss: tensor(0.1351, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 730\n",
      "Loss: tensor(0.1351, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 731\n",
      "Loss: tensor(0.1351, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 732\n",
      "Loss: tensor(0.1351, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 733\n",
      "Loss: tensor(0.1351, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 734\n",
      "Loss: tensor(0.1351, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 735\n",
      "Loss: tensor(0.1351, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 736\n",
      "Loss: tensor(0.1351, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 737\n",
      "Loss: tensor(0.1351, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 738\n",
      "Loss: tensor(0.1351, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 739\n",
      "Loss: tensor(0.1351, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 740\n",
      "Loss: tensor(0.1351, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 741\n",
      "Loss: tensor(0.1351, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 742\n",
      "Loss: tensor(0.1351, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 743\n",
      "Loss: tensor(0.1351, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 744\n",
      "Loss: tensor(0.1351, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 745\n",
      "Loss: tensor(0.1351, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 746\n",
      "Loss: tensor(0.1351, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 747\n",
      "Loss: tensor(0.1351, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 748\n",
      "Loss: tensor(0.1351, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 749\n",
      "Loss: tensor(0.1351, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 750\n",
      "Loss: tensor(0.1351, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 751\n",
      "Loss: tensor(0.1351, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 752\n",
      "Loss: tensor(0.1351, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 753\n",
      "Loss: tensor(0.1351, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 754\n",
      "Loss: tensor(0.1351, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 755\n",
      "Loss: tensor(0.1351, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 756\n",
      "Loss: tensor(0.1351, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 757\n",
      "Loss: tensor(0.1351, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 758\n",
      "Loss: tensor(0.1351, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 759\n",
      "Loss: tensor(0.1351, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 760\n",
      "Loss: tensor(0.1351, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 761\n",
      "Loss: tensor(0.1351, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 762\n",
      "Loss: tensor(0.1351, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 763\n",
      "Loss: tensor(0.1351, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 764\n",
      "Loss: tensor(0.1351, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 765\n",
      "Loss: tensor(0.1351, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 766\n",
      "Loss: tensor(0.1351, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 767\n",
      "Loss: tensor(0.1351, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 768\n",
      "Loss: tensor(0.1351, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 769\n",
      "Loss: tensor(0.1351, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 770\n",
      "Loss: tensor(0.1351, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 771\n",
      "Loss: tensor(0.1351, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 772\n",
      "Loss: tensor(0.1351, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 773\n",
      "Loss: tensor(0.1351, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 774\n",
      "Loss: tensor(0.1351, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 775\n",
      "Loss: tensor(0.1351, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 776\n",
      "Loss: tensor(0.1351, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 777\n",
      "Loss: tensor(0.1351, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 778\n",
      "Loss: tensor(0.1351, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 779\n",
      "Loss: tensor(0.1351, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 780\n",
      "Loss: tensor(0.1351, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 781\n",
      "Loss: tensor(0.1351, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 782\n",
      "Loss: tensor(0.1351, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 783\n",
      "Loss: tensor(0.1351, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 784\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor(0.1351, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 785\n",
      "Loss: tensor(0.1351, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 786\n",
      "Loss: tensor(0.1351, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 787\n",
      "Loss: tensor(0.1351, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 788\n",
      "Loss: tensor(0.1351, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 789\n",
      "Loss: tensor(0.1351, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 790\n",
      "Loss: tensor(0.1350, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 791\n",
      "Loss: tensor(0.1350, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 792\n",
      "Loss: tensor(0.1350, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 793\n",
      "Loss: tensor(0.1350, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 794\n",
      "Loss: tensor(0.1350, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 795\n",
      "Loss: tensor(0.1350, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 796\n",
      "Loss: tensor(0.1350, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 797\n",
      "Loss: tensor(0.1350, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 798\n",
      "Loss: tensor(0.1350, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 799\n",
      "Loss: tensor(0.1350, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 800\n",
      "Loss: tensor(0.1350, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 801\n",
      "Loss: tensor(0.1350, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 802\n",
      "Loss: tensor(0.1350, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 803\n",
      "Loss: tensor(0.1350, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 804\n",
      "Loss: tensor(0.1350, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 805\n",
      "Loss: tensor(0.1350, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 806\n",
      "Loss: tensor(0.1350, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 807\n",
      "Loss: tensor(0.1350, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 808\n",
      "Loss: tensor(0.1350, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 809\n",
      "Loss: tensor(0.1350, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 810\n",
      "Loss: tensor(0.1350, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 811\n",
      "Loss: tensor(0.1350, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 812\n",
      "Loss: tensor(0.1350, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 813\n",
      "Loss: tensor(0.1350, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 814\n",
      "Loss: tensor(0.1350, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 815\n",
      "Loss: tensor(0.1350, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 816\n",
      "Loss: tensor(0.1350, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 817\n",
      "Loss: tensor(0.1350, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 818\n",
      "Loss: tensor(0.1350, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 819\n",
      "Loss: tensor(0.1350, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 820\n",
      "Loss: tensor(0.1350, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 821\n",
      "Loss: tensor(0.1350, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 822\n",
      "Loss: tensor(0.1350, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 823\n",
      "Loss: tensor(0.1350, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 824\n",
      "Loss: tensor(0.1350, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 825\n",
      "Loss: tensor(0.1350, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 826\n",
      "Loss: tensor(0.1350, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 827\n",
      "Loss: tensor(0.1350, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 828\n",
      "Loss: tensor(0.1350, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 829\n",
      "Loss: tensor(0.1350, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 830\n",
      "Loss: tensor(0.1350, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 831\n",
      "Loss: tensor(0.1350, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 832\n",
      "Loss: tensor(0.1350, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 833\n",
      "Loss: tensor(0.1350, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 834\n",
      "Loss: tensor(0.1350, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 835\n",
      "Loss: tensor(0.1350, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 836\n",
      "Loss: tensor(0.1350, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 837\n",
      "Loss: tensor(0.1350, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 838\n",
      "Loss: tensor(0.1350, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 839\n",
      "Loss: tensor(0.1350, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 840\n",
      "Loss: tensor(0.1350, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 841\n",
      "Loss: tensor(0.1350, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 842\n",
      "Loss: tensor(0.1350, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 843\n",
      "Loss: tensor(0.1350, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 844\n",
      "Loss: tensor(0.1350, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 845\n",
      "Loss: tensor(0.1350, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 846\n",
      "Loss: tensor(0.1350, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 847\n",
      "Loss: tensor(0.1350, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 848\n",
      "Loss: tensor(0.1350, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 849\n",
      "Loss: tensor(0.1350, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 850\n",
      "Loss: tensor(0.1350, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 851\n",
      "Loss: tensor(0.1350, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 852\n",
      "Loss: tensor(0.1350, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 853\n",
      "Loss: tensor(0.1350, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 854\n",
      "Loss: tensor(0.1350, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 855\n",
      "Loss: tensor(0.1350, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 856\n",
      "Loss: tensor(0.1350, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 857\n",
      "Loss: tensor(0.1350, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 858\n",
      "Loss: tensor(0.1350, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 859\n",
      "Loss: tensor(0.1350, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 860\n",
      "Loss: tensor(0.1350, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 861\n",
      "Loss: tensor(0.1350, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 862\n",
      "Loss: tensor(0.1350, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 863\n",
      "Loss: tensor(0.1350, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 864\n",
      "Loss: tensor(0.1350, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 865\n",
      "Loss: tensor(0.1350, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 866\n",
      "Loss: tensor(0.1350, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 867\n",
      "Loss: tensor(0.1350, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 868\n",
      "Loss: tensor(0.1350, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 869\n",
      "Loss: tensor(0.1350, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 870\n",
      "Loss: tensor(0.1350, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 871\n",
      "Loss: tensor(0.1349, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 872\n",
      "Loss: tensor(0.1349, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 873\n",
      "Loss: tensor(0.1349, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 874\n",
      "Loss: tensor(0.1349, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 875\n",
      "Loss: tensor(0.1349, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 876\n",
      "Loss: tensor(0.1349, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 877\n",
      "Loss: tensor(0.1349, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 878\n",
      "Loss: tensor(0.1349, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 879\n",
      "Loss: tensor(0.1349, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 880\n",
      "Loss: tensor(0.1349, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 881\n",
      "Loss: tensor(0.1349, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 882\n",
      "Loss: tensor(0.1349, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 883\n",
      "Loss: tensor(0.1349, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 884\n",
      "Loss: tensor(0.1349, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 885\n",
      "Loss: tensor(0.1349, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 886\n",
      "Loss: tensor(0.1349, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 887\n",
      "Loss: tensor(0.1349, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 888\n",
      "Loss: tensor(0.1349, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 889\n",
      "Loss: tensor(0.1349, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 890\n",
      "Loss: tensor(0.1349, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 891\n",
      "Loss: tensor(0.1349, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 892\n",
      "Loss: tensor(0.1349, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 893\n",
      "Loss: tensor(0.1349, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 894\n",
      "Loss: tensor(0.1349, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 895\n",
      "Loss: tensor(0.1349, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 896\n",
      "Loss: tensor(0.1349, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 897\n",
      "Loss: tensor(0.1349, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 898\n",
      "Loss: tensor(0.1349, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 899\n",
      "Loss: tensor(0.1349, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 900\n",
      "Loss: tensor(0.1349, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 901\n",
      "Loss: tensor(0.1349, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 902\n",
      "Loss: tensor(0.1349, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 903\n",
      "Loss: tensor(0.1349, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 904\n",
      "Loss: tensor(0.1349, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 905\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor(0.1349, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 906\n",
      "Loss: tensor(0.1349, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 907\n",
      "Loss: tensor(0.1349, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 908\n",
      "Loss: tensor(0.1349, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 909\n",
      "Loss: tensor(0.1349, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 910\n",
      "Loss: tensor(0.1349, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 911\n",
      "Loss: tensor(0.1349, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 912\n",
      "Loss: tensor(0.1349, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 913\n",
      "Loss: tensor(0.1349, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 914\n",
      "Loss: tensor(0.1349, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 915\n",
      "Loss: tensor(0.1349, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 916\n",
      "Loss: tensor(0.1349, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 917\n",
      "Loss: tensor(0.1349, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 918\n",
      "Loss: tensor(0.1349, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 919\n",
      "Loss: tensor(0.1349, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 920\n",
      "Loss: tensor(0.1349, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 921\n",
      "Loss: tensor(0.1349, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 922\n",
      "Loss: tensor(0.1349, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 923\n",
      "Loss: tensor(0.1349, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 924\n",
      "Loss: tensor(0.1349, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 925\n",
      "Loss: tensor(0.1349, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 926\n",
      "Loss: tensor(0.1349, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 927\n",
      "Loss: tensor(0.1349, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 928\n",
      "Loss: tensor(0.1349, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 929\n",
      "Loss: tensor(0.1349, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 930\n",
      "Loss: tensor(0.1349, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 931\n",
      "Loss: tensor(0.1349, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 932\n",
      "Loss: tensor(0.1349, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 933\n",
      "Loss: tensor(0.1349, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 934\n",
      "Loss: tensor(0.1349, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 935\n",
      "Loss: tensor(0.1349, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 936\n",
      "Loss: tensor(0.1349, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 937\n",
      "Loss: tensor(0.1349, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 938\n",
      "Loss: tensor(0.1349, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 939\n",
      "Loss: tensor(0.1349, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 940\n",
      "Loss: tensor(0.1349, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 941\n",
      "Loss: tensor(0.1349, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 942\n",
      "Loss: tensor(0.1349, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 943\n",
      "Loss: tensor(0.1349, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 944\n",
      "Loss: tensor(0.1349, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 945\n",
      "Loss: tensor(0.1349, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 946\n",
      "Loss: tensor(0.1349, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 947\n",
      "Loss: tensor(0.1349, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 948\n",
      "Loss: tensor(0.1349, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 949\n",
      "Loss: tensor(0.1349, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 950\n",
      "Loss: tensor(0.1349, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 951\n",
      "Loss: tensor(0.1349, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 952\n",
      "Loss: tensor(0.1349, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 953\n",
      "Loss: tensor(0.1349, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 954\n",
      "Loss: tensor(0.1349, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 955\n",
      "Loss: tensor(0.1349, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 956\n",
      "Loss: tensor(0.1348, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 957\n",
      "Loss: tensor(0.1348, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 958\n",
      "Loss: tensor(0.1348, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 959\n",
      "Loss: tensor(0.1348, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 960\n",
      "Loss: tensor(0.1348, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 961\n",
      "Loss: tensor(0.1348, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 962\n",
      "Loss: tensor(0.1348, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 963\n",
      "Loss: tensor(0.1348, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 964\n",
      "Loss: tensor(0.1348, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 965\n",
      "Loss: tensor(0.1348, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 966\n",
      "Loss: tensor(0.1348, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 967\n",
      "Loss: tensor(0.1348, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 968\n",
      "Loss: tensor(0.1348, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 969\n",
      "Loss: tensor(0.1348, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 970\n",
      "Loss: tensor(0.1348, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 971\n",
      "Loss: tensor(0.1348, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 972\n",
      "Loss: tensor(0.1348, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 973\n",
      "Loss: tensor(0.1348, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 974\n",
      "Loss: tensor(0.1348, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 975\n",
      "Loss: tensor(0.1348, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 976\n",
      "Loss: tensor(0.1348, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 977\n",
      "Loss: tensor(0.1348, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 978\n",
      "Loss: tensor(0.1348, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 979\n",
      "Loss: tensor(0.1348, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 980\n",
      "Loss: tensor(0.1348, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 981\n",
      "Loss: tensor(0.1348, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 982\n",
      "Loss: tensor(0.1348, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 983\n",
      "Loss: tensor(0.1348, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 984\n",
      "Loss: tensor(0.1348, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 985\n",
      "Loss: tensor(0.1348, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 986\n",
      "Loss: tensor(0.1348, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 987\n",
      "Loss: tensor(0.1348, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 988\n",
      "Loss: tensor(0.1348, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 989\n",
      "Loss: tensor(0.1348, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 990\n",
      "Loss: tensor(0.1348, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 991\n",
      "Loss: tensor(0.1348, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 992\n",
      "Loss: tensor(0.1348, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 993\n",
      "Loss: tensor(0.1348, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 994\n",
      "Loss: tensor(0.1348, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 995\n",
      "Loss: tensor(0.1348, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 996\n",
      "Loss: tensor(0.1348, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 997\n",
      "Loss: tensor(0.1348, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 998\n",
      "Loss: tensor(0.1348, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 999\n",
      "Loss: tensor(0.1348, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1000\n",
      "Loss: tensor(0.1348, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1001\n",
      "Loss: tensor(0.1348, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1002\n",
      "Loss: tensor(0.1348, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1003\n",
      "Loss: tensor(0.1348, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1004\n",
      "Loss: tensor(0.1348, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1005\n",
      "Loss: tensor(0.1348, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1006\n",
      "Loss: tensor(0.1348, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1007\n",
      "Loss: tensor(0.1348, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1008\n",
      "Loss: tensor(0.1348, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1009\n",
      "Loss: tensor(0.1348, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1010\n",
      "Loss: tensor(0.1348, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1011\n",
      "Loss: tensor(0.1348, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1012\n",
      "Loss: tensor(0.1348, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1013\n",
      "Loss: tensor(0.1348, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1014\n",
      "Loss: tensor(0.1348, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1015\n",
      "Loss: tensor(0.1348, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1016\n",
      "Loss: tensor(0.1348, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1017\n",
      "Loss: tensor(0.1348, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1018\n",
      "Loss: tensor(0.1348, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1019\n",
      "Loss: tensor(0.1348, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1020\n",
      "Loss: tensor(0.1348, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1021\n",
      "Loss: tensor(0.1348, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1022\n",
      "Loss: tensor(0.1348, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1023\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor(0.1348, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1024\n",
      "Loss: tensor(0.1348, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1025\n",
      "Loss: tensor(0.1348, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1026\n",
      "Loss: tensor(0.1348, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1027\n",
      "Loss: tensor(0.1348, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1028\n",
      "Loss: tensor(0.1348, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1029\n",
      "Loss: tensor(0.1348, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1030\n",
      "Loss: tensor(0.1348, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1031\n",
      "Loss: tensor(0.1348, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1032\n",
      "Loss: tensor(0.1348, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1033\n",
      "Loss: tensor(0.1348, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1034\n",
      "Loss: tensor(0.1348, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1035\n",
      "Loss: tensor(0.1348, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1036\n",
      "Loss: tensor(0.1348, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1037\n",
      "Loss: tensor(0.1348, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1038\n",
      "Loss: tensor(0.1348, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1039\n",
      "Loss: tensor(0.1348, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1040\n",
      "Loss: tensor(0.1348, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1041\n",
      "Loss: tensor(0.1347, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1042\n",
      "Loss: tensor(0.1347, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1043\n",
      "Loss: tensor(0.1347, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1044\n",
      "Loss: tensor(0.1347, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1045\n",
      "Loss: tensor(0.1347, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1046\n",
      "Loss: tensor(0.1347, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1047\n",
      "Loss: tensor(0.1347, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1048\n",
      "Loss: tensor(0.1347, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1049\n",
      "Loss: tensor(0.1347, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1050\n",
      "Loss: tensor(0.1347, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1051\n",
      "Loss: tensor(0.1347, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1052\n",
      "Loss: tensor(0.1347, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1053\n",
      "Loss: tensor(0.1347, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1054\n",
      "Loss: tensor(0.1347, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1055\n",
      "Loss: tensor(0.1347, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1056\n",
      "Loss: tensor(0.1347, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1057\n",
      "Loss: tensor(0.1347, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1058\n",
      "Loss: tensor(0.1347, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1059\n",
      "Loss: tensor(0.1347, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1060\n",
      "Loss: tensor(0.1347, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1061\n",
      "Loss: tensor(0.1347, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1062\n",
      "Loss: tensor(0.1347, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1063\n",
      "Loss: tensor(0.1347, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1064\n",
      "Loss: tensor(0.1347, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1065\n",
      "Loss: tensor(0.1347, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1066\n",
      "Loss: tensor(0.1347, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1067\n",
      "Loss: tensor(0.1347, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1068\n",
      "Loss: tensor(0.1347, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1069\n",
      "Loss: tensor(0.1347, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1070\n",
      "Loss: tensor(0.1347, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1071\n",
      "Loss: tensor(0.1347, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1072\n",
      "Loss: tensor(0.1347, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1073\n",
      "Loss: tensor(0.1347, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1074\n",
      "Loss: tensor(0.1347, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1075\n",
      "Loss: tensor(0.1347, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1076\n",
      "Loss: tensor(0.1347, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1077\n",
      "Loss: tensor(0.1347, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1078\n",
      "Loss: tensor(0.1347, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1079\n",
      "Loss: tensor(0.1347, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1080\n",
      "Loss: tensor(0.1347, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1081\n",
      "Loss: tensor(0.1347, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1082\n",
      "Loss: tensor(0.1347, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1083\n",
      "Loss: tensor(0.1347, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1084\n",
      "Loss: tensor(0.1347, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1085\n",
      "Loss: tensor(0.1347, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1086\n",
      "Loss: tensor(0.1347, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1087\n",
      "Loss: tensor(0.1347, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1088\n",
      "Loss: tensor(0.1347, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1089\n",
      "Loss: tensor(0.1347, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1090\n",
      "Loss: tensor(0.1347, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1091\n",
      "Loss: tensor(0.1347, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1092\n",
      "Loss: tensor(0.1347, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1093\n",
      "Loss: tensor(0.1347, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1094\n",
      "Loss: tensor(0.1347, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1095\n",
      "Loss: tensor(0.1347, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1096\n",
      "Loss: tensor(0.1347, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1097\n",
      "Loss: tensor(0.1347, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1098\n",
      "Loss: tensor(0.1347, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1099\n",
      "Loss: tensor(0.1347, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1100\n",
      "Loss: tensor(0.1347, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1101\n",
      "Loss: tensor(0.1347, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1102\n",
      "Loss: tensor(0.1347, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1103\n",
      "Loss: tensor(0.1347, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1104\n",
      "Loss: tensor(0.1347, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1105\n",
      "Loss: tensor(0.1347, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1106\n",
      "Loss: tensor(0.1347, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1107\n",
      "Loss: tensor(0.1347, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1108\n",
      "Loss: tensor(0.1347, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1109\n",
      "Loss: tensor(0.1347, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1110\n",
      "Loss: tensor(0.1347, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1111\n",
      "Loss: tensor(0.1347, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1112\n",
      "Loss: tensor(0.1347, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1113\n",
      "Loss: tensor(0.1347, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1114\n",
      "Loss: tensor(0.1347, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1115\n",
      "Loss: tensor(0.1347, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1116\n",
      "Loss: tensor(0.1347, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1117\n",
      "Loss: tensor(0.1347, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1118\n",
      "Loss: tensor(0.1347, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1119\n",
      "Loss: tensor(0.1347, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1120\n",
      "Loss: tensor(0.1347, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1121\n",
      "Loss: tensor(0.1347, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1122\n",
      "Loss: tensor(0.1347, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1123\n",
      "Loss: tensor(0.1347, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1124\n",
      "Loss: tensor(0.1347, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1125\n",
      "Loss: tensor(0.1346, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1126\n",
      "Loss: tensor(0.1346, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1127\n",
      "Loss: tensor(0.1346, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1128\n",
      "Loss: tensor(0.1346, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1129\n",
      "Loss: tensor(0.1346, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1130\n",
      "Loss: tensor(0.1346, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1131\n",
      "Loss: tensor(0.1346, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1132\n",
      "Loss: tensor(0.1346, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1133\n",
      "Loss: tensor(0.1346, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1134\n",
      "Loss: tensor(0.1346, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1135\n",
      "Loss: tensor(0.1346, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1136\n",
      "Loss: tensor(0.1346, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1137\n",
      "Loss: tensor(0.1346, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1138\n",
      "Loss: tensor(0.1346, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1139\n",
      "Loss: tensor(0.1346, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1140\n",
      "Loss: tensor(0.1346, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1141\n",
      "Loss: tensor(0.1346, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1142\n",
      "Loss: tensor(0.1346, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1143\n",
      "Loss: tensor(0.1346, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1144\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor(0.1346, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1145\n",
      "Loss: tensor(0.1346, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1146\n",
      "Loss: tensor(0.1346, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1147\n",
      "Loss: tensor(0.1346, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1148\n",
      "Loss: tensor(0.1346, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1149\n",
      "Loss: tensor(0.1346, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1150\n",
      "Loss: tensor(0.1346, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1151\n",
      "Loss: tensor(0.1346, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1152\n",
      "Loss: tensor(0.1346, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1153\n",
      "Loss: tensor(0.1346, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1154\n",
      "Loss: tensor(0.1346, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1155\n",
      "Loss: tensor(0.1346, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1156\n",
      "Loss: tensor(0.1346, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1157\n",
      "Loss: tensor(0.1346, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1158\n",
      "Loss: tensor(0.1346, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1159\n",
      "Loss: tensor(0.1346, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1160\n",
      "Loss: tensor(0.1346, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1161\n",
      "Loss: tensor(0.1346, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1162\n",
      "Loss: tensor(0.1346, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1163\n",
      "Loss: tensor(0.1346, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1164\n",
      "Loss: tensor(0.1346, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1165\n",
      "Loss: tensor(0.1346, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1166\n",
      "Loss: tensor(0.1346, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1167\n",
      "Loss: tensor(0.1346, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1168\n",
      "Loss: tensor(0.1346, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1169\n",
      "Loss: tensor(0.1346, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1170\n",
      "Loss: tensor(0.1346, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1171\n",
      "Loss: tensor(0.1346, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1172\n",
      "Loss: tensor(0.1346, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1173\n",
      "Loss: tensor(0.1346, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1174\n",
      "Loss: tensor(0.1346, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1175\n",
      "Loss: tensor(0.1346, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1176\n",
      "Loss: tensor(0.1346, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1177\n",
      "Loss: tensor(0.1346, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1178\n",
      "Loss: tensor(0.1346, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1179\n",
      "Loss: tensor(0.1346, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1180\n",
      "Loss: tensor(0.1346, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1181\n",
      "Loss: tensor(0.1346, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1182\n",
      "Loss: tensor(0.1346, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1183\n",
      "Loss: tensor(0.1346, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1184\n",
      "Loss: tensor(0.1346, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1185\n",
      "Loss: tensor(0.1346, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1186\n",
      "Loss: tensor(0.1346, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1187\n",
      "Loss: tensor(0.1346, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1188\n",
      "Loss: tensor(0.1346, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1189\n",
      "Loss: tensor(0.1346, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1190\n",
      "Loss: tensor(0.1346, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1191\n",
      "Loss: tensor(0.1346, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1192\n",
      "Loss: tensor(0.1346, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1193\n",
      "Loss: tensor(0.1346, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1194\n",
      "Loss: tensor(0.1346, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1195\n",
      "Loss: tensor(0.1346, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1196\n",
      "Loss: tensor(0.1346, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1197\n",
      "Loss: tensor(0.1346, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1198\n",
      "Loss: tensor(0.1346, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1199\n",
      "Loss: tensor(0.1346, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1200\n",
      "Loss: tensor(0.1346, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1201\n",
      "Loss: tensor(0.1345, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1202\n",
      "Loss: tensor(0.1345, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1203\n",
      "Loss: tensor(0.1345, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1204\n",
      "Loss: tensor(0.1345, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1205\n",
      "Loss: tensor(0.1345, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1206\n",
      "Loss: tensor(0.1345, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1207\n",
      "Loss: tensor(0.1345, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1208\n",
      "Loss: tensor(0.1345, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1209\n",
      "Loss: tensor(0.1345, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1210\n",
      "Loss: tensor(0.1345, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1211\n",
      "Loss: tensor(0.1345, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1212\n",
      "Loss: tensor(0.1345, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1213\n",
      "Loss: tensor(0.1345, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1214\n",
      "Loss: tensor(0.1345, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1215\n",
      "Loss: tensor(0.1345, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1216\n",
      "Loss: tensor(0.1345, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1217\n",
      "Loss: tensor(0.1345, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1218\n",
      "Loss: tensor(0.1345, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1219\n",
      "Loss: tensor(0.1345, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1220\n",
      "Loss: tensor(0.1345, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1221\n",
      "Loss: tensor(0.1345, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1222\n",
      "Loss: tensor(0.1345, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1223\n",
      "Loss: tensor(0.1345, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1224\n",
      "Loss: tensor(0.1345, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1225\n",
      "Loss: tensor(0.1345, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1226\n",
      "Loss: tensor(0.1345, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1227\n",
      "Loss: tensor(0.1345, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1228\n",
      "Loss: tensor(0.1345, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1229\n",
      "Loss: tensor(0.1345, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1230\n",
      "Loss: tensor(0.1345, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1231\n",
      "Loss: tensor(0.1345, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1232\n",
      "Loss: tensor(0.1345, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1233\n",
      "Loss: tensor(0.1345, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1234\n",
      "Loss: tensor(0.1345, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1235\n",
      "Loss: tensor(0.1345, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1236\n",
      "Loss: tensor(0.1345, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1237\n",
      "Loss: tensor(0.1345, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1238\n",
      "Loss: tensor(0.1345, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1239\n",
      "Loss: tensor(0.1345, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1240\n",
      "Loss: tensor(0.1345, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1241\n",
      "Loss: tensor(0.1345, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1242\n",
      "Loss: tensor(0.1345, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1243\n",
      "Loss: tensor(0.1345, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1244\n",
      "Loss: tensor(0.1345, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1245\n",
      "Loss: tensor(0.1345, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1246\n",
      "Loss: tensor(0.1345, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1247\n",
      "Loss: tensor(0.1345, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1248\n",
      "Loss: tensor(0.1345, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1249\n",
      "Loss: tensor(0.1345, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1250\n",
      "Loss: tensor(0.1345, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1251\n",
      "Loss: tensor(0.1345, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1252\n",
      "Loss: tensor(0.1345, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1253\n",
      "Loss: tensor(0.1345, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1254\n",
      "Loss: tensor(0.1345, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1255\n",
      "Loss: tensor(0.1345, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1256\n",
      "Loss: tensor(0.1345, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1257\n",
      "Loss: tensor(0.1345, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1258\n",
      "Loss: tensor(0.1345, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1259\n",
      "Loss: tensor(0.1345, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1260\n",
      "Loss: tensor(0.1345, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1261\n",
      "Loss: tensor(0.1345, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1262\n",
      "Loss: tensor(0.1345, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1263\n",
      "Loss: tensor(0.1345, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1264\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor(0.1345, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1265\n",
      "Loss: tensor(0.1345, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1266\n",
      "Loss: tensor(0.1345, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1267\n",
      "Loss: tensor(0.1345, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1268\n",
      "Loss: tensor(0.1345, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1269\n",
      "Loss: tensor(0.1345, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1270\n",
      "Loss: tensor(0.1344, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1271\n",
      "Loss: tensor(0.1344, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1272\n",
      "Loss: tensor(0.1344, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1273\n",
      "Loss: tensor(0.1344, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1274\n",
      "Loss: tensor(0.1344, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1275\n",
      "Loss: tensor(0.1344, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1276\n",
      "Loss: tensor(0.1344, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1277\n",
      "Loss: tensor(0.1344, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1278\n",
      "Loss: tensor(0.1344, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1279\n",
      "Loss: tensor(0.1344, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1280\n",
      "Loss: tensor(0.1344, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1281\n",
      "Loss: tensor(0.1344, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1282\n",
      "Loss: tensor(0.1344, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1283\n",
      "Loss: tensor(0.1344, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1284\n",
      "Loss: tensor(0.1344, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1285\n",
      "Loss: tensor(0.1344, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1286\n",
      "Loss: tensor(0.1344, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1287\n",
      "Loss: tensor(0.1344, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1288\n",
      "Loss: tensor(0.1344, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1289\n",
      "Loss: tensor(0.1344, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1290\n",
      "Loss: tensor(0.1344, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1291\n",
      "Loss: tensor(0.1344, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1292\n",
      "Loss: tensor(0.1344, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1293\n",
      "Loss: tensor(0.1344, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1294\n",
      "Loss: tensor(0.1344, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1295\n",
      "Loss: tensor(0.1344, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1296\n",
      "Loss: tensor(0.1344, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1297\n",
      "Loss: tensor(0.1344, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1298\n",
      "Loss: tensor(0.1344, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1299\n",
      "Loss: tensor(0.1344, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1300\n",
      "Loss: tensor(0.1344, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1301\n",
      "Loss: tensor(0.1344, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1302\n",
      "Loss: tensor(0.1344, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1303\n",
      "Loss: tensor(0.1344, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1304\n",
      "Loss: tensor(0.1344, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1305\n",
      "Loss: tensor(0.1344, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1306\n",
      "Loss: tensor(0.1344, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1307\n",
      "Loss: tensor(0.1344, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1308\n",
      "Loss: tensor(0.1344, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1309\n",
      "Loss: tensor(0.1344, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1310\n",
      "Loss: tensor(0.1344, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1311\n",
      "Loss: tensor(0.1344, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1312\n",
      "Loss: tensor(0.1344, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1313\n",
      "Loss: tensor(0.1344, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1314\n",
      "Loss: tensor(0.1344, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1315\n",
      "Loss: tensor(0.1344, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1316\n",
      "Loss: tensor(0.1344, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1317\n",
      "Loss: tensor(0.1344, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1318\n",
      "Loss: tensor(0.1344, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1319\n",
      "Loss: tensor(0.1344, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1320\n",
      "Loss: tensor(0.1344, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1321\n",
      "Loss: tensor(0.1344, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1322\n",
      "Loss: tensor(0.1344, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1323\n",
      "Loss: tensor(0.1344, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1324\n",
      "Loss: tensor(0.1344, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1325\n",
      "Loss: tensor(0.1344, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1326\n",
      "Loss: tensor(0.1344, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1327\n",
      "Loss: tensor(0.1344, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1328\n",
      "Loss: tensor(0.1344, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1329\n",
      "Loss: tensor(0.1344, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1330\n",
      "Loss: tensor(0.1344, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1331\n",
      "Loss: tensor(0.1344, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1332\n",
      "Loss: tensor(0.1343, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1333\n",
      "Loss: tensor(0.1343, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1334\n",
      "Loss: tensor(0.1343, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1335\n",
      "Loss: tensor(0.1343, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1336\n",
      "Loss: tensor(0.1343, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1337\n",
      "Loss: tensor(0.1343, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1338\n",
      "Loss: tensor(0.1343, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1339\n",
      "Loss: tensor(0.1343, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1340\n",
      "Loss: tensor(0.1343, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1341\n",
      "Loss: tensor(0.1343, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1342\n",
      "Loss: tensor(0.1343, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1343\n",
      "Loss: tensor(0.1343, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1344\n",
      "Loss: tensor(0.1343, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1345\n",
      "Loss: tensor(0.1343, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1346\n",
      "Loss: tensor(0.1343, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1347\n",
      "Loss: tensor(0.1343, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1348\n",
      "Loss: tensor(0.1343, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1349\n",
      "Loss: tensor(0.1343, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1350\n",
      "Loss: tensor(0.1343, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1351\n",
      "Loss: tensor(0.1343, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1352\n",
      "Loss: tensor(0.1343, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1353\n",
      "Loss: tensor(0.1343, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1354\n",
      "Loss: tensor(0.1343, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1355\n",
      "Loss: tensor(0.1343, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1356\n",
      "Loss: tensor(0.1343, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1357\n",
      "Loss: tensor(0.1343, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1358\n",
      "Loss: tensor(0.1343, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1359\n",
      "Loss: tensor(0.1343, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1360\n",
      "Loss: tensor(0.1343, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1361\n",
      "Loss: tensor(0.1343, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1362\n",
      "Loss: tensor(0.1343, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1363\n",
      "Loss: tensor(0.1343, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1364\n",
      "Loss: tensor(0.1343, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1365\n",
      "Loss: tensor(0.1343, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1366\n",
      "Loss: tensor(0.1343, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1367\n",
      "Loss: tensor(0.1343, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1368\n",
      "Loss: tensor(0.1343, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1369\n",
      "Loss: tensor(0.1343, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1370\n",
      "Loss: tensor(0.1343, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1371\n",
      "Loss: tensor(0.1343, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1372\n",
      "Loss: tensor(0.1343, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1373\n",
      "Loss: tensor(0.1343, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1374\n",
      "Loss: tensor(0.1343, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1375\n",
      "Loss: tensor(0.1343, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1376\n",
      "Loss: tensor(0.1343, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1377\n",
      "Loss: tensor(0.1343, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1378\n",
      "Loss: tensor(0.1343, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1379\n",
      "Loss: tensor(0.1343, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1380\n",
      "Loss: tensor(0.1343, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1381\n",
      "Loss: tensor(0.1343, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1382\n",
      "Loss: tensor(0.1343, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1383\n",
      "Loss: tensor(0.1343, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1384\n",
      "Loss: tensor(0.1343, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1385\n",
      "Loss: tensor(0.1343, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1386\n",
      "Loss: tensor(0.1343, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1387\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor(0.1343, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1388\n",
      "Loss: tensor(0.1343, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1389\n",
      "Loss: tensor(0.1342, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1390\n",
      "Loss: tensor(0.1342, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1391\n",
      "Loss: tensor(0.1342, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1392\n",
      "Loss: tensor(0.1342, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1393\n",
      "Loss: tensor(0.1342, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1394\n",
      "Loss: tensor(0.1342, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1395\n",
      "Loss: tensor(0.1342, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1396\n",
      "Loss: tensor(0.1342, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1397\n",
      "Loss: tensor(0.1342, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1398\n",
      "Loss: tensor(0.1342, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1399\n",
      "Loss: tensor(0.1342, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1400\n",
      "Loss: tensor(0.1342, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1401\n",
      "Loss: tensor(0.1342, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1402\n",
      "Loss: tensor(0.1342, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1403\n",
      "Loss: tensor(0.1342, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1404\n",
      "Loss: tensor(0.1342, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1405\n",
      "Loss: tensor(0.1342, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1406\n",
      "Loss: tensor(0.1342, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1407\n",
      "Loss: tensor(0.1342, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1408\n",
      "Loss: tensor(0.1342, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1409\n",
      "Loss: tensor(0.1342, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1410\n",
      "Loss: tensor(0.1342, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1411\n",
      "Loss: tensor(0.1342, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1412\n",
      "Loss: tensor(0.1342, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1413\n",
      "Loss: tensor(0.1342, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1414\n",
      "Loss: tensor(0.1342, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1415\n",
      "Loss: tensor(0.1342, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1416\n",
      "Loss: tensor(0.1342, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1417\n",
      "Loss: tensor(0.1342, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1418\n",
      "Loss: tensor(0.1342, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1419\n",
      "Loss: tensor(0.1342, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1420\n",
      "Loss: tensor(0.1342, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1421\n",
      "Loss: tensor(0.1342, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1422\n",
      "Loss: tensor(0.1342, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1423\n",
      "Loss: tensor(0.1342, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1424\n",
      "Loss: tensor(0.1342, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1425\n",
      "Loss: tensor(0.1342, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1426\n",
      "Loss: tensor(0.1342, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1427\n",
      "Loss: tensor(0.1342, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1428\n",
      "Loss: tensor(0.1342, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1429\n",
      "Loss: tensor(0.1342, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1430\n",
      "Loss: tensor(0.1342, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1431\n",
      "Loss: tensor(0.1342, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1432\n",
      "Loss: tensor(0.1342, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1433\n",
      "Loss: tensor(0.1342, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1434\n",
      "Loss: tensor(0.1342, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1435\n",
      "Loss: tensor(0.1342, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1436\n",
      "Loss: tensor(0.1342, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1437\n",
      "Loss: tensor(0.1342, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1438\n",
      "Loss: tensor(0.1342, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1439\n",
      "Loss: tensor(0.1342, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1440\n",
      "Loss: tensor(0.1342, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1441\n",
      "Loss: tensor(0.1342, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1442\n",
      "Loss: tensor(0.1341, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1443\n",
      "Loss: tensor(0.1341, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1444\n",
      "Loss: tensor(0.1341, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1445\n",
      "Loss: tensor(0.1341, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1446\n",
      "Loss: tensor(0.1341, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1447\n",
      "Loss: tensor(0.1341, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1448\n",
      "Loss: tensor(0.1341, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1449\n",
      "Loss: tensor(0.1341, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1450\n",
      "Loss: tensor(0.1341, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1451\n",
      "Loss: tensor(0.1341, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1452\n",
      "Loss: tensor(0.1341, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1453\n",
      "Loss: tensor(0.1341, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1454\n",
      "Loss: tensor(0.1341, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1455\n",
      "Loss: tensor(0.1341, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1456\n",
      "Loss: tensor(0.1341, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1457\n",
      "Loss: tensor(0.1341, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1458\n",
      "Loss: tensor(0.1341, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1459\n",
      "Loss: tensor(0.1341, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1460\n",
      "Loss: tensor(0.1341, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1461\n",
      "Loss: tensor(0.1341, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1462\n",
      "Loss: tensor(0.1341, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1463\n",
      "Loss: tensor(0.1341, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1464\n",
      "Loss: tensor(0.1341, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1465\n",
      "Loss: tensor(0.1341, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1466\n",
      "Loss: tensor(0.1341, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1467\n",
      "Loss: tensor(0.1341, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1468\n",
      "Loss: tensor(0.1341, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1469\n",
      "Loss: tensor(0.1341, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1470\n",
      "Loss: tensor(0.1341, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1471\n",
      "Loss: tensor(0.1341, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1472\n",
      "Loss: tensor(0.1341, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1473\n",
      "Loss: tensor(0.1341, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1474\n",
      "Loss: tensor(0.1341, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1475\n",
      "Loss: tensor(0.1341, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1476\n",
      "Loss: tensor(0.1341, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1477\n",
      "Loss: tensor(0.1341, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1478\n",
      "Loss: tensor(0.1341, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1479\n",
      "Loss: tensor(0.1341, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1480\n",
      "Loss: tensor(0.1341, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1481\n",
      "Loss: tensor(0.1341, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1482\n",
      "Loss: tensor(0.1341, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1483\n",
      "Loss: tensor(0.1341, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1484\n",
      "Loss: tensor(0.1341, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1485\n",
      "Loss: tensor(0.1341, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1486\n",
      "Loss: tensor(0.1341, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1487\n",
      "Loss: tensor(0.1341, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1488\n",
      "Loss: tensor(0.1341, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1489\n",
      "Loss: tensor(0.1341, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1490\n",
      "Loss: tensor(0.1341, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1491\n",
      "Loss: tensor(0.1340, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1492\n",
      "Loss: tensor(0.1340, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1493\n",
      "Loss: tensor(0.1340, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1494\n",
      "Loss: tensor(0.1340, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1495\n",
      "Loss: tensor(0.1340, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1496\n",
      "Loss: tensor(0.1340, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1497\n",
      "Loss: tensor(0.1340, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1498\n",
      "Loss: tensor(0.1340, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1499\n",
      "Loss: tensor(0.1340, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1500\n",
      "Loss: tensor(0.1340, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1501\n",
      "Loss: tensor(0.1340, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1502\n",
      "Loss: tensor(0.1340, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1503\n",
      "Loss: tensor(0.1340, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1504\n",
      "Loss: tensor(0.1340, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1505\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor(0.1340, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1506\n",
      "Loss: tensor(0.1340, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1507\n",
      "Loss: tensor(0.1340, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1508\n",
      "Loss: tensor(0.1340, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1509\n",
      "Loss: tensor(0.1340, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1510\n",
      "Loss: tensor(0.1340, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1511\n",
      "Loss: tensor(0.1340, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1512\n",
      "Loss: tensor(0.1340, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1513\n",
      "Loss: tensor(0.1340, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1514\n",
      "Loss: tensor(0.1340, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1515\n",
      "Loss: tensor(0.1340, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1516\n",
      "Loss: tensor(0.1340, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1517\n",
      "Loss: tensor(0.1340, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1518\n",
      "Loss: tensor(0.1340, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1519\n",
      "Loss: tensor(0.1340, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1520\n",
      "Loss: tensor(0.1340, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1521\n",
      "Loss: tensor(0.1340, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1522\n",
      "Loss: tensor(0.1340, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1523\n",
      "Loss: tensor(0.1340, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1524\n",
      "Loss: tensor(0.1340, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1525\n",
      "Loss: tensor(0.1340, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1526\n",
      "Loss: tensor(0.1340, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1527\n",
      "Loss: tensor(0.1340, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1528\n",
      "Loss: tensor(0.1340, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1529\n",
      "Loss: tensor(0.1340, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1530\n",
      "Loss: tensor(0.1340, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1531\n",
      "Loss: tensor(0.1340, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1532\n",
      "Loss: tensor(0.1340, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1533\n",
      "Loss: tensor(0.1340, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1534\n",
      "Loss: tensor(0.1340, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1535\n",
      "Loss: tensor(0.1340, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1536\n",
      "Loss: tensor(0.1340, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1537\n",
      "Loss: tensor(0.1340, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1538\n",
      "Loss: tensor(0.1339, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1539\n",
      "Loss: tensor(0.1339, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1540\n",
      "Loss: tensor(0.1339, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1541\n",
      "Loss: tensor(0.1339, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1542\n",
      "Loss: tensor(0.1339, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1543\n",
      "Loss: tensor(0.1339, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1544\n",
      "Loss: tensor(0.1339, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1545\n",
      "Loss: tensor(0.1339, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1546\n",
      "Loss: tensor(0.1339, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1547\n",
      "Loss: tensor(0.1339, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1548\n",
      "Loss: tensor(0.1339, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1549\n",
      "Loss: tensor(0.1339, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1550\n",
      "Loss: tensor(0.1339, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1551\n",
      "Loss: tensor(0.1339, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1552\n",
      "Loss: tensor(0.1339, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1553\n",
      "Loss: tensor(0.1339, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1554\n",
      "Loss: tensor(0.1339, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1555\n",
      "Loss: tensor(0.1339, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1556\n",
      "Loss: tensor(0.1339, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1557\n",
      "Loss: tensor(0.1339, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1558\n",
      "Loss: tensor(0.1339, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1559\n",
      "Loss: tensor(0.1339, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1560\n",
      "Loss: tensor(0.1339, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1561\n",
      "Loss: tensor(0.1339, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1562\n",
      "Loss: tensor(0.1339, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1563\n",
      "Loss: tensor(0.1339, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1564\n",
      "Loss: tensor(0.1339, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1565\n",
      "Loss: tensor(0.1339, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1566\n",
      "Loss: tensor(0.1339, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1567\n",
      "Loss: tensor(0.1339, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1568\n",
      "Loss: tensor(0.1339, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1569\n",
      "Loss: tensor(0.1339, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1570\n",
      "Loss: tensor(0.1339, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1571\n",
      "Loss: tensor(0.1339, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1572\n",
      "Loss: tensor(0.1339, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1573\n",
      "Loss: tensor(0.1339, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1574\n",
      "Loss: tensor(0.1339, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1575\n",
      "Loss: tensor(0.1339, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1576\n",
      "Loss: tensor(0.1339, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1577\n",
      "Loss: tensor(0.1339, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1578\n",
      "Loss: tensor(0.1339, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1579\n",
      "Loss: tensor(0.1339, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1580\n",
      "Loss: tensor(0.1339, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1581\n",
      "Loss: tensor(0.1339, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1582\n",
      "Loss: tensor(0.1339, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1583\n",
      "Loss: tensor(0.1338, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1584\n",
      "Loss: tensor(0.1338, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1585\n",
      "Loss: tensor(0.1338, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1586\n",
      "Loss: tensor(0.1338, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1587\n",
      "Loss: tensor(0.1338, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1588\n",
      "Loss: tensor(0.1338, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1589\n",
      "Loss: tensor(0.1338, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1590\n",
      "Loss: tensor(0.1338, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1591\n",
      "Loss: tensor(0.1338, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1592\n",
      "Loss: tensor(0.1338, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1593\n",
      "Loss: tensor(0.1338, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1594\n",
      "Loss: tensor(0.1338, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1595\n",
      "Loss: tensor(0.1338, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1596\n",
      "Loss: tensor(0.1338, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1597\n",
      "Loss: tensor(0.1338, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1598\n",
      "Loss: tensor(0.1338, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1599\n",
      "Loss: tensor(0.1338, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1600\n",
      "Loss: tensor(0.1338, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1601\n",
      "Loss: tensor(0.1338, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1602\n",
      "Loss: tensor(0.1338, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1603\n",
      "Loss: tensor(0.1338, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1604\n",
      "Loss: tensor(0.1338, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1605\n",
      "Loss: tensor(0.1338, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1606\n",
      "Loss: tensor(0.1338, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1607\n",
      "Loss: tensor(0.1338, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1608\n",
      "Loss: tensor(0.1338, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1609\n",
      "Loss: tensor(0.1338, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1610\n",
      "Loss: tensor(0.1338, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1611\n",
      "Loss: tensor(0.1338, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1612\n",
      "Loss: tensor(0.1338, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1613\n",
      "Loss: tensor(0.1338, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1614\n",
      "Loss: tensor(0.1338, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1615\n",
      "Loss: tensor(0.1338, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1616\n",
      "Loss: tensor(0.1338, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1617\n",
      "Loss: tensor(0.1338, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1618\n",
      "Loss: tensor(0.1338, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1619\n",
      "Loss: tensor(0.1338, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1620\n",
      "Loss: tensor(0.1338, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1621\n",
      "Loss: tensor(0.1338, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1622\n",
      "Loss: tensor(0.1338, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1623\n",
      "Loss: tensor(0.1338, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1624\n",
      "Loss: tensor(0.1338, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1625\n",
      "Loss: tensor(0.1338, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1626\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor(0.1338, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1627\n",
      "Loss: tensor(0.1337, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1628\n",
      "Loss: tensor(0.1337, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1629\n",
      "Loss: tensor(0.1337, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1630\n",
      "Loss: tensor(0.1337, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1631\n",
      "Loss: tensor(0.1337, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1632\n",
      "Loss: tensor(0.1337, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1633\n",
      "Loss: tensor(0.1337, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1634\n",
      "Loss: tensor(0.1337, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1635\n",
      "Loss: tensor(0.1337, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1636\n",
      "Loss: tensor(0.1337, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1637\n",
      "Loss: tensor(0.1337, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1638\n",
      "Loss: tensor(0.1337, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1639\n",
      "Loss: tensor(0.1337, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1640\n",
      "Loss: tensor(0.1337, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1641\n",
      "Loss: tensor(0.1337, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1642\n",
      "Loss: tensor(0.1337, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1643\n",
      "Loss: tensor(0.1337, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1644\n",
      "Loss: tensor(0.1337, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1645\n",
      "Loss: tensor(0.1337, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1646\n",
      "Loss: tensor(0.1337, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1647\n",
      "Loss: tensor(0.1337, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1648\n",
      "Loss: tensor(0.1337, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1649\n",
      "Loss: tensor(0.1337, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1650\n",
      "Loss: tensor(0.1337, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1651\n",
      "Loss: tensor(0.1337, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1652\n",
      "Loss: tensor(0.1337, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1653\n",
      "Loss: tensor(0.1337, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1654\n",
      "Loss: tensor(0.1337, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1655\n",
      "Loss: tensor(0.1337, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1656\n",
      "Loss: tensor(0.1337, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1657\n",
      "Loss: tensor(0.1337, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1658\n",
      "Loss: tensor(0.1337, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1659\n",
      "Loss: tensor(0.1337, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1660\n",
      "Loss: tensor(0.1337, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1661\n",
      "Loss: tensor(0.1337, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1662\n",
      "Loss: tensor(0.1337, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1663\n",
      "Loss: tensor(0.1337, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1664\n",
      "Loss: tensor(0.1337, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1665\n",
      "Loss: tensor(0.1337, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1666\n",
      "Loss: tensor(0.1337, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1667\n",
      "Loss: tensor(0.1337, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1668\n",
      "Loss: tensor(0.1337, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1669\n",
      "Loss: tensor(0.1337, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1670\n",
      "Loss: tensor(0.1336, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1671\n",
      "Loss: tensor(0.1336, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1672\n",
      "Loss: tensor(0.1336, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1673\n",
      "Loss: tensor(0.1336, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1674\n",
      "Loss: tensor(0.1336, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1675\n",
      "Loss: tensor(0.1336, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1676\n",
      "Loss: tensor(0.1336, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1677\n",
      "Loss: tensor(0.1336, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1678\n",
      "Loss: tensor(0.1336, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1679\n",
      "Loss: tensor(0.1336, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1680\n",
      "Loss: tensor(0.1336, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1681\n",
      "Loss: tensor(0.1336, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1682\n",
      "Loss: tensor(0.1336, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1683\n",
      "Loss: tensor(0.1336, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1684\n",
      "Loss: tensor(0.1336, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1685\n",
      "Loss: tensor(0.1336, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1686\n",
      "Loss: tensor(0.1336, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1687\n",
      "Loss: tensor(0.1336, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1688\n",
      "Loss: tensor(0.1336, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1689\n",
      "Loss: tensor(0.1336, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1690\n",
      "Loss: tensor(0.1336, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1691\n",
      "Loss: tensor(0.1336, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1692\n",
      "Loss: tensor(0.1336, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1693\n",
      "Loss: tensor(0.1336, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1694\n",
      "Loss: tensor(0.1336, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1695\n",
      "Loss: tensor(0.1336, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1696\n",
      "Loss: tensor(0.1336, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1697\n",
      "Loss: tensor(0.1336, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1698\n",
      "Loss: tensor(0.1336, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1699\n",
      "Loss: tensor(0.1336, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1700\n",
      "Loss: tensor(0.1336, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1701\n",
      "Loss: tensor(0.1336, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1702\n",
      "Loss: tensor(0.1336, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1703\n",
      "Loss: tensor(0.1336, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1704\n",
      "Loss: tensor(0.1336, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1705\n",
      "Loss: tensor(0.1336, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1706\n",
      "Loss: tensor(0.1336, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1707\n",
      "Loss: tensor(0.1336, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1708\n",
      "Loss: tensor(0.1336, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1709\n",
      "Loss: tensor(0.1336, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1710\n",
      "Loss: tensor(0.1336, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1711\n",
      "Loss: tensor(0.1336, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1712\n",
      "Loss: tensor(0.1336, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1713\n",
      "Loss: tensor(0.1336, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1714\n",
      "Loss: tensor(0.1335, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1715\n",
      "Loss: tensor(0.1335, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1716\n",
      "Loss: tensor(0.1335, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1717\n",
      "Loss: tensor(0.1335, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1718\n",
      "Loss: tensor(0.1335, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1719\n",
      "Loss: tensor(0.1335, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1720\n",
      "Loss: tensor(0.1335, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1721\n",
      "Loss: tensor(0.1335, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1722\n",
      "Loss: tensor(0.1335, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1723\n",
      "Loss: tensor(0.1335, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1724\n",
      "Loss: tensor(0.1335, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1725\n",
      "Loss: tensor(0.1335, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1726\n",
      "Loss: tensor(0.1335, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1727\n",
      "Loss: tensor(0.1335, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1728\n",
      "Loss: tensor(0.1335, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1729\n",
      "Loss: tensor(0.1335, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1730\n",
      "Loss: tensor(0.1335, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1731\n",
      "Loss: tensor(0.1335, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1732\n",
      "Loss: tensor(0.1335, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1733\n",
      "Loss: tensor(0.1335, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1734\n",
      "Loss: tensor(0.1335, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1735\n",
      "Loss: tensor(0.1335, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1736\n",
      "Loss: tensor(0.1335, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1737\n",
      "Loss: tensor(0.1335, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1738\n",
      "Loss: tensor(0.1335, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1739\n",
      "Loss: tensor(0.1335, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1740\n",
      "Loss: tensor(0.1335, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1741\n",
      "Loss: tensor(0.1335, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1742\n",
      "Loss: tensor(0.1335, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1743\n",
      "Loss: tensor(0.1335, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1744\n",
      "Loss: tensor(0.1335, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1745\n",
      "Loss: tensor(0.1335, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1746\n",
      "Loss: tensor(0.1335, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1747\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor(0.1335, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1748\n",
      "Loss: tensor(0.1335, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1749\n",
      "Loss: tensor(0.1335, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1750\n",
      "Loss: tensor(0.1335, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1751\n",
      "Loss: tensor(0.1335, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1752\n",
      "Loss: tensor(0.1335, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1753\n",
      "Loss: tensor(0.1335, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1754\n",
      "Loss: tensor(0.1335, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1755\n",
      "Loss: tensor(0.1335, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1756\n",
      "Loss: tensor(0.1335, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1757\n",
      "Loss: tensor(0.1335, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1758\n",
      "Loss: tensor(0.1334, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1759\n",
      "Loss: tensor(0.1334, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1760\n",
      "Loss: tensor(0.1334, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1761\n",
      "Loss: tensor(0.1334, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1762\n",
      "Loss: tensor(0.1334, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1763\n",
      "Loss: tensor(0.1334, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1764\n",
      "Loss: tensor(0.1334, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1765\n",
      "Loss: tensor(0.1334, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1766\n",
      "Loss: tensor(0.1334, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1767\n",
      "Loss: tensor(0.1334, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1768\n",
      "Loss: tensor(0.1334, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1769\n",
      "Loss: tensor(0.1334, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1770\n",
      "Loss: tensor(0.1334, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1771\n",
      "Loss: tensor(0.1334, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1772\n",
      "Loss: tensor(0.1334, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1773\n",
      "Loss: tensor(0.1334, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1774\n",
      "Loss: tensor(0.1334, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1775\n",
      "Loss: tensor(0.1334, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1776\n",
      "Loss: tensor(0.1334, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1777\n",
      "Loss: tensor(0.1334, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1778\n",
      "Loss: tensor(0.1334, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1779\n",
      "Loss: tensor(0.1334, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1780\n",
      "Loss: tensor(0.1334, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1781\n",
      "Loss: tensor(0.1334, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1782\n",
      "Loss: tensor(0.1334, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1783\n",
      "Loss: tensor(0.1334, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1784\n",
      "Loss: tensor(0.1334, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1785\n",
      "Loss: tensor(0.1334, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1786\n",
      "Loss: tensor(0.1334, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1787\n",
      "Loss: tensor(0.1334, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1788\n",
      "Loss: tensor(0.1334, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1789\n",
      "Loss: tensor(0.1334, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1790\n",
      "Loss: tensor(0.1334, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1791\n",
      "Loss: tensor(0.1334, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1792\n",
      "Loss: tensor(0.1334, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1793\n",
      "Loss: tensor(0.1334, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1794\n",
      "Loss: tensor(0.1334, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1795\n",
      "Loss: tensor(0.1334, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1796\n",
      "Loss: tensor(0.1334, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1797\n",
      "Loss: tensor(0.1334, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1798\n",
      "Loss: tensor(0.1334, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1799\n",
      "Loss: tensor(0.1334, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1800\n",
      "Loss: tensor(0.1334, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1801\n",
      "Loss: tensor(0.1333, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1802\n",
      "Loss: tensor(0.1333, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1803\n",
      "Loss: tensor(0.1333, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1804\n",
      "Loss: tensor(0.1333, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1805\n",
      "Loss: tensor(0.1333, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1806\n",
      "Loss: tensor(0.1333, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1807\n",
      "Loss: tensor(0.1333, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1808\n",
      "Loss: tensor(0.1333, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1809\n",
      "Loss: tensor(0.1333, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1810\n",
      "Loss: tensor(0.1333, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1811\n",
      "Loss: tensor(0.1333, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1812\n",
      "Loss: tensor(0.1333, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1813\n",
      "Loss: tensor(0.1333, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1814\n",
      "Loss: tensor(0.1333, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1815\n",
      "Loss: tensor(0.1333, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1816\n",
      "Loss: tensor(0.1333, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1817\n",
      "Loss: tensor(0.1333, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1818\n",
      "Loss: tensor(0.1333, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1819\n",
      "Loss: tensor(0.1333, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1820\n",
      "Loss: tensor(0.1333, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1821\n",
      "Loss: tensor(0.1333, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1822\n",
      "Loss: tensor(0.1333, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1823\n",
      "Loss: tensor(0.1333, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1824\n",
      "Loss: tensor(0.1333, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1825\n",
      "Loss: tensor(0.1333, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1826\n",
      "Loss: tensor(0.1333, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1827\n",
      "Loss: tensor(0.1333, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1828\n",
      "Loss: tensor(0.1333, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1829\n",
      "Loss: tensor(0.1333, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1830\n",
      "Loss: tensor(0.1333, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1831\n",
      "Loss: tensor(0.1333, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1832\n",
      "Loss: tensor(0.1333, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1833\n",
      "Loss: tensor(0.1333, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1834\n",
      "Loss: tensor(0.1333, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1835\n",
      "Loss: tensor(0.1333, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1836\n",
      "Loss: tensor(0.1333, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1837\n",
      "Loss: tensor(0.1333, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1838\n",
      "Loss: tensor(0.1333, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1839\n",
      "Loss: tensor(0.1333, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1840\n",
      "Loss: tensor(0.1332, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1841\n",
      "Loss: tensor(0.1332, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1842\n",
      "Loss: tensor(0.1332, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1843\n",
      "Loss: tensor(0.1332, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1844\n",
      "Loss: tensor(0.1332, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1845\n",
      "Loss: tensor(0.1332, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1846\n",
      "Loss: tensor(0.1332, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1847\n",
      "Loss: tensor(0.1332, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1848\n",
      "Loss: tensor(0.1332, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1849\n",
      "Loss: tensor(0.1332, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1850\n",
      "Loss: tensor(0.1332, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1851\n",
      "Loss: tensor(0.1332, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1852\n",
      "Loss: tensor(0.1332, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1853\n",
      "Loss: tensor(0.1332, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1854\n",
      "Loss: tensor(0.1332, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1855\n",
      "Loss: tensor(0.1332, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1856\n",
      "Loss: tensor(0.1332, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1857\n",
      "Loss: tensor(0.1332, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1858\n",
      "Loss: tensor(0.1332, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1859\n",
      "Loss: tensor(0.1332, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1860\n",
      "Loss: tensor(0.1332, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1861\n",
      "Loss: tensor(0.1332, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1862\n",
      "Loss: tensor(0.1332, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1863\n",
      "Loss: tensor(0.1332, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1864\n",
      "Loss: tensor(0.1332, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1865\n",
      "Loss: tensor(0.1332, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1866\n",
      "Loss: tensor(0.1332, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1867\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor(0.1332, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1868\n",
      "Loss: tensor(0.1332, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1869\n",
      "Loss: tensor(0.1332, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1870\n",
      "Loss: tensor(0.1332, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1871\n",
      "Loss: tensor(0.1332, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1872\n",
      "Loss: tensor(0.1332, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1873\n",
      "Loss: tensor(0.1332, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1874\n",
      "Loss: tensor(0.1332, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1875\n",
      "Loss: tensor(0.1331, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1876\n",
      "Loss: tensor(0.1331, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1877\n",
      "Loss: tensor(0.1331, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1878\n",
      "Loss: tensor(0.1331, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1879\n",
      "Loss: tensor(0.1331, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1880\n",
      "Loss: tensor(0.1331, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1881\n",
      "Loss: tensor(0.1331, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1882\n",
      "Loss: tensor(0.1331, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1883\n",
      "Loss: tensor(0.1331, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1884\n",
      "Loss: tensor(0.1331, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1885\n",
      "Loss: tensor(0.1331, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1886\n",
      "Loss: tensor(0.1331, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1887\n",
      "Loss: tensor(0.1331, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1888\n",
      "Loss: tensor(0.1331, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1889\n",
      "Loss: tensor(0.1331, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1890\n",
      "Loss: tensor(0.1331, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1891\n",
      "Loss: tensor(0.1331, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1892\n",
      "Loss: tensor(0.1331, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1893\n",
      "Loss: tensor(0.1331, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1894\n",
      "Loss: tensor(0.1331, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1895\n",
      "Loss: tensor(0.1331, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1896\n",
      "Loss: tensor(0.1331, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1897\n",
      "Loss: tensor(0.1331, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1898\n",
      "Loss: tensor(0.1331, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1899\n",
      "Loss: tensor(0.1331, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1900\n",
      "Loss: tensor(0.1331, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1901\n",
      "Loss: tensor(0.1331, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1902\n",
      "Loss: tensor(0.1331, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1903\n",
      "Loss: tensor(0.1331, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1904\n",
      "Loss: tensor(0.1331, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1905\n",
      "Loss: tensor(0.1330, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1906\n",
      "Loss: tensor(0.1330, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1907\n",
      "Loss: tensor(0.1330, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1908\n",
      "Loss: tensor(0.1330, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1909\n",
      "Loss: tensor(0.1330, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1910\n",
      "Loss: tensor(0.1330, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1911\n",
      "Loss: tensor(0.1330, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1912\n",
      "Loss: tensor(0.1330, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1913\n",
      "Loss: tensor(0.1330, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1914\n",
      "Loss: tensor(0.1330, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1915\n",
      "Loss: tensor(0.1330, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1916\n",
      "Loss: tensor(0.1330, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1917\n",
      "Loss: tensor(0.1330, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1918\n",
      "Loss: tensor(0.1330, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1919\n",
      "Loss: tensor(0.1330, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1920\n",
      "Loss: tensor(0.1330, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1921\n",
      "Loss: tensor(0.1330, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1922\n",
      "Loss: tensor(0.1330, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1923\n",
      "Loss: tensor(0.1330, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1924\n",
      "Loss: tensor(0.1330, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1925\n",
      "Loss: tensor(0.1330, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1926\n",
      "Loss: tensor(0.1330, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1927\n",
      "Loss: tensor(0.1330, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1928\n",
      "Loss: tensor(0.1330, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1929\n",
      "Loss: tensor(0.1330, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1930\n",
      "Loss: tensor(0.1330, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1931\n",
      "Loss: tensor(0.1329, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1932\n",
      "Loss: tensor(0.1329, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1933\n",
      "Loss: tensor(0.1329, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1934\n",
      "Loss: tensor(0.1329, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1935\n",
      "Loss: tensor(0.1329, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1936\n",
      "Loss: tensor(0.1329, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1937\n",
      "Loss: tensor(0.1329, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1938\n",
      "Loss: tensor(0.1329, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1939\n",
      "Loss: tensor(0.1329, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1940\n",
      "Loss: tensor(0.1329, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1941\n",
      "Loss: tensor(0.1329, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1942\n",
      "Loss: tensor(0.1329, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1943\n",
      "Loss: tensor(0.1329, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1944\n",
      "Loss: tensor(0.1329, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1945\n",
      "Loss: tensor(0.1329, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1946\n",
      "Loss: tensor(0.1329, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1947\n",
      "Loss: tensor(0.1329, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1948\n",
      "Loss: tensor(0.1329, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1949\n",
      "Loss: tensor(0.1329, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1950\n",
      "Loss: tensor(0.1329, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1951\n",
      "Loss: tensor(0.1329, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1952\n",
      "Loss: tensor(0.1329, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1953\n",
      "Loss: tensor(0.1329, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1954\n",
      "Loss: tensor(0.1329, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1955\n",
      "Loss: tensor(0.1328, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1956\n",
      "Loss: tensor(0.1328, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1957\n",
      "Loss: tensor(0.1328, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1958\n",
      "Loss: tensor(0.1328, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1959\n",
      "Loss: tensor(0.1328, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1960\n",
      "Loss: tensor(0.1328, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1961\n",
      "Loss: tensor(0.1328, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1962\n",
      "Loss: tensor(0.1328, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1963\n",
      "Loss: tensor(0.1328, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1964\n",
      "Loss: tensor(0.1328, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1965\n",
      "Loss: tensor(0.1328, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1966\n",
      "Loss: tensor(0.1328, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1967\n",
      "Loss: tensor(0.1328, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1968\n",
      "Loss: tensor(0.1328, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1969\n",
      "Loss: tensor(0.1328, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1970\n",
      "Loss: tensor(0.1328, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1971\n",
      "Loss: tensor(0.1328, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1972\n",
      "Loss: tensor(0.1328, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1973\n",
      "Loss: tensor(0.1328, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1974\n",
      "Loss: tensor(0.1328, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1975\n",
      "Loss: tensor(0.1328, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1976\n",
      "Loss: tensor(0.1328, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1977\n",
      "Loss: tensor(0.1327, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1978\n",
      "Loss: tensor(0.1327, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1979\n",
      "Loss: tensor(0.1327, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1980\n",
      "Loss: tensor(0.1327, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1981\n",
      "Loss: tensor(0.1327, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1982\n",
      "Loss: tensor(0.1327, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1983\n",
      "Loss: tensor(0.1327, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1984\n",
      "Loss: tensor(0.1327, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1985\n",
      "Loss: tensor(0.1327, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1986\n",
      "Loss: tensor(0.1327, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1987\n",
      "Loss: tensor(0.1327, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1988\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor(0.1327, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1989\n",
      "Loss: tensor(0.1327, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1990\n",
      "Loss: tensor(0.1327, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1991\n",
      "Loss: tensor(0.1327, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1992\n",
      "Loss: tensor(0.1327, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1993\n",
      "Loss: tensor(0.1327, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1994\n",
      "Loss: tensor(0.1327, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1995\n",
      "Loss: tensor(0.1327, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1996\n",
      "Loss: tensor(0.1327, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1997\n",
      "Loss: tensor(0.1326, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1998\n",
      "Loss: tensor(0.1326, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1999\n",
      "Loss: tensor(0.1326, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2000\n",
      "Loss: tensor(0.1326, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2001\n",
      "Loss: tensor(0.1326, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2002\n",
      "Loss: tensor(0.1326, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2003\n",
      "Loss: tensor(0.1326, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2004\n",
      "Loss: tensor(0.1326, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2005\n",
      "Loss: tensor(0.1326, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2006\n",
      "Loss: tensor(0.1326, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2007\n",
      "Loss: tensor(0.1326, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2008\n",
      "Loss: tensor(0.1326, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2009\n",
      "Loss: tensor(0.1326, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2010\n",
      "Loss: tensor(0.1326, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2011\n",
      "Loss: tensor(0.1326, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2012\n",
      "Loss: tensor(0.1326, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2013\n",
      "Loss: tensor(0.1326, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2014\n",
      "Loss: tensor(0.1326, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2015\n",
      "Loss: tensor(0.1326, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2016\n",
      "Loss: tensor(0.1325, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2017\n",
      "Loss: tensor(0.1325, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2018\n",
      "Loss: tensor(0.1325, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2019\n",
      "Loss: tensor(0.1325, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2020\n",
      "Loss: tensor(0.1325, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2021\n",
      "Loss: tensor(0.1325, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2022\n",
      "Loss: tensor(0.1325, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2023\n",
      "Loss: tensor(0.1325, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2024\n",
      "Loss: tensor(0.1325, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2025\n",
      "Loss: tensor(0.1325, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2026\n",
      "Loss: tensor(0.1325, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2027\n",
      "Loss: tensor(0.1325, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2028\n",
      "Loss: tensor(0.1325, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2029\n",
      "Loss: tensor(0.1325, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2030\n",
      "Loss: tensor(0.1325, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2031\n",
      "Loss: tensor(0.1325, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2032\n",
      "Loss: tensor(0.1324, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2033\n",
      "Loss: tensor(0.1324, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2034\n",
      "Loss: tensor(0.1324, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2035\n",
      "Loss: tensor(0.1324, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2036\n",
      "Loss: tensor(0.1324, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2037\n",
      "Loss: tensor(0.1324, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2038\n",
      "Loss: tensor(0.1324, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2039\n",
      "Loss: tensor(0.1324, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2040\n",
      "Loss: tensor(0.1324, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2041\n",
      "Loss: tensor(0.1324, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2042\n",
      "Loss: tensor(0.1324, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2043\n",
      "Loss: tensor(0.1324, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2044\n",
      "Loss: tensor(0.1324, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2045\n",
      "Loss: tensor(0.1324, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2046\n",
      "Loss: tensor(0.1324, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2047\n",
      "Loss: tensor(0.1324, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2048\n",
      "Loss: tensor(0.1324, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2049\n",
      "Loss: tensor(0.1323, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2050\n",
      "Loss: tensor(0.1323, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2051\n",
      "Loss: tensor(0.1323, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2052\n",
      "Loss: tensor(0.1323, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2053\n",
      "Loss: tensor(0.1323, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2054\n",
      "Loss: tensor(0.1323, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2055\n",
      "Loss: tensor(0.1323, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2056\n",
      "Loss: tensor(0.1323, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2057\n",
      "Loss: tensor(0.1323, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2058\n",
      "Loss: tensor(0.1323, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2059\n",
      "Loss: tensor(0.1323, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2060\n",
      "Loss: tensor(0.1323, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2061\n",
      "Loss: tensor(0.1323, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2062\n",
      "Loss: tensor(0.1323, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2063\n",
      "Loss: tensor(0.1322, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2064\n",
      "Loss: tensor(0.1322, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2065\n",
      "Loss: tensor(0.1322, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2066\n",
      "Loss: tensor(0.1322, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2067\n",
      "Loss: tensor(0.1322, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2068\n",
      "Loss: tensor(0.1322, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2069\n",
      "Loss: tensor(0.1322, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2070\n",
      "Loss: tensor(0.1322, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2071\n",
      "Loss: tensor(0.1322, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2072\n",
      "Loss: tensor(0.1322, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2073\n",
      "Loss: tensor(0.1322, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2074\n",
      "Loss: tensor(0.1322, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2075\n",
      "Loss: tensor(0.1322, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2076\n",
      "Loss: tensor(0.1322, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2077\n",
      "Loss: tensor(0.1322, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2078\n",
      "Loss: tensor(0.1321, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2079\n",
      "Loss: tensor(0.1321, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2080\n",
      "Loss: tensor(0.1321, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2081\n",
      "Loss: tensor(0.1321, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2082\n",
      "Loss: tensor(0.1321, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2083\n",
      "Loss: tensor(0.1321, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2084\n",
      "Loss: tensor(0.1321, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2085\n",
      "Loss: tensor(0.1321, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2086\n",
      "Loss: tensor(0.1321, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2087\n",
      "Loss: tensor(0.1321, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2088\n",
      "Loss: tensor(0.1321, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2089\n",
      "Loss: tensor(0.1321, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2090\n",
      "Loss: tensor(0.1321, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2091\n",
      "Loss: tensor(0.1321, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2092\n",
      "Loss: tensor(0.1320, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2093\n",
      "Loss: tensor(0.1320, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2094\n",
      "Loss: tensor(0.1320, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2095\n",
      "Loss: tensor(0.1320, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2096\n",
      "Loss: tensor(0.1320, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2097\n",
      "Loss: tensor(0.1320, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2098\n",
      "Loss: tensor(0.1320, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2099\n",
      "Loss: tensor(0.1320, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2100\n",
      "Loss: tensor(0.1320, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2101\n",
      "Loss: tensor(0.1320, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2102\n",
      "Loss: tensor(0.1320, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2103\n",
      "Loss: tensor(0.1320, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2104\n",
      "Loss: tensor(0.1320, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2105\n",
      "Loss: tensor(0.1320, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2106\n",
      "Loss: tensor(0.1319, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2107\n",
      "Loss: tensor(0.1319, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2108\n",
      "Loss: tensor(0.1319, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2109\n",
      "Loss: tensor(0.1319, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2110\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor(0.1319, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2111\n",
      "Loss: tensor(0.1319, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2112\n",
      "Loss: tensor(0.1319, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2113\n",
      "Loss: tensor(0.1319, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2114\n",
      "Loss: tensor(0.1319, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2115\n",
      "Loss: tensor(0.1319, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2116\n",
      "Loss: tensor(0.1319, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2117\n",
      "Loss: tensor(0.1319, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2118\n",
      "Loss: tensor(0.1319, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2119\n",
      "Loss: tensor(0.1319, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2120\n",
      "Loss: tensor(0.1318, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2121\n",
      "Loss: tensor(0.1318, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2122\n",
      "Loss: tensor(0.1318, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2123\n",
      "Loss: tensor(0.1318, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2124\n",
      "Loss: tensor(0.1318, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2125\n",
      "Loss: tensor(0.1318, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2126\n",
      "Loss: tensor(0.1318, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2127\n",
      "Loss: tensor(0.1318, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2128\n",
      "Loss: tensor(0.1318, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2129\n",
      "Loss: tensor(0.1318, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2130\n",
      "Loss: tensor(0.1318, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2131\n",
      "Loss: tensor(0.1318, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2132\n",
      "Loss: tensor(0.1318, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2133\n",
      "Loss: tensor(0.1318, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2134\n",
      "Loss: tensor(0.1317, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2135\n",
      "Loss: tensor(0.1317, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2136\n",
      "Loss: tensor(0.1317, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2137\n",
      "Loss: tensor(0.1317, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2138\n",
      "Loss: tensor(0.1317, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2139\n",
      "Loss: tensor(0.1317, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2140\n",
      "Loss: tensor(0.1317, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2141\n",
      "Loss: tensor(0.1317, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2142\n",
      "Loss: tensor(0.1317, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2143\n",
      "Loss: tensor(0.1317, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2144\n",
      "Loss: tensor(0.1317, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2145\n",
      "Loss: tensor(0.1317, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2146\n",
      "Loss: tensor(0.1317, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2147\n",
      "Loss: tensor(0.1317, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2148\n",
      "Loss: tensor(0.1316, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2149\n",
      "Loss: tensor(0.1316, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2150\n",
      "Loss: tensor(0.1316, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2151\n",
      "Loss: tensor(0.1316, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2152\n",
      "Loss: tensor(0.1316, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2153\n",
      "Loss: tensor(0.1316, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2154\n",
      "Loss: tensor(0.1316, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2155\n",
      "Loss: tensor(0.1316, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2156\n",
      "Loss: tensor(0.1316, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2157\n",
      "Loss: tensor(0.1316, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2158\n",
      "Loss: tensor(0.1316, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2159\n",
      "Loss: tensor(0.1316, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2160\n",
      "Loss: tensor(0.1316, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2161\n",
      "Loss: tensor(0.1316, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2162\n",
      "Loss: tensor(0.1315, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2163\n",
      "Loss: tensor(0.1315, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2164\n",
      "Loss: tensor(0.1315, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2165\n",
      "Loss: tensor(0.1315, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2166\n",
      "Loss: tensor(0.1315, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2167\n",
      "Loss: tensor(0.1315, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2168\n",
      "Loss: tensor(0.1315, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2169\n",
      "Loss: tensor(0.1315, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2170\n",
      "Loss: tensor(0.1315, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2171\n",
      "Loss: tensor(0.1315, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2172\n",
      "Loss: tensor(0.1315, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2173\n",
      "Loss: tensor(0.1315, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2174\n",
      "Loss: tensor(0.1315, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2175\n",
      "Loss: tensor(0.1315, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2176\n",
      "Loss: tensor(0.1315, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2177\n",
      "Loss: tensor(0.1314, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2178\n",
      "Loss: tensor(0.1314, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2179\n",
      "Loss: tensor(0.1314, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2180\n",
      "Loss: tensor(0.1314, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2181\n",
      "Loss: tensor(0.1314, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2182\n",
      "Loss: tensor(0.1314, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2183\n",
      "Loss: tensor(0.1314, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2184\n",
      "Loss: tensor(0.1314, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2185\n",
      "Loss: tensor(0.1314, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2186\n",
      "Loss: tensor(0.1314, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2187\n",
      "Loss: tensor(0.1314, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2188\n",
      "Loss: tensor(0.1314, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2189\n",
      "Loss: tensor(0.1314, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2190\n",
      "Loss: tensor(0.1314, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2191\n",
      "Loss: tensor(0.1313, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2192\n",
      "Loss: tensor(0.1313, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2193\n",
      "Loss: tensor(0.1313, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2194\n",
      "Loss: tensor(0.1313, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2195\n",
      "Loss: tensor(0.1313, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2196\n",
      "Loss: tensor(0.1313, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2197\n",
      "Loss: tensor(0.1313, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2198\n",
      "Loss: tensor(0.1313, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2199\n",
      "Loss: tensor(0.1313, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2200\n",
      "Loss: tensor(0.1313, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2201\n",
      "Loss: tensor(0.1313, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2202\n",
      "Loss: tensor(0.1313, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2203\n",
      "Loss: tensor(0.1313, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2204\n",
      "Loss: tensor(0.1313, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2205\n",
      "Loss: tensor(0.1313, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2206\n",
      "Loss: tensor(0.1312, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2207\n",
      "Loss: tensor(0.1312, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2208\n",
      "Loss: tensor(0.1312, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2209\n",
      "Loss: tensor(0.1312, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2210\n",
      "Loss: tensor(0.1312, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2211\n",
      "Loss: tensor(0.1312, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2212\n",
      "Loss: tensor(0.1312, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2213\n",
      "Loss: tensor(0.1312, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2214\n",
      "Loss: tensor(0.1312, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2215\n",
      "Loss: tensor(0.1312, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2216\n",
      "Loss: tensor(0.1312, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2217\n",
      "Loss: tensor(0.1312, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2218\n",
      "Loss: tensor(0.1312, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2219\n",
      "Loss: tensor(0.1312, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2220\n",
      "Loss: tensor(0.1312, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2221\n",
      "Loss: tensor(0.1311, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2222\n",
      "Loss: tensor(0.1311, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2223\n",
      "Loss: tensor(0.1311, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2224\n",
      "Loss: tensor(0.1311, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2225\n",
      "Loss: tensor(0.1311, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2226\n",
      "Loss: tensor(0.1311, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2227\n",
      "Loss: tensor(0.1311, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2228\n",
      "Loss: tensor(0.1311, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2229\n",
      "Loss: tensor(0.1311, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2230\n",
      "Loss: tensor(0.1311, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2231\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor(0.1311, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2232\n",
      "Loss: tensor(0.1311, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2233\n",
      "Loss: tensor(0.1311, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2234\n",
      "Loss: tensor(0.1311, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2235\n",
      "Loss: tensor(0.1311, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2236\n",
      "Loss: tensor(0.1310, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2237\n",
      "Loss: tensor(0.1310, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2238\n",
      "Loss: tensor(0.1310, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2239\n",
      "Loss: tensor(0.1310, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2240\n",
      "Loss: tensor(0.1310, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2241\n",
      "Loss: tensor(0.1310, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2242\n",
      "Loss: tensor(0.1310, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2243\n",
      "Loss: tensor(0.1310, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2244\n",
      "Loss: tensor(0.1310, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2245\n",
      "Loss: tensor(0.1310, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2246\n",
      "Loss: tensor(0.1310, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2247\n",
      "Loss: tensor(0.1310, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2248\n",
      "Loss: tensor(0.1310, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2249\n",
      "Loss: tensor(0.1310, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2250\n",
      "Loss: tensor(0.1310, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2251\n",
      "Loss: tensor(0.1309, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2252\n",
      "Loss: tensor(0.1309, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2253\n",
      "Loss: tensor(0.1309, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2254\n",
      "Loss: tensor(0.1309, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2255\n",
      "Loss: tensor(0.1309, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2256\n",
      "Loss: tensor(0.1309, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2257\n",
      "Loss: tensor(0.1309, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2258\n",
      "Loss: tensor(0.1309, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2259\n",
      "Loss: tensor(0.1309, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2260\n",
      "Loss: tensor(0.1309, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2261\n",
      "Loss: tensor(0.1309, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2262\n",
      "Loss: tensor(0.1309, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2263\n",
      "Loss: tensor(0.1309, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2264\n",
      "Loss: tensor(0.1309, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2265\n",
      "Loss: tensor(0.1309, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2266\n",
      "Loss: tensor(0.1308, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2267\n",
      "Loss: tensor(0.1308, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2268\n",
      "Loss: tensor(0.1308, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2269\n",
      "Loss: tensor(0.1308, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2270\n",
      "Loss: tensor(0.1308, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2271\n",
      "Loss: tensor(0.1308, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2272\n",
      "Loss: tensor(0.1308, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2273\n",
      "Loss: tensor(0.1308, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2274\n",
      "Loss: tensor(0.1308, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2275\n",
      "Loss: tensor(0.1308, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2276\n",
      "Loss: tensor(0.1308, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2277\n",
      "Loss: tensor(0.1308, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2278\n",
      "Loss: tensor(0.1308, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2279\n",
      "Loss: tensor(0.1308, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2280\n",
      "Loss: tensor(0.1308, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2281\n",
      "Loss: tensor(0.1307, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2282\n",
      "Loss: tensor(0.1307, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2283\n",
      "Loss: tensor(0.1307, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2284\n",
      "Loss: tensor(0.1307, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2285\n",
      "Loss: tensor(0.1307, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2286\n",
      "Loss: tensor(0.1307, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2287\n",
      "Loss: tensor(0.1307, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2288\n",
      "Loss: tensor(0.1307, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2289\n",
      "Loss: tensor(0.1307, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2290\n",
      "Loss: tensor(0.1307, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2291\n",
      "Loss: tensor(0.1307, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2292\n",
      "Loss: tensor(0.1307, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2293\n",
      "Loss: tensor(0.1307, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2294\n",
      "Loss: tensor(0.1307, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2295\n",
      "Loss: tensor(0.1307, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2296\n",
      "Loss: tensor(0.1307, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2297\n",
      "Loss: tensor(0.1306, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2298\n",
      "Loss: tensor(0.1306, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2299\n",
      "Loss: tensor(0.1306, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2300\n",
      "Loss: tensor(0.1306, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2301\n",
      "Loss: tensor(0.1306, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2302\n",
      "Loss: tensor(0.1306, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2303\n",
      "Loss: tensor(0.1306, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2304\n",
      "Loss: tensor(0.1306, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2305\n",
      "Loss: tensor(0.1306, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2306\n",
      "Loss: tensor(0.1306, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2307\n",
      "Loss: tensor(0.1306, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2308\n",
      "Loss: tensor(0.1306, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2309\n",
      "Loss: tensor(0.1306, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2310\n",
      "Loss: tensor(0.1306, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2311\n",
      "Loss: tensor(0.1305, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2312\n",
      "Loss: tensor(0.1305, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2313\n",
      "Loss: tensor(0.1305, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2314\n",
      "Loss: tensor(0.1305, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2315\n",
      "Loss: tensor(0.1305, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2316\n",
      "Loss: tensor(0.1305, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2317\n",
      "Loss: tensor(0.1305, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2318\n",
      "Loss: tensor(0.1305, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2319\n",
      "Loss: tensor(0.1305, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2320\n",
      "Loss: tensor(0.1305, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2321\n",
      "Loss: tensor(0.1305, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2322\n",
      "Loss: tensor(0.1305, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2323\n",
      "Loss: tensor(0.1305, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2324\n",
      "Loss: tensor(0.1305, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2325\n",
      "Loss: tensor(0.1305, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2326\n",
      "Loss: tensor(0.1304, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2327\n",
      "Loss: tensor(0.1304, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2328\n",
      "Loss: tensor(0.1304, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2329\n",
      "Loss: tensor(0.1304, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2330\n",
      "Loss: tensor(0.1304, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2331\n",
      "Loss: tensor(0.1304, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2332\n",
      "Loss: tensor(0.1304, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2333\n",
      "Loss: tensor(0.1304, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2334\n",
      "Loss: tensor(0.1304, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2335\n",
      "Loss: tensor(0.1304, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2336\n",
      "Loss: tensor(0.1304, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2337\n",
      "Loss: tensor(0.1304, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2338\n",
      "Loss: tensor(0.1304, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2339\n",
      "Loss: tensor(0.1304, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2340\n",
      "Loss: tensor(0.1304, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2341\n",
      "Loss: tensor(0.1303, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2342\n",
      "Loss: tensor(0.1303, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2343\n",
      "Loss: tensor(0.1303, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2344\n",
      "Loss: tensor(0.1303, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2345\n",
      "Loss: tensor(0.1303, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2346\n",
      "Loss: tensor(0.1303, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2347\n",
      "Loss: tensor(0.1303, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2348\n",
      "Loss: tensor(0.1303, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2349\n",
      "Loss: tensor(0.1303, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2350\n",
      "Loss: tensor(0.1303, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2351\n",
      "Loss: tensor(0.1303, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2352\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor(0.1303, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2353\n",
      "Loss: tensor(0.1303, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2354\n",
      "Loss: tensor(0.1303, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2355\n",
      "Loss: tensor(0.1302, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2356\n",
      "Loss: tensor(0.1302, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2357\n",
      "Loss: tensor(0.1302, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2358\n",
      "Loss: tensor(0.1302, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2359\n",
      "Loss: tensor(0.1302, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2360\n",
      "Loss: tensor(0.1302, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2361\n",
      "Loss: tensor(0.1302, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2362\n",
      "Loss: tensor(0.1302, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2363\n",
      "Loss: tensor(0.1302, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2364\n",
      "Loss: tensor(0.1302, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2365\n",
      "Loss: tensor(0.1302, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2366\n",
      "Loss: tensor(0.1302, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2367\n",
      "Loss: tensor(0.1302, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2368\n",
      "Loss: tensor(0.1302, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2369\n",
      "Loss: tensor(0.1302, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2370\n",
      "Loss: tensor(0.1301, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2371\n",
      "Loss: tensor(0.1301, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2372\n",
      "Loss: tensor(0.1301, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2373\n",
      "Loss: tensor(0.1301, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2374\n",
      "Loss: tensor(0.1301, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2375\n",
      "Loss: tensor(0.1301, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2376\n",
      "Loss: tensor(0.1301, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2377\n",
      "Loss: tensor(0.1301, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2378\n",
      "Loss: tensor(0.1301, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2379\n",
      "Loss: tensor(0.1301, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2380\n",
      "Loss: tensor(0.1301, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2381\n",
      "Loss: tensor(0.1301, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2382\n",
      "Loss: tensor(0.1301, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2383\n",
      "Loss: tensor(0.1301, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2384\n",
      "Loss: tensor(0.1300, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2385\n",
      "Loss: tensor(0.1300, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2386\n",
      "Loss: tensor(0.1300, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2387\n",
      "Loss: tensor(0.1300, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2388\n",
      "Loss: tensor(0.1300, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2389\n",
      "Loss: tensor(0.1300, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2390\n",
      "Loss: tensor(0.1300, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2391\n",
      "Loss: tensor(0.1300, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2392\n",
      "Loss: tensor(0.1300, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2393\n",
      "Loss: tensor(0.1300, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2394\n",
      "Loss: tensor(0.1300, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2395\n",
      "Loss: tensor(0.1300, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2396\n",
      "Loss: tensor(0.1300, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2397\n",
      "Loss: tensor(0.1300, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2398\n",
      "Loss: tensor(0.1299, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2399\n",
      "Loss: tensor(0.1299, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2400\n",
      "Loss: tensor(0.1299, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2401\n",
      "Loss: tensor(0.1299, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2402\n",
      "Loss: tensor(0.1299, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2403\n",
      "Loss: tensor(0.1299, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2404\n",
      "Loss: tensor(0.1299, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2405\n",
      "Loss: tensor(0.1299, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2406\n",
      "Loss: tensor(0.1299, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2407\n",
      "Loss: tensor(0.1299, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2408\n",
      "Loss: tensor(0.1299, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2409\n",
      "Loss: tensor(0.1299, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2410\n",
      "Loss: tensor(0.1299, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2411\n",
      "Loss: tensor(0.1299, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2412\n",
      "Loss: tensor(0.1298, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2413\n",
      "Loss: tensor(0.1298, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2414\n",
      "Loss: tensor(0.1298, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2415\n",
      "Loss: tensor(0.1298, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2416\n",
      "Loss: tensor(0.1298, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2417\n",
      "Loss: tensor(0.1298, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2418\n",
      "Loss: tensor(0.1298, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2419\n",
      "Loss: tensor(0.1298, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2420\n",
      "Loss: tensor(0.1298, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2421\n",
      "Loss: tensor(0.1298, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2422\n",
      "Loss: tensor(0.1298, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2423\n",
      "Loss: tensor(0.1298, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2424\n",
      "Loss: tensor(0.1298, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2425\n",
      "Loss: tensor(0.1298, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2426\n",
      "Loss: tensor(0.1297, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2427\n",
      "Loss: tensor(0.1297, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2428\n",
      "Loss: tensor(0.1297, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2429\n",
      "Loss: tensor(0.1297, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2430\n",
      "Loss: tensor(0.1297, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2431\n",
      "Loss: tensor(0.1297, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2432\n",
      "Loss: tensor(0.1297, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2433\n",
      "Loss: tensor(0.1297, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2434\n",
      "Loss: tensor(0.1297, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2435\n",
      "Loss: tensor(0.1297, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2436\n",
      "Loss: tensor(0.1297, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2437\n",
      "Loss: tensor(0.1297, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2438\n",
      "Loss: tensor(0.1297, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2439\n",
      "Loss: tensor(0.1297, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2440\n",
      "Loss: tensor(0.1297, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2441\n",
      "Loss: tensor(0.1296, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2442\n",
      "Loss: tensor(0.1296, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2443\n",
      "Loss: tensor(0.1296, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2444\n",
      "Loss: tensor(0.1296, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2445\n",
      "Loss: tensor(0.1296, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2446\n",
      "Loss: tensor(0.1296, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2447\n",
      "Loss: tensor(0.1296, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2448\n",
      "Loss: tensor(0.1296, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2449\n",
      "Loss: tensor(0.1296, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2450\n",
      "Loss: tensor(0.1296, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2451\n",
      "Loss: tensor(0.1296, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2452\n",
      "Loss: tensor(0.1296, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2453\n",
      "Loss: tensor(0.1295, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2454\n",
      "Loss: tensor(0.1295, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2455\n",
      "Loss: tensor(0.1295, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2456\n",
      "Loss: tensor(0.1295, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2457\n",
      "Loss: tensor(0.1295, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2458\n",
      "Loss: tensor(0.1295, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2459\n",
      "Loss: tensor(0.1295, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2460\n",
      "Loss: tensor(0.1295, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2461\n",
      "Loss: tensor(0.1295, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2462\n",
      "Loss: tensor(0.1295, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2463\n",
      "Loss: tensor(0.1295, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2464\n",
      "Loss: tensor(0.1295, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2465\n",
      "Loss: tensor(0.1295, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2466\n",
      "Loss: tensor(0.1294, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2467\n",
      "Loss: tensor(0.1294, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2468\n",
      "Loss: tensor(0.1294, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2469\n",
      "Loss: tensor(0.1294, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2470\n",
      "Loss: tensor(0.1294, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2471\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor(0.1294, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2472\n",
      "Loss: tensor(0.1294, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2473\n",
      "Loss: tensor(0.1294, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2474\n",
      "Loss: tensor(0.1294, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2475\n",
      "Loss: tensor(0.1294, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2476\n",
      "Loss: tensor(0.1294, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2477\n",
      "Loss: tensor(0.1294, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2478\n",
      "Loss: tensor(0.1294, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2479\n",
      "Loss: tensor(0.1293, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2480\n",
      "Loss: tensor(0.1293, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2481\n",
      "Loss: tensor(0.1293, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2482\n",
      "Loss: tensor(0.1293, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2483\n",
      "Loss: tensor(0.1293, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2484\n",
      "Loss: tensor(0.1293, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2485\n",
      "Loss: tensor(0.1293, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2486\n",
      "Loss: tensor(0.1293, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2487\n",
      "Loss: tensor(0.1293, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2488\n",
      "Loss: tensor(0.1293, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2489\n",
      "Loss: tensor(0.1293, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2490\n",
      "Loss: tensor(0.1293, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2491\n",
      "Loss: tensor(0.1293, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2492\n",
      "Loss: tensor(0.1292, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2493\n",
      "Loss: tensor(0.1292, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2494\n",
      "Loss: tensor(0.1292, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2495\n",
      "Loss: tensor(0.1292, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2496\n",
      "Loss: tensor(0.1292, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2497\n",
      "Loss: tensor(0.1292, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2498\n",
      "Loss: tensor(0.1292, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2499\n",
      "Loss: tensor(0.1292, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2500\n",
      "Loss: tensor(0.1292, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2501\n",
      "Loss: tensor(0.1292, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2502\n",
      "Loss: tensor(0.1292, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2503\n",
      "Loss: tensor(0.1292, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2504\n",
      "Loss: tensor(0.1291, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2505\n",
      "Loss: tensor(0.1291, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2506\n",
      "Loss: tensor(0.1291, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2507\n",
      "Loss: tensor(0.1291, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2508\n",
      "Loss: tensor(0.1291, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2509\n",
      "Loss: tensor(0.1291, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2510\n",
      "Loss: tensor(0.1291, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2511\n",
      "Loss: tensor(0.1291, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2512\n",
      "Loss: tensor(0.1291, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2513\n",
      "Loss: tensor(0.1291, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2514\n",
      "Loss: tensor(0.1291, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2515\n",
      "Loss: tensor(0.1291, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2516\n",
      "Loss: tensor(0.1291, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2517\n",
      "Loss: tensor(0.1290, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2518\n",
      "Loss: tensor(0.1290, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2519\n",
      "Loss: tensor(0.1290, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2520\n",
      "Loss: tensor(0.1290, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2521\n",
      "Loss: tensor(0.1290, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2522\n",
      "Loss: tensor(0.1290, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2523\n",
      "Loss: tensor(0.1290, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2524\n",
      "Loss: tensor(0.1290, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2525\n",
      "Loss: tensor(0.1290, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2526\n",
      "Loss: tensor(0.1290, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2527\n",
      "Loss: tensor(0.1290, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2528\n",
      "Loss: tensor(0.1290, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2529\n",
      "Loss: tensor(0.1289, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2530\n",
      "Loss: tensor(0.1289, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2531\n",
      "Loss: tensor(0.1289, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2532\n",
      "Loss: tensor(0.1289, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2533\n",
      "Loss: tensor(0.1289, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2534\n",
      "Loss: tensor(0.1289, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2535\n",
      "Loss: tensor(0.1289, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2536\n",
      "Loss: tensor(0.1289, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2537\n",
      "Loss: tensor(0.1289, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2538\n",
      "Loss: tensor(0.1289, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2539\n",
      "Loss: tensor(0.1289, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2540\n",
      "Loss: tensor(0.1289, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2541\n",
      "Loss: tensor(0.1288, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2542\n",
      "Loss: tensor(0.1288, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2543\n",
      "Loss: tensor(0.1288, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2544\n",
      "Loss: tensor(0.1288, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2545\n",
      "Loss: tensor(0.1288, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2546\n",
      "Loss: tensor(0.1288, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2547\n",
      "Loss: tensor(0.1288, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2548\n",
      "Loss: tensor(0.1288, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2549\n",
      "Loss: tensor(0.1288, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2550\n",
      "Loss: tensor(0.1288, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2551\n",
      "Loss: tensor(0.1288, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2552\n",
      "Loss: tensor(0.1288, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2553\n",
      "Loss: tensor(0.1287, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2554\n",
      "Loss: tensor(0.1287, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2555\n",
      "Loss: tensor(0.1287, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2556\n",
      "Loss: tensor(0.1287, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2557\n",
      "Loss: tensor(0.1287, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2558\n",
      "Loss: tensor(0.1287, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2559\n",
      "Loss: tensor(0.1287, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2560\n",
      "Loss: tensor(0.1287, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2561\n",
      "Loss: tensor(0.1287, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2562\n",
      "Loss: tensor(0.1287, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2563\n",
      "Loss: tensor(0.1287, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2564\n",
      "Loss: tensor(0.1286, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2565\n",
      "Loss: tensor(0.1286, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2566\n",
      "Loss: tensor(0.1286, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2567\n",
      "Loss: tensor(0.1286, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2568\n",
      "Loss: tensor(0.1286, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2569\n",
      "Loss: tensor(0.1286, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2570\n",
      "Loss: tensor(0.1286, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2571\n",
      "Loss: tensor(0.1286, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2572\n",
      "Loss: tensor(0.1286, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2573\n",
      "Loss: tensor(0.1286, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2574\n",
      "Loss: tensor(0.1286, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2575\n",
      "Loss: tensor(0.1286, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2576\n",
      "Loss: tensor(0.1286, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2577\n",
      "Loss: tensor(0.1285, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2578\n",
      "Loss: tensor(0.1285, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2579\n",
      "Loss: tensor(0.1285, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2580\n",
      "Loss: tensor(0.1285, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2581\n",
      "Loss: tensor(0.1285, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2582\n",
      "Loss: tensor(0.1285, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2583\n",
      "Loss: tensor(0.1285, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2584\n",
      "Loss: tensor(0.1285, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2585\n",
      "Loss: tensor(0.1285, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2586\n",
      "Loss: tensor(0.1285, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2587\n",
      "Loss: tensor(0.1284, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2588\n",
      "Loss: tensor(0.1284, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2589\n",
      "Loss: tensor(0.1284, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2590\n",
      "Loss: tensor(0.1284, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2591\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor(0.1284, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2592\n",
      "Loss: tensor(0.1284, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2593\n",
      "Loss: tensor(0.1284, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2594\n",
      "Loss: tensor(0.1284, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2595\n",
      "Loss: tensor(0.1284, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2596\n",
      "Loss: tensor(0.1284, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2597\n",
      "Loss: tensor(0.1284, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2598\n",
      "Loss: tensor(0.1283, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2599\n",
      "Loss: tensor(0.1283, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2600\n",
      "Loss: tensor(0.1283, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2601\n",
      "Loss: tensor(0.1283, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2602\n",
      "Loss: tensor(0.1283, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2603\n",
      "Loss: tensor(0.1283, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2604\n",
      "Loss: tensor(0.1283, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2605\n",
      "Loss: tensor(0.1283, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2606\n",
      "Loss: tensor(0.1283, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2607\n",
      "Loss: tensor(0.1283, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2608\n",
      "Loss: tensor(0.1283, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2609\n",
      "Loss: tensor(0.1282, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2610\n",
      "Loss: tensor(0.1282, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2611\n",
      "Loss: tensor(0.1282, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2612\n",
      "Loss: tensor(0.1282, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2613\n",
      "Loss: tensor(0.1282, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2614\n",
      "Loss: tensor(0.1282, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2615\n",
      "Loss: tensor(0.1282, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2616\n",
      "Loss: tensor(0.1282, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2617\n",
      "Loss: tensor(0.1282, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2618\n",
      "Loss: tensor(0.1282, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2619\n",
      "Loss: tensor(0.1282, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2620\n",
      "Loss: tensor(0.1281, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2621\n",
      "Loss: tensor(0.1281, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2622\n",
      "Loss: tensor(0.1281, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2623\n",
      "Loss: tensor(0.1281, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2624\n",
      "Loss: tensor(0.1281, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2625\n",
      "Loss: tensor(0.1281, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2626\n",
      "Loss: tensor(0.1281, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2627\n",
      "Loss: tensor(0.1281, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2628\n",
      "Loss: tensor(0.1281, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2629\n",
      "Loss: tensor(0.1281, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2630\n",
      "Loss: tensor(0.1281, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2631\n",
      "Loss: tensor(0.1280, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2632\n",
      "Loss: tensor(0.1280, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2633\n",
      "Loss: tensor(0.1280, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2634\n",
      "Loss: tensor(0.1280, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2635\n",
      "Loss: tensor(0.1280, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2636\n",
      "Loss: tensor(0.1280, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2637\n",
      "Loss: tensor(0.1280, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2638\n",
      "Loss: tensor(0.1280, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2639\n",
      "Loss: tensor(0.1280, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2640\n",
      "Loss: tensor(0.1280, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2641\n",
      "Loss: tensor(0.1279, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2642\n",
      "Loss: tensor(0.1279, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2643\n",
      "Loss: tensor(0.1279, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2644\n",
      "Loss: tensor(0.1279, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2645\n",
      "Loss: tensor(0.1279, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2646\n",
      "Loss: tensor(0.1279, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2647\n",
      "Loss: tensor(0.1279, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2648\n",
      "Loss: tensor(0.1279, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2649\n",
      "Loss: tensor(0.1279, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2650\n",
      "Loss: tensor(0.1279, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2651\n",
      "Loss: tensor(0.1278, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2652\n",
      "Loss: tensor(0.1278, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2653\n",
      "Loss: tensor(0.1278, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2654\n",
      "Loss: tensor(0.1278, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2655\n",
      "Loss: tensor(0.1278, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2656\n",
      "Loss: tensor(0.1278, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2657\n",
      "Loss: tensor(0.1278, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2658\n",
      "Loss: tensor(0.1278, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2659\n",
      "Loss: tensor(0.1278, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2660\n",
      "Loss: tensor(0.1278, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2661\n",
      "Loss: tensor(0.1277, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2662\n",
      "Loss: tensor(0.1277, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2663\n",
      "Loss: tensor(0.1277, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2664\n",
      "Loss: tensor(0.1277, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2665\n",
      "Loss: tensor(0.1277, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2666\n",
      "Loss: tensor(0.1277, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2667\n",
      "Loss: tensor(0.1277, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2668\n",
      "Loss: tensor(0.1277, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2669\n",
      "Loss: tensor(0.1277, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2670\n",
      "Loss: tensor(0.1277, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2671\n",
      "Loss: tensor(0.1276, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2672\n",
      "Loss: tensor(0.1276, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2673\n",
      "Loss: tensor(0.1276, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2674\n",
      "Loss: tensor(0.1276, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2675\n",
      "Loss: tensor(0.1276, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2676\n",
      "Loss: tensor(0.1276, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2677\n",
      "Loss: tensor(0.1276, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2678\n",
      "Loss: tensor(0.1276, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2679\n",
      "Loss: tensor(0.1276, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2680\n",
      "Loss: tensor(0.1276, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2681\n",
      "Loss: tensor(0.1275, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2682\n",
      "Loss: tensor(0.1275, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2683\n",
      "Loss: tensor(0.1275, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2684\n",
      "Loss: tensor(0.1275, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2685\n",
      "Loss: tensor(0.1275, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2686\n",
      "Loss: tensor(0.1275, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2687\n",
      "Loss: tensor(0.1275, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2688\n",
      "Loss: tensor(0.1275, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2689\n",
      "Loss: tensor(0.1275, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2690\n",
      "Loss: tensor(0.1274, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2691\n",
      "Loss: tensor(0.1274, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2692\n",
      "Loss: tensor(0.1274, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2693\n",
      "Loss: tensor(0.1274, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2694\n",
      "Loss: tensor(0.1274, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2695\n",
      "Loss: tensor(0.1274, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2696\n",
      "Loss: tensor(0.1274, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2697\n",
      "Loss: tensor(0.1274, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2698\n",
      "Loss: tensor(0.1274, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2699\n",
      "Loss: tensor(0.1274, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2700\n",
      "Loss: tensor(0.1273, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2701\n",
      "Loss: tensor(0.1273, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2702\n",
      "Loss: tensor(0.1273, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2703\n",
      "Loss: tensor(0.1273, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2704\n",
      "Loss: tensor(0.1273, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2705\n",
      "Loss: tensor(0.1273, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2706\n",
      "Loss: tensor(0.1273, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2707\n",
      "Loss: tensor(0.1273, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2708\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor(0.1273, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2709\n",
      "Loss: tensor(0.1273, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2710\n",
      "Loss: tensor(0.1272, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2711\n",
      "Loss: tensor(0.1272, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2712\n",
      "Loss: tensor(0.1272, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2713\n",
      "Loss: tensor(0.1272, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2714\n",
      "Loss: tensor(0.1272, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2715\n",
      "Loss: tensor(0.1272, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2716\n",
      "Loss: tensor(0.1272, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2717\n",
      "Loss: tensor(0.1272, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2718\n",
      "Loss: tensor(0.1271, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2719\n",
      "Loss: tensor(0.1271, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2720\n",
      "Loss: tensor(0.1271, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2721\n",
      "Loss: tensor(0.1271, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2722\n",
      "Loss: tensor(0.1271, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2723\n",
      "Loss: tensor(0.1271, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2724\n",
      "Loss: tensor(0.1271, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2725\n",
      "Loss: tensor(0.1271, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2726\n",
      "Loss: tensor(0.1271, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2727\n",
      "Loss: tensor(0.1271, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2728\n",
      "Loss: tensor(0.1270, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2729\n",
      "Loss: tensor(0.1270, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2730\n",
      "Loss: tensor(0.1270, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2731\n",
      "Loss: tensor(0.1270, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2732\n",
      "Loss: tensor(0.1270, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2733\n",
      "Loss: tensor(0.1270, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2734\n",
      "Loss: tensor(0.1270, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2735\n",
      "Loss: tensor(0.1270, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2736\n",
      "Loss: tensor(0.1270, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2737\n",
      "Loss: tensor(0.1269, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2738\n",
      "Loss: tensor(0.1269, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2739\n",
      "Loss: tensor(0.1269, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2740\n",
      "Loss: tensor(0.1269, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2741\n",
      "Loss: tensor(0.1269, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2742\n",
      "Loss: tensor(0.1269, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2743\n",
      "Loss: tensor(0.1269, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2744\n",
      "Loss: tensor(0.1269, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2745\n",
      "Loss: tensor(0.1268, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2746\n",
      "Loss: tensor(0.1268, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2747\n",
      "Loss: tensor(0.1268, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2748\n",
      "Loss: tensor(0.1268, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2749\n",
      "Loss: tensor(0.1268, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2750\n",
      "Loss: tensor(0.1268, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2751\n",
      "Loss: tensor(0.1268, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2752\n",
      "Loss: tensor(0.1268, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2753\n",
      "Loss: tensor(0.1268, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2754\n",
      "Loss: tensor(0.1267, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2755\n",
      "Loss: tensor(0.1267, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2756\n",
      "Loss: tensor(0.1267, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2757\n",
      "Loss: tensor(0.1267, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2758\n",
      "Loss: tensor(0.1267, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2759\n",
      "Loss: tensor(0.1267, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2760\n",
      "Loss: tensor(0.1267, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2761\n",
      "Loss: tensor(0.1267, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2762\n",
      "Loss: tensor(0.1267, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2763\n",
      "Loss: tensor(0.1266, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2764\n",
      "Loss: tensor(0.1266, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2765\n",
      "Loss: tensor(0.1266, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2766\n",
      "Loss: tensor(0.1266, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2767\n",
      "Loss: tensor(0.1266, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2768\n",
      "Loss: tensor(0.1266, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2769\n",
      "Loss: tensor(0.1266, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2770\n",
      "Loss: tensor(0.1266, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2771\n",
      "Loss: tensor(0.1265, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2772\n",
      "Loss: tensor(0.1265, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2773\n",
      "Loss: tensor(0.1265, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2774\n",
      "Loss: tensor(0.1265, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2775\n",
      "Loss: tensor(0.1265, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2776\n",
      "Loss: tensor(0.1265, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2777\n",
      "Loss: tensor(0.1265, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2778\n",
      "Loss: tensor(0.1265, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2779\n",
      "Loss: tensor(0.1265, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2780\n",
      "Loss: tensor(0.1264, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2781\n",
      "Loss: tensor(0.1264, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2782\n",
      "Loss: tensor(0.1264, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2783\n",
      "Loss: tensor(0.1264, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2784\n",
      "Loss: tensor(0.1264, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2785\n",
      "Loss: tensor(0.1264, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2786\n",
      "Loss: tensor(0.1264, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2787\n",
      "Loss: tensor(0.1264, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2788\n",
      "Loss: tensor(0.1263, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2789\n",
      "Loss: tensor(0.1263, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2790\n",
      "Loss: tensor(0.1263, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2791\n",
      "Loss: tensor(0.1263, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2792\n",
      "Loss: tensor(0.1263, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2793\n",
      "Loss: tensor(0.1263, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2794\n",
      "Loss: tensor(0.1263, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2795\n",
      "Loss: tensor(0.1263, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2796\n",
      "Loss: tensor(0.1262, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2797\n",
      "Loss: tensor(0.1262, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2798\n",
      "Loss: tensor(0.1262, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2799\n",
      "Loss: tensor(0.1262, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2800\n",
      "Loss: tensor(0.1262, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2801\n",
      "Loss: tensor(0.1262, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2802\n",
      "Loss: tensor(0.1262, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2803\n",
      "Loss: tensor(0.1262, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2804\n",
      "Loss: tensor(0.1261, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2805\n",
      "Loss: tensor(0.1261, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2806\n",
      "Loss: tensor(0.1261, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2807\n",
      "Loss: tensor(0.1261, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2808\n",
      "Loss: tensor(0.1261, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2809\n",
      "Loss: tensor(0.1261, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2810\n",
      "Loss: tensor(0.1261, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2811\n",
      "Loss: tensor(0.1261, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2812\n",
      "Loss: tensor(0.1260, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2813\n",
      "Loss: tensor(0.1260, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2814\n",
      "Loss: tensor(0.1260, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2815\n",
      "Loss: tensor(0.1260, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2816\n",
      "Loss: tensor(0.1260, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2817\n",
      "Loss: tensor(0.1260, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2818\n",
      "Loss: tensor(0.1260, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2819\n",
      "Loss: tensor(0.1260, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2820\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2821\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2822\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2823\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2824\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2825\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2826\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2827\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2828\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2829\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2830\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2831\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2832\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2833\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2834\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2835\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2836\n",
      "Loss: tensor(0.1257, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2837\n",
      "Loss: tensor(0.1257, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2838\n",
      "Loss: tensor(0.1257, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2839\n",
      "Loss: tensor(0.1257, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2840\n",
      "Loss: tensor(0.1257, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2841\n",
      "Loss: tensor(0.1257, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2842\n",
      "Loss: tensor(0.1257, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2843\n",
      "Loss: tensor(0.1257, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2844\n",
      "Loss: tensor(0.1256, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2845\n",
      "Loss: tensor(0.1256, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2846\n",
      "Loss: tensor(0.1256, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2847\n",
      "Loss: tensor(0.1256, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2848\n",
      "Loss: tensor(0.1256, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2849\n",
      "Loss: tensor(0.1256, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2850\n",
      "Loss: tensor(0.1256, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2851\n",
      "Loss: tensor(0.1255, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2852\n",
      "Loss: tensor(0.1255, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2853\n",
      "Loss: tensor(0.1255, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2854\n",
      "Loss: tensor(0.1255, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2855\n",
      "Loss: tensor(0.1255, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2856\n",
      "Loss: tensor(0.1255, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2857\n",
      "Loss: tensor(0.1255, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2858\n",
      "Loss: tensor(0.1255, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2859\n",
      "Loss: tensor(0.1254, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2860\n",
      "Loss: tensor(0.1254, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2861\n",
      "Loss: tensor(0.1254, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2862\n",
      "Loss: tensor(0.1254, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2863\n",
      "Loss: tensor(0.1254, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2864\n",
      "Loss: tensor(0.1254, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2865\n",
      "Loss: tensor(0.1254, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2866\n",
      "Loss: tensor(0.1254, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2867\n",
      "Loss: tensor(0.1253, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2868\n",
      "Loss: tensor(0.1253, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2869\n",
      "Loss: tensor(0.1253, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2870\n",
      "Loss: tensor(0.1253, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2871\n",
      "Loss: tensor(0.1253, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2872\n",
      "Loss: tensor(0.1253, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2873\n",
      "Loss: tensor(0.1253, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2874\n",
      "Loss: tensor(0.1252, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2875\n",
      "Loss: tensor(0.1252, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2876\n",
      "Loss: tensor(0.1252, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2877\n",
      "Loss: tensor(0.1252, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2878\n",
      "Loss: tensor(0.1252, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2879\n",
      "Loss: tensor(0.1252, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2880\n",
      "Loss: tensor(0.1252, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2881\n",
      "Loss: tensor(0.1252, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2882\n",
      "Loss: tensor(0.1251, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2883\n",
      "Loss: tensor(0.1251, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2884\n",
      "Loss: tensor(0.1251, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2885\n",
      "Loss: tensor(0.1251, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2886\n",
      "Loss: tensor(0.1251, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2887\n",
      "Loss: tensor(0.1251, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2888\n",
      "Loss: tensor(0.1251, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2889\n",
      "Loss: tensor(0.1250, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2890\n",
      "Loss: tensor(0.1250, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2891\n",
      "Loss: tensor(0.1250, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2892\n",
      "Loss: tensor(0.1250, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2893\n",
      "Loss: tensor(0.1250, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2894\n",
      "Loss: tensor(0.1250, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2895\n",
      "Loss: tensor(0.1250, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2896\n",
      "Loss: tensor(0.1249, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2897\n",
      "Loss: tensor(0.1249, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2898\n",
      "Loss: tensor(0.1249, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2899\n",
      "Loss: tensor(0.1249, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2900\n",
      "Loss: tensor(0.1249, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2901\n",
      "Loss: tensor(0.1249, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2902\n",
      "Loss: tensor(0.1249, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2903\n",
      "Loss: tensor(0.1249, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2904\n",
      "Loss: tensor(0.1248, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2905\n",
      "Loss: tensor(0.1248, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2906\n",
      "Loss: tensor(0.1248, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2907\n",
      "Loss: tensor(0.1248, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2908\n",
      "Loss: tensor(0.1248, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2909\n",
      "Loss: tensor(0.1248, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2910\n",
      "Loss: tensor(0.1248, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2911\n",
      "Loss: tensor(0.1247, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2912\n",
      "Loss: tensor(0.1247, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2913\n",
      "Loss: tensor(0.1247, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2914\n",
      "Loss: tensor(0.1247, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2915\n",
      "Loss: tensor(0.1247, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2916\n",
      "Loss: tensor(0.1247, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2917\n",
      "Loss: tensor(0.1247, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2918\n",
      "Loss: tensor(0.1246, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2919\n",
      "Loss: tensor(0.1246, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2920\n",
      "Loss: tensor(0.1246, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2921\n",
      "Loss: tensor(0.1246, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2922\n",
      "Loss: tensor(0.1246, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2923\n",
      "Loss: tensor(0.1246, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2924\n",
      "Loss: tensor(0.1246, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2925\n",
      "Loss: tensor(0.1245, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2926\n",
      "Loss: tensor(0.1245, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2927\n",
      "Loss: tensor(0.1245, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2928\n",
      "Loss: tensor(0.1245, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2929\n",
      "Loss: tensor(0.1245, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2930\n",
      "Loss: tensor(0.1245, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2931\n",
      "Loss: tensor(0.1245, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2932\n",
      "Loss: tensor(0.1244, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2933\n",
      "Loss: tensor(0.1244, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2934\n",
      "Loss: tensor(0.1244, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2935\n",
      "Loss: tensor(0.1244, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2936\n",
      "Loss: tensor(0.1244, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2937\n",
      "Loss: tensor(0.1244, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2938\n",
      "Loss: tensor(0.1244, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2939\n",
      "Loss: tensor(0.1244, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2940\n",
      "Loss: tensor(0.1244, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2941\n",
      "Loss: tensor(0.1243, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2942\n",
      "Loss: tensor(0.1243, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2943\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor(0.1243, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2944\n",
      "Loss: tensor(0.1243, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2945\n",
      "Loss: tensor(0.1243, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2946\n",
      "Loss: tensor(0.1243, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2947\n",
      "Loss: tensor(0.1242, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2948\n",
      "Loss: tensor(0.1242, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2949\n",
      "Loss: tensor(0.1242, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2950\n",
      "Loss: tensor(0.1242, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2951\n",
      "Loss: tensor(0.1242, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2952\n",
      "Loss: tensor(0.1242, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2953\n",
      "Loss: tensor(0.1242, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2954\n",
      "Loss: tensor(0.1241, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2955\n",
      "Loss: tensor(0.1241, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2956\n",
      "Loss: tensor(0.1241, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2957\n",
      "Loss: tensor(0.1241, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2958\n",
      "Loss: tensor(0.1241, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2959\n",
      "Loss: tensor(0.1241, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2960\n",
      "Loss: tensor(0.1241, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2961\n",
      "Loss: tensor(0.1240, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2962\n",
      "Loss: tensor(0.1240, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2963\n",
      "Loss: tensor(0.1240, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2964\n",
      "Loss: tensor(0.1240, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2965\n",
      "Loss: tensor(0.1240, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2966\n",
      "Loss: tensor(0.1240, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2967\n",
      "Loss: tensor(0.1240, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2968\n",
      "Loss: tensor(0.1239, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2969\n",
      "Loss: tensor(0.1239, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2970\n",
      "Loss: tensor(0.1239, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2971\n",
      "Loss: tensor(0.1239, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2972\n",
      "Loss: tensor(0.1239, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2973\n",
      "Loss: tensor(0.1239, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2974\n",
      "Loss: tensor(0.1239, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2975\n",
      "Loss: tensor(0.1238, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2976\n",
      "Loss: tensor(0.1238, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2977\n",
      "Loss: tensor(0.1238, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2978\n",
      "Loss: tensor(0.1238, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2979\n",
      "Loss: tensor(0.1238, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2980\n",
      "Loss: tensor(0.1238, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2981\n",
      "Loss: tensor(0.1237, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2982\n",
      "Loss: tensor(0.1237, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2983\n",
      "Loss: tensor(0.1237, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2984\n",
      "Loss: tensor(0.1237, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2985\n",
      "Loss: tensor(0.1237, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2986\n",
      "Loss: tensor(0.1237, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2987\n",
      "Loss: tensor(0.1237, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2988\n",
      "Loss: tensor(0.1236, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2989\n",
      "Loss: tensor(0.1236, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2990\n",
      "Loss: tensor(0.1236, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2991\n",
      "Loss: tensor(0.1236, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2992\n",
      "Loss: tensor(0.1236, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2993\n",
      "Loss: tensor(0.1236, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2994\n",
      "Loss: tensor(0.1236, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2995\n",
      "Loss: tensor(0.1235, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2996\n",
      "Loss: tensor(0.1235, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2997\n",
      "Loss: tensor(0.1235, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2998\n",
      "Loss: tensor(0.1235, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2999\n",
      "Loss: tensor(0.1235, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3000\n",
      "Loss: tensor(0.1235, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3001\n",
      "Loss: tensor(0.1235, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3002\n",
      "Loss: tensor(0.1234, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3003\n",
      "Loss: tensor(0.1234, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3004\n",
      "Loss: tensor(0.1234, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3005\n",
      "Loss: tensor(0.1234, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3006\n",
      "Loss: tensor(0.1234, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3007\n",
      "Loss: tensor(0.1234, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3008\n",
      "Loss: tensor(0.1234, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3009\n",
      "Loss: tensor(0.1233, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3010\n",
      "Loss: tensor(0.1233, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3011\n",
      "Loss: tensor(0.1233, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3012\n",
      "Loss: tensor(0.1233, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3013\n",
      "Loss: tensor(0.1233, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3014\n",
      "Loss: tensor(0.1233, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3015\n",
      "Loss: tensor(0.1233, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3016\n",
      "Loss: tensor(0.1232, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3017\n",
      "Loss: tensor(0.1232, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3018\n",
      "Loss: tensor(0.1232, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3019\n",
      "Loss: tensor(0.1232, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3020\n",
      "Loss: tensor(0.1232, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3021\n",
      "Loss: tensor(0.1232, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3022\n",
      "Loss: tensor(0.1232, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3023\n",
      "Loss: tensor(0.1231, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3024\n",
      "Loss: tensor(0.1231, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3025\n",
      "Loss: tensor(0.1231, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3026\n",
      "Loss: tensor(0.1231, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3027\n",
      "Loss: tensor(0.1231, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3028\n",
      "Loss: tensor(0.1231, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3029\n",
      "Loss: tensor(0.1231, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3030\n",
      "Loss: tensor(0.1230, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3031\n",
      "Loss: tensor(0.1230, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3032\n",
      "Loss: tensor(0.1230, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3033\n",
      "Loss: tensor(0.1230, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3034\n",
      "Loss: tensor(0.1230, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3035\n",
      "Loss: tensor(0.1230, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3036\n",
      "Loss: tensor(0.1229, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3037\n",
      "Loss: tensor(0.1229, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3038\n",
      "Loss: tensor(0.1229, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3039\n",
      "Loss: tensor(0.1229, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3040\n",
      "Loss: tensor(0.1229, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3041\n",
      "Loss: tensor(0.1229, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3042\n",
      "Loss: tensor(0.1229, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3043\n",
      "Loss: tensor(0.1228, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3044\n",
      "Loss: tensor(0.1228, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3045\n",
      "Loss: tensor(0.1228, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3046\n",
      "Loss: tensor(0.1228, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3047\n",
      "Loss: tensor(0.1228, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3048\n",
      "Loss: tensor(0.1228, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3049\n",
      "Loss: tensor(0.1228, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3050\n",
      "Loss: tensor(0.1227, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3051\n",
      "Loss: tensor(0.1227, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3052\n",
      "Loss: tensor(0.1227, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3053\n",
      "Loss: tensor(0.1227, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3054\n",
      "Loss: tensor(0.1227, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3055\n",
      "Loss: tensor(0.1227, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3056\n",
      "Loss: tensor(0.1227, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3057\n",
      "Loss: tensor(0.1226, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3058\n",
      "Loss: tensor(0.1226, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3059\n",
      "Loss: tensor(0.1226, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3060\n",
      "Loss: tensor(0.1226, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3061\n",
      "Loss: tensor(0.1226, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3062\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor(0.1226, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3063\n",
      "Loss: tensor(0.1226, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3064\n",
      "Loss: tensor(0.1225, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3065\n",
      "Loss: tensor(0.1225, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3066\n",
      "Loss: tensor(0.1225, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3067\n",
      "Loss: tensor(0.1225, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3068\n",
      "Loss: tensor(0.1225, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3069\n",
      "Loss: tensor(0.1225, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3070\n",
      "Loss: tensor(0.1225, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3071\n",
      "Loss: tensor(0.1224, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3072\n",
      "Loss: tensor(0.1224, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3073\n",
      "Loss: tensor(0.1224, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3074\n",
      "Loss: tensor(0.1224, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3075\n",
      "Loss: tensor(0.1224, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3076\n",
      "Loss: tensor(0.1224, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3077\n",
      "Loss: tensor(0.1224, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3078\n",
      "Loss: tensor(0.1223, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3079\n",
      "Loss: tensor(0.1223, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3080\n",
      "Loss: tensor(0.1223, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3081\n",
      "Loss: tensor(0.1223, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3082\n",
      "Loss: tensor(0.1223, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3083\n",
      "Loss: tensor(0.1223, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3084\n",
      "Loss: tensor(0.1222, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3085\n",
      "Loss: tensor(0.1222, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3086\n",
      "Loss: tensor(0.1222, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3087\n",
      "Loss: tensor(0.1222, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3088\n",
      "Loss: tensor(0.1222, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3089\n",
      "Loss: tensor(0.1222, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3090\n",
      "Loss: tensor(0.1222, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3091\n",
      "Loss: tensor(0.1221, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3092\n",
      "Loss: tensor(0.1221, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3093\n",
      "Loss: tensor(0.1221, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3094\n",
      "Loss: tensor(0.1221, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3095\n",
      "Loss: tensor(0.1221, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3096\n",
      "Loss: tensor(0.1221, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3097\n",
      "Loss: tensor(0.1221, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3098\n",
      "Loss: tensor(0.1220, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3099\n",
      "Loss: tensor(0.1220, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3100\n",
      "Loss: tensor(0.1220, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3101\n",
      "Loss: tensor(0.1220, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3102\n",
      "Loss: tensor(0.1220, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3103\n",
      "Loss: tensor(0.1220, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3104\n",
      "Loss: tensor(0.1220, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3105\n",
      "Loss: tensor(0.1219, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3106\n",
      "Loss: tensor(0.1219, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3107\n",
      "Loss: tensor(0.1219, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3108\n",
      "Loss: tensor(0.1219, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3109\n",
      "Loss: tensor(0.1219, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3110\n",
      "Loss: tensor(0.1219, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3111\n",
      "Loss: tensor(0.1219, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3112\n",
      "Loss: tensor(0.1218, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3113\n",
      "Loss: tensor(0.1218, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3114\n",
      "Loss: tensor(0.1218, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3115\n",
      "Loss: tensor(0.1218, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3116\n",
      "Loss: tensor(0.1218, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3117\n",
      "Loss: tensor(0.1218, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3118\n",
      "Loss: tensor(0.1218, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3119\n",
      "Loss: tensor(0.1217, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3120\n",
      "Loss: tensor(0.1217, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3121\n",
      "Loss: tensor(0.1217, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3122\n",
      "Loss: tensor(0.1217, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3123\n",
      "Loss: tensor(0.1217, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3124\n",
      "Loss: tensor(0.1217, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3125\n",
      "Loss: tensor(0.1217, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3126\n",
      "Loss: tensor(0.1216, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3127\n",
      "Loss: tensor(0.1216, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3128\n",
      "Loss: tensor(0.1216, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3129\n",
      "Loss: tensor(0.1216, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3130\n",
      "Loss: tensor(0.1216, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3131\n",
      "Loss: tensor(0.1216, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3132\n",
      "Loss: tensor(0.1215, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3133\n",
      "Loss: tensor(0.1215, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3134\n",
      "Loss: tensor(0.1215, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3135\n",
      "Loss: tensor(0.1215, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3136\n",
      "Loss: tensor(0.1215, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3137\n",
      "Loss: tensor(0.1215, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3138\n",
      "Loss: tensor(0.1215, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3139\n",
      "Loss: tensor(0.1214, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3140\n",
      "Loss: tensor(0.1214, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3141\n",
      "Loss: tensor(0.1214, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3142\n",
      "Loss: tensor(0.1214, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3143\n",
      "Loss: tensor(0.1214, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3144\n",
      "Loss: tensor(0.1214, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3145\n",
      "Loss: tensor(0.1214, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3146\n",
      "Loss: tensor(0.1213, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3147\n",
      "Loss: tensor(0.1213, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3148\n",
      "Loss: tensor(0.1213, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3149\n",
      "Loss: tensor(0.1213, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3150\n",
      "Loss: tensor(0.1213, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3151\n",
      "Loss: tensor(0.1213, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3152\n",
      "Loss: tensor(0.1213, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3153\n",
      "Loss: tensor(0.1212, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3154\n",
      "Loss: tensor(0.1212, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3155\n",
      "Loss: tensor(0.1212, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3156\n",
      "Loss: tensor(0.1212, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3157\n",
      "Loss: tensor(0.1212, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3158\n",
      "Loss: tensor(0.1212, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3159\n",
      "Loss: tensor(0.1212, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3160\n",
      "Loss: tensor(0.1211, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3161\n",
      "Loss: tensor(0.1211, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3162\n",
      "Loss: tensor(0.1211, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3163\n",
      "Loss: tensor(0.1211, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3164\n",
      "Loss: tensor(0.1211, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3165\n",
      "Loss: tensor(0.1211, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3166\n",
      "Loss: tensor(0.1211, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3167\n",
      "Loss: tensor(0.1210, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3168\n",
      "Loss: tensor(0.1210, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3169\n",
      "Loss: tensor(0.1210, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3170\n",
      "Loss: tensor(0.1210, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3171\n",
      "Loss: tensor(0.1210, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3172\n",
      "Loss: tensor(0.1210, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3173\n",
      "Loss: tensor(0.1210, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3174\n",
      "Loss: tensor(0.1209, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3175\n",
      "Loss: tensor(0.1209, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3176\n",
      "Loss: tensor(0.1209, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3177\n",
      "Loss: tensor(0.1209, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3178\n",
      "Loss: tensor(0.1209, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3179\n",
      "Loss: tensor(0.1209, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3180\n",
      "Loss: tensor(0.1209, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3181\n",
      "Loss: tensor(0.1208, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3182\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor(0.1208, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3183\n",
      "Loss: tensor(0.1208, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3184\n",
      "Loss: tensor(0.1208, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3185\n",
      "Loss: tensor(0.1208, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3186\n",
      "Loss: tensor(0.1208, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3187\n",
      "Loss: tensor(0.1208, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3188\n",
      "Loss: tensor(0.1208, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3189\n",
      "Loss: tensor(0.1207, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3190\n",
      "Loss: tensor(0.1207, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3191\n",
      "Loss: tensor(0.1207, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3192\n",
      "Loss: tensor(0.1207, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3193\n",
      "Loss: tensor(0.1207, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3194\n",
      "Loss: tensor(0.1207, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3195\n",
      "Loss: tensor(0.1206, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3196\n",
      "Loss: tensor(0.1206, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3197\n",
      "Loss: tensor(0.1206, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3198\n",
      "Loss: tensor(0.1206, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3199\n",
      "Loss: tensor(0.1206, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3200\n",
      "Loss: tensor(0.1206, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3201\n",
      "Loss: tensor(0.1206, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3202\n",
      "Loss: tensor(0.1205, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3203\n",
      "Loss: tensor(0.1205, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3204\n",
      "Loss: tensor(0.1205, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3205\n",
      "Loss: tensor(0.1205, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3206\n",
      "Loss: tensor(0.1205, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3207\n",
      "Loss: tensor(0.1205, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3208\n",
      "Loss: tensor(0.1205, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3209\n",
      "Loss: tensor(0.1204, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3210\n",
      "Loss: tensor(0.1204, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3211\n",
      "Loss: tensor(0.1204, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3212\n",
      "Loss: tensor(0.1204, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3213\n",
      "Loss: tensor(0.1204, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3214\n",
      "Loss: tensor(0.1204, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3215\n",
      "Loss: tensor(0.1204, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3216\n",
      "Loss: tensor(0.1203, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3217\n",
      "Loss: tensor(0.1203, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3218\n",
      "Loss: tensor(0.1203, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3219\n",
      "Loss: tensor(0.1203, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3220\n",
      "Loss: tensor(0.1203, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3221\n",
      "Loss: tensor(0.1203, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3222\n",
      "Loss: tensor(0.1203, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3223\n",
      "Loss: tensor(0.1202, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3224\n",
      "Loss: tensor(0.1202, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3225\n",
      "Loss: tensor(0.1202, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3226\n",
      "Loss: tensor(0.1202, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3227\n",
      "Loss: tensor(0.1202, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3228\n",
      "Loss: tensor(0.1202, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3229\n",
      "Loss: tensor(0.1202, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3230\n",
      "Loss: tensor(0.1201, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3231\n",
      "Loss: tensor(0.1201, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3232\n",
      "Loss: tensor(0.1201, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3233\n",
      "Loss: tensor(0.1201, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3234\n",
      "Loss: tensor(0.1201, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3235\n",
      "Loss: tensor(0.1201, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3236\n",
      "Loss: tensor(0.1201, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3237\n",
      "Loss: tensor(0.1200, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3238\n",
      "Loss: tensor(0.1200, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3239\n",
      "Loss: tensor(0.1200, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3240\n",
      "Loss: tensor(0.1200, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3241\n",
      "Loss: tensor(0.1200, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3242\n",
      "Loss: tensor(0.1200, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3243\n",
      "Loss: tensor(0.1200, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3244\n",
      "Loss: tensor(0.1199, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3245\n",
      "Loss: tensor(0.1199, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3246\n",
      "Loss: tensor(0.1199, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3247\n",
      "Loss: tensor(0.1199, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3248\n",
      "Loss: tensor(0.1199, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3249\n",
      "Loss: tensor(0.1199, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3250\n",
      "Loss: tensor(0.1199, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3251\n",
      "Loss: tensor(0.1198, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3252\n",
      "Loss: tensor(0.1198, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3253\n",
      "Loss: tensor(0.1198, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3254\n",
      "Loss: tensor(0.1198, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3255\n",
      "Loss: tensor(0.1198, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3256\n",
      "Loss: tensor(0.1198, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3257\n",
      "Loss: tensor(0.1198, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3258\n",
      "Loss: tensor(0.1197, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3259\n",
      "Loss: tensor(0.1197, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3260\n",
      "Loss: tensor(0.1197, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3261\n",
      "Loss: tensor(0.1197, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3262\n",
      "Loss: tensor(0.1197, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3263\n",
      "Loss: tensor(0.1197, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3264\n",
      "Loss: tensor(0.1197, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3265\n",
      "Loss: tensor(0.1196, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3266\n",
      "Loss: tensor(0.1196, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3267\n",
      "Loss: tensor(0.1196, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3268\n",
      "Loss: tensor(0.1196, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3269\n",
      "Loss: tensor(0.1196, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3270\n",
      "Loss: tensor(0.1196, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3271\n",
      "Loss: tensor(0.1196, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3272\n",
      "Loss: tensor(0.1195, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3273\n",
      "Loss: tensor(0.1195, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3274\n",
      "Loss: tensor(0.1195, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3275\n",
      "Loss: tensor(0.1195, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3276\n",
      "Loss: tensor(0.1195, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3277\n",
      "Loss: tensor(0.1195, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3278\n",
      "Loss: tensor(0.1195, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3279\n",
      "Loss: tensor(0.1194, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3280\n",
      "Loss: tensor(0.1194, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3281\n",
      "Loss: tensor(0.1194, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3282\n",
      "Loss: tensor(0.1194, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3283\n",
      "Loss: tensor(0.1194, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3284\n",
      "Loss: tensor(0.1194, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3285\n",
      "Loss: tensor(0.1194, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3286\n",
      "Loss: tensor(0.1193, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3287\n",
      "Loss: tensor(0.1193, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3288\n",
      "Loss: tensor(0.1193, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3289\n",
      "Loss: tensor(0.1193, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3290\n",
      "Loss: tensor(0.1193, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3291\n",
      "Loss: tensor(0.1193, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3292\n",
      "Loss: tensor(0.1193, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3293\n",
      "Loss: tensor(0.1193, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3294\n",
      "Loss: tensor(0.1192, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3295\n",
      "Loss: tensor(0.1192, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3296\n",
      "Loss: tensor(0.1192, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3297\n",
      "Loss: tensor(0.1192, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3298\n",
      "Loss: tensor(0.1192, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3299\n",
      "Loss: tensor(0.1192, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3300\n",
      "Loss: tensor(0.1191, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3301\n",
      "Loss: tensor(0.1191, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3302\n",
      "Loss: tensor(0.1191, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3303\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor(0.1191, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3304\n",
      "Loss: tensor(0.1191, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3305\n",
      "Loss: tensor(0.1191, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3306\n",
      "Loss: tensor(0.1191, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3307\n",
      "Loss: tensor(0.1190, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3308\n",
      "Loss: tensor(0.1190, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3309\n",
      "Loss: tensor(0.1190, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3310\n",
      "Loss: tensor(0.1190, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3311\n",
      "Loss: tensor(0.1190, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3312\n",
      "Loss: tensor(0.1190, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3313\n",
      "Loss: tensor(0.1190, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3314\n",
      "Loss: tensor(0.1189, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3315\n",
      "Loss: tensor(0.1189, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3316\n",
      "Loss: tensor(0.1189, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3317\n",
      "Loss: tensor(0.1189, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3318\n",
      "Loss: tensor(0.1189, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3319\n",
      "Loss: tensor(0.1189, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3320\n",
      "Loss: tensor(0.1189, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3321\n",
      "Loss: tensor(0.1188, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3322\n",
      "Loss: tensor(0.1188, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3323\n",
      "Loss: tensor(0.1188, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3324\n",
      "Loss: tensor(0.1188, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3325\n",
      "Loss: tensor(0.1188, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3326\n",
      "Loss: tensor(0.1188, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3327\n",
      "Loss: tensor(0.1188, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3328\n",
      "Loss: tensor(0.1187, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3329\n",
      "Loss: tensor(0.1187, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3330\n",
      "Loss: tensor(0.1187, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3331\n",
      "Loss: tensor(0.1187, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3332\n",
      "Loss: tensor(0.1187, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3333\n",
      "Loss: tensor(0.1187, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3334\n",
      "Loss: tensor(0.1187, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3335\n",
      "Loss: tensor(0.1186, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3336\n",
      "Loss: tensor(0.1186, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3337\n",
      "Loss: tensor(0.1186, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3338\n",
      "Loss: tensor(0.1186, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3339\n",
      "Loss: tensor(0.1186, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3340\n",
      "Loss: tensor(0.1186, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3341\n",
      "Loss: tensor(0.1186, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3342\n",
      "Loss: tensor(0.1185, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3343\n",
      "Loss: tensor(0.1185, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3344\n",
      "Loss: tensor(0.1185, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3345\n",
      "Loss: tensor(0.1185, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3346\n",
      "Loss: tensor(0.1185, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3347\n",
      "Loss: tensor(0.1185, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3348\n",
      "Loss: tensor(0.1185, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3349\n",
      "Loss: tensor(0.1184, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3350\n",
      "Loss: tensor(0.1184, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3351\n",
      "Loss: tensor(0.1184, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3352\n",
      "Loss: tensor(0.1184, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3353\n",
      "Loss: tensor(0.1184, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3354\n",
      "Loss: tensor(0.1184, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3355\n",
      "Loss: tensor(0.1184, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3356\n",
      "Loss: tensor(0.1184, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3357\n",
      "Loss: tensor(0.1183, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3358\n",
      "Loss: tensor(0.1183, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3359\n",
      "Loss: tensor(0.1183, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3360\n",
      "Loss: tensor(0.1183, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3361\n",
      "Loss: tensor(0.1183, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3362\n",
      "Loss: tensor(0.1183, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3363\n",
      "Loss: tensor(0.1183, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3364\n",
      "Loss: tensor(0.1182, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3365\n",
      "Loss: tensor(0.1182, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3366\n",
      "Loss: tensor(0.1182, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3367\n",
      "Loss: tensor(0.1182, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3368\n",
      "Loss: tensor(0.1182, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3369\n",
      "Loss: tensor(0.1182, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3370\n",
      "Loss: tensor(0.1182, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3371\n",
      "Loss: tensor(0.1181, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3372\n",
      "Loss: tensor(0.1181, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3373\n",
      "Loss: tensor(0.1181, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3374\n",
      "Loss: tensor(0.1181, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3375\n",
      "Loss: tensor(0.1181, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3376\n",
      "Loss: tensor(0.1181, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3377\n",
      "Loss: tensor(0.1181, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3378\n",
      "Loss: tensor(0.1181, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3379\n",
      "Loss: tensor(0.1180, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3380\n",
      "Loss: tensor(0.1180, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3381\n",
      "Loss: tensor(0.1180, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3382\n",
      "Loss: tensor(0.1180, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3383\n",
      "Loss: tensor(0.1180, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3384\n",
      "Loss: tensor(0.1180, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3385\n",
      "Loss: tensor(0.1179, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3386\n",
      "Loss: tensor(0.1179, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3387\n",
      "Loss: tensor(0.1179, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3388\n",
      "Loss: tensor(0.1179, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3389\n",
      "Loss: tensor(0.1179, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3390\n",
      "Loss: tensor(0.1179, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3391\n",
      "Loss: tensor(0.1179, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3392\n",
      "Loss: tensor(0.1178, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3393\n",
      "Loss: tensor(0.1178, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3394\n",
      "Loss: tensor(0.1178, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3395\n",
      "Loss: tensor(0.1178, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3396\n",
      "Loss: tensor(0.1178, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3397\n",
      "Loss: tensor(0.1178, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3398\n",
      "Loss: tensor(0.1178, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3399\n",
      "Loss: tensor(0.1178, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3400\n",
      "Loss: tensor(0.1177, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3401\n",
      "Loss: tensor(0.1177, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3402\n",
      "Loss: tensor(0.1177, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3403\n",
      "Loss: tensor(0.1177, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3404\n",
      "Loss: tensor(0.1177, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3405\n",
      "Loss: tensor(0.1177, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3406\n",
      "Loss: tensor(0.1177, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3407\n",
      "Loss: tensor(0.1176, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3408\n",
      "Loss: tensor(0.1176, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3409\n",
      "Loss: tensor(0.1176, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3410\n",
      "Loss: tensor(0.1176, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3411\n",
      "Loss: tensor(0.1176, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3412\n",
      "Loss: tensor(0.1176, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3413\n",
      "Loss: tensor(0.1176, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3414\n",
      "Loss: tensor(0.1175, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3415\n",
      "Loss: tensor(0.1175, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3416\n",
      "Loss: tensor(0.1175, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3417\n",
      "Loss: tensor(0.1175, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3418\n",
      "Loss: tensor(0.1175, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3419\n",
      "Loss: tensor(0.1175, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3420\n",
      "Loss: tensor(0.1175, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3421\n",
      "Loss: tensor(0.1174, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3422\n",
      "Loss: tensor(0.1174, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3423\n",
      "Loss: tensor(0.1174, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3424\n",
      "Loss: tensor(0.1174, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3425\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor(0.1174, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3426\n",
      "Loss: tensor(0.1174, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3427\n",
      "Loss: tensor(0.1174, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3428\n",
      "Loss: tensor(0.1174, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3429\n",
      "Loss: tensor(0.1174, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3430\n",
      "Loss: tensor(0.1174, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3431\n",
      "Loss: tensor(0.1173, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3432\n",
      "Loss: tensor(0.1173, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3433\n",
      "Loss: tensor(0.1173, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3434\n",
      "Loss: tensor(0.1173, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3435\n",
      "Loss: tensor(0.1173, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3436\n",
      "Loss: tensor(0.1172, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3437\n",
      "Loss: tensor(0.1172, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3438\n",
      "Loss: tensor(0.1172, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3439\n",
      "Loss: tensor(0.1172, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3440\n",
      "Loss: tensor(0.1172, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3441\n",
      "Loss: tensor(0.1172, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3442\n",
      "Loss: tensor(0.1172, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3443\n",
      "Loss: tensor(0.1172, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3444\n",
      "Loss: tensor(0.1171, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3445\n",
      "Loss: tensor(0.1171, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3446\n",
      "Loss: tensor(0.1171, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3447\n",
      "Loss: tensor(0.1171, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3448\n",
      "Loss: tensor(0.1171, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3449\n",
      "Loss: tensor(0.1171, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3450\n",
      "Loss: tensor(0.1171, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3451\n",
      "Loss: tensor(0.1170, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3452\n",
      "Loss: tensor(0.1170, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3453\n",
      "Loss: tensor(0.1170, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3454\n",
      "Loss: tensor(0.1170, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3455\n",
      "Loss: tensor(0.1170, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3456\n",
      "Loss: tensor(0.1170, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3457\n",
      "Loss: tensor(0.1170, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3458\n",
      "Loss: tensor(0.1169, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3459\n",
      "Loss: tensor(0.1169, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3460\n",
      "Loss: tensor(0.1169, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3461\n",
      "Loss: tensor(0.1169, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3462\n",
      "Loss: tensor(0.1169, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3463\n",
      "Loss: tensor(0.1169, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3464\n",
      "Loss: tensor(0.1169, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3465\n",
      "Loss: tensor(0.1168, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3466\n",
      "Loss: tensor(0.1168, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3467\n",
      "Loss: tensor(0.1168, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3468\n",
      "Loss: tensor(0.1168, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3469\n",
      "Loss: tensor(0.1168, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3470\n",
      "Loss: tensor(0.1168, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3471\n",
      "Loss: tensor(0.1168, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3472\n",
      "Loss: tensor(0.1168, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3473\n",
      "Loss: tensor(0.1167, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3474\n",
      "Loss: tensor(0.1167, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3475\n",
      "Loss: tensor(0.1167, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3476\n",
      "Loss: tensor(0.1167, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3477\n",
      "Loss: tensor(0.1167, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3478\n",
      "Loss: tensor(0.1167, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3479\n",
      "Loss: tensor(0.1167, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3480\n",
      "Loss: tensor(0.1166, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3481\n",
      "Loss: tensor(0.1166, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3482\n",
      "Loss: tensor(0.1166, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3483\n",
      "Loss: tensor(0.1166, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3484\n",
      "Loss: tensor(0.1166, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3485\n",
      "Loss: tensor(0.1166, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3486\n",
      "Loss: tensor(0.1166, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3487\n",
      "Loss: tensor(0.1166, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3488\n",
      "Loss: tensor(0.1165, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3489\n",
      "Loss: tensor(0.1165, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3490\n",
      "Loss: tensor(0.1165, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3491\n",
      "Loss: tensor(0.1165, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3492\n",
      "Loss: tensor(0.1165, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3493\n",
      "Loss: tensor(0.1165, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3494\n",
      "Loss: tensor(0.1165, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3495\n",
      "Loss: tensor(0.1164, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3496\n",
      "Loss: tensor(0.1164, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3497\n",
      "Loss: tensor(0.1164, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3498\n",
      "Loss: tensor(0.1164, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3499\n",
      "Loss: tensor(0.1164, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3500\n",
      "Loss: tensor(0.1164, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3501\n",
      "Loss: tensor(0.1164, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3502\n",
      "Loss: tensor(0.1164, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3503\n",
      "Loss: tensor(0.1163, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3504\n",
      "Loss: tensor(0.1163, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3505\n",
      "Loss: tensor(0.1163, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3506\n",
      "Loss: tensor(0.1163, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3507\n",
      "Loss: tensor(0.1163, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3508\n",
      "Loss: tensor(0.1163, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3509\n",
      "Loss: tensor(0.1163, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3510\n",
      "Loss: tensor(0.1162, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3511\n",
      "Loss: tensor(0.1162, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3512\n",
      "Loss: tensor(0.1162, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3513\n",
      "Loss: tensor(0.1162, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3514\n",
      "Loss: tensor(0.1162, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3515\n",
      "Loss: tensor(0.1162, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3516\n",
      "Loss: tensor(0.1162, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3517\n",
      "Loss: tensor(0.1161, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3518\n",
      "Loss: tensor(0.1161, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3519\n",
      "Loss: tensor(0.1161, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3520\n",
      "Loss: tensor(0.1161, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3521\n",
      "Loss: tensor(0.1161, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3522\n",
      "Loss: tensor(0.1161, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3523\n",
      "Loss: tensor(0.1161, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3524\n",
      "Loss: tensor(0.1161, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3525\n",
      "Loss: tensor(0.1160, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3526\n",
      "Loss: tensor(0.1160, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3527\n",
      "Loss: tensor(0.1160, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3528\n",
      "Loss: tensor(0.1160, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3529\n",
      "Loss: tensor(0.1160, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3530\n",
      "Loss: tensor(0.1160, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3531\n",
      "Loss: tensor(0.1160, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3532\n",
      "Loss: tensor(0.1159, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3533\n",
      "Loss: tensor(0.1159, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3534\n",
      "Loss: tensor(0.1159, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3535\n",
      "Loss: tensor(0.1159, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3536\n",
      "Loss: tensor(0.1159, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3537\n",
      "Loss: tensor(0.1159, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3538\n",
      "Loss: tensor(0.1159, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3539\n",
      "Loss: tensor(0.1159, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3540\n",
      "Loss: tensor(0.1158, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3541\n",
      "Loss: tensor(0.1158, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3542\n",
      "Loss: tensor(0.1158, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3543\n",
      "Loss: tensor(0.1158, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3544\n",
      "Loss: tensor(0.1158, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3545\n",
      "Loss: tensor(0.1158, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3546\n",
      "Loss: tensor(0.1158, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3547\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor(0.1158, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3548\n",
      "Loss: tensor(0.1157, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3549\n",
      "Loss: tensor(0.1157, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3550\n",
      "Loss: tensor(0.1157, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3551\n",
      "Loss: tensor(0.1157, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3552\n",
      "Loss: tensor(0.1157, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3553\n",
      "Loss: tensor(0.1157, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3554\n",
      "Loss: tensor(0.1157, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3555\n",
      "Loss: tensor(0.1156, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3556\n",
      "Loss: tensor(0.1156, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3557\n",
      "Loss: tensor(0.1156, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3558\n",
      "Loss: tensor(0.1156, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3559\n",
      "Loss: tensor(0.1156, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3560\n",
      "Loss: tensor(0.1156, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3561\n",
      "Loss: tensor(0.1156, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3562\n",
      "Loss: tensor(0.1156, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3563\n",
      "Loss: tensor(0.1155, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3564\n",
      "Loss: tensor(0.1155, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3565\n",
      "Loss: tensor(0.1155, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3566\n",
      "Loss: tensor(0.1155, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3567\n",
      "Loss: tensor(0.1155, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3568\n",
      "Loss: tensor(0.1155, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3569\n",
      "Loss: tensor(0.1155, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3570\n",
      "Loss: tensor(0.1155, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3571\n",
      "Loss: tensor(0.1154, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3572\n",
      "Loss: tensor(0.1154, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3573\n",
      "Loss: tensor(0.1154, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3574\n",
      "Loss: tensor(0.1154, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3575\n",
      "Loss: tensor(0.1154, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3576\n",
      "Loss: tensor(0.1154, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3577\n",
      "Loss: tensor(0.1154, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3578\n",
      "Loss: tensor(0.1153, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3579\n",
      "Loss: tensor(0.1153, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3580\n",
      "Loss: tensor(0.1153, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3581\n",
      "Loss: tensor(0.1153, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3582\n",
      "Loss: tensor(0.1153, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3583\n",
      "Loss: tensor(0.1153, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3584\n",
      "Loss: tensor(0.1153, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3585\n",
      "Loss: tensor(0.1153, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3586\n",
      "Loss: tensor(0.1152, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3587\n",
      "Loss: tensor(0.1152, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3588\n",
      "Loss: tensor(0.1152, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3589\n",
      "Loss: tensor(0.1152, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3590\n",
      "Loss: tensor(0.1152, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3591\n",
      "Loss: tensor(0.1152, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3592\n",
      "Loss: tensor(0.1152, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3593\n",
      "Loss: tensor(0.1152, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3594\n",
      "Loss: tensor(0.1151, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3595\n",
      "Loss: tensor(0.1151, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3596\n",
      "Loss: tensor(0.1151, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3597\n",
      "Loss: tensor(0.1151, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3598\n",
      "Loss: tensor(0.1151, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3599\n",
      "Loss: tensor(0.1151, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3600\n",
      "Loss: tensor(0.1151, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3601\n",
      "Loss: tensor(0.1151, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3602\n",
      "Loss: tensor(0.1150, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3603\n",
      "Loss: tensor(0.1150, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3604\n",
      "Loss: tensor(0.1150, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3605\n",
      "Loss: tensor(0.1150, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3606\n",
      "Loss: tensor(0.1150, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3607\n",
      "Loss: tensor(0.1150, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3608\n",
      "Loss: tensor(0.1150, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3609\n",
      "Loss: tensor(0.1150, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3610\n",
      "Loss: tensor(0.1149, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3611\n",
      "Loss: tensor(0.1149, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3612\n",
      "Loss: tensor(0.1149, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3613\n",
      "Loss: tensor(0.1149, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3614\n",
      "Loss: tensor(0.1149, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3615\n",
      "Loss: tensor(0.1149, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3616\n",
      "Loss: tensor(0.1149, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3617\n",
      "Loss: tensor(0.1148, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3618\n",
      "Loss: tensor(0.1148, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3619\n",
      "Loss: tensor(0.1148, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3620\n",
      "Loss: tensor(0.1148, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3621\n",
      "Loss: tensor(0.1148, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3622\n",
      "Loss: tensor(0.1148, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3623\n",
      "Loss: tensor(0.1148, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3624\n",
      "Loss: tensor(0.1148, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3625\n",
      "Loss: tensor(0.1147, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3626\n",
      "Loss: tensor(0.1147, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3627\n",
      "Loss: tensor(0.1147, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3628\n",
      "Loss: tensor(0.1147, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3629\n",
      "Loss: tensor(0.1147, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3630\n",
      "Loss: tensor(0.1147, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3631\n",
      "Loss: tensor(0.1147, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3632\n",
      "Loss: tensor(0.1147, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3633\n",
      "Loss: tensor(0.1146, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3634\n",
      "Loss: tensor(0.1146, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3635\n",
      "Loss: tensor(0.1146, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3636\n",
      "Loss: tensor(0.1146, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3637\n",
      "Loss: tensor(0.1146, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3638\n",
      "Loss: tensor(0.1146, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3639\n",
      "Loss: tensor(0.1146, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3640\n",
      "Loss: tensor(0.1146, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3641\n",
      "Loss: tensor(0.1145, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3642\n",
      "Loss: tensor(0.1145, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3643\n",
      "Loss: tensor(0.1145, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3644\n",
      "Loss: tensor(0.1145, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3645\n",
      "Loss: tensor(0.1145, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3646\n",
      "Loss: tensor(0.1145, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3647\n",
      "Loss: tensor(0.1145, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3648\n",
      "Loss: tensor(0.1145, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3649\n",
      "Loss: tensor(0.1144, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3650\n",
      "Loss: tensor(0.1144, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3651\n",
      "Loss: tensor(0.1144, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3652\n",
      "Loss: tensor(0.1144, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3653\n",
      "Loss: tensor(0.1144, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3654\n",
      "Loss: tensor(0.1144, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3655\n",
      "Loss: tensor(0.1144, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3656\n",
      "Loss: tensor(0.1144, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3657\n",
      "Loss: tensor(0.1143, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3658\n",
      "Loss: tensor(0.1143, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3659\n",
      "Loss: tensor(0.1143, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3660\n",
      "Loss: tensor(0.1143, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3661\n",
      "Loss: tensor(0.1143, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3662\n",
      "Loss: tensor(0.1143, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3663\n",
      "Loss: tensor(0.1143, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3664\n",
      "Loss: tensor(0.1143, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3665\n",
      "Loss: tensor(0.1143, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3666\n",
      "Loss: tensor(0.1142, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3667\n",
      "Loss: tensor(0.1142, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3668\n",
      "Loss: tensor(0.1142, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3669\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor(0.1142, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3670\n",
      "Loss: tensor(0.1142, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3671\n",
      "Loss: tensor(0.1142, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3672\n",
      "Loss: tensor(0.1142, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3673\n",
      "Loss: tensor(0.1141, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3674\n",
      "Loss: tensor(0.1141, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3675\n",
      "Loss: tensor(0.1141, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3676\n",
      "Loss: tensor(0.1141, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3677\n",
      "Loss: tensor(0.1141, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3678\n",
      "Loss: tensor(0.1141, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3679\n",
      "Loss: tensor(0.1141, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3680\n",
      "Loss: tensor(0.1141, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3681\n",
      "Loss: tensor(0.1140, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3682\n",
      "Loss: tensor(0.1140, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3683\n",
      "Loss: tensor(0.1140, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3684\n",
      "Loss: tensor(0.1140, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3685\n",
      "Loss: tensor(0.1140, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3686\n",
      "Loss: tensor(0.1140, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3687\n",
      "Loss: tensor(0.1140, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3688\n",
      "Loss: tensor(0.1140, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3689\n",
      "Loss: tensor(0.1140, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3690\n",
      "Loss: tensor(0.1139, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3691\n",
      "Loss: tensor(0.1139, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3692\n",
      "Loss: tensor(0.1139, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3693\n",
      "Loss: tensor(0.1139, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3694\n",
      "Loss: tensor(0.1139, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3695\n",
      "Loss: tensor(0.1139, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3696\n",
      "Loss: tensor(0.1139, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3697\n",
      "Loss: tensor(0.1139, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3698\n",
      "Loss: tensor(0.1138, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3699\n",
      "Loss: tensor(0.1138, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3700\n",
      "Loss: tensor(0.1138, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3701\n",
      "Loss: tensor(0.1138, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3702\n",
      "Loss: tensor(0.1138, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3703\n",
      "Loss: tensor(0.1138, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3704\n",
      "Loss: tensor(0.1138, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3705\n",
      "Loss: tensor(0.1138, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3706\n",
      "Loss: tensor(0.1137, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3707\n",
      "Loss: tensor(0.1137, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3708\n",
      "Loss: tensor(0.1137, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3709\n",
      "Loss: tensor(0.1137, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3710\n",
      "Loss: tensor(0.1137, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3711\n",
      "Loss: tensor(0.1137, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3712\n",
      "Loss: tensor(0.1137, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3713\n",
      "Loss: tensor(0.1137, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3714\n",
      "Loss: tensor(0.1136, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3715\n",
      "Loss: tensor(0.1136, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3716\n",
      "Loss: tensor(0.1136, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3717\n",
      "Loss: tensor(0.1136, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3718\n",
      "Loss: tensor(0.1136, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3719\n",
      "Loss: tensor(0.1136, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3720\n",
      "Loss: tensor(0.1136, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3721\n",
      "Loss: tensor(0.1136, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3722\n",
      "Loss: tensor(0.1136, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3723\n",
      "Loss: tensor(0.1135, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3724\n",
      "Loss: tensor(0.1135, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3725\n",
      "Loss: tensor(0.1135, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3726\n",
      "Loss: tensor(0.1135, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3727\n",
      "Loss: tensor(0.1135, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3728\n",
      "Loss: tensor(0.1135, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3729\n",
      "Loss: tensor(0.1135, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3730\n",
      "Loss: tensor(0.1135, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3731\n",
      "Loss: tensor(0.1134, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3732\n",
      "Loss: tensor(0.1134, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3733\n",
      "Loss: tensor(0.1134, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3734\n",
      "Loss: tensor(0.1134, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3735\n",
      "Loss: tensor(0.1134, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3736\n",
      "Loss: tensor(0.1134, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3737\n",
      "Loss: tensor(0.1134, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3738\n",
      "Loss: tensor(0.1134, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3739\n",
      "Loss: tensor(0.1134, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3740\n",
      "Loss: tensor(0.1133, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3741\n",
      "Loss: tensor(0.1133, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3742\n",
      "Loss: tensor(0.1133, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3743\n",
      "Loss: tensor(0.1133, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3744\n",
      "Loss: tensor(0.1133, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3745\n",
      "Loss: tensor(0.1133, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3746\n",
      "Loss: tensor(0.1133, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3747\n",
      "Loss: tensor(0.1133, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3748\n",
      "Loss: tensor(0.1133, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3749\n",
      "Loss: tensor(0.1133, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3750\n",
      "Loss: tensor(0.1133, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3751\n",
      "Loss: tensor(0.1133, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3752\n",
      "Loss: tensor(0.1132, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3753\n",
      "Loss: tensor(0.1132, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3754\n",
      "Loss: tensor(0.1132, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3755\n",
      "Loss: tensor(0.1132, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3756\n",
      "Loss: tensor(0.1132, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3757\n",
      "Loss: tensor(0.1132, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3758\n",
      "Loss: tensor(0.1132, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3759\n",
      "Loss: tensor(0.1131, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3760\n",
      "Loss: tensor(0.1131, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3761\n",
      "Loss: tensor(0.1131, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3762\n",
      "Loss: tensor(0.1131, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3763\n",
      "Loss: tensor(0.1131, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3764\n",
      "Loss: tensor(0.1131, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3765\n",
      "Loss: tensor(0.1131, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3766\n",
      "Loss: tensor(0.1130, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3767\n",
      "Loss: tensor(0.1130, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3768\n",
      "Loss: tensor(0.1130, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3769\n",
      "Loss: tensor(0.1130, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3770\n",
      "Loss: tensor(0.1130, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3771\n",
      "Loss: tensor(0.1130, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3772\n",
      "Loss: tensor(0.1130, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3773\n",
      "Loss: tensor(0.1130, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3774\n",
      "Loss: tensor(0.1130, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3775\n",
      "Loss: tensor(0.1129, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3776\n",
      "Loss: tensor(0.1129, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3777\n",
      "Loss: tensor(0.1129, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3778\n",
      "Loss: tensor(0.1129, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3779\n",
      "Loss: tensor(0.1129, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3780\n",
      "Loss: tensor(0.1129, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3781\n",
      "Loss: tensor(0.1129, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3782\n",
      "Loss: tensor(0.1129, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3783\n",
      "Loss: tensor(0.1128, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3784\n",
      "Loss: tensor(0.1128, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3785\n",
      "Loss: tensor(0.1128, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3786\n",
      "Loss: tensor(0.1128, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3787\n",
      "Loss: tensor(0.1128, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3788\n",
      "Loss: tensor(0.1128, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3789\n",
      "Loss: tensor(0.1128, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3790\n",
      "Loss: tensor(0.1128, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3791\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor(0.1128, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3792\n",
      "Loss: tensor(0.1127, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3793\n",
      "Loss: tensor(0.1127, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3794\n",
      "Loss: tensor(0.1127, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3795\n",
      "Loss: tensor(0.1127, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3796\n",
      "Loss: tensor(0.1127, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3797\n",
      "Loss: tensor(0.1127, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3798\n",
      "Loss: tensor(0.1127, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3799\n",
      "Loss: tensor(0.1127, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3800\n",
      "Loss: tensor(0.1127, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3801\n",
      "Loss: tensor(0.1126, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3802\n",
      "Loss: tensor(0.1126, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3803\n",
      "Loss: tensor(0.1126, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3804\n",
      "Loss: tensor(0.1126, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3805\n",
      "Loss: tensor(0.1126, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3806\n",
      "Loss: tensor(0.1126, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3807\n",
      "Loss: tensor(0.1126, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3808\n",
      "Loss: tensor(0.1126, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3809\n",
      "Loss: tensor(0.1126, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3810\n",
      "Loss: tensor(0.1125, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3811\n",
      "Loss: tensor(0.1125, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3812\n",
      "Loss: tensor(0.1125, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3813\n",
      "Loss: tensor(0.1125, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3814\n",
      "Loss: tensor(0.1125, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3815\n",
      "Loss: tensor(0.1125, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3816\n",
      "Loss: tensor(0.1125, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3817\n",
      "Loss: tensor(0.1125, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3818\n",
      "Loss: tensor(0.1125, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3819\n",
      "Loss: tensor(0.1125, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3820\n",
      "Loss: tensor(0.1124, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3821\n",
      "Loss: tensor(0.1124, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3822\n",
      "Loss: tensor(0.1124, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3823\n",
      "Loss: tensor(0.1124, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3824\n",
      "Loss: tensor(0.1124, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3825\n",
      "Loss: tensor(0.1124, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3826\n",
      "Loss: tensor(0.1124, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3827\n",
      "Loss: tensor(0.1124, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3828\n",
      "Loss: tensor(0.1124, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3829\n",
      "Loss: tensor(0.1124, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3830\n",
      "Loss: tensor(0.1124, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3831\n",
      "Loss: tensor(0.1123, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3832\n",
      "Loss: tensor(0.1123, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3833\n",
      "Loss: tensor(0.1123, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3834\n",
      "Loss: tensor(0.1123, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3835\n",
      "Loss: tensor(0.1123, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3836\n",
      "Loss: tensor(0.1123, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3837\n",
      "Loss: tensor(0.1123, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3838\n",
      "Loss: tensor(0.1122, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3839\n",
      "Loss: tensor(0.1122, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3840\n",
      "Loss: tensor(0.1122, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3841\n",
      "Loss: tensor(0.1122, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3842\n",
      "Loss: tensor(0.1122, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3843\n",
      "Loss: tensor(0.1122, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3844\n",
      "Loss: tensor(0.1122, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3845\n",
      "Loss: tensor(0.1122, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3846\n",
      "Loss: tensor(0.1122, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3847\n",
      "Loss: tensor(0.1122, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3848\n",
      "Loss: tensor(0.1121, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3849\n",
      "Loss: tensor(0.1121, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3850\n",
      "Loss: tensor(0.1121, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3851\n",
      "Loss: tensor(0.1121, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3852\n",
      "Loss: tensor(0.1121, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3853\n",
      "Loss: tensor(0.1121, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3854\n",
      "Loss: tensor(0.1121, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3855\n",
      "Loss: tensor(0.1121, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3856\n",
      "Loss: tensor(0.1121, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3857\n",
      "Loss: tensor(0.1120, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3858\n",
      "Loss: tensor(0.1120, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3859\n",
      "Loss: tensor(0.1120, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3860\n",
      "Loss: tensor(0.1120, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3861\n",
      "Loss: tensor(0.1120, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3862\n",
      "Loss: tensor(0.1120, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3863\n",
      "Loss: tensor(0.1120, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3864\n",
      "Loss: tensor(0.1120, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3865\n",
      "Loss: tensor(0.1120, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3866\n",
      "Loss: tensor(0.1120, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3867\n",
      "Loss: tensor(0.1119, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3868\n",
      "Loss: tensor(0.1119, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3869\n",
      "Loss: tensor(0.1119, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3870\n",
      "Loss: tensor(0.1119, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3871\n",
      "Loss: tensor(0.1119, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3872\n",
      "Loss: tensor(0.1119, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3873\n",
      "Loss: tensor(0.1119, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3874\n",
      "Loss: tensor(0.1119, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3875\n",
      "Loss: tensor(0.1119, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3876\n",
      "Loss: tensor(0.1119, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3877\n",
      "Loss: tensor(0.1118, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3878\n",
      "Loss: tensor(0.1118, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3879\n",
      "Loss: tensor(0.1118, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3880\n",
      "Loss: tensor(0.1118, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3881\n",
      "Loss: tensor(0.1118, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3882\n",
      "Loss: tensor(0.1118, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3883\n",
      "Loss: tensor(0.1118, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3884\n",
      "Loss: tensor(0.1118, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3885\n",
      "Loss: tensor(0.1118, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3886\n",
      "Loss: tensor(0.1117, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3887\n",
      "Loss: tensor(0.1117, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3888\n",
      "Loss: tensor(0.1117, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3889\n",
      "Loss: tensor(0.1117, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3890\n",
      "Loss: tensor(0.1117, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3891\n",
      "Loss: tensor(0.1117, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3892\n",
      "Loss: tensor(0.1117, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3893\n",
      "Loss: tensor(0.1117, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3894\n",
      "Loss: tensor(0.1117, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3895\n",
      "Loss: tensor(0.1117, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3896\n",
      "Loss: tensor(0.1116, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3897\n",
      "Loss: tensor(0.1116, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3898\n",
      "Loss: tensor(0.1116, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3899\n",
      "Loss: tensor(0.1116, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3900\n",
      "Loss: tensor(0.1116, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3901\n",
      "Loss: tensor(0.1116, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3902\n",
      "Loss: tensor(0.1116, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3903\n",
      "Loss: tensor(0.1116, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3904\n",
      "Loss: tensor(0.1116, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3905\n",
      "Loss: tensor(0.1116, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3906\n",
      "Loss: tensor(0.1115, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3907\n",
      "Loss: tensor(0.1115, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3908\n",
      "Loss: tensor(0.1115, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3909\n",
      "Loss: tensor(0.1115, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3910\n",
      "Loss: tensor(0.1115, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3911\n",
      "Loss: tensor(0.1115, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3912\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor(0.1115, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3913\n",
      "Loss: tensor(0.1115, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3914\n",
      "Loss: tensor(0.1115, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3915\n",
      "Loss: tensor(0.1115, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3916\n",
      "Loss: tensor(0.1115, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3917\n",
      "Loss: tensor(0.1114, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3918\n",
      "Loss: tensor(0.1114, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3919\n",
      "Loss: tensor(0.1114, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3920\n",
      "Loss: tensor(0.1114, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3921\n",
      "Loss: tensor(0.1114, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3922\n",
      "Loss: tensor(0.1114, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3923\n",
      "Loss: tensor(0.1114, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3924\n",
      "Loss: tensor(0.1114, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3925\n",
      "Loss: tensor(0.1114, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3926\n",
      "Loss: tensor(0.1114, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3927\n",
      "Loss: tensor(0.1114, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3928\n",
      "Loss: tensor(0.1114, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3929\n",
      "Loss: tensor(0.1113, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3930\n",
      "Loss: tensor(0.1113, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3931\n",
      "Loss: tensor(0.1113, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3932\n",
      "Loss: tensor(0.1113, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3933\n",
      "Loss: tensor(0.1113, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3934\n",
      "Loss: tensor(0.1113, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3935\n",
      "Loss: tensor(0.1113, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3936\n",
      "Loss: tensor(0.1113, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3937\n",
      "Loss: tensor(0.1113, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3938\n",
      "Loss: tensor(0.1112, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3939\n",
      "Loss: tensor(0.1112, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3940\n",
      "Loss: tensor(0.1112, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3941\n",
      "Loss: tensor(0.1112, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3942\n",
      "Loss: tensor(0.1112, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3943\n",
      "Loss: tensor(0.1112, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3944\n",
      "Loss: tensor(0.1112, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3945\n",
      "Loss: tensor(0.1112, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3946\n",
      "Loss: tensor(0.1112, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3947\n",
      "Loss: tensor(0.1112, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3948\n",
      "Loss: tensor(0.1111, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3949\n",
      "Loss: tensor(0.1111, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3950\n",
      "Loss: tensor(0.1111, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3951\n",
      "Loss: tensor(0.1111, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3952\n",
      "Loss: tensor(0.1111, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3953\n",
      "Loss: tensor(0.1111, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3954\n",
      "Loss: tensor(0.1111, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3955\n",
      "Loss: tensor(0.1111, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3956\n",
      "Loss: tensor(0.1111, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3957\n",
      "Loss: tensor(0.1111, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3958\n",
      "Loss: tensor(0.1111, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3959\n",
      "Loss: tensor(0.1110, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3960\n",
      "Loss: tensor(0.1110, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3961\n",
      "Loss: tensor(0.1110, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3962\n",
      "Loss: tensor(0.1110, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3963\n",
      "Loss: tensor(0.1110, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3964\n",
      "Loss: tensor(0.1110, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3965\n",
      "Loss: tensor(0.1110, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3966\n",
      "Loss: tensor(0.1110, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3967\n",
      "Loss: tensor(0.1110, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3968\n",
      "Loss: tensor(0.1110, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3969\n",
      "Loss: tensor(0.1110, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3970\n",
      "Loss: tensor(0.1109, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3971\n",
      "Loss: tensor(0.1109, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3972\n",
      "Loss: tensor(0.1109, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3973\n",
      "Loss: tensor(0.1109, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3974\n",
      "Loss: tensor(0.1109, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3975\n",
      "Loss: tensor(0.1109, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3976\n",
      "Loss: tensor(0.1109, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3977\n",
      "Loss: tensor(0.1109, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3978\n",
      "Loss: tensor(0.1109, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3979\n",
      "Loss: tensor(0.1109, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3980\n",
      "Loss: tensor(0.1109, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3981\n",
      "Loss: tensor(0.1108, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3982\n",
      "Loss: tensor(0.1108, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3983\n",
      "Loss: tensor(0.1108, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3984\n",
      "Loss: tensor(0.1108, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3985\n",
      "Loss: tensor(0.1108, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3986\n",
      "Loss: tensor(0.1108, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3987\n",
      "Loss: tensor(0.1108, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3988\n",
      "Loss: tensor(0.1108, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3989\n",
      "Loss: tensor(0.1108, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3990\n",
      "Loss: tensor(0.1108, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3991\n",
      "Loss: tensor(0.1108, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3992\n",
      "Loss: tensor(0.1107, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3993\n",
      "Loss: tensor(0.1107, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3994\n",
      "Loss: tensor(0.1107, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3995\n",
      "Loss: tensor(0.1107, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3996\n",
      "Loss: tensor(0.1107, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3997\n",
      "Loss: tensor(0.1107, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3998\n",
      "Loss: tensor(0.1107, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3999\n",
      "Loss: tensor(0.1107, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4000\n",
      "Loss: tensor(0.1107, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4001\n",
      "Loss: tensor(0.1107, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4002\n",
      "Loss: tensor(0.1107, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4003\n",
      "Loss: tensor(0.1106, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4004\n",
      "Loss: tensor(0.1106, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4005\n",
      "Loss: tensor(0.1106, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4006\n",
      "Loss: tensor(0.1106, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4007\n",
      "Loss: tensor(0.1106, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4008\n",
      "Loss: tensor(0.1106, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4009\n",
      "Loss: tensor(0.1106, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4010\n",
      "Loss: tensor(0.1106, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4011\n",
      "Loss: tensor(0.1106, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4012\n",
      "Loss: tensor(0.1106, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4013\n",
      "Loss: tensor(0.1106, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4014\n",
      "Loss: tensor(0.1106, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4015\n",
      "Loss: tensor(0.1105, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4016\n",
      "Loss: tensor(0.1105, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4017\n",
      "Loss: tensor(0.1105, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4018\n",
      "Loss: tensor(0.1105, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4019\n",
      "Loss: tensor(0.1105, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4020\n",
      "Loss: tensor(0.1105, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4021\n",
      "Loss: tensor(0.1105, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4022\n",
      "Loss: tensor(0.1105, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4023\n",
      "Loss: tensor(0.1105, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4024\n",
      "Loss: tensor(0.1105, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4025\n",
      "Loss: tensor(0.1105, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4026\n",
      "Loss: tensor(0.1105, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4027\n",
      "Loss: tensor(0.1104, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4028\n",
      "Loss: tensor(0.1104, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4029\n",
      "Loss: tensor(0.1104, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4030\n",
      "Loss: tensor(0.1104, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4031\n",
      "Loss: tensor(0.1104, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4032\n",
      "Loss: tensor(0.1104, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4033\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor(0.1104, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4034\n",
      "Loss: tensor(0.1104, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4035\n",
      "Loss: tensor(0.1104, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4036\n",
      "Loss: tensor(0.1104, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4037\n",
      "Loss: tensor(0.1104, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4038\n",
      "Loss: tensor(0.1103, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4039\n",
      "Loss: tensor(0.1103, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4040\n",
      "Loss: tensor(0.1103, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4041\n",
      "Loss: tensor(0.1103, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4042\n",
      "Loss: tensor(0.1103, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4043\n",
      "Loss: tensor(0.1103, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4044\n",
      "Loss: tensor(0.1103, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4045\n",
      "Loss: tensor(0.1103, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4046\n",
      "Loss: tensor(0.1103, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4047\n",
      "Loss: tensor(0.1103, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4048\n",
      "Loss: tensor(0.1103, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4049\n",
      "Loss: tensor(0.1103, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4050\n",
      "Loss: tensor(0.1102, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4051\n",
      "Loss: tensor(0.1102, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4052\n",
      "Loss: tensor(0.1102, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4053\n",
      "Loss: tensor(0.1102, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4054\n",
      "Loss: tensor(0.1102, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4055\n",
      "Loss: tensor(0.1102, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4056\n",
      "Loss: tensor(0.1102, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4057\n",
      "Loss: tensor(0.1102, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4058\n",
      "Loss: tensor(0.1102, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4059\n",
      "Loss: tensor(0.1102, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4060\n",
      "Loss: tensor(0.1102, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4061\n",
      "Loss: tensor(0.1102, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4062\n",
      "Loss: tensor(0.1101, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4063\n",
      "Loss: tensor(0.1101, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4064\n",
      "Loss: tensor(0.1101, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4065\n",
      "Loss: tensor(0.1101, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4066\n",
      "Loss: tensor(0.1101, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4067\n",
      "Loss: tensor(0.1101, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4068\n",
      "Loss: tensor(0.1101, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4069\n",
      "Loss: tensor(0.1101, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4070\n",
      "Loss: tensor(0.1101, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4071\n",
      "Loss: tensor(0.1101, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4072\n",
      "Loss: tensor(0.1101, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4073\n",
      "Loss: tensor(0.1101, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4074\n",
      "Loss: tensor(0.1100, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4075\n",
      "Loss: tensor(0.1100, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4076\n",
      "Loss: tensor(0.1100, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4077\n",
      "Loss: tensor(0.1100, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4078\n",
      "Loss: tensor(0.1100, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4079\n",
      "Loss: tensor(0.1100, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4080\n",
      "Loss: tensor(0.1100, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4081\n",
      "Loss: tensor(0.1100, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4082\n",
      "Loss: tensor(0.1100, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4083\n",
      "Loss: tensor(0.1100, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4084\n",
      "Loss: tensor(0.1100, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4085\n",
      "Loss: tensor(0.1100, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4086\n",
      "Loss: tensor(0.1100, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4087\n",
      "Loss: tensor(0.1099, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4088\n",
      "Loss: tensor(0.1099, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4089\n",
      "Loss: tensor(0.1099, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4090\n",
      "Loss: tensor(0.1099, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4091\n",
      "Loss: tensor(0.1099, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4092\n",
      "Loss: tensor(0.1099, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4093\n",
      "Loss: tensor(0.1099, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4094\n",
      "Loss: tensor(0.1099, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4095\n",
      "Loss: tensor(0.1099, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4096\n",
      "Loss: tensor(0.1099, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4097\n",
      "Loss: tensor(0.1099, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4098\n",
      "Loss: tensor(0.1099, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4099\n",
      "Loss: tensor(0.1099, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4100\n",
      "Loss: tensor(0.1098, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4101\n",
      "Loss: tensor(0.1098, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4102\n",
      "Loss: tensor(0.1098, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4103\n",
      "Loss: tensor(0.1098, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4104\n",
      "Loss: tensor(0.1098, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4105\n",
      "Loss: tensor(0.1098, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4106\n",
      "Loss: tensor(0.1098, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4107\n",
      "Loss: tensor(0.1098, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4108\n",
      "Loss: tensor(0.1098, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4109\n",
      "Loss: tensor(0.1098, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4110\n",
      "Loss: tensor(0.1098, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4111\n",
      "Loss: tensor(0.1098, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4112\n",
      "Loss: tensor(0.1098, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4113\n",
      "Loss: tensor(0.1097, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4114\n",
      "Loss: tensor(0.1097, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4115\n",
      "Loss: tensor(0.1097, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4116\n",
      "Loss: tensor(0.1097, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4117\n",
      "Loss: tensor(0.1097, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4118\n",
      "Loss: tensor(0.1097, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4119\n",
      "Loss: tensor(0.1097, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4120\n",
      "Loss: tensor(0.1097, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4121\n",
      "Loss: tensor(0.1097, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4122\n",
      "Loss: tensor(0.1097, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4123\n",
      "Loss: tensor(0.1097, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4124\n",
      "Loss: tensor(0.1097, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4125\n",
      "Loss: tensor(0.1097, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4126\n",
      "Loss: tensor(0.1096, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4127\n",
      "Loss: tensor(0.1096, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4128\n",
      "Loss: tensor(0.1096, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4129\n",
      "Loss: tensor(0.1096, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4130\n",
      "Loss: tensor(0.1096, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4131\n",
      "Loss: tensor(0.1096, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4132\n",
      "Loss: tensor(0.1096, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4133\n",
      "Loss: tensor(0.1096, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4134\n",
      "Loss: tensor(0.1096, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4135\n",
      "Loss: tensor(0.1096, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4136\n",
      "Loss: tensor(0.1096, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4137\n",
      "Loss: tensor(0.1096, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4138\n",
      "Loss: tensor(0.1096, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4139\n",
      "Loss: tensor(0.1096, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4140\n",
      "Loss: tensor(0.1095, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4141\n",
      "Loss: tensor(0.1095, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4142\n",
      "Loss: tensor(0.1096, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4143\n",
      "Loss: tensor(0.1096, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4144\n",
      "Loss: tensor(0.1096, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4145\n",
      "Loss: tensor(0.1096, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4146\n",
      "Loss: tensor(0.1095, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4147\n",
      "Loss: tensor(0.1095, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4148\n",
      "Loss: tensor(0.1095, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4149\n",
      "Loss: tensor(0.1095, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4150\n",
      "Loss: tensor(0.1095, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4151\n",
      "Loss: tensor(0.1095, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4152\n",
      "Loss: tensor(0.1095, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4153\n",
      "Loss: tensor(0.1094, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4154\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor(0.1094, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4155\n",
      "Loss: tensor(0.1094, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4156\n",
      "Loss: tensor(0.1094, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4157\n",
      "Loss: tensor(0.1094, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4158\n",
      "Loss: tensor(0.1094, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4159\n",
      "Loss: tensor(0.1094, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4160\n",
      "Loss: tensor(0.1094, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4161\n",
      "Loss: tensor(0.1094, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4162\n",
      "Loss: tensor(0.1094, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4163\n",
      "Loss: tensor(0.1094, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4164\n",
      "Loss: tensor(0.1094, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4165\n",
      "Loss: tensor(0.1094, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4166\n",
      "Loss: tensor(0.1094, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4167\n",
      "Loss: tensor(0.1093, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4168\n",
      "Loss: tensor(0.1093, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4169\n",
      "Loss: tensor(0.1093, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4170\n",
      "Loss: tensor(0.1093, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4171\n",
      "Loss: tensor(0.1093, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4172\n",
      "Loss: tensor(0.1093, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4173\n",
      "Loss: tensor(0.1093, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4174\n",
      "Loss: tensor(0.1093, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4175\n",
      "Loss: tensor(0.1093, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4176\n",
      "Loss: tensor(0.1093, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4177\n",
      "Loss: tensor(0.1093, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4178\n",
      "Loss: tensor(0.1093, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4179\n",
      "Loss: tensor(0.1093, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4180\n",
      "Loss: tensor(0.1092, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4181\n",
      "Loss: tensor(0.1092, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4182\n",
      "Loss: tensor(0.1092, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4183\n",
      "Loss: tensor(0.1092, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4184\n",
      "Loss: tensor(0.1092, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4185\n",
      "Loss: tensor(0.1092, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4186\n",
      "Loss: tensor(0.1092, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4187\n",
      "Loss: tensor(0.1092, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4188\n",
      "Loss: tensor(0.1092, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4189\n",
      "Loss: tensor(0.1092, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4190\n",
      "Loss: tensor(0.1092, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4191\n",
      "Loss: tensor(0.1092, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4192\n",
      "Loss: tensor(0.1092, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4193\n",
      "Loss: tensor(0.1092, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4194\n",
      "Loss: tensor(0.1091, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4195\n",
      "Loss: tensor(0.1091, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4196\n",
      "Loss: tensor(0.1091, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4197\n",
      "Loss: tensor(0.1091, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4198\n",
      "Loss: tensor(0.1091, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4199\n",
      "Loss: tensor(0.1091, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4200\n",
      "Loss: tensor(0.1091, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4201\n",
      "Loss: tensor(0.1091, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4202\n",
      "Loss: tensor(0.1091, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4203\n",
      "Loss: tensor(0.1091, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4204\n",
      "Loss: tensor(0.1091, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4205\n",
      "Loss: tensor(0.1091, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4206\n",
      "Loss: tensor(0.1091, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4207\n",
      "Loss: tensor(0.1091, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4208\n",
      "Loss: tensor(0.1091, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4209\n",
      "Loss: tensor(0.1090, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4210\n",
      "Loss: tensor(0.1090, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4211\n",
      "Loss: tensor(0.1090, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4212\n",
      "Loss: tensor(0.1090, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4213\n",
      "Loss: tensor(0.1090, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4214\n",
      "Loss: tensor(0.1090, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4215\n",
      "Loss: tensor(0.1090, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4216\n",
      "Loss: tensor(0.1090, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4217\n",
      "Loss: tensor(0.1090, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4218\n",
      "Loss: tensor(0.1090, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4219\n",
      "Loss: tensor(0.1090, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4220\n",
      "Loss: tensor(0.1090, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4221\n",
      "Loss: tensor(0.1090, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4222\n",
      "Loss: tensor(0.1090, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4223\n",
      "Loss: tensor(0.1090, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4224\n",
      "Loss: tensor(0.1089, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4225\n",
      "Loss: tensor(0.1089, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4226\n",
      "Loss: tensor(0.1089, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4227\n",
      "Loss: tensor(0.1089, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4228\n",
      "Loss: tensor(0.1089, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4229\n",
      "Loss: tensor(0.1089, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4230\n",
      "Loss: tensor(0.1089, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4231\n",
      "Loss: tensor(0.1089, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4232\n",
      "Loss: tensor(0.1089, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4233\n",
      "Loss: tensor(0.1089, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4234\n",
      "Loss: tensor(0.1089, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4235\n",
      "Loss: tensor(0.1089, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4236\n",
      "Loss: tensor(0.1089, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4237\n",
      "Loss: tensor(0.1089, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4238\n",
      "Loss: tensor(0.1088, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4239\n",
      "Loss: tensor(0.1088, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4240\n",
      "Loss: tensor(0.1088, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4241\n",
      "Loss: tensor(0.1088, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4242\n",
      "Loss: tensor(0.1088, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4243\n",
      "Loss: tensor(0.1088, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4244\n",
      "Loss: tensor(0.1088, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4245\n",
      "Loss: tensor(0.1088, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4246\n",
      "Loss: tensor(0.1088, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4247\n",
      "Loss: tensor(0.1088, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4248\n",
      "Loss: tensor(0.1088, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4249\n",
      "Loss: tensor(0.1088, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4250\n",
      "Loss: tensor(0.1088, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4251\n",
      "Loss: tensor(0.1088, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4252\n",
      "Loss: tensor(0.1088, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4253\n",
      "Loss: tensor(0.1088, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4254\n",
      "Loss: tensor(0.1087, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4255\n",
      "Loss: tensor(0.1087, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4256\n",
      "Loss: tensor(0.1087, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4257\n",
      "Loss: tensor(0.1087, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4258\n",
      "Loss: tensor(0.1087, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4259\n",
      "Loss: tensor(0.1087, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4260\n",
      "Loss: tensor(0.1087, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4261\n",
      "Loss: tensor(0.1087, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4262\n",
      "Loss: tensor(0.1087, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4263\n",
      "Loss: tensor(0.1087, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4264\n",
      "Loss: tensor(0.1087, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4265\n",
      "Loss: tensor(0.1087, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4266\n",
      "Loss: tensor(0.1087, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4267\n",
      "Loss: tensor(0.1087, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4268\n",
      "Loss: tensor(0.1087, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4269\n",
      "Loss: tensor(0.1087, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4270\n",
      "Loss: tensor(0.1087, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4271\n",
      "Loss: tensor(0.1087, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4272\n",
      "Loss: tensor(0.1086, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4273\n",
      "Loss: tensor(0.1086, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4274\n",
      "Loss: tensor(0.1086, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4275\n",
      "Loss: tensor(0.1086, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4276\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor(0.1086, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4277\n",
      "Loss: tensor(0.1086, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4278\n",
      "Loss: tensor(0.1086, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4279\n",
      "Loss: tensor(0.1086, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4280\n",
      "Loss: tensor(0.1086, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4281\n",
      "Loss: tensor(0.1086, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4282\n",
      "Loss: tensor(0.1086, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4283\n",
      "Loss: tensor(0.1086, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4284\n",
      "Loss: tensor(0.1086, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4285\n",
      "Loss: tensor(0.1085, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4286\n",
      "Loss: tensor(0.1085, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4287\n",
      "Loss: tensor(0.1085, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4288\n",
      "Loss: tensor(0.1085, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4289\n",
      "Loss: tensor(0.1085, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4290\n",
      "Loss: tensor(0.1085, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4291\n",
      "Loss: tensor(0.1085, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4292\n",
      "Loss: tensor(0.1085, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4293\n",
      "Loss: tensor(0.1085, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4294\n",
      "Loss: tensor(0.1085, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4295\n",
      "Loss: tensor(0.1085, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4296\n",
      "Loss: tensor(0.1085, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4297\n",
      "Loss: tensor(0.1085, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4298\n",
      "Loss: tensor(0.1085, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4299\n",
      "Loss: tensor(0.1085, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4300\n",
      "Loss: tensor(0.1085, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4301\n",
      "Loss: tensor(0.1084, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4302\n",
      "Loss: tensor(0.1084, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4303\n",
      "Loss: tensor(0.1084, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4304\n",
      "Loss: tensor(0.1084, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4305\n",
      "Loss: tensor(0.1084, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4306\n",
      "Loss: tensor(0.1084, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4307\n",
      "Loss: tensor(0.1084, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4308\n",
      "Loss: tensor(0.1084, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4309\n",
      "Loss: tensor(0.1084, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4310\n",
      "Loss: tensor(0.1084, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4311\n",
      "Loss: tensor(0.1084, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4312\n",
      "Loss: tensor(0.1084, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4313\n",
      "Loss: tensor(0.1084, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4314\n",
      "Loss: tensor(0.1084, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4315\n",
      "Loss: tensor(0.1084, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4316\n",
      "Loss: tensor(0.1084, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4317\n",
      "Loss: tensor(0.1083, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4318\n",
      "Loss: tensor(0.1083, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4319\n",
      "Loss: tensor(0.1083, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4320\n",
      "Loss: tensor(0.1083, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4321\n",
      "Loss: tensor(0.1083, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4322\n",
      "Loss: tensor(0.1083, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4323\n",
      "Loss: tensor(0.1083, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4324\n",
      "Loss: tensor(0.1083, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4325\n",
      "Loss: tensor(0.1083, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4326\n",
      "Loss: tensor(0.1083, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4327\n",
      "Loss: tensor(0.1083, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4328\n",
      "Loss: tensor(0.1083, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4329\n",
      "Loss: tensor(0.1083, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4330\n",
      "Loss: tensor(0.1083, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4331\n",
      "Loss: tensor(0.1083, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4332\n",
      "Loss: tensor(0.1083, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4333\n",
      "Loss: tensor(0.1083, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4334\n",
      "Loss: tensor(0.1082, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4335\n",
      "Loss: tensor(0.1082, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4336\n",
      "Loss: tensor(0.1082, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4337\n",
      "Loss: tensor(0.1082, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4338\n",
      "Loss: tensor(0.1082, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4339\n",
      "Loss: tensor(0.1082, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4340\n",
      "Loss: tensor(0.1082, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4341\n",
      "Loss: tensor(0.1082, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4342\n",
      "Loss: tensor(0.1082, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4343\n",
      "Loss: tensor(0.1082, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4344\n",
      "Loss: tensor(0.1082, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4345\n",
      "Loss: tensor(0.1082, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4346\n",
      "Loss: tensor(0.1082, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4347\n",
      "Loss: tensor(0.1082, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4348\n",
      "Loss: tensor(0.1082, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4349\n",
      "Loss: tensor(0.1082, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4350\n",
      "Loss: tensor(0.1082, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4351\n",
      "Loss: tensor(0.1081, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4352\n",
      "Loss: tensor(0.1081, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4353\n",
      "Loss: tensor(0.1081, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4354\n",
      "Loss: tensor(0.1081, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4355\n",
      "Loss: tensor(0.1081, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4356\n",
      "Loss: tensor(0.1081, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4357\n",
      "Loss: tensor(0.1081, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4358\n",
      "Loss: tensor(0.1081, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4359\n",
      "Loss: tensor(0.1081, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4360\n",
      "Loss: tensor(0.1081, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4361\n",
      "Loss: tensor(0.1081, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4362\n",
      "Loss: tensor(0.1081, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4363\n",
      "Loss: tensor(0.1081, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4364\n",
      "Loss: tensor(0.1081, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4365\n",
      "Loss: tensor(0.1081, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4366\n",
      "Loss: tensor(0.1081, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4367\n",
      "Loss: tensor(0.1081, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4368\n",
      "Loss: tensor(0.1080, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4369\n",
      "Loss: tensor(0.1080, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4370\n",
      "Loss: tensor(0.1080, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4371\n",
      "Loss: tensor(0.1080, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4372\n",
      "Loss: tensor(0.1080, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4373\n",
      "Loss: tensor(0.1080, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4374\n",
      "Loss: tensor(0.1080, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4375\n",
      "Loss: tensor(0.1080, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4376\n",
      "Loss: tensor(0.1080, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4377\n",
      "Loss: tensor(0.1080, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4378\n",
      "Loss: tensor(0.1080, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4379\n",
      "Loss: tensor(0.1080, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4380\n",
      "Loss: tensor(0.1080, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4381\n",
      "Loss: tensor(0.1080, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4382\n",
      "Loss: tensor(0.1080, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4383\n",
      "Loss: tensor(0.1080, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4384\n",
      "Loss: tensor(0.1080, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4385\n",
      "Loss: tensor(0.1079, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4386\n",
      "Loss: tensor(0.1079, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4387\n",
      "Loss: tensor(0.1079, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4388\n",
      "Loss: tensor(0.1079, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4389\n",
      "Loss: tensor(0.1079, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4390\n",
      "Loss: tensor(0.1079, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4391\n",
      "Loss: tensor(0.1079, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4392\n",
      "Loss: tensor(0.1079, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4393\n",
      "Loss: tensor(0.1079, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4394\n",
      "Loss: tensor(0.1079, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4395\n",
      "Loss: tensor(0.1079, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4396\n",
      "Loss: tensor(0.1079, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4397\n",
      "Loss: tensor(0.1079, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4398\n",
      "Loss: tensor(0.1079, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4399\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor(0.1079, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4400\n",
      "Loss: tensor(0.1079, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4401\n",
      "Loss: tensor(0.1079, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4402\n",
      "Loss: tensor(0.1079, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4403\n",
      "Loss: tensor(0.1078, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4404\n",
      "Loss: tensor(0.1078, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4405\n",
      "Loss: tensor(0.1078, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4406\n",
      "Loss: tensor(0.1078, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4407\n",
      "Loss: tensor(0.1078, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4408\n",
      "Loss: tensor(0.1078, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4409\n",
      "Loss: tensor(0.1078, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4410\n",
      "Loss: tensor(0.1078, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4411\n",
      "Loss: tensor(0.1078, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4412\n",
      "Loss: tensor(0.1078, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4413\n",
      "Loss: tensor(0.1078, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4414\n",
      "Loss: tensor(0.1078, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4415\n",
      "Loss: tensor(0.1078, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4416\n",
      "Loss: tensor(0.1078, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4417\n",
      "Loss: tensor(0.1078, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4418\n",
      "Loss: tensor(0.1078, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4419\n",
      "Loss: tensor(0.1078, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4420\n",
      "Loss: tensor(0.1078, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4421\n",
      "Loss: tensor(0.1078, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4422\n",
      "Loss: tensor(0.1078, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4423\n",
      "Loss: tensor(0.1078, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4424\n",
      "Loss: tensor(0.1077, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4425\n",
      "Loss: tensor(0.1077, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4426\n",
      "Loss: tensor(0.1077, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4427\n",
      "Loss: tensor(0.1077, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4428\n",
      "Loss: tensor(0.1077, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4429\n",
      "Loss: tensor(0.1077, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4430\n",
      "Loss: tensor(0.1077, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4431\n",
      "Loss: tensor(0.1077, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4432\n",
      "Loss: tensor(0.1077, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4433\n",
      "Loss: tensor(0.1077, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4434\n",
      "Loss: tensor(0.1077, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4435\n",
      "Loss: tensor(0.1077, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4436\n",
      "Loss: tensor(0.1077, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4437\n",
      "Loss: tensor(0.1077, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4438\n",
      "Loss: tensor(0.1077, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4439\n",
      "Loss: tensor(0.1077, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4440\n",
      "Loss: tensor(0.1076, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4441\n",
      "Loss: tensor(0.1076, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4442\n",
      "Loss: tensor(0.1076, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4443\n",
      "Loss: tensor(0.1076, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4444\n",
      "Loss: tensor(0.1076, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4445\n",
      "Loss: tensor(0.1076, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4446\n",
      "Loss: tensor(0.1076, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4447\n",
      "Loss: tensor(0.1076, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4448\n",
      "Loss: tensor(0.1076, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4449\n",
      "Loss: tensor(0.1076, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4450\n",
      "Loss: tensor(0.1076, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4451\n",
      "Loss: tensor(0.1076, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4452\n",
      "Loss: tensor(0.1076, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4453\n",
      "Loss: tensor(0.1076, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4454\n",
      "Loss: tensor(0.1076, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4455\n",
      "Loss: tensor(0.1076, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4456\n",
      "Loss: tensor(0.1076, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4457\n",
      "Loss: tensor(0.1076, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4458\n",
      "Loss: tensor(0.1076, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4459\n",
      "Loss: tensor(0.1075, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4460\n",
      "Loss: tensor(0.1075, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4461\n",
      "Loss: tensor(0.1075, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4462\n",
      "Loss: tensor(0.1075, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4463\n",
      "Loss: tensor(0.1075, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4464\n",
      "Loss: tensor(0.1075, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4465\n",
      "Loss: tensor(0.1075, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4466\n",
      "Loss: tensor(0.1075, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4467\n",
      "Loss: tensor(0.1075, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4468\n",
      "Loss: tensor(0.1075, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4469\n",
      "Loss: tensor(0.1075, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4470\n",
      "Loss: tensor(0.1075, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4471\n",
      "Loss: tensor(0.1075, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4472\n",
      "Loss: tensor(0.1075, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4473\n",
      "Loss: tensor(0.1075, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4474\n",
      "Loss: tensor(0.1075, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4475\n",
      "Loss: tensor(0.1075, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4476\n",
      "Loss: tensor(0.1075, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4477\n",
      "Loss: tensor(0.1075, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4478\n",
      "Loss: tensor(0.1074, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4479\n",
      "Loss: tensor(0.1074, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4480\n",
      "Loss: tensor(0.1074, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4481\n",
      "Loss: tensor(0.1074, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4482\n",
      "Loss: tensor(0.1074, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4483\n",
      "Loss: tensor(0.1074, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4484\n",
      "Loss: tensor(0.1074, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4485\n",
      "Loss: tensor(0.1074, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4486\n",
      "Loss: tensor(0.1074, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4487\n",
      "Loss: tensor(0.1074, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4488\n",
      "Loss: tensor(0.1074, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4489\n",
      "Loss: tensor(0.1074, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4490\n",
      "Loss: tensor(0.1074, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4491\n",
      "Loss: tensor(0.1074, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4492\n",
      "Loss: tensor(0.1074, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4493\n",
      "Loss: tensor(0.1074, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4494\n",
      "Loss: tensor(0.1074, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4495\n",
      "Loss: tensor(0.1074, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4496\n",
      "Loss: tensor(0.1074, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4497\n",
      "Loss: tensor(0.1074, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4498\n",
      "Loss: tensor(0.1073, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4499\n",
      "Loss: tensor(0.1073, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4500\n",
      "Loss: tensor(0.1073, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4501\n",
      "Loss: tensor(0.1073, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4502\n",
      "Loss: tensor(0.1073, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4503\n",
      "Loss: tensor(0.1073, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4504\n",
      "Loss: tensor(0.1073, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4505\n",
      "Loss: tensor(0.1073, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4506\n",
      "Loss: tensor(0.1073, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4507\n",
      "Loss: tensor(0.1073, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4508\n",
      "Loss: tensor(0.1073, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4509\n",
      "Loss: tensor(0.1073, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4510\n",
      "Loss: tensor(0.1073, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4511\n",
      "Loss: tensor(0.1073, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4512\n",
      "Loss: tensor(0.1073, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4513\n",
      "Loss: tensor(0.1073, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4514\n",
      "Loss: tensor(0.1073, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4515\n",
      "Loss: tensor(0.1073, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4516\n",
      "Loss: tensor(0.1073, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4517\n",
      "Loss: tensor(0.1073, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4518\n",
      "Loss: tensor(0.1072, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4519\n",
      "Loss: tensor(0.1072, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4520\n",
      "Loss: tensor(0.1072, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4521\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor(0.1072, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4522\n",
      "Loss: tensor(0.1072, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4523\n",
      "Loss: tensor(0.1072, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4524\n",
      "Loss: tensor(0.1072, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4525\n",
      "Loss: tensor(0.1072, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4526\n",
      "Loss: tensor(0.1072, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4527\n",
      "Loss: tensor(0.1072, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4528\n",
      "Loss: tensor(0.1072, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4529\n",
      "Loss: tensor(0.1072, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4530\n",
      "Loss: tensor(0.1072, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4531\n",
      "Loss: tensor(0.1072, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4532\n",
      "Loss: tensor(0.1072, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4533\n",
      "Loss: tensor(0.1072, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4534\n",
      "Loss: tensor(0.1072, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4535\n",
      "Loss: tensor(0.1072, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4536\n",
      "Loss: tensor(0.1072, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4537\n",
      "Loss: tensor(0.1072, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4538\n",
      "Loss: tensor(0.1072, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4539\n",
      "Loss: tensor(0.1072, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4540\n",
      "Loss: tensor(0.1072, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4541\n",
      "Loss: tensor(0.1072, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4542\n",
      "Loss: tensor(0.1072, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4543\n",
      "Loss: tensor(0.1072, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4544\n",
      "Loss: tensor(0.1071, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4545\n",
      "Loss: tensor(0.1071, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4546\n",
      "Loss: tensor(0.1071, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4547\n",
      "Loss: tensor(0.1071, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4548\n",
      "Loss: tensor(0.1071, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4549\n",
      "Loss: tensor(0.1071, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4550\n",
      "Loss: tensor(0.1071, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4551\n",
      "Loss: tensor(0.1071, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4552\n",
      "Loss: tensor(0.1071, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4553\n",
      "Loss: tensor(0.1071, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4554\n",
      "Loss: tensor(0.1071, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4555\n",
      "Loss: tensor(0.1071, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4556\n",
      "Loss: tensor(0.1071, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4557\n",
      "Loss: tensor(0.1071, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4558\n",
      "Loss: tensor(0.1071, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4559\n",
      "Loss: tensor(0.1071, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4560\n",
      "Loss: tensor(0.1070, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4561\n",
      "Loss: tensor(0.1070, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4562\n",
      "Loss: tensor(0.1070, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4563\n",
      "Loss: tensor(0.1070, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4564\n",
      "Loss: tensor(0.1070, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4565\n",
      "Loss: tensor(0.1070, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4566\n",
      "Loss: tensor(0.1070, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4567\n",
      "Loss: tensor(0.1070, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4568\n",
      "Loss: tensor(0.1070, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4569\n",
      "Loss: tensor(0.1070, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4570\n",
      "Loss: tensor(0.1070, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4571\n",
      "Loss: tensor(0.1070, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4572\n",
      "Loss: tensor(0.1070, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4573\n",
      "Loss: tensor(0.1070, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4574\n",
      "Loss: tensor(0.1070, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4575\n",
      "Loss: tensor(0.1070, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4576\n",
      "Loss: tensor(0.1070, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4577\n",
      "Loss: tensor(0.1070, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4578\n",
      "Loss: tensor(0.1070, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4579\n",
      "Loss: tensor(0.1070, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4580\n",
      "Loss: tensor(0.1069, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4581\n",
      "Loss: tensor(0.1069, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4582\n",
      "Loss: tensor(0.1069, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4583\n",
      "Loss: tensor(0.1069, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4584\n",
      "Loss: tensor(0.1069, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4585\n",
      "Loss: tensor(0.1069, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4586\n",
      "Loss: tensor(0.1069, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4587\n",
      "Loss: tensor(0.1069, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4588\n",
      "Loss: tensor(0.1069, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4589\n",
      "Loss: tensor(0.1069, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4590\n",
      "Loss: tensor(0.1069, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4591\n",
      "Loss: tensor(0.1069, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4592\n",
      "Loss: tensor(0.1069, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4593\n",
      "Loss: tensor(0.1069, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4594\n",
      "Loss: tensor(0.1069, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4595\n",
      "Loss: tensor(0.1069, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4596\n",
      "Loss: tensor(0.1069, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4597\n",
      "Loss: tensor(0.1069, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4598\n",
      "Loss: tensor(0.1069, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4599\n",
      "Loss: tensor(0.1069, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4600\n",
      "Loss: tensor(0.1069, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4601\n",
      "Loss: tensor(0.1068, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4602\n",
      "Loss: tensor(0.1068, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4603\n",
      "Loss: tensor(0.1068, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4604\n",
      "Loss: tensor(0.1068, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4605\n",
      "Loss: tensor(0.1068, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4606\n",
      "Loss: tensor(0.1068, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4607\n",
      "Loss: tensor(0.1068, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4608\n",
      "Loss: tensor(0.1068, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4609\n",
      "Loss: tensor(0.1068, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4610\n",
      "Loss: tensor(0.1068, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4611\n",
      "Loss: tensor(0.1068, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4612\n",
      "Loss: tensor(0.1068, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4613\n",
      "Loss: tensor(0.1068, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4614\n",
      "Loss: tensor(0.1068, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4615\n",
      "Loss: tensor(0.1068, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4616\n",
      "Loss: tensor(0.1068, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4617\n",
      "Loss: tensor(0.1068, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4618\n",
      "Loss: tensor(0.1068, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4619\n",
      "Loss: tensor(0.1068, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4620\n",
      "Loss: tensor(0.1068, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4621\n",
      "Loss: tensor(0.1068, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4622\n",
      "Loss: tensor(0.1068, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4623\n",
      "Loss: tensor(0.1068, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4624\n",
      "Loss: tensor(0.1068, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4625\n",
      "Loss: tensor(0.1067, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4626\n",
      "Loss: tensor(0.1067, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4627\n",
      "Loss: tensor(0.1067, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4628\n",
      "Loss: tensor(0.1067, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4629\n",
      "Loss: tensor(0.1067, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4630\n",
      "Loss: tensor(0.1067, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4631\n",
      "Loss: tensor(0.1067, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4632\n",
      "Loss: tensor(0.1067, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4633\n",
      "Loss: tensor(0.1067, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4634\n",
      "Loss: tensor(0.1067, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4635\n",
      "Loss: tensor(0.1067, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4636\n",
      "Loss: tensor(0.1067, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4637\n",
      "Loss: tensor(0.1067, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4638\n",
      "Loss: tensor(0.1067, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4639\n",
      "Loss: tensor(0.1067, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4640\n",
      "Loss: tensor(0.1067, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4641\n",
      "Loss: tensor(0.1067, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4642\n",
      "Loss: tensor(0.1067, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4643\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor(0.1067, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4644\n",
      "Loss: tensor(0.1067, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4645\n",
      "Loss: tensor(0.1067, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4646\n",
      "Loss: tensor(0.1066, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4647\n",
      "Loss: tensor(0.1066, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4648\n",
      "Loss: tensor(0.1066, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4649\n",
      "Loss: tensor(0.1066, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4650\n",
      "Loss: tensor(0.1066, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4651\n",
      "Loss: tensor(0.1066, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4652\n",
      "Loss: tensor(0.1066, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4653\n",
      "Loss: tensor(0.1066, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4654\n",
      "Loss: tensor(0.1066, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4655\n",
      "Loss: tensor(0.1066, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4656\n",
      "Loss: tensor(0.1066, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4657\n",
      "Loss: tensor(0.1066, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4658\n",
      "Loss: tensor(0.1066, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4659\n",
      "Loss: tensor(0.1066, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4660\n",
      "Loss: tensor(0.1066, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4661\n",
      "Loss: tensor(0.1066, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4662\n",
      "Loss: tensor(0.1066, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4663\n",
      "Loss: tensor(0.1066, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4664\n",
      "Loss: tensor(0.1066, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4665\n",
      "Loss: tensor(0.1066, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4666\n",
      "Loss: tensor(0.1066, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4667\n",
      "Loss: tensor(0.1066, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4668\n",
      "Loss: tensor(0.1065, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4669\n",
      "Loss: tensor(0.1065, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4670\n",
      "Loss: tensor(0.1065, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4671\n",
      "Loss: tensor(0.1065, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4672\n",
      "Loss: tensor(0.1065, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4673\n",
      "Loss: tensor(0.1065, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4674\n",
      "Loss: tensor(0.1065, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4675\n",
      "Loss: tensor(0.1065, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4676\n",
      "Loss: tensor(0.1065, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4677\n",
      "Loss: tensor(0.1065, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4678\n",
      "Loss: tensor(0.1065, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4679\n",
      "Loss: tensor(0.1065, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4680\n",
      "Loss: tensor(0.1065, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4681\n",
      "Loss: tensor(0.1065, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4682\n",
      "Loss: tensor(0.1065, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4683\n",
      "Loss: tensor(0.1065, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4684\n",
      "Loss: tensor(0.1065, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4685\n",
      "Loss: tensor(0.1065, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4686\n",
      "Loss: tensor(0.1065, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4687\n",
      "Loss: tensor(0.1065, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4688\n",
      "Loss: tensor(0.1065, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4689\n",
      "Loss: tensor(0.1065, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4690\n",
      "Loss: tensor(0.1065, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4691\n",
      "Loss: tensor(0.1065, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4692\n",
      "Loss: tensor(0.1064, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4693\n",
      "Loss: tensor(0.1064, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4694\n",
      "Loss: tensor(0.1064, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4695\n",
      "Loss: tensor(0.1064, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4696\n",
      "Loss: tensor(0.1064, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4697\n",
      "Loss: tensor(0.1064, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4698\n",
      "Loss: tensor(0.1064, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4699\n",
      "Loss: tensor(0.1064, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4700\n",
      "Loss: tensor(0.1064, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4701\n",
      "Loss: tensor(0.1064, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4702\n",
      "Loss: tensor(0.1064, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4703\n",
      "Loss: tensor(0.1064, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4704\n",
      "Loss: tensor(0.1064, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4705\n",
      "Loss: tensor(0.1064, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4706\n",
      "Loss: tensor(0.1064, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4707\n",
      "Loss: tensor(0.1064, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4708\n",
      "Loss: tensor(0.1064, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4709\n",
      "Loss: tensor(0.1064, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4710\n",
      "Loss: tensor(0.1064, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4711\n",
      "Loss: tensor(0.1064, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4712\n",
      "Loss: tensor(0.1064, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4713\n",
      "Loss: tensor(0.1064, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4714\n",
      "Loss: tensor(0.1064, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4715\n",
      "Loss: tensor(0.1063, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4716\n",
      "Loss: tensor(0.1063, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4717\n",
      "Loss: tensor(0.1063, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4718\n",
      "Loss: tensor(0.1063, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4719\n",
      "Loss: tensor(0.1063, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4720\n",
      "Loss: tensor(0.1063, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4721\n",
      "Loss: tensor(0.1063, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4722\n",
      "Loss: tensor(0.1063, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4723\n",
      "Loss: tensor(0.1063, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4724\n",
      "Loss: tensor(0.1063, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4725\n",
      "Loss: tensor(0.1063, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4726\n",
      "Loss: tensor(0.1063, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4727\n",
      "Loss: tensor(0.1063, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4728\n",
      "Loss: tensor(0.1063, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4729\n",
      "Loss: tensor(0.1063, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4730\n",
      "Loss: tensor(0.1063, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4731\n",
      "Loss: tensor(0.1063, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4732\n",
      "Loss: tensor(0.1063, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4733\n",
      "Loss: tensor(0.1063, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4734\n",
      "Loss: tensor(0.1063, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4735\n",
      "Loss: tensor(0.1063, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4736\n",
      "Loss: tensor(0.1063, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4737\n",
      "Loss: tensor(0.1063, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4738\n",
      "Loss: tensor(0.1063, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4739\n",
      "Loss: tensor(0.1063, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4740\n",
      "Loss: tensor(0.1062, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4741\n",
      "Loss: tensor(0.1062, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4742\n",
      "Loss: tensor(0.1062, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4743\n",
      "Loss: tensor(0.1062, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4744\n",
      "Loss: tensor(0.1062, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4745\n",
      "Loss: tensor(0.1062, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4746\n",
      "Loss: tensor(0.1062, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4747\n",
      "Loss: tensor(0.1062, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4748\n",
      "Loss: tensor(0.1062, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4749\n",
      "Loss: tensor(0.1062, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4750\n",
      "Loss: tensor(0.1062, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4751\n",
      "Loss: tensor(0.1062, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4752\n",
      "Loss: tensor(0.1062, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4753\n",
      "Loss: tensor(0.1062, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4754\n",
      "Loss: tensor(0.1062, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4755\n",
      "Loss: tensor(0.1062, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4756\n",
      "Loss: tensor(0.1062, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4757\n",
      "Loss: tensor(0.1062, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4758\n",
      "Loss: tensor(0.1062, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4759\n",
      "Loss: tensor(0.1062, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4760\n",
      "Loss: tensor(0.1062, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4761\n",
      "Loss: tensor(0.1062, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4762\n",
      "Loss: tensor(0.1062, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4763\n",
      "Loss: tensor(0.1062, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4764\n",
      "Loss: tensor(0.1062, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4765\n",
      "Loss: tensor(0.1061, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4766\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor(0.1061, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4767\n",
      "Loss: tensor(0.1062, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4768\n",
      "Loss: tensor(0.1062, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4769\n",
      "Loss: tensor(0.1061, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4770\n",
      "Loss: tensor(0.1061, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4771\n",
      "Loss: tensor(0.1061, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4772\n",
      "Loss: tensor(0.1061, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4773\n",
      "Loss: tensor(0.1061, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4774\n",
      "Loss: tensor(0.1061, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4775\n",
      "Loss: tensor(0.1061, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4776\n",
      "Loss: tensor(0.1061, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4777\n",
      "Loss: tensor(0.1061, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4778\n",
      "Loss: tensor(0.1061, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4779\n",
      "Loss: tensor(0.1061, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4780\n",
      "Loss: tensor(0.1061, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4781\n",
      "Loss: tensor(0.1061, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4782\n",
      "Loss: tensor(0.1061, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4783\n",
      "Loss: tensor(0.1061, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4784\n",
      "Loss: tensor(0.1061, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4785\n",
      "Loss: tensor(0.1061, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4786\n",
      "Loss: tensor(0.1061, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4787\n",
      "Loss: tensor(0.1061, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4788\n",
      "Loss: tensor(0.1061, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4789\n",
      "Loss: tensor(0.1061, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4790\n",
      "Loss: tensor(0.1060, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4791\n",
      "Loss: tensor(0.1060, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4792\n",
      "Loss: tensor(0.1060, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4793\n",
      "Loss: tensor(0.1060, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4794\n",
      "Loss: tensor(0.1060, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4795\n",
      "Loss: tensor(0.1060, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4796\n",
      "Loss: tensor(0.1060, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4797\n",
      "Loss: tensor(0.1060, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4798\n",
      "Loss: tensor(0.1060, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4799\n",
      "Loss: tensor(0.1060, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4800\n",
      "Loss: tensor(0.1060, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4801\n",
      "Loss: tensor(0.1060, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4802\n",
      "Loss: tensor(0.1060, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4803\n",
      "Loss: tensor(0.1060, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4804\n",
      "Loss: tensor(0.1060, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4805\n",
      "Loss: tensor(0.1060, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4806\n",
      "Loss: tensor(0.1060, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4807\n",
      "Loss: tensor(0.1060, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4808\n",
      "Loss: tensor(0.1060, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4809\n",
      "Loss: tensor(0.1060, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4810\n",
      "Loss: tensor(0.1060, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4811\n",
      "Loss: tensor(0.1060, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4812\n",
      "Loss: tensor(0.1060, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4813\n",
      "Loss: tensor(0.1060, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4814\n",
      "Loss: tensor(0.1060, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4815\n",
      "Loss: tensor(0.1060, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4816\n",
      "Loss: tensor(0.1059, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4817\n",
      "Loss: tensor(0.1059, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4818\n",
      "Loss: tensor(0.1059, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4819\n",
      "Loss: tensor(0.1059, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4820\n",
      "Loss: tensor(0.1059, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4821\n",
      "Loss: tensor(0.1059, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4822\n",
      "Loss: tensor(0.1059, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4823\n",
      "Loss: tensor(0.1059, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4824\n",
      "Loss: tensor(0.1059, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4825\n",
      "Loss: tensor(0.1059, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4826\n",
      "Loss: tensor(0.1059, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4827\n",
      "Loss: tensor(0.1059, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4828\n",
      "Loss: tensor(0.1059, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4829\n",
      "Loss: tensor(0.1059, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4830\n",
      "Loss: tensor(0.1059, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4831\n",
      "Loss: tensor(0.1059, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4832\n",
      "Loss: tensor(0.1059, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4833\n",
      "Loss: tensor(0.1059, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4834\n",
      "Loss: tensor(0.1059, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4835\n",
      "Loss: tensor(0.1059, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4836\n",
      "Loss: tensor(0.1059, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4837\n",
      "Loss: tensor(0.1059, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4838\n",
      "Loss: tensor(0.1059, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4839\n",
      "Loss: tensor(0.1059, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4840\n",
      "Loss: tensor(0.1059, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4841\n",
      "Loss: tensor(0.1059, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4842\n",
      "Loss: tensor(0.1058, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4843\n",
      "Loss: tensor(0.1058, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4844\n",
      "Loss: tensor(0.1058, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4845\n",
      "Loss: tensor(0.1058, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4846\n",
      "Loss: tensor(0.1058, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4847\n",
      "Loss: tensor(0.1058, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4848\n",
      "Loss: tensor(0.1058, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4849\n",
      "Loss: tensor(0.1058, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4850\n",
      "Loss: tensor(0.1058, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4851\n",
      "Loss: tensor(0.1058, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4852\n",
      "Loss: tensor(0.1058, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4853\n",
      "Loss: tensor(0.1058, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4854\n",
      "Loss: tensor(0.1058, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4855\n",
      "Loss: tensor(0.1058, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4856\n",
      "Loss: tensor(0.1058, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4857\n",
      "Loss: tensor(0.1058, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4858\n",
      "Loss: tensor(0.1058, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4859\n",
      "Loss: tensor(0.1058, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4860\n",
      "Loss: tensor(0.1058, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4861\n",
      "Loss: tensor(0.1058, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4862\n",
      "Loss: tensor(0.1058, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4863\n",
      "Loss: tensor(0.1058, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4864\n",
      "Loss: tensor(0.1058, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4865\n",
      "Loss: tensor(0.1058, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4866\n",
      "Loss: tensor(0.1058, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4867\n",
      "Loss: tensor(0.1058, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4868\n",
      "Loss: tensor(0.1058, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4869\n",
      "Loss: tensor(0.1057, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4870\n",
      "Loss: tensor(0.1057, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4871\n",
      "Loss: tensor(0.1057, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4872\n",
      "Loss: tensor(0.1057, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4873\n",
      "Loss: tensor(0.1057, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4874\n",
      "Loss: tensor(0.1057, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4875\n",
      "Loss: tensor(0.1057, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4876\n",
      "Loss: tensor(0.1057, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4877\n",
      "Loss: tensor(0.1057, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4878\n",
      "Loss: tensor(0.1057, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4879\n",
      "Loss: tensor(0.1057, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4880\n",
      "Loss: tensor(0.1057, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4881\n",
      "Loss: tensor(0.1057, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4882\n",
      "Loss: tensor(0.1057, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4883\n",
      "Loss: tensor(0.1057, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4884\n",
      "Loss: tensor(0.1057, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4885\n",
      "Loss: tensor(0.1057, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4886\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor(0.1057, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4887\n",
      "Loss: tensor(0.1057, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4888\n",
      "Loss: tensor(0.1057, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4889\n",
      "Loss: tensor(0.1057, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4890\n",
      "Loss: tensor(0.1057, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4891\n",
      "Loss: tensor(0.1057, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4892\n",
      "Loss: tensor(0.1057, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4893\n",
      "Loss: tensor(0.1057, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4894\n",
      "Loss: tensor(0.1057, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4895\n",
      "Loss: tensor(0.1057, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4896\n",
      "Loss: tensor(0.1057, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4897\n",
      "Loss: tensor(0.1057, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4898\n",
      "Loss: tensor(0.1057, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4899\n",
      "Loss: tensor(0.1057, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4900\n",
      "Loss: tensor(0.1057, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4901\n",
      "Loss: tensor(0.1057, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4902\n",
      "Loss: tensor(0.1057, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4903\n",
      "Loss: tensor(0.1056, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4904\n",
      "Loss: tensor(0.1056, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4905\n",
      "Loss: tensor(0.1056, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4906\n",
      "Loss: tensor(0.1056, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4907\n",
      "Loss: tensor(0.1056, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4908\n",
      "Loss: tensor(0.1056, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4909\n",
      "Loss: tensor(0.1056, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4910\n",
      "Loss: tensor(0.1056, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4911\n",
      "Loss: tensor(0.1056, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4912\n",
      "Loss: tensor(0.1056, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4913\n",
      "Loss: tensor(0.1056, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4914\n",
      "Loss: tensor(0.1056, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4915\n",
      "Loss: tensor(0.1056, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4916\n",
      "Loss: tensor(0.1056, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4917\n",
      "Loss: tensor(0.1056, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4918\n",
      "Loss: tensor(0.1056, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4919\n",
      "Loss: tensor(0.1056, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4920\n",
      "Loss: tensor(0.1056, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4921\n",
      "Loss: tensor(0.1056, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4922\n",
      "Loss: tensor(0.1056, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4923\n",
      "Loss: tensor(0.1056, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4924\n",
      "Loss: tensor(0.1056, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4925\n",
      "Loss: tensor(0.1056, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4926\n",
      "Loss: tensor(0.1055, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4927\n",
      "Loss: tensor(0.1055, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4928\n",
      "Loss: tensor(0.1055, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4929\n",
      "Loss: tensor(0.1055, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4930\n",
      "Loss: tensor(0.1055, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4931\n",
      "Loss: tensor(0.1055, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4932\n",
      "Loss: tensor(0.1055, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4933\n",
      "Loss: tensor(0.1055, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4934\n",
      "Loss: tensor(0.1055, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4935\n",
      "Loss: tensor(0.1055, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4936\n",
      "Loss: tensor(0.1055, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4937\n",
      "Loss: tensor(0.1055, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4938\n",
      "Loss: tensor(0.1055, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4939\n",
      "Loss: tensor(0.1055, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4940\n",
      "Loss: tensor(0.1055, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4941\n",
      "Loss: tensor(0.1055, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4942\n",
      "Loss: tensor(0.1055, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4943\n",
      "Loss: tensor(0.1055, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4944\n",
      "Loss: tensor(0.1055, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4945\n",
      "Loss: tensor(0.1055, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4946\n",
      "Loss: tensor(0.1055, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4947\n",
      "Loss: tensor(0.1055, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4948\n",
      "Loss: tensor(0.1055, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4949\n",
      "Loss: tensor(0.1055, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4950\n",
      "Loss: tensor(0.1055, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4951\n",
      "Loss: tensor(0.1055, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4952\n",
      "Loss: tensor(0.1055, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4953\n",
      "Loss: tensor(0.1055, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4954\n",
      "Loss: tensor(0.1055, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4955\n",
      "Loss: tensor(0.1054, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4956\n",
      "Loss: tensor(0.1054, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4957\n",
      "Loss: tensor(0.1054, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4958\n",
      "Loss: tensor(0.1054, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4959\n",
      "Loss: tensor(0.1054, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4960\n",
      "Loss: tensor(0.1054, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4961\n",
      "Loss: tensor(0.1054, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4962\n",
      "Loss: tensor(0.1054, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4963\n",
      "Loss: tensor(0.1054, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4964\n",
      "Loss: tensor(0.1054, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4965\n",
      "Loss: tensor(0.1054, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4966\n",
      "Loss: tensor(0.1054, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4967\n",
      "Loss: tensor(0.1054, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4968\n",
      "Loss: tensor(0.1054, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4969\n",
      "Loss: tensor(0.1054, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4970\n",
      "Loss: tensor(0.1054, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4971\n",
      "Loss: tensor(0.1054, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4972\n",
      "Loss: tensor(0.1054, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4973\n",
      "Loss: tensor(0.1054, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4974\n",
      "Loss: tensor(0.1054, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4975\n",
      "Loss: tensor(0.1054, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4976\n",
      "Loss: tensor(0.1054, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4977\n",
      "Loss: tensor(0.1054, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4978\n",
      "Loss: tensor(0.1054, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4979\n",
      "Loss: tensor(0.1054, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4980\n",
      "Loss: tensor(0.1054, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4981\n",
      "Loss: tensor(0.1054, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4982\n",
      "Loss: tensor(0.1054, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4983\n",
      "Loss: tensor(0.1054, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4984\n",
      "Loss: tensor(0.1054, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4985\n",
      "Loss: tensor(0.1054, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4986\n",
      "Loss: tensor(0.1053, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4987\n",
      "Loss: tensor(0.1053, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4988\n",
      "Loss: tensor(0.1053, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4989\n",
      "Loss: tensor(0.1053, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4990\n",
      "Loss: tensor(0.1053, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4991\n",
      "Loss: tensor(0.1053, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4992\n",
      "Loss: tensor(0.1053, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4993\n",
      "Loss: tensor(0.1053, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4994\n",
      "Loss: tensor(0.1053, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4995\n",
      "Loss: tensor(0.1053, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4996\n",
      "Loss: tensor(0.1053, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4997\n",
      "Loss: tensor(0.1053, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4998\n",
      "Loss: tensor(0.1053, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4999\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor(0.1053, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5000\n",
      "Loss: tensor(0.1053, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5001\n",
      "Loss: tensor(0.1053, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5002\n",
      "Loss: tensor(0.1053, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5003\n",
      "Loss: tensor(0.1053, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5004\n",
      "Loss: tensor(0.1053, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5005\n",
      "Loss: tensor(0.1053, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5006\n",
      "Loss: tensor(0.1053, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5007\n",
      "Loss: tensor(0.1053, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5008\n",
      "Loss: tensor(0.1053, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5009\n",
      "Loss: tensor(0.1053, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5010\n",
      "Loss: tensor(0.1053, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5011\n",
      "Loss: tensor(0.1053, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5012\n",
      "Loss: tensor(0.1053, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5013\n",
      "Loss: tensor(0.1053, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5014\n",
      "Loss: tensor(0.1053, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5015\n",
      "Loss: tensor(0.1053, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5016\n",
      "Loss: tensor(0.1053, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5017\n",
      "Loss: tensor(0.1052, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5018\n",
      "Loss: tensor(0.1052, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5019\n",
      "Loss: tensor(0.1052, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5020\n",
      "Loss: tensor(0.1052, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5021\n",
      "Loss: tensor(0.1052, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5022\n",
      "Loss: tensor(0.1052, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5023\n",
      "Loss: tensor(0.1052, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5024\n",
      "Loss: tensor(0.1052, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5025\n",
      "Loss: tensor(0.1052, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5026\n",
      "Loss: tensor(0.1052, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5027\n",
      "Loss: tensor(0.1052, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5028\n",
      "Loss: tensor(0.1052, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5029\n",
      "Loss: tensor(0.1052, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5030\n",
      "Loss: tensor(0.1052, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5031\n",
      "Loss: tensor(0.1052, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5032\n",
      "Loss: tensor(0.1052, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5033\n",
      "Loss: tensor(0.1052, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5034\n",
      "Loss: tensor(0.1052, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5035\n",
      "Loss: tensor(0.1052, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5036\n",
      "Loss: tensor(0.1052, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5037\n",
      "Loss: tensor(0.1052, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5038\n",
      "Loss: tensor(0.1052, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5039\n",
      "Loss: tensor(0.1052, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5040\n",
      "Loss: tensor(0.1052, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5041\n",
      "Loss: tensor(0.1052, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5042\n",
      "Loss: tensor(0.1052, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5043\n",
      "Loss: tensor(0.1052, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5044\n",
      "Loss: tensor(0.1052, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5045\n",
      "Loss: tensor(0.1052, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5046\n",
      "Loss: tensor(0.1052, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5047\n",
      "Loss: tensor(0.1052, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5048\n",
      "Loss: tensor(0.1052, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5049\n",
      "Loss: tensor(0.1052, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5050\n",
      "Loss: tensor(0.1052, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5051\n",
      "Loss: tensor(0.1052, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5052\n",
      "Loss: tensor(0.1052, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5053\n",
      "Loss: tensor(0.1051, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5054\n",
      "Loss: tensor(0.1051, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5055\n",
      "Loss: tensor(0.1051, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5056\n",
      "Loss: tensor(0.1051, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5057\n",
      "Loss: tensor(0.1051, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5058\n",
      "Loss: tensor(0.1051, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5059\n",
      "Loss: tensor(0.1051, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5060\n",
      "Loss: tensor(0.1051, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5061\n",
      "Loss: tensor(0.1051, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5062\n",
      "Loss: tensor(0.1051, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5063\n",
      "Loss: tensor(0.1051, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5064\n",
      "Loss: tensor(0.1051, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5065\n",
      "Loss: tensor(0.1051, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5066\n",
      "Loss: tensor(0.1051, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5067\n",
      "Loss: tensor(0.1051, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5068\n",
      "Loss: tensor(0.1051, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5069\n",
      "Loss: tensor(0.1051, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5070\n",
      "Loss: tensor(0.1051, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5071\n",
      "Loss: tensor(0.1051, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5072\n",
      "Loss: tensor(0.1051, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5073\n",
      "Loss: tensor(0.1051, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5074\n",
      "Loss: tensor(0.1051, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5075\n",
      "Loss: tensor(0.1051, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5076\n",
      "Loss: tensor(0.1051, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5077\n",
      "Loss: tensor(0.1051, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5078\n",
      "Loss: tensor(0.1051, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5079\n",
      "Loss: tensor(0.1051, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5080\n",
      "Loss: tensor(0.1051, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5081\n",
      "Loss: tensor(0.1051, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5082\n",
      "Loss: tensor(0.1050, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5083\n",
      "Loss: tensor(0.1050, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5084\n",
      "Loss: tensor(0.1050, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5085\n",
      "Loss: tensor(0.1050, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5086\n",
      "Loss: tensor(0.1050, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5087\n",
      "Loss: tensor(0.1050, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5088\n",
      "Loss: tensor(0.1050, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5089\n",
      "Loss: tensor(0.1050, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5090\n",
      "Loss: tensor(0.1050, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5091\n",
      "Loss: tensor(0.1050, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5092\n",
      "Loss: tensor(0.1050, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5093\n",
      "Loss: tensor(0.1050, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5094\n",
      "Loss: tensor(0.1050, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5095\n",
      "Loss: tensor(0.1050, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5096\n",
      "Loss: tensor(0.1050, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5097\n",
      "Loss: tensor(0.1050, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5098\n",
      "Loss: tensor(0.1050, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5099\n",
      "Loss: tensor(0.1050, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5100\n",
      "Loss: tensor(0.1050, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5101\n",
      "Loss: tensor(0.1050, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5102\n",
      "Loss: tensor(0.1050, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5103\n",
      "Loss: tensor(0.1050, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5104\n",
      "Loss: tensor(0.1050, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5105\n",
      "Loss: tensor(0.1050, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5106\n",
      "Loss: tensor(0.1050, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5107\n",
      "Loss: tensor(0.1050, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5108\n",
      "Loss: tensor(0.1050, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5109\n",
      "Loss: tensor(0.1050, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5110\n",
      "Loss: tensor(0.1050, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5111\n",
      "Loss: tensor(0.1050, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5112\n",
      "Loss: tensor(0.1050, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5113\n",
      "Loss: tensor(0.1050, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5114\n",
      "Loss: tensor(0.1050, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5115\n",
      "Loss: tensor(0.1049, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5116\n",
      "Loss: tensor(0.1049, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5117\n",
      "Loss: tensor(0.1049, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5118\n",
      "Loss: tensor(0.1049, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5119\n",
      "Loss: tensor(0.1049, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor(0.1049, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5121\n",
      "Loss: tensor(0.1049, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5122\n",
      "Loss: tensor(0.1049, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5123\n",
      "Loss: tensor(0.1049, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5124\n",
      "Loss: tensor(0.1049, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5125\n",
      "Loss: tensor(0.1049, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5126\n",
      "Loss: tensor(0.1049, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5127\n",
      "Loss: tensor(0.1049, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5128\n",
      "Loss: tensor(0.1049, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5129\n",
      "Loss: tensor(0.1049, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5130\n",
      "Loss: tensor(0.1049, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5131\n",
      "Loss: tensor(0.1049, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5132\n",
      "Loss: tensor(0.1049, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5133\n",
      "Loss: tensor(0.1049, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5134\n",
      "Loss: tensor(0.1049, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5135\n",
      "Loss: tensor(0.1049, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5136\n",
      "Loss: tensor(0.1049, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5137\n",
      "Loss: tensor(0.1049, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5138\n",
      "Loss: tensor(0.1049, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5139\n",
      "Loss: tensor(0.1049, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5140\n",
      "Loss: tensor(0.1049, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5141\n",
      "Loss: tensor(0.1049, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5142\n",
      "Loss: tensor(0.1049, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5143\n",
      "Loss: tensor(0.1049, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5144\n",
      "Loss: tensor(0.1049, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5145\n",
      "Loss: tensor(0.1049, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5146\n",
      "Loss: tensor(0.1049, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5147\n",
      "Loss: tensor(0.1049, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5148\n",
      "Loss: tensor(0.1049, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5149\n",
      "Loss: tensor(0.1049, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5150\n",
      "Loss: tensor(0.1048, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5151\n",
      "Loss: tensor(0.1048, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5152\n",
      "Loss: tensor(0.1048, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5153\n",
      "Loss: tensor(0.1048, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5154\n",
      "Loss: tensor(0.1048, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5155\n",
      "Loss: tensor(0.1048, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5156\n",
      "Loss: tensor(0.1048, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5157\n",
      "Loss: tensor(0.1048, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5158\n",
      "Loss: tensor(0.1048, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5159\n",
      "Loss: tensor(0.1048, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5160\n",
      "Loss: tensor(0.1048, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5161\n",
      "Loss: tensor(0.1048, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5162\n",
      "Loss: tensor(0.1048, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5163\n",
      "Loss: tensor(0.1048, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5164\n",
      "Loss: tensor(0.1048, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5165\n",
      "Loss: tensor(0.1048, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5166\n",
      "Loss: tensor(0.1048, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5167\n",
      "Loss: tensor(0.1048, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5168\n",
      "Loss: tensor(0.1048, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5169\n",
      "Loss: tensor(0.1048, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5170\n",
      "Loss: tensor(0.1048, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5171\n",
      "Loss: tensor(0.1048, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5172\n",
      "Loss: tensor(0.1048, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5173\n",
      "Loss: tensor(0.1048, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5174\n",
      "Loss: tensor(0.1048, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5175\n",
      "Loss: tensor(0.1048, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5176\n",
      "Loss: tensor(0.1048, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5177\n",
      "Loss: tensor(0.1048, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5178\n",
      "Loss: tensor(0.1048, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5179\n",
      "Loss: tensor(0.1048, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5180\n",
      "Loss: tensor(0.1048, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5181\n",
      "Loss: tensor(0.1048, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5182\n",
      "Loss: tensor(0.1048, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5183\n",
      "Loss: tensor(0.1048, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5184\n",
      "Loss: tensor(0.1048, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5185\n",
      "Loss: tensor(0.1048, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5186\n",
      "Loss: tensor(0.1047, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5187\n",
      "Loss: tensor(0.1047, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5188\n",
      "Loss: tensor(0.1047, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5189\n",
      "Loss: tensor(0.1047, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5190\n",
      "Loss: tensor(0.1047, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5191\n",
      "Loss: tensor(0.1047, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5192\n",
      "Loss: tensor(0.1047, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5193\n",
      "Loss: tensor(0.1047, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5194\n",
      "Loss: tensor(0.1047, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5195\n",
      "Loss: tensor(0.1047, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5196\n",
      "Loss: tensor(0.1047, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5197\n",
      "Loss: tensor(0.1047, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5198\n",
      "Loss: tensor(0.1047, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5199\n",
      "Loss: tensor(0.1047, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5200\n",
      "Loss: tensor(0.1047, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5201\n",
      "Loss: tensor(0.1047, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5202\n",
      "Loss: tensor(0.1047, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5203\n",
      "Loss: tensor(0.1047, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5204\n",
      "Loss: tensor(0.1047, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5205\n",
      "Loss: tensor(0.1047, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5206\n",
      "Loss: tensor(0.1047, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5207\n",
      "Loss: tensor(0.1047, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5208\n",
      "Loss: tensor(0.1047, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5209\n",
      "Loss: tensor(0.1047, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5210\n",
      "Loss: tensor(0.1047, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5211\n",
      "Loss: tensor(0.1047, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5212\n",
      "Loss: tensor(0.1047, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5213\n",
      "Loss: tensor(0.1047, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5214\n",
      "Loss: tensor(0.1047, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5215\n",
      "Loss: tensor(0.1047, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5216\n",
      "Loss: tensor(0.1047, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5217\n",
      "Loss: tensor(0.1047, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5218\n",
      "Loss: tensor(0.1047, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5219\n",
      "Loss: tensor(0.1047, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5220\n",
      "Loss: tensor(0.1047, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5221\n",
      "Loss: tensor(0.1047, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5222\n",
      "Loss: tensor(0.1047, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5223\n",
      "Loss: tensor(0.1046, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5224\n",
      "Loss: tensor(0.1046, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5225\n",
      "Loss: tensor(0.1046, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5226\n",
      "Loss: tensor(0.1046, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5227\n",
      "Loss: tensor(0.1046, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5228\n",
      "Loss: tensor(0.1046, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5229\n",
      "Loss: tensor(0.1046, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5230\n",
      "Loss: tensor(0.1046, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5231\n",
      "Loss: tensor(0.1046, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5232\n",
      "Loss: tensor(0.1046, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5233\n",
      "Loss: tensor(0.1046, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5234\n",
      "Loss: tensor(0.1046, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5235\n",
      "Loss: tensor(0.1046, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5236\n",
      "Loss: tensor(0.1046, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5237\n",
      "Loss: tensor(0.1046, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5238\n",
      "Loss: tensor(0.1046, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5239\n",
      "Loss: tensor(0.1046, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5240\n",
      "Loss: tensor(0.1046, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5241\n",
      "Loss: tensor(0.1046, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5242\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor(0.1046, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5243\n",
      "Loss: tensor(0.1046, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5244\n",
      "Loss: tensor(0.1046, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5245\n",
      "Loss: tensor(0.1046, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5246\n",
      "Loss: tensor(0.1046, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5247\n",
      "Loss: tensor(0.1046, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5248\n",
      "Loss: tensor(0.1046, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5249\n",
      "Loss: tensor(0.1046, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5250\n",
      "Loss: tensor(0.1046, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5251\n",
      "Loss: tensor(0.1046, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5252\n",
      "Loss: tensor(0.1046, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5253\n",
      "Loss: tensor(0.1046, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5254\n",
      "Loss: tensor(0.1046, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5255\n",
      "Loss: tensor(0.1046, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5256\n",
      "Loss: tensor(0.1046, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5257\n",
      "Loss: tensor(0.1046, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5258\n",
      "Loss: tensor(0.1046, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5259\n",
      "Loss: tensor(0.1046, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5260\n",
      "Loss: tensor(0.1046, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5261\n",
      "Loss: tensor(0.1045, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5262\n",
      "Loss: tensor(0.1045, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5263\n",
      "Loss: tensor(0.1045, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5264\n",
      "Loss: tensor(0.1045, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5265\n",
      "Loss: tensor(0.1045, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5266\n",
      "Loss: tensor(0.1045, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5267\n",
      "Loss: tensor(0.1045, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5268\n",
      "Loss: tensor(0.1045, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5269\n",
      "Loss: tensor(0.1045, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5270\n",
      "Loss: tensor(0.1045, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5271\n",
      "Loss: tensor(0.1045, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5272\n",
      "Loss: tensor(0.1045, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5273\n",
      "Loss: tensor(0.1045, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5274\n",
      "Loss: tensor(0.1045, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5275\n",
      "Loss: tensor(0.1045, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5276\n",
      "Loss: tensor(0.1045, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5277\n",
      "Loss: tensor(0.1045, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5278\n",
      "Loss: tensor(0.1045, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5279\n",
      "Loss: tensor(0.1045, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5280\n",
      "Loss: tensor(0.1045, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5281\n",
      "Loss: tensor(0.1045, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5282\n",
      "Loss: tensor(0.1045, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5283\n",
      "Loss: tensor(0.1045, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5284\n",
      "Loss: tensor(0.1045, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5285\n",
      "Loss: tensor(0.1045, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5286\n",
      "Loss: tensor(0.1045, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5287\n",
      "Loss: tensor(0.1045, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5288\n",
      "Loss: tensor(0.1045, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5289\n",
      "Loss: tensor(0.1045, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5290\n",
      "Loss: tensor(0.1045, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5291\n",
      "Loss: tensor(0.1045, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5292\n",
      "Loss: tensor(0.1045, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5293\n",
      "Loss: tensor(0.1045, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5294\n",
      "Loss: tensor(0.1045, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5295\n",
      "Loss: tensor(0.1045, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5296\n",
      "Loss: tensor(0.1045, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5297\n",
      "Loss: tensor(0.1045, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5298\n",
      "Loss: tensor(0.1045, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5299\n",
      "Loss: tensor(0.1044, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5300\n",
      "Loss: tensor(0.1044, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5301\n",
      "Loss: tensor(0.1044, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5302\n",
      "Loss: tensor(0.1044, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5303\n",
      "Loss: tensor(0.1044, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5304\n",
      "Loss: tensor(0.1044, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5305\n",
      "Loss: tensor(0.1044, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5306\n",
      "Loss: tensor(0.1044, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5307\n",
      "Loss: tensor(0.1044, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5308\n",
      "Loss: tensor(0.1044, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5309\n",
      "Loss: tensor(0.1044, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5310\n",
      "Loss: tensor(0.1044, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5311\n",
      "Loss: tensor(0.1044, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5312\n",
      "Loss: tensor(0.1044, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5313\n",
      "Loss: tensor(0.1044, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5314\n",
      "Loss: tensor(0.1044, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5315\n",
      "Loss: tensor(0.1044, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5316\n",
      "Loss: tensor(0.1044, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5317\n",
      "Loss: tensor(0.1044, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5318\n",
      "Loss: tensor(0.1044, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5319\n",
      "Loss: tensor(0.1044, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5320\n",
      "Loss: tensor(0.1044, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5321\n",
      "Loss: tensor(0.1044, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5322\n",
      "Loss: tensor(0.1044, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5323\n",
      "Loss: tensor(0.1044, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5324\n",
      "Loss: tensor(0.1044, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5325\n",
      "Loss: tensor(0.1044, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5326\n",
      "Loss: tensor(0.1044, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5327\n",
      "Loss: tensor(0.1044, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5328\n",
      "Loss: tensor(0.1044, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5329\n",
      "Loss: tensor(0.1044, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5330\n",
      "Loss: tensor(0.1044, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5331\n",
      "Loss: tensor(0.1044, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5332\n",
      "Loss: tensor(0.1044, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5333\n",
      "Loss: tensor(0.1044, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5334\n",
      "Loss: tensor(0.1044, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5335\n",
      "Loss: tensor(0.1044, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5336\n",
      "Loss: tensor(0.1044, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5337\n",
      "Loss: tensor(0.1044, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5338\n",
      "Loss: tensor(0.1044, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5339\n",
      "Loss: tensor(0.1044, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5340\n",
      "Loss: tensor(0.1044, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5341\n",
      "Loss: tensor(0.1043, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5342\n",
      "Loss: tensor(0.1043, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5343\n",
      "Loss: tensor(0.1044, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5344\n",
      "Loss: tensor(0.1044, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5345\n",
      "Loss: tensor(0.1043, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5346\n",
      "Loss: tensor(0.1043, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5347\n",
      "Loss: tensor(0.1043, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5348\n",
      "Loss: tensor(0.1043, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5349\n",
      "Loss: tensor(0.1043, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5350\n",
      "Loss: tensor(0.1043, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5351\n",
      "Loss: tensor(0.1043, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5352\n",
      "Loss: tensor(0.1043, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5353\n",
      "Loss: tensor(0.1043, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5354\n",
      "Loss: tensor(0.1043, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5355\n",
      "Loss: tensor(0.1043, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5356\n",
      "Loss: tensor(0.1043, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5357\n",
      "Loss: tensor(0.1043, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5358\n",
      "Loss: tensor(0.1043, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5359\n",
      "Loss: tensor(0.1043, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5360\n",
      "Loss: tensor(0.1043, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5361\n",
      "Loss: tensor(0.1043, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5362\n",
      "Loss: tensor(0.1043, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5363\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor(0.1043, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5364\n",
      "Loss: tensor(0.1043, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5365\n",
      "Loss: tensor(0.1043, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5366\n",
      "Loss: tensor(0.1043, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5367\n",
      "Loss: tensor(0.1043, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5368\n",
      "Loss: tensor(0.1043, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5369\n",
      "Loss: tensor(0.1043, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5370\n",
      "Loss: tensor(0.1043, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5371\n",
      "Loss: tensor(0.1043, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5372\n",
      "Loss: tensor(0.1043, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5373\n",
      "Loss: tensor(0.1043, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5374\n",
      "Loss: tensor(0.1043, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5375\n",
      "Loss: tensor(0.1043, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5376\n",
      "Loss: tensor(0.1043, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5377\n",
      "Loss: tensor(0.1043, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5378\n",
      "Loss: tensor(0.1043, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5379\n",
      "Loss: tensor(0.1043, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5380\n",
      "Loss: tensor(0.1042, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5381\n",
      "Loss: tensor(0.1042, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5382\n",
      "Loss: tensor(0.1042, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5383\n",
      "Loss: tensor(0.1042, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5384\n",
      "Loss: tensor(0.1042, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5385\n",
      "Loss: tensor(0.1042, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5386\n",
      "Loss: tensor(0.1042, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5387\n",
      "Loss: tensor(0.1042, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5388\n",
      "Loss: tensor(0.1042, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5389\n",
      "Loss: tensor(0.1042, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5390\n",
      "Loss: tensor(0.1042, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5391\n",
      "Loss: tensor(0.1042, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5392\n",
      "Loss: tensor(0.1042, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5393\n",
      "Loss: tensor(0.1042, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5394\n",
      "Loss: tensor(0.1042, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5395\n",
      "Loss: tensor(0.1042, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5396\n",
      "Loss: tensor(0.1042, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5397\n",
      "Loss: tensor(0.1042, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5398\n",
      "Loss: tensor(0.1042, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5399\n",
      "Loss: tensor(0.1042, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5400\n",
      "Loss: tensor(0.1042, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5401\n",
      "Loss: tensor(0.1042, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5402\n",
      "Loss: tensor(0.1042, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5403\n",
      "Loss: tensor(0.1042, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5404\n",
      "Loss: tensor(0.1042, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5405\n",
      "Loss: tensor(0.1042, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5406\n",
      "Loss: tensor(0.1042, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5407\n",
      "Loss: tensor(0.1042, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5408\n",
      "Loss: tensor(0.1042, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5409\n",
      "Loss: tensor(0.1042, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5410\n",
      "Loss: tensor(0.1042, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5411\n",
      "Loss: tensor(0.1042, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5412\n",
      "Loss: tensor(0.1042, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5413\n",
      "Loss: tensor(0.1042, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5414\n",
      "Loss: tensor(0.1042, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5415\n",
      "Loss: tensor(0.1042, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5416\n",
      "Loss: tensor(0.1042, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5417\n",
      "Loss: tensor(0.1042, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5418\n",
      "Loss: tensor(0.1042, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5419\n",
      "Loss: tensor(0.1042, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5420\n",
      "Loss: tensor(0.1042, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5421\n",
      "Loss: tensor(0.1042, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5422\n",
      "Loss: tensor(0.1042, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5423\n",
      "Loss: tensor(0.1042, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5424\n",
      "Loss: tensor(0.1041, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5425\n",
      "Loss: tensor(0.1041, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5426\n",
      "Loss: tensor(0.1041, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5427\n",
      "Loss: tensor(0.1041, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5428\n",
      "Loss: tensor(0.1041, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5429\n",
      "Loss: tensor(0.1041, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5430\n",
      "Loss: tensor(0.1041, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5431\n",
      "Loss: tensor(0.1041, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5432\n",
      "Loss: tensor(0.1041, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5433\n",
      "Loss: tensor(0.1041, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5434\n",
      "Loss: tensor(0.1041, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5435\n",
      "Loss: tensor(0.1041, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5436\n",
      "Loss: tensor(0.1041, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5437\n",
      "Loss: tensor(0.1041, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5438\n",
      "Loss: tensor(0.1041, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5439\n",
      "Loss: tensor(0.1041, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5440\n",
      "Loss: tensor(0.1041, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5441\n",
      "Loss: tensor(0.1041, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5442\n",
      "Loss: tensor(0.1041, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5443\n",
      "Loss: tensor(0.1041, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5444\n",
      "Loss: tensor(0.1041, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5445\n",
      "Loss: tensor(0.1041, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5446\n",
      "Loss: tensor(0.1041, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5447\n",
      "Loss: tensor(0.1041, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5448\n",
      "Loss: tensor(0.1041, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5449\n",
      "Loss: tensor(0.1041, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5450\n",
      "Loss: tensor(0.1041, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5451\n",
      "Loss: tensor(0.1041, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5452\n",
      "Loss: tensor(0.1041, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5453\n",
      "Loss: tensor(0.1041, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5454\n",
      "Loss: tensor(0.1041, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5455\n",
      "Loss: tensor(0.1041, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5456\n",
      "Loss: tensor(0.1041, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5457\n",
      "Loss: tensor(0.1041, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5458\n",
      "Loss: tensor(0.1041, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5459\n",
      "Loss: tensor(0.1041, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5460\n",
      "Loss: tensor(0.1041, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5461\n",
      "Loss: tensor(0.1041, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5462\n",
      "Loss: tensor(0.1041, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5463\n",
      "Loss: tensor(0.1041, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5464\n",
      "Loss: tensor(0.1041, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5465\n",
      "Loss: tensor(0.1041, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5466\n",
      "Loss: tensor(0.1040, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5467\n",
      "Loss: tensor(0.1040, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5468\n",
      "Loss: tensor(0.1040, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5469\n",
      "Loss: tensor(0.1040, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5470\n",
      "Loss: tensor(0.1040, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5471\n",
      "Loss: tensor(0.1040, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5472\n",
      "Loss: tensor(0.1040, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5473\n",
      "Loss: tensor(0.1040, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5474\n",
      "Loss: tensor(0.1040, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5475\n",
      "Loss: tensor(0.1040, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5476\n",
      "Loss: tensor(0.1040, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5477\n",
      "Loss: tensor(0.1040, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5478\n",
      "Loss: tensor(0.1040, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5479\n",
      "Loss: tensor(0.1040, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5480\n",
      "Loss: tensor(0.1040, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5481\n",
      "Loss: tensor(0.1040, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5482\n",
      "Loss: tensor(0.1040, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5483\n",
      "Loss: tensor(0.1040, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5484\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor(0.1040, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5485\n",
      "Loss: tensor(0.1040, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5486\n",
      "Loss: tensor(0.1040, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5487\n",
      "Loss: tensor(0.1040, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5488\n",
      "Loss: tensor(0.1040, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5489\n",
      "Loss: tensor(0.1040, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5490\n",
      "Loss: tensor(0.1040, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5491\n",
      "Loss: tensor(0.1040, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5492\n",
      "Loss: tensor(0.1040, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5493\n",
      "Loss: tensor(0.1040, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5494\n",
      "Loss: tensor(0.1040, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5495\n",
      "Loss: tensor(0.1040, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5496\n",
      "Loss: tensor(0.1040, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5497\n",
      "Loss: tensor(0.1040, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5498\n",
      "Loss: tensor(0.1040, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5499\n",
      "Loss: tensor(0.1040, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5500\n",
      "Loss: tensor(0.1040, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5501\n",
      "Loss: tensor(0.1040, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5502\n",
      "Loss: tensor(0.1040, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5503\n",
      "Loss: tensor(0.1040, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5504\n",
      "Loss: tensor(0.1040, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5505\n",
      "Loss: tensor(0.1040, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5506\n",
      "Loss: tensor(0.1040, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5507\n",
      "Loss: tensor(0.1040, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5508\n",
      "Loss: tensor(0.1040, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5509\n",
      "Loss: tensor(0.1040, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5510\n",
      "Loss: tensor(0.1040, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5511\n",
      "Loss: tensor(0.1039, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5512\n",
      "Loss: tensor(0.1039, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5513\n",
      "Loss: tensor(0.1039, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5514\n",
      "Loss: tensor(0.1039, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5515\n",
      "Loss: tensor(0.1039, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5516\n",
      "Loss: tensor(0.1039, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5517\n",
      "Loss: tensor(0.1039, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5518\n",
      "Loss: tensor(0.1039, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5519\n",
      "Loss: tensor(0.1039, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5520\n",
      "Loss: tensor(0.1039, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5521\n",
      "Loss: tensor(0.1039, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5522\n",
      "Loss: tensor(0.1039, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5523\n",
      "Loss: tensor(0.1039, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5524\n",
      "Loss: tensor(0.1039, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5525\n",
      "Loss: tensor(0.1039, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5526\n",
      "Loss: tensor(0.1039, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5527\n",
      "Loss: tensor(0.1039, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5528\n",
      "Loss: tensor(0.1039, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5529\n",
      "Loss: tensor(0.1039, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5530\n",
      "Loss: tensor(0.1039, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5531\n",
      "Loss: tensor(0.1039, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5532\n",
      "Loss: tensor(0.1039, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5533\n",
      "Loss: tensor(0.1039, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5534\n",
      "Loss: tensor(0.1039, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5535\n",
      "Loss: tensor(0.1039, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5536\n",
      "Loss: tensor(0.1039, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5537\n",
      "Loss: tensor(0.1039, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5538\n",
      "Loss: tensor(0.1039, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5539\n",
      "Loss: tensor(0.1039, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5540\n",
      "Loss: tensor(0.1039, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5541\n",
      "Loss: tensor(0.1039, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5542\n",
      "Loss: tensor(0.1039, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5543\n",
      "Loss: tensor(0.1039, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5544\n",
      "Loss: tensor(0.1039, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5545\n",
      "Loss: tensor(0.1039, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5546\n",
      "Loss: tensor(0.1039, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5547\n",
      "Loss: tensor(0.1039, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5548\n",
      "Loss: tensor(0.1039, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5549\n",
      "Loss: tensor(0.1039, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5550\n",
      "Loss: tensor(0.1039, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5551\n",
      "Loss: tensor(0.1039, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5552\n",
      "Loss: tensor(0.1039, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5553\n",
      "Loss: tensor(0.1039, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5554\n",
      "Loss: tensor(0.1039, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5555\n",
      "Loss: tensor(0.1039, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5556\n",
      "Loss: tensor(0.1039, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5557\n",
      "Loss: tensor(0.1039, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5558\n",
      "Loss: tensor(0.1038, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5559\n",
      "Loss: tensor(0.1038, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5560\n",
      "Loss: tensor(0.1038, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5561\n",
      "Loss: tensor(0.1038, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5562\n",
      "Loss: tensor(0.1038, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5563\n",
      "Loss: tensor(0.1038, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5564\n",
      "Loss: tensor(0.1038, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5565\n",
      "Loss: tensor(0.1038, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5566\n",
      "Loss: tensor(0.1038, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5567\n",
      "Loss: tensor(0.1038, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5568\n",
      "Loss: tensor(0.1038, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5569\n",
      "Loss: tensor(0.1038, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5570\n",
      "Loss: tensor(0.1038, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5571\n",
      "Loss: tensor(0.1038, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5572\n",
      "Loss: tensor(0.1038, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5573\n",
      "Loss: tensor(0.1038, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5574\n",
      "Loss: tensor(0.1038, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5575\n",
      "Loss: tensor(0.1038, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5576\n",
      "Loss: tensor(0.1038, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5577\n",
      "Loss: tensor(0.1038, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5578\n",
      "Loss: tensor(0.1038, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5579\n",
      "Loss: tensor(0.1038, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5580\n",
      "Loss: tensor(0.1038, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5581\n",
      "Loss: tensor(0.1038, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5582\n",
      "Loss: tensor(0.1038, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5583\n",
      "Loss: tensor(0.1038, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5584\n",
      "Loss: tensor(0.1038, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5585\n",
      "Loss: tensor(0.1038, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5586\n",
      "Loss: tensor(0.1038, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5587\n",
      "Loss: tensor(0.1038, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5588\n",
      "Loss: tensor(0.1038, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5589\n",
      "Loss: tensor(0.1038, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5590\n",
      "Loss: tensor(0.1038, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5591\n",
      "Loss: tensor(0.1038, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5592\n",
      "Loss: tensor(0.1038, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5593\n",
      "Loss: tensor(0.1038, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5594\n",
      "Loss: tensor(0.1038, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5595\n",
      "Loss: tensor(0.1038, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5596\n",
      "Loss: tensor(0.1038, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5597\n",
      "Loss: tensor(0.1038, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5598\n",
      "Loss: tensor(0.1038, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5599\n",
      "Loss: tensor(0.1038, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5600\n",
      "Loss: tensor(0.1038, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5601\n",
      "Loss: tensor(0.1038, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5602\n",
      "Loss: tensor(0.1038, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5603\n",
      "Loss: tensor(0.1037, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5604\n",
      "Loss: tensor(0.1037, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5605\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor(0.1037, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5606\n",
      "Loss: tensor(0.1037, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5607\n",
      "Loss: tensor(0.1037, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5608\n",
      "Loss: tensor(0.1037, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5609\n",
      "Loss: tensor(0.1037, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5610\n",
      "Loss: tensor(0.1037, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5611\n",
      "Loss: tensor(0.1037, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5612\n",
      "Loss: tensor(0.1037, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5613\n",
      "Loss: tensor(0.1037, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5614\n",
      "Loss: tensor(0.1037, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5615\n",
      "Loss: tensor(0.1037, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5616\n",
      "Loss: tensor(0.1037, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5617\n",
      "Loss: tensor(0.1037, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5618\n",
      "Loss: tensor(0.1037, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5619\n",
      "Loss: tensor(0.1037, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5620\n",
      "Loss: tensor(0.1037, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5621\n",
      "Loss: tensor(0.1037, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5622\n",
      "Loss: tensor(0.1037, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5623\n",
      "Loss: tensor(0.1037, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5624\n",
      "Loss: tensor(0.1037, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5625\n",
      "Loss: tensor(0.1037, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5626\n",
      "Loss: tensor(0.1037, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5627\n",
      "Loss: tensor(0.1037, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5628\n",
      "Loss: tensor(0.1037, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5629\n",
      "Loss: tensor(0.1037, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5630\n",
      "Loss: tensor(0.1037, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5631\n",
      "Loss: tensor(0.1037, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5632\n",
      "Loss: tensor(0.1037, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5633\n",
      "Loss: tensor(0.1037, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5634\n",
      "Loss: tensor(0.1037, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5635\n",
      "Loss: tensor(0.1037, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5636\n",
      "Loss: tensor(0.1037, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5637\n",
      "Loss: tensor(0.1037, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5638\n",
      "Loss: tensor(0.1037, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5639\n",
      "Loss: tensor(0.1037, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5640\n",
      "Loss: tensor(0.1037, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5641\n",
      "Loss: tensor(0.1037, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5642\n",
      "Loss: tensor(0.1037, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5643\n",
      "Loss: tensor(0.1037, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5644\n",
      "Loss: tensor(0.1037, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5645\n",
      "Loss: tensor(0.1037, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5646\n",
      "Loss: tensor(0.1037, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5647\n",
      "Loss: tensor(0.1037, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5648\n",
      "Loss: tensor(0.1037, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5649\n",
      "Loss: tensor(0.1037, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5650\n",
      "Loss: tensor(0.1037, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5651\n",
      "Loss: tensor(0.1037, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5652\n",
      "Loss: tensor(0.1036, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5653\n",
      "Loss: tensor(0.1036, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5654\n",
      "Loss: tensor(0.1036, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5655\n",
      "Loss: tensor(0.1036, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5656\n",
      "Loss: tensor(0.1036, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5657\n",
      "Loss: tensor(0.1036, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5658\n",
      "Loss: tensor(0.1036, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5659\n",
      "Loss: tensor(0.1036, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5660\n",
      "Loss: tensor(0.1036, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5661\n",
      "Loss: tensor(0.1036, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5662\n",
      "Loss: tensor(0.1036, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5663\n",
      "Loss: tensor(0.1036, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5664\n",
      "Loss: tensor(0.1036, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5665\n",
      "Loss: tensor(0.1036, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5666\n",
      "Loss: tensor(0.1036, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5667\n",
      "Loss: tensor(0.1036, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5668\n",
      "Loss: tensor(0.1036, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5669\n",
      "Loss: tensor(0.1036, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5670\n",
      "Loss: tensor(0.1036, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5671\n",
      "Loss: tensor(0.1036, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5672\n",
      "Loss: tensor(0.1036, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5673\n",
      "Loss: tensor(0.1036, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5674\n",
      "Loss: tensor(0.1036, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5675\n",
      "Loss: tensor(0.1036, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5676\n",
      "Loss: tensor(0.1036, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5677\n",
      "Loss: tensor(0.1036, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5678\n",
      "Loss: tensor(0.1036, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5679\n",
      "Loss: tensor(0.1036, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5680\n",
      "Loss: tensor(0.1036, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5681\n",
      "Loss: tensor(0.1036, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5682\n",
      "Loss: tensor(0.1036, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5683\n",
      "Loss: tensor(0.1036, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5684\n",
      "Loss: tensor(0.1036, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5685\n",
      "Loss: tensor(0.1036, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5686\n",
      "Loss: tensor(0.1036, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5687\n",
      "Loss: tensor(0.1036, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5688\n",
      "Loss: tensor(0.1036, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5689\n",
      "Loss: tensor(0.1036, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5690\n",
      "Loss: tensor(0.1036, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5691\n",
      "Loss: tensor(0.1036, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5692\n",
      "Loss: tensor(0.1036, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5693\n",
      "Loss: tensor(0.1036, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5694\n",
      "Loss: tensor(0.1036, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5695\n",
      "Loss: tensor(0.1036, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5696\n",
      "Loss: tensor(0.1036, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5697\n",
      "Loss: tensor(0.1036, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5698\n",
      "Loss: tensor(0.1036, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5699\n",
      "Loss: tensor(0.1036, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5700\n",
      "Loss: tensor(0.1036, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5701\n",
      "Loss: tensor(0.1035, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5702\n",
      "Loss: tensor(0.1035, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5703\n",
      "Loss: tensor(0.1035, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5704\n",
      "Loss: tensor(0.1035, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5705\n",
      "Loss: tensor(0.1035, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5706\n",
      "Loss: tensor(0.1035, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5707\n",
      "Loss: tensor(0.1035, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5708\n",
      "Loss: tensor(0.1035, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5709\n",
      "Loss: tensor(0.1035, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5710\n",
      "Loss: tensor(0.1035, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5711\n",
      "Loss: tensor(0.1035, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5712\n",
      "Loss: tensor(0.1035, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5713\n",
      "Loss: tensor(0.1035, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5714\n",
      "Loss: tensor(0.1035, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5715\n",
      "Loss: tensor(0.1035, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5716\n",
      "Loss: tensor(0.1035, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5717\n",
      "Loss: tensor(0.1035, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5718\n",
      "Loss: tensor(0.1035, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5719\n",
      "Loss: tensor(0.1035, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5720\n",
      "Loss: tensor(0.1035, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5721\n",
      "Loss: tensor(0.1035, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5722\n",
      "Loss: tensor(0.1035, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5723\n",
      "Loss: tensor(0.1035, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5724\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor(0.1035, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5725\n",
      "Loss: tensor(0.1035, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5726\n",
      "Loss: tensor(0.1035, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5727\n",
      "Loss: tensor(0.1035, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5728\n",
      "Loss: tensor(0.1035, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5729\n",
      "Loss: tensor(0.1035, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5730\n",
      "Loss: tensor(0.1035, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5731\n",
      "Loss: tensor(0.1035, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5732\n",
      "Loss: tensor(0.1035, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5733\n",
      "Loss: tensor(0.1035, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5734\n",
      "Loss: tensor(0.1035, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5735\n",
      "Loss: tensor(0.1035, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5736\n",
      "Loss: tensor(0.1035, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5737\n",
      "Loss: tensor(0.1035, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5738\n",
      "Loss: tensor(0.1035, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5739\n",
      "Loss: tensor(0.1035, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5740\n",
      "Loss: tensor(0.1035, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5741\n",
      "Loss: tensor(0.1035, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5742\n",
      "Loss: tensor(0.1035, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5743\n",
      "Loss: tensor(0.1035, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5744\n",
      "Loss: tensor(0.1035, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5745\n",
      "Loss: tensor(0.1035, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5746\n",
      "Loss: tensor(0.1035, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5747\n",
      "Loss: tensor(0.1035, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5748\n",
      "Loss: tensor(0.1035, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5749\n",
      "Loss: tensor(0.1035, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5750\n",
      "Loss: tensor(0.1034, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5751\n",
      "Loss: tensor(0.1034, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5752\n",
      "Loss: tensor(0.1034, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5753\n",
      "Loss: tensor(0.1034, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5754\n",
      "Loss: tensor(0.1034, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5755\n",
      "Loss: tensor(0.1034, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5756\n",
      "Loss: tensor(0.1034, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5757\n",
      "Loss: tensor(0.1034, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5758\n",
      "Loss: tensor(0.1034, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5759\n",
      "Loss: tensor(0.1034, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5760\n",
      "Loss: tensor(0.1034, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5761\n",
      "Loss: tensor(0.1034, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5762\n",
      "Loss: tensor(0.1034, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5763\n",
      "Loss: tensor(0.1034, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5764\n",
      "Loss: tensor(0.1034, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5765\n",
      "Loss: tensor(0.1034, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5766\n",
      "Loss: tensor(0.1034, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5767\n",
      "Loss: tensor(0.1034, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5768\n",
      "Loss: tensor(0.1034, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5769\n",
      "Loss: tensor(0.1034, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5770\n",
      "Loss: tensor(0.1034, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5771\n",
      "Loss: tensor(0.1034, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5772\n",
      "Loss: tensor(0.1034, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5773\n",
      "Loss: tensor(0.1034, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5774\n",
      "Loss: tensor(0.1034, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5775\n",
      "Loss: tensor(0.1034, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5776\n",
      "Loss: tensor(0.1034, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5777\n",
      "Loss: tensor(0.1034, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5778\n",
      "Loss: tensor(0.1034, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5779\n",
      "Loss: tensor(0.1034, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5780\n",
      "Loss: tensor(0.1034, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5781\n",
      "Loss: tensor(0.1034, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5782\n",
      "Loss: tensor(0.1034, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5783\n",
      "Loss: tensor(0.1034, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5784\n",
      "Loss: tensor(0.1034, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5785\n",
      "Loss: tensor(0.1034, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5786\n",
      "Loss: tensor(0.1034, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5787\n",
      "Loss: tensor(0.1034, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5788\n",
      "Loss: tensor(0.1034, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5789\n",
      "Loss: tensor(0.1034, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5790\n",
      "Loss: tensor(0.1034, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5791\n",
      "Loss: tensor(0.1034, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5792\n",
      "Loss: tensor(0.1034, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5793\n",
      "Loss: tensor(0.1034, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5794\n",
      "Loss: tensor(0.1034, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5795\n",
      "Loss: tensor(0.1034, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5796\n",
      "Loss: tensor(0.1034, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5797\n",
      "Loss: tensor(0.1034, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5798\n",
      "Loss: tensor(0.1034, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5799\n",
      "Loss: tensor(0.1034, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5800\n",
      "Loss: tensor(0.1034, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5801\n",
      "Loss: tensor(0.1033, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5802\n",
      "Loss: tensor(0.1033, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5803\n",
      "Loss: tensor(0.1033, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5804\n",
      "Loss: tensor(0.1033, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5805\n",
      "Loss: tensor(0.1033, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5806\n",
      "Loss: tensor(0.1033, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5807\n",
      "Loss: tensor(0.1033, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5808\n",
      "Loss: tensor(0.1033, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5809\n",
      "Loss: tensor(0.1033, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5810\n",
      "Loss: tensor(0.1033, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5811\n",
      "Loss: tensor(0.1033, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5812\n",
      "Loss: tensor(0.1033, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5813\n",
      "Loss: tensor(0.1033, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5814\n",
      "Loss: tensor(0.1033, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5815\n",
      "Loss: tensor(0.1033, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5816\n",
      "Loss: tensor(0.1033, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5817\n",
      "Loss: tensor(0.1033, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5818\n",
      "Loss: tensor(0.1033, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5819\n",
      "Loss: tensor(0.1033, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5820\n",
      "Loss: tensor(0.1033, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5821\n",
      "Loss: tensor(0.1033, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5822\n",
      "Loss: tensor(0.1033, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5823\n",
      "Loss: tensor(0.1033, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5824\n",
      "Loss: tensor(0.1033, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5825\n",
      "Loss: tensor(0.1033, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5826\n",
      "Loss: tensor(0.1033, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5827\n",
      "Loss: tensor(0.1033, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5828\n",
      "Loss: tensor(0.1033, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5829\n",
      "Loss: tensor(0.1033, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5830\n",
      "Loss: tensor(0.1033, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5831\n",
      "Loss: tensor(0.1033, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5832\n",
      "Loss: tensor(0.1033, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5833\n",
      "Loss: tensor(0.1033, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5834\n",
      "Loss: tensor(0.1033, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5835\n",
      "Loss: tensor(0.1033, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5836\n",
      "Loss: tensor(0.1033, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5837\n",
      "Loss: tensor(0.1033, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5838\n",
      "Loss: tensor(0.1033, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5839\n",
      "Loss: tensor(0.1033, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5840\n",
      "Loss: tensor(0.1033, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5841\n",
      "Loss: tensor(0.1033, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5842\n",
      "Loss: tensor(0.1033, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5843\n",
      "Loss: tensor(0.1033, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5844\n",
      "Loss: tensor(0.1033, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5845\n",
      "Loss: tensor(0.1033, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5846\n",
      "Loss: tensor(0.1033, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5847\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor(0.1033, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5848\n",
      "Loss: tensor(0.1033, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5849\n",
      "Loss: tensor(0.1033, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5850\n",
      "Loss: tensor(0.1033, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5851\n",
      "Loss: tensor(0.1033, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5852\n",
      "Loss: tensor(0.1033, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5853\n",
      "Loss: tensor(0.1033, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5854\n",
      "Loss: tensor(0.1033, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5855\n",
      "Loss: tensor(0.1033, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5856\n",
      "Loss: tensor(0.1033, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5857\n",
      "Loss: tensor(0.1033, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5858\n",
      "Loss: tensor(0.1033, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5859\n",
      "Loss: tensor(0.1033, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5860\n",
      "Loss: tensor(0.1033, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5861\n",
      "Loss: tensor(0.1033, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5862\n",
      "Loss: tensor(0.1033, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5863\n",
      "Loss: tensor(0.1032, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5864\n",
      "Loss: tensor(0.1032, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5865\n",
      "Loss: tensor(0.1032, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5866\n",
      "Loss: tensor(0.1032, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5867\n",
      "Loss: tensor(0.1032, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5868\n",
      "Loss: tensor(0.1032, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5869\n",
      "Loss: tensor(0.1032, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5870\n",
      "Loss: tensor(0.1032, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5871\n",
      "Loss: tensor(0.1032, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5872\n",
      "Loss: tensor(0.1032, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5873\n",
      "Loss: tensor(0.1032, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5874\n",
      "Loss: tensor(0.1032, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5875\n",
      "Loss: tensor(0.1032, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5876\n",
      "Loss: tensor(0.1032, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5877\n",
      "Loss: tensor(0.1032, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5878\n",
      "Loss: tensor(0.1032, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5879\n",
      "Loss: tensor(0.1032, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5880\n",
      "Loss: tensor(0.1032, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5881\n",
      "Loss: tensor(0.1032, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5882\n",
      "Loss: tensor(0.1032, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5883\n",
      "Loss: tensor(0.1032, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5884\n",
      "Loss: tensor(0.1032, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5885\n",
      "Loss: tensor(0.1032, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5886\n",
      "Loss: tensor(0.1032, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5887\n",
      "Loss: tensor(0.1032, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5888\n",
      "Loss: tensor(0.1032, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5889\n",
      "Loss: tensor(0.1032, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5890\n",
      "Loss: tensor(0.1032, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5891\n",
      "Loss: tensor(0.1032, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5892\n",
      "Loss: tensor(0.1032, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5893\n",
      "Loss: tensor(0.1032, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5894\n",
      "Loss: tensor(0.1032, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5895\n",
      "Loss: tensor(0.1032, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5896\n",
      "Loss: tensor(0.1032, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5897\n",
      "Loss: tensor(0.1032, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5898\n",
      "Loss: tensor(0.1032, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5899\n",
      "Loss: tensor(0.1032, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5900\n",
      "Loss: tensor(0.1032, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5901\n",
      "Loss: tensor(0.1032, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5902\n",
      "Loss: tensor(0.1032, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5903\n",
      "Loss: tensor(0.1032, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5904\n",
      "Loss: tensor(0.1032, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5905\n",
      "Loss: tensor(0.1031, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5906\n",
      "Loss: tensor(0.1031, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5907\n",
      "Loss: tensor(0.1031, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5908\n",
      "Loss: tensor(0.1031, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5909\n",
      "Loss: tensor(0.1031, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5910\n",
      "Loss: tensor(0.1031, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5911\n",
      "Loss: tensor(0.1031, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5912\n",
      "Loss: tensor(0.1031, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5913\n",
      "Loss: tensor(0.1031, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5914\n",
      "Loss: tensor(0.1031, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5915\n",
      "Loss: tensor(0.1031, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5916\n",
      "Loss: tensor(0.1031, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5917\n",
      "Loss: tensor(0.1031, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5918\n",
      "Loss: tensor(0.1031, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5919\n",
      "Loss: tensor(0.1031, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5920\n",
      "Loss: tensor(0.1031, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5921\n",
      "Loss: tensor(0.1031, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5922\n",
      "Loss: tensor(0.1031, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5923\n",
      "Loss: tensor(0.1031, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5924\n",
      "Loss: tensor(0.1031, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5925\n",
      "Loss: tensor(0.1031, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5926\n",
      "Loss: tensor(0.1031, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5927\n",
      "Loss: tensor(0.1031, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5928\n",
      "Loss: tensor(0.1031, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5929\n",
      "Loss: tensor(0.1031, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5930\n",
      "Loss: tensor(0.1031, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5931\n",
      "Loss: tensor(0.1031, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5932\n",
      "Loss: tensor(0.1031, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5933\n",
      "Loss: tensor(0.1031, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5934\n",
      "Loss: tensor(0.1031, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5935\n",
      "Loss: tensor(0.1031, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5936\n",
      "Loss: tensor(0.1031, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5937\n",
      "Loss: tensor(0.1031, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5938\n",
      "Loss: tensor(0.1031, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5939\n",
      "Loss: tensor(0.1031, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5940\n",
      "Loss: tensor(0.1031, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5941\n",
      "Loss: tensor(0.1031, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5942\n",
      "Loss: tensor(0.1031, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5943\n",
      "Loss: tensor(0.1031, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5944\n",
      "Loss: tensor(0.1031, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5945\n",
      "Loss: tensor(0.1031, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5946\n",
      "Loss: tensor(0.1031, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5947\n",
      "Loss: tensor(0.1031, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5948\n",
      "Loss: tensor(0.1031, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5949\n",
      "Loss: tensor(0.1031, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5950\n",
      "Loss: tensor(0.1031, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5951\n",
      "Loss: tensor(0.1031, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5952\n",
      "Loss: tensor(0.1031, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5953\n",
      "Loss: tensor(0.1031, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5954\n",
      "Loss: tensor(0.1031, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5955\n",
      "Loss: tensor(0.1031, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5956\n",
      "Loss: tensor(0.1031, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5957\n",
      "Loss: tensor(0.1031, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5958\n",
      "Loss: tensor(0.1030, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5959\n",
      "Loss: tensor(0.1030, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5960\n",
      "Loss: tensor(0.1030, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5961\n",
      "Loss: tensor(0.1030, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5962\n",
      "Loss: tensor(0.1030, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5963\n",
      "Loss: tensor(0.1030, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5964\n",
      "Loss: tensor(0.1030, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5965\n",
      "Loss: tensor(0.1030, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5966\n",
      "Loss: tensor(0.1030, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5967\n",
      "Loss: tensor(0.1030, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5968\n",
      "Loss: tensor(0.1030, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5969\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor(0.1030, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5970\n",
      "Loss: tensor(0.1030, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5971\n",
      "Loss: tensor(0.1030, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5972\n",
      "Loss: tensor(0.1030, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5973\n",
      "Loss: tensor(0.1030, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5974\n",
      "Loss: tensor(0.1030, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5975\n",
      "Loss: tensor(0.1030, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5976\n",
      "Loss: tensor(0.1030, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5977\n",
      "Loss: tensor(0.1030, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5978\n",
      "Loss: tensor(0.1030, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5979\n",
      "Loss: tensor(0.1030, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5980\n",
      "Loss: tensor(0.1030, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5981\n",
      "Loss: tensor(0.1030, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5982\n",
      "Loss: tensor(0.1030, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5983\n",
      "Loss: tensor(0.1030, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5984\n",
      "Loss: tensor(0.1030, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5985\n",
      "Loss: tensor(0.1030, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5986\n",
      "Loss: tensor(0.1030, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5987\n",
      "Loss: tensor(0.1030, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5988\n",
      "Loss: tensor(0.1030, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5989\n",
      "Loss: tensor(0.1030, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5990\n",
      "Loss: tensor(0.1030, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5991\n",
      "Loss: tensor(0.1030, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5992\n",
      "Loss: tensor(0.1030, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5993\n",
      "Loss: tensor(0.1030, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5994\n",
      "Loss: tensor(0.1030, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5995\n",
      "Loss: tensor(0.1030, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5996\n",
      "Loss: tensor(0.1030, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5997\n",
      "Loss: tensor(0.1030, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5998\n",
      "Loss: tensor(0.1030, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5999\n",
      "Loss: tensor(0.1030, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6000\n",
      "Loss: tensor(0.1030, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6001\n",
      "Loss: tensor(0.1030, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6002\n",
      "Loss: tensor(0.1030, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6003\n",
      "Loss: tensor(0.1030, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6004\n",
      "Loss: tensor(0.1030, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6005\n",
      "Loss: tensor(0.1030, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6006\n",
      "Loss: tensor(0.1030, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6007\n",
      "Loss: tensor(0.1030, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6008\n",
      "Loss: tensor(0.1030, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6009\n",
      "Loss: tensor(0.1030, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6010\n",
      "Loss: tensor(0.1030, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6011\n",
      "Loss: tensor(0.1030, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6012\n",
      "Loss: tensor(0.1030, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6013\n",
      "Loss: tensor(0.1029, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6014\n",
      "Loss: tensor(0.1029, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6015\n",
      "Loss: tensor(0.1029, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6016\n",
      "Loss: tensor(0.1029, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6017\n",
      "Loss: tensor(0.1029, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6018\n",
      "Loss: tensor(0.1029, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6019\n",
      "Loss: tensor(0.1029, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6020\n",
      "Loss: tensor(0.1029, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6021\n",
      "Loss: tensor(0.1029, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6022\n",
      "Loss: tensor(0.1029, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6023\n",
      "Loss: tensor(0.1029, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6024\n",
      "Loss: tensor(0.1029, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6025\n",
      "Loss: tensor(0.1029, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6026\n",
      "Loss: tensor(0.1029, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6027\n",
      "Loss: tensor(0.1029, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6028\n",
      "Loss: tensor(0.1029, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6029\n",
      "Loss: tensor(0.1029, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6030\n",
      "Loss: tensor(0.1029, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6031\n",
      "Loss: tensor(0.1029, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6032\n",
      "Loss: tensor(0.1029, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6033\n",
      "Loss: tensor(0.1029, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6034\n",
      "Loss: tensor(0.1029, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6035\n",
      "Loss: tensor(0.1029, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6036\n",
      "Loss: tensor(0.1029, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6037\n",
      "Loss: tensor(0.1029, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6038\n",
      "Loss: tensor(0.1029, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6039\n",
      "Loss: tensor(0.1029, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6040\n",
      "Loss: tensor(0.1029, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6041\n",
      "Loss: tensor(0.1029, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6042\n",
      "Loss: tensor(0.1029, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6043\n",
      "Loss: tensor(0.1029, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6044\n",
      "Loss: tensor(0.1029, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6045\n",
      "Loss: tensor(0.1029, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6046\n",
      "Loss: tensor(0.1029, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6047\n",
      "Loss: tensor(0.1029, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6048\n",
      "Loss: tensor(0.1029, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6049\n",
      "Loss: tensor(0.1029, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6050\n",
      "Loss: tensor(0.1029, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6051\n",
      "Loss: tensor(0.1029, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6052\n",
      "Loss: tensor(0.1029, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6053\n",
      "Loss: tensor(0.1029, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6054\n",
      "Loss: tensor(0.1029, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6055\n",
      "Loss: tensor(0.1029, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6056\n",
      "Loss: tensor(0.1029, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6057\n",
      "Loss: tensor(0.1029, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6058\n",
      "Loss: tensor(0.1029, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6059\n",
      "Loss: tensor(0.1029, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6060\n",
      "Loss: tensor(0.1029, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6061\n",
      "Loss: tensor(0.1029, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6062\n",
      "Loss: tensor(0.1029, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6063\n",
      "Loss: tensor(0.1029, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6064\n",
      "Loss: tensor(0.1029, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6065\n",
      "Loss: tensor(0.1029, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6066\n",
      "Loss: tensor(0.1029, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6067\n",
      "Loss: tensor(0.1029, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6068\n",
      "Loss: tensor(0.1029, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6069\n",
      "Loss: tensor(0.1028, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6070\n",
      "Loss: tensor(0.1028, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6071\n",
      "Loss: tensor(0.1028, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6072\n",
      "Loss: tensor(0.1028, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6073\n",
      "Loss: tensor(0.1028, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6074\n",
      "Loss: tensor(0.1028, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6075\n",
      "Loss: tensor(0.1028, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6076\n",
      "Loss: tensor(0.1028, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6077\n",
      "Loss: tensor(0.1028, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6078\n",
      "Loss: tensor(0.1028, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6079\n",
      "Loss: tensor(0.1028, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6080\n",
      "Loss: tensor(0.1028, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6081\n",
      "Loss: tensor(0.1028, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6082\n",
      "Loss: tensor(0.1028, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6083\n",
      "Loss: tensor(0.1028, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6084\n",
      "Loss: tensor(0.1028, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6085\n",
      "Loss: tensor(0.1028, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6086\n",
      "Loss: tensor(0.1028, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6087\n",
      "Loss: tensor(0.1028, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6088\n",
      "Loss: tensor(0.1028, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6089\n",
      "Loss: tensor(0.1028, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6090\n",
      "Loss: tensor(0.1028, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6091\n",
      "Loss: tensor(0.1028, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6092\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor(0.1028, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6093\n",
      "Loss: tensor(0.1028, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6094\n",
      "Loss: tensor(0.1028, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6095\n",
      "Loss: tensor(0.1028, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6096\n",
      "Loss: tensor(0.1028, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6097\n",
      "Loss: tensor(0.1028, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6098\n",
      "Loss: tensor(0.1028, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6099\n",
      "Loss: tensor(0.1028, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6100\n",
      "Loss: tensor(0.1028, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6101\n",
      "Loss: tensor(0.1028, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6102\n",
      "Loss: tensor(0.1028, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6103\n",
      "Loss: tensor(0.1028, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6104\n",
      "Loss: tensor(0.1028, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6105\n",
      "Loss: tensor(0.1028, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6106\n",
      "Loss: tensor(0.1028, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6107\n",
      "Loss: tensor(0.1028, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6108\n",
      "Loss: tensor(0.1028, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6109\n",
      "Loss: tensor(0.1028, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6110\n",
      "Loss: tensor(0.1028, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6111\n",
      "Loss: tensor(0.1028, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6112\n",
      "Loss: tensor(0.1028, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6113\n",
      "Loss: tensor(0.1028, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6114\n",
      "Loss: tensor(0.1028, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6115\n",
      "Loss: tensor(0.1028, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6116\n",
      "Loss: tensor(0.1028, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6117\n",
      "Loss: tensor(0.1028, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6118\n",
      "Loss: tensor(0.1028, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6119\n",
      "Loss: tensor(0.1028, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6120\n",
      "Loss: tensor(0.1028, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6121\n",
      "Loss: tensor(0.1028, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6122\n",
      "Loss: tensor(0.1028, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6123\n",
      "Loss: tensor(0.1028, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6124\n",
      "Loss: tensor(0.1028, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6125\n",
      "Loss: tensor(0.1028, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6126\n",
      "Loss: tensor(0.1028, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6127\n",
      "Loss: tensor(0.1028, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6128\n",
      "Loss: tensor(0.1028, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6129\n",
      "Loss: tensor(0.1027, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6130\n",
      "Loss: tensor(0.1027, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6131\n",
      "Loss: tensor(0.1027, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6132\n",
      "Loss: tensor(0.1027, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6133\n",
      "Loss: tensor(0.1027, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6134\n",
      "Loss: tensor(0.1027, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6135\n",
      "Loss: tensor(0.1027, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6136\n",
      "Loss: tensor(0.1027, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6137\n",
      "Loss: tensor(0.1027, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6138\n",
      "Loss: tensor(0.1027, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6139\n",
      "Loss: tensor(0.1027, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6140\n",
      "Loss: tensor(0.1027, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6141\n",
      "Loss: tensor(0.1027, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6142\n",
      "Loss: tensor(0.1027, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6143\n",
      "Loss: tensor(0.1027, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6144\n",
      "Loss: tensor(0.1027, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6145\n",
      "Loss: tensor(0.1027, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6146\n",
      "Loss: tensor(0.1027, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6147\n",
      "Loss: tensor(0.1027, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6148\n",
      "Loss: tensor(0.1027, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6149\n",
      "Loss: tensor(0.1027, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6150\n",
      "Loss: tensor(0.1027, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6151\n",
      "Loss: tensor(0.1027, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6152\n",
      "Loss: tensor(0.1027, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6153\n",
      "Loss: tensor(0.1027, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6154\n",
      "Loss: tensor(0.1027, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6155\n",
      "Loss: tensor(0.1027, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6156\n",
      "Loss: tensor(0.1027, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6157\n",
      "Loss: tensor(0.1027, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6158\n",
      "Loss: tensor(0.1027, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6159\n",
      "Loss: tensor(0.1027, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6160\n",
      "Loss: tensor(0.1027, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6161\n",
      "Loss: tensor(0.1027, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6162\n",
      "Loss: tensor(0.1027, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6163\n",
      "Loss: tensor(0.1027, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6164\n",
      "Loss: tensor(0.1027, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6165\n",
      "Loss: tensor(0.1027, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6166\n",
      "Loss: tensor(0.1027, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6167\n",
      "Loss: tensor(0.1027, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6168\n",
      "Loss: tensor(0.1027, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6169\n",
      "Loss: tensor(0.1027, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6170\n",
      "Loss: tensor(0.1027, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6171\n",
      "Loss: tensor(0.1027, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6172\n",
      "Loss: tensor(0.1027, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6173\n",
      "Loss: tensor(0.1027, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6174\n",
      "Loss: tensor(0.1027, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6175\n",
      "Loss: tensor(0.1027, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6176\n",
      "Loss: tensor(0.1027, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6177\n",
      "Loss: tensor(0.1027, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6178\n",
      "Loss: tensor(0.1027, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6179\n",
      "Loss: tensor(0.1027, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6180\n",
      "Loss: tensor(0.1027, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6181\n",
      "Loss: tensor(0.1027, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6182\n",
      "Loss: tensor(0.1027, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6183\n",
      "Loss: tensor(0.1026, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6184\n",
      "Loss: tensor(0.1026, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6185\n",
      "Loss: tensor(0.1026, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6186\n",
      "Loss: tensor(0.1026, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6187\n",
      "Loss: tensor(0.1026, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6188\n",
      "Loss: tensor(0.1026, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6189\n",
      "Loss: tensor(0.1026, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6190\n",
      "Loss: tensor(0.1026, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6191\n",
      "Loss: tensor(0.1026, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6192\n",
      "Loss: tensor(0.1026, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6193\n",
      "Loss: tensor(0.1026, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6194\n",
      "Loss: tensor(0.1026, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6195\n",
      "Loss: tensor(0.1026, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6196\n",
      "Loss: tensor(0.1026, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6197\n",
      "Loss: tensor(0.1026, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6198\n",
      "Loss: tensor(0.1026, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6199\n",
      "Loss: tensor(0.1026, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6200\n",
      "Loss: tensor(0.1026, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6201\n",
      "Loss: tensor(0.1026, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6202\n",
      "Loss: tensor(0.1026, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6203\n",
      "Loss: tensor(0.1026, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6204\n",
      "Loss: tensor(0.1026, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6205\n",
      "Loss: tensor(0.1026, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6206\n",
      "Loss: tensor(0.1026, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6207\n",
      "Loss: tensor(0.1026, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6208\n",
      "Loss: tensor(0.1026, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6209\n",
      "Loss: tensor(0.1026, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6210\n",
      "Loss: tensor(0.1026, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6211\n",
      "Loss: tensor(0.1026, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6212\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor(0.1026, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6213\n",
      "Loss: tensor(0.1026, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6214\n",
      "Loss: tensor(0.1026, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6215\n",
      "Loss: tensor(0.1026, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6216\n",
      "Loss: tensor(0.1026, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6217\n",
      "Loss: tensor(0.1026, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6218\n",
      "Loss: tensor(0.1026, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6219\n",
      "Loss: tensor(0.1026, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6220\n",
      "Loss: tensor(0.1026, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6221\n",
      "Loss: tensor(0.1026, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6222\n",
      "Loss: tensor(0.1026, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6223\n",
      "Loss: tensor(0.1026, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6224\n",
      "Loss: tensor(0.1026, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6225\n",
      "Loss: tensor(0.1026, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6226\n",
      "Loss: tensor(0.1026, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6227\n",
      "Loss: tensor(0.1026, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6228\n",
      "Loss: tensor(0.1026, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6229\n",
      "Loss: tensor(0.1026, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6230\n",
      "Loss: tensor(0.1026, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6231\n",
      "Loss: tensor(0.1026, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6232\n",
      "Loss: tensor(0.1026, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6233\n",
      "Loss: tensor(0.1026, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6234\n",
      "Loss: tensor(0.1026, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6235\n",
      "Loss: tensor(0.1026, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6236\n",
      "Loss: tensor(0.1026, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6237\n",
      "Loss: tensor(0.1026, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6238\n",
      "Loss: tensor(0.1026, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6239\n",
      "Loss: tensor(0.1026, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6240\n",
      "Loss: tensor(0.1026, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6241\n",
      "Loss: tensor(0.1026, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6242\n",
      "Loss: tensor(0.1025, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6243\n",
      "Loss: tensor(0.1025, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6244\n",
      "Loss: tensor(0.1025, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6245\n",
      "Loss: tensor(0.1025, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6246\n",
      "Loss: tensor(0.1025, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6247\n",
      "Loss: tensor(0.1025, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6248\n",
      "Loss: tensor(0.1025, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6249\n",
      "Loss: tensor(0.1025, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6250\n",
      "Loss: tensor(0.1025, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6251\n",
      "Loss: tensor(0.1025, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6252\n",
      "Loss: tensor(0.1025, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6253\n",
      "Loss: tensor(0.1025, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6254\n",
      "Loss: tensor(0.1025, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6255\n",
      "Loss: tensor(0.1025, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6256\n",
      "Loss: tensor(0.1025, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6257\n",
      "Loss: tensor(0.1025, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6258\n",
      "Loss: tensor(0.1025, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6259\n",
      "Loss: tensor(0.1025, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6260\n",
      "Loss: tensor(0.1025, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6261\n",
      "Loss: tensor(0.1025, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6262\n",
      "Loss: tensor(0.1025, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6263\n",
      "Loss: tensor(0.1025, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6264\n",
      "Loss: tensor(0.1025, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6265\n",
      "Loss: tensor(0.1025, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6266\n",
      "Loss: tensor(0.1025, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6267\n",
      "Loss: tensor(0.1025, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6268\n",
      "Loss: tensor(0.1025, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6269\n",
      "Loss: tensor(0.1025, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6270\n",
      "Loss: tensor(0.1025, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6271\n",
      "Loss: tensor(0.1025, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6272\n",
      "Loss: tensor(0.1025, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6273\n",
      "Loss: tensor(0.1025, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6274\n",
      "Loss: tensor(0.1025, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6275\n",
      "Loss: tensor(0.1025, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6276\n",
      "Loss: tensor(0.1025, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6277\n",
      "Loss: tensor(0.1025, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6278\n",
      "Loss: tensor(0.1025, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6279\n",
      "Loss: tensor(0.1025, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6280\n",
      "Loss: tensor(0.1025, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6281\n",
      "Loss: tensor(0.1025, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6282\n",
      "Loss: tensor(0.1025, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6283\n",
      "Loss: tensor(0.1025, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6284\n",
      "Loss: tensor(0.1025, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6285\n",
      "Loss: tensor(0.1025, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6286\n",
      "Loss: tensor(0.1025, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6287\n",
      "Loss: tensor(0.1025, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6288\n",
      "Loss: tensor(0.1025, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6289\n",
      "Loss: tensor(0.1025, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6290\n",
      "Loss: tensor(0.1025, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6291\n",
      "Loss: tensor(0.1025, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6292\n",
      "Loss: tensor(0.1025, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6293\n",
      "Loss: tensor(0.1025, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6294\n",
      "Loss: tensor(0.1025, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6295\n",
      "Loss: tensor(0.1025, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6296\n",
      "Loss: tensor(0.1025, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6297\n",
      "Loss: tensor(0.1025, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6298\n",
      "Loss: tensor(0.1025, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6299\n",
      "Loss: tensor(0.1025, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6300\n",
      "Loss: tensor(0.1025, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6301\n",
      "Loss: tensor(0.1025, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6302\n",
      "Loss: tensor(0.1025, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6303\n",
      "Loss: tensor(0.1025, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6304\n",
      "Loss: tensor(0.1025, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6305\n",
      "Loss: tensor(0.1025, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6306\n",
      "Loss: tensor(0.1025, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6307\n",
      "Loss: tensor(0.1025, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6308\n",
      "Loss: tensor(0.1024, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6309\n",
      "Loss: tensor(0.1024, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6310\n",
      "Loss: tensor(0.1024, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6311\n",
      "Loss: tensor(0.1024, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6312\n",
      "Loss: tensor(0.1024, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6313\n",
      "Loss: tensor(0.1024, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6314\n",
      "Loss: tensor(0.1024, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6315\n",
      "Loss: tensor(0.1024, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6316\n",
      "Loss: tensor(0.1024, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6317\n",
      "Loss: tensor(0.1024, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6318\n",
      "Loss: tensor(0.1024, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6319\n",
      "Loss: tensor(0.1024, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6320\n",
      "Loss: tensor(0.1024, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6321\n",
      "Loss: tensor(0.1024, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6322\n",
      "Loss: tensor(0.1024, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6323\n",
      "Loss: tensor(0.1024, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6324\n",
      "Loss: tensor(0.1024, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6325\n",
      "Loss: tensor(0.1024, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6326\n",
      "Loss: tensor(0.1024, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6327\n",
      "Loss: tensor(0.1024, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6328\n",
      "Loss: tensor(0.1024, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6329\n",
      "Loss: tensor(0.1024, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6330\n",
      "Loss: tensor(0.1024, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6331\n",
      "Loss: tensor(0.1024, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6332\n",
      "Loss: tensor(0.1024, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6333\n",
      "Loss: tensor(0.1024, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6334\n",
      "Loss: tensor(0.1024, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6335\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor(0.1024, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6336\n",
      "Loss: tensor(0.1024, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6337\n",
      "Loss: tensor(0.1024, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6338\n",
      "Loss: tensor(0.1024, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6339\n",
      "Loss: tensor(0.1024, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6340\n",
      "Loss: tensor(0.1024, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6341\n",
      "Loss: tensor(0.1024, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6342\n",
      "Loss: tensor(0.1024, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6343\n",
      "Loss: tensor(0.1024, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6344\n",
      "Loss: tensor(0.1024, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6345\n",
      "Loss: tensor(0.1024, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6346\n",
      "Loss: tensor(0.1024, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6347\n",
      "Loss: tensor(0.1024, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6348\n",
      "Loss: tensor(0.1024, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6349\n",
      "Loss: tensor(0.1024, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6350\n",
      "Loss: tensor(0.1024, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6351\n",
      "Loss: tensor(0.1024, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6352\n",
      "Loss: tensor(0.1024, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6353\n",
      "Loss: tensor(0.1024, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6354\n",
      "Loss: tensor(0.1024, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6355\n",
      "Loss: tensor(0.1024, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6356\n",
      "Loss: tensor(0.1024, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6357\n",
      "Loss: tensor(0.1024, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6358\n",
      "Loss: tensor(0.1024, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6359\n",
      "Loss: tensor(0.1024, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6360\n",
      "Loss: tensor(0.1024, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6361\n",
      "Loss: tensor(0.1024, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6362\n",
      "Loss: tensor(0.1023, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6363\n",
      "Loss: tensor(0.1023, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6364\n",
      "Loss: tensor(0.1023, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6365\n",
      "Loss: tensor(0.1023, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6366\n",
      "Loss: tensor(0.1023, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6367\n",
      "Loss: tensor(0.1023, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6368\n",
      "Loss: tensor(0.1023, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6369\n",
      "Loss: tensor(0.1023, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6370\n",
      "Loss: tensor(0.1023, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6371\n",
      "Loss: tensor(0.1023, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6372\n",
      "Loss: tensor(0.1023, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6373\n",
      "Loss: tensor(0.1023, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6374\n",
      "Loss: tensor(0.1023, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6375\n",
      "Loss: tensor(0.1023, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6376\n",
      "Loss: tensor(0.1023, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6377\n",
      "Loss: tensor(0.1023, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6378\n",
      "Loss: tensor(0.1023, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6379\n",
      "Loss: tensor(0.1023, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6380\n",
      "Loss: tensor(0.1023, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6381\n",
      "Loss: tensor(0.1023, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6382\n",
      "Loss: tensor(0.1023, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6383\n",
      "Loss: tensor(0.1023, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6384\n",
      "Loss: tensor(0.1023, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6385\n",
      "Loss: tensor(0.1023, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6386\n",
      "Loss: tensor(0.1023, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6387\n",
      "Loss: tensor(0.1023, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6388\n",
      "Loss: tensor(0.1023, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6389\n",
      "Loss: tensor(0.1023, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6390\n",
      "Loss: tensor(0.1023, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6391\n",
      "Loss: tensor(0.1023, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6392\n",
      "Loss: tensor(0.1023, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6393\n",
      "Loss: tensor(0.1023, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6394\n",
      "Loss: tensor(0.1023, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6395\n",
      "Loss: tensor(0.1023, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6396\n",
      "Loss: tensor(0.1023, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6397\n",
      "Loss: tensor(0.1023, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6398\n",
      "Loss: tensor(0.1023, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6399\n",
      "Loss: tensor(0.1023, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6400\n",
      "Loss: tensor(0.1023, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6401\n",
      "Loss: tensor(0.1023, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6402\n",
      "Loss: tensor(0.1023, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6403\n",
      "Loss: tensor(0.1023, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6404\n",
      "Loss: tensor(0.1023, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6405\n",
      "Loss: tensor(0.1023, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6406\n",
      "Loss: tensor(0.1023, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6407\n",
      "Loss: tensor(0.1023, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6408\n",
      "Loss: tensor(0.1023, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6409\n",
      "Loss: tensor(0.1023, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6410\n",
      "Loss: tensor(0.1023, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6411\n",
      "Loss: tensor(0.1023, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6412\n",
      "Loss: tensor(0.1023, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6413\n",
      "Loss: tensor(0.1023, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6414\n",
      "Loss: tensor(0.1023, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6415\n",
      "Loss: tensor(0.1023, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6416\n",
      "Loss: tensor(0.1023, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6417\n",
      "Loss: tensor(0.1023, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6418\n",
      "Loss: tensor(0.1023, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6419\n",
      "Loss: tensor(0.1023, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6420\n",
      "Loss: tensor(0.1023, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6421\n",
      "Loss: tensor(0.1023, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6422\n",
      "Loss: tensor(0.1023, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6423\n",
      "Loss: tensor(0.1023, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6424\n",
      "Loss: tensor(0.1022, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6425\n",
      "Loss: tensor(0.1022, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6426\n",
      "Loss: tensor(0.1022, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6427\n",
      "Loss: tensor(0.1022, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6428\n",
      "Loss: tensor(0.1022, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6429\n",
      "Loss: tensor(0.1022, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6430\n",
      "Loss: tensor(0.1022, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6431\n",
      "Loss: tensor(0.1022, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6432\n",
      "Loss: tensor(0.1022, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6433\n",
      "Loss: tensor(0.1022, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6434\n",
      "Loss: tensor(0.1022, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6435\n",
      "Loss: tensor(0.1022, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6436\n",
      "Loss: tensor(0.1022, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6437\n",
      "Loss: tensor(0.1022, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6438\n",
      "Loss: tensor(0.1022, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6439\n",
      "Loss: tensor(0.1022, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6440\n",
      "Loss: tensor(0.1022, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6441\n",
      "Loss: tensor(0.1022, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6442\n",
      "Loss: tensor(0.1022, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6443\n",
      "Loss: tensor(0.1022, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6444\n",
      "Loss: tensor(0.1022, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6445\n",
      "Loss: tensor(0.1022, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6446\n",
      "Loss: tensor(0.1022, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6447\n",
      "Loss: tensor(0.1022, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6448\n",
      "Loss: tensor(0.1022, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6449\n",
      "Loss: tensor(0.1022, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6450\n",
      "Loss: tensor(0.1022, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6451\n",
      "Loss: tensor(0.1022, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6452\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor(0.1022, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6453\n",
      "Loss: tensor(0.1022, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6454\n",
      "Loss: tensor(0.1022, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6455\n",
      "Loss: tensor(0.1022, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6456\n",
      "Loss: tensor(0.1022, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6457\n",
      "Loss: tensor(0.1022, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6458\n",
      "Loss: tensor(0.1022, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6459\n",
      "Loss: tensor(0.1022, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6460\n",
      "Loss: tensor(0.1022, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6461\n",
      "Loss: tensor(0.1022, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6462\n",
      "Loss: tensor(0.1022, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6463\n",
      "Loss: tensor(0.1022, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6464\n",
      "Loss: tensor(0.1022, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6465\n",
      "Loss: tensor(0.1022, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6466\n",
      "Loss: tensor(0.1022, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6467\n",
      "Loss: tensor(0.1022, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6468\n",
      "Loss: tensor(0.1022, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6469\n",
      "Loss: tensor(0.1022, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6470\n",
      "Loss: tensor(0.1022, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6471\n",
      "Loss: tensor(0.1022, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6472\n",
      "Loss: tensor(0.1022, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6473\n",
      "Loss: tensor(0.1022, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6474\n",
      "Loss: tensor(0.1022, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6475\n",
      "Loss: tensor(0.1022, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6476\n",
      "Loss: tensor(0.1022, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6477\n",
      "Loss: tensor(0.1022, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6478\n",
      "Loss: tensor(0.1022, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6479\n",
      "Loss: tensor(0.1022, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6480\n",
      "Loss: tensor(0.1022, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6481\n",
      "Loss: tensor(0.1022, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6482\n",
      "Loss: tensor(0.1022, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6483\n",
      "Loss: tensor(0.1022, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6484\n",
      "Loss: tensor(0.1022, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6485\n",
      "Loss: tensor(0.1022, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6486\n",
      "Loss: tensor(0.1021, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6487\n",
      "Loss: tensor(0.1021, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6488\n",
      "Loss: tensor(0.1021, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6489\n",
      "Loss: tensor(0.1021, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6490\n",
      "Loss: tensor(0.1021, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6491\n",
      "Loss: tensor(0.1021, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6492\n",
      "Loss: tensor(0.1021, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6493\n",
      "Loss: tensor(0.1021, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6494\n",
      "Loss: tensor(0.1021, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6495\n",
      "Loss: tensor(0.1021, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6496\n",
      "Loss: tensor(0.1021, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6497\n",
      "Loss: tensor(0.1021, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6498\n",
      "Loss: tensor(0.1021, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6499\n",
      "Loss: tensor(0.1021, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6500\n",
      "Loss: tensor(0.1021, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6501\n",
      "Loss: tensor(0.1021, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6502\n",
      "Loss: tensor(0.1021, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6503\n",
      "Loss: tensor(0.1021, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6504\n",
      "Loss: tensor(0.1021, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6505\n",
      "Loss: tensor(0.1021, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6506\n",
      "Loss: tensor(0.1021, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6507\n",
      "Loss: tensor(0.1021, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6508\n",
      "Loss: tensor(0.1021, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6509\n",
      "Loss: tensor(0.1021, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6510\n",
      "Loss: tensor(0.1021, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6511\n",
      "Loss: tensor(0.1021, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6512\n",
      "Loss: tensor(0.1021, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6513\n",
      "Loss: tensor(0.1021, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6514\n",
      "Loss: tensor(0.1021, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6515\n",
      "Loss: tensor(0.1021, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6516\n",
      "Loss: tensor(0.1021, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6517\n",
      "Loss: tensor(0.1021, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6518\n",
      "Loss: tensor(0.1021, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6519\n",
      "Loss: tensor(0.1021, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6520\n",
      "Loss: tensor(0.1021, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6521\n",
      "Loss: tensor(0.1021, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6522\n",
      "Loss: tensor(0.1021, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6523\n",
      "Loss: tensor(0.1021, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6524\n",
      "Loss: tensor(0.1021, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6525\n",
      "Loss: tensor(0.1021, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6526\n",
      "Loss: tensor(0.1021, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6527\n",
      "Loss: tensor(0.1021, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6528\n",
      "Loss: tensor(0.1021, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6529\n",
      "Loss: tensor(0.1021, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6530\n",
      "Loss: tensor(0.1021, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6531\n",
      "Loss: tensor(0.1021, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6532\n",
      "Loss: tensor(0.1021, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6533\n",
      "Loss: tensor(0.1021, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6534\n",
      "Loss: tensor(0.1021, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6535\n",
      "Loss: tensor(0.1021, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6536\n",
      "Loss: tensor(0.1021, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6537\n",
      "Loss: tensor(0.1021, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6538\n",
      "Loss: tensor(0.1021, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6539\n",
      "Loss: tensor(0.1021, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6540\n",
      "Loss: tensor(0.1021, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6541\n",
      "Loss: tensor(0.1021, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6542\n",
      "Loss: tensor(0.1021, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6543\n",
      "Loss: tensor(0.1021, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6544\n",
      "Loss: tensor(0.1021, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6545\n",
      "Loss: tensor(0.1021, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6546\n",
      "Loss: tensor(0.1021, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6547\n",
      "Loss: tensor(0.1021, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6548\n",
      "Loss: tensor(0.1021, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6549\n",
      "Loss: tensor(0.1020, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6550\n",
      "Loss: tensor(0.1020, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6551\n",
      "Loss: tensor(0.1020, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6552\n",
      "Loss: tensor(0.1020, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6553\n",
      "Loss: tensor(0.1020, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6554\n",
      "Loss: tensor(0.1020, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6555\n",
      "Loss: tensor(0.1020, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6556\n",
      "Loss: tensor(0.1020, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6557\n",
      "Loss: tensor(0.1020, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6558\n",
      "Loss: tensor(0.1020, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6559\n",
      "Loss: tensor(0.1020, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6560\n",
      "Loss: tensor(0.1020, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6561\n",
      "Loss: tensor(0.1020, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6562\n",
      "Loss: tensor(0.1020, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6563\n",
      "Loss: tensor(0.1020, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6564\n",
      "Loss: tensor(0.1020, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6565\n",
      "Loss: tensor(0.1020, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6566\n",
      "Loss: tensor(0.1020, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6567\n",
      "Loss: tensor(0.1020, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6568\n",
      "Loss: tensor(0.1020, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6569\n",
      "Loss: tensor(0.1020, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6570\n",
      "Loss: tensor(0.1020, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor(0.1020, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6572\n",
      "Loss: tensor(0.1020, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6573\n",
      "Loss: tensor(0.1020, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6574\n",
      "Loss: tensor(0.1020, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6575\n",
      "Loss: tensor(0.1020, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6576\n",
      "Loss: tensor(0.1020, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6577\n",
      "Loss: tensor(0.1020, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6578\n",
      "Loss: tensor(0.1020, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6579\n",
      "Loss: tensor(0.1020, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6580\n",
      "Loss: tensor(0.1020, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6581\n",
      "Loss: tensor(0.1020, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6582\n",
      "Loss: tensor(0.1020, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6583\n",
      "Loss: tensor(0.1020, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6584\n",
      "Loss: tensor(0.1020, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6585\n",
      "Loss: tensor(0.1020, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6586\n",
      "Loss: tensor(0.1020, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6587\n",
      "Loss: tensor(0.1020, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6588\n",
      "Loss: tensor(0.1020, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6589\n",
      "Loss: tensor(0.1020, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6590\n",
      "Loss: tensor(0.1020, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6591\n",
      "Loss: tensor(0.1020, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6592\n",
      "Loss: tensor(0.1020, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6593\n",
      "Loss: tensor(0.1020, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6594\n",
      "Loss: tensor(0.1020, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6595\n",
      "Loss: tensor(0.1020, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6596\n",
      "Loss: tensor(0.1020, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6597\n",
      "Loss: tensor(0.1020, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6598\n",
      "Loss: tensor(0.1020, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6599\n",
      "Loss: tensor(0.1020, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6600\n",
      "Loss: tensor(0.1020, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6601\n",
      "Loss: tensor(0.1020, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6602\n",
      "Loss: tensor(0.1020, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6603\n",
      "Loss: tensor(0.1020, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6604\n",
      "Loss: tensor(0.1020, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6605\n",
      "Loss: tensor(0.1020, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6606\n",
      "Loss: tensor(0.1020, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6607\n",
      "Loss: tensor(0.1020, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6608\n",
      "Loss: tensor(0.1020, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6609\n",
      "Loss: tensor(0.1020, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6610\n",
      "Loss: tensor(0.1020, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6611\n",
      "Loss: tensor(0.1020, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6612\n",
      "Loss: tensor(0.1020, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6613\n",
      "Loss: tensor(0.1020, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6614\n",
      "Loss: tensor(0.1020, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6615\n",
      "Loss: tensor(0.1020, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6616\n",
      "Loss: tensor(0.1019, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6617\n",
      "Loss: tensor(0.1019, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6618\n",
      "Loss: tensor(0.1019, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6619\n",
      "Loss: tensor(0.1019, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6620\n",
      "Loss: tensor(0.1019, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6621\n",
      "Loss: tensor(0.1019, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6622\n",
      "Loss: tensor(0.1019, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6623\n",
      "Loss: tensor(0.1019, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6624\n",
      "Loss: tensor(0.1019, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6625\n",
      "Loss: tensor(0.1019, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6626\n",
      "Loss: tensor(0.1019, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6627\n",
      "Loss: tensor(0.1019, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6628\n",
      "Loss: tensor(0.1019, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6629\n",
      "Loss: tensor(0.1019, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6630\n",
      "Loss: tensor(0.1019, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6631\n",
      "Loss: tensor(0.1019, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6632\n",
      "Loss: tensor(0.1019, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6633\n",
      "Loss: tensor(0.1019, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6634\n",
      "Loss: tensor(0.1019, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6635\n",
      "Loss: tensor(0.1019, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6636\n",
      "Loss: tensor(0.1019, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6637\n",
      "Loss: tensor(0.1019, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6638\n",
      "Loss: tensor(0.1019, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6639\n",
      "Loss: tensor(0.1019, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6640\n",
      "Loss: tensor(0.1019, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6641\n",
      "Loss: tensor(0.1019, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6642\n",
      "Loss: tensor(0.1019, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6643\n",
      "Loss: tensor(0.1019, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6644\n",
      "Loss: tensor(0.1019, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6645\n",
      "Loss: tensor(0.1019, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6646\n",
      "Loss: tensor(0.1019, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6647\n",
      "Loss: tensor(0.1019, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6648\n",
      "Loss: tensor(0.1019, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6649\n",
      "Loss: tensor(0.1019, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6650\n",
      "Loss: tensor(0.1019, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6651\n",
      "Loss: tensor(0.1019, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6652\n",
      "Loss: tensor(0.1019, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6653\n",
      "Loss: tensor(0.1019, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6654\n",
      "Loss: tensor(0.1019, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6655\n",
      "Loss: tensor(0.1019, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6656\n",
      "Loss: tensor(0.1019, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6657\n",
      "Loss: tensor(0.1019, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6658\n",
      "Loss: tensor(0.1019, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6659\n",
      "Loss: tensor(0.1019, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6660\n",
      "Loss: tensor(0.1019, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6661\n",
      "Loss: tensor(0.1019, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6662\n",
      "Loss: tensor(0.1019, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6663\n",
      "Loss: tensor(0.1019, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6664\n",
      "Loss: tensor(0.1019, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6665\n",
      "Loss: tensor(0.1019, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6666\n",
      "Loss: tensor(0.1019, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6667\n",
      "Loss: tensor(0.1019, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6668\n",
      "Loss: tensor(0.1019, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6669\n",
      "Loss: tensor(0.1019, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6670\n",
      "Loss: tensor(0.1019, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6671\n",
      "Loss: tensor(0.1019, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6672\n",
      "Loss: tensor(0.1019, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6673\n",
      "Loss: tensor(0.1019, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6674\n",
      "Loss: tensor(0.1019, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6675\n",
      "Loss: tensor(0.1019, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6676\n",
      "Loss: tensor(0.1019, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6677\n",
      "Loss: tensor(0.1019, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6678\n",
      "Loss: tensor(0.1019, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6679\n",
      "Loss: tensor(0.1019, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6680\n",
      "Loss: tensor(0.1019, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6681\n",
      "Loss: tensor(0.1019, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6682\n",
      "Loss: tensor(0.1019, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6683\n",
      "Loss: tensor(0.1019, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6684\n",
      "Loss: tensor(0.1019, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6685\n",
      "Loss: tensor(0.1019, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6686\n",
      "Loss: tensor(0.1019, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6687\n",
      "Loss: tensor(0.1019, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6688\n",
      "Loss: tensor(0.1019, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6689\n",
      "Loss: tensor(0.1018, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6690\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor(0.1018, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6691\n",
      "Loss: tensor(0.1018, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6692\n",
      "Loss: tensor(0.1018, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6693\n",
      "Loss: tensor(0.1018, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6694\n",
      "Loss: tensor(0.1018, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6695\n",
      "Loss: tensor(0.1018, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6696\n",
      "Loss: tensor(0.1018, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6697\n",
      "Loss: tensor(0.1018, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6698\n",
      "Loss: tensor(0.1018, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6699\n",
      "Loss: tensor(0.1018, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6700\n",
      "Loss: tensor(0.1018, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6701\n",
      "Loss: tensor(0.1018, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6702\n",
      "Loss: tensor(0.1018, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6703\n",
      "Loss: tensor(0.1018, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6704\n",
      "Loss: tensor(0.1018, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6705\n",
      "Loss: tensor(0.1018, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6706\n",
      "Loss: tensor(0.1018, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6707\n",
      "Loss: tensor(0.1018, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6708\n",
      "Loss: tensor(0.1018, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6709\n",
      "Loss: tensor(0.1018, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6710\n",
      "Loss: tensor(0.1018, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6711\n",
      "Loss: tensor(0.1018, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6712\n",
      "Loss: tensor(0.1018, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6713\n",
      "Loss: tensor(0.1018, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6714\n",
      "Loss: tensor(0.1018, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6715\n",
      "Loss: tensor(0.1018, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6716\n",
      "Loss: tensor(0.1018, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6717\n",
      "Loss: tensor(0.1018, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6718\n",
      "Loss: tensor(0.1018, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6719\n",
      "Loss: tensor(0.1018, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6720\n",
      "Loss: tensor(0.1018, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6721\n",
      "Loss: tensor(0.1018, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6722\n",
      "Loss: tensor(0.1018, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6723\n",
      "Loss: tensor(0.1018, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6724\n",
      "Loss: tensor(0.1018, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6725\n",
      "Loss: tensor(0.1018, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6726\n",
      "Loss: tensor(0.1018, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6727\n",
      "Loss: tensor(0.1018, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6728\n",
      "Loss: tensor(0.1018, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6729\n",
      "Loss: tensor(0.1018, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6730\n",
      "Loss: tensor(0.1018, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6731\n",
      "Loss: tensor(0.1018, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6732\n",
      "Loss: tensor(0.1018, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6733\n",
      "Loss: tensor(0.1018, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6734\n",
      "Loss: tensor(0.1018, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6735\n",
      "Loss: tensor(0.1018, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6736\n",
      "Loss: tensor(0.1018, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6737\n",
      "Loss: tensor(0.1018, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6738\n",
      "Loss: tensor(0.1018, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6739\n",
      "Loss: tensor(0.1018, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6740\n",
      "Loss: tensor(0.1018, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6741\n",
      "Loss: tensor(0.1018, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6742\n",
      "Loss: tensor(0.1018, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6743\n",
      "Loss: tensor(0.1018, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6744\n",
      "Loss: tensor(0.1018, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6745\n",
      "Loss: tensor(0.1018, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6746\n",
      "Loss: tensor(0.1018, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6747\n",
      "Loss: tensor(0.1018, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6748\n",
      "Loss: tensor(0.1018, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6749\n",
      "Loss: tensor(0.1018, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6750\n",
      "Loss: tensor(0.1018, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6751\n",
      "Loss: tensor(0.1018, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6752\n",
      "Loss: tensor(0.1018, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6753\n",
      "Loss: tensor(0.1018, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6754\n",
      "Loss: tensor(0.1018, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6755\n",
      "Loss: tensor(0.1018, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6756\n",
      "Loss: tensor(0.1018, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6757\n",
      "Loss: tensor(0.1018, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6758\n",
      "Loss: tensor(0.1018, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6759\n",
      "Loss: tensor(0.1018, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6760\n",
      "Loss: tensor(0.1018, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6761\n",
      "Loss: tensor(0.1018, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6762\n",
      "Loss: tensor(0.1018, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6763\n",
      "Loss: tensor(0.1017, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6764\n",
      "Loss: tensor(0.1017, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6765\n",
      "Loss: tensor(0.1017, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6766\n",
      "Loss: tensor(0.1017, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6767\n",
      "Loss: tensor(0.1017, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6768\n",
      "Loss: tensor(0.1017, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6769\n",
      "Loss: tensor(0.1017, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6770\n",
      "Loss: tensor(0.1017, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6771\n",
      "Loss: tensor(0.1017, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6772\n",
      "Loss: tensor(0.1017, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6773\n",
      "Loss: tensor(0.1017, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6774\n",
      "Loss: tensor(0.1017, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6775\n",
      "Loss: tensor(0.1017, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6776\n",
      "Loss: tensor(0.1017, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6777\n",
      "Loss: tensor(0.1017, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6778\n",
      "Loss: tensor(0.1017, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6779\n",
      "Loss: tensor(0.1017, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6780\n",
      "Loss: tensor(0.1017, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6781\n",
      "Loss: tensor(0.1017, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6782\n",
      "Loss: tensor(0.1017, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6783\n",
      "Loss: tensor(0.1017, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6784\n",
      "Loss: tensor(0.1017, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6785\n",
      "Loss: tensor(0.1017, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6786\n",
      "Loss: tensor(0.1017, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6787\n",
      "Loss: tensor(0.1017, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6788\n",
      "Loss: tensor(0.1017, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6789\n",
      "Loss: tensor(0.1017, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6790\n",
      "Loss: tensor(0.1017, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6791\n",
      "Loss: tensor(0.1017, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6792\n",
      "Loss: tensor(0.1017, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6793\n",
      "Loss: tensor(0.1017, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6794\n",
      "Loss: tensor(0.1017, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6795\n",
      "Loss: tensor(0.1017, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6796\n",
      "Loss: tensor(0.1017, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6797\n",
      "Loss: tensor(0.1017, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6798\n",
      "Loss: tensor(0.1017, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6799\n",
      "Loss: tensor(0.1017, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6800\n",
      "Loss: tensor(0.1017, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6801\n",
      "Loss: tensor(0.1017, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6802\n",
      "Loss: tensor(0.1017, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6803\n",
      "Loss: tensor(0.1017, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6804\n",
      "Loss: tensor(0.1017, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6805\n",
      "Loss: tensor(0.1017, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6806\n",
      "Loss: tensor(0.1017, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6807\n",
      "Loss: tensor(0.1017, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6808\n",
      "Loss: tensor(0.1017, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6809\n",
      "Loss: tensor(0.1017, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6810\n",
      "Loss: tensor(0.1017, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6811\n",
      "Loss: tensor(0.1017, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6812\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor(0.1017, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6813\n",
      "Loss: tensor(0.1017, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6814\n",
      "Loss: tensor(0.1017, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6815\n",
      "Loss: tensor(0.1017, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6816\n",
      "Loss: tensor(0.1017, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6817\n",
      "Loss: tensor(0.1017, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6818\n",
      "Loss: tensor(0.1017, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6819\n",
      "Loss: tensor(0.1017, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6820\n",
      "Loss: tensor(0.1017, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6821\n",
      "Loss: tensor(0.1017, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6822\n",
      "Loss: tensor(0.1017, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6823\n",
      "Loss: tensor(0.1017, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6824\n",
      "Loss: tensor(0.1017, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6825\n",
      "Loss: tensor(0.1017, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6826\n",
      "Loss: tensor(0.1017, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6827\n",
      "Loss: tensor(0.1017, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6828\n",
      "Loss: tensor(0.1017, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6829\n",
      "Loss: tensor(0.1017, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6830\n",
      "Loss: tensor(0.1017, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6831\n",
      "Loss: tensor(0.1017, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6832\n",
      "Loss: tensor(0.1017, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6833\n",
      "Loss: tensor(0.1017, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6834\n",
      "Loss: tensor(0.1017, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6835\n",
      "Loss: tensor(0.1017, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6836\n",
      "Loss: tensor(0.1017, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6837\n",
      "Loss: tensor(0.1017, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6838\n",
      "Loss: tensor(0.1017, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6839\n",
      "Loss: tensor(0.1017, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6840\n",
      "Loss: tensor(0.1017, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6841\n",
      "Loss: tensor(0.1017, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6842\n",
      "Loss: tensor(0.1017, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6843\n",
      "Loss: tensor(0.1017, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6844\n",
      "Loss: tensor(0.1017, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6845\n",
      "Loss: tensor(0.1016, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6846\n",
      "Loss: tensor(0.1016, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6847\n",
      "Loss: tensor(0.1016, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6848\n",
      "Loss: tensor(0.1016, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6849\n",
      "Loss: tensor(0.1016, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6850\n",
      "Loss: tensor(0.1016, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6851\n",
      "Loss: tensor(0.1016, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6852\n",
      "Loss: tensor(0.1016, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6853\n",
      "Loss: tensor(0.1016, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6854\n",
      "Loss: tensor(0.1016, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6855\n",
      "Loss: tensor(0.1016, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6856\n",
      "Loss: tensor(0.1016, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6857\n",
      "Loss: tensor(0.1016, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6858\n",
      "Loss: tensor(0.1016, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6859\n",
      "Loss: tensor(0.1016, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6860\n",
      "Loss: tensor(0.1016, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6861\n",
      "Loss: tensor(0.1016, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6862\n",
      "Loss: tensor(0.1016, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6863\n",
      "Loss: tensor(0.1016, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6864\n",
      "Loss: tensor(0.1016, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6865\n",
      "Loss: tensor(0.1016, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6866\n",
      "Loss: tensor(0.1016, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6867\n",
      "Loss: tensor(0.1016, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6868\n",
      "Loss: tensor(0.1016, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6869\n",
      "Loss: tensor(0.1016, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6870\n",
      "Loss: tensor(0.1016, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6871\n",
      "Loss: tensor(0.1016, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6872\n",
      "Loss: tensor(0.1016, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6873\n",
      "Loss: tensor(0.1016, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6874\n",
      "Loss: tensor(0.1016, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6875\n",
      "Loss: tensor(0.1016, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6876\n",
      "Loss: tensor(0.1016, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6877\n",
      "Loss: tensor(0.1016, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6878\n",
      "Loss: tensor(0.1016, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6879\n",
      "Loss: tensor(0.1016, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6880\n",
      "Loss: tensor(0.1016, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6881\n",
      "Loss: tensor(0.1016, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6882\n",
      "Loss: tensor(0.1016, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6883\n",
      "Loss: tensor(0.1016, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6884\n",
      "Loss: tensor(0.1016, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6885\n",
      "Loss: tensor(0.1016, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6886\n",
      "Loss: tensor(0.1016, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6887\n",
      "Loss: tensor(0.1016, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6888\n",
      "Loss: tensor(0.1016, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6889\n",
      "Loss: tensor(0.1016, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6890\n",
      "Loss: tensor(0.1016, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6891\n",
      "Loss: tensor(0.1016, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6892\n",
      "Loss: tensor(0.1016, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6893\n",
      "Loss: tensor(0.1016, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6894\n",
      "Loss: tensor(0.1016, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6895\n",
      "Loss: tensor(0.1016, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6896\n",
      "Loss: tensor(0.1016, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6897\n",
      "Loss: tensor(0.1016, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6898\n",
      "Loss: tensor(0.1016, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6899\n",
      "Loss: tensor(0.1016, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6900\n",
      "Loss: tensor(0.1016, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6901\n",
      "Loss: tensor(0.1016, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6902\n",
      "Loss: tensor(0.1016, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6903\n",
      "Loss: tensor(0.1016, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6904\n",
      "Loss: tensor(0.1016, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6905\n",
      "Loss: tensor(0.1016, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6906\n",
      "Loss: tensor(0.1016, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6907\n",
      "Loss: tensor(0.1016, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6908\n",
      "Loss: tensor(0.1016, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6909\n",
      "Loss: tensor(0.1016, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6910\n",
      "Loss: tensor(0.1016, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6911\n",
      "Loss: tensor(0.1016, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6912\n",
      "Loss: tensor(0.1016, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6913\n",
      "Loss: tensor(0.1016, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6914\n",
      "Loss: tensor(0.1016, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6915\n",
      "Loss: tensor(0.1016, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6916\n",
      "Loss: tensor(0.1016, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6917\n",
      "Loss: tensor(0.1016, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6918\n",
      "Loss: tensor(0.1016, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6919\n",
      "Loss: tensor(0.1016, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6920\n",
      "Loss: tensor(0.1016, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6921\n",
      "Loss: tensor(0.1016, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6922\n",
      "Loss: tensor(0.1016, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6923\n",
      "Loss: tensor(0.1016, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6924\n",
      "Loss: tensor(0.1016, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6925\n",
      "Loss: tensor(0.1016, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6926\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor(0.1016, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6927\n",
      "Loss: tensor(0.1016, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6928\n",
      "Loss: tensor(0.1016, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6929\n",
      "Loss: tensor(0.1016, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6930\n",
      "Loss: tensor(0.1016, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6931\n",
      "Loss: tensor(0.1016, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6932\n",
      "Loss: tensor(0.1016, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6933\n",
      "Loss: tensor(0.1016, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6934\n",
      "Loss: tensor(0.1016, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6935\n",
      "Loss: tensor(0.1015, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6936\n",
      "Loss: tensor(0.1015, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6937\n",
      "Loss: tensor(0.1015, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6938\n",
      "Loss: tensor(0.1015, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6939\n",
      "Loss: tensor(0.1015, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6940\n",
      "Loss: tensor(0.1015, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6941\n",
      "Loss: tensor(0.1015, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6942\n",
      "Loss: tensor(0.1015, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6943\n",
      "Loss: tensor(0.1015, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6944\n",
      "Loss: tensor(0.1015, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6945\n",
      "Loss: tensor(0.1015, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6946\n",
      "Loss: tensor(0.1015, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6947\n",
      "Loss: tensor(0.1015, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6948\n",
      "Loss: tensor(0.1015, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6949\n",
      "Loss: tensor(0.1015, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6950\n",
      "Loss: tensor(0.1015, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6951\n",
      "Loss: tensor(0.1015, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6952\n",
      "Loss: tensor(0.1015, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6953\n",
      "Loss: tensor(0.1015, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6954\n",
      "Loss: tensor(0.1015, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6955\n",
      "Loss: tensor(0.1015, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6956\n",
      "Loss: tensor(0.1015, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6957\n",
      "Loss: tensor(0.1015, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6958\n",
      "Loss: tensor(0.1015, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6959\n",
      "Loss: tensor(0.1015, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6960\n",
      "Loss: tensor(0.1015, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6961\n",
      "Loss: tensor(0.1015, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6962\n",
      "Loss: tensor(0.1015, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6963\n",
      "Loss: tensor(0.1015, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6964\n",
      "Loss: tensor(0.1015, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6965\n",
      "Loss: tensor(0.1015, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6966\n",
      "Loss: tensor(0.1015, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6967\n",
      "Loss: tensor(0.1015, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6968\n",
      "Loss: tensor(0.1015, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6969\n",
      "Loss: tensor(0.1015, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6970\n",
      "Loss: tensor(0.1015, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6971\n",
      "Loss: tensor(0.1015, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6972\n",
      "Loss: tensor(0.1015, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6973\n",
      "Loss: tensor(0.1015, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6974\n",
      "Loss: tensor(0.1015, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6975\n",
      "Loss: tensor(0.1015, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6976\n",
      "Loss: tensor(0.1015, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6977\n",
      "Loss: tensor(0.1015, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6978\n",
      "Loss: tensor(0.1015, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6979\n",
      "Loss: tensor(0.1015, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6980\n",
      "Loss: tensor(0.1015, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6981\n",
      "Loss: tensor(0.1015, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6982\n",
      "Loss: tensor(0.1015, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6983\n",
      "Loss: tensor(0.1015, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6984\n",
      "Loss: tensor(0.1015, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6985\n",
      "Loss: tensor(0.1015, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6986\n",
      "Loss: tensor(0.1015, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6987\n",
      "Loss: tensor(0.1015, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6988\n",
      "Loss: tensor(0.1015, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6989\n",
      "Loss: tensor(0.1015, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6990\n",
      "Loss: tensor(0.1015, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6991\n",
      "Loss: tensor(0.1015, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6992\n",
      "Loss: tensor(0.1015, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6993\n",
      "Loss: tensor(0.1015, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6994\n",
      "Loss: tensor(0.1015, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6995\n",
      "Loss: tensor(0.1015, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6996\n",
      "Loss: tensor(0.1015, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6997\n",
      "Loss: tensor(0.1015, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6998\n",
      "Loss: tensor(0.1015, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6999\n",
      "Loss: tensor(0.1015, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7000\n",
      "Loss: tensor(0.1015, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7001\n",
      "Loss: tensor(0.1015, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7002\n",
      "Loss: tensor(0.1015, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7003\n",
      "Loss: tensor(0.1015, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7004\n",
      "Loss: tensor(0.1015, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7005\n",
      "Loss: tensor(0.1015, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7006\n",
      "Loss: tensor(0.1015, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7007\n",
      "Loss: tensor(0.1015, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7008\n",
      "Loss: tensor(0.1015, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7009\n",
      "Loss: tensor(0.1015, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7010\n",
      "Loss: tensor(0.1015, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7011\n",
      "Loss: tensor(0.1015, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7012\n",
      "Loss: tensor(0.1015, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7013\n",
      "Loss: tensor(0.1015, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7014\n",
      "Loss: tensor(0.1015, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7015\n",
      "Loss: tensor(0.1015, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7016\n",
      "Loss: tensor(0.1015, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7017\n",
      "Loss: tensor(0.1015, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7018\n",
      "Loss: tensor(0.1015, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7019\n",
      "Loss: tensor(0.1015, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7020\n",
      "Loss: tensor(0.1015, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7021\n",
      "Loss: tensor(0.1015, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7022\n",
      "Loss: tensor(0.1015, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7023\n",
      "Loss: tensor(0.1015, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7024\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor(0.1015, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7025\n",
      "Loss: tensor(0.1015, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7026\n",
      "Loss: tensor(0.1015, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7027\n",
      "Loss: tensor(0.1015, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7028\n",
      "Loss: tensor(0.1015, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7029\n",
      "Loss: tensor(0.1014, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7030\n",
      "Loss: tensor(0.1014, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7031\n",
      "Loss: tensor(0.1014, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7032\n",
      "Loss: tensor(0.1014, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7033\n",
      "Loss: tensor(0.1014, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7034\n",
      "Loss: tensor(0.1014, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7035\n",
      "Loss: tensor(0.1014, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7036\n",
      "Loss: tensor(0.1014, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7037\n",
      "Loss: tensor(0.1014, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7038\n",
      "Loss: tensor(0.1014, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7039\n",
      "Loss: tensor(0.1014, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7040\n",
      "Loss: tensor(0.1014, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7041\n",
      "Loss: tensor(0.1014, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7042\n",
      "Loss: tensor(0.1014, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7043\n",
      "Loss: tensor(0.1015, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7044\n",
      "Loss: tensor(0.1015, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7045\n",
      "Loss: tensor(0.1015, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7046\n",
      "Loss: tensor(0.1015, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7047\n",
      "Loss: tensor(0.1014, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7048\n",
      "Loss: tensor(0.1014, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7049\n",
      "Loss: tensor(0.1014, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7050\n",
      "Loss: tensor(0.1014, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7051\n",
      "Loss: tensor(0.1014, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7052\n",
      "Loss: tensor(0.1014, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7053\n",
      "Loss: tensor(0.1014, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7054\n",
      "Loss: tensor(0.1014, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7055\n",
      "Loss: tensor(0.1014, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7056\n",
      "Loss: tensor(0.1014, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7057\n",
      "Loss: tensor(0.1014, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7058\n",
      "Loss: tensor(0.1014, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7059\n",
      "Loss: tensor(0.1014, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7060\n",
      "Loss: tensor(0.1014, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7061\n",
      "Loss: tensor(0.1014, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7062\n",
      "Loss: tensor(0.1014, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7063\n",
      "Loss: tensor(0.1014, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7064\n",
      "Loss: tensor(0.1014, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7065\n",
      "Loss: tensor(0.1014, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7066\n",
      "Loss: tensor(0.1014, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7067\n",
      "Loss: tensor(0.1014, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7068\n",
      "Loss: tensor(0.1014, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7069\n",
      "Loss: tensor(0.1014, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7070\n",
      "Loss: tensor(0.1014, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7071\n",
      "Loss: tensor(0.1014, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7072\n",
      "Loss: tensor(0.1014, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7073\n",
      "Loss: tensor(0.1014, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7074\n",
      "Loss: tensor(0.1014, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7075\n",
      "Loss: tensor(0.1014, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7076\n",
      "Loss: tensor(0.1014, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7077\n",
      "Loss: tensor(0.1014, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7078\n",
      "Loss: tensor(0.1014, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7079\n",
      "Loss: tensor(0.1014, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7080\n",
      "Loss: tensor(0.1014, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7081\n",
      "Loss: tensor(0.1014, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7082\n",
      "Loss: tensor(0.1014, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7083\n",
      "Loss: tensor(0.1014, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7084\n",
      "Loss: tensor(0.1014, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7085\n",
      "Loss: tensor(0.1014, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7086\n",
      "Loss: tensor(0.1014, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7087\n",
      "Loss: tensor(0.1014, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7088\n",
      "Loss: tensor(0.1014, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7089\n",
      "Loss: tensor(0.1014, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7090\n",
      "Loss: tensor(0.1014, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7091\n",
      "Loss: tensor(0.1014, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7092\n",
      "Loss: tensor(0.1014, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7093\n",
      "Loss: tensor(0.1014, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7094\n",
      "Loss: tensor(0.1014, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7095\n",
      "Loss: tensor(0.1014, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7096\n",
      "Loss: tensor(0.1014, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7097\n",
      "Loss: tensor(0.1014, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7098\n",
      "Loss: tensor(0.1014, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7099\n",
      "Loss: tensor(0.1014, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7100\n",
      "Loss: tensor(0.1014, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7101\n",
      "Loss: tensor(0.1014, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7102\n",
      "Loss: tensor(0.1014, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7103\n",
      "Loss: tensor(0.1014, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7104\n",
      "Loss: tensor(0.1014, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7105\n",
      "Loss: tensor(0.1014, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7106\n",
      "Loss: tensor(0.1014, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7107\n",
      "Loss: tensor(0.1014, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7108\n",
      "Loss: tensor(0.1014, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7109\n",
      "Loss: tensor(0.1014, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7110\n",
      "Loss: tensor(0.1014, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7111\n",
      "Loss: tensor(0.1014, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7112\n",
      "Loss: tensor(0.1014, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7113\n",
      "Loss: tensor(0.1014, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7114\n",
      "Loss: tensor(0.1014, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7115\n",
      "Loss: tensor(0.1014, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7116\n",
      "Loss: tensor(0.1014, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7117\n",
      "Loss: tensor(0.1014, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7118\n",
      "Loss: tensor(0.1014, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7119\n",
      "Loss: tensor(0.1014, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7120\n",
      "Loss: tensor(0.1014, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7121\n",
      "Loss: tensor(0.1014, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7122\n",
      "Loss: tensor(0.1014, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7123\n",
      "Loss: tensor(0.1014, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7124\n",
      "Loss: tensor(0.1014, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7125\n",
      "Loss: tensor(0.1014, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7126\n",
      "Loss: tensor(0.1014, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7127\n",
      "Loss: tensor(0.1014, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7128\n",
      "Loss: tensor(0.1014, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7129\n",
      "Loss: tensor(0.1014, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7130\n",
      "Loss: tensor(0.1014, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7131\n",
      "Loss: tensor(0.1014, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7132\n",
      "Loss: tensor(0.1014, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7133\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor(0.1014, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7134\n",
      "Loss: tensor(0.1014, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7135\n",
      "Loss: tensor(0.1013, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7136\n",
      "Loss: tensor(0.1013, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7137\n",
      "Loss: tensor(0.1013, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7138\n",
      "Loss: tensor(0.1013, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7139\n",
      "Loss: tensor(0.1013, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7140\n",
      "Loss: tensor(0.1013, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7141\n",
      "Loss: tensor(0.1013, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7142\n",
      "Loss: tensor(0.1013, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7143\n",
      "Loss: tensor(0.1013, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7144\n",
      "Loss: tensor(0.1013, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7145\n",
      "Loss: tensor(0.1013, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7146\n",
      "Loss: tensor(0.1013, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7147\n",
      "Loss: tensor(0.1013, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7148\n",
      "Loss: tensor(0.1013, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7149\n",
      "Loss: tensor(0.1013, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7150\n",
      "Loss: tensor(0.1013, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7151\n",
      "Loss: tensor(0.1013, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7152\n",
      "Loss: tensor(0.1013, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7153\n",
      "Loss: tensor(0.1013, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7154\n",
      "Loss: tensor(0.1013, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7155\n",
      "Loss: tensor(0.1013, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7156\n",
      "Loss: tensor(0.1013, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7157\n",
      "Loss: tensor(0.1013, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7158\n",
      "Loss: tensor(0.1013, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7159\n",
      "Loss: tensor(0.1013, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7160\n",
      "Loss: tensor(0.1013, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7161\n",
      "Loss: tensor(0.1013, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7162\n",
      "Loss: tensor(0.1013, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7163\n",
      "Loss: tensor(0.1013, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7164\n",
      "Loss: tensor(0.1013, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7165\n",
      "Loss: tensor(0.1013, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7166\n",
      "Loss: tensor(0.1013, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7167\n",
      "Loss: tensor(0.1013, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7168\n",
      "Loss: tensor(0.1013, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7169\n",
      "Loss: tensor(0.1013, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7170\n",
      "Loss: tensor(0.1013, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7171\n",
      "Loss: tensor(0.1013, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7172\n",
      "Loss: tensor(0.1013, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7173\n",
      "Loss: tensor(0.1013, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7174\n",
      "Loss: tensor(0.1013, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7175\n",
      "Loss: tensor(0.1013, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7176\n",
      "Loss: tensor(0.1013, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7177\n",
      "Loss: tensor(0.1013, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7178\n",
      "Loss: tensor(0.1013, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7179\n",
      "Loss: tensor(0.1013, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7180\n",
      "Loss: tensor(0.1013, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7181\n",
      "Loss: tensor(0.1013, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7182\n",
      "Loss: tensor(0.1013, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7183\n",
      "Loss: tensor(0.1013, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7184\n",
      "Loss: tensor(0.1013, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7185\n",
      "Loss: tensor(0.1013, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7186\n",
      "Loss: tensor(0.1013, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7187\n",
      "Loss: tensor(0.1013, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7188\n",
      "Loss: tensor(0.1013, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7189\n",
      "Loss: tensor(0.1013, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7190\n",
      "Loss: tensor(0.1013, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7191\n",
      "Loss: tensor(0.1013, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7192\n",
      "Loss: tensor(0.1013, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7193\n",
      "Loss: tensor(0.1013, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7194\n",
      "Loss: tensor(0.1013, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7195\n",
      "Loss: tensor(0.1013, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7196\n",
      "Loss: tensor(0.1013, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7197\n",
      "Loss: tensor(0.1013, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7198\n",
      "Loss: tensor(0.1013, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7199\n",
      "Loss: tensor(0.1013, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7200\n",
      "Loss: tensor(0.1013, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7201\n",
      "Loss: tensor(0.1013, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7202\n",
      "Loss: tensor(0.1013, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7203\n",
      "Loss: tensor(0.1013, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7204\n",
      "Loss: tensor(0.1013, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7205\n",
      "Loss: tensor(0.1013, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7206\n",
      "Loss: tensor(0.1013, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7207\n",
      "Loss: tensor(0.1013, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7208\n",
      "Loss: tensor(0.1013, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7209\n",
      "Loss: tensor(0.1013, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7210\n",
      "Loss: tensor(0.1013, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7211\n",
      "Loss: tensor(0.1013, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7212\n",
      "Loss: tensor(0.1013, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7213\n",
      "Loss: tensor(0.1013, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7214\n",
      "Loss: tensor(0.1013, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7215\n",
      "Loss: tensor(0.1013, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7216\n",
      "Loss: tensor(0.1013, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7217\n",
      "Loss: tensor(0.1013, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7218\n",
      "Loss: tensor(0.1013, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7219\n",
      "Loss: tensor(0.1013, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7220\n",
      "Loss: tensor(0.1013, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7221\n",
      "Loss: tensor(0.1013, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7222\n",
      "Loss: tensor(0.1013, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7223\n",
      "Loss: tensor(0.1013, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7224\n",
      "Loss: tensor(0.1013, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7225\n",
      "Loss: tensor(0.1013, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7226\n",
      "Loss: tensor(0.1013, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7227\n",
      "Loss: tensor(0.1013, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7228\n",
      "Loss: tensor(0.1013, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7229\n",
      "Loss: tensor(0.1013, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7230\n",
      "Loss: tensor(0.1013, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7231\n",
      "Loss: tensor(0.1013, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7232\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor(0.1013, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7233\n",
      "Loss: tensor(0.1013, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7234\n",
      "Loss: tensor(0.1013, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7235\n",
      "Loss: tensor(0.1013, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7236\n",
      "Loss: tensor(0.1013, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7237\n",
      "Loss: tensor(0.1013, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7238\n",
      "Loss: tensor(0.1013, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7239\n",
      "Loss: tensor(0.1013, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7240\n",
      "Loss: tensor(0.1013, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7241\n",
      "Loss: tensor(0.1013, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7242\n",
      "Loss: tensor(0.1013, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7243\n",
      "Loss: tensor(0.1013, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7244\n",
      "Loss: tensor(0.1013, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7245\n",
      "Loss: tensor(0.1013, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7246\n",
      "Loss: tensor(0.1013, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7247\n",
      "Loss: tensor(0.1013, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7248\n",
      "Loss: tensor(0.1013, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7249\n",
      "Loss: tensor(0.1013, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7250\n",
      "Loss: tensor(0.1013, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7251\n",
      "Loss: tensor(0.1013, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7252\n",
      "Loss: tensor(0.1013, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7253\n",
      "Loss: tensor(0.1013, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7254\n",
      "Loss: tensor(0.1012, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7255\n",
      "Loss: tensor(0.1012, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7256\n",
      "Loss: tensor(0.1012, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7257\n",
      "Loss: tensor(0.1012, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7258\n",
      "Loss: tensor(0.1012, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7259\n",
      "Loss: tensor(0.1012, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7260\n",
      "Loss: tensor(0.1012, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7261\n",
      "Loss: tensor(0.1012, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7262\n",
      "Loss: tensor(0.1012, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7263\n",
      "Loss: tensor(0.1012, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7264\n",
      "Loss: tensor(0.1012, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7265\n",
      "Loss: tensor(0.1012, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7266\n",
      "Loss: tensor(0.1012, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7267\n",
      "Loss: tensor(0.1012, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7268\n",
      "Loss: tensor(0.1012, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7269\n",
      "Loss: tensor(0.1012, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7270\n",
      "Loss: tensor(0.1012, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7271\n",
      "Loss: tensor(0.1012, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7272\n",
      "Loss: tensor(0.1012, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7273\n",
      "Loss: tensor(0.1012, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7274\n",
      "Loss: tensor(0.1012, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7275\n",
      "Loss: tensor(0.1012, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7276\n",
      "Loss: tensor(0.1012, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7277\n",
      "Loss: tensor(0.1012, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7278\n",
      "Loss: tensor(0.1012, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7279\n",
      "Loss: tensor(0.1012, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7280\n",
      "Loss: tensor(0.1012, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7281\n",
      "Loss: tensor(0.1012, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7282\n",
      "Loss: tensor(0.1012, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7283\n",
      "Loss: tensor(0.1012, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7284\n",
      "Loss: tensor(0.1012, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7285\n",
      "Loss: tensor(0.1012, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7286\n",
      "Loss: tensor(0.1012, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7287\n",
      "Loss: tensor(0.1012, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7288\n",
      "Loss: tensor(0.1012, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7289\n",
      "Loss: tensor(0.1012, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7290\n",
      "Loss: tensor(0.1012, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7291\n",
      "Loss: tensor(0.1012, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7292\n",
      "Loss: tensor(0.1012, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7293\n",
      "Loss: tensor(0.1012, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7294\n",
      "Loss: tensor(0.1012, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7295\n",
      "Loss: tensor(0.1012, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7296\n",
      "Loss: tensor(0.1012, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7297\n",
      "Loss: tensor(0.1012, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7298\n",
      "Loss: tensor(0.1012, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7299\n",
      "Loss: tensor(0.1012, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7300\n",
      "Loss: tensor(0.1012, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7301\n",
      "Loss: tensor(0.1012, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7302\n",
      "Loss: tensor(0.1012, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7303\n",
      "Loss: tensor(0.1012, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7304\n",
      "Loss: tensor(0.1012, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7305\n",
      "Loss: tensor(0.1012, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7306\n",
      "Loss: tensor(0.1012, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7307\n",
      "Loss: tensor(0.1012, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7308\n",
      "Loss: tensor(0.1012, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7309\n",
      "Loss: tensor(0.1012, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7310\n",
      "Loss: tensor(0.1012, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7311\n",
      "Loss: tensor(0.1012, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7312\n",
      "Loss: tensor(0.1012, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7313\n",
      "Loss: tensor(0.1012, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7314\n",
      "Loss: tensor(0.1012, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7315\n",
      "Loss: tensor(0.1012, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7316\n",
      "Loss: tensor(0.1012, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7317\n",
      "Loss: tensor(0.1012, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7318\n",
      "Loss: tensor(0.1012, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7319\n",
      "Loss: tensor(0.1012, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7320\n",
      "Loss: tensor(0.1012, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7321\n",
      "Loss: tensor(0.1012, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7322\n",
      "Loss: tensor(0.1012, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7323\n",
      "Loss: tensor(0.1012, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7324\n",
      "Loss: tensor(0.1012, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7325\n",
      "Loss: tensor(0.1012, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7326\n",
      "Loss: tensor(0.1012, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7327\n",
      "Loss: tensor(0.1012, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7328\n",
      "Loss: tensor(0.1012, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7329\n",
      "Loss: tensor(0.1012, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7330\n",
      "Loss: tensor(0.1012, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7331\n",
      "Loss: tensor(0.1012, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7332\n",
      "Loss: tensor(0.1012, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7333\n",
      "Loss: tensor(0.1012, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7334\n",
      "Loss: tensor(0.1012, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7335\n",
      "Loss: tensor(0.1012, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7336\n",
      "Loss: tensor(0.1012, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7337\n",
      "Loss: tensor(0.1012, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7338\n",
      "Loss: tensor(0.1012, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7339\n",
      "Loss: tensor(0.1012, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7340\n",
      "Loss: tensor(0.1012, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7341\n",
      "Loss: tensor(0.1012, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7342\n",
      "Loss: tensor(0.1012, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7343\n",
      "Loss: tensor(0.1012, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7344\n",
      "Loss: tensor(0.1012, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7345\n",
      "Loss: tensor(0.1012, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7346\n",
      "Loss: tensor(0.1012, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7347\n",
      "Loss: tensor(0.1012, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7348\n",
      "Loss: tensor(0.1012, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7349\n",
      "Loss: tensor(0.1012, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7350\n",
      "Loss: tensor(0.1012, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7351\n",
      "Loss: tensor(0.1012, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7352\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor(0.1012, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7353\n",
      "Loss: tensor(0.1012, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7354\n",
      "Loss: tensor(0.1012, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7355\n",
      "Loss: tensor(0.1012, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7356\n",
      "Loss: tensor(0.1012, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7357\n",
      "Loss: tensor(0.1012, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7358\n",
      "Loss: tensor(0.1012, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7359\n",
      "Loss: tensor(0.1012, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7360\n",
      "Loss: tensor(0.1012, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7361\n",
      "Loss: tensor(0.1012, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7362\n",
      "Loss: tensor(0.1012, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7363\n",
      "Loss: tensor(0.1012, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7364\n",
      "Loss: tensor(0.1012, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7365\n",
      "Loss: tensor(0.1012, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7366\n",
      "Loss: tensor(0.1012, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7367\n",
      "Loss: tensor(0.1012, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7368\n",
      "Loss: tensor(0.1012, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7369\n",
      "Loss: tensor(0.1012, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7370\n",
      "Loss: tensor(0.1012, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7371\n",
      "Loss: tensor(0.1011, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7372\n",
      "Loss: tensor(0.1011, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7373\n",
      "Loss: tensor(0.1011, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7374\n",
      "Loss: tensor(0.1011, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7375\n",
      "Loss: tensor(0.1011, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7376\n",
      "Loss: tensor(0.1011, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7377\n",
      "Loss: tensor(0.1011, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7378\n",
      "Loss: tensor(0.1011, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7379\n",
      "Loss: tensor(0.1011, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7380\n",
      "Loss: tensor(0.1011, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7381\n",
      "Loss: tensor(0.1011, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7382\n",
      "Loss: tensor(0.1011, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7383\n",
      "Loss: tensor(0.1011, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7384\n",
      "Loss: tensor(0.1011, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7385\n",
      "Loss: tensor(0.1011, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7386\n",
      "Loss: tensor(0.1011, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7387\n",
      "Loss: tensor(0.1011, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7388\n",
      "Loss: tensor(0.1011, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7389\n",
      "Loss: tensor(0.1011, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7390\n",
      "Loss: tensor(0.1011, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7391\n",
      "Loss: tensor(0.1011, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7392\n",
      "Loss: tensor(0.1011, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7393\n",
      "Loss: tensor(0.1011, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7394\n",
      "Loss: tensor(0.1011, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7395\n",
      "Loss: tensor(0.1011, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7396\n",
      "Loss: tensor(0.1011, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7397\n",
      "Loss: tensor(0.1011, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7398\n",
      "Loss: tensor(0.1011, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7399\n",
      "Loss: tensor(0.1011, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7400\n",
      "Loss: tensor(0.1011, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7401\n",
      "Loss: tensor(0.1011, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7402\n",
      "Loss: tensor(0.1011, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7403\n",
      "Loss: tensor(0.1011, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7404\n",
      "Loss: tensor(0.1011, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7405\n",
      "Loss: tensor(0.1011, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7406\n",
      "Loss: tensor(0.1011, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7407\n",
      "Loss: tensor(0.1011, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7408\n",
      "Loss: tensor(0.1011, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7409\n",
      "Loss: tensor(0.1011, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7410\n",
      "Loss: tensor(0.1011, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7411\n",
      "Loss: tensor(0.1011, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7412\n",
      "Loss: tensor(0.1011, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7413\n",
      "Loss: tensor(0.1011, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7414\n",
      "Loss: tensor(0.1011, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7415\n",
      "Loss: tensor(0.1011, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7416\n",
      "Loss: tensor(0.1011, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7417\n",
      "Loss: tensor(0.1011, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7418\n",
      "Loss: tensor(0.1011, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7419\n",
      "Loss: tensor(0.1011, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7420\n",
      "Loss: tensor(0.1011, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7421\n",
      "Loss: tensor(0.1011, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7422\n",
      "Loss: tensor(0.1011, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7423\n",
      "Loss: tensor(0.1011, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7424\n",
      "Loss: tensor(0.1011, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7425\n",
      "Loss: tensor(0.1011, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7426\n",
      "Loss: tensor(0.1011, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7427\n",
      "Loss: tensor(0.1011, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7428\n",
      "Loss: tensor(0.1011, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7429\n",
      "Loss: tensor(0.1011, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7430\n",
      "Loss: tensor(0.1011, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7431\n",
      "Loss: tensor(0.1011, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7432\n",
      "Loss: tensor(0.1011, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7433\n",
      "Loss: tensor(0.1011, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7434\n",
      "Loss: tensor(0.1011, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7435\n",
      "Loss: tensor(0.1011, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7436\n",
      "Loss: tensor(0.1011, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7437\n",
      "Loss: tensor(0.1011, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7438\n",
      "Loss: tensor(0.1011, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7439\n",
      "Loss: tensor(0.1011, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7440\n",
      "Loss: tensor(0.1011, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7441\n",
      "Loss: tensor(0.1011, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7442\n",
      "Loss: tensor(0.1011, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7443\n",
      "Loss: tensor(0.1011, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7444\n",
      "Loss: tensor(0.1011, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7445\n",
      "Loss: tensor(0.1011, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7446\n",
      "Loss: tensor(0.1011, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7447\n",
      "Loss: tensor(0.1011, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7448\n",
      "Loss: tensor(0.1011, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7449\n",
      "Loss: tensor(0.1011, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7450\n",
      "Loss: tensor(0.1011, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7451\n",
      "Loss: tensor(0.1011, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7452\n",
      "Loss: tensor(0.1011, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7453\n",
      "Loss: tensor(0.1011, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7454\n",
      "Loss: tensor(0.1011, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7455\n",
      "Loss: tensor(0.1011, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7456\n",
      "Loss: tensor(0.1011, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7457\n",
      "Loss: tensor(0.1011, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7458\n",
      "Loss: tensor(0.1011, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7459\n",
      "Loss: tensor(0.1011, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7460\n",
      "Loss: tensor(0.1011, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7461\n",
      "Loss: tensor(0.1011, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7462\n",
      "Loss: tensor(0.1011, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7463\n",
      "Loss: tensor(0.1011, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7464\n",
      "Loss: tensor(0.1011, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7465\n",
      "Loss: tensor(0.1011, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7466\n",
      "Loss: tensor(0.1011, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7467\n",
      "Loss: tensor(0.1011, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7468\n",
      "Loss: tensor(0.1011, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7469\n",
      "Loss: tensor(0.1011, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7470\n",
      "Loss: tensor(0.1011, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7471\n",
      "Loss: tensor(0.1011, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7472\n",
      "Loss: tensor(0.1011, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7473\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor(0.1011, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7474\n",
      "Loss: tensor(0.1011, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7475\n",
      "Loss: tensor(0.1011, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7476\n",
      "Loss: tensor(0.1011, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7477\n",
      "Loss: tensor(0.1011, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7478\n",
      "Loss: tensor(0.1011, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7479\n",
      "Loss: tensor(0.1011, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7480\n",
      "Loss: tensor(0.1011, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7481\n",
      "Loss: tensor(0.1011, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7482\n",
      "Loss: tensor(0.1011, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7483\n",
      "Loss: tensor(0.1011, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7484\n",
      "Loss: tensor(0.1011, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7485\n",
      "Loss: tensor(0.1011, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7486\n",
      "Loss: tensor(0.1011, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7487\n",
      "Loss: tensor(0.1011, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7488\n",
      "Loss: tensor(0.1011, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7489\n",
      "Loss: tensor(0.1011, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7490\n",
      "Loss: tensor(0.1011, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7491\n",
      "Loss: tensor(0.1011, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7492\n",
      "Loss: tensor(0.1011, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7493\n",
      "Loss: tensor(0.1011, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7494\n",
      "Loss: tensor(0.1011, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7495\n",
      "Loss: tensor(0.1011, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7496\n",
      "Loss: tensor(0.1011, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7497\n",
      "Loss: tensor(0.1011, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7498\n",
      "Loss: tensor(0.1011, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7499\n",
      "Loss: tensor(0.1011, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7500\n",
      "Loss: tensor(0.1011, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7501\n",
      "Loss: tensor(0.1011, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7502\n",
      "Loss: tensor(0.1011, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7503\n",
      "Loss: tensor(0.1011, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7504\n",
      "Loss: tensor(0.1011, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7505\n",
      "Loss: tensor(0.1011, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7506\n",
      "Loss: tensor(0.1011, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7507\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7508\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7509\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7510\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7511\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7512\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7513\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7514\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7515\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7516\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7517\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7518\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7519\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7520\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7521\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7522\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7523\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7524\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7525\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7526\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7527\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7528\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7529\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7530\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7531\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7532\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7533\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7534\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7535\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7536\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7537\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7538\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7539\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7540\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7541\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7542\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7543\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7544\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7545\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7546\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7547\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7548\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7549\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7550\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7551\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7552\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7553\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7554\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7555\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7556\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7557\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7558\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7559\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7560\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7561\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7562\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7563\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7564\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7565\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7566\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7567\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7568\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7569\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7570\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7571\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7572\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7573\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7574\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7575\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7576\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7577\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7578\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7579\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7580\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7581\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7582\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7583\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7584\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7585\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7586\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7587\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7588\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7589\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7590\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7591\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7592\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7593\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7594\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7595\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7596\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7597\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7598\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7599\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7600\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7601\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7602\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7603\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7604\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7605\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7606\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7607\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7608\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7609\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7610\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7611\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7612\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7613\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7614\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7615\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7616\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7617\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7618\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7619\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7620\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7621\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7622\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7623\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7624\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7625\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7626\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7627\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7628\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7629\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7630\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7631\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7632\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7633\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7634\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7635\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7636\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7637\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7638\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7639\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7640\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7641\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7642\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7643\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7644\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7645\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7646\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7647\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7648\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7649\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7650\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7651\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7652\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7653\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7654\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7655\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7656\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7657\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7658\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7659\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7660\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7661\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7662\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7663\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7664\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7665\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7666\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7667\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7668\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7669\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7670\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7671\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7672\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7673\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7674\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7675\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7676\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7677\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7678\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7679\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7680\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7681\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7682\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7683\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7684\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7685\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7686\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7687\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7688\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7689\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7690\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7691\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7692\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7693\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7694\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7695\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7696\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7697\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7698\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7699\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7700\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7701\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7702\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7703\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7704\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7705\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7706\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7707\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7708\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7709\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7710\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7711\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7712\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7713\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7714\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7715\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7716\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7717\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7718\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7719\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7720\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7721\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7722\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7723\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7724\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7725\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7726\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7727\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7728\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7729\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7730\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7731\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7732\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7733\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7734\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7735\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7736\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7737\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7738\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7739\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7740\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7741\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7742\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7743\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7744\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7745\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7746\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7747\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7748\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7749\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7750\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7751\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7752\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7753\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7754\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7755\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7756\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7757\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7758\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7759\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7760\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7761\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7762\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7763\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7764\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7765\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7766\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7767\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7768\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7769\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7770\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7771\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7772\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7773\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7774\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7775\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7776\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7777\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7778\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7779\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7780\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7781\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7782\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7783\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7784\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7785\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7786\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7787\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7788\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7789\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7790\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7791\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7792\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7793\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7794\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7795\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7796\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7797\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7798\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7799\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7800\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7801\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7802\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7803\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7804\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7805\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7806\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7807\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7808\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7809\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7810\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7811\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7812\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7813\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7814\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7815\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7816\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7817\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7818\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7819\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7820\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7821\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7822\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7823\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7824\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7825\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7826\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7827\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7828\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7829\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7830\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7831\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7832\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7833\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7834\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7835\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7836\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7837\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7838\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7839\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7840\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7841\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7842\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7843\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7844\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7845\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7846\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7847\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7848\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7849\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7850\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7851\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7852\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7853\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7854\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7855\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7856\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7857\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7858\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7859\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7860\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7861\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7862\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7863\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7864\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7865\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7866\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7867\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7868\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7869\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7870\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7871\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7872\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7873\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7874\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7875\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7876\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7877\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7878\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7879\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7880\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7881\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7882\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7883\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7884\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7885\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7886\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7887\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7888\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7889\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7890\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7891\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7892\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7893\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7894\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7895\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7896\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7897\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7898\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7899\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7900\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7901\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7902\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7903\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7904\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7905\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7906\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7907\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7908\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7909\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7910\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7911\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7912\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7913\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7914\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7915\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7916\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7917\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7918\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7919\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7920\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7921\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7922\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7923\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7924\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7925\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7926\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7927\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7928\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7929\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7930\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7931\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7932\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7933\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7934\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7935\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7936\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7937\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7938\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7939\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7940\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7941\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7942\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7943\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7944\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7945\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7946\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7947\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7948\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7949\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7950\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7951\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7952\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7953\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7954\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7955\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7956\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7957\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7958\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7959\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7960\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7961\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7962\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7963\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7964\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7965\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7966\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7967\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7968\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7969\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7970\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7971\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7972\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7973\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7974\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7975\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7976\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7977\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7978\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7979\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7980\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7981\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7982\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7983\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7984\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7985\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7986\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7987\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7988\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7989\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7990\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7991\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7992\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7993\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7994\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7995\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7996\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7997\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7998\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7999\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(500):  \n",
    "        \n",
    "    optimizer.zero_grad()   # zero the gradient buffers\n",
    "    output = net(input.float())\n",
    "\n",
    "    loss = criterion(output, targets)\n",
    "    print('Loss:', loss, ' at epoch:', epoch)\n",
    "\n",
    "    loss.backward()  #backprop\n",
    "    optimizer.step()    # Does the update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the FCNN model\n",
    "\n",
    "stage='NNetwork/'\n",
    "SavesDirectory='./TunedModels/'+model_class+'/'+model_version+\"/\"+stage\n",
    "#PATH = SavesDirectory+'Tanh_MSE_adam4645.pth'\n",
    "\n",
    "torch.save(net.state_dict(), PATH)\n",
    "\n",
    "# more on saving pytorch networks: https://pytorch.org/docs/stable/notes/serialization.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load previously saved FCNN model \n",
    "\n",
    "stage='NNetwork/'\n",
    "SavesDirectory='./TunedModels/'+model_class+'/'+model_version+\"/\"+stage\n",
    "#PATH = SavesDirectory+'Tanh_MSE_adam21.pth'\n",
    "\n",
    "net = Net()\n",
    "net.load_state_dict(torch.load(PATH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0050, 0.0100, 0.0050,  ..., 0.4244, 0.4128, 0.2757],\n",
       "        [0.0000, 0.0000, 0.0000,  ..., 0.4248, 0.4120, 0.2759],\n",
       "        [0.0200, 0.0250, 0.0600,  ..., 0.4247, 0.4130, 0.2773],\n",
       "        ...,\n",
       "        [0.0100, 0.0050, 0.0250,  ..., 0.4227, 0.4129, 0.2743],\n",
       "        [0.2200, 0.0950, 0.0350,  ..., 0.4266, 0.4102, 0.2756],\n",
       "        [0.0050, 0.0600, 0.0100,  ..., 0.4263, 0.4101, 0.2760]],\n",
       "       dtype=torch.float64)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the test data\n",
    "\n",
    "TestData=pd.read_excel('testReputation.xlsx' )\n",
    "TestData=TestData.iloc[:,:-2].astype(float)\n",
    "TestData=TestData/200\n",
    "\n",
    "SavesDirectory='./TunedModels/'+model_class+'/'+model_version+\"/Saves/\"\n",
    "TF_Output=pd.read_csv( SavesDirectory+'testOut.tsv', sep='\\t')\n",
    "\n",
    "TestData=pd.concat([TestData,TF_Output], axis=1)\n",
    "\n",
    "\n",
    "TestData=torch.tensor(TestData.values)\n",
    "TestData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0, 0, 0, 1, 0],\n",
       "        [0, 0, 0, 1, 0, 0],\n",
       "        [0, 1, 0, 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 1, 0, 0, 0],\n",
       "        [1, 0, 0, 0, 0, 0],\n",
       "        [0, 1, 0, 0, 0, 0]], dtype=torch.uint8)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels=pd.read_excel('testReputation.xlsx' )\n",
    "labels=labels.iloc[:,-1] \n",
    "labelsOneHot=pd.get_dummies(labels)\n",
    "\n",
    "TestLables =torch.tensor(labelsOneHot.values)\n",
    "TestLables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 3 2 1 1 1 3 4 4 4 4 3 3 4 3 3 1 3 1 4 4 4 3 1 1 4 1 3 3 4 4 1 0 4 4 1 4 4 4 4 3 1 4 1 4 4 3 4 4 4 4 1 1 3 3 4 5 5 4 1 1 1 4 3 1 4 3 3 4 4 1 4 1 1 1 1 1 1 4 4 1 1 1 4 1 1 4 4 1 4 4 4 3 1 2 4 4 1 3 1 4 0 4 3 3 1 1 3 1 3 1 3 3 3 1 1 0 4 1 2 2 4 4 3 1 1 1 1 5 1 3 2 3 1 1 2 0 2 2 1 4 1 3 3 3 4 4 3 4 3 0 1 1 3 5 3 4 5 3 3 3 1 4 4 3 5 4 2 3 1 3 3 4 5 3 1 3 4 0 2 1 3 4 5 1 3 2 4 1 3 5 2 4 0 1 3 2 2 3 1 1 4 5 3 4 3 3 5 1 3 3 3 3 1 4 1 2 3 3 1 1 1 4 1 1 5 3 2 3 0 5 1 0 1 1 5 4 0 4 2 2 1 2 4 4 1 2 1 3 3 0 3 4 1 3 3 4 0 4 1 2 1 1 2 0 3 1 3 4 2 3 4 1 2 5 2 5 1 2 4 2 1 4 5 1 4 3 1 5 0 3 5 1 3 1 1 3 4 2 3 1 5 3 3 5 3 2 5 3 1 1 3 1 3 3 4 5 3 3 3 4 1 5 1 3 0 5 1 5 4 4 3 3 3 5 1 1 3 3 2 4 2 3 3 3 5 2 5 5 1 1 0 4 1 4 1 1 3 1 2 1 1 1 1 2 0 3 5 2 1 0 1 4 4 4 3 3 5 2 1 3 1 3 4 3 3 3 3 1 4 3 2 1 1 2 1 3 4 3 4 4 3 0 1 4 5 2 3 3 3 4 2 4 1 2 1 1 5 3 3 4 4 4 1 1 3 4 3 4 3 5 1 2 1 2 5 3 4 4 1 5 4 4 1 3 1 3 2 2 3 1 3 1 1 4 3 4 3 1 1 5 1 3 4 4 3 1 3 1 3 3 4 1 0 3 3 3 1 3 3 2 3 1 3 4 1 2 4 3 1 1 3 5 3 3 3 3 4 3 4 3 4 1 3 4 3 5 0 4 3 1 5 2 1 1 5 4 3 1 5 5 3 2 1 1 4 4 3 1 5 1 0 0 1 1 4 3 1 3 5 2 5 4 2 1 3 0 5 3 1 1 3 1 2 3 5 4 2 2 1 3 1 4 1 0 1 2 4 1 1 3 3 5 0 2 3 3 4 3 4 1 3 3 1 2 3 3 3 3 1 4 2 3 2 1 4 3 4 4 3 5 4 2 4 1 3 1 1 4 4 1 5 4 2 4 5 4 3 1 4 2 2 3 1 2 4 4 5 4 0 0 2 3 4 3 1 4 4 2 2 2 3 3 3 3 4 4 2 3 2 3 2 3 2 1 3 1 1 4 3 5 2 1 5 3 4 4 3 4 0 4 4 5 3 2 4 1 1 3 3 5 1 4 3 3 2 3 3 2 4 2 5 3 4 3 4 4 4 4 0 4 2 4 1 4 3 3 3 1 2 4 4 3 4 3 5 5 1 1 4 1 4 4 4 4 4 4 5 3 1 3 2 1 4 4 3 3 4 1 1 3 4 4 4 3 2 4 0 3 0 3 4 4 3 1 5 4 1 1 3 2 5 1 1 1 4 1 1 1 2 2 4 3 4 2 2 1 5 3 4 3 3 5 2 0 5 2 1 2 4 4 1 5 4 5 3 1 2 5 3 5 1 1 1 5 1 0 2 3 5 1 4 5 4 3 1 5 4 0 4 1 5 3 4 3 4 3 3 3 3 4 3 4 5 1 1 4 5 0 2 4 4 3 3 4 3 4 0 3 5 0 3 3 0 4 3 3 3 0 5 4 4 5 1 1 1 3 3 0 0 4 5 1 0 0 1 3 0 1 4 4 1 2 3 3 3 5 4 3 4 4 2 1 4 4 1 3 4 3 2 1 4 1 2 2 1 4 2 5 5 3 0 3 2 2 4 4 0 0 2 3 3 1 3 3 5 3 2 1 2 2 1 4 2 3 3 3 1 1 2 4 4 1 1 4 3 5 3 0 5 3 3 1 4 3 3 2 4 5 5 0 3 3 3 5 5 1 2 3 1 2 1 0 4 4 4 4 4 4 4 5 2 4 4 4 4 4 1 4 3 2 2 5 4 4 4 1 1 5 3 1 4 4 1 1 3 0 3 1 2 3 1 2 3 3 4 1 3 5 1 4 0 5 3 5 1 4 3 2 0 3 4 5 1 5 4 1 3 4 4 4 3 5 1 4 4 5 3 0 1 1 0 4 3 4 5 3 5 0 1 2 0 4 4 3 0 2 1 2 3 3 3 3 4 4 0 3 5 1 1 0 3 3 4 3 4 1 4 2 2 4 5 4 1 2 2 4 1 2 1 4 4 4 2 1 3 2 1 1 4 5 3 0 2 1 2 2 5 2 1 3 1 4 5 1 2 3 2 3 1 4 5 2 2 3 1 1 4 4 4 5 2 2 3 2 4 3 1 0 3 4 3 1 4 2 4 4 4 4 4 2 4 2 2 2 4 1 1 5 5 3 3 4 1 4 2 0 2 4 1 4 4 1 1 3 0 2 4 4 4 2 1 4 4 1 0 4 3 3 3 1 1 4 4 1 2 4 3 1 1 5 1 4 2 0 1 3 4 4 1 2 1 1 1 1 2 4 1 5 1 3 2 3 2 1 0 2 2 4 3 4 1 4 1 4 3 4 3 3 3 2 4 3 4 1 4 3 1 3 1 3 1 1 2 2 4 4 1 3 3 1 4 1 4 0 0 1 2 1 4 3 0 1 Correct: 596 out of: 1283\n",
      "Accuracy of the network :  46.45362431800468\n"
     ]
    }
   ],
   "source": [
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "Y=[]  #target\n",
    "Pred=[]  #predicted\n",
    "\n",
    "with torch.no_grad():\n",
    "    for row in range(len(TestData)):\n",
    "        outputs = net(TestData[row,:].float())\n",
    "        result=0\n",
    "        total+=1\n",
    "        if outputs[0]<outputs[1]:result=1\n",
    "        if outputs[result]<outputs[2]:result=2\n",
    "        if outputs[result]<outputs[3]:result=3\n",
    "        if outputs[result]<outputs[4]:result=4\n",
    "        if outputs[result]<outputs[5]:result=5\n",
    "        \n",
    "        if labelsOneHot.iloc[row,result]==1: correct+=1\n",
    "        \n",
    "        Y.append(result)\n",
    "        Pred.append(labels.iloc[row])\n",
    "        \n",
    "        print(result, end=' ')\n",
    "        \n",
    "       \n",
    "print('Correct:', correct, 'out of:', total )\n",
    "print('Accuracy of the network : ',( 100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 46  14   5   1   2   3]\n",
      " [ 21 134  38  42  36  35]\n",
      " [  6  27  80  18  13  13]\n",
      " [ 13  39  42 140  59  26]\n",
      " [  4  26  35  54 129  67]\n",
      " [  2  10  14  12  10  67]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics \n",
    "print(metrics.confusion_matrix(Y,Pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Pants       0.50      0.65      0.56        71\n",
      "       False       0.54      0.44      0.48       306\n",
      " Barely-True       0.37      0.51      0.43       157\n",
      "   Half-True       0.52      0.44      0.48       319\n",
      " Mostly-True       0.52      0.41      0.46       315\n",
      "        True       0.32      0.58      0.41       115\n",
      "\n",
      "    accuracy                           0.46      1283\n",
      "   macro avg       0.46      0.50      0.47      1283\n",
      "weighted avg       0.49      0.46      0.47      1283\n",
      "\n"
     ]
    }
   ],
   "source": [
    "target_names = ['Pants', 'False', 'Barely-True','Half-True','Mostly-True','True']\n",
    "\n",
    "print(metrics.classification_report(Y, Pred,target_names =target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
