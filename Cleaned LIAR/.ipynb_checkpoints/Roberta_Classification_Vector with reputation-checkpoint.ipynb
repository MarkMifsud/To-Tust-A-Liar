{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we first do the classification using the transformer This is our first classification task.\n",
    "\n",
    "The output classification vector from the transformer is saved to be used by the FCNN This is our second classification task.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing necessary libraries\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import sklearn\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from simpletransformers.classification import ClassificationModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the dataset\n",
    "\n",
    "Some pre-processing to the dataset has already been done in preparation for various tests, so this processing is not from scratch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# procedure for getting the data sets and formatting them for the transformer\n",
    " \n",
    "\n",
    "def prepareDataset( filename):\n",
    "     \n",
    "    ReadSet=pd.read_excel(filename )\n",
    "\n",
    "    ReadSet['text']=ReadSet['Statement']\n",
    "    ReadSet['labels']=ReadSet['Label']\n",
    "    \n",
    "    ReadSet=ReadSet.drop(['ID','Label','Statement','Subject','Speaker','Job','From','Affiliation','PantsTotal','NotRealTotal','BarelyTotal','HalfTotal','MostlyTotal' ,'RealTotal','Context'],axis=1)\n",
    "    \n",
    "\n",
    "    return ReadSet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>President Obama is a Muslim.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>An independent payment advisory board created ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>U.S. Sen. Bill Nelson was the deciding vote fo...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Large phone companies and their trade associat...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RIPTA has really some of the fullest buses for...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10094</th>\n",
       "      <td>The Georgia Dome has returned $10 billion in e...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10095</th>\n",
       "      <td>Then-Gov. Carl Sanders put 56 percent of the s...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10096</th>\n",
       "      <td>Nathan Deal saved the HOPE scholarship program.</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10097</th>\n",
       "      <td>John Faso took money from fossil fuel companie...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10098</th>\n",
       "      <td>With the exception of slavery and the Chinese ...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10099 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  labels\n",
       "0                           President Obama is a Muslim.       0\n",
       "1      An independent payment advisory board created ...       0\n",
       "2      U.S. Sen. Bill Nelson was the deciding vote fo...       2\n",
       "3      Large phone companies and their trade associat...       4\n",
       "4      RIPTA has really some of the fullest buses for...       4\n",
       "...                                                  ...     ...\n",
       "10094  The Georgia Dome has returned $10 billion in e...       1\n",
       "10095  Then-Gov. Carl Sanders put 56 percent of the s...       4\n",
       "10096    Nathan Deal saved the HOPE scholarship program.       4\n",
       "10097  John Faso took money from fossil fuel companie...       3\n",
       "10098  With the exception of slavery and the Chinese ...       4\n",
       "\n",
       "[10099 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# preparing the training dataset\n",
    "train=prepareDataset( 'train-clean.xlsx')\n",
    "# and display for inspecting\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>New Jerseys once-broken pension system is now ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The new health care law will cut $500 billion ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>For thousands of public employees, Wisconsin G...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Because as a Senator Toomey stood up for Wall ...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The governors budget proposal reduces the stat...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1267</th>\n",
       "      <td>You can import as many hemp products into this...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1268</th>\n",
       "      <td>Says when Republicans took over the state legi...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1269</th>\n",
       "      <td>Wisconsin's laws ranked the worst in the world...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1270</th>\n",
       "      <td>There currently are 825,000 student stations s...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1271</th>\n",
       "      <td>Black people are eight times more likely to be...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1272 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  labels\n",
       "0     New Jerseys once-broken pension system is now ...       3\n",
       "1     The new health care law will cut $500 billion ...       2\n",
       "2     For thousands of public employees, Wisconsin G...       3\n",
       "3     Because as a Senator Toomey stood up for Wall ...       4\n",
       "4     The governors budget proposal reduces the stat...       5\n",
       "...                                                 ...     ...\n",
       "1267  You can import as many hemp products into this...       5\n",
       "1268  Says when Republicans took over the state legi...       3\n",
       "1269  Wisconsin's laws ranked the worst in the world...       2\n",
       "1270  There currently are 825,000 student stations s...       4\n",
       "1271  Black people are eight times more likely to be...       3\n",
       "\n",
       "[1272 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# preparing the evaluation/validation dataset\n",
    "Eval=prepareDataset('valid-clean.xlsx')\n",
    "# and display for inspecting\n",
    "Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>In a lawsuit between private citizens, a Flori...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Obama-Nelson economic record: Job creation   a...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Says George LeMieux even compared Marco Rubio ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Gene Green is the NRAs favorite Democrat in Co...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>In labor negotiations with city employees, Mil...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1250</th>\n",
       "      <td>Says Milwaukee County Executive Chris Abele sp...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1251</th>\n",
       "      <td>The words subhuman mongrel, which Ted Nugent c...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1252</th>\n",
       "      <td>California's Prop 55 prevents $4 billion in ne...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1253</th>\n",
       "      <td>Says One of the states largest governments mad...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1254</th>\n",
       "      <td>Expanding the sale of full-strength beer and w...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1255 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  labels\n",
       "0     In a lawsuit between private citizens, a Flori...       4\n",
       "1     Obama-Nelson economic record: Job creation   a...       4\n",
       "2     Says George LeMieux even compared Marco Rubio ...       2\n",
       "3     Gene Green is the NRAs favorite Democrat in Co...       2\n",
       "4     In labor negotiations with city employees, Mil...       2\n",
       "...                                                 ...     ...\n",
       "1250  Says Milwaukee County Executive Chris Abele sp...       1\n",
       "1251  The words subhuman mongrel, which Ted Nugent c...       5\n",
       "1252  California's Prop 55 prevents $4 billion in ne...       2\n",
       "1253  Says One of the states largest governments mad...       0\n",
       "1254  Expanding the sale of full-strength beer and w...       3\n",
       "\n",
       "[1255 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# preparing the test set dataset\n",
    "test=prepareDataset('test-clean.xlsx')\n",
    "test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up the transformer for fine tuning\n",
    "\n",
    "This is where changes are done to optimise the model\n",
    "\n",
    "The simpletransformers library is the quickest way to do this at the time of writing. \n",
    "For more information on the settings and their default value go here:\n",
    "https://github.com/ThilinaRajapakse/simpletransformers#default-settings \n",
    "\n",
    "###### Please do read that reference before changing any parameters. Don't try to be a hero!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model variables were set up: \n"
     ]
    }
   ],
   "source": [
    "#Set the model being used here\n",
    "model_class='roberta'  # bert or roberta or albert\n",
    "model_version='roberta-large' #bert-base-cased, roberta-base, roberta-large, albert-base-v2 OR albert-large-v2\n",
    "\n",
    "\n",
    "output_folder='./TunedModels/'+model_class+'/'+model_version+\"/\"\n",
    "cache_directory= \"./TunedModels/\"+model_class+\"/\"+model_version+\"/cache/\"\n",
    "labels_count=6  # the number of classification classes\n",
    "\n",
    "print('model variables were set up: ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G:\\0 finalThesis\\CleanedText\n",
      "./TunedModels/roberta/roberta-large/\n",
      "./TunedModels/roberta/roberta-large/cache/\n"
     ]
    }
   ],
   "source": [
    "# use this to test if writing to the directories is working\n",
    "\n",
    "import os\n",
    "print(os.getcwd())\n",
    "print(output_folder)\n",
    "print(cache_directory)\n",
    "\n",
    "testWrite=train.head(30)\n",
    " \n",
    "testWrite.to_csv(output_folder+'DeleteThisToo.tsv', sep='\\t')\n",
    "testWrite.to_csv(cache_directory+'DeleteThisToo.tsv', sep='\\t')\n",
    "\n",
    "del(testWrite)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "save_every_steps=1285\n",
    "# assuming training batch size of 8\n",
    "# any number above 1284 saves the model only at every epoch\n",
    "# Saving the model mid training very often will consume disk space fast\n",
    "\n",
    "train_args={\n",
    "    \"output_dir\":output_folder,\n",
    "    \"cache_dir\":cache_directory,\n",
    "    'reprocess_input_data': True,\n",
    "    'overwrite_output_dir': True,\n",
    "    'num_train_epochs': 1,\n",
    "    \"save_steps\": save_every_steps, \n",
    "    \"learning_rate\": 1.2e-5,\n",
    "    \"train_batch_size\": 64,\n",
    "    \"eval_batch_size\": 16,\n",
    "    \"evaluate_during_training_steps\": 5,\n",
    "    \"max_seq_length\": 100,\n",
    "    \"n_gpu\": 1,\n",
    "}\n",
    "\n",
    "# Create a ClassificationModel\n",
    "model = ClassificationModel(model_class, model_version, num_labels=labels_count, args=train_args) \n",
    "\n",
    "# You can set class weights by using the optional weight argument"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading a saved model (based on above args{})\n",
    "\n",
    "If you stopped training you can continue training from a previously saved check point.\n",
    "The next cell allows you to load a model from any checkpoint.\n",
    "The number of epochs in the train_args{} will be done and continue tuning from your checkpoint.\n",
    "\n",
    "###### HOWEVER\n",
    "It will overwrite previous checkpoints!\n",
    "Example:  If you load an epoch-3 checkpoint, the epoch-1 checkpoint will be overwritten by the 4th epoch and it will be equivalent to a 4th epoch even if you have epoch-1 in the name.\n",
    "###### SO BE CAREFUL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model, please wait...\n",
      "model in use is : ./TunedModels/roberta/roberta-large/checkpoint-158-epoch-2\n"
     ]
    }
   ],
   "source": [
    "# loading a previously saved model based on this particular Transformer Class and model_name\n",
    "\n",
    "# loading the checkpoint that gave the best result\n",
    "CheckPoint='checkpoint-158-epoch-2'  #epoch 2\n",
    "\n",
    "\n",
    "preSavedCheckpoint=output_folder+CheckPoint\n",
    "\n",
    "print('Loading model, please wait...')\n",
    "model = ClassificationModel( model_class, preSavedCheckpoint, num_labels=labels_count, args=train_args) \n",
    "print('model in use is :', preSavedCheckpoint )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the Transformer\n",
    "\n",
    "Skip the next cell if you want to skip the training and go directly to the evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting to features started. Cache is not used.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "243081fbeb214fb491e1b30553328748",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=10099.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.\n",
      "\n",
      "Defaults for this optimization level are:\n",
      "enabled                : True\n",
      "opt_level              : O1\n",
      "cast_model_type        : None\n",
      "patch_torch_functions  : True\n",
      "keep_batchnorm_fp32    : None\n",
      "master_weights         : None\n",
      "loss_scale             : dynamic\n",
      "Processing user overrides (additional kwargs that are not None)...\n",
      "After processing overrides, optimization options are:\n",
      "enabled                : True\n",
      "opt_level              : O1\n",
      "cast_model_type        : None\n",
      "patch_torch_functions  : True\n",
      "keep_batchnorm_fp32    : None\n",
      "master_weights         : None\n",
      "loss_scale             : dynamic\n",
      "Warning:  multi_tensor_applier fused unscale kernel is unavailable, possibly because apex was installed without --cuda_ext --cpp_ext. Using Python fallback.  Original ImportError was: ModuleNotFoundError(\"No module named 'amp_C'\")\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ac318604e174c98b4f0eabfe95d45da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch', max=1.0, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1aca2eb8cbf94cf0b72631e585c1927d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Current iteration', max=158.0, style=ProgressStyle(descri…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "Running loss: 1.684256"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mark\\Anaconda3\\envs\\thesis\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:110: UserWarning: Seems like `optimizer.step()` has been overridden after learning rate scheduler initialization. Please, make sure to call `optimizer.step()` before `lr_scheduler.step()`. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\"Seems like `optimizer.step()` has been overridden after learning rate scheduler \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running loss: 1.736382"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mark\\Anaconda3\\envs\\thesis\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:224: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running loss: 1.701106Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n",
      "Running loss: 1.633070\n",
      "\n",
      "Training of roberta model complete. Saved to ./TunedModels/roberta/roberta-large/.\n",
      "Training time:  0:06:13.748483\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "current_time = datetime.now()\n",
    "model.train_model(train)\n",
    "print(\"Training time: \", datetime.now() - current_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating the training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features loaded from cache at ./TunedModels/roberta/roberta-large/cache/cached_dev_roberta_100_6_10099\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d98c02912591461c9a8f9eae9633d68c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=632.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{'mcc': 0.149840177358642, 'acc': 0.3061689276165957, 'eval_loss': 1.6335370689630508}\n",
      "Features loaded from cache at ./TunedModels/roberta/roberta-large/cache/cached_dev_roberta_100_6_1272\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f22776ad5954522a1bcc2f3b68c3301",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=80.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{'mcc': 0.10770351896373395, 'acc': 0.2720125786163522, 'eval_loss': 1.6629067718982697}\n",
      "Features loaded from cache at ./TunedModels/roberta/roberta-large/cache/cached_dev_roberta_100_6_1255\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47f990cbb9bb493e8a32c4c9b85965f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=79.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{'mcc': 0.11210817139008797, 'acc': 0.27808764940239045, 'eval_loss': 1.6613262318357636}\n",
      "Training Result: 0.3061689276165957\n",
      "Eval Result: 0.2720125786163522\n",
      "Test Set Result: 0.27808764940239045\n"
     ]
    }
   ],
   "source": [
    "TrainResult, TrainModel_outputs, wrong_predictions = model.eval_model(train, acc=sklearn.metrics.accuracy_score)\n",
    "\n",
    "EvalResult, EvalModel_outputs, wrong_predictions = model.eval_model(Eval, acc=sklearn.metrics.accuracy_score)\n",
    "\n",
    "TestResult, TestModel_outputs, wrong_predictions = model.eval_model(test, acc=sklearn.metrics.accuracy_score)\n",
    "\n",
    "print('Training Result:', TrainResult['acc'])\n",
    "#print('Model Out:', TrainModel_outputs)\n",
    "\n",
    "print('Eval Result:', EvalResult['acc'])\n",
    "#print('Model Out:', EvalModel_outputs)\n",
    "\n",
    "print('Test Set Result:', TestResult['acc'])\n",
    "#print('Model Out:', TestModel_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.34228516  0.46289062  0.2927246  -0.28295898 -0.72021484 -0.74902344] 1   4 \n",
      "[-1.8691406  -0.3149414  -0.25976562  0.91064453  0.51904297 -0.13464355] 3   4 \n",
      "[ 0.04214478  0.38330078 -0.03775024 -0.18640137 -0.5517578  -0.2109375 ] 1   2 \n",
      "[-0.73291016  0.10534668  0.38208008  0.26586914 -0.17687988 -0.18286133] 2   2 Match 1\n",
      "\n",
      "[-0.9584961   0.17883301  0.38549805  0.52001953 -0.44140625 -0.70654297] 3   2 \n",
      "[-1.8574219  -0.11785889 -0.25830078  0.33813477  0.61376953  0.3618164 ] 4   5 \n",
      "[ 0.30493164  0.28393555  0.21118164 -0.19335938 -0.6489258  -0.6171875 ] 0   3 \n",
      "[-0.56640625  0.01655579  0.12792969  0.12005615 -0.27734375 -0.25170898] 2   2 Match 2\n",
      "\n",
      "[-0.15014648  0.27612305  0.3161621  -0.13305664 -0.32958984 -0.70654297] 2   1 \n",
      "[-0.42211914  0.06347656  0.3166504   0.05316162 -0.62353516 -0.56933594] 2   0 \n",
      "[-1.5712891  -0.04925537 -0.46801758  0.00417709  0.53759766  0.6982422 ] 5   5 Match 3\n",
      "\n",
      "[-0.48266602  0.39208984  0.7055664   0.06658936 -0.36254883 -0.8208008 ] 2   2 Match 4\n",
      "\n",
      "[-2.3242188  -0.3137207  -0.35205078  0.6738281   0.9477539   0.38305664] 4   5 \n",
      "[-1.8320312  -0.33520508 -0.10339355  0.6489258   0.54345703  0.40600586] 3   5 \n",
      "[-1.4951172  -0.19726562  0.07073975  0.4284668   0.22949219  0.14685059] 3   3 Match 5\n",
      "\n",
      "[-0.04989624  0.4272461   0.22143555 -0.33520508 -0.5727539  -0.38012695] 1   1 Match 6\n",
      "\n",
      "[-0.8955078   0.02787781  0.13562012  0.14624023  0.14367676  0.0567627 ] 3   0 \n",
      "[ 0.07910156  0.5786133   0.5649414   0.15124512 -0.79589844 -1.1572266 ] 1   1 Match 7\n",
      "\n",
      "[-1.953125   -0.26904297 -0.31030273  0.6738281   0.44628906  0.40112305] 3   1 \n",
      "[-0.86376953  0.13916016  0.63916016  0.61572266 -0.43798828 -0.8911133 ] 2   2 Match 8\n",
      "\n",
      "[-1.0478516   0.3034668   0.49243164  0.44384766 -0.2854004  -0.8051758 ] 2   1 \n",
      "[-0.5029297   0.21875    -0.03826904 -0.03710938  0.06524658  0.01538086] 1   0 \n",
      "[-1.4921875  -0.21191406 -0.23266602  0.5336914   0.4880371   0.2998047 ] 3   4 \n",
      "[-0.44750977  0.19812012  0.44750977  0.02178955 -0.6035156  -0.58154297] 2   2 Match 9\n",
      "\n",
      "[-1.9316406  -0.38793945 -0.13317871  0.7919922   0.59277344 -0.07592773] 3   2 \n",
      "[-0.5761719   0.11468506  0.14453125 -0.01876831 -0.03634644 -0.1159668 ] 2   4 \n",
      "[-0.55810547  0.2800293   0.48364258  0.33496094 -0.4038086  -0.734375  ] 2   1 \n",
      "[-1.4970703  -0.22497559 -0.12188721  0.4169922   0.28271484 -0.02120972] 3   3 Match 10\n",
      "\n",
      "[-0.9399414   0.13452148  0.4477539   0.20043945 -0.22668457 -0.47509766] 2   0 \n",
      "[-0.46777344  0.3461914   0.3161621   0.40039062 -0.24963379 -0.78125   ] 3   2 \n",
      "[-0.8935547   0.2861328   0.5732422   0.28320312 -0.4428711  -0.80566406] 2   3 \n",
      "[-1.4375     -0.04144287  0.33666992  0.8852539  -0.10565186 -0.51123047] 3   1 \n",
      "[-1.0136719   0.17407227  0.40112305  0.3696289  -0.10308838 -0.4909668 ] 2   1 \n",
      "[-0.3984375   0.27807617  0.69091797  0.31274414 -0.61279297 -0.92089844] 2   1 \n",
      "[-0.64404297  0.359375    0.68115234  0.5932617  -0.45581055 -1.0019531 ] 2   1 \n",
      "[ 0.17285156  0.15429688  0.14672852  0.01202393 -0.5732422  -0.41625977] 0   2 \n",
      "[-1.3466797  -0.11590576  0.19885254  0.6640625   0.00221634 -0.58251953] 3   2 \n",
      "[-0.16015625  0.2290039   0.4140625   0.30908203 -0.48901367 -0.8691406 ] 2   3 \n",
      "[-1.5224609  -0.03625488  0.16870117  0.69189453 -0.02812195 -0.33764648] 3   4 \n",
      "[-1.4335938  -0.20275879 -0.13708496  0.23535156  0.4873047   0.07946777] 4   2 \n",
      "[-1.7412109  -0.28149414 -0.39501953  0.1217041   0.60498047  0.5629883 ] 4   5 \n",
      "[-1.1875      0.03411865 -0.09686279  0.24597168  0.29541016  0.09954834] 4   2 \n",
      "[-1.0693359  -0.19055176 -0.38012695  0.04116821  0.06420898  0.3942871 ] 5   1 \n",
      "[-0.1204834   0.31713867  0.3605957   0.04541016 -0.75146484 -0.5888672 ] 2   0 \n",
      "[-1.6728516  -0.15100098  0.16003418  0.5908203   0.2783203  -0.35205078] 3   2 \n",
      "[-0.44970703  0.40795898  0.49389648  0.44604492 -0.6147461  -0.94677734] 2   2 Match 11\n",
      "\n",
      "[-1.1728516   0.16516113  0.59472656  0.4050293  -0.08514404 -0.5888672 ] 2   1 \n",
      "[-1.0166016   0.00791931  0.1496582   0.37426758  0.02342224 -0.10919189] 3   3 Match 12\n",
      "\n",
      "[-1.3652344  -0.02693176  0.33081055  0.6796875   0.05395508 -0.46118164] 3   3 Match 13\n",
      "\n",
      "[-1.5712891  -0.00605011  0.00515747  0.28857422  0.4033203   0.07128906] 4   1 \n",
      "[-1.0986328   0.14550781  0.13464355  0.19396973 -0.0970459  -0.14172363] 3   2 \n",
      "[-1.7207031  -0.18908691 -0.25390625  0.34301758  0.5541992   0.4621582 ] 4   3 \n",
      "[-0.49169922  0.14697266  0.39672852  0.31640625 -0.23742676 -0.7397461 ] 2   2 Match 14\n",
      "\n",
      "[-2.0488281  -0.29370117 -0.47021484  0.4794922   0.6640625   0.6040039 ] 4   5 \n",
      "[-0.04980469  0.45092773  0.29956055  0.19543457 -0.7714844  -0.9135742 ] 1   0 \n",
      "[-1.5615234  -0.13671875  0.00568008  0.26220703  0.5595703   0.09906006] 4   5 \n",
      "[-0.46069336  0.10931396 -0.02322388  0.02964783 -0.12927246 -0.2133789 ] 1   5 \n",
      "[-1.4677734  -0.21325684 -0.13745117  0.46606445  0.3395996   0.10955811] 3   1 \n",
      "[-0.20227051  0.21447754 -0.06677246 -0.05639648 -0.17956543 -0.18640137] 1   3 \n",
      "[-0.18029785  0.13427734  0.00465393 -0.17016602 -0.3083496  -0.01245117] 1   1 Match 15\n",
      "\n",
      "[-0.85546875  0.11810303  0.45361328  0.53466797 -0.06463623 -0.57373047] 3   2 \n",
      "[-0.5595703   0.07348633 -0.09753418  0.02365112 -0.02250671 -0.1083374 ] 1   5 \n",
      "[-0.63623047  0.07519531  0.01977539 -0.02172852  0.08172607 -0.04873657] 4   5 \n",
      "[-1.0019531   0.20751953  0.53466797  0.5463867  -0.20947266 -0.8051758 ] 3   2 \n",
      "[-1.3085938  -0.22558594  0.31030273  0.46679688 -0.01506805 -0.01641846] 3   5 \n",
      "[-1.4033203  -0.03024292  0.18249512  0.43188477  0.45214844 -0.12219238] 4   5 \n",
      "[-0.9399414   0.1114502   0.20178223  0.22607422 -0.23083496 -0.26831055] 3   5 \n",
      "[-1.4042969  -0.1619873   0.4104004   0.53759766 -0.04974365 -0.3779297 ] 3   2 \n",
      "[-0.42651367  0.07415771 -0.19946289 -0.04324341 -0.02857971 -0.04086304] 1   1 Match 16\n",
      "\n",
      "[-0.32250977  0.14562988 -0.03848267 -0.03549194 -0.07403564 -0.10119629] 1   3 \n",
      "[-1.78125    -0.20214844 -0.2565918   0.2055664   0.62597656  0.4494629 ] 4   1 \n",
      "[-0.33007812  0.04660034 -0.17675781  0.00154209 -0.07885742 -0.08953857] 1   3 \n",
      "[-1.0585938  -0.03097534  0.3317871   0.3918457  -0.03399658 -0.2854004 ] 3   3 Match 17\n",
      "\n",
      "[-1.5869141   0.01255798  0.1439209   0.5419922   0.1932373  -0.20812988] 3   5 \n",
      "[-1.0439453   0.10510254  0.01902771  0.23547363  0.02554321 -0.16345215] 3   4 \n",
      "[-1.171875    0.11676025  0.34936523  0.5698242  -0.03665161 -0.5654297 ] 3   1 \n",
      "[-1.2294922   0.00534439  0.17272949  0.5214844   0.2956543  -0.04598999] 3   5 \n",
      "[-1.5830078  -0.03311157 -0.26367188  0.16955566  0.6933594   0.6010742 ] 4   4 Match 18\n",
      "\n",
      "[-1.8105469  -0.140625    0.27490234  0.8779297   0.2052002  -0.45947266] 3   3 Match 19\n",
      "\n",
      "[-0.5839844   0.11816406 -0.09014893  0.06921387 -0.03878784 -0.17712402] 1   1 Match 20\n",
      "\n",
      "[-1.7705078  -0.06085205  0.07098389  1.0488281   0.29785156 -0.49243164] 3   4 \n",
      "[-0.64990234  0.05648804 -0.09020996  0.10827637  0.02577209 -0.12084961] 3   3 Match 21\n",
      "\n",
      "[-1.2382812   0.15917969  0.2878418   0.4350586  -0.04296875 -0.2800293 ] 3   4 \n",
      "[-1.3886719   0.05770874  0.13476562  0.14575195  0.1928711  -0.14355469] 4   3 \n",
      "[-1.4335938   0.12164307  0.39404297  0.3149414  -0.06176758 -0.49682617] 2   2 Match 22\n",
      "\n",
      "[-1.5087891  -0.10882568  0.38916016  0.9692383   0.02462769 -0.34179688] 3   4 \n",
      "[-1.8505859  -0.31420898 -0.05688477  0.8696289   0.28393555  0.05856323] 3   4 \n",
      "[-1.9794922   0.07757568  0.05984497  0.8730469   0.45874023 -0.26586914] 3   1 \n",
      "[-1.671875   -0.2626953  -0.48486328  0.43066406  0.6098633   0.51171875] 4   5 \n",
      "[-1.6728516  -0.12463379  0.2614746   0.89697266  0.17126465 -0.47436523] 3   4 \n",
      "[-1.8994141  -0.14770508 -0.03659058  0.6484375   0.7426758   0.13757324] 4   4 Match 23\n",
      "\n",
      "[-1.6523438   0.13867188  0.56591797  0.88964844  0.12512207 -0.6699219 ] 3   5 \n",
      "[-1.5996094  -0.24353027 -0.06756592  0.703125    0.4560547   0.04299927] 3   1 \n",
      "[-2.2285156  -0.3935547  -0.6542969   0.6269531   0.88427734  0.61035156] 4   3 \n",
      "[-1.7753906  -0.0947876   0.0604248   0.7294922   0.3203125  -0.21008301] 3   3 Match 24\n",
      "\n",
      "[-2.0429688  -0.43017578 -0.49438477  0.82958984  0.7246094   0.5917969 ] 3   3 Match 25\n",
      "\n",
      "[-1.2392578   0.16674805  0.5229492   0.41674805 -0.13269043 -0.67626953] 2   4 \n",
      "[-0.97216797 -0.021698    0.0055809   0.13195801 -0.10595703 -0.05853271] 3   3 Match 26\n",
      "\n",
      "[-1.5117188   0.0383606   0.32177734  0.64208984  0.25976562 -0.24353027] 3   4 \n",
      "[-0.3491211   0.32836914  0.18981934  0.07324219 -0.1619873  -0.39257812] 1   4 \n",
      "[-1.1074219  -0.0064888   0.33447266  0.36035156 -0.02815247 -0.30786133] 3   3 Match 27\n",
      "\n",
      "[-0.5463867   0.16699219  0.54541016  0.5546875  -0.40551758 -0.8027344 ] 3   4 \n",
      "[-0.8354492   0.2121582   0.14257812  0.11450195 -0.11065674 -0.1607666 ] 1   3 \n",
      "[-1.8125     -0.2788086  -0.3317871   0.36132812  0.7348633   0.609375  ] 4   5 \n",
      "[-1.9794922  -0.24780273 -0.19641113  0.5317383   0.7626953   0.35180664] 4   4 Match 28\n",
      "\n",
      "[-1.7109375  -0.10760498  0.20361328  0.4465332   0.36328125 -0.13769531] 3   4 \n",
      "[-0.49975586  0.33740234  0.44506836  0.4560547  -0.47973633 -0.81347656] 3   2 \n",
      "[-0.93066406  0.05285645  0.35717773  0.4086914   0.00165272 -0.3046875 ] 3   2 \n",
      "[-1.7197266  -0.4038086  -0.24450684  0.4675293   0.52685547  0.2932129 ] 4   3 \n",
      "[-1.8779297  -0.23413086 -0.31860352  0.42749023  0.58691406  0.24816895] 4   3 \n",
      "[-1.9296875  -0.33496094 -0.39501953  0.45507812  0.8442383   0.47387695] 4   4 Match 29\n",
      "\n",
      "[-1.8476562  -0.18017578 -0.61328125  0.34472656  0.7421875   0.7441406 ] 5   4 \n",
      "[-1.8046875   0.01806641 -0.35620117  0.28808594  0.9716797   0.85253906] 4   4 Match 30\n",
      "\n",
      "[-1.6513672  -0.27539062 -0.29492188  0.41381836  0.5410156   0.12927246] 4   4 Match 31\n",
      "\n",
      "[-2.0449219  -0.29785156 -0.63183594  0.4345703   0.7895508   0.80029297] 5   4 \n",
      "[-0.8823242   0.05651855  0.19165039  0.3083496  -0.14074707 -0.4309082 ] 3   2 \n",
      "[-1.9980469  -0.0569458  -0.16967773  0.7709961   0.7895508   0.15966797] 4   4 Match 32\n",
      "\n",
      "[-1.2324219  -0.05905151  0.0158844   0.51123047  0.15222168 -0.203125  ] 3   3 Match 33\n",
      "\n",
      "[-0.25390625  0.10467529  0.23022461  0.074646   -0.3425293  -0.4519043 ] 2   5 \n",
      "[-1.3720703  -0.17077637 -0.49194336  0.11663818  0.3972168   0.4729004 ] 5   3 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.3681641   0.08105469  0.40014648  0.7714844   0.03692627 -0.61572266] 3   3 Match 34\n",
      "\n",
      "[-1.3066406  -0.05053711  0.3798828   0.62841797 -0.13928223 -0.6171875 ] 3   3 Match 35\n",
      "\n",
      "[-1.6201172  -0.05007935 -0.03436279  0.35839844  0.17700195  0.03411865] 3   1 \n",
      "[-0.5800781   0.05212402  0.3215332   0.15588379 -0.20898438 -0.42285156] 2   5 \n",
      "[-0.30688477  0.11743164  0.37646484  0.11474609 -0.3083496  -0.5996094 ] 2   0 \n",
      "[-1.6796875  -0.10046387 -0.3046875   0.30151367  0.4716797   0.37280273] 4   1 \n",
      "[-1.8720703  -0.15649414 -0.37182617  0.32739258  0.8515625   0.79052734] 4   5 \n",
      "[-2.2519531  -0.5161133  -0.6152344   0.5625      0.89160156  0.94091797] 5   4 \n",
      "[-1.6435547  -0.17053223 -0.4338379   0.31054688  0.82714844  0.5107422 ] 4   4 Match 36\n",
      "\n",
      "[-0.21569824  0.15612793  0.21191406  0.0637207  -0.33032227 -0.47485352] 2   4 \n",
      "[-0.47021484  0.37841797  0.53027344  0.25512695 -0.43359375 -0.74853516] 2   2 Match 37\n",
      "\n",
      "[-1.4101562  -0.09979248 -0.30151367  0.40673828  0.4387207  -0.12164307] 4   4 Match 38\n",
      "\n",
      "[-1.5058594  -0.10180664 -0.20617676  0.18200684  0.49047852  0.29077148] 4   4 Match 39\n",
      "\n",
      "[-1.0810547  -0.1496582   0.07330322  0.3959961  -0.02241516 -0.28686523] 3   4 \n",
      "[-1.2529297  -0.0037117   0.5859375   0.76220703 -0.25878906 -0.66503906] 3   3 Match 40\n",
      "\n",
      "[-2.0195312  -0.50341797 -0.20471191  0.97753906  0.45214844 -0.02339172] 3   5 \n",
      "[-0.79052734  0.20483398  0.4741211   0.28442383 -0.23901367 -0.8041992 ] 2   2 Match 41\n",
      "\n",
      "[-0.80371094  0.1439209   0.30322266  0.23876953 -0.3466797  -0.54589844] 2   4 \n",
      "[-0.11993408  0.24316406  0.1114502  -0.23327637 -0.47045898 -0.43530273] 1   2 \n",
      "[-1.7685547  -0.20153809 -0.03512573  0.7216797   0.20153809 -0.0736084 ] 3   2 \n",
      "[-1.5214844  -0.42041016 -0.49291992  0.2467041   0.49023438  0.42382812] 4   0 \n",
      "[-0.20690918  0.12243652 -0.1439209  -0.08428955 -0.14611816 -0.13012695] 1   1 Match 42\n",
      "\n",
      "[-0.67285156 -0.12445068  0.0046463   0.2902832  -0.15759277 -0.1418457 ] 3   5 \n",
      "[-0.56933594  0.41064453  0.5756836   0.38671875 -0.5517578  -1.1162109 ] 2   3 \n",
      "[-0.37426758  0.12683105  0.08062744 -0.03323364 -0.0328064  -0.24182129] 1   2 \n",
      "[-0.08007812  0.29736328  0.13757324 -0.10351562 -0.49389648 -0.40673828] 1   3 \n",
      "[-0.60058594  0.17370605  0.02217102  0.03207397 -0.09552002 -0.25073242] 1   4 \n",
      "[-2.234375  -0.4338379 -0.3503418  0.7285156  0.8486328  0.5      ] 4   4 Match 43\n",
      "\n",
      "[-1.3896484   0.11236572  0.22363281  0.3395996   0.48657227  0.22033691] 4   1 \n",
      "[-1.3828125  -0.02992249  0.19226074  0.44921875  0.11352539 -0.1772461 ] 3   5 \n",
      "[-1.7431641  -0.27807617 -0.23205566  0.38061523  0.7504883   0.61865234] 4   4 Match 44\n",
      "\n",
      "[-2.328125   -0.40454102 -0.6772461   0.5854492   0.94433594  0.8964844 ] 4   5 \n",
      "[-2.0585938  -0.3486328  -0.40039062  0.58447266  0.59765625  0.6464844 ] 5   5 Match 45\n",
      "\n",
      "[-1.078125    0.1161499   0.35620117  0.57958984 -0.3840332  -0.5439453 ] 3   4 \n",
      "[-2.1835938  -0.10644531 -0.65527344  0.41015625  0.9506836   0.9628906 ] 5   4 \n",
      "[-1.9433594  -0.17700195 -0.0770874   0.5942383   0.39038086  0.00340271] 3   2 \n",
      "[-0.28710938  0.10137939 -0.1137085  -0.05471802 -0.11767578 -0.1192627 ] 1   2 \n",
      "[-2.1054688  -0.20349121 -0.5932617   0.38208008  0.71972656  0.5722656 ] 4   4 Match 46\n",
      "\n",
      "[ 0.47338867  0.46704102  0.51171875  0.05343628 -0.9038086  -1.03125   ] 2   0 \n",
      "[ 0.8305664   0.625       0.37719727 -0.3137207  -1.0722656  -1.0517578 ] 0   0 Match 47\n",
      "\n",
      "[-0.1083374   0.4091797  -0.04833984 -0.11938477 -0.2890625  -0.49316406] 1   0 \n",
      "[-0.12646484  0.40722656 -0.09362793 -0.12268066 -0.3059082  -0.13366699] 1   5 \n",
      "[ 0.19458008  0.27905273  0.27124023 -0.00221443 -0.66552734 -0.828125  ] 1   1 Match 48\n",
      "\n",
      "[-0.59716797  0.17590332  0.19030762  0.22937012  0.13024902 -0.33032227] 3   1 \n",
      "[-1.0068359   0.00501251 -0.0725708   0.1586914   0.4321289   0.35058594] 4   0 \n",
      "[ 0.26708984  0.3095703   0.00732803 -0.29663086 -0.61572266 -0.46118164] 1   0 \n",
      "[ 0.26660156  0.5131836   0.13549805 -0.38549805 -0.74121094 -0.76171875] 1   0 \n",
      "[-2.3789062  -0.29492188 -0.50878906  0.7841797   0.65283203  0.50878906] 3   4 \n",
      "[-1.4755859  -0.13671875  0.07452393  0.33251953  0.22521973  0.08673096] 3   4 \n",
      "[ 0.05697632  0.3828125   0.50390625  0.2084961  -0.5776367  -0.86328125] 2   3 \n",
      "[-1.375      -0.08551025  0.18664551  0.33569336  0.4074707  -0.10925293] 4   3 \n",
      "[-1.171875    0.08557129  0.45654297  0.42138672 -0.16662598 -0.63964844] 2   5 \n",
      "[-1.6777344  -0.25610352 -0.05322266  0.75146484  0.27783203 -0.28222656] 3   3 Match 49\n",
      "\n",
      "[-1.3242188  -0.03149414 -0.61083984 -0.11352539  0.49194336  0.7397461 ] 5   5 Match 50\n",
      "\n",
      "[-1.3300781  -0.19104004 -0.5097656   0.1875      0.55615234  0.69384766] 5   5 Match 51\n",
      "\n",
      "[-2.1210938  -0.22607422 -0.2685547   0.640625    0.77197266  0.6689453 ] 4   1 \n",
      "[-1.5253906  -0.31152344 -0.33081055  0.28955078  0.43286133  0.34277344] 4   5 \n",
      "[-0.4736328   0.04205322 -0.1739502  -0.01285553  0.00640106 -0.01837158] 1   2 \n",
      "[-2.2421875  -0.22375488 -0.5214844   0.55810547  0.7319336   0.97802734] 5   4 \n",
      "[-1.6962891  -0.32543945 -0.0904541   0.8691406   0.26904297 -0.31103516] 3   3 Match 52\n",
      "\n",
      "[-1.5078125  -0.33618164 -0.2734375   0.38330078  0.36621094  0.09814453] 3   5 \n",
      "[-1.4179688   0.11260986  0.5107422   0.6123047  -0.16784668 -0.5175781 ] 3   0 \n",
      "[-1.5595703   0.00658417  0.5102539   0.7631836  -0.10424805 -0.64697266] 3   0 \n",
      "[-1.8535156  -0.27783203 -0.02246094  0.7973633   0.49902344 -0.09863281] 3   2 \n",
      "[-1.6748047  -0.15686035 -0.5161133   0.31225586  0.4243164   0.43579102] 5   4 \n",
      "[-0.47558594  0.26342773  0.20593262  0.04794312 -0.18054199 -0.50390625] 1   0 \n",
      "[-1.6611328  -0.30615234 -0.43652344  0.2631836   0.5595703   0.6401367 ] 5   5 Match 53\n",
      "\n",
      "[-1.0693359  -0.02148438  0.49487305  0.6225586  -0.08154297 -0.43896484] 3   2 \n",
      "[ 0.14343262  0.43310547  0.15905762 -0.28759766 -0.5234375  -0.43725586] 1   1 Match 54\n",
      "\n",
      "[ 0.16113281  0.18005371 -0.16625977 -0.23950195 -0.34814453 -0.24829102] 1   5 \n",
      "[-0.93408203  0.38305664  0.58251953  0.8388672  -0.3774414  -0.98291016] 3   2 \n",
      "[-0.29833984  0.19934082  0.18383789 -0.15356445 -0.26342773 -0.5541992 ] 1   5 \n",
      "[-1.2568359  -0.02587891  0.14355469  0.41186523  0.03125    -0.32983398] 3   0 \n",
      "[-1.9648438  -0.22875977  0.13415527  1.0791016   0.43286133 -0.16577148] 3   4 \n",
      "[-1.7333984  -0.24707031 -0.35839844  0.29516602  0.51464844  0.51416016] 4   4 Match 55\n",
      "\n",
      "[-1.3847656  -0.18835449  0.24023438  0.4633789   0.03463745 -0.21154785] 3   4 \n",
      "[-0.0319519   0.3552246   0.5463867   0.01193237 -0.6723633  -0.7060547 ] 2   3 \n",
      "[-1.5087891  -0.02409363  0.23657227  0.16760254 -0.10095215 -0.15527344] 2   5 \n",
      "[-0.14379883  0.31054688 -0.00319099 -0.27905273 -0.44482422 -0.04699707] 1   5 \n",
      "[ 0.01030731  0.4567871   0.62841797  0.2692871  -0.9355469  -0.98046875] 2   2 Match 56\n",
      "\n",
      "[-1.0234375   0.21875    -0.04501343  0.13342285 -0.22741699  0.11663818] 1   5 \n",
      "[-0.85253906  0.03570557 -0.25024414  0.1496582   0.1940918   0.11895752] 4   5 \n",
      "[-0.14831543  0.07281494 -0.21386719 -0.1270752  -0.16748047 -0.09729004] 1   1 Match 57\n",
      "\n",
      "[-1.6083984  -0.35180664 -0.25878906  0.5708008   0.56689453  0.31860352] 3   1 \n",
      "[ 0.46362305  0.48535156  0.47143555 -0.02038574 -0.9711914  -0.93408203] 1   0 \n",
      "[ 0.4296875   0.40673828  0.06512451 -0.35791016 -0.77734375 -0.6015625 ] 0   2 \n",
      "[-0.76660156  0.06069946 -0.21533203 -0.17749023 -0.10198975  0.00888062] 1   0 \n",
      "[-1.0634766   0.06298828  0.28149414  0.17419434 -0.1743164  -0.29223633] 2   0 \n",
      "[ 0.18847656  0.3803711   0.22338867 -0.28295898 -0.68359375 -0.77197266] 1   0 \n",
      "[-0.6245117   0.06567383  0.18457031 -0.02682495 -0.34301758 -0.41064453] 2   0 \n",
      "[-0.6904297   0.28466797  0.24206543  0.23583984 -0.44506836 -0.4975586 ] 1   1 Match 58\n",
      "\n",
      "[-0.39746094  0.09155273  0.12322998  0.08770752 -0.34326172 -0.35864258] 2   0 \n",
      "[-1.8916016  -0.5234375  -0.52246094  0.45385742  0.5024414   0.49609375] 4   1 \n",
      "[-0.45507812  0.4638672   0.49829102  0.41357422 -0.67871094 -0.98779297] 2   2 Match 59\n",
      "\n",
      "[-0.8881836   0.12878418  0.2401123   0.12756348 -0.27294922 -0.44311523] 2   2 Match 60\n",
      "\n",
      "[-1.5244141  -0.02590942 -0.39770508  0.23144531  0.63916016  0.7265625 ] 5   4 \n",
      "[ 0.49902344  0.5         0.38183594 -0.1204834  -0.94140625 -1.0185547 ] 1   0 \n",
      "[-2.0039062  -0.20092773 -0.09649658  0.81591797  0.51220703 -0.09417725] 3   2 \n",
      "[-0.3935547   0.13793945 -0.01430511  0.05728149 -0.07012939 -0.23339844] 1   5 \n",
      "[-1.0957031   0.08630371 -0.06878662  0.03817749  0.1328125   0.14929199] 5   5 Match 61\n",
      "\n",
      "[-1.9589844  -0.30859375 -0.2364502   0.75634766  0.63671875  0.29370117] 3   4 \n",
      "[-1.3652344e+00 -9.5397949e-02  2.3117065e-02  5.5371094e-01\n",
      "  1.6601562e-01 -6.6900253e-04] 3   5 \n",
      "[-1.0195312  -0.13574219  0.02316284  0.24597168  0.02954102 -0.02061462] 3   2 \n",
      "[-0.66064453  0.18029785  0.31469727  0.16442871 -0.21069336 -0.55859375] 2   4 \n",
      "[-1.2861328  -0.10070801 -0.04653931  0.11608887  0.05944824 -0.03213501] 3   2 \n",
      "[-2.015625   -0.15600586  0.04873657  0.8574219   0.57373047  0.01864624] 3   3 Match 62\n",
      "\n",
      "[-2.2851562  -0.23095703 -0.6665039   0.45239258  0.86376953  0.85839844] 4   5 \n",
      "[-1.0214844   0.12756348 -0.15625     0.04324341 -0.13000488  0.12438965] 1   1 Match 63\n",
      "\n",
      "[-2.25       -0.4116211  -0.8051758   0.42285156  0.72802734  0.9628906 ] 5   1 \n",
      "[-0.6767578   0.26733398  0.47583008  0.11016846 -0.38256836 -0.5488281 ] 2   3 \n",
      "[-1.8408203  -0.42163086 -0.18701172  0.9526367   0.46875    -0.07110596] 3   3 Match 64\n",
      "\n",
      "[-1.6679688  -0.12939453  0.004879    0.5600586   0.4555664   0.0553894 ] 3   0 \n",
      "[-0.98339844  0.15270996  0.34765625  0.3803711  -0.14367676 -0.6142578 ] 3   2 \n",
      "[-0.83740234  0.22644043  0.22924805  0.16210938  0.01712036 -0.32495117] 2   5 \n",
      "[-2.3417969  -0.32592773 -0.42895508  0.48950195  0.8051758   0.5073242 ] 4   3 \n",
      "[-1.6230469  -0.36621094 -0.01539612  0.8095703   0.38598633 -0.20629883] 3   1 \n",
      "[-1.7744141  -0.03948975  0.15808105  0.7973633   0.40405273 -0.21594238] 3   3 Match 65\n",
      "\n",
      "[-1.3681641   0.1743164   0.3173828   0.88134766  0.2084961  -0.5595703 ] 3   0 \n",
      "[-1.6992188   0.0769043   0.11816406  0.53759766  0.5073242  -0.01824951] 3   3 Match 66\n",
      "\n",
      "[-1.8056641  -0.28515625  0.20532227  0.98095703  0.2322998  -0.2709961 ] 3   3 Match 67\n",
      "\n",
      "[-1.8398438  -0.16467285 -0.24475098  0.38842773  0.45410156  0.4050293 ] 4   4 Match 68\n",
      "\n",
      "[-1.390625   -0.14929199  0.45288086  0.74072266 -0.09527588 -0.54003906] 3   3 Match 69\n",
      "\n",
      "[-0.5493164   0.10687256  0.4975586   0.37597656 -0.14465332 -0.68408203] 2   3 \n",
      "[-0.0814209   0.39282227  0.4169922   0.08514404 -0.6123047  -0.91259766] 2   3 \n",
      "[-0.8618164   0.02362061 -0.25756836  0.06106567  0.15393066 -0.02017212] 4   4 Match 70\n",
      "\n",
      "[-0.9248047  -0.0046463   0.28808594  0.2927246   0.32592773  0.03561401] 4   4 Match 71\n",
      "\n",
      "[-1.7255859   0.04333496 -0.00841522  0.22473145  0.42211914  0.10015869] 4   4 Match 72\n",
      "\n",
      "[-1.4560547  -0.0138092   0.21813965  0.51660156 -0.00526428 -0.43969727] 3   3 Match 73\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.24072266  0.31103516  0.24389648 -0.16247559 -0.58496094 -0.57666016] 1   2 \n",
      "[-1.3515625  -0.07824707  0.27026367  0.3544922   0.18908691 -0.33618164] 3   5 \n",
      "[ 0.16638184  0.46606445  0.48828125  0.09100342 -0.5878906  -0.94384766] 2   2 Match 74\n",
      "\n",
      "[-0.703125    0.00269508 -0.12585449  0.02636719 -0.30517578 -0.14978027] 3   4 \n",
      "[-1.1962891  -0.08477783  0.2668457   0.5102539   0.0385437  -0.16699219] 3   4 \n",
      "[-0.14013672  0.22973633  0.23303223  0.01661682 -0.37646484 -0.6113281 ] 2   2 Match 75\n",
      "\n",
      "[-0.3527832   0.20458984  0.00534821 -0.21728516 -0.4892578  -0.27783203] 1   0 \n",
      "[-1.0771484  -0.04437256 -0.16015625  0.09246826  0.06097412  0.16955566] 5   4 \n",
      "[-0.31884766  0.30322266  0.2401123   0.1517334  -0.1850586  -0.37426758] 1   3 \n",
      "[-1.625      -0.13952637 -0.034729    0.53808594  0.4777832   0.14282227] 3   4 \n",
      "[-1.6699219  -0.15600586 -0.1875      0.39331055  0.32104492  0.45532227] 5   2 \n",
      "[-1.1748047   0.07220459 -0.56396484 -0.1282959   0.45043945  0.68115234] 5   5 Match 76\n",
      "\n",
      "[-2.0078125   0.00557709 -0.45288086  0.24829102  0.69628906  0.90283203] 5   1 \n",
      "[-0.8208008   0.11859131 -0.40795898 -0.03222656 -0.11505127  0.27441406] 5   5 Match 77\n",
      "\n",
      "[-1.7539062  -0.2619629  -0.23376465  0.4699707   0.35229492  0.3125    ] 3   1 \n",
      "[-1.6601562  -0.08007812 -0.35107422  0.34521484  0.6044922   0.6425781 ] 5   4 \n",
      "[-1.5839844   0.01241302 -0.21166992  0.3022461   0.42529297  0.43481445] 5   4 \n",
      "[-1.6445312  -0.09490967  0.23461914  0.80566406  0.19274902 -0.39208984] 3   3 Match 78\n",
      "\n",
      "[-0.80126953  0.13195801  0.4428711   0.28393555 -0.00197792 -0.27612305] 2   4 \n",
      "[-0.00476456  0.32299805  0.42944336 -0.07324219 -0.72998047 -0.78808594] 2   2 Match 79\n",
      "\n",
      "[ 0.13549805  0.29492188  0.42114258  0.03762817 -0.7236328  -1.1083984 ] 2   0 \n",
      "[-1.3818359   0.2644043   0.18774414  0.78271484  0.03753662 -0.52001953] 3   1 \n",
      "[-1.8242188  -0.15698242  0.01469421  0.78222656  0.14416504 -0.22509766] 3   4 \n",
      "[-1.4501953  -0.18347168 -0.5605469   0.16015625  0.4501953   0.7236328 ] 5   1 \n",
      "[-1.2802734  -0.02593994  0.51708984  0.79345703 -0.3930664  -0.71533203] 3   2 \n",
      "[-0.49609375  0.40405273  0.65478516  0.26538086 -0.5136719  -1.0449219 ] 2   2 Match 80\n",
      "\n",
      "[-0.19824219  0.15893555 -0.07073975 -0.09033203 -0.15270996 -0.13439941] 1   1 Match 81\n",
      "\n",
      "[-1.6884766  -0.02990723 -0.5576172   0.18261719  0.46826172  0.7260742 ] 5   4 \n",
      "[-0.4411621   0.25610352  0.13793945  0.06216431 -0.6665039  -0.5834961 ] 1   1 Match 82\n",
      "\n",
      "[-1.4492188  -0.20544434 -0.34570312  0.33447266  0.42041016  0.19616699] 4   5 \n",
      "[-1.6484375  -0.21411133 -0.02104187  0.50097656  0.4038086  -0.07781982] 3   4 \n",
      "[-0.84472656  0.0317688   0.42114258  0.3647461  -0.18457031 -0.5966797 ] 2   3 \n",
      "[-2.1464844  -0.39892578 -0.2626953   0.97216797  0.79589844  0.15222168] 3   2 \n",
      "[-1.5498047  -0.05239868 -0.07244873  0.55029297  0.42260742 -0.11090088] 3   4 \n",
      "[-1.2138672   0.13085938  0.5083008   0.50927734 -0.19592285 -0.6044922 ] 3   4 \n",
      "[-1.6865234   0.14172363 -0.30297852  0.19335938  0.2163086   0.7133789 ] 5   1 \n",
      "[-1.3945312  -0.20288086 -0.00978088  0.41552734  0.3786621   0.2915039 ] 3   4 \n",
      "[ 0.36401367  0.49731445  0.53125    -0.16442871 -0.7319336  -0.8779297 ] 2   1 \n",
      "[-0.3125      0.28100586  0.31225586  0.08935547 -0.45385742 -0.6269531 ] 2   1 \n",
      "[-1.8125     -0.22277832 -0.47875977  0.30737305  0.5229492   0.9135742 ] 5   4 \n",
      "[ 0.2854004   0.3527832   0.22058105 -0.07006836 -0.7939453  -0.75634766] 1   5 \n",
      "[-1.7978516   0.01594543  0.10852051  0.7915039   0.28564453 -0.35717773] 3   3 Match 83\n",
      "\n",
      "[-2.1796875  -0.32910156 -0.54052734  0.71972656  0.7519531   0.72314453] 4   5 \n",
      "[-1.7949219  -0.3605957  -0.27416992  0.55371094  0.51220703  0.20825195] 3   3 Match 84\n",
      "\n",
      "[-0.82666016  0.23913574  0.42016602  0.33764648 -0.25317383 -0.6269531 ] 2   4 \n",
      "[-1.2832031  -0.00428772  0.36083984  0.48046875  0.17028809 -0.38598633] 3   4 \n",
      "[-1.2910156  -0.18066406 -0.44091797  0.1998291   0.60839844  0.5439453 ] 4   1 \n",
      "[-2.0078125  -0.3515625  -0.10906982  0.56884766  0.7192383   0.33764648] 4   1 \n",
      "[-1.2880859   0.20776367  0.22973633  0.11810303 -0.07299805 -0.11450195] 2   2 Match 85\n",
      "\n",
      "[-1.5244141  -0.3154297  -0.20703125  0.6044922   0.43579102 -0.1149292 ] 3   4 \n",
      "[-0.8745117   0.1574707   0.42333984  0.2244873  -0.43115234 -0.56640625] 2   3 \n",
      "[-1.3144531   0.1381836   0.4350586   0.36132812  0.09814453 -0.31176758] 2   2 Match 86\n",
      "\n",
      "[-0.6113281   0.23999023  0.3630371   0.12084961 -0.33447266 -0.28125   ] 2   0 \n",
      "[-1.4238281   0.15771484  0.33447266  0.23950195  0.1484375  -0.32202148] 2   5 \n",
      "[-1.6923828  -0.17700195 -0.3017578   0.05938721  0.46411133  0.8222656 ] 5   1 \n",
      "[-0.87402344  0.03109741  0.5419922   0.47631836 -0.38305664 -0.5878906 ] 2   2 Match 87\n",
      "\n",
      "[-1.4052734  -0.09460449 -0.28198242  0.13903809  0.6015625   0.36206055] 4   1 \n",
      "[-1.4306641  -0.22033691 -0.56640625  0.20483398  0.20947266  0.72998047] 5   5 Match 88\n",
      "\n",
      "[-1.7285156  -0.09204102  0.2154541   0.72753906  0.07489014 -0.15612793] 3   3 Match 89\n",
      "\n",
      "[-0.98339844  0.09057617 -0.20678711  0.00888062 -0.13024902 -0.14526367] 1   1 Match 90\n",
      "\n",
      "[-1.6064453  -0.25195312  0.01073456  0.43579102  0.3762207  -0.01797485] 3   4 \n",
      "[-0.82958984  0.13024902  0.13305664  0.00859833 -0.16882324 -0.47631836] 2   4 \n",
      "[ 0.01502228  0.24169922  0.26367188  0.06542969 -0.5883789  -0.48364258] 2   3 \n",
      "[-0.38549805  0.23156738  0.3791504   0.18029785 -0.8095703  -0.60498047] 2   0 \n",
      "[-1.4345703  -0.28149414  0.02243042  0.52001953  0.38964844  0.12432861] 3   3 Match 91\n",
      "\n",
      "[-1.0107422   0.2607422   0.53564453  0.5913086  -0.31958008 -0.81347656] 3   2 \n",
      "[-0.88964844 -0.18200684  0.09643555  0.21154785 -0.13879395 -0.45336914] 3   4 \n",
      "[ 0.36889648  0.49658203  0.24121094 -0.22937012 -0.66748047 -0.7211914 ] 1   0 \n",
      "[-0.4855957   0.3527832   0.74365234  0.3076172  -0.4567871  -0.90283203] 2   2 Match 92\n",
      "\n",
      "[-1.0302734   0.00352287  0.2602539   0.26220703  0.00805664 -0.05419922] 3   2 \n",
      "[-0.19897461  0.09863281 -0.13598633 -0.07928467 -0.11627197 -0.1430664 ] 1   2 \n",
      "[-0.60839844 -0.04797363 -0.20336914  0.05081177  0.0234375   0.04025269] 3   3 Match 93\n",
      "\n",
      "[-0.2878418   0.10339355 -0.15039062 -0.05795288 -0.11499023 -0.13696289] 1   5 \n",
      "[-1.3623047  -0.0824585   0.31811523  0.47558594  0.04003906 -0.43823242] 3   2 \n",
      "[-1.8496094  -0.22961426  0.1538086   0.77978516  0.24853516 -0.32080078] 3   3 Match 94\n",
      "\n",
      "[-0.75927734  0.30249023  0.45996094  0.38330078 -0.29003906 -0.75683594] 2   3 \n",
      "[-0.06835938  0.23278809  0.30981445 -0.07080078 -0.8041992  -0.6064453 ] 2   3 \n",
      "[-0.8564453  -0.04003906 -0.07659912  0.11621094 -0.09429932 -0.09991455] 3   3 Match 95\n",
      "\n",
      "[-0.66015625  0.27148438  0.58447266  0.31933594 -0.42260742 -0.6464844 ] 2   1 \n",
      "[-0.13366699  0.34985352  0.20666504 -0.21350098 -0.46411133 -0.25317383] 1   3 \n",
      "[-1.2626953   0.16040039  0.00539017  0.27783203 -0.07183838 -0.22875977] 3   5 \n",
      "[-1.4111328  -0.05343628  0.01675415  0.41186523  0.21276855 -0.35986328] 3   1 \n",
      "[-0.71533203  0.19494629  0.42822266  0.41479492 -0.38305664 -0.70996094] 2   5 \n",
      "[-1.0732422  -0.08184814  0.1907959   0.31689453  0.08978271 -0.21276855] 3   1 \n",
      "[-1.8652344  -0.15783691  0.08276367  0.7910156   0.2578125  -0.4025879 ] 3   3 Match 96\n",
      "\n",
      "[-2.0097656  -0.3737793  -0.45141602  0.47094727  0.81152344  0.6489258 ] 4   4 Match 97\n",
      "\n",
      "[-0.69873047  0.22851562  0.34033203  0.3894043  -0.3215332  -0.57666016] 3   2 \n",
      "[-1.6708984  -0.16101074 -0.01286316  0.8779297   0.43066406 -0.31201172] 3   4 \n",
      "[-0.50146484  0.47045898  0.73291016  0.08740234 -0.5517578  -1.09375   ] 2   1 \n",
      "[-1.9091797  -0.36279297 -0.5551758   0.2076416   0.7788086   0.7246094 ] 4   4 Match 98\n",
      "\n",
      "[-1.18652344e-01  3.69384766e-01  6.01562500e-01  3.67641449e-04\n",
      " -4.69726562e-01 -7.90039062e-01] 2   1 \n",
      "[-0.26489258  0.6064453   0.7158203   0.40283203 -0.72314453 -0.8935547 ] 2   2 Match 99\n",
      "\n",
      "[-0.14465332  0.49487305  0.4765625   0.35351562 -0.7207031  -1.        ] 1   0 \n",
      "[-1.0263672   0.08978271  0.21740723  0.3232422   0.23901367 -0.17553711] 3   5 \n",
      "[-0.4050293   0.45922852  0.24157715  0.21130371 -0.04354858 -0.40844727] 1   2 \n",
      "[-0.02636719  0.28100586  0.15966797 -0.04800415 -0.6879883  -0.63183594] 1   3 \n",
      "[-0.57421875  0.0994873   0.16027832  0.0703125  -0.11474609 -0.29858398] 2   0 \n",
      "[-0.4724121   0.08935547 -0.15612793 -0.05914307 -0.00396729  0.03518677] 1   3 \n",
      "[-0.13427734  0.3395996  -0.05374146 -0.19799805 -0.08282471 -0.2479248 ] 1   5 \n",
      "[ 0.62841797  0.46777344  0.15026855 -0.18457031 -0.72216797 -0.46826172] 0   5 \n",
      "[ 0.6323242   0.6191406   0.3317871   0.04858398 -0.9736328  -1.0761719 ] 0   2 \n",
      "[-0.45214844  0.2376709   0.20471191  0.30200195 -0.36669922 -0.5263672 ] 3   2 \n",
      "[-0.7319336   0.10479736  0.07861328  0.22827148 -0.02203369 -0.5029297 ] 3   1 \n",
      "[ 0.3701172   0.5722656   0.37646484 -0.2919922  -0.7949219  -0.85595703] 1   2 \n",
      "[-0.19946289  0.1739502   0.21582031  0.05392456 -0.48046875 -0.4453125 ] 2   2 Match 100\n",
      "\n",
      "[-2.1972656  -0.4663086  -0.45825195  0.6894531   0.6669922   0.3544922 ] 3   3 Match 101\n",
      "\n",
      "[-2.0722656  -0.43286133 -0.5727539   0.67041016  0.6142578   0.51123047] 3   3 Match 102\n",
      "\n",
      "[-0.20568848  0.35424805  0.15734863 -0.09094238 -0.33398438 -0.2763672 ] 1   3 \n",
      "[-0.25463867  0.2939453   0.3876953   0.24523926 -0.6669922  -0.97314453] 2   3 \n",
      "[-0.4975586   0.16638184  0.49023438  0.30004883 -0.1829834  -0.9477539 ] 2   2 Match 103\n",
      "\n",
      "[-0.99902344 -0.06210327  0.03796387  0.23754883  0.28295898 -0.18908691] 4   0 \n",
      "[-0.69970703  0.30029297  0.2722168   0.57470703 -0.21899414 -0.8354492 ] 3   3 Match 104\n",
      "\n",
      "[ 0.17504883  0.4189453   0.26171875 -0.07373047 -0.6333008  -0.58447266] 1   2 \n",
      "[-1.3310547  -0.1430664   0.2052002   0.5307617   0.16467285 -0.23583984] 3   4 \n",
      "[-0.9160156   0.06124878  0.49609375  0.6713867  -0.12091064 -0.71875   ] 3   4 \n",
      "[-0.22961426  0.06982422 -0.15917969 -0.03302002 -0.12817383 -0.10449219] 1   1 Match 105\n",
      "\n",
      "[-0.27807617  0.12030029  0.1628418   0.00497818 -0.1661377  -0.2919922 ] 2   2 Match 106\n",
      "\n",
      "[-0.80029297  0.16333008  0.2607422   0.25073242  0.1048584  -0.3347168 ] 2   0 \n",
      "[-0.01231384  0.36254883  0.08087158 -0.11651611 -0.60253906 -0.7558594 ] 1   5 \n",
      "[-0.6826172   0.31274414 -0.05462646  0.0949707  -0.14709473 -0.36206055] 1   4 \n",
      "[-1.3261719   0.07598877  0.21643066  0.6635742   0.2084961  -0.20568848] 3   4 \n",
      "[-1.5058594  -0.20397949 -0.36547852  0.3737793   0.46777344  0.31054688] 4   2 \n",
      "[ 0.27563477  0.49853516  0.16137695 -0.2932129  -0.5229492  -0.3486328 ] 1   1 Match 107\n",
      "\n",
      "[-0.49121094 -0.00666046 -0.22351074  0.00756836  0.021698    0.06787109] 5   5 Match 108\n",
      "\n",
      "[-2.0214844  -0.43798828 -0.56591797  0.5073242   0.9067383   0.77197266] 4   1 \n",
      "[-2.3203125  -0.29833984 -0.31713867  0.61083984  0.9863281   0.46557617] 4   4 Match 109\n",
      "\n",
      "[-0.37231445  0.06976318  0.20996094 -0.1796875   0.08392334 -0.18847656] 2   3 \n",
      "[ 0.02380371  0.43139648  0.3005371  -0.16833496 -0.5522461  -0.46484375] 1   1 Match 110\n",
      "\n",
      "[ 0.32617188  0.41577148  0.30395508 -0.16638184 -0.7324219  -0.6147461 ] 1   3 \n",
      "[-0.83496094 -0.02015686  0.09802246  0.171875   -0.05331421 -0.35620117] 3   3 Match 111\n",
      "\n",
      "[-0.72021484  0.14831543  0.1854248   0.33398438 -0.18615723 -0.26586914] 3   2 \n",
      "[-0.6723633  -0.04211426  0.37231445  0.3852539  -0.46655273 -0.61816406] 3   1 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.49194336  0.14868164  0.30737305  0.20349121 -0.4873047  -0.5913086 ] 2   2 Match 112\n",
      "\n",
      "[-0.6582031   0.16125488  0.2890625   0.01625061 -0.44311523 -0.44555664] 2   1 \n",
      "[-1.5458984  -0.14074707 -0.4140625   0.22595215  0.3461914   0.70654297] 5   5 Match 113\n",
      "\n",
      "[-0.87646484  0.08898926  0.47705078  0.18566895 -0.26660156 -0.39404297] 2   2 Match 114\n",
      "\n",
      "[-0.40454102  0.18408203 -0.21691895 -0.1184082  -0.14318848 -0.08947754] 1   2 \n",
      "[-0.6220703   0.46850586  0.53125     0.5410156  -0.3815918  -0.9399414 ] 3   2 \n",
      "[-1.6357422  -0.3803711  -0.31298828  0.43188477  0.578125    0.5048828 ] 4   4 Match 115\n",
      "\n",
      "[-0.30322266  0.07550049 -0.11724854 -0.04504395 -0.14221191 -0.13244629] 1   1 Match 116\n",
      "\n",
      "[-1.2822266  -0.11035156  0.28515625  0.5517578   0.04605103 -0.49145508] 3   4 \n",
      "[-0.07293701  0.5175781   0.36767578 -0.12078857 -0.75       -0.79785156] 1   3 \n",
      "[-1.6054688  -0.06237793 -0.42041016  0.17956543  0.40527344  0.83935547] 5   5 Match 117\n",
      "\n",
      "[-1.296875   -0.18737793 -0.24487305  0.31518555  0.4086914   0.24243164] 4   3 \n",
      "[-1.2558594  -0.11212158  0.04013062  0.3725586   0.26635742  0.29614258] 3   2 \n",
      "[-1.1669922   0.15539551  0.3388672   0.69189453  0.02497864 -0.67822266] 3   2 \n",
      "[-2.0957031  -0.1427002  -0.39624023  0.89990234  0.6953125   0.1821289 ] 3   1 \n",
      "[-1.2421875   0.11224365  0.31884766  0.43066406  0.01605225 -0.25708008] 3   1 \n",
      "[-1.6738281  -0.09710693 -0.13647461  0.70947266  0.23327637  0.1385498 ] 3   5 \n",
      "[-1.3671875   0.42504883  0.41845703  0.6904297   0.00371361 -0.6845703 ] 3   3 Match 118\n",
      "\n",
      "[-0.3720703   0.35961914  0.40356445  0.11993408 -0.50927734 -0.86083984] 2   2 Match 119\n",
      "\n",
      "[ 0.42138672  0.7451172   0.42797852 -0.19384766 -1.0908203  -1.1445312 ] 1   0 \n",
      "[-2.1230469  -0.5053711  -0.2163086   0.90478516  0.5288086   0.3215332 ] 3   3 Match 120\n",
      "\n",
      "[-1.1123047  -0.13134766  0.2734375   0.45141602 -0.06549072 -0.38989258] 3   2 \n",
      "[-1.2177734  -0.01364136  0.09313965  0.5708008   0.07269287 -0.40185547] 3   1 \n",
      "[-2.0488281  -0.37963867 -0.5722656   0.40820312  0.9003906   0.76953125] 4   2 \n",
      "[-0.92529297  0.14782715  0.61376953  0.66308594 -0.34033203 -0.7470703 ] 3   3 Match 121\n",
      "\n",
      "[-0.4736328   0.12524414  0.2076416   0.20410156 -0.28979492 -0.4765625 ] 2   3 \n",
      "[-1.7148438  -0.0847168  -0.2861328   0.31030273  0.6899414   0.40698242] 4   2 \n",
      "[-1.2011719  -0.06240845 -0.2401123   0.1854248   0.1895752   0.2421875 ] 5   4 \n",
      "[-0.23791504  0.21679688  0.30395508  0.13806152 -0.47460938 -0.63720703] 2   1 \n",
      "[-0.82958984  0.13781738  0.21350098  0.3269043  -0.15917969 -0.4868164 ] 3   3 Match 122\n",
      "\n",
      "[-1.7744141  -0.34448242 -0.39208984  0.3095703   0.7705078   0.6972656 ] 4   3 \n",
      "[-0.73828125  0.19592285  0.22143555 -0.16833496 -0.16723633 -0.28344727] 2   1 \n",
      "[-1.7617188  -0.25952148 -0.0206604   0.81396484  0.49951172 -0.02702332] 3   1 \n",
      "[-0.67333984  0.13293457  0.14855957  0.07214355 -0.01869202 -0.28759766] 2   0 \n",
      "[-1.3291016  -0.18579102 -0.41235352  0.19958496  0.43579102  0.26171875] 4   1 \n",
      "[-0.4729004   0.20703125  0.13024902 -0.07763672 -0.39868164 -0.21435547] 1   0 \n",
      "[-1.6826172  -0.3623047  -0.23376465  0.4736328   0.50878906  0.4260254 ] 4   0 \n",
      "[-0.39624023  0.24743652 -0.20983887 -0.35473633 -0.3347168  -0.21655273] 1   2 \n",
      "[-1.7753906 -0.2722168  0.0475769  0.9589844  0.4482422 -0.1508789] 3   0 \n",
      "[-0.3984375   0.24682617 -0.0748291  -0.0435791  -0.4555664  -0.14709473] 1   0 \n",
      "[-0.49194336  0.10229492  0.16564941 -0.01820374 -0.09277344 -0.28588867] 2   1 \n",
      "[-1.9501953  -0.24353027 -0.15991211  0.43798828  0.6074219   0.45361328] 4   1 \n",
      "[-1.6328125  -0.10351562 -0.52441406  0.17663574  0.6870117   0.88378906] 5   5 Match 123\n",
      "\n",
      "[-0.8979492  -0.04711914  0.2298584   0.5488281  -0.14953613 -0.66552734] 3   3 Match 124\n",
      "\n",
      "[-1.6630859  -0.12548828 -0.19104004  0.3955078   0.48486328  0.2927246 ] 4   3 \n",
      "[-0.7885742   0.30688477  0.6279297   0.28564453 -0.11920166 -0.7597656 ] 2   2 Match 125\n",
      "\n",
      "[-0.7753906   0.24804688  0.3474121   0.18701172 -0.30981445 -0.6323242 ] 2   2 Match 126\n",
      "\n",
      "[-0.6176758   0.01708984  0.11450195  0.25195312 -0.09790039 -0.23706055] 3   4 \n",
      "[-0.32641602  0.12792969 -0.16931152 -0.07067871 -0.08679199 -0.09906006] 1   2 \n",
      "[-0.95947266  0.08624268 -0.01687622  0.03689575  0.06561279  0.03289795] 1   2 \n",
      "[-1.7890625   0.04324341  0.08557129  0.5390625   0.27124023 -0.2052002 ] 3   5 \n",
      "[-0.15478516  0.25146484  0.06204224 -0.07519531 -0.3166504  -0.47753906] 1   1 Match 127\n",
      "\n",
      "[-0.47509766 -0.00471497  0.2705078   0.25317383 -0.23693848 -0.40112305] 2   1 \n",
      "[-0.5078125   0.14746094  0.4807129   0.22998047 -0.49902344 -0.80371094] 2   2 Match 128\n",
      "\n",
      "[-1.7832031  -0.07171631 -0.01863098  0.5576172   0.34106445  0.08648682] 3   3 Match 129\n",
      "\n",
      "[-0.6230469   0.10943604  0.56152344  0.11114502 -0.4621582  -0.9272461 ] 2   0 \n",
      "[-1.8857422  -0.31713867 -0.23803711  0.41333008  0.6870117   0.3466797 ] 4   5 \n",
      "[ 0.07537842  0.35473633  0.20861816 -0.06945801 -0.25390625 -0.32714844] 1   4 \n",
      "[-0.29101562  0.1340332   0.41845703  0.13989258 -0.54541016 -0.74853516] 2   3 \n",
      "[-1.4277344  -0.02246094 -0.44213867  0.11645508  0.6308594   0.5332031 ] 4   5 \n",
      "[-1.2177734   0.13513184  0.39404297  0.4338379  -0.1586914  -0.45703125] 3   4 \n",
      "[-1.3466797  -0.17260742 -0.3486328   0.08538818  0.43774414  0.3762207 ] 4   5 \n",
      "[-0.95996094  0.23364258  0.47875977  0.44506836 -0.15942383 -0.79003906] 2   0 \n",
      "[-1.8291016  -0.18322754 -0.19128418  0.6723633   0.41845703  0.17260742] 3   4 \n",
      "[-2.3925781  -0.5234375  -0.56884766  0.86328125  0.87060547  0.2208252 ] 4   5 \n",
      "[ 0.17004395  0.40795898 -0.02778625 -0.24157715 -0.5571289  -0.5073242 ] 1   4 \n",
      "[-1.3447266  -0.16772461  0.02082825  0.42016602  0.27734375  0.13842773] 3   3 Match 130\n",
      "\n",
      "[-0.21606445  0.40478516  0.03515625 -0.27978516 -0.19885254 -0.20166016] 1   2 \n",
      "[-1.7226562  -0.31274414 -0.14086914  0.5957031   0.49902344  0.27246094] 3   4 \n",
      "[-1.3271484   0.06884766  0.46728516  0.7290039   0.05175781 -0.5917969 ] 3   2 \n",
      "[-1.8398438  -0.08721924  0.1050415   0.7529297   0.23706055 -0.28295898] 3   2 \n",
      "[-1.3808594e+00  3.9794922e-02 -2.5341797e-01 -5.4883957e-04\n",
      "  3.7744141e-01  7.2021484e-01] 5   5 Match 131\n",
      "\n",
      "[-2.1386719  -0.43530273 -0.59765625  0.5473633   0.69433594  0.60253906] 4   4 Match 132\n",
      "\n",
      "[ 0.93847656  0.59033203  0.25927734 -0.4116211  -0.8935547  -0.6665039 ] 0   3 \n",
      "[-0.35961914  0.2529297   0.21838379 -0.05343628 -0.2631836  -0.41723633] 1   1 Match 133\n",
      "\n",
      "[-0.5986328   0.28222656  0.03503418 -0.17883301 -0.10571289 -0.11645508] 1   2 \n",
      "[-1.8486328  -0.2401123   0.15197754  0.7167969   0.51123047 -0.02587891] 3   3 Match 134\n",
      "\n",
      "[-1.9970703  -0.35083008 -0.2692871   0.43652344  0.6479492   0.38842773] 4   3 \n",
      "[-2.2695312  -0.21276855 -0.4645996   0.42456055  0.8095703   0.8461914 ] 5   3 \n",
      "[-2.1054688  -0.17993164 -0.46899414  0.5097656   0.5605469   0.7753906 ] 5   4 \n",
      "[-1.6103516  -0.30981445 -0.16052246  0.5942383   0.38916016 -0.11022949] 3   5 \n",
      "[-0.42382812  0.09735107 -0.24719238 -0.03503418  0.00063181  0.07250977] 1   2 \n",
      "[ 0.00680161  0.20910645  0.23583984  0.05377197 -0.6171875  -0.7480469 ] 2   0 \n",
      "[-1.2568359   0.02365112  0.22387695  0.41210938  0.14294434 -0.24829102] 3   1 \n",
      "[-2.2070312  -0.37524414 -0.57177734  0.5253906   0.9604492   0.796875  ] 4   2 \n",
      "[-2.2324219  -0.38110352 -0.3293457   0.6777344   0.7133789   0.42895508] 4   2 \n",
      "[ 0.56396484  0.48413086  0.17541504 -0.40576172 -0.7783203  -0.69677734] 0   0 Match 135\n",
      "\n",
      "[-0.08380127  0.45776367  0.04086304 -0.30639648 -0.6074219  -0.4555664 ] 1   0 \n",
      "[-0.7753906   0.03143311 -0.05911255  0.36499023 -0.11779785 -0.20214844] 3   1 \n",
      "[-1.4150391  -0.11907959 -0.09033203  0.46923828  0.44555664 -0.06970215] 3   5 \n",
      "[-1.5039062  -0.2902832  -0.23217773  0.45214844  0.4416504   0.0892334 ] 3   5 \n",
      "[-2.2167969  -0.44506836 -0.38427734  0.7114258   0.7792969   0.6669922 ] 4   5 \n",
      "[-0.61035156 -0.01519775  0.20874023  0.24951172 -0.29101562 -0.37451172] 3   2 \n",
      "[ 0.07769775  0.38549805  0.5385742  -0.12194824 -0.5805664  -0.7631836 ] 2   3 \n",
      "[-0.2286377   0.22814941  0.16137695 -0.14746094 -0.48828125 -0.32250977] 1   3 \n",
      "[-2.1855469  -0.30419922 -0.15283203  0.7265625   0.4416504   0.0328064 ] 3   4 \n",
      "[-1.8789062  -0.43432617 -0.359375    0.52441406  0.4465332   0.25146484] 3   4 \n",
      "[-1.4140625  -0.20996094 -0.08074951  0.44921875  0.22460938 -0.00973511] 3   3 Match 136\n",
      "\n",
      "[-0.9633789   0.16760254  0.38378906  0.29711914 -0.17785645 -0.60595703] 2   5 \n",
      "[ 0.28076172  0.5996094   0.14099121 -0.27856445 -0.6201172  -0.59033203] 1   2 \n",
      "[-1.2939453   0.00636292  0.09320068  0.16760254  0.28881836  0.01047516] 4   3 \n",
      "[-1.96875    -0.38110352 -0.13439941  0.6010742   0.55371094  0.02078247] 3   4 \n",
      "[-0.60791016  0.07904053  0.23352051  0.42260742 -0.27905273 -0.52685547] 3   2 \n",
      "[-0.46044922  0.03521729 -0.1998291  -0.11016846 -0.24523926 -0.06890869] 1   5 \n",
      "[-0.39135742  0.18640137 -0.01928711 -0.10095215 -0.20751953 -0.18579102] 1   5 \n",
      "[-1.5595703   0.03237915 -0.20629883  0.17773438  0.5966797   0.18798828] 4   2 \n",
      "[-0.4633789   0.45703125  0.61083984  0.01049042 -0.5708008  -0.9111328 ] 2   3 \n",
      "[-0.7807617  -0.02049255  0.36108398  0.31713867 -0.06402588 -0.2980957 ] 2   1 \n",
      "[-1.8662109  -0.36669922 -0.38745117  0.39990234  0.63916016  0.6123047 ] 4   5 \n",
      "[-1.7343750e+00 -4.9924850e-04  1.3378906e-01  7.2265625e-01\n",
      "  2.3632812e-01 -3.3105469e-01] 3   3 Match 137\n",
      "\n",
      "[-2.1601562  -0.51660156 -0.41992188  0.85253906  0.5410156   0.09973145] 3   4 \n",
      "[-0.5214844   0.44921875  0.43041992 -0.04049683 -0.22961426 -0.5605469 ] 1   2 \n",
      "[-1.6904297  -0.26049805 -0.51904297  0.13244629  0.51660156  0.6899414 ] 5   4 \n",
      "[ 0.06045532  0.47729492  0.65966797  0.10882568 -0.71777344 -0.93408203] 2   2 Match 138\n",
      "\n",
      "[-2.4023438  -0.30493164 -0.58154297  0.57910156  0.9199219   0.9238281 ] 5   5 Match 139\n",
      "\n",
      "[-2.2167969  -0.27514648 -0.4711914   0.5102539   0.97021484  0.8178711 ] 4   3 \n",
      "[-0.7285156   0.15893555 -0.09338379 -0.13977051 -0.11474609 -0.00985718] 1   1 Match 140\n",
      "\n",
      "[-0.4814453   0.24731445  0.10321045  0.18029785 -0.2980957  -0.50390625] 1   3 \n",
      "[-0.67529297  0.08551025  0.14758301  0.09924316 -0.01204681 -0.22131348] 2   4 \n",
      "[-1.4814453  -0.19836426 -0.17138672  0.42529297  0.41503906  0.18005371] 3   5 \n",
      "[-1.7929688  -0.1361084  -0.27563477  0.3347168   0.55078125  0.4169922 ] 4   3 \n",
      "[-0.44091797  0.11535645 -0.12280273 -0.13659668 -0.05163574 -0.06137085] 1   5 \n",
      "[-1.2001953  -0.04840088  0.29956055  0.43774414 -0.14013672 -0.14941406] 3   3 Match 141\n",
      "\n",
      "[-0.9213867  -0.1192627   0.1182251   0.3894043  -0.04537964 -0.1282959 ] 3   5 \n",
      "[-0.6958008   0.05163574  0.18041992  0.19055176 -0.23303223 -0.14831543] 3   4 \n",
      "[-0.50927734  0.08447266 -0.10491943 -0.02905273 -0.07080078 -0.06561279] 1   3 \n",
      "[-1.0146484   0.10827637  0.26611328  0.42578125 -0.02650452 -0.01766968] 3   5 \n",
      "[-1.0800781  -0.04589844 -0.03710938  0.18054199  0.13989258 -0.00512314] 3   3 Match 142\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.34399414  0.24816895  0.02238464  0.06842041 -0.14453125 -0.31347656] 1   2 \n",
      "[-0.97509766  0.10070801  0.1574707   0.25219727 -0.02905273 -0.41259766] 3   2 \n",
      "[-0.17175293  0.33666992  0.1895752  -0.02011108 -0.46411133 -0.52490234] 1   2 \n",
      "[-0.4326172   0.1652832  -0.13391113  0.03448486 -0.01824951 -0.12420654] 1   1 Match 143\n",
      "\n",
      "[-2.0703125  -0.59765625 -0.1842041   0.8496094   0.6879883   0.08770752] 3   4 \n",
      "[-0.24206543  0.19836426  0.24291992 -0.14013672 -0.41723633 -0.48535156] 2   2 Match 144\n",
      "\n",
      "[-1.8154297  -0.16955566 -0.44262695  0.20947266  0.72558594  0.58447266] 4   1 \n",
      "[-1.078125   -0.03921509 -0.12268066 -0.02496338 -0.01124573  0.24450684] 5   5 Match 145\n",
      "\n",
      "[-1.8681641  -0.35839844 -0.15917969  0.38989258  0.765625    0.23510742] 4   3 \n",
      "[-1.6376953   0.05950928  0.28881836  0.5136719   0.47216797 -0.31591797] 3   3 Match 146\n",
      "\n",
      "[-1.1591797   0.11950684 -0.23205566  0.02293396  0.50390625  0.1496582 ] 4   2 \n",
      "[-1.5488281  -0.26538086 -0.62841797  0.27001953  0.6152344   0.73095703] 5   3 \n",
      "[-1.1630859  -0.05157471 -0.0241394   0.1895752   0.0869751   0.05975342] 3   5 \n",
      "[-0.9296875  -0.0317688   0.28979492  0.51220703  0.05133057 -0.2084961 ] 3   4 \n",
      "[-1.5664062  -0.26245117 -0.05447388  0.64990234  0.38500977 -0.12084961] 3   5 \n",
      "[-1.1464844   0.10394287  0.18383789  0.34643555  0.06088257 -0.3503418 ] 3   2 \n",
      "[-0.95458984  0.22070312  0.5283203   0.4074707  -0.4116211  -0.63671875] 2   5 \n",
      "[-1.0976562   0.06402588  0.42871094  0.5678711  -0.03875732 -0.54589844] 3   3 Match 147\n",
      "\n",
      "[-1.3378906  -0.11279297  0.14929199  0.45703125  0.27612305  0.03598022] 3   4 \n",
      "[-0.10266113  0.09069824 -0.18566895 -0.06384277 -0.13513184 -0.09570312] 1   3 \n",
      "[-0.2590332   0.22668457  0.4182129  -0.04336548 -0.3569336  -0.6767578 ] 2   2 Match 148\n",
      "\n",
      "[-0.00777817  0.23168945  0.2319336  -0.11816406 -0.39135742 -0.61621094] 2   5 \n",
      "[-0.3720703   0.4506836   0.296875    0.22058105 -0.5107422  -0.45776367] 1   3 \n",
      "[-1.4863281  -0.20251465 -0.07806396  0.33544922  0.4560547   0.41015625] 4   3 \n",
      "[-0.5390625   0.25439453  0.4482422   0.29345703 -0.36157227 -0.71875   ] 2   2 Match 149\n",
      "\n",
      "[-0.7475586   0.32666016 -0.12866211 -0.00617981 -0.09570312 -0.03720093] 1   0 \n",
      "[-0.6201172   0.32666016  0.52246094  0.28198242 -0.30810547 -0.9375    ] 2   4 \n",
      "[-1.0273438   0.18286133  0.3112793   0.18640137 -0.30737305 -0.37182617] 2   4 \n",
      "[-1.6621094  -0.27929688 -0.38110352  0.22766113  0.76220703  0.3605957 ] 4   4 Match 150\n",
      "\n",
      "[-0.6743164   0.1821289  -0.00279427 -0.14782715 -0.12359619  0.0925293 ] 1   1 Match 151\n",
      "\n",
      "[-1.6972656  -0.27392578 -0.45825195  0.18701172  0.5986328   0.6772461 ] 5   3 \n",
      "[-0.62841797  0.08508301  0.42797852  0.40161133 -0.18359375 -0.4716797 ] 2   1 \n",
      "[-0.93603516  0.18237305 -0.23840332 -0.05752563  0.2890625   0.16918945] 4   5 \n",
      "[-1.9003906  -0.12194824 -0.18713379  0.4375      0.4658203   0.31469727] 4   3 \n",
      "[-1.0195312   0.3955078  -0.16296387  0.19433594  0.12225342 -0.01977539] 1   1 Match 152\n",
      "\n",
      "[-0.92041016  0.03155518  0.2861328   0.55615234 -0.08337402 -0.3708496 ] 3   2 \n",
      "[-1.7802734  -0.23864746  0.04998779  0.6430664   0.37402344  0.2019043 ] 3   5 \n",
      "[-1.4228516   0.22241211  0.26635742  0.4621582  -0.26220703 -0.3720703 ] 3   3 Match 153\n",
      "\n",
      "[-2.3046875  -0.3388672  -0.50634766  0.7285156   0.7973633   0.45117188] 4   5 \n",
      "[-2.1816406  -0.33251953 -0.45947266  0.52490234  0.74560547  0.41845703] 4   5 \n",
      "[-1.9912109  -0.26611328 -0.19116211  0.65771484  0.55566406 -0.07910156] 3   5 \n",
      "[-0.9003906   0.2097168   0.21142578  0.26538086 -0.20812988 -0.33642578] 3   1 \n",
      "[-1.0712891  -0.01646423  0.01615906 -0.09979248  0.17138672  0.19812012] 5   4 \n",
      "[-1.7265625  -0.11853027  0.04205322  0.6220703   0.07592773  0.01899719] 3   1 \n",
      "[-2.421875   -0.41308594 -0.4572754   0.62402344  0.8486328   0.72509766] 4   4 Match 154\n",
      "\n",
      "[-1.7802734  -0.24084473 -0.3215332   0.46069336  0.5488281   0.2524414 ] 4   5 \n",
      "[-1.9863281  -0.3293457  -0.45507812  0.38208008  0.70703125  0.49194336] 4   2 \n",
      "[-2.1445312  -0.42895508 -0.33422852  0.6308594   0.69189453  0.6020508 ] 4   4 Match 155\n",
      "\n",
      "[-0.34985352  0.01157379  0.10339355 -0.01208496 -0.4104004  -0.29858398] 2   4 \n",
      "[-1.5878906  -0.26635742 -0.17199707  0.6176758   0.49487305 -0.00278091] 3   5 \n",
      "[-1.4833984  -0.17907715 -0.38452148  0.46044922  0.28271484  0.30273438] 3   4 \n",
      "[-1.5517578  -0.2211914  -0.24169922  0.33642578  0.56884766  0.18237305] 4   4 Match 156\n",
      "\n",
      "[-1.4375     -0.10021973  0.02851868  0.7246094   0.16955566 -0.28808594] 3   2 \n",
      "[-1.9472656  -0.5048828  -0.26391602  0.8027344   0.5136719   0.12719727] 3   4 \n",
      "[-2.0117188  -0.38964844 -0.16992188  0.6303711   0.7319336   0.38330078] 4   4 Match 157\n",
      "\n",
      "[-2.2148438  -0.3791504  -0.23608398  0.8334961   0.5913086   0.5053711 ] 3   3 Match 158\n",
      "\n",
      "[-0.62646484 -0.01573181  0.04608154  0.03375244 -0.16455078 -0.1015625 ] 2   4 \n",
      "[-0.9243164   0.06524658  0.10137939 -0.02206421 -0.0302887  -0.09991455] 2   4 \n",
      "[-1.7783203  -0.32958984 -0.02151489  0.7807617   0.47094727  0.06634521] 3   3 Match 159\n",
      "\n",
      "[-2.0429688  -0.39233398 -0.23291016  0.6503906   0.62939453  0.45239258] 3   1 \n",
      "[-0.9370117  -0.04364014  0.10601807  0.5048828   0.3046875  -0.16918945] 3   1 \n",
      "[-1.9775391  -0.37646484 -0.40673828  0.43823242  0.7973633   0.66796875] 4   4 Match 160\n",
      "\n",
      "[-1.2128906   0.06915283  0.01992798  0.33447266  0.08990479 -0.1529541 ] 3   4 \n",
      "[-0.80029297  0.13647461  0.31835938  0.13916016 -0.31811523 -0.42260742] 2   1 \n",
      "[-0.19238281  0.28833008  0.39501953 -0.05044556 -0.5126953  -0.6567383 ] 2   1 \n",
      "[-2.203125   -0.2878418  -0.12646484  0.9472656   0.48657227 -0.07550049] 3   4 \n",
      "[-1.7167969  -0.28295898 -0.08612061  0.4650879   0.34204102 -0.06066895] 3   4 \n",
      "[ 0.04058838  0.27294922 -0.12561035 -0.22497559 -0.27685547 -0.2479248 ] 1   0 \n",
      "[-0.03677368  0.09643555 -0.15649414 -0.11999512 -0.21923828 -0.17944336] 1   0 \n",
      "[ 0.65771484  0.7792969   0.53515625 -0.04592896 -0.7890625  -1.2304688 ] 1   2 \n",
      "[-1.9169922  -0.1829834  -0.31274414  0.7426758   0.85302734  0.21411133] 4   1 \n",
      "[-1.5126953   0.1038208   0.03488159  0.47607422  0.4165039  -0.25073242] 3   1 \n",
      "[-1.9277344  -0.24584961  0.01133728  0.79785156  0.21582031 -0.03771973] 3   4 \n",
      "[-1.5136719  -0.16540527 -0.09613037  0.48339844  0.26171875 -0.10766602] 3   3 Match 161\n",
      "\n",
      "[-0.89990234  0.19458008  0.1206665   0.18200684  0.41137695  0.30908203] 4   5 \n",
      "[-2.0175781  -0.31079102 -0.5957031   0.3984375   0.64208984  0.7084961 ] 5   4 \n",
      "[-0.29003906  0.27612305  0.05953979 -0.11639404 -0.28320312  0.05438232] 1   1 Match 162\n",
      "\n",
      "[-1.5419922   0.20410156  0.41210938  0.68115234 -0.1005249  -0.50097656] 3   1 \n",
      "[-1.6767578  -0.30419922 -0.46777344  0.4104004   0.39916992  0.7089844 ] 5   5 Match 163\n",
      "\n",
      "[-0.3684082   0.48413086  0.5263672   0.10876465 -0.46777344 -0.7441406 ] 2   1 \n",
      "[-1.8564453  -0.15319824 -0.09887695  0.6191406   0.48242188  0.06304932] 3   5 \n",
      "[-1.15625     0.0151062  -0.27685547 -0.15466309  0.2890625   0.36889648] 5   4 \n",
      "[-0.18286133  0.24108887  0.09124756 -0.09100342 -0.41625977 -0.18652344] 1   5 \n",
      "[-1.7929688  -0.26904297 -0.43774414  0.41259766  0.49609375  0.8442383 ] 5   5 Match 164\n",
      "\n",
      "[-0.3071289   0.10687256  0.13586426 -0.07897949 -0.3701172  -0.48999023] 2   4 \n",
      "[-1.1904297e+00  2.1064281e-04 -7.7636719e-02  3.0273438e-01\n",
      "  1.1224365e-01  7.4523926e-02] 3   4 \n",
      "[-0.9824219   0.16772461  0.03463745  0.29125977  0.04251099 -0.18029785] 3   1 \n",
      "[-0.16345215  0.39868164  0.37646484  0.08850098 -0.67871094 -0.4572754 ] 1   4 \n",
      "[-0.7714844   0.14575195  0.32763672  0.03369141 -0.3305664  -0.3959961 ] 2   2 Match 165\n",
      "\n",
      "[-0.6279297   0.02845764 -0.03744507  0.02282715  0.06262207 -0.01741028] 4   3 \n",
      "[-1.4951172  -0.14611816 -0.42407227  0.1899414   0.5136719   0.72021484] 5   4 \n",
      "[-1.7792969  -0.49438477 -0.22802734  0.66259766  0.5419922   0.03720093] 3   4 \n",
      "[-1.6474609  -0.3798828  -0.02581787  0.69921875  0.5854492  -0.03955078] 3   4 \n",
      "[-0.8598633   0.4152832   0.12176514  0.2109375   0.23071289 -0.15563965] 1   1 Match 166\n",
      "\n",
      "[-2.0761719  -0.18005371 -0.5366211   0.39453125  0.92871094  0.625     ] 4   4 Match 167\n",
      "\n",
      "[-1.5644531  -0.26049805 -0.23376465  0.37304688  0.42895508  0.21728516] 4   3 \n",
      "[ 0.32006836  0.44433594  0.21142578 -0.40454102 -0.5620117  -0.47973633] 1   5 \n",
      "[-0.546875    0.06481934 -0.1227417   0.00553513  0.07073975  0.0103302 ] 4   1 \n",
      "[-0.7270508   0.00204849  0.22924805  0.07794189 -0.2220459  -0.26757812] 2   3 \n",
      "[-0.41455078  0.2590332  -0.1126709  -0.26831055 -0.24780273  0.23632812] 1   3 \n",
      "[-1.2363281   0.12286377  0.33447266  0.38916016 -0.13916016 -0.18591309] 3   5 \n",
      "[-0.33520508  0.28442383  0.5307617   0.30273438 -0.45581055 -0.7294922 ] 2   2 Match 168\n",
      "\n",
      "[-0.26538086  0.15270996 -0.09155273 -0.01354218 -0.14074707 -0.13659668] 1   1 Match 169\n",
      "\n",
      "[-1.7548828  -0.19689941 -0.38916016  0.31567383  0.4128418   0.52783203] 5   5 Match 170\n",
      "\n",
      "[-1.1992188   0.19665527  0.18713379  0.23291016 -0.21716309 -0.3720703 ] 3   1 \n",
      "[-0.26879883  0.1932373   0.19836426  0.02983093 -0.64990234 -0.5253906 ] 2   5 \n",
      "[-1.5068359   0.04449463  0.16516113  0.70654297  0.28637695 -0.3408203 ] 3   3 Match 171\n",
      "\n",
      "[-1.0117188   0.171875    0.44580078  0.6166992  -0.12524414 -0.7680664 ] 3   1 \n",
      "[-0.30126953  0.5058594   0.29467773  0.00894165 -0.41479492 -0.78515625] 1   2 \n",
      "[-1.7714844  -0.06384277 -0.03726196  0.55566406  0.36987305  0.07879639] 3   1 \n",
      "[-0.72216797  0.26733398  0.45532227  0.34472656 -0.6826172  -0.8203125 ] 2   3 \n",
      "[-0.01330566  0.1862793   0.14819336 -0.1875     -0.42919922 -0.12805176] 1   1 Match 172\n",
      "\n",
      "[-0.7006836   0.20593262  0.02926636 -0.04064941 -0.01948547 -0.02990723] 1   5 \n",
      "[-0.29858398  0.1071167  -0.14233398 -0.03799438 -0.09533691 -0.18237305] 1   5 \n",
      "[-0.80566406  0.02742004  0.23364258  0.22338867 -0.09912109 -0.5908203 ] 2   1 \n",
      "[-1.5302734  -0.21032715 -0.06658936  0.29882812  0.49829102  0.2064209 ] 4   3 \n",
      "[-1.265625   -0.16064453  0.17578125  0.32348633  0.24316406 -0.18444824] 3   3 Match 173\n",
      "\n",
      "[-2.4277344  -0.2939453  -0.5541992   0.4724121   0.94189453  0.7919922 ] 4   4 Match 174\n",
      "\n",
      "[-1.3457031  -0.09210205  0.3581543   0.5727539  -0.02287292 -0.5185547 ] 3   3 Match 175\n",
      "\n",
      "[-0.8041992   0.17468262  0.29516602  0.11895752  0.03128052 -0.38745117] 2   1 \n",
      "[-1.6542969  -0.09216309 -0.02487183  0.57373047  0.3244629  -0.06707764] 3   5 \n",
      "[-1.8037109  -0.42919922 -0.3774414   0.5463867   0.54589844  0.28808594] 3   2 \n",
      "[-2.515625   -0.546875   -0.50927734  0.8510742   0.99609375  0.58496094] 4   4 Match 176\n",
      "\n",
      "[-1.5195312   0.08074951 -0.24267578  0.2685547   0.46264648  0.5048828 ] 5   5 Match 177\n",
      "\n",
      "[-1.9199219  -0.13684082  0.13513184  0.8417969   0.23339844 -0.10943604] 3   0 \n",
      "[-0.4482422   0.24267578  0.2512207   0.1875     -0.03152466 -0.37402344] 2   4 \n",
      "[-0.36938477  0.453125    0.3605957   0.14758301 -0.10430908 -0.81152344] 1   4 \n",
      "[-1.4648438  -0.19067383  0.1907959   0.6611328   0.46606445 -0.03808594] 3   4 \n",
      "[-1.0722656   0.11010742  0.17053223  0.16796875  0.02024841 -0.33789062] 2   3 \n",
      "[-1.3486328   0.12451172  0.3408203   0.40576172  0.11517334 -0.35131836] 3   4 \n",
      "[-1.6923828  -0.00536728  0.11047363  0.37353516  0.45922852  0.01599121] 4   2 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-2.2128906  -0.30639648 -0.26245117  0.62890625  0.6801758   0.5888672 ] 4   5 \n",
      "[-0.98095703  0.19421387  0.55615234  0.37841797 -0.3347168  -0.73046875] 2   4 \n",
      "[-1.7207031  -0.16992188 -0.08825684  0.41845703  0.6538086   0.22888184] 4   5 \n",
      "[-2.0429688  -0.23669434 -0.4580078   0.45483398  0.51171875  0.67285156] 5   3 \n",
      "[-0.88378906 -0.0071373   0.14929199  0.06204224 -0.1538086  -0.08392334] 2   3 \n",
      "[-1.6152344  -0.22741699 -0.47314453  0.13720703  0.6225586   0.51171875] 4   4 Match 178\n",
      "\n",
      "[-1.2011719   0.08404541  0.50683594  0.53027344 -0.15063477 -0.5649414 ] 3   3 Match 179\n",
      "\n",
      "[-1.0712891   0.17675781  0.43359375  0.5385742  -0.23278809 -0.55078125] 3   5 \n",
      "[-0.8359375   0.09368896  0.36499023  0.26367188 -0.046875   -0.29418945] 2   5 \n",
      "[-0.5566406  -0.17358398 -0.03112793  0.1829834  -0.14416504  0.04006958] 3   5 \n",
      "[-1.0009766  -0.16088867  0.33276367  0.39672852 -0.02835083 -0.08148193] 3   5 \n",
      "[-1.3037109   0.19628906  0.27416992  0.4921875  -0.0032692  -0.36328125] 3   4 \n",
      "[-1.9150391  -0.27929688 -0.29125977  0.65966797  0.44311523  0.20361328] 3   2 \n",
      "[-1.8271484  -0.22485352  0.0970459   0.8696289   0.1986084  -0.25219727] 3   4 \n",
      "[-0.2310791   0.16918945 -0.11645508 -0.04940796 -0.13061523 -0.15515137] 1   2 \n",
      "[-1.8017578  -0.2541504   0.20373535  0.7583008   0.11431885 -0.17297363] 3   1 \n",
      "[-1.4824219   0.27490234  0.08233643  0.56689453  0.1081543  -0.41674805] 3   3 Match 180\n",
      "\n",
      "[-0.46435547  0.18457031  0.10858154  0.20825195 -0.11004639 -0.31274414] 3   5 \n",
      "[-1.1259766   0.02601624 -0.19372559  0.03457642  0.13586426  0.14489746] 5   4 \n",
      "[-1.3554688  -0.08404541  0.4025879   0.7060547  -0.11096191 -0.28637695] 3   3 Match 181\n",
      "\n",
      "[-1.1240234   0.13745117  0.2836914   0.37817383 -0.17858887 -0.4555664 ] 3   4 \n",
      "[-1.2646484  -0.01353455  0.19189453  0.51660156 -0.17321777 -0.25341797] 3   3 Match 182\n",
      "\n",
      "[-1.0429688   0.21264648  0.39575195  0.6308594  -0.08959961 -0.5810547 ] 3   4 \n",
      "[ 0.20983887  0.34155273  0.10510254 -0.08050537 -0.42211914 -0.70703125] 1   5 \n",
      "[-0.17321777  0.3293457   0.33862305  0.02313232 -0.53027344 -0.5366211 ] 2   2 Match 183\n",
      "\n",
      "[-0.62646484  0.42822266  0.1899414  -0.05966187  0.00832367 -0.42773438] 1   5 \n",
      "[-1.6650391  -0.10754395 -0.33129883  0.34204102  0.6269531   0.30810547] 4   4 Match 184\n",
      "\n",
      "[-1.515625   -0.00991821  0.0112915   0.46289062  0.41992188 -0.20666504] 3   2 \n",
      "[-1.5898438   0.11376953 -0.08782959  0.45410156  0.10443115 -0.32836914] 3   3 Match 185\n",
      "\n",
      "[-1.6533203  -0.24414062 -0.22875977  0.51660156  0.39892578  0.36938477] 3   2 \n",
      "[-0.5283203   0.1472168   0.1796875   0.10400391 -0.23901367 -0.31835938] 2   5 \n",
      "[-1.2363281  -0.12097168 -0.37182617  0.0055809   0.40429688  0.64404297] 5   5 Match 186\n",
      "\n",
      "[-1.0908203   0.0480957   0.05484009  0.21459961 -0.42016602 -0.1616211 ] 3   4 \n",
      "[-2.2167969  -0.2993164  -0.6171875   0.49023438  0.82421875  0.8720703 ] 5   3 \n",
      "[-2.1269531  -0.20910645 -0.38549805  0.4099121   0.7182617   0.78466797] 5   5 Match 187\n",
      "\n",
      "[-1.8505859  -0.27001953 -0.24975586  0.56933594  0.5488281   0.19384766] 3   5 \n",
      "[-1.4501953  -0.13256836 -0.31176758  0.34692383  0.3413086   0.22363281] 3   2 \n",
      "[-0.7109375   0.14074707  0.32592773  0.14099121 -0.3708496  -0.70996094] 2   2 Match 188\n",
      "\n",
      "[-0.9008789   0.21777344  0.6274414   0.5551758  -0.05673218 -0.7446289 ] 2   4 \n",
      "[-1.7675781  -0.18041992 -0.7270508   0.15246582  0.62402344  1.0888672 ] 5   4 \n",
      "[-0.01837158  0.6196289   0.45092773  0.10784912 -0.5942383  -1.0986328 ] 1   1 Match 189\n",
      "\n",
      "[-0.38061523  0.28466797  0.49560547  0.06945801 -0.43725586 -0.546875  ] 2   2 Match 190\n",
      "\n",
      "[-0.4309082   0.5800781   0.55078125  0.26660156 -0.7138672  -0.83496094] 1   0 \n",
      "[-0.6479492   0.18151855  0.3515625   0.28515625 -0.32739258 -0.36499023] 2   2 Match 191\n",
      "\n",
      "[-1.6230469  -0.12609863 -0.34814453  0.18200684  0.44458008  0.43359375] 4   4 Match 192\n",
      "\n",
      "[-1.5576172  -0.19519043 -0.22314453  0.39013672  0.5527344   0.38232422] 4   2 \n",
      "[-0.8076172   0.04519653  0.15136719  0.08251953  0.10040283 -0.30395508] 2   0 \n",
      "[-0.56103516  0.21582031  0.04296875 -0.19592285 -0.37475586 -0.19128418] 1   3 \n",
      "[-1.8857422  -0.13134766 -0.11364746  0.58447266  0.6166992   0.40234375] 4   5 \n",
      "[ 0.10443115  0.3359375   0.2902832  -0.13244629 -0.6567383  -0.6826172 ] 1   5 \n",
      "[-2.234375   -0.43798828 -0.34838867  0.9824219   0.64404297  0.20007324] 3   5 \n",
      "[-0.18725586  0.11206055 -0.13891602 -0.06201172 -0.16552734 -0.14794922] 1   2 \n",
      "[-0.9477539   0.1640625   0.28125     0.24450684 -0.33447266 -0.53027344] 2   4 \n",
      "[-0.82128906  0.04229736  0.25048828  0.08099365 -0.12078857 -0.18798828] 2   3 \n",
      "[-0.6777344   0.13635254  0.17712402 -0.07562256 -0.1772461  -0.41552734] 2   3 \n",
      "[-0.4885254   0.09960938 -0.1875      0.02297974 -0.04110718 -0.09881592] 1   5 \n",
      "[-0.5239258   0.23022461  0.30151367  0.01163483 -0.4399414  -0.44213867] 2   4 \n",
      "[-1.9150391  -0.3383789  -0.47460938  0.6118164   0.60595703  0.59716797] 3   5 \n",
      "[-0.37817383  0.2998047   0.4609375   0.15466309 -0.3671875  -0.7753906 ] 2   0 \n",
      "[-0.7685547   0.13684082  0.3684082   0.18322754 -0.01786804 -0.43530273] 2   2 Match 193\n",
      "\n",
      "[-1.8125     -0.19506836 -0.40039062  0.3154297   0.65185547  0.64208984] 4   5 \n",
      "[-0.5136719   0.23266602  0.4819336   0.16467285 -0.40185547 -0.7685547 ] 2   1 \n",
      "[-2.3535156  -0.453125   -0.6035156   0.59228516  0.81152344  0.76416016] 4   5 \n",
      "[-1.9345703  -0.25756836 -0.53222656  0.38232422  0.5678711   0.7236328 ] 5   4 \n",
      "[-1.9765625  -0.15686035 -0.20568848  0.7216797   0.45654297  0.09118652] 3   1 \n",
      "[-1.3349609   0.07751465  0.31713867  0.48510742 -0.30322266 -0.5390625 ] 3   1 \n",
      "[ 0.28710938  0.5209961   0.42919922 -0.09906006 -0.7421875  -0.88916016] 1   4 \n",
      "[-0.6791992   0.15002441  0.40185547  0.4482422  -0.26879883 -0.7167969 ] 3   3 Match 194\n",
      "\n",
      "[-2.2519531  -0.41381836 -0.2668457   0.7324219   0.6503906   0.2758789 ] 3   3 Match 195\n",
      "\n",
      "[-0.29785156  0.25585938 -0.07666016 -0.01235199 -0.34375    -0.14672852] 1   4 \n",
      "[-0.46679688  0.10693359  0.40429688  0.3408203  -0.1484375  -0.5395508 ] 2   2 Match 196\n",
      "\n",
      "[-1.3007812   0.07922363  0.01119995  0.22253418  0.22717285  0.14147949] 4   4 Match 197\n",
      "\n",
      "[-0.9873047   0.20349121  0.37890625  0.36645508 -0.47265625 -0.28173828] 2   2 Match 198\n",
      "\n",
      "[-0.49804688  0.29541016  0.43286133  0.15246582 -0.50634766 -0.53125   ] 2   1 \n",
      "[-0.91259766  0.03717041 -0.13134766  0.13781738  0.09057617 -0.12475586] 3   0 \n",
      "[-1.8349609  -0.31396484 -0.5966797   0.14868164  0.87597656  0.9350586 ] 5   4 \n",
      "[-1.6455078  -0.00931549 -0.32250977  0.2355957   0.5288086   0.5107422 ] 4   1 \n",
      "[-1.9667969  -0.44140625 -0.07092285  0.6850586   0.42993164 -0.15673828] 3   5 \n",
      "[-1.4140625  -0.11804199 -0.26660156  0.21911621  0.6459961   0.59716797] 4   4 Match 199\n",
      "\n",
      "[-1.2382812  -0.09136963 -0.07629395  0.36206055  0.40625     0.30859375] 4   2 \n",
      "[-2.3671875  -0.34594727 -0.6894531   0.5024414   0.89404297  0.81933594] 4   4 Match 200\n",
      "\n",
      "[-1.4580078  -0.20996094 -0.14501953  0.34936523  0.3955078   0.23876953] 4   4 Match 201\n",
      "\n",
      "[-1.8681641  -0.05270386 -0.2680664   0.22229004  0.8144531   0.5878906 ] 4   4 Match 202\n",
      "\n",
      "[-2.4160156  -0.2800293  -0.4790039   0.6010742   0.8925781   0.80322266] 4   4 Match 203\n",
      "\n",
      "[-1.8056641  -0.38500977 -0.32470703  0.45166016  0.47924805  0.21643066] 4   3 \n",
      "[-1.2363281   0.07147217  0.4111328   0.5786133  -0.23925781 -0.3515625 ] 3   1 \n",
      "[-0.63720703  0.03207397 -0.18225098 -0.16052246 -0.10211182  0.28881836] 5   1 \n",
      "[-1.3066406   0.20410156  0.51904297  0.66748047 -0.3395996  -0.6953125 ] 3   1 \n",
      "[-1.3398438  -0.15197754 -0.17260742  0.1665039   0.1394043   0.48901367] 5   1 \n",
      "[-0.36132812  0.29174805  0.16381836  0.05529785 -0.2758789  -0.61035156] 1   4 \n",
      "[ 0.02914429  0.26586914  0.10375977 -0.15698242 -0.4741211  -0.50439453] 1   1 Match 204\n",
      "\n",
      "[-1.1455078  -0.10717773  0.06002808  0.33642578  0.05081177 -0.34399414] 3   4 \n",
      "[-1.1875     -0.02108765 -0.1887207   0.05255127  0.21191406  0.3005371 ] 5   4 \n",
      "[-1.4570312  -0.20800781  0.28710938  0.64697266 -0.07122803 -0.42089844] 3   4 \n",
      "[-0.35327148  0.09429932 -0.12219238 -0.06884766 -0.11291504 -0.12634277] 1   1 Match 205\n",
      "\n",
      "[-1.3017578  -0.06518555  0.25268555  0.48364258  0.07666016 -0.26904297] 3   2 \n",
      "[-1.1611328   0.12817383  0.46191406  0.65527344  0.01259613 -0.57421875] 3   5 \n",
      "[-1.6035156  -0.15783691 -0.4074707   0.42797852  0.42773438  0.5126953 ] 5   3 \n",
      "[-0.60791016  0.11364746  0.09472656 -0.07861328 -0.13708496 -0.25756836] 1   2 \n",
      "[-1.3935547   0.04418945  0.05334473  0.4152832   0.17260742 -0.06143188] 3   5 \n",
      "[-2.0234375  -0.4621582  -0.29858398  0.6196289   0.7973633   0.15625   ] 4   1 \n",
      "[-1.9814453  -0.2401123  -0.4868164   0.31079102  0.6347656   0.76171875] 5   3 \n",
      "[-0.13220215  0.15136719 -0.04638672 -0.14953613 -0.34570312 -0.18640137] 1   1 Match 206\n",
      "\n",
      "[-2.4746094  -0.51220703 -0.70214844  0.5986328   0.94873047  0.7871094 ] 4   5 \n",
      "[-0.8413086  -0.01631165 -0.10266113  0.04489136  0.06518555  0.11065674] 5   3 \n",
      "[-2.1464844  -0.40576172 -0.35839844  0.55126953  0.8413086   0.6347656 ] 4   4 Match 207\n",
      "\n",
      "[-1.6357422  -0.12548828 -0.08117676  0.41430664  0.37280273  0.2697754 ] 3   5 \n",
      "[-2.1191406  -0.36669922 -0.6640625   0.40795898  0.8251953   0.7763672 ] 4   4 Match 208\n",
      "\n",
      "[-1.8144531  -0.3310547  -0.3618164   0.5698242   0.6381836   0.49682617] 4   5 \n",
      "[-0.6972656   0.32421875  0.51660156  0.33251953 -0.7084961  -0.7373047 ] 2   5 \n",
      "[-2.3164062  -0.47973633 -0.7504883   0.48413086  1.0224609   1.0595703 ] 5   5 Match 209\n",
      "\n",
      "[-2.0039062  -0.3408203  -0.34643555  0.6489258   0.6123047   0.10882568] 3   4 \n",
      "[-1.3662109   0.12902832 -0.27514648  0.05950928  0.2770996   0.45629883] 5   5 Match 210\n",
      "\n",
      "[ 0.58203125  0.5473633   0.35961914 -0.26416016 -0.77197266 -0.80859375] 0   0 Match 211\n",
      "\n",
      "[-1.4863281   0.02952576  0.6118164   0.69140625 -0.03753662 -0.7167969 ] 3   2 \n",
      "[-1.75       -0.14343262  0.15026855  0.58740234  0.34985352 -0.11578369] 3   5 \n",
      "[-1.6552734  -0.19116211 -0.17907715  0.34887695  0.6064453   0.21777344] 4   1 \n",
      "[-1.4775391  -0.05804443 -0.0125885   0.26782227  0.1517334   0.12805176] 3   2 \n",
      "[ 0.3293457   0.33544922 -0.07067871 -0.32177734 -0.49316406 -0.01223755] 1   2 \n",
      "[-1.5830078  -0.3076172  -0.28955078  0.4465332   0.32958984  0.05892944] 3   1 \n",
      "[-1.53125    -0.01303864  0.51220703  0.6777344   0.00867462 -0.58740234] 3   2 \n",
      "[-1.0556641  -0.09368896  0.04873657  0.5756836   0.06817627 -0.22558594] 3   1 \n",
      "[-1.6220703   0.02076721 -0.3017578   0.1071167   0.80126953  0.6557617 ] 4   5 \n",
      "[-1.6396484  -0.3088379  -0.2401123   0.39111328  0.7084961   0.40283203] 4   3 \n",
      "[-1.6455078   0.09295654  0.10699463  0.6074219   0.33618164 -0.17285156] 3   4 \n",
      "[-1.6689453  -0.2154541  -0.3803711   0.29077148  0.44628906  0.5366211 ] 5   3 \n",
      "[-0.1977539   0.10546875 -0.18066406 -0.04220581 -0.10174561 -0.14648438] 1   4 \n",
      "[-0.95654297  0.05865479  0.2244873   0.21557617  0.08966064 -0.05749512] 2   3 \n",
      "[-0.5786133   0.36669922  0.57177734  0.5136719  -0.5102539  -0.8823242 ] 2   3 \n",
      "[-1.46875     0.11077881 -0.23828125  0.09259033  0.44702148  0.29907227] 4   2 \n",
      "[-0.91552734  0.5263672   0.58447266  0.5229492  -0.48266602 -0.8046875 ] 2   1 \n",
      "[-0.8120117   0.03839111 -0.01405334  0.21862793  0.03283691  0.15368652] 3   3 Match 212\n",
      "\n",
      "[-0.19702148  0.23657227  0.14025879 -0.07714844 -0.3725586  -0.2861328 ] 1   4 \n",
      "[-1.2333984   0.08654785  0.26367188  0.47705078  0.11352539 -0.5234375 ] 3   4 \n",
      "[-1.0107422   0.30151367  0.3623047   0.26513672  0.01873779 -0.25024414] 2   4 \n",
      "[-1.4794922  -0.22741699 -0.48486328  0.13842773  0.38745117  0.6430664 ] 5   2 \n",
      "[-1.6894531  -0.14831543 -0.44970703 -0.02285767  0.55566406  0.73779297] 5   5 Match 213\n",
      "\n",
      "[-1.4443359   0.09875488 -0.32495117  0.30786133  0.58251953  0.26220703] 4   4 Match 214\n",
      "\n",
      "[-0.45776367  0.01704407 -0.18920898  0.00918579 -0.0319519  -0.01448822] 1   4 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.4638672  -0.2692871  -0.25634766  0.27905273  0.25512695  0.21228027] 3   3 Match 215\n",
      "\n",
      "[-1.6035156   0.01256561  0.22631836  0.5151367   0.2939453   0.13293457] 3   2 \n",
      "[ 0.02359009  0.30371094  0.20336914 -0.24206543 -0.4711914  -0.30126953] 1   0 \n",
      "[-1.9121094  -0.26049805 -0.3684082   0.3623047   0.56689453  0.5966797 ] 5   3 \n",
      "[-1.2685547   0.03295898  0.47387695  0.76660156 -0.1928711  -0.5942383 ] 3   4 \n",
      "[-1.1894531   0.05776978 -0.578125   -0.01985168  0.39501953  0.78222656] 5   2 \n",
      "[-0.84521484  0.10406494  0.48339844  0.31982422 -0.43432617 -0.82128906] 2   3 \n",
      "[-0.22180176  0.48217773  0.32836914 -0.01629639 -0.3100586  -0.58496094] 1   4 \n",
      "[-0.6044922   0.3125      0.30371094  0.05197144 -0.36376953 -0.3774414 ] 1   1 Match 216\n",
      "\n",
      "[-1.3779297  -0.10876465  0.17150879  0.50439453  0.14526367 -0.07183838] 3   2 \n",
      "[-1.6132812  -0.13928223 -0.19360352  0.3330078   0.56103516  0.50097656] 4   4 Match 217\n",
      "\n",
      "[-1.0283203   0.17663574  0.39404297  0.09838867 -0.17749023 -0.42333984] 2   2 Match 218\n",
      "\n",
      "[-0.89160156  0.15576172 -0.2232666  -0.33203125 -0.13745117  0.17858887] 5   5 Match 219\n",
      "\n",
      "[-0.8989258   0.20056152  0.09588623  0.22216797 -0.1743164  -0.4050293 ] 3   5 \n",
      "[-2.4003906  -0.40356445 -0.5151367   0.7373047   0.83691406  0.7529297 ] 4   4 Match 220\n",
      "\n",
      "[-0.9355469  -0.11645508 -0.28393555  0.07342529  0.30786133  0.5107422 ] 5   5 Match 221\n",
      "\n",
      "[-0.5864258   0.37304688  0.7602539   0.45361328 -0.6484375  -0.9536133 ] 2   2 Match 222\n",
      "\n",
      "[-0.24194336  0.30029297  0.33422852  0.29077148 -0.55078125 -0.9746094 ] 2   3 \n",
      "[-1.7714844  -0.01670837  0.14135742  0.60546875  0.16918945 -0.36645508] 3   4 \n",
      "[-1.8525391  -0.20141602 -0.02659607  0.48095703  0.59472656  0.3642578 ] 4   3 \n",
      "[-1.7617188  -0.06781006  0.15563965  0.68847656  0.23657227 -0.21008301] 3   3 Match 223\n",
      "\n",
      "[-0.17932129  0.32006836  0.3564453   0.25854492 -0.5810547  -0.7529297 ] 2   4 \n",
      "[-2.4121094  -0.5004883  -0.72558594  0.66015625  0.7988281   0.8486328 ] 5   3 \n",
      "[-0.8466797   0.15148926  0.39404297  0.40771484 -0.33764648 -0.671875  ] 3   2 \n",
      "[-1.5683594  -0.4350586  -0.33154297  0.41210938  0.43164062  0.37353516] 4   4 Match 224\n",
      "\n",
      "[-0.80615234  0.05761719  0.12445068  0.0802002  -0.16772461 -0.06671143] 2   3 \n",
      "[ 0.00496292  0.32421875  0.65527344  0.08947754 -0.9165039  -0.9921875 ] 2   0 \n",
      "[-0.87890625 -0.00382996 -0.35229492 -0.06341553  0.04293823  0.33398438] 5   1 \n",
      "[-0.9267578   0.14685059  0.1505127   0.10754395 -0.19616699 -0.34204102] 2   1 \n",
      "[-0.9482422  -0.01290894 -0.05123901 -0.06732178 -0.00624466  0.20617676] 5   5 Match 225\n",
      "\n",
      "[-1.0566406   0.1661377   0.32348633  0.5629883   0.08679199 -0.61865234] 3   5 \n",
      "[-0.91748047  0.34545898  0.7558594   0.49487305 -0.42407227 -0.8598633 ] 2   2 Match 226\n",
      "\n",
      "[-1.7822266  -0.3256836  -0.27148438  0.4633789   0.45117188  0.27734375] 3   4 \n",
      "[-1.7841797  -0.4645996  -0.3798828   0.4951172   0.6118164   0.50439453] 4   3 \n",
      "[-1.6455078  -0.22106934 -0.32666016  0.36743164  0.50634766  0.32080078] 4   2 \n",
      "[-0.87158203  0.1394043   0.16625977  0.11749268 -0.27368164 -0.41430664] 2   1 \n",
      "[-1.9072266  -0.24230957 -0.33422852  0.34570312  0.61865234  0.4584961 ] 4   3 \n",
      "[-1.9794922  -0.34985352 -0.27368164  0.3486328   0.5527344   0.39501953] 4   1 \n",
      "[-1.7050781  -0.21569824 -0.27685547  0.63623047  0.5097656   0.2397461 ] 3   4 \n",
      "[-1.5185547  -0.24743652 -0.38061523  0.42285156  0.5229492   0.35864258] 4   3 \n",
      "[-0.6533203   0.2980957  -0.04336548 -0.03543091 -0.08703613 -0.21704102] 1   2 \n",
      "[-0.4267578   0.12670898  0.26708984  0.07757568 -0.30444336 -0.39257812] 2   0 \n",
      "[-0.37060547  0.28833008  0.07452393 -0.17578125 -0.40722656 -0.23376465] 1   5 \n",
      "[-0.7866211   0.14172363  0.22375488  0.30786133 -0.2692871  -0.3869629 ] 3   1 \n",
      "[-0.5786133   0.06347656 -0.10797119  0.07745361  0.04333496 -0.07189941] 3   4 \n",
      "[-0.88134766  0.03038025  0.2298584   0.13562012 -0.23498535 -0.37719727] 2   4 \n",
      "[-1.4443359  -0.12854004 -0.00345612  0.453125    0.16027832 -0.3466797 ] 3   1 \n",
      "[-0.23901367  0.27368164  0.2680664   0.04971313 -0.484375   -0.6230469 ] 1   0 \n",
      "[-0.39672852  0.30908203  0.42114258  0.3239746  -0.64941406 -0.6635742 ] 2   1 \n",
      "[-1.6650391   0.065979   -0.28466797  0.59765625  0.7138672   0.53466797] 4   0 \n",
      "[-1.4052734   0.02998352  0.6147461   0.8515625  -0.11846924 -0.7841797 ] 3   3 Match 227\n",
      "\n",
      "[-0.88427734  0.1907959   0.03591919  0.09686279 -0.09039307 -0.17016602] 1   1 Match 228\n",
      "\n",
      "[-1.6357422  -0.36132812  0.04071045  0.38598633  0.1920166   0.0604248 ] 3   4 \n",
      "[-0.9458008   0.06033325  0.15124512  0.43823242 -0.07061768 -0.34301758] 3   0 \n",
      "[-1.0195312   0.12512207  0.43115234  0.55078125 -0.36669922 -0.6977539 ] 3   5 \n",
      "[-1.0263672   0.20471191 -0.17028809 -0.11962891  0.04623413  0.10443115] 1   2 \n",
      "[-0.31103516  0.24523926  0.03585815 -0.09625244 -0.2368164  -0.26171875] 1   5 \n",
      "[-1.2412109  -0.02510071  0.24829102  0.35131836  0.46801758 -0.09759521] 4   1 \n",
      "[-0.95654297 -0.052948   -0.10284424  0.2548828   0.31420898  0.03117371] 4   0 \n",
      "[-0.5859375   0.10290527  0.02313232 -0.15563965 -0.10021973 -0.11846924] 1   2 \n",
      "[ 0.0546875   0.35498047 -0.00241661 -0.33276367 -0.8251953  -0.25952148] 1   0 \n",
      "[-1.3017578   0.04559326  0.27246094  0.42529297  0.10882568 -0.19628906] 3   2 \n",
      "[-0.09509277  0.47705078  0.36938477 -0.00694656 -0.67529297 -0.91552734] 1   1 Match 229\n",
      "\n",
      "[-0.4111328   0.11871338  0.097229    0.13415527 -0.25561523 -0.2355957 ] 3   1 \n",
      "[-1.5878906e+00 -4.2438507e-05  2.6635742e-01  5.9716797e-01\n",
      "  7.9284668e-02 -3.7060547e-01] 3   1 \n",
      "[-0.2602539   0.33935547  0.55029297  0.28930664 -0.7265625  -0.8120117 ] 2   5 \n",
      "[-0.23461914  0.14160156  0.02137756 -0.0625     -0.20776367 -0.34594727] 1   2 \n",
      "[-0.1652832   0.34423828  0.45532227  0.18383789 -0.61572266 -0.97753906] 2   2 Match 230\n",
      "\n",
      "[-1.1289062  -0.11450195 -0.01647949  0.34887695  0.15612793  0.07446289] 3   2 \n",
      "[-1.6142578  -0.18676758 -0.34228516  0.22106934  0.7270508   0.5527344 ] 4   3 \n",
      "[ 0.02497864  0.23876953  0.16662598 -0.05563354 -0.4560547  -0.49316406] 1   4 \n",
      "[-1.6679688  -0.12109375  0.24438477  0.8071289   0.00939178 -0.4050293 ] 3   4 \n",
      "[-1.1542969   0.06756592  0.10632324  0.20898438 -0.27172852 -0.38256836] 3   5 \n",
      "[-1.5537109  -0.17077637 -0.5180664   0.33081055  0.5131836   0.6191406 ] 5   5 Match 231\n",
      "\n",
      "[-0.76171875  0.23547363  0.4099121   0.30517578 -0.08581543 -0.5883789 ] 2   2 Match 232\n",
      "\n",
      "[-1.3876953   0.1204834   0.1394043   0.6245117   0.25561523 -0.52685547] 3   3 Match 233\n",
      "\n",
      "[-1.0009766  -0.06256104  0.02548218  0.19116211  0.13806152  0.23168945] 5   4 \n",
      "[-1.3320312  -0.01651001  0.2680664   0.32104492  0.02682495 -0.07342529] 3   3 Match 234\n",
      "\n",
      "[-0.7988281   0.20043945 -0.19885254  0.04876709 -0.22033691  0.25927734] 5   1 \n",
      "[-1.3769531  -0.06494141  0.3227539   0.4716797  -0.0289917  -0.3540039 ] 3   5 \n",
      "[-0.31298828  0.30273438  0.35791016  0.04205322 -0.42773438 -0.70458984] 2   1 \n",
      "[-0.5527344   0.21520996  0.62841797  0.29174805 -0.51660156 -0.72558594] 2   2 Match 235\n",
      "\n",
      "[ 0.07684326  0.5205078   0.25024414 -0.1977539  -0.43847656 -0.67333984] 1   4 \n",
      "[-1.0361328   0.3864746   0.40454102  0.48901367 -0.12243652 -0.7602539 ] 3   1 \n",
      "[-1.4863281  -0.17053223  0.19152832  0.84033203  0.1027832  -0.61328125] 3   3 Match 236\n",
      "\n",
      "[-1.6582031  -0.08251953  0.03222656  0.78466797  0.3552246   0.00881195] 3   2 \n",
      "[-1.8242188  -0.1274414   0.10913086  0.82177734  0.13574219 -0.03515625] 3   1 \n",
      "[-0.3383789   0.27954102  0.30737305  0.19360352 -0.32617188 -0.7338867 ] 2   4 \n",
      "[-0.3581543   0.3701172   0.09832764 -0.29663086 -0.30249023 -0.0994873 ] 1   2 \n",
      "[-1.5058594  -0.06304932  0.24328613  0.62353516  0.12939453 -0.44750977] 3   1 \n",
      "[-1.8701172  -0.36035156 -0.36376953  0.42260742  0.68896484  0.32202148] 4   3 \n",
      "[-1.6455078  -0.11395264 -0.23486328  0.4321289   0.4104004   0.13012695] 3   4 \n",
      "[-0.82470703  0.16577148  0.11273193  0.11096191 -0.2319336  -0.30151367] 1   1 Match 237\n",
      "\n",
      "[-0.47460938  0.18676758  0.24963379  0.05325317 -0.19311523 -0.36621094] 2   2 Match 238\n",
      "\n",
      "[-1.8515625  -0.35131836 -0.4333496   0.51416016  0.5493164   0.3046875 ] 4   4 Match 239\n",
      "\n",
      "[-0.37597656 -0.04727173 -0.05105591 -0.07495117 -0.27172852 -0.05328369] 1   1 Match 240\n",
      "\n",
      "[-1.6904297  -0.29418945 -0.34228516  0.39892578  0.5371094   0.44921875] 4   4 Match 241\n",
      "\n",
      "[-0.39282227  0.15612793  0.3330078   0.01548767 -0.5883789  -0.54589844] 2   1 \n",
      "[-2.1152344  -0.28955078 -0.625       0.4736328   0.9033203   1.0458984 ] 5   5 Match 242\n",
      "\n",
      "[-1.9853516  -0.29296875 -0.27001953  0.4609375   0.6933594   0.54541016] 4   5 \n",
      "[-2.0214844  -0.43310547 -0.42578125  0.42211914  0.9169922   0.69628906] 4   3 \n",
      "[-0.86816406  0.19104004  0.11346436  0.48388672 -0.16552734 -0.30541992] 3   1 \n",
      "[-0.6582031   0.13378906  0.5683594   0.24328613 -0.22973633 -0.25195312] 2   2 Match 243\n",
      "\n",
      "[-0.44311523  0.2322998   0.53222656  0.22558594 -0.42456055 -0.7636719 ] 2   1 \n",
      "[-1.421875    0.05981445  0.4716797   0.65771484 -0.17687988 -0.65234375] 3   5 \n",
      "[-0.3005371   0.58984375  0.80371094  0.2166748  -0.6435547  -1.2373047 ] 2   1 \n",
      "[-0.5683594   0.16674805  0.73339844  0.32910156 -0.4638672  -0.82958984] 2   2 Match 244\n",
      "\n",
      "[-0.41137695  0.28051758  0.18615723 -0.18225098 -0.41064453 -0.25708008] 1   2 \n",
      "[-0.9067383   0.0970459   0.27197266  0.14428711 -0.38916016 -0.3203125 ] 2   4 \n",
      "[-1.2939453  -0.01747131 -0.040802    0.22363281 -0.05422974  0.02287292] 3   2 \n",
      "[-0.23828125  0.13269043  0.15136719  0.09051514 -0.33911133 -0.36743164] 2   2 Match 245\n",
      "\n",
      "[-0.45776367  0.18493652 -0.08178711 -0.0010376  -0.12298584 -0.15991211] 1   5 \n",
      "[-0.82177734  0.21118164  0.4855957   0.4050293  -0.3864746  -0.60791016] 2   3 \n",
      "[-0.9868164  -0.07171631  0.38305664  0.32226562  0.09222412 -0.5029297 ] 2   2 Match 246\n",
      "\n",
      "[-1.5605469  -0.04217529  0.05236816  0.5263672   0.3635254   0.00386238] 3   3 Match 247\n",
      "\n",
      "[-2.078125   -0.38427734 -0.16186523  0.6855469   0.43774414 -0.03662109] 3   4 \n",
      "[-8.1835938e-01 -6.2084198e-04  1.7553711e-01  2.6904297e-01\n",
      " -2.2607422e-01 -2.7221680e-01] 3   2 \n",
      "[-2.0566406  -0.28149414  0.03074646  0.92822266  0.5722656   0.12390137] 3   1 \n",
      "[-0.7470703   0.11138916  0.16589355  0.13110352  0.09436035 -0.02088928] 2   4 \n",
      "[-1.1806641   0.24450684  0.35888672  0.37402344 -0.13342285 -0.36865234] 3   1 \n",
      "[-0.86328125  0.05633545  0.17272949 -0.06164551 -0.20239258 -0.04382324] 2   3 \n",
      "[-1.328125   -0.06555176  0.20605469  0.8183594   0.16442871 -0.46411133] 3   5 \n",
      "[-1.2177734  -0.09088135  0.2421875   0.5058594  -0.08135986 -0.5083008 ] 3   3 Match 248\n",
      "\n",
      "[-1.6230469  -0.22973633 -0.5654297   0.13085938  0.30078125  0.81396484] 5   5 Match 249\n",
      "\n",
      "[ 0.06130981  0.41503906  0.4519043   0.12854004 -0.69140625 -0.8198242 ] 2   3 \n",
      "[-1.7314453  -0.40551758 -0.23742676  0.5683594   0.4482422  -0.07647705] 3   5 \n",
      "[-1.6708984  -0.25512695 -0.17736816  0.55078125  0.58496094  0.19812012] 4   4 Match 250\n",
      "\n",
      "[-0.18322754  0.27319336  0.4970703   0.19494629 -0.6381836  -0.82177734] 2   0 \n",
      "[-0.91845703 -0.00338364 -0.03662109  0.14404297  0.23400879 -0.17272949] 4   1 \n",
      "[-0.6455078   0.15466309  0.09680176  0.21459961 -0.0254364  -0.23657227] 3   1 \n",
      "[-0.1607666   0.4494629   0.3720703   0.08508301 -0.55029297 -0.62841797] 1   0 \n",
      "[-1.1582031   0.0539856   0.00739288  0.28881836  0.03735352 -0.28344727] 3   4 \n",
      "[-0.16918945  0.34472656  0.58154297  0.21057129 -0.68115234 -0.81103516] 2   3 \n",
      "[-1.6816406  -0.14807129 -0.43896484  0.2553711   0.7416992   0.55859375] 4   4 Match 251\n",
      "\n",
      "[-1.1308594   0.13439941 -0.06573486  0.17041016  0.0770874   0.2409668 ] 5   1 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-2.1015625  -0.34643555 -0.60791016  0.34448242  0.6875      0.7832031 ] 5   3 \n",
      "[-1.5439453  -0.13916016 -0.05691528  0.39941406  0.31201172  0.13745117] 3   3 Match 252\n",
      "\n",
      "[-1.9130859  -0.32080078 -0.2705078   0.546875    0.48291016  0.05618286] 3   3 Match 253\n",
      "\n",
      "[-1.5927734  -0.22497559 -0.5864258   0.03918457  0.60498047  0.79052734] 5   4 \n",
      "[-1.1464844   0.05474854 -0.4116211  -0.15039062  0.11889648  0.1619873 ] 5   5 Match 254\n",
      "\n",
      "[-1.5019531  -0.16723633 -0.39404297  0.26342773  0.51904297  0.8129883 ] 5   4 \n",
      "[-2.4941406  -0.28881836 -0.6435547   0.6689453   0.95703125  0.97021484] 5   5 Match 255\n",
      "\n",
      "[-1.6240234  -0.15649414 -0.38793945  0.10076904  0.609375    0.5756836 ] 4   3 \n",
      "[-0.09375     0.31567383 -0.06732178 -0.13171387 -0.26660156 -0.24182129] 1   3 \n",
      "[-0.41552734  0.28271484  0.57128906  0.29785156 -0.4494629  -0.89697266] 2   4 \n",
      "[-1.2998047  -0.22509766 -0.07598877  0.25610352  0.25317383  0.1940918 ] 3   2 \n",
      "[-2.3164062  -0.2775879  -0.7182617   0.47875977  1.1025391   1.0185547 ] 4   4 Match 256\n",
      "\n",
      "[-1.6396484  -0.08111572  0.12017822  0.6455078   0.12310791 -0.3552246 ] 3   3 Match 257\n",
      "\n",
      "[-0.91503906 -0.02384949  0.2775879   0.4892578  -0.07562256 -0.38842773] 3   3 Match 258\n",
      "\n",
      "[-1.8261719  -0.32592773 -0.40551758  0.36108398  0.8466797   0.6640625 ] 4   2 \n",
      "[-0.06744385  0.5209961   0.5517578   0.34716797 -0.7441406  -1.0292969 ] 2   2 Match 259\n",
      "\n",
      "[-2.0019531  -0.3569336  -0.25        0.8300781   0.5698242   0.16052246] 3   4 \n",
      "[-1.8164062  -0.07537842 -0.10998535  0.49023438  0.20263672 -0.01163483] 3   2 \n",
      "[-2.1933594  -0.23327637 -0.29760742  0.47460938  0.77441406  0.2993164 ] 4   5 \n",
      "[-1.0634766  -0.01829529 -0.52783203 -0.05108643  0.08355713  0.56396484] 5   1 \n",
      "[-0.45629883  0.234375    0.0146637   0.18347168 -0.12078857 -0.28393555] 1   4 \n",
      "[-0.44360352  0.43041992  0.4777832   0.46801758 -0.47338867 -0.86035156] 2   2 Match 260\n",
      "\n",
      "[-0.46411133  0.07110596 -0.05639648 -0.25952148 -0.12573242 -0.00114822] 1   4 \n",
      "[-1.0546875   0.12182617  0.01585388  0.13378906  0.23608398  0.3046875 ] 5   5 Match 261\n",
      "\n",
      "[-0.91015625 -0.07513428  0.23303223  0.1282959  -0.10443115 -0.22131348] 2   3 \n",
      "[-0.5703125   0.13195801  0.13378906  0.15979004 -0.2076416  -0.4020996 ] 3   2 \n",
      "[-1.6044922  -0.15270996 -0.04608154  0.42626953  0.5107422   0.15881348] 4   5 \n",
      "[-1.6455078  -0.16394043 -0.19921875  0.3540039   0.4794922   0.29589844] 4   4 Match 262\n",
      "\n",
      "[-1.1103516   0.11236572  0.1361084   0.3642578   0.02876282 -0.17077637] 3   3 Match 263\n",
      "\n",
      "[-0.08691406  0.25390625 -0.2121582  -0.3059082  -0.36547852 -0.23181152] 1   0 \n",
      "[-2.1289062  -0.48242188 -0.21728516  0.83496094  0.5854492   0.11010742] 3   5 \n",
      "[-1.0449219   0.01596069 -0.38330078 -0.02180481  0.3059082   0.4650879 ] 5   3 \n",
      "[-0.22875977  0.41430664  0.31152344  0.06616211 -0.546875   -0.4807129 ] 1   1 Match 264\n",
      "\n",
      "[-0.6484375   0.19262695  0.4321289   0.66748047 -0.3552246  -0.92089844] 3   3 Match 265\n",
      "\n",
      "[-0.19042969  0.1907959   0.12927246 -0.10113525 -0.38793945 -0.4243164 ] 1   1 Match 266\n",
      "\n",
      "[-0.29638672  0.38085938  0.43286133 -0.01512146 -0.24438477 -0.6665039 ] 2   1 \n",
      "[ 0.31176758  0.3022461  -0.2322998  -0.37475586 -0.40478516 -0.22229004] 0   0 Match 267\n",
      "\n",
      "[-0.78222656  0.10656738  0.32104492  0.34399414 -0.125      -0.6333008 ] 3   2 \n",
      "[ 0.07403564  0.33935547  0.23840332 -0.16040039 -0.35766602 -0.47338867] 1   0 \n",
      "[-0.78808594  0.09570312  0.04443359  0.20495605  0.06481934 -0.18591309] 3   3 Match 268\n",
      "\n",
      "[-0.04507446  0.54589844  0.5024414  -0.00435257 -0.5395508  -0.77685547] 1   5 \n",
      "[-0.22705078  0.19787598  0.33984375 -0.04281616 -0.46142578 -0.4519043 ] 2   1 \n",
      "[-0.8876953   0.00719452  0.1508789   0.08843994 -0.31591797 -0.26660156] 2   2 Match 269\n",
      "\n",
      "[-1.7480469  -0.14428711  0.2364502   0.7832031   0.34570312 -0.28833008] 3   3 Match 270\n",
      "\n",
      "[-2.3183594  -0.5786133  -0.37280273  0.7133789   0.83251953  0.5371094 ] 4   4 Match 271\n",
      "\n",
      "[-1.3896484  -0.109375    0.15966797  0.60498047  0.07617188 -0.29296875] 3   5 \n",
      "[-0.43115234  0.0690918   0.27539062  0.18066406 -0.27392578 -0.38867188] 2   4 \n",
      "[-1.7431641  -0.24633789 -0.39233398  0.3071289   0.6694336   0.71533203] 5   1 \n",
      "[-0.23278809  0.43017578  0.6357422   0.34643555 -0.7114258  -1.1337891 ] 2   1 \n",
      "[-1.3203125  -0.05718994 -0.10705566  0.15246582  0.41674805  0.15258789] 4   1 \n",
      "[-1.5644531  -0.09014893  0.20007324  0.51660156  0.40966797 -0.17700195] 3   3 Match 272\n",
      "\n",
      "[-1.5263672   0.0703125  -0.15881348  0.3540039   0.5629883   0.19555664] 4   5 \n",
      "[-9.0283203e-01  9.1064453e-02  4.3487549e-02  1.5234375e-01\n",
      " -5.6457520e-04  1.9226074e-02] 3   5 \n",
      "[-1.0800781   0.1574707   0.27539062  0.24511719  0.07147217 -0.37231445] 2   3 \n",
      "[-1.2519531   0.13427734  0.04321289  0.24145508  0.39941406  0.0453186 ] 4   1 \n",
      "[-0.9550781   0.23083496  0.5751953   0.50683594 -0.02966309 -0.7973633 ] 2   1 \n",
      "[ 0.01713562  0.45043945  0.46606445  0.17260742 -0.50097656 -0.87158203] 2   3 \n",
      "[ 0.08789062  0.72021484 -0.06433105 -0.34326172 -0.3095703  -0.12255859] 1   1 Match 273\n",
      "\n",
      "[-0.6230469   0.2800293   0.24707031  0.17919922 -0.10229492 -0.46875   ] 1   1 Match 274\n",
      "\n",
      "[-1.0703125   0.25170898  0.1574707   0.15930176  0.20214844 -0.40039062] 1   1 Match 275\n",
      "\n",
      "[-1.6376953  -0.16040039  0.05303955  0.40625     0.44213867 -0.16369629] 4   1 \n",
      "[-0.17456055  0.34033203  0.28979492 -0.0869751  -0.72753906 -0.6245117 ] 1   3 \n",
      "[-0.48999023  0.03903198 -0.01448822  0.05029297 -0.1850586  -0.28564453] 3   1 \n",
      "[-1.9277344  -0.10314941 -0.4350586   0.28833008  0.68310547  0.88183594] 5   2 \n",
      "[-2.0820312  -0.4104004  -0.10015869  0.7036133   0.44995117  0.3708496 ] 3   4 \n",
      "[-0.0368042   0.4387207  -0.01966858 -0.04275513 -0.52197266 -0.3474121 ] 1   3 \n",
      "[-2.1425781  -0.34570312 -0.05255127  0.9614258   0.68603516  0.04742432] 3   3 Match 276\n",
      "\n",
      "[ 0.6308594   0.5214844   0.17578125 -0.1315918  -0.51220703 -0.6611328 ] 0   0 Match 277\n",
      "\n",
      "[-1.6318359  -0.17102051  0.23754883  1.1464844  -0.02296448 -0.66503906] 3   3 Match 278\n",
      "\n",
      "[-1.3339844  -0.15942383  0.4008789   0.6464844  -0.02946472 -0.43359375] 3   3 Match 279\n",
      "\n",
      "[-1.5673828  -0.08331299  0.34277344  0.34472656  0.05471802 -0.22033691] 3   1 \n",
      "[-0.7758789   0.06536865  0.44604492  0.49609375 -0.32080078 -0.5629883 ] 3   3 Match 280\n",
      "\n",
      "[-1.0947266   0.09143066  0.39501953  0.30932617 -0.07220459 -0.33642578] 2   3 \n",
      "[-0.35205078  0.33154297  0.53125     0.25732422 -0.39526367 -0.7548828 ] 2   1 \n",
      "[ 0.07080078  0.33374023  0.3076172  -0.10601807 -0.7636719  -0.76708984] 1   1 Match 281\n",
      "\n",
      "[-0.86621094  0.090271    0.39648438  0.3347168  -0.21435547 -0.58691406] 2   0 \n",
      "[-1.3994141   0.01641846 -0.24926758  0.06347656  0.3642578   0.5024414 ] 5   5 Match 282\n",
      "\n",
      "[-1.4863281  -0.10443115 -0.15185547  0.31835938  0.37353516  0.12426758] 4   5 \n",
      "[-2.1347656 -0.4506836 -0.4152832  0.6953125  0.7451172  0.6225586] 4   5 \n",
      "[-2.265625   -0.29296875 -0.47021484  0.5332031   0.59033203  0.63427734] 5   3 \n",
      "[-1.8378906  -0.19812012 -0.12866211  0.35424805  0.57666016  0.53515625] 4   3 \n",
      "[-1.4511719   0.01417542  0.10723877  0.6958008   0.14929199 -0.28833008] 3   3 Match 283\n",
      "\n",
      "[-1.375       0.05661011  0.13000488  0.7832031   0.08526611 -0.14794922] 3   1 \n",
      "[-2.0136719  -0.33203125  0.01957703  0.8354492   0.49267578 -0.1083374 ] 3   2 \n",
      "[ 0.18603516  0.2919922   0.17626953  0.03143311 -0.49414062 -0.5097656 ] 1   1 Match 284\n",
      "\n",
      "[-1.7197266  -0.48095703 -0.47631836  0.3984375   0.47314453  0.53564453] 5   3 \n",
      "[-1.25       -0.02503967  0.05514526  0.3581543   0.02919006 -0.17016602] 3   4 \n",
      "[-1.1357422  -0.04544067  0.01669312  0.31176758  0.02624512 -0.17834473] 3   0 \n",
      "[-1.8291016  -0.20166016 -0.11114502  0.42114258  0.23376465  0.29003906] 3   4 \n",
      "[-2.0976562  -0.35498047 -0.42797852  0.6274414   0.6699219   0.35986328] 4   4 Match 285\n",
      "\n",
      "[-9.6777344e-01  3.1176758e-01 -6.9641113e-02 -9.1314316e-04\n",
      "  2.7694702e-02 -1.6064453e-01] 1   5 \n",
      "[-2.2402344  -0.46948242 -0.4416504   0.8540039   0.6826172   0.32055664] 3   3 Match 286\n",
      "\n",
      "[ 1.1318359   0.7241211   0.23376465 -0.3515625  -0.93066406 -0.81347656] 0   0 Match 287\n",
      "\n",
      "[ 0.39697266  0.35766602  0.27246094  0.18457031 -0.640625   -0.8588867 ] 0   3 \n",
      "[-1.65625    -0.21875    -0.05224609  0.71972656  0.3540039   0.03768921] 3   0 \n",
      "[-2.1171875  -0.3112793  -0.22998047  0.7792969   0.7211914   0.34960938] 3   3 Match 288\n",
      "\n",
      "[-1.5205078  -0.2685547  -0.4963379   0.09814453  0.5620117   0.52978516] 4   5 \n",
      "[-2.4960938  -0.49414062 -0.5727539   0.75        0.97998047  0.80615234] 4   2 \n",
      "[-0.78125     0.29223633  0.23168945  0.21032715  0.03866577 -0.4008789 ] 1   5 \n",
      "[-1.4257812   0.0513916   0.23937988  0.2775879   0.28759766 -0.22705078] 4   1 \n",
      "[-1.5966797   0.0085907  -0.12963867  0.4921875   0.5854492  -0.03475952] 4   2 \n",
      "[-2.         -0.29956055 -0.06097412  0.6176758   0.7871094   0.23205566] 4   5 \n",
      "[-0.546875    0.14611816  0.2849121   0.02449036 -0.5366211  -0.58496094] 2   1 \n",
      "[-1.2851562   0.02833557  0.39331055  0.40307617  0.10668945 -0.32373047] 3   1 \n",
      "[-1.4667969   0.0916748   0.29492188  0.5913086   0.13659668 -0.44628906] 3   4 \n",
      "[-1.7949219  -0.22497559 -0.5463867   0.2734375   0.8095703   0.7368164 ] 4   5 \n",
      "[-0.26049805  0.16955566  0.44580078  0.00294876 -0.7294922  -0.6225586 ] 2   1 \n",
      "[-0.04672241  0.46533203  0.2109375  -0.42114258 -0.5175781  -0.51171875] 1   3 \n",
      "[-0.28735352  0.5908203   0.30737305  0.38330078 -0.76123047 -0.79541016] 1   1 Match 289\n",
      "\n",
      "[-1.6611328   0.02923584  0.2602539   0.6748047   0.23815918 -0.44799805] 3   2 \n",
      "[-0.8720703   0.24536133  0.3955078   0.19494629 -0.41552734 -0.7426758 ] 2   2 Match 290\n",
      "\n",
      "[-1.4980469  -0.1328125   0.10406494  0.5078125   0.03219604 -0.14819336] 3   4 \n",
      "[-0.9609375  -0.05847168 -0.09436035  0.26586914  0.05111694 -0.029953  ] 3   4 \n",
      "[-1.6982422  -0.26245117 -0.22717285  0.24707031  0.6352539   0.45996094] 4   2 \n",
      "[-1.9189453  -0.3215332  -0.25976562  0.5805664   0.4777832   0.10961914] 3   3 Match 291\n",
      "\n",
      "[-2.0136719  -0.21289062 -0.40893555  0.45874023  0.6616211   0.5126953 ] 4   4 Match 292\n",
      "\n",
      "[-1.9462891  -0.37475586 -0.25048828  0.6274414   0.6171875   0.3569336 ] 3   3 Match 293\n",
      "\n",
      "[-1.8310547  -0.2709961  -0.23876953  0.39501953  0.76904297  0.5410156 ] 4   2 \n",
      "[-1.0546875   0.28149414  0.29882812  0.5649414  -0.2692871  -0.7285156 ] 3   2 \n",
      "[-0.3959961   0.55810547  0.48120117  0.4897461  -0.54296875 -1.171875  ] 1   2 \n",
      "[-1.1289062   0.11938477  0.40429688  0.54248047 -0.08148193 -0.6508789 ] 3   4 \n",
      "[-0.6015625   0.35888672  0.08215332 -0.01567078 -0.1348877  -0.31567383] 1   2 \n",
      "[-1.0654297   0.22424316  0.6074219   0.74121094 -0.31079102 -0.78564453] 3   3 Match 294\n",
      "\n",
      "[-2.0664062  -0.31860352 -0.00764084  1.0791016   0.38745117 -0.0164032 ] 3   1 \n",
      "[-1.1806641  -0.08538818  0.33862305  0.4519043  -0.05596924 -0.2763672 ] 3   3 Match 295\n",
      "\n",
      "[-1.9541016  -0.26660156 -0.20617676  0.5024414   0.5332031   0.11175537] 4   2 \n",
      "[-0.98046875  0.3942871   0.32104492  0.13513184 -0.06427002 -0.86816406] 1   1 Match 296\n",
      "\n",
      "[ 0.1986084   0.34399414  0.67089844 -0.11779785 -0.7705078  -1.0029297 ] 2   3 \n",
      "[-1.1523438  -0.03936768  0.10028076  0.3388672   0.1616211  -0.03250122] 3   4 \n",
      "[-0.6020508   0.34838867  0.82128906  0.3840332  -0.7138672  -0.88183594] 2   3 \n",
      "[-1.4775391   0.15209961  0.11450195  0.42016602  0.17260742 -0.14831543] 3   3 Match 297\n",
      "\n",
      "[-1.1464844   0.23583984  0.34423828  0.5673828  -0.08679199 -0.57128906] 3   1 \n",
      "[-1.8066406  -0.10571289  0.2529297   0.90722656  0.3857422  -0.26464844] 3   2 \n",
      "[-0.3244629   0.07415771  0.13232422 -0.1439209  -0.3737793  -0.20617676] 2   1 \n",
      "[-0.8017578   0.09521484 -0.19641113 -0.20019531  0.02966309  0.07025146] 1   1 Match 298\n",
      "\n",
      "[-2.4941406  -0.39770508 -0.4777832   0.7558594   0.8881836   0.72265625] 4   4 Match 299\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[-0.90966797  0.21472168  0.31835938  0.48291016 -0.1459961  -0.47192383] 3   4 \n",
      "[-0.640625    0.11114502 -0.08636475  0.14489746 -0.09649658 -0.12878418] 3   5 \n",
      "[-2.2851562  -0.52685547 -0.32373047  0.76123047  0.69970703  0.5073242 ] 3   1 \n",
      "[-1.0585938   0.01319885  0.21435547  0.46166992 -0.14147949 -0.24511719] 3   3 Match 300\n",
      "\n",
      "[-0.84765625  0.36254883  0.67578125  0.55322266 -0.5629883  -0.84521484] 2   3 \n",
      "[-2.3300781  -0.4597168  -0.41870117  0.61865234  0.8803711   0.31103516] 4   5 \n",
      "[-1.2744141  -0.03036499  0.05459595  0.34472656  0.21777344 -0.02493286] 3   3 Match 301\n",
      "\n",
      "[-1.2880859   0.04122925  0.42578125  0.47436523 -0.05847168 -0.53808594] 3   1 \n",
      "[-0.3876953   0.30444336 -0.2467041  -0.17016602 -0.28198242  0.10919189] 1   4 \n",
      "[-1.6259766  -0.10302734  0.11700439  0.79785156  0.37646484 -0.24414062] 3   3 Match 302\n",
      "\n",
      "[-0.04470825  0.33740234  0.30151367  0.15844727 -0.41357422 -0.83740234] 1   3 \n",
      "[-1.7685547  -0.4013672  -0.42578125  0.50878906  0.6748047   0.46142578] 4   3 \n",
      "[-2.078125   -0.39453125 -0.515625    0.3894043   0.8071289   0.64697266] 4   3 \n",
      "[-1.8857422  -0.34545898 -0.390625    0.4165039   0.70214844  0.8051758 ] 5   4 \n",
      "[-1.6376953  -0.2121582  -0.0171814   0.61279297  0.19665527 -0.24108887] 3   3 Match 303\n",
      "\n",
      "[-1.1044922   0.02590942 -0.30810547 -0.14477539  0.32983398  0.47485352] 5   3 \n",
      "[-0.3708496   0.06530762 -0.1427002  -0.0385437  -0.07769775 -0.05679321] 1   3 \n",
      "[-0.29174805  0.07214355 -0.09051514 -0.00124264 -0.14001465 -0.20581055] 1   2 \n",
      "[-1.9082031  -0.36914062 -0.21911621  0.76123047  0.69189453  0.28076172] 3   5 \n",
      "[-1.8662109  -0.4326172  -0.21813965  0.7939453   0.4645996   0.23669434] 3   2 \n",
      "[-0.41210938  0.14929199 -0.10449219 -0.04046631 -0.05740356 -0.16479492] 1   1 Match 304\n",
      "\n",
      "[-1.5351562  -0.19360352 -0.15429688  0.1772461   0.30151367  0.25390625] 4   2 \n",
      "[-0.47729492  0.18469238 -0.13586426 -0.03582764 -0.04055786 -0.03805542] 1   5 \n",
      "[-0.45458984  0.12445068  0.10546875  0.0287323  -0.19677734 -0.5673828 ] 1   1 Match 305\n",
      "\n",
      "[-2.2441406  -0.39233398 -0.29492188  0.66259766  0.7993164   0.31689453] 4   5 \n",
      "[-1.6210938  -0.15795898 -0.44799805  0.42797852  0.68847656  0.41748047] 4   1 \n",
      "[-1.0693359   0.12121582  0.11218262  0.2541504  -0.11602783 -0.1694336 ] 3   3 Match 306\n",
      "\n",
      "[-0.44970703  0.00836945 -0.20483398 -0.04193115 -0.0055809  -0.00106525] 1   0 \n",
      "[-1.5898438  -0.08825684  0.30664062  1.0498047  -0.04998779 -0.61816406] 3   3 Match 307\n",
      "\n",
      "[-0.26171875  0.12194824 -0.13220215 -0.07043457 -0.08782959 -0.17883301] 1   3 \n",
      "[-0.4584961   0.2800293   0.5498047   0.49682617 -0.3330078  -0.95996094] 2   1 \n",
      "[-1.1914062   0.1574707   0.29760742  0.6201172  -0.12341309 -0.6328125 ] 3   1 \n",
      "[-1.4726562  -0.1862793  -0.3347168   0.30664062  0.37963867  0.33642578] 4   1 \n",
      "[-1.1367188  -0.1027832  -0.44921875  0.10632324  0.43017578  0.6035156 ] 5   1 \n",
      "[-0.85791016  0.12219238 -0.14001465  0.03372192 -0.17480469 -0.00917816] 1   3 \n",
      "[-1.3789062  -0.05270386 -0.45166016  0.09899902  0.4428711   0.72802734] 5   5 Match 308\n",
      "\n",
      "[-3.9428711e-01  9.2895508e-02 -1.3024902e-01  1.8084049e-04\n",
      " -6.7871094e-02 -1.3000488e-01] 1   3 \n",
      "[-1.78125    -0.3244629  -0.01145935  0.54785156  0.5800781   0.1586914 ] 4   3 \n",
      "[-1.6337891  -0.21789551 -0.0619812   0.3930664   0.41259766  0.15429688] 4   2 \n",
      "[ 0.10089111  0.19897461  0.23120117 -0.1430664  -0.63964844 -0.4572754 ] 2   3 \n",
      "[ 0.45507812  0.6489258   0.07940674 -0.37231445 -0.6845703  -0.5107422 ] 1   4 \n",
      "[-1.1855469   0.03120422  0.01771545  0.359375    0.21740723  0.02610779] 3   5 \n",
      "[-1.2861328  -0.05706787  0.10888672  0.4140625   0.18591309 -0.06799316] 3   2 \n",
      "[-1.4912109   0.07098389  0.02531433  0.48242188  0.20239258 -0.06500244] 3   1 \n",
      "[-0.38623047  0.21240234  0.28955078 -0.03527832 -0.4189453  -0.3708496 ] 2   1 \n",
      "[-0.49951172  0.22741699  0.21411133  0.00268936 -0.2442627  -0.45996094] 1   1 Match 309\n",
      "\n",
      "[-1.0869141   0.14562988  0.6274414   0.59472656 -0.40576172 -0.9404297 ] 2   2 Match 310\n",
      "\n",
      "[-1.4902344  -0.08831787 -0.11303711  0.20166016  0.5341797   0.31469727] 4   1 \n",
      "[-0.8203125   0.15649414  0.5751953   0.5019531  -0.40429688 -0.80371094] 2   2 Match 311\n",
      "\n",
      "[-0.7138672   0.21789551  0.5625      0.3269043  -0.6040039  -0.9082031 ] 2   0 \n",
      "[-1.3369141  -0.19812012 -0.2980957   0.01476288  0.73876953  0.48461914] 4   4 Match 312\n",
      "\n",
      "[-0.1451416   0.06939697 -0.15917969 -0.05282593 -0.13977051 -0.12145996] 1   1 Match 313\n",
      "\n",
      "[-1.0898438   0.07495117  0.07073975  0.27661133  0.03469849 -0.4086914 ] 3   1 \n",
      "[-0.5942383   0.02110291  0.09814453  0.01960754 -0.3803711  -0.44384766] 2   2 Match 314\n",
      "\n",
      "[-0.15185547  0.5209961   0.26049805 -0.4416504  -0.50390625 -0.7001953 ] 1   1 Match 315\n",
      "\n",
      "[-1.4345703   0.00293922  0.03692627  0.28295898  0.07824707 -0.06137085] 3   4 \n",
      "[-1.5957031  -0.00287247  0.2854004   0.6333008   0.09887695 -0.49316406] 3   3 Match 316\n",
      "\n",
      "[-2.0996094  -0.35864258 -0.36206055  0.5932617   0.6357422   0.3395996 ] 4   3 \n",
      "[-1.4794922  -0.01473236  0.10430908  0.59375     0.00229836 -0.421875  ] 3   3 Match 317\n",
      "\n",
      "[-1.8720703  -0.22668457 -0.4165039   0.33496094  0.6508789   0.75146484] 5   3 \n",
      "[-1.7958984  -0.28564453 -0.2163086   0.83984375  0.35717773 -0.05786133] 3   0 \n",
      "[-1.5927734  -0.20837402 -0.5332031   0.21203613  0.6152344   0.79541016] 5   4 \n",
      "[-1.9589844  -0.29003906  0.08953857  0.85009766  0.43041992 -0.12731934] 3   2 \n",
      "[-0.484375    0.05621338 -0.13391113 -0.16931152 -0.21533203 -0.04995728] 1   3 \n",
      "[-0.3713379   0.1538086   0.1328125   0.11541748 -0.28857422 -0.5751953 ] 1   1 Match 318\n",
      "\n",
      "[-2.         -0.38305664 -0.17980957  0.6464844   0.5996094   0.2290039 ] 3   4 \n",
      "[-0.7055664   0.17919922 -0.0051384   0.04266357 -0.27416992 -0.29907227] 1   1 Match 319\n",
      "\n",
      "[-1.7089844  -0.2607422   0.05328369  0.68652344  0.12182617 -0.22460938] 3   4 \n",
      "[-0.7988281   0.45507812  0.5800781   0.6147461  -0.5214844  -1.2041016 ] 3   2 \n",
      "[-1.3183594  -0.21740723 -0.09906006  0.37597656  0.41748047  0.14257812] 4   3 \n",
      "[ 0.4802246   0.5649414   0.56640625 -0.10229492 -0.8251953  -0.97509766] 2   2 Match 320\n",
      "\n",
      "[ 0.09191895  0.38842773  0.21936035 -0.3317871  -0.58154297 -0.46044922] 1   3 \n",
      "[-1.0703125   0.15441895  0.02262878 -0.13415527  0.17871094 -0.03500366] 4   1 \n",
      "[-1.6982422  -0.36669922 -0.23144531  0.41918945  0.57666016  0.3322754 ] 4   5 \n",
      "[-0.06420898  0.24414062  0.20141602 -0.13134766 -0.28466797 -0.546875  ] 1   5 \n",
      "[-0.27783203  0.4645996   0.6201172   0.24511719 -0.6035156  -0.99658203] 2   1 \n",
      "[-1.5507812  -0.06085205  0.3227539   0.58984375  0.32470703  0.11383057] 3   2 \n",
      "[-0.625       0.20251465  0.37353516  0.15161133 -0.1854248  -0.53759766] 2   1 \n",
      "[-1.3769531  -0.2553711  -0.5209961   0.0501709   0.49023438  0.65185547] 5   4 \n",
      "[-1.7167969  -0.17333984 -0.21618652  0.36010742  0.48950195  0.20141602] 4   3 \n",
      "[-1.7910156  -0.3857422  -0.42016602  0.41479492  0.6533203   0.53222656] 4   5 \n",
      "[-0.03363037  0.43945312  0.5932617  -0.052948   -0.6821289  -0.9794922 ] 2   0 \n",
      "[-2.0371094  -0.26171875 -0.18164062  0.93896484  0.5864258  -0.05404663] 3   4 \n",
      "[-1.1103516   0.25146484  0.39624023  0.5385742  -0.22302246 -0.94140625] 3   1 \n",
      "[-1.90625    -0.3317871  -0.39746094  0.35180664  0.84033203  0.5019531 ] 4   2 \n",
      "[-0.01651001  0.41015625 -0.02005005 -0.22912598 -0.44067383 -0.26660156] 1   5 \n",
      "[-1.6289062  -0.1652832   0.06268311  0.5566406   0.22729492 -0.1628418 ] 3   5 \n",
      "[-1.8417969  -0.14477539 -0.3227539   0.20288086  0.74365234  0.64746094] 4   5 \n",
      "[-1.5361328  -0.00834656  0.13793945  0.3647461   0.19042969 -0.19641113] 3   3 Match 321\n",
      "\n",
      "[-1.2109375  -0.11486816  0.2746582   0.42382812 -0.11212158 -0.18591309] 3   2 \n",
      "[-0.2668457   0.09625244  0.27563477 -0.0635376  -0.3696289  -0.42529297] 2   3 \n",
      "[-0.24133301  0.16430664  0.24389648  0.3720703  -0.36865234 -0.4260254 ] 3   1 \n",
      "[-1.6914062  -0.01156616 -0.00624847  0.47802734  0.60546875  0.15234375] 4   1 \n",
      "[-1.6015625  -0.05487061  0.06488037  0.4416504   0.29785156 -0.0769043 ] 3   5 \n",
      "[-0.2734375   0.19689941  0.24609375  0.02990723 -0.2836914  -0.41625977] 2   1 \n",
      "[-0.14672852  0.17248535  0.07879639  0.0049324  -0.39282227 -0.42822266] 1   0 \n",
      "[-2.2128906  -0.43017578 -0.68652344  0.57958984  0.7807617   0.9394531 ] 5   0 \n",
      "[-1.3603516   0.18188477  0.5834961   0.7368164  -0.06945801 -0.68847656] 3   5 \n",
      "[-0.37646484  0.08331299 -0.15917969 -0.02561951 -0.04992676 -0.06542969] 1   1 Match 322\n",
      "\n",
      "[-0.70214844  0.03942871 -0.12310791 -0.0645752  -0.28222656  0.12487793] 5   4 \n",
      "[-0.12072754  0.65771484  0.74658203  0.16601562 -0.54541016 -1.0927734 ] 2   3 \n",
      "[-0.32202148  0.13916016  0.09002686  0.05270386 -0.3034668  -0.25390625] 1   1 Match 323\n",
      "\n",
      "[-0.82373047  0.0892334   0.8432617   0.56884766 -0.52246094 -0.9824219 ] 2   4 \n",
      "[-1.2607422   0.09973145  0.32714844  0.38183594  0.11779785 -0.3408203 ] 3   1 \n",
      "[-0.30639648  0.25732422  0.3942871  -0.17907715 -0.8354492  -0.9453125 ] 2   0 \n",
      "[ 0.14904785  0.40429688  0.4873047   0.07965088 -0.64501953 -0.94140625] 2   0 \n",
      "[-1.1445312   0.15161133  0.32202148  0.73535156 -0.29711914 -0.73828125] 3   4 \n",
      "[-1.4550781  -0.03692627  0.25610352  0.65771484  0.13183594 -0.28833008] 3   4 \n",
      "[-0.9707031  -0.06262207  0.12792969  0.1628418  -0.24902344 -0.08306885] 3   1 \n",
      "[-2.3769531  -0.5029297  -0.5444336   0.60791016  0.97265625  0.53027344] 4   4 Match 324\n",
      "\n",
      "[-1.4951172  -0.06402588  0.46679688  0.5732422  -0.08825684 -0.26953125] 3   2 \n",
      "[-1.7880859  -0.2939453  -0.11254883  0.79296875  0.23535156 -0.15771484] 3   1 \n",
      "[-0.39331055  0.01847839  0.07415771  0.04043579 -0.30200195 -0.3088379 ] 2   3 \n",
      "[-1.7314453  -0.11462402 -0.01974487  0.57666016  0.3400879  -0.11334229] 3   5 \n",
      "[-1.3203125   0.08709717  0.24951172  0.51171875  0.17749023 -0.39331055] 3   5 \n",
      "[-0.63964844  0.18591309  0.45751953  0.21118164 -0.44506836 -0.61083984] 2   5 \n",
      "[-0.67578125  0.25708008  0.53759766  0.27294922 -0.375      -0.65722656] 2   2 Match 325\n",
      "\n",
      "[-0.9296875   0.11376953  0.37451172  0.15600586 -0.08361816 -0.2607422 ] 2   3 \n",
      "[-2.1152344  -0.4873047  -0.6098633   0.41210938  0.8041992   0.6479492 ] 4   5 \n",
      "[-1.5244141  -0.10614014 -0.14416504  0.1875      0.46875     0.45629883] 4   4 Match 326\n",
      "\n",
      "[-1.25        0.09338379  0.38916016  0.55908203 -0.00360489 -0.33081055] 3   1 \n",
      "[ 0.13439941  0.25805664  0.2734375   0.15161133 -0.5185547  -0.60595703] 2   2 Match 327\n",
      "\n",
      "[-0.6298828   0.5         0.5263672   0.60595703 -0.5551758  -1.0019531 ] 3   1 \n",
      "[-0.89160156  0.05422974  0.22473145  0.27124023 -0.26660156 -0.5019531 ] 3   2 \n",
      "[-0.68408203 -0.04058838  0.27026367  0.27490234 -0.09082031 -0.4958496 ] 3   3 Match 328\n",
      "\n",
      "[ 0.390625    0.4873047   0.33618164  0.06787109 -0.7451172  -0.9770508 ] 1   1 Match 329\n",
      "\n",
      "[ 0.19970703  0.42358398  0.2006836  -0.28466797 -0.7270508  -0.33984375] 1   3 \n",
      "[-0.23352051  0.48095703  0.45874023  0.09320068 -0.3322754  -0.98779297] 1   4 \n",
      "[-0.49780273  0.25097656 -0.00514603 -0.06982422 -0.33911133 -0.3635254 ] 1   2 \n",
      "[-1.3876953   0.00724411  0.63916016  0.5439453  -0.07348633 -0.54052734] 2   5 \n",
      "[-0.03068542  0.2607422   0.04562378 -0.04489136 -0.3227539  -0.38549805] 1   1 Match 330\n",
      "\n",
      "[-1.2705078   0.18078613  0.14587402  0.3815918   0.07629395 -0.39208984] 3   4 \n",
      "[-1.3867188  -0.11645508  0.22753906  0.6176758  -0.05618286 -0.34399414] 3   4 \n",
      "[-1.1289062  -0.08905029  0.19689941  0.46484375  0.01461029 -0.07421875] 3   2 \n",
      "[ 0.00195503  0.20141602  0.07513428 -0.10321045 -0.38110352 -0.37304688] 1   2 \n",
      "[-1.2119141  -0.04656982 -0.02165222  0.3605957   0.02230835 -0.13879395] 3   2 \n",
      "[-0.02493286  0.40527344  0.66845703  0.0637207  -0.640625   -0.9301758 ] 2   0 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.14538574  0.40527344  0.58251953 -0.04415894 -0.71533203 -0.86572266] 2   1 \n",
      "[-1.703125   -0.2277832   0.00418472  0.47436523  0.17700195  0.04946899] 3   5 \n",
      "[-0.5966797   0.17578125  0.19677734  0.1060791  -0.38891602 -0.41210938] 2   1 \n",
      "[-0.38916016  0.08068848 -0.0869751  -0.01216125 -0.10375977 -0.16101074] 1   1 Match 331\n",
      "\n",
      "[-0.9951172   0.01531219  0.05358887  0.13122559  0.31201172 -0.17504883] 4   2 \n",
      "[-1.6962891  -0.07714844 -0.17993164  0.45166016  0.3269043   0.32543945] 3   4 \n",
      "[-1.6240234  -0.17590332 -0.36376953  0.48266602  0.57958984  0.47973633] 4   2 \n",
      "[-1.8671875  -0.25878906 -0.37402344  0.4140625   0.6113281   0.5004883 ] 4   5 \n",
      "[-1.4667969  -0.11212158 -0.28686523  0.16894531  0.41333008  0.38110352] 4   1 \n",
      "[-0.92333984  0.18347168  0.56591797  0.45043945 -0.3137207  -0.640625  ] 2   3 \n",
      "[-1.9863281  -0.13476562 -0.20727539  0.68066406  0.80566406  0.38671875] 4   3 \n",
      "[-2.3535156 -0.5253906 -0.7011719  0.6767578  0.9760742  1.0917969] 5   3 \n",
      "[-2.140625   -0.12475586 -0.03089905  0.7817383   0.3671875  -0.09643555] 3   2 \n",
      "[-1.3261719  -0.15466309  0.31958008  0.6660156   0.14624023 -0.35375977] 3   3 Match 332\n",
      "\n",
      "[-0.41577148  0.16955566 -0.09008789 -0.03393555 -0.06787109 -0.1697998 ] 1   2 \n",
      "[-0.67871094 -0.0055542  -0.23950195  0.05154419  0.07012939  0.01383972] 4   5 \n",
      "[-2.0664062  -0.24658203 -0.4794922   0.41235352  0.6557617   0.4309082 ] 4   4 Match 333\n",
      "\n",
      "[-1.7060547  -0.10455322 -0.15942383  0.3828125   0.44213867  0.25830078] 4   3 \n",
      "[-0.3647461   0.33935547  0.27539062 -0.0480957  -0.4794922  -0.44921875] 1   4 \n",
      "[-1.1503906  -0.16699219  0.13171387  0.29956055  0.07250977 -0.11047363] 3   3 Match 334\n",
      "\n",
      "[-1.9248047  -0.30493164 -0.31835938  0.60546875  0.51464844  0.41210938] 3   4 \n",
      "[-0.45654297  0.02166748  0.17712402  0.16186523 -0.2479248  -0.3552246 ] 2   1 \n",
      "[-1.7128906  -0.08459473 -0.04046631  0.34838867  0.41259766  0.20019531] 4   1 \n",
      "[ 0.36401367  0.4074707   0.57910156 -0.07592773 -1.0039062  -1.0888672 ] 2   3 \n",
      "[-0.19641113  0.0982666  -0.19873047 -0.08172607 -0.125      -0.07989502] 1   1 Match 335\n",
      "\n",
      "[-2.1640625  -0.4243164  -0.40795898  0.5527344   0.61621094  0.51123047] 4   3 \n",
      "[-0.77001953  0.27661133  0.56884766  0.56103516 -0.45898438 -1.0947266 ] 2   3 \n",
      "[-1.4609375   0.00830841  0.30566406  0.8286133  -0.14160156 -0.5546875 ] 3   3 Match 336\n",
      "\n",
      "[ 0.12988281  0.4489746   0.44067383 -0.06524658 -0.4741211  -0.6542969 ] 1   1 Match 337\n",
      "\n",
      "[-1.5537109  -0.17211914  0.08209229  0.52441406  0.02850342 -0.3491211 ] 3   5 \n",
      "[ 0.55810547  0.7260742   0.40161133 -0.125      -0.9482422  -1.0595703 ] 1   0 \n",
      "[-0.29296875  0.03823853 -0.2644043  -0.16369629 -0.3166504   0.04824829] 5   0 \n",
      "[-1.6943359  -0.11853027 -0.22387695  0.33007812  0.609375    0.3486328 ] 4   4 Match 338\n",
      "\n",
      "[-1.5976562   0.13012695  0.41308594  0.63427734  0.15686035 -0.5878906 ] 3   3 Match 339\n",
      "\n",
      "[-0.34277344  0.05291748 -0.19140625 -0.02308655 -0.02510071  0.01683044] 1   4 \n",
      "[-1.0449219   0.28466797  0.48706055  0.58203125 -0.12280273 -0.6738281 ] 3   2 \n",
      "[-0.9736328   0.03634644  0.10968018  0.05487061  0.13781738 -0.04135132] 4   0 \n",
      "[-1.0107422  -0.04827881 -0.13879395  0.25512695  0.34375     0.18652344] 4   2 \n",
      "[-1.0791016e+00  9.7322464e-04  4.1748047e-01  3.9086914e-01\n",
      " -2.3962402e-01 -6.2841797e-01] 2   3 \n",
      "[-1.4648438  -0.24804688 -0.24633789  0.2993164   0.52783203  0.23718262] 4   4 Match 340\n",
      "\n",
      "[ 0.25073242  0.6699219   0.6040039  -0.02008057 -1.0224609  -1.1748047 ] 1   1 Match 341\n",
      "\n",
      "[-1.4306641   0.10272217  0.21105957  0.61572266 -0.03408813 -0.3996582 ] 3   5 \n",
      "[-0.89941406  0.08148193  0.06488037  0.09191895  0.03936768 -0.02297974] 3   0 \n",
      "[-0.21960449  0.2076416   0.21679688  0.05429077 -0.43041992 -0.5253906 ] 2   1 \n",
      "[ 0.4897461   0.47094727  0.20031738 -0.08587646 -0.6176758  -0.6689453 ] 0   0 Match 342\n",
      "\n",
      "[-1.3134766   0.03417969  0.12176514  0.43847656  0.23864746 -0.05282593] 3   4 \n",
      "[-0.04171753  0.34155273  0.02244568 -0.31469727 -0.22558594 -0.17944336] 1   0 \n",
      "[-0.33422852  0.13806152  0.26000977 -0.07879639 -0.58740234 -0.44311523] 2   1 \n",
      "[-0.89453125 -0.12731934  0.18286133  0.4411621   0.14099121 -0.2758789 ] 3   2 \n",
      "[-2.1171875  -0.3828125  -0.48217773  0.640625    0.8720703   0.6791992 ] 4   2 \n",
      "[-1.5332031  -0.15539551 -0.29174805  0.18481445  0.46069336  0.8696289 ] 5   0 \n",
      "[-0.6113281   0.08990479 -0.02037048 -0.00617218 -0.04421997 -0.16455078] 1   1 Match 343\n",
      "\n",
      "[ 0.30273438  0.3540039   0.05529785 -0.29711914 -0.55078125 -0.2849121 ] 1   2 \n",
      "[-1.5146484  -0.22607422 -0.37524414  0.2644043   0.26293945  0.68603516] 5   5 Match 344\n",
      "\n",
      "[-0.85009766  0.15734863  0.04187012 -0.12414551 -0.2536621   0.07519531] 1   2 \n",
      "[-0.90283203  0.14233398  0.17956543  0.1706543  -0.10028076 -0.20251465] 2   5 \n",
      "[-0.6567383   0.16711426 -0.09692383 -0.11804199 -0.22924805  0.10845947] 1   5 \n",
      "[-1.1923828  -0.03643799 -0.01418304  0.1730957   0.38305664  0.04623413] 4   4 Match 345\n",
      "\n",
      "[-1.1923828  -0.05319214 -0.17419434  0.30786133  0.42895508  0.23083496] 4   3 \n",
      "[-0.84716797  0.04684448  0.0096283   0.23339844 -0.13513184 -0.21435547] 3   4 \n",
      "[-1.4775391  -0.05697632 -0.4675293   0.18908691  0.6113281   0.42578125] 4   3 \n",
      "[-0.3959961   0.05767822 -0.18408203 -0.04348755 -0.03491211 -0.03222656] 1   1 Match 346\n",
      "\n",
      "[-1.8759766  -0.2902832  -0.2553711   0.5698242   0.55126953  0.18359375] 3   1 \n",
      "[-0.06854248  0.13378906 -0.1048584  -0.27807617 -0.39135742 -0.3334961 ] 1   1 Match 347\n",
      "\n",
      "[-0.45751953  0.12188721  0.42358398  0.04104614 -0.31835938 -0.6064453 ] 2   1 \n",
      "[ 0.3527832   0.3154297  -0.0395813  -0.296875   -0.52246094 -0.43408203] 0   5 \n",
      "[-1.4423828   0.21936035  0.5097656   0.48999023 -0.14758301 -0.68359375] 2   2 Match 348\n",
      "\n",
      "[-1.5898438  -0.11956787  0.10083008  0.4494629   0.26831055 -0.03729248] 3   0 \n",
      "[-0.9814453   0.05822754  0.0461731   0.24194336  0.01213837 -0.21374512] 3   3 Match 349\n",
      "\n",
      "349\n"
     ]
    }
   ],
   "source": [
    "Pred=[]\n",
    "\n",
    "countCorrect=0\n",
    "\n",
    "for row in range(TestModel_outputs.shape[0]):\n",
    "    outputs=TestModel_outputs[row]\n",
    "    #print(test.iloc[row,0])\n",
    "    print(outputs, end=' ')\n",
    "    \n",
    "    result=0\n",
    "    if outputs[0]<outputs[1]:result=1\n",
    "    if outputs[result]<outputs[2]:result=2\n",
    "    if outputs[result]<outputs[3]:result=3\n",
    "    if outputs[result]<outputs[4]:result=4\n",
    "    if outputs[result]<outputs[5]:result=5\n",
    "    Pred.append(result)\n",
    "    print(result, ' ',test.iloc[row,1], end=' ')\n",
    "    if result==test.iloc[row,1]:\n",
    "        countCorrect+=1\n",
    "        print('Match',countCorrect)\n",
    "    print('')\n",
    "\n",
    "print(countCorrect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  7  31  28  15   7   3]\n",
      " [  0  65  53  69  32  14]\n",
      " [  3  41  66  79  28   4]\n",
      " [  3  31  50 110  42  19]\n",
      " [  0  24  29 101  64  31]\n",
      " [  2  33  18  64  52  37]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "print(metrics.confusion_matrix(test['labels'],Pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Pants       0.47      0.08      0.13        91\n",
      "       False       0.29      0.28      0.28       233\n",
      " Barely-True       0.27      0.30      0.28       221\n",
      "   Half-True       0.25      0.43      0.32       255\n",
      " Mostly-True       0.28      0.26      0.27       249\n",
      "        True       0.34      0.18      0.24       206\n",
      "\n",
      "    accuracy                           0.28      1255\n",
      "   macro avg       0.32      0.25      0.25      1255\n",
      "weighted avg       0.30      0.28      0.27      1255\n",
      "\n"
     ]
    }
   ],
   "source": [
    "target_names = ['Pants', 'False', 'Barely-True','Half-True','Mostly-True','True']\n",
    "\n",
    "print(metrics.classification_report(test['labels'], Pred,target_names =target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving...\n",
      "Saving Complete on 2020-05-01 11:57:38.696120 in: ./TunedModels/roberta/roberta-large/Saves/\n"
     ]
    }
   ],
   "source": [
    "# saving the output of the models to CSVs\n",
    "#these are 1X6 classification vectors\n",
    "\n",
    "SavesDirectory='./TunedModels/'+model_class+'/'+model_version+\"/Saves/\"\n",
    "print('Saving...')\n",
    "trainOut = pd.DataFrame(data= TrainModel_outputs )\n",
    "trainOut.to_csv(SavesDirectory+'trainOut.tsv', sep='\\t',  index=False)\n",
    "\n",
    "evalOut = pd.DataFrame(data= EvalModel_outputs )\n",
    "evalOut.to_csv(SavesDirectory+'evalOut.tsv', sep='\\t',  index=False)\n",
    "\n",
    "testOut = pd.DataFrame(data= TestModel_outputs )\n",
    "testOut.to_csv(SavesDirectory+'testOut.tsv', sep='\\t',  index=False)\n",
    "\n",
    "print('Saving Complete on',datetime.now() ,'in:', SavesDirectory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "del(model)\n",
    "del(train,Eval,test)\n",
    "del(trainOut,evalOut,testOut)\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Adding the reputation vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section takes the output results from the transformer used above and uses it together with the speaker's reputation to enhance the classification.\n",
    "\n",
    "Before running this section it is suggested that you halt the program and start running it again from this cell. The neural net will likely have an error caused by some unreleased variable used by thr simple transformers library. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PantsTotal</th>\n",
       "      <th>NotRealTotal</th>\n",
       "      <th>BarelyTotal</th>\n",
       "      <th>HalfTotal</th>\n",
       "      <th>MostlyTotal</th>\n",
       "      <th>RealTotal</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.005</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.363281</td>\n",
       "      <td>0.844238</td>\n",
       "      <td>0.187134</td>\n",
       "      <td>-0.561035</td>\n",
       "      <td>-0.919922</td>\n",
       "      <td>-0.999512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.005</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.385010</td>\n",
       "      <td>0.440186</td>\n",
       "      <td>0.621094</td>\n",
       "      <td>0.145508</td>\n",
       "      <td>-0.747070</td>\n",
       "      <td>-1.106445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.005</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.102539</td>\n",
       "      <td>0.123962</td>\n",
       "      <td>0.210327</td>\n",
       "      <td>0.223267</td>\n",
       "      <td>-0.249512</td>\n",
       "      <td>-0.057983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.369141</td>\n",
       "      <td>-0.163452</td>\n",
       "      <td>0.201782</td>\n",
       "      <td>0.436523</td>\n",
       "      <td>0.174072</td>\n",
       "      <td>-0.210938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.648438</td>\n",
       "      <td>-0.130493</td>\n",
       "      <td>-0.181396</td>\n",
       "      <td>0.435303</td>\n",
       "      <td>0.427734</td>\n",
       "      <td>0.327393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10094</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.687500</td>\n",
       "      <td>-0.177002</td>\n",
       "      <td>-0.099304</td>\n",
       "      <td>0.610840</td>\n",
       "      <td>0.259521</td>\n",
       "      <td>-0.136963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10095</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.946289</td>\n",
       "      <td>-0.401123</td>\n",
       "      <td>-0.247559</td>\n",
       "      <td>0.578125</td>\n",
       "      <td>0.709961</td>\n",
       "      <td>0.442627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10096</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.206299</td>\n",
       "      <td>0.503418</td>\n",
       "      <td>0.000852</td>\n",
       "      <td>-0.274414</td>\n",
       "      <td>-0.712402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10097</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.681152</td>\n",
       "      <td>0.008560</td>\n",
       "      <td>0.301758</td>\n",
       "      <td>0.293701</td>\n",
       "      <td>-0.668945</td>\n",
       "      <td>-0.617188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10098</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.923828</td>\n",
       "      <td>-0.077515</td>\n",
       "      <td>-0.418457</td>\n",
       "      <td>-0.117371</td>\n",
       "      <td>0.007282</td>\n",
       "      <td>0.267578</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10099 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       PantsTotal  NotRealTotal  BarelyTotal  HalfTotal  MostlyTotal  \\\n",
       "0           0.005         0.000         0.00      0.000        0.000   \n",
       "1           0.005         0.000         0.01      0.000        0.000   \n",
       "2           0.005         0.000         0.01      0.000        0.000   \n",
       "3           0.000         0.000         0.00      0.000        0.005   \n",
       "4           0.000         0.000         0.00      0.000        0.005   \n",
       "...           ...           ...          ...        ...          ...   \n",
       "10094       0.000         0.005         0.00      0.000        0.010   \n",
       "10095       0.000         0.005         0.00      0.000        0.010   \n",
       "10096       0.000         0.005         0.00      0.000        0.010   \n",
       "10097       0.000         0.000         0.00      0.005        0.000   \n",
       "10098       0.000         0.000         0.00      0.000        0.005   \n",
       "\n",
       "       RealTotal         0         1         2         3         4         5  \n",
       "0            0.0  1.363281  0.844238  0.187134 -0.561035 -0.919922 -0.999512  \n",
       "1            0.0 -0.385010  0.440186  0.621094  0.145508 -0.747070 -1.106445  \n",
       "2            0.0 -1.102539  0.123962  0.210327  0.223267 -0.249512 -0.057983  \n",
       "3            0.0 -1.369141 -0.163452  0.201782  0.436523  0.174072 -0.210938  \n",
       "4            0.0 -1.648438 -0.130493 -0.181396  0.435303  0.427734  0.327393  \n",
       "...          ...       ...       ...       ...       ...       ...       ...  \n",
       "10094        0.0 -1.687500 -0.177002 -0.099304  0.610840  0.259521 -0.136963  \n",
       "10095        0.0 -1.946289 -0.401123 -0.247559  0.578125  0.709961  0.442627  \n",
       "10096        0.0 -0.638672  0.206299  0.503418  0.000852 -0.274414 -0.712402  \n",
       "10097        0.0 -0.681152  0.008560  0.301758  0.293701 -0.668945 -0.617188  \n",
       "10098        0.0 -0.923828 -0.077515 -0.418457 -0.117371  0.007282  0.267578  \n",
       "\n",
       "[10099 rows x 12 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "train=pd.read_excel('train-clean-Reputation.xlsx' )\n",
    "train=train.iloc[:,:-1].astype(float)\n",
    "train=train/200  #for scaling\n",
    "#train\n",
    "\n",
    "model_class='roberta'  # bert or roberta or albert\n",
    "model_version='roberta-large' #bert-base-cased, roberta-base, roberta-large, albert-base-v2 OR albert-large-v2\n",
    "\n",
    "SavesDirectory='./TunedModels/'+model_class+'/'+model_version+\"/Saves/\"\n",
    "TF_Output=pd.read_csv( SavesDirectory+'trainOut.tsv', sep='\\t')\n",
    "\n",
    "train=pd.concat([train,TF_Output], axis=1)\n",
    "\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10094</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10095</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10096</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10097</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10098</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10099 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0  1  2  3  4  5\n",
       "0      1  0  0  0  0  0\n",
       "1      1  0  0  0  0  0\n",
       "2      0  0  1  0  0  0\n",
       "3      0  0  0  0  1  0\n",
       "4      0  0  0  0  1  0\n",
       "...   .. .. .. .. .. ..\n",
       "10094  0  1  0  0  0  0\n",
       "10095  0  0  0  0  1  0\n",
       "10096  0  0  0  0  1  0\n",
       "10097  0  0  0  1  0  0\n",
       "10098  0  0  0  0  1  0\n",
       "\n",
       "[10099 rows x 6 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TrainLables=pd.read_excel('train-clean-Reputation.xlsx' )\n",
    "TrainLables=TrainLables.iloc[:,-1] \n",
    "\n",
    "TrainLables=pd.get_dummies(TrainLables)\n",
    "TrainLables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 5.0000e-03,  0.0000e+00,  0.0000e+00,  ..., -5.6104e-01,\n",
       "         -9.1992e-01, -9.9951e-01],\n",
       "        [ 5.0000e-03,  0.0000e+00,  1.0000e-02,  ...,  1.4551e-01,\n",
       "         -7.4707e-01, -1.1064e+00],\n",
       "        [ 5.0000e-03,  0.0000e+00,  1.0000e-02,  ...,  2.2327e-01,\n",
       "         -2.4951e-01, -5.7983e-02],\n",
       "        ...,\n",
       "        [ 0.0000e+00,  5.0000e-03,  0.0000e+00,  ...,  8.5163e-04,\n",
       "         -2.7441e-01, -7.1240e-01],\n",
       "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  2.9370e-01,\n",
       "         -6.6895e-01, -6.1719e-01],\n",
       "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ..., -1.1737e-01,\n",
       "          7.2823e-03,  2.6758e-01]], dtype=torch.float64)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input=torch.tensor(train.values)\n",
    "\n",
    "input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 1., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 1., 0., 0.],\n",
       "        [0., 0., 0., 0., 1., 0.]], dtype=torch.float64)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets=torch.tensor(TrainLables.astype(float).values)\n",
    "\n",
    "targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input size: 12\n",
      "output size: 6\n"
     ]
    }
   ],
   "source": [
    " \n",
    "size= torch.tensor(input[0].size())\n",
    "InputSize=size.item()\n",
    "\n",
    "OutputSize=torch.tensor(targets[0].size()).item()\n",
    "\n",
    "print('input size:', InputSize)\n",
    "print('output size:', OutputSize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Net(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "         \n",
    "        # an affine operation: y = Wx + b\n",
    "        self.fc1 = nn.Linear(InputSize, 24)  # input size \n",
    "        self.fc2 = nn.Linear(24, 12)\n",
    "        self.fc3 = nn.Linear(12, OutputSize)  #classifies 'outputsize' different classes\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.tanh(self.fc1(x))\n",
    "        x = torch.tanh(self.fc2(x)) \n",
    "        x = torch.tanh(self.fc3(x)).double()\n",
    "        return x\n",
    "\n",
    "    \n",
    "\n",
    "#now we use it\n",
    "\n",
    "net = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here we  setup the neural network parameters\n",
    "# pick an optimizer (Simple Gradient Descent)\n",
    "\n",
    "learning_rate = 9e-4\n",
    "criterion = nn.MSELoss()  #computes the loss Function\n",
    "\n",
    "import torch.optim as optim\n",
    "\n",
    "# creating optimizer\n",
    "#optimizer = optim.SGD(net.parameters(), lr=learning_rate)\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor(0.2468, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 0\n",
      "Loss: tensor(0.2430, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1\n",
      "Loss: tensor(0.2392, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2\n",
      "Loss: tensor(0.2355, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3\n",
      "Loss: tensor(0.2319, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4\n",
      "Loss: tensor(0.2283, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5\n",
      "Loss: tensor(0.2248, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6\n",
      "Loss: tensor(0.2214, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7\n",
      "Loss: tensor(0.2180, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8\n",
      "Loss: tensor(0.2147, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 9\n",
      "Loss: tensor(0.2114, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 10\n",
      "Loss: tensor(0.2083, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 11\n",
      "Loss: tensor(0.2051, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 12\n",
      "Loss: tensor(0.2021, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 13\n",
      "Loss: tensor(0.1991, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 14\n",
      "Loss: tensor(0.1962, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 15\n",
      "Loss: tensor(0.1933, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 16\n",
      "Loss: tensor(0.1905, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 17\n",
      "Loss: tensor(0.1878, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 18\n",
      "Loss: tensor(0.1851, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 19\n",
      "Loss: tensor(0.1826, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 20\n",
      "Loss: tensor(0.1800, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 21\n",
      "Loss: tensor(0.1776, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 22\n",
      "Loss: tensor(0.1752, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 23\n",
      "Loss: tensor(0.1729, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 24\n",
      "Loss: tensor(0.1707, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 25\n",
      "Loss: tensor(0.1685, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 26\n",
      "Loss: tensor(0.1664, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 27\n",
      "Loss: tensor(0.1644, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 28\n",
      "Loss: tensor(0.1625, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 29\n",
      "Loss: tensor(0.1606, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 30\n",
      "Loss: tensor(0.1588, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 31\n",
      "Loss: tensor(0.1570, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 32\n",
      "Loss: tensor(0.1554, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 33\n",
      "Loss: tensor(0.1538, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 34\n",
      "Loss: tensor(0.1523, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 35\n",
      "Loss: tensor(0.1508, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 36\n",
      "Loss: tensor(0.1495, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 37\n",
      "Loss: tensor(0.1482, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 38\n",
      "Loss: tensor(0.1470, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 39\n",
      "Loss: tensor(0.1458, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 40\n",
      "Loss: tensor(0.1448, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 41\n",
      "Loss: tensor(0.1438, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 42\n",
      "Loss: tensor(0.1428, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 43\n",
      "Loss: tensor(0.1420, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 44\n",
      "Loss: tensor(0.1412, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 45\n",
      "Loss: tensor(0.1404, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 46\n",
      "Loss: tensor(0.1398, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 47\n",
      "Loss: tensor(0.1392, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 48\n",
      "Loss: tensor(0.1386, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 49\n",
      "Loss: tensor(0.1381, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 50\n",
      "Loss: tensor(0.1377, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 51\n",
      "Loss: tensor(0.1373, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 52\n",
      "Loss: tensor(0.1369, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 53\n",
      "Loss: tensor(0.1366, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 54\n",
      "Loss: tensor(0.1363, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 55\n",
      "Loss: tensor(0.1360, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 56\n",
      "Loss: tensor(0.1358, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 57\n",
      "Loss: tensor(0.1356, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 58\n",
      "Loss: tensor(0.1354, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 59\n",
      "Loss: tensor(0.1353, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 60\n",
      "Loss: tensor(0.1351, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 61\n",
      "Loss: tensor(0.1350, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 62\n",
      "Loss: tensor(0.1349, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 63\n",
      "Loss: tensor(0.1348, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 64\n",
      "Loss: tensor(0.1347, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 65\n",
      "Loss: tensor(0.1346, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 66\n",
      "Loss: tensor(0.1345, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 67\n",
      "Loss: tensor(0.1344, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 68\n",
      "Loss: tensor(0.1343, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 69\n",
      "Loss: tensor(0.1343, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 70\n",
      "Loss: tensor(0.1342, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 71\n",
      "Loss: tensor(0.1341, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 72\n",
      "Loss: tensor(0.1341, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 73\n",
      "Loss: tensor(0.1340, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 74\n",
      "Loss: tensor(0.1339, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 75\n",
      "Loss: tensor(0.1339, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 76\n",
      "Loss: tensor(0.1338, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 77\n",
      "Loss: tensor(0.1337, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 78\n",
      "Loss: tensor(0.1337, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 79\n",
      "Loss: tensor(0.1336, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 80\n",
      "Loss: tensor(0.1336, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 81\n",
      "Loss: tensor(0.1335, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 82\n",
      "Loss: tensor(0.1335, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 83\n",
      "Loss: tensor(0.1334, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 84\n",
      "Loss: tensor(0.1334, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 85\n",
      "Loss: tensor(0.1333, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 86\n",
      "Loss: tensor(0.1333, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 87\n",
      "Loss: tensor(0.1332, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 88\n",
      "Loss: tensor(0.1332, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 89\n",
      "Loss: tensor(0.1331, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 90\n",
      "Loss: tensor(0.1331, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 91\n",
      "Loss: tensor(0.1330, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 92\n",
      "Loss: tensor(0.1330, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 93\n",
      "Loss: tensor(0.1330, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 94\n",
      "Loss: tensor(0.1329, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 95\n",
      "Loss: tensor(0.1329, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 96\n",
      "Loss: tensor(0.1328, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 97\n",
      "Loss: tensor(0.1328, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 98\n",
      "Loss: tensor(0.1328, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 99\n",
      "Loss: tensor(0.1327, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 100\n",
      "Loss: tensor(0.1327, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 101\n",
      "Loss: tensor(0.1327, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 102\n",
      "Loss: tensor(0.1326, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 103\n",
      "Loss: tensor(0.1326, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 104\n",
      "Loss: tensor(0.1326, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 105\n",
      "Loss: tensor(0.1325, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 106\n",
      "Loss: tensor(0.1325, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 107\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor(0.1325, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 108\n",
      "Loss: tensor(0.1324, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 109\n",
      "Loss: tensor(0.1324, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 110\n",
      "Loss: tensor(0.1324, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 111\n",
      "Loss: tensor(0.1323, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 112\n",
      "Loss: tensor(0.1323, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 113\n",
      "Loss: tensor(0.1323, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 114\n",
      "Loss: tensor(0.1322, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 115\n",
      "Loss: tensor(0.1322, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 116\n",
      "Loss: tensor(0.1322, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 117\n",
      "Loss: tensor(0.1322, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 118\n",
      "Loss: tensor(0.1321, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 119\n",
      "Loss: tensor(0.1321, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 120\n",
      "Loss: tensor(0.1321, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 121\n",
      "Loss: tensor(0.1321, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 122\n",
      "Loss: tensor(0.1320, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 123\n",
      "Loss: tensor(0.1320, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 124\n",
      "Loss: tensor(0.1320, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 125\n",
      "Loss: tensor(0.1320, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 126\n",
      "Loss: tensor(0.1319, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 127\n",
      "Loss: tensor(0.1319, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 128\n",
      "Loss: tensor(0.1319, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 129\n",
      "Loss: tensor(0.1319, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 130\n",
      "Loss: tensor(0.1318, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 131\n",
      "Loss: tensor(0.1318, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 132\n",
      "Loss: tensor(0.1318, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 133\n",
      "Loss: tensor(0.1318, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 134\n",
      "Loss: tensor(0.1318, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 135\n",
      "Loss: tensor(0.1317, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 136\n",
      "Loss: tensor(0.1317, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 137\n",
      "Loss: tensor(0.1317, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 138\n",
      "Loss: tensor(0.1317, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 139\n",
      "Loss: tensor(0.1317, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 140\n",
      "Loss: tensor(0.1316, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 141\n",
      "Loss: tensor(0.1316, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 142\n",
      "Loss: tensor(0.1316, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 143\n",
      "Loss: tensor(0.1316, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 144\n",
      "Loss: tensor(0.1316, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 145\n",
      "Loss: tensor(0.1315, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 146\n",
      "Loss: tensor(0.1315, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 147\n",
      "Loss: tensor(0.1315, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 148\n",
      "Loss: tensor(0.1315, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 149\n",
      "Loss: tensor(0.1315, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 150\n",
      "Loss: tensor(0.1314, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 151\n",
      "Loss: tensor(0.1314, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 152\n",
      "Loss: tensor(0.1314, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 153\n",
      "Loss: tensor(0.1314, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 154\n",
      "Loss: tensor(0.1314, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 155\n",
      "Loss: tensor(0.1314, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 156\n",
      "Loss: tensor(0.1313, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 157\n",
      "Loss: tensor(0.1313, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 158\n",
      "Loss: tensor(0.1313, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 159\n",
      "Loss: tensor(0.1313, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 160\n",
      "Loss: tensor(0.1313, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 161\n",
      "Loss: tensor(0.1313, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 162\n",
      "Loss: tensor(0.1312, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 163\n",
      "Loss: tensor(0.1312, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 164\n",
      "Loss: tensor(0.1312, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 165\n",
      "Loss: tensor(0.1312, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 166\n",
      "Loss: tensor(0.1312, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 167\n",
      "Loss: tensor(0.1312, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 168\n",
      "Loss: tensor(0.1312, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 169\n",
      "Loss: tensor(0.1311, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 170\n",
      "Loss: tensor(0.1311, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 171\n",
      "Loss: tensor(0.1311, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 172\n",
      "Loss: tensor(0.1311, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 173\n",
      "Loss: tensor(0.1311, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 174\n",
      "Loss: tensor(0.1311, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 175\n",
      "Loss: tensor(0.1311, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 176\n",
      "Loss: tensor(0.1310, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 177\n",
      "Loss: tensor(0.1310, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 178\n",
      "Loss: tensor(0.1310, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 179\n",
      "Loss: tensor(0.1310, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 180\n",
      "Loss: tensor(0.1310, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 181\n",
      "Loss: tensor(0.1310, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 182\n",
      "Loss: tensor(0.1310, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 183\n",
      "Loss: tensor(0.1310, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 184\n",
      "Loss: tensor(0.1309, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 185\n",
      "Loss: tensor(0.1309, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 186\n",
      "Loss: tensor(0.1309, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 187\n",
      "Loss: tensor(0.1309, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 188\n",
      "Loss: tensor(0.1309, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 189\n",
      "Loss: tensor(0.1309, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 190\n",
      "Loss: tensor(0.1309, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 191\n",
      "Loss: tensor(0.1309, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 192\n",
      "Loss: tensor(0.1309, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 193\n",
      "Loss: tensor(0.1308, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 194\n",
      "Loss: tensor(0.1308, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 195\n",
      "Loss: tensor(0.1308, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 196\n",
      "Loss: tensor(0.1308, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 197\n",
      "Loss: tensor(0.1308, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 198\n",
      "Loss: tensor(0.1308, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 199\n",
      "Loss: tensor(0.1308, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 200\n",
      "Loss: tensor(0.1308, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 201\n",
      "Loss: tensor(0.1308, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 202\n",
      "Loss: tensor(0.1308, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 203\n",
      "Loss: tensor(0.1307, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 204\n",
      "Loss: tensor(0.1307, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 205\n",
      "Loss: tensor(0.1307, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 206\n",
      "Loss: tensor(0.1307, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 207\n",
      "Loss: tensor(0.1307, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 208\n",
      "Loss: tensor(0.1307, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 209\n",
      "Loss: tensor(0.1307, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 210\n",
      "Loss: tensor(0.1307, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 211\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor(0.1307, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 212\n",
      "Loss: tensor(0.1307, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 213\n",
      "Loss: tensor(0.1307, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 214\n",
      "Loss: tensor(0.1307, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 215\n",
      "Loss: tensor(0.1306, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 216\n",
      "Loss: tensor(0.1306, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 217\n",
      "Loss: tensor(0.1306, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 218\n",
      "Loss: tensor(0.1306, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 219\n",
      "Loss: tensor(0.1306, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 220\n",
      "Loss: tensor(0.1306, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 221\n",
      "Loss: tensor(0.1306, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 222\n",
      "Loss: tensor(0.1306, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 223\n",
      "Loss: tensor(0.1306, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 224\n",
      "Loss: tensor(0.1306, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 225\n",
      "Loss: tensor(0.1306, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 226\n",
      "Loss: tensor(0.1306, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 227\n",
      "Loss: tensor(0.1305, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 228\n",
      "Loss: tensor(0.1305, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 229\n",
      "Loss: tensor(0.1305, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 230\n",
      "Loss: tensor(0.1305, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 231\n",
      "Loss: tensor(0.1305, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 232\n",
      "Loss: tensor(0.1305, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 233\n",
      "Loss: tensor(0.1305, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 234\n",
      "Loss: tensor(0.1305, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 235\n",
      "Loss: tensor(0.1305, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 236\n",
      "Loss: tensor(0.1305, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 237\n",
      "Loss: tensor(0.1305, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 238\n",
      "Loss: tensor(0.1305, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 239\n",
      "Loss: tensor(0.1305, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 240\n",
      "Loss: tensor(0.1305, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 241\n",
      "Loss: tensor(0.1304, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 242\n",
      "Loss: tensor(0.1304, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 243\n",
      "Loss: tensor(0.1304, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 244\n",
      "Loss: tensor(0.1304, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 245\n",
      "Loss: tensor(0.1304, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 246\n",
      "Loss: tensor(0.1304, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 247\n",
      "Loss: tensor(0.1304, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 248\n",
      "Loss: tensor(0.1304, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 249\n",
      "Loss: tensor(0.1304, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 250\n",
      "Loss: tensor(0.1304, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 251\n",
      "Loss: tensor(0.1304, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 252\n",
      "Loss: tensor(0.1304, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 253\n",
      "Loss: tensor(0.1304, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 254\n",
      "Loss: tensor(0.1304, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 255\n",
      "Loss: tensor(0.1304, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 256\n",
      "Loss: tensor(0.1303, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 257\n",
      "Loss: tensor(0.1303, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 258\n",
      "Loss: tensor(0.1303, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 259\n",
      "Loss: tensor(0.1303, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 260\n",
      "Loss: tensor(0.1303, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 261\n",
      "Loss: tensor(0.1303, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 262\n",
      "Loss: tensor(0.1303, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 263\n",
      "Loss: tensor(0.1303, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 264\n",
      "Loss: tensor(0.1303, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 265\n",
      "Loss: tensor(0.1303, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 266\n",
      "Loss: tensor(0.1303, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 267\n",
      "Loss: tensor(0.1303, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 268\n",
      "Loss: tensor(0.1303, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 269\n",
      "Loss: tensor(0.1303, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 270\n",
      "Loss: tensor(0.1303, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 271\n",
      "Loss: tensor(0.1302, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 272\n",
      "Loss: tensor(0.1302, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 273\n",
      "Loss: tensor(0.1302, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 274\n",
      "Loss: tensor(0.1302, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 275\n",
      "Loss: tensor(0.1302, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 276\n",
      "Loss: tensor(0.1302, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 277\n",
      "Loss: tensor(0.1302, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 278\n",
      "Loss: tensor(0.1302, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 279\n",
      "Loss: tensor(0.1302, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 280\n",
      "Loss: tensor(0.1302, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 281\n",
      "Loss: tensor(0.1302, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 282\n",
      "Loss: tensor(0.1302, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 283\n",
      "Loss: tensor(0.1302, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 284\n",
      "Loss: tensor(0.1302, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 285\n",
      "Loss: tensor(0.1302, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 286\n",
      "Loss: tensor(0.1302, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 287\n",
      "Loss: tensor(0.1302, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 288\n",
      "Loss: tensor(0.1301, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 289\n",
      "Loss: tensor(0.1301, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 290\n",
      "Loss: tensor(0.1301, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 291\n",
      "Loss: tensor(0.1301, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 292\n",
      "Loss: tensor(0.1301, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 293\n",
      "Loss: tensor(0.1301, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 294\n",
      "Loss: tensor(0.1301, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 295\n",
      "Loss: tensor(0.1301, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 296\n",
      "Loss: tensor(0.1301, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 297\n",
      "Loss: tensor(0.1301, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 298\n",
      "Loss: tensor(0.1301, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 299\n",
      "Loss: tensor(0.1301, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 300\n",
      "Loss: tensor(0.1301, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 301\n",
      "Loss: tensor(0.1301, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 302\n",
      "Loss: tensor(0.1301, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 303\n",
      "Loss: tensor(0.1301, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 304\n",
      "Loss: tensor(0.1301, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 305\n",
      "Loss: tensor(0.1300, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 306\n",
      "Loss: tensor(0.1300, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 307\n",
      "Loss: tensor(0.1300, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 308\n",
      "Loss: tensor(0.1300, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 309\n",
      "Loss: tensor(0.1300, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 310\n",
      "Loss: tensor(0.1300, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 311\n",
      "Loss: tensor(0.1300, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 312\n",
      "Loss: tensor(0.1300, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 313\n",
      "Loss: tensor(0.1300, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 314\n",
      "Loss: tensor(0.1300, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 315\n",
      "Loss: tensor(0.1300, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 316\n",
      "Loss: tensor(0.1300, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 317\n",
      "Loss: tensor(0.1300, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 318\n",
      "Loss: tensor(0.1300, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 319\n",
      "Loss: tensor(0.1300, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 320\n",
      "Loss: tensor(0.1300, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 321\n",
      "Loss: tensor(0.1300, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 322\n",
      "Loss: tensor(0.1299, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 323\n",
      "Loss: tensor(0.1299, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 324\n",
      "Loss: tensor(0.1299, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 325\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor(0.1299, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 326\n",
      "Loss: tensor(0.1299, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 327\n",
      "Loss: tensor(0.1299, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 328\n",
      "Loss: tensor(0.1299, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 329\n",
      "Loss: tensor(0.1299, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 330\n",
      "Loss: tensor(0.1299, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 331\n",
      "Loss: tensor(0.1299, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 332\n",
      "Loss: tensor(0.1299, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 333\n",
      "Loss: tensor(0.1299, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 334\n",
      "Loss: tensor(0.1299, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 335\n",
      "Loss: tensor(0.1299, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 336\n",
      "Loss: tensor(0.1299, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 337\n",
      "Loss: tensor(0.1299, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 338\n",
      "Loss: tensor(0.1299, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 339\n",
      "Loss: tensor(0.1299, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 340\n",
      "Loss: tensor(0.1299, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 341\n",
      "Loss: tensor(0.1298, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 342\n",
      "Loss: tensor(0.1298, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 343\n",
      "Loss: tensor(0.1298, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 344\n",
      "Loss: tensor(0.1298, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 345\n",
      "Loss: tensor(0.1298, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 346\n",
      "Loss: tensor(0.1298, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 347\n",
      "Loss: tensor(0.1298, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 348\n",
      "Loss: tensor(0.1298, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 349\n",
      "Loss: tensor(0.1298, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 350\n",
      "Loss: tensor(0.1298, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 351\n",
      "Loss: tensor(0.1298, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 352\n",
      "Loss: tensor(0.1298, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 353\n",
      "Loss: tensor(0.1298, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 354\n",
      "Loss: tensor(0.1298, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 355\n",
      "Loss: tensor(0.1298, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 356\n",
      "Loss: tensor(0.1298, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 357\n",
      "Loss: tensor(0.1298, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 358\n",
      "Loss: tensor(0.1298, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 359\n",
      "Loss: tensor(0.1298, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 360\n",
      "Loss: tensor(0.1297, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 361\n",
      "Loss: tensor(0.1297, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 362\n",
      "Loss: tensor(0.1297, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 363\n",
      "Loss: tensor(0.1297, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 364\n",
      "Loss: tensor(0.1297, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 365\n",
      "Loss: tensor(0.1297, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 366\n",
      "Loss: tensor(0.1297, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 367\n",
      "Loss: tensor(0.1297, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 368\n",
      "Loss: tensor(0.1297, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 369\n",
      "Loss: tensor(0.1297, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 370\n",
      "Loss: tensor(0.1297, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 371\n",
      "Loss: tensor(0.1297, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 372\n",
      "Loss: tensor(0.1297, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 373\n",
      "Loss: tensor(0.1297, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 374\n",
      "Loss: tensor(0.1297, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 375\n",
      "Loss: tensor(0.1297, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 376\n",
      "Loss: tensor(0.1297, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 377\n",
      "Loss: tensor(0.1297, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 378\n",
      "Loss: tensor(0.1297, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 379\n",
      "Loss: tensor(0.1297, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 380\n",
      "Loss: tensor(0.1296, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 381\n",
      "Loss: tensor(0.1296, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 382\n",
      "Loss: tensor(0.1296, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 383\n",
      "Loss: tensor(0.1296, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 384\n",
      "Loss: tensor(0.1296, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 385\n",
      "Loss: tensor(0.1296, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 386\n",
      "Loss: tensor(0.1296, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 387\n",
      "Loss: tensor(0.1296, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 388\n",
      "Loss: tensor(0.1296, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 389\n",
      "Loss: tensor(0.1296, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 390\n",
      "Loss: tensor(0.1296, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 391\n",
      "Loss: tensor(0.1296, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 392\n",
      "Loss: tensor(0.1296, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 393\n",
      "Loss: tensor(0.1296, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 394\n",
      "Loss: tensor(0.1296, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 395\n",
      "Loss: tensor(0.1296, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 396\n",
      "Loss: tensor(0.1296, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 397\n",
      "Loss: tensor(0.1296, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 398\n",
      "Loss: tensor(0.1296, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 399\n",
      "Loss: tensor(0.1296, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 400\n",
      "Loss: tensor(0.1296, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 401\n",
      "Loss: tensor(0.1296, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 402\n",
      "Loss: tensor(0.1295, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 403\n",
      "Loss: tensor(0.1295, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 404\n",
      "Loss: tensor(0.1295, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 405\n",
      "Loss: tensor(0.1295, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 406\n",
      "Loss: tensor(0.1295, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 407\n",
      "Loss: tensor(0.1295, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 408\n",
      "Loss: tensor(0.1295, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 409\n",
      "Loss: tensor(0.1295, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 410\n",
      "Loss: tensor(0.1295, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 411\n",
      "Loss: tensor(0.1295, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 412\n",
      "Loss: tensor(0.1295, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 413\n",
      "Loss: tensor(0.1295, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 414\n",
      "Loss: tensor(0.1295, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 415\n",
      "Loss: tensor(0.1295, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 416\n",
      "Loss: tensor(0.1295, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 417\n",
      "Loss: tensor(0.1295, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 418\n",
      "Loss: tensor(0.1295, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 419\n",
      "Loss: tensor(0.1295, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 420\n",
      "Loss: tensor(0.1295, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 421\n",
      "Loss: tensor(0.1295, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 422\n",
      "Loss: tensor(0.1295, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 423\n",
      "Loss: tensor(0.1295, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 424\n",
      "Loss: tensor(0.1295, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 425\n",
      "Loss: tensor(0.1294, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 426\n",
      "Loss: tensor(0.1294, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 427\n",
      "Loss: tensor(0.1294, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 428\n",
      "Loss: tensor(0.1294, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 429\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor(0.1294, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 430\n",
      "Loss: tensor(0.1294, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 431\n",
      "Loss: tensor(0.1294, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 432\n",
      "Loss: tensor(0.1294, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 433\n",
      "Loss: tensor(0.1294, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 434\n",
      "Loss: tensor(0.1294, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 435\n",
      "Loss: tensor(0.1294, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 436\n",
      "Loss: tensor(0.1294, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 437\n",
      "Loss: tensor(0.1294, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 438\n",
      "Loss: tensor(0.1294, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 439\n",
      "Loss: tensor(0.1294, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 440\n",
      "Loss: tensor(0.1294, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 441\n",
      "Loss: tensor(0.1294, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 442\n",
      "Loss: tensor(0.1294, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 443\n",
      "Loss: tensor(0.1294, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 444\n",
      "Loss: tensor(0.1294, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 445\n",
      "Loss: tensor(0.1294, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 446\n",
      "Loss: tensor(0.1294, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 447\n",
      "Loss: tensor(0.1294, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 448\n",
      "Loss: tensor(0.1294, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 449\n",
      "Loss: tensor(0.1293, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 450\n",
      "Loss: tensor(0.1293, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 451\n",
      "Loss: tensor(0.1293, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 452\n",
      "Loss: tensor(0.1293, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 453\n",
      "Loss: tensor(0.1293, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 454\n",
      "Loss: tensor(0.1293, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 455\n",
      "Loss: tensor(0.1293, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 456\n",
      "Loss: tensor(0.1293, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 457\n",
      "Loss: tensor(0.1293, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 458\n",
      "Loss: tensor(0.1293, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 459\n",
      "Loss: tensor(0.1293, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 460\n",
      "Loss: tensor(0.1293, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 461\n",
      "Loss: tensor(0.1293, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 462\n",
      "Loss: tensor(0.1293, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 463\n",
      "Loss: tensor(0.1293, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 464\n",
      "Loss: tensor(0.1293, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 465\n",
      "Loss: tensor(0.1293, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 466\n",
      "Loss: tensor(0.1293, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 467\n",
      "Loss: tensor(0.1293, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 468\n",
      "Loss: tensor(0.1293, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 469\n",
      "Loss: tensor(0.1293, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 470\n",
      "Loss: tensor(0.1293, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 471\n",
      "Loss: tensor(0.1293, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 472\n",
      "Loss: tensor(0.1293, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 473\n",
      "Loss: tensor(0.1293, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 474\n",
      "Loss: tensor(0.1293, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 475\n",
      "Loss: tensor(0.1293, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 476\n",
      "Loss: tensor(0.1292, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 477\n",
      "Loss: tensor(0.1292, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 478\n",
      "Loss: tensor(0.1292, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 479\n",
      "Loss: tensor(0.1292, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 480\n",
      "Loss: tensor(0.1292, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 481\n",
      "Loss: tensor(0.1292, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 482\n",
      "Loss: tensor(0.1292, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 483\n",
      "Loss: tensor(0.1292, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 484\n",
      "Loss: tensor(0.1292, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 485\n",
      "Loss: tensor(0.1292, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 486\n",
      "Loss: tensor(0.1292, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 487\n",
      "Loss: tensor(0.1292, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 488\n",
      "Loss: tensor(0.1292, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 489\n",
      "Loss: tensor(0.1292, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 490\n",
      "Loss: tensor(0.1292, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 491\n",
      "Loss: tensor(0.1292, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 492\n",
      "Loss: tensor(0.1292, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 493\n",
      "Loss: tensor(0.1292, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 494\n",
      "Loss: tensor(0.1292, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 495\n",
      "Loss: tensor(0.1292, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 496\n",
      "Loss: tensor(0.1292, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 497\n",
      "Loss: tensor(0.1292, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 498\n",
      "Loss: tensor(0.1292, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 499\n",
      "Loss: tensor(0.1292, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 500\n",
      "Loss: tensor(0.1292, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 501\n",
      "Loss: tensor(0.1292, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 502\n",
      "Loss: tensor(0.1292, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 503\n",
      "Loss: tensor(0.1292, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 504\n",
      "Loss: tensor(0.1292, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 505\n",
      "Loss: tensor(0.1291, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 506\n",
      "Loss: tensor(0.1291, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 507\n",
      "Loss: tensor(0.1291, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 508\n",
      "Loss: tensor(0.1291, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 509\n",
      "Loss: tensor(0.1291, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 510\n",
      "Loss: tensor(0.1291, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 511\n",
      "Loss: tensor(0.1291, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 512\n",
      "Loss: tensor(0.1291, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 513\n",
      "Loss: tensor(0.1291, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 514\n",
      "Loss: tensor(0.1291, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 515\n",
      "Loss: tensor(0.1291, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 516\n",
      "Loss: tensor(0.1291, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 517\n",
      "Loss: tensor(0.1291, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 518\n",
      "Loss: tensor(0.1291, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 519\n",
      "Loss: tensor(0.1291, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 520\n",
      "Loss: tensor(0.1291, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 521\n",
      "Loss: tensor(0.1291, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 522\n",
      "Loss: tensor(0.1291, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 523\n",
      "Loss: tensor(0.1291, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 524\n",
      "Loss: tensor(0.1291, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 525\n",
      "Loss: tensor(0.1291, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 526\n",
      "Loss: tensor(0.1291, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 527\n",
      "Loss: tensor(0.1291, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 528\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor(0.1291, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 529\n",
      "Loss: tensor(0.1291, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 530\n",
      "Loss: tensor(0.1291, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 531\n",
      "Loss: tensor(0.1291, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 532\n",
      "Loss: tensor(0.1291, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 533\n",
      "Loss: tensor(0.1291, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 534\n",
      "Loss: tensor(0.1291, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 535\n",
      "Loss: tensor(0.1290, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 536\n",
      "Loss: tensor(0.1290, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 537\n",
      "Loss: tensor(0.1290, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 538\n",
      "Loss: tensor(0.1290, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 539\n",
      "Loss: tensor(0.1290, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 540\n",
      "Loss: tensor(0.1290, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 541\n",
      "Loss: tensor(0.1290, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 542\n",
      "Loss: tensor(0.1290, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 543\n",
      "Loss: tensor(0.1290, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 544\n",
      "Loss: tensor(0.1290, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 545\n",
      "Loss: tensor(0.1290, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 546\n",
      "Loss: tensor(0.1290, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 547\n",
      "Loss: tensor(0.1290, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 548\n",
      "Loss: tensor(0.1290, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 549\n",
      "Loss: tensor(0.1290, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 550\n",
      "Loss: tensor(0.1290, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 551\n",
      "Loss: tensor(0.1290, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 552\n",
      "Loss: tensor(0.1290, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 553\n",
      "Loss: tensor(0.1290, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 554\n",
      "Loss: tensor(0.1290, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 555\n",
      "Loss: tensor(0.1290, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 556\n",
      "Loss: tensor(0.1290, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 557\n",
      "Loss: tensor(0.1290, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 558\n",
      "Loss: tensor(0.1290, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 559\n",
      "Loss: tensor(0.1290, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 560\n",
      "Loss: tensor(0.1290, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 561\n",
      "Loss: tensor(0.1290, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 562\n",
      "Loss: tensor(0.1290, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 563\n",
      "Loss: tensor(0.1290, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 564\n",
      "Loss: tensor(0.1290, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 565\n",
      "Loss: tensor(0.1290, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 566\n",
      "Loss: tensor(0.1290, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 567\n",
      "Loss: tensor(0.1290, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 568\n",
      "Loss: tensor(0.1289, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 569\n",
      "Loss: tensor(0.1289, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 570\n",
      "Loss: tensor(0.1289, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 571\n",
      "Loss: tensor(0.1289, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 572\n",
      "Loss: tensor(0.1289, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 573\n",
      "Loss: tensor(0.1289, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 574\n",
      "Loss: tensor(0.1289, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 575\n",
      "Loss: tensor(0.1289, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 576\n",
      "Loss: tensor(0.1289, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 577\n",
      "Loss: tensor(0.1289, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 578\n",
      "Loss: tensor(0.1289, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 579\n",
      "Loss: tensor(0.1289, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 580\n",
      "Loss: tensor(0.1289, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 581\n",
      "Loss: tensor(0.1289, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 582\n",
      "Loss: tensor(0.1289, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 583\n",
      "Loss: tensor(0.1289, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 584\n",
      "Loss: tensor(0.1289, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 585\n",
      "Loss: tensor(0.1289, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 586\n",
      "Loss: tensor(0.1289, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 587\n",
      "Loss: tensor(0.1289, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 588\n",
      "Loss: tensor(0.1289, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 589\n",
      "Loss: tensor(0.1289, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 590\n",
      "Loss: tensor(0.1289, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 591\n",
      "Loss: tensor(0.1289, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 592\n",
      "Loss: tensor(0.1289, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 593\n",
      "Loss: tensor(0.1289, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 594\n",
      "Loss: tensor(0.1289, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 595\n",
      "Loss: tensor(0.1289, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 596\n",
      "Loss: tensor(0.1289, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 597\n",
      "Loss: tensor(0.1289, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 598\n",
      "Loss: tensor(0.1289, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 599\n",
      "Loss: tensor(0.1289, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 600\n",
      "Loss: tensor(0.1289, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 601\n",
      "Loss: tensor(0.1288, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 602\n",
      "Loss: tensor(0.1288, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 603\n",
      "Loss: tensor(0.1288, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 604\n",
      "Loss: tensor(0.1288, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 605\n",
      "Loss: tensor(0.1288, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 606\n",
      "Loss: tensor(0.1288, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 607\n",
      "Loss: tensor(0.1288, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 608\n",
      "Loss: tensor(0.1288, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 609\n",
      "Loss: tensor(0.1288, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 610\n",
      "Loss: tensor(0.1288, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 611\n",
      "Loss: tensor(0.1288, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 612\n",
      "Loss: tensor(0.1288, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 613\n",
      "Loss: tensor(0.1288, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 614\n",
      "Loss: tensor(0.1288, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 615\n",
      "Loss: tensor(0.1288, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 616\n",
      "Loss: tensor(0.1288, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 617\n",
      "Loss: tensor(0.1288, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 618\n",
      "Loss: tensor(0.1288, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 619\n",
      "Loss: tensor(0.1288, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 620\n",
      "Loss: tensor(0.1288, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 621\n",
      "Loss: tensor(0.1288, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 622\n",
      "Loss: tensor(0.1288, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 623\n",
      "Loss: tensor(0.1288, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 624\n",
      "Loss: tensor(0.1288, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 625\n",
      "Loss: tensor(0.1288, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 626\n",
      "Loss: tensor(0.1288, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 627\n",
      "Loss: tensor(0.1288, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 628\n",
      "Loss: tensor(0.1288, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 629\n",
      "Loss: tensor(0.1288, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 630\n",
      "Loss: tensor(0.1288, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 631\n",
      "Loss: tensor(0.1288, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 632\n",
      "Loss: tensor(0.1288, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 633\n",
      "Loss: tensor(0.1288, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 634\n",
      "Loss: tensor(0.1288, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 635\n",
      "Loss: tensor(0.1287, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 636\n",
      "Loss: tensor(0.1287, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 637\n",
      "Loss: tensor(0.1287, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 638\n",
      "Loss: tensor(0.1287, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 639\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor(0.1287, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 640\n",
      "Loss: tensor(0.1287, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 641\n",
      "Loss: tensor(0.1287, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 642\n",
      "Loss: tensor(0.1287, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 643\n",
      "Loss: tensor(0.1287, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 644\n",
      "Loss: tensor(0.1287, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 645\n",
      "Loss: tensor(0.1287, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 646\n",
      "Loss: tensor(0.1287, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 647\n",
      "Loss: tensor(0.1287, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 648\n",
      "Loss: tensor(0.1287, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 649\n",
      "Loss: tensor(0.1287, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 650\n",
      "Loss: tensor(0.1287, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 651\n",
      "Loss: tensor(0.1287, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 652\n",
      "Loss: tensor(0.1287, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 653\n",
      "Loss: tensor(0.1287, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 654\n",
      "Loss: tensor(0.1287, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 655\n",
      "Loss: tensor(0.1287, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 656\n",
      "Loss: tensor(0.1287, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 657\n",
      "Loss: tensor(0.1287, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 658\n",
      "Loss: tensor(0.1287, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 659\n",
      "Loss: tensor(0.1287, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 660\n",
      "Loss: tensor(0.1287, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 661\n",
      "Loss: tensor(0.1287, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 662\n",
      "Loss: tensor(0.1287, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 663\n",
      "Loss: tensor(0.1287, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 664\n",
      "Loss: tensor(0.1287, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 665\n",
      "Loss: tensor(0.1287, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 666\n",
      "Loss: tensor(0.1287, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 667\n",
      "Loss: tensor(0.1287, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 668\n",
      "Loss: tensor(0.1287, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 669\n",
      "Loss: tensor(0.1287, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 670\n",
      "Loss: tensor(0.1286, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 671\n",
      "Loss: tensor(0.1286, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 672\n",
      "Loss: tensor(0.1286, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 673\n",
      "Loss: tensor(0.1286, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 674\n",
      "Loss: tensor(0.1286, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 675\n",
      "Loss: tensor(0.1286, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 676\n",
      "Loss: tensor(0.1286, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 677\n",
      "Loss: tensor(0.1286, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 678\n",
      "Loss: tensor(0.1286, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 679\n",
      "Loss: tensor(0.1286, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 680\n",
      "Loss: tensor(0.1286, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 681\n",
      "Loss: tensor(0.1286, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 682\n",
      "Loss: tensor(0.1286, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 683\n",
      "Loss: tensor(0.1286, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 684\n",
      "Loss: tensor(0.1286, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 685\n",
      "Loss: tensor(0.1286, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 686\n",
      "Loss: tensor(0.1286, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 687\n",
      "Loss: tensor(0.1286, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 688\n",
      "Loss: tensor(0.1286, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 689\n",
      "Loss: tensor(0.1286, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 690\n",
      "Loss: tensor(0.1286, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 691\n",
      "Loss: tensor(0.1286, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 692\n",
      "Loss: tensor(0.1286, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 693\n",
      "Loss: tensor(0.1286, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 694\n",
      "Loss: tensor(0.1286, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 695\n",
      "Loss: tensor(0.1286, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 696\n",
      "Loss: tensor(0.1286, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 697\n",
      "Loss: tensor(0.1286, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 698\n",
      "Loss: tensor(0.1286, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 699\n",
      "Loss: tensor(0.1286, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 700\n",
      "Loss: tensor(0.1286, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 701\n",
      "Loss: tensor(0.1286, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 702\n",
      "Loss: tensor(0.1286, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 703\n",
      "Loss: tensor(0.1286, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 704\n",
      "Loss: tensor(0.1286, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 705\n",
      "Loss: tensor(0.1286, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 706\n",
      "Loss: tensor(0.1285, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 707\n",
      "Loss: tensor(0.1285, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 708\n",
      "Loss: tensor(0.1285, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 709\n",
      "Loss: tensor(0.1285, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 710\n",
      "Loss: tensor(0.1285, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 711\n",
      "Loss: tensor(0.1285, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 712\n",
      "Loss: tensor(0.1285, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 713\n",
      "Loss: tensor(0.1285, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 714\n",
      "Loss: tensor(0.1285, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 715\n",
      "Loss: tensor(0.1285, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 716\n",
      "Loss: tensor(0.1285, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 717\n",
      "Loss: tensor(0.1285, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 718\n",
      "Loss: tensor(0.1285, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 719\n",
      "Loss: tensor(0.1285, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 720\n",
      "Loss: tensor(0.1285, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 721\n",
      "Loss: tensor(0.1285, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 722\n",
      "Loss: tensor(0.1285, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 723\n",
      "Loss: tensor(0.1285, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 724\n",
      "Loss: tensor(0.1285, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 725\n",
      "Loss: tensor(0.1285, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 726\n",
      "Loss: tensor(0.1285, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 727\n",
      "Loss: tensor(0.1285, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 728\n",
      "Loss: tensor(0.1285, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 729\n",
      "Loss: tensor(0.1285, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 730\n",
      "Loss: tensor(0.1285, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 731\n",
      "Loss: tensor(0.1285, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 732\n",
      "Loss: tensor(0.1285, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 733\n",
      "Loss: tensor(0.1285, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 734\n",
      "Loss: tensor(0.1285, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 735\n",
      "Loss: tensor(0.1285, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 736\n",
      "Loss: tensor(0.1285, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 737\n",
      "Loss: tensor(0.1285, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 738\n",
      "Loss: tensor(0.1285, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 739\n",
      "Loss: tensor(0.1285, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 740\n",
      "Loss: tensor(0.1285, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 741\n",
      "Loss: tensor(0.1285, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 742\n",
      "Loss: tensor(0.1284, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 743\n",
      "Loss: tensor(0.1284, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 744\n",
      "Loss: tensor(0.1284, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 745\n",
      "Loss: tensor(0.1284, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 746\n",
      "Loss: tensor(0.1284, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 747\n",
      "Loss: tensor(0.1284, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 748\n",
      "Loss: tensor(0.1284, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 749\n",
      "Loss: tensor(0.1284, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 750\n",
      "Loss: tensor(0.1284, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 751\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor(0.1284, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 752\n",
      "Loss: tensor(0.1284, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 753\n",
      "Loss: tensor(0.1284, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 754\n",
      "Loss: tensor(0.1284, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 755\n",
      "Loss: tensor(0.1284, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 756\n",
      "Loss: tensor(0.1284, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 757\n",
      "Loss: tensor(0.1284, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 758\n",
      "Loss: tensor(0.1284, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 759\n",
      "Loss: tensor(0.1284, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 760\n",
      "Loss: tensor(0.1284, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 761\n",
      "Loss: tensor(0.1284, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 762\n",
      "Loss: tensor(0.1284, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 763\n",
      "Loss: tensor(0.1284, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 764\n",
      "Loss: tensor(0.1284, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 765\n",
      "Loss: tensor(0.1284, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 766\n",
      "Loss: tensor(0.1284, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 767\n",
      "Loss: tensor(0.1284, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 768\n",
      "Loss: tensor(0.1284, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 769\n",
      "Loss: tensor(0.1284, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 770\n",
      "Loss: tensor(0.1284, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 771\n",
      "Loss: tensor(0.1284, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 772\n",
      "Loss: tensor(0.1284, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 773\n",
      "Loss: tensor(0.1284, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 774\n",
      "Loss: tensor(0.1284, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 775\n",
      "Loss: tensor(0.1284, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 776\n",
      "Loss: tensor(0.1284, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 777\n",
      "Loss: tensor(0.1284, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 778\n",
      "Loss: tensor(0.1284, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 779\n",
      "Loss: tensor(0.1283, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 780\n",
      "Loss: tensor(0.1283, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 781\n",
      "Loss: tensor(0.1283, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 782\n",
      "Loss: tensor(0.1283, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 783\n",
      "Loss: tensor(0.1283, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 784\n",
      "Loss: tensor(0.1283, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 785\n",
      "Loss: tensor(0.1283, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 786\n",
      "Loss: tensor(0.1283, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 787\n",
      "Loss: tensor(0.1283, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 788\n",
      "Loss: tensor(0.1283, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 789\n",
      "Loss: tensor(0.1283, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 790\n",
      "Loss: tensor(0.1283, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 791\n",
      "Loss: tensor(0.1283, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 792\n",
      "Loss: tensor(0.1283, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 793\n",
      "Loss: tensor(0.1283, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 794\n",
      "Loss: tensor(0.1283, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 795\n",
      "Loss: tensor(0.1283, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 796\n",
      "Loss: tensor(0.1283, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 797\n",
      "Loss: tensor(0.1283, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 798\n",
      "Loss: tensor(0.1283, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 799\n",
      "Loss: tensor(0.1283, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 800\n",
      "Loss: tensor(0.1283, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 801\n",
      "Loss: tensor(0.1283, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 802\n",
      "Loss: tensor(0.1283, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 803\n",
      "Loss: tensor(0.1283, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 804\n",
      "Loss: tensor(0.1283, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 805\n",
      "Loss: tensor(0.1283, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 806\n",
      "Loss: tensor(0.1283, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 807\n",
      "Loss: tensor(0.1283, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 808\n",
      "Loss: tensor(0.1283, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 809\n",
      "Loss: tensor(0.1283, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 810\n",
      "Loss: tensor(0.1283, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 811\n",
      "Loss: tensor(0.1283, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 812\n",
      "Loss: tensor(0.1283, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 813\n",
      "Loss: tensor(0.1283, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 814\n",
      "Loss: tensor(0.1283, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 815\n",
      "Loss: tensor(0.1283, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 816\n",
      "Loss: tensor(0.1283, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 817\n",
      "Loss: tensor(0.1282, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 818\n",
      "Loss: tensor(0.1282, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 819\n",
      "Loss: tensor(0.1282, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 820\n",
      "Loss: tensor(0.1282, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 821\n",
      "Loss: tensor(0.1282, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 822\n",
      "Loss: tensor(0.1282, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 823\n",
      "Loss: tensor(0.1282, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 824\n",
      "Loss: tensor(0.1282, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 825\n",
      "Loss: tensor(0.1282, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 826\n",
      "Loss: tensor(0.1282, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 827\n",
      "Loss: tensor(0.1282, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 828\n",
      "Loss: tensor(0.1282, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 829\n",
      "Loss: tensor(0.1282, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 830\n",
      "Loss: tensor(0.1282, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 831\n",
      "Loss: tensor(0.1282, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 832\n",
      "Loss: tensor(0.1282, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 833\n",
      "Loss: tensor(0.1282, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 834\n",
      "Loss: tensor(0.1282, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 835\n",
      "Loss: tensor(0.1282, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 836\n",
      "Loss: tensor(0.1282, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 837\n",
      "Loss: tensor(0.1282, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 838\n",
      "Loss: tensor(0.1282, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 839\n",
      "Loss: tensor(0.1282, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 840\n",
      "Loss: tensor(0.1282, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 841\n",
      "Loss: tensor(0.1282, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 842\n",
      "Loss: tensor(0.1282, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 843\n",
      "Loss: tensor(0.1282, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 844\n",
      "Loss: tensor(0.1282, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 845\n",
      "Loss: tensor(0.1282, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 846\n",
      "Loss: tensor(0.1282, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 847\n",
      "Loss: tensor(0.1282, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 848\n",
      "Loss: tensor(0.1282, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 849\n",
      "Loss: tensor(0.1282, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 850\n",
      "Loss: tensor(0.1282, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 851\n",
      "Loss: tensor(0.1282, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 852\n",
      "Loss: tensor(0.1282, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 853\n",
      "Loss: tensor(0.1282, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 854\n",
      "Loss: tensor(0.1282, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 855\n",
      "Loss: tensor(0.1282, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 856\n",
      "Loss: tensor(0.1281, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 857\n",
      "Loss: tensor(0.1281, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 858\n",
      "Loss: tensor(0.1281, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 859\n",
      "Loss: tensor(0.1281, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 860\n",
      "Loss: tensor(0.1281, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 861\n",
      "Loss: tensor(0.1281, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 862\n",
      "Loss: tensor(0.1281, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 863\n",
      "Loss: tensor(0.1281, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 864\n",
      "Loss: tensor(0.1281, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 865\n",
      "Loss: tensor(0.1281, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 866\n",
      "Loss: tensor(0.1281, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 867\n",
      "Loss: tensor(0.1281, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 868\n",
      "Loss: tensor(0.1281, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 869\n",
      "Loss: tensor(0.1281, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 870\n",
      "Loss: tensor(0.1281, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 871\n",
      "Loss: tensor(0.1281, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 872\n",
      "Loss: tensor(0.1281, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 873\n",
      "Loss: tensor(0.1281, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 874\n",
      "Loss: tensor(0.1281, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 875\n",
      "Loss: tensor(0.1281, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 876\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor(0.1281, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 877\n",
      "Loss: tensor(0.1281, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 878\n",
      "Loss: tensor(0.1281, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 879\n",
      "Loss: tensor(0.1281, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 880\n",
      "Loss: tensor(0.1281, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 881\n",
      "Loss: tensor(0.1281, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 882\n",
      "Loss: tensor(0.1281, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 883\n",
      "Loss: tensor(0.1281, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 884\n",
      "Loss: tensor(0.1281, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 885\n",
      "Loss: tensor(0.1281, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 886\n",
      "Loss: tensor(0.1281, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 887\n",
      "Loss: tensor(0.1281, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 888\n",
      "Loss: tensor(0.1281, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 889\n",
      "Loss: tensor(0.1281, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 890\n",
      "Loss: tensor(0.1281, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 891\n",
      "Loss: tensor(0.1281, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 892\n",
      "Loss: tensor(0.1281, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 893\n",
      "Loss: tensor(0.1281, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 894\n",
      "Loss: tensor(0.1281, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 895\n",
      "Loss: tensor(0.1281, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 896\n",
      "Loss: tensor(0.1281, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 897\n",
      "Loss: tensor(0.1280, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 898\n",
      "Loss: tensor(0.1280, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 899\n",
      "Loss: tensor(0.1280, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 900\n",
      "Loss: tensor(0.1280, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 901\n",
      "Loss: tensor(0.1280, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 902\n",
      "Loss: tensor(0.1280, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 903\n",
      "Loss: tensor(0.1280, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 904\n",
      "Loss: tensor(0.1280, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 905\n",
      "Loss: tensor(0.1280, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 906\n",
      "Loss: tensor(0.1280, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 907\n",
      "Loss: tensor(0.1280, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 908\n",
      "Loss: tensor(0.1280, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 909\n",
      "Loss: tensor(0.1280, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 910\n",
      "Loss: tensor(0.1280, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 911\n",
      "Loss: tensor(0.1280, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 912\n",
      "Loss: tensor(0.1280, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 913\n",
      "Loss: tensor(0.1280, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 914\n",
      "Loss: tensor(0.1280, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 915\n",
      "Loss: tensor(0.1280, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 916\n",
      "Loss: tensor(0.1280, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 917\n",
      "Loss: tensor(0.1280, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 918\n",
      "Loss: tensor(0.1280, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 919\n",
      "Loss: tensor(0.1280, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 920\n",
      "Loss: tensor(0.1280, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 921\n",
      "Loss: tensor(0.1280, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 922\n",
      "Loss: tensor(0.1280, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 923\n",
      "Loss: tensor(0.1280, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 924\n",
      "Loss: tensor(0.1280, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 925\n",
      "Loss: tensor(0.1280, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 926\n",
      "Loss: tensor(0.1280, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 927\n",
      "Loss: tensor(0.1280, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 928\n",
      "Loss: tensor(0.1280, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 929\n",
      "Loss: tensor(0.1280, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 930\n",
      "Loss: tensor(0.1280, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 931\n",
      "Loss: tensor(0.1280, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 932\n",
      "Loss: tensor(0.1280, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 933\n",
      "Loss: tensor(0.1280, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 934\n",
      "Loss: tensor(0.1280, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 935\n",
      "Loss: tensor(0.1280, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 936\n",
      "Loss: tensor(0.1280, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 937\n",
      "Loss: tensor(0.1279, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 938\n",
      "Loss: tensor(0.1279, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 939\n",
      "Loss: tensor(0.1279, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 940\n",
      "Loss: tensor(0.1279, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 941\n",
      "Loss: tensor(0.1279, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 942\n",
      "Loss: tensor(0.1279, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 943\n",
      "Loss: tensor(0.1279, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 944\n",
      "Loss: tensor(0.1279, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 945\n",
      "Loss: tensor(0.1279, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 946\n",
      "Loss: tensor(0.1279, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 947\n",
      "Loss: tensor(0.1279, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 948\n",
      "Loss: tensor(0.1279, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 949\n",
      "Loss: tensor(0.1279, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 950\n",
      "Loss: tensor(0.1279, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 951\n",
      "Loss: tensor(0.1279, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 952\n",
      "Loss: tensor(0.1279, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 953\n",
      "Loss: tensor(0.1279, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 954\n",
      "Loss: tensor(0.1279, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 955\n",
      "Loss: tensor(0.1279, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 956\n",
      "Loss: tensor(0.1279, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 957\n",
      "Loss: tensor(0.1279, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 958\n",
      "Loss: tensor(0.1279, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 959\n",
      "Loss: tensor(0.1279, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 960\n",
      "Loss: tensor(0.1279, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 961\n",
      "Loss: tensor(0.1279, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 962\n",
      "Loss: tensor(0.1279, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 963\n",
      "Loss: tensor(0.1279, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 964\n",
      "Loss: tensor(0.1279, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 965\n",
      "Loss: tensor(0.1279, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 966\n",
      "Loss: tensor(0.1279, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 967\n",
      "Loss: tensor(0.1279, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 968\n",
      "Loss: tensor(0.1279, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 969\n",
      "Loss: tensor(0.1279, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 970\n",
      "Loss: tensor(0.1279, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 971\n",
      "Loss: tensor(0.1279, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 972\n",
      "Loss: tensor(0.1279, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 973\n",
      "Loss: tensor(0.1279, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 974\n",
      "Loss: tensor(0.1279, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 975\n",
      "Loss: tensor(0.1279, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 976\n",
      "Loss: tensor(0.1279, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 977\n",
      "Loss: tensor(0.1279, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 978\n",
      "Loss: tensor(0.1278, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 979\n",
      "Loss: tensor(0.1278, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 980\n",
      "Loss: tensor(0.1278, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 981\n",
      "Loss: tensor(0.1278, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 982\n",
      "Loss: tensor(0.1278, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 983\n",
      "Loss: tensor(0.1278, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 984\n",
      "Loss: tensor(0.1278, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 985\n",
      "Loss: tensor(0.1278, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 986\n",
      "Loss: tensor(0.1278, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 987\n",
      "Loss: tensor(0.1278, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 988\n",
      "Loss: tensor(0.1278, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 989\n",
      "Loss: tensor(0.1278, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 990\n",
      "Loss: tensor(0.1278, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 991\n",
      "Loss: tensor(0.1278, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 992\n",
      "Loss: tensor(0.1278, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 993\n",
      "Loss: tensor(0.1278, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 994\n",
      "Loss: tensor(0.1278, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 995\n",
      "Loss: tensor(0.1278, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 996\n",
      "Loss: tensor(0.1278, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 997\n",
      "Loss: tensor(0.1278, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 998\n",
      "Loss: tensor(0.1278, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 999\n",
      "Loss: tensor(0.1278, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1000\n",
      "Loss: tensor(0.1278, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1001\n",
      "Loss: tensor(0.1278, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1002\n",
      "Loss: tensor(0.1278, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1003\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor(0.1278, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1004\n",
      "Loss: tensor(0.1278, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1005\n",
      "Loss: tensor(0.1278, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1006\n",
      "Loss: tensor(0.1278, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1007\n",
      "Loss: tensor(0.1278, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1008\n",
      "Loss: tensor(0.1278, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1009\n",
      "Loss: tensor(0.1278, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1010\n",
      "Loss: tensor(0.1278, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1011\n",
      "Loss: tensor(0.1278, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1012\n",
      "Loss: tensor(0.1278, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1013\n",
      "Loss: tensor(0.1278, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1014\n",
      "Loss: tensor(0.1278, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1015\n",
      "Loss: tensor(0.1278, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1016\n",
      "Loss: tensor(0.1278, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1017\n",
      "Loss: tensor(0.1278, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1018\n",
      "Loss: tensor(0.1278, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1019\n",
      "Loss: tensor(0.1277, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1020\n",
      "Loss: tensor(0.1277, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1021\n",
      "Loss: tensor(0.1277, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1022\n",
      "Loss: tensor(0.1277, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1023\n",
      "Loss: tensor(0.1277, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1024\n",
      "Loss: tensor(0.1277, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1025\n",
      "Loss: tensor(0.1277, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1026\n",
      "Loss: tensor(0.1277, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1027\n",
      "Loss: tensor(0.1277, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1028\n",
      "Loss: tensor(0.1277, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1029\n",
      "Loss: tensor(0.1277, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1030\n",
      "Loss: tensor(0.1277, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1031\n",
      "Loss: tensor(0.1277, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1032\n",
      "Loss: tensor(0.1277, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1033\n",
      "Loss: tensor(0.1277, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1034\n",
      "Loss: tensor(0.1277, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1035\n",
      "Loss: tensor(0.1277, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1036\n",
      "Loss: tensor(0.1277, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1037\n",
      "Loss: tensor(0.1277, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1038\n",
      "Loss: tensor(0.1277, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1039\n",
      "Loss: tensor(0.1277, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1040\n",
      "Loss: tensor(0.1277, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1041\n",
      "Loss: tensor(0.1277, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1042\n",
      "Loss: tensor(0.1277, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1043\n",
      "Loss: tensor(0.1277, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1044\n",
      "Loss: tensor(0.1277, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1045\n",
      "Loss: tensor(0.1277, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1046\n",
      "Loss: tensor(0.1277, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1047\n",
      "Loss: tensor(0.1277, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1048\n",
      "Loss: tensor(0.1277, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1049\n",
      "Loss: tensor(0.1277, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1050\n",
      "Loss: tensor(0.1277, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1051\n",
      "Loss: tensor(0.1277, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1052\n",
      "Loss: tensor(0.1277, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1053\n",
      "Loss: tensor(0.1277, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1054\n",
      "Loss: tensor(0.1277, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1055\n",
      "Loss: tensor(0.1277, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1056\n",
      "Loss: tensor(0.1277, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1057\n",
      "Loss: tensor(0.1277, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1058\n",
      "Loss: tensor(0.1277, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1059\n",
      "Loss: tensor(0.1276, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1060\n",
      "Loss: tensor(0.1276, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1061\n",
      "Loss: tensor(0.1276, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1062\n",
      "Loss: tensor(0.1276, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1063\n",
      "Loss: tensor(0.1276, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1064\n",
      "Loss: tensor(0.1276, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1065\n",
      "Loss: tensor(0.1276, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1066\n",
      "Loss: tensor(0.1276, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1067\n",
      "Loss: tensor(0.1276, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1068\n",
      "Loss: tensor(0.1276, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1069\n",
      "Loss: tensor(0.1276, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1070\n",
      "Loss: tensor(0.1276, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1071\n",
      "Loss: tensor(0.1276, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1072\n",
      "Loss: tensor(0.1276, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1073\n",
      "Loss: tensor(0.1276, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1074\n",
      "Loss: tensor(0.1276, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1075\n",
      "Loss: tensor(0.1276, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1076\n",
      "Loss: tensor(0.1276, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1077\n",
      "Loss: tensor(0.1276, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1078\n",
      "Loss: tensor(0.1276, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1079\n",
      "Loss: tensor(0.1276, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1080\n",
      "Loss: tensor(0.1276, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1081\n",
      "Loss: tensor(0.1276, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1082\n",
      "Loss: tensor(0.1276, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1083\n",
      "Loss: tensor(0.1276, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1084\n",
      "Loss: tensor(0.1276, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1085\n",
      "Loss: tensor(0.1276, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1086\n",
      "Loss: tensor(0.1276, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1087\n",
      "Loss: tensor(0.1276, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1088\n",
      "Loss: tensor(0.1276, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1089\n",
      "Loss: tensor(0.1276, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1090\n",
      "Loss: tensor(0.1276, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1091\n",
      "Loss: tensor(0.1276, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1092\n",
      "Loss: tensor(0.1276, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1093\n",
      "Loss: tensor(0.1276, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1094\n",
      "Loss: tensor(0.1276, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1095\n",
      "Loss: tensor(0.1276, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1096\n",
      "Loss: tensor(0.1276, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1097\n",
      "Loss: tensor(0.1276, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1098\n",
      "Loss: tensor(0.1276, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1099\n",
      "Loss: tensor(0.1275, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1100\n",
      "Loss: tensor(0.1275, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1101\n",
      "Loss: tensor(0.1275, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1102\n",
      "Loss: tensor(0.1275, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1103\n",
      "Loss: tensor(0.1275, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1104\n",
      "Loss: tensor(0.1275, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1105\n",
      "Loss: tensor(0.1275, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1106\n",
      "Loss: tensor(0.1275, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1107\n",
      "Loss: tensor(0.1275, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1108\n",
      "Loss: tensor(0.1275, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1109\n",
      "Loss: tensor(0.1275, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1110\n",
      "Loss: tensor(0.1275, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1111\n",
      "Loss: tensor(0.1275, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1112\n",
      "Loss: tensor(0.1275, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1113\n",
      "Loss: tensor(0.1275, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1114\n",
      "Loss: tensor(0.1275, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1115\n",
      "Loss: tensor(0.1275, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1116\n",
      "Loss: tensor(0.1275, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1117\n",
      "Loss: tensor(0.1275, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1118\n",
      "Loss: tensor(0.1275, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1119\n",
      "Loss: tensor(0.1275, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1120\n",
      "Loss: tensor(0.1275, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1121\n",
      "Loss: tensor(0.1275, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1122\n",
      "Loss: tensor(0.1275, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1123\n",
      "Loss: tensor(0.1275, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1124\n",
      "Loss: tensor(0.1275, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor(0.1275, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1126\n",
      "Loss: tensor(0.1275, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1127\n",
      "Loss: tensor(0.1275, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1128\n",
      "Loss: tensor(0.1275, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1129\n",
      "Loss: tensor(0.1275, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1130\n",
      "Loss: tensor(0.1275, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1131\n",
      "Loss: tensor(0.1275, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1132\n",
      "Loss: tensor(0.1275, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1133\n",
      "Loss: tensor(0.1275, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1134\n",
      "Loss: tensor(0.1275, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1135\n",
      "Loss: tensor(0.1275, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1136\n",
      "Loss: tensor(0.1275, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1137\n",
      "Loss: tensor(0.1275, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1138\n",
      "Loss: tensor(0.1275, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1139\n",
      "Loss: tensor(0.1274, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1140\n",
      "Loss: tensor(0.1274, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1141\n",
      "Loss: tensor(0.1274, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1142\n",
      "Loss: tensor(0.1274, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1143\n",
      "Loss: tensor(0.1274, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1144\n",
      "Loss: tensor(0.1274, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1145\n",
      "Loss: tensor(0.1274, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1146\n",
      "Loss: tensor(0.1274, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1147\n",
      "Loss: tensor(0.1274, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1148\n",
      "Loss: tensor(0.1274, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1149\n",
      "Loss: tensor(0.1274, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1150\n",
      "Loss: tensor(0.1274, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1151\n",
      "Loss: tensor(0.1274, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1152\n",
      "Loss: tensor(0.1274, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1153\n",
      "Loss: tensor(0.1274, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1154\n",
      "Loss: tensor(0.1274, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1155\n",
      "Loss: tensor(0.1274, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1156\n",
      "Loss: tensor(0.1274, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1157\n",
      "Loss: tensor(0.1274, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1158\n",
      "Loss: tensor(0.1274, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1159\n",
      "Loss: tensor(0.1274, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1160\n",
      "Loss: tensor(0.1274, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1161\n",
      "Loss: tensor(0.1274, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1162\n",
      "Loss: tensor(0.1274, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1163\n",
      "Loss: tensor(0.1274, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1164\n",
      "Loss: tensor(0.1274, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1165\n",
      "Loss: tensor(0.1274, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1166\n",
      "Loss: tensor(0.1274, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1167\n",
      "Loss: tensor(0.1274, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1168\n",
      "Loss: tensor(0.1274, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1169\n",
      "Loss: tensor(0.1274, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1170\n",
      "Loss: tensor(0.1274, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1171\n",
      "Loss: tensor(0.1274, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1172\n",
      "Loss: tensor(0.1274, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1173\n",
      "Loss: tensor(0.1274, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1174\n",
      "Loss: tensor(0.1274, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1175\n",
      "Loss: tensor(0.1274, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1176\n",
      "Loss: tensor(0.1274, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1177\n",
      "Loss: tensor(0.1274, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1178\n",
      "Loss: tensor(0.1274, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1179\n",
      "Loss: tensor(0.1273, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1180\n",
      "Loss: tensor(0.1273, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1181\n",
      "Loss: tensor(0.1273, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1182\n",
      "Loss: tensor(0.1273, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1183\n",
      "Loss: tensor(0.1273, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1184\n",
      "Loss: tensor(0.1273, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1185\n",
      "Loss: tensor(0.1273, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1186\n",
      "Loss: tensor(0.1273, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1187\n",
      "Loss: tensor(0.1273, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1188\n",
      "Loss: tensor(0.1273, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1189\n",
      "Loss: tensor(0.1273, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1190\n",
      "Loss: tensor(0.1273, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1191\n",
      "Loss: tensor(0.1273, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1192\n",
      "Loss: tensor(0.1273, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1193\n",
      "Loss: tensor(0.1273, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1194\n",
      "Loss: tensor(0.1273, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1195\n",
      "Loss: tensor(0.1273, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1196\n",
      "Loss: tensor(0.1273, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1197\n",
      "Loss: tensor(0.1273, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1198\n",
      "Loss: tensor(0.1273, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1199\n",
      "Loss: tensor(0.1273, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1200\n",
      "Loss: tensor(0.1273, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1201\n",
      "Loss: tensor(0.1273, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1202\n",
      "Loss: tensor(0.1273, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1203\n",
      "Loss: tensor(0.1273, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1204\n",
      "Loss: tensor(0.1273, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1205\n",
      "Loss: tensor(0.1273, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1206\n",
      "Loss: tensor(0.1273, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1207\n",
      "Loss: tensor(0.1273, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1208\n",
      "Loss: tensor(0.1273, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1209\n",
      "Loss: tensor(0.1273, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1210\n",
      "Loss: tensor(0.1273, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1211\n",
      "Loss: tensor(0.1273, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1212\n",
      "Loss: tensor(0.1273, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1213\n",
      "Loss: tensor(0.1273, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1214\n",
      "Loss: tensor(0.1273, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1215\n",
      "Loss: tensor(0.1273, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1216\n",
      "Loss: tensor(0.1273, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1217\n",
      "Loss: tensor(0.1273, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1218\n",
      "Loss: tensor(0.1273, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1219\n",
      "Loss: tensor(0.1273, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1220\n",
      "Loss: tensor(0.1272, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1221\n",
      "Loss: tensor(0.1272, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1222\n",
      "Loss: tensor(0.1272, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1223\n",
      "Loss: tensor(0.1272, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1224\n",
      "Loss: tensor(0.1272, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1225\n",
      "Loss: tensor(0.1272, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1226\n",
      "Loss: tensor(0.1272, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1227\n",
      "Loss: tensor(0.1272, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1228\n",
      "Loss: tensor(0.1272, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1229\n",
      "Loss: tensor(0.1272, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1230\n",
      "Loss: tensor(0.1272, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1231\n",
      "Loss: tensor(0.1272, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1232\n",
      "Loss: tensor(0.1272, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1233\n",
      "Loss: tensor(0.1272, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1234\n",
      "Loss: tensor(0.1272, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1235\n",
      "Loss: tensor(0.1272, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1236\n",
      "Loss: tensor(0.1272, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1237\n",
      "Loss: tensor(0.1272, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1238\n",
      "Loss: tensor(0.1272, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1239\n",
      "Loss: tensor(0.1272, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1240\n",
      "Loss: tensor(0.1272, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1241\n",
      "Loss: tensor(0.1272, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1242\n",
      "Loss: tensor(0.1272, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1243\n",
      "Loss: tensor(0.1272, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1244\n",
      "Loss: tensor(0.1272, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1245\n",
      "Loss: tensor(0.1272, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1246\n",
      "Loss: tensor(0.1272, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1247\n",
      "Loss: tensor(0.1272, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1248\n",
      "Loss: tensor(0.1272, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1249\n",
      "Loss: tensor(0.1272, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1250\n",
      "Loss: tensor(0.1272, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1251\n",
      "Loss: tensor(0.1272, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1252\n",
      "Loss: tensor(0.1272, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1253\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor(0.1272, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1254\n",
      "Loss: tensor(0.1272, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1255\n",
      "Loss: tensor(0.1272, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1256\n",
      "Loss: tensor(0.1272, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1257\n",
      "Loss: tensor(0.1272, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1258\n",
      "Loss: tensor(0.1272, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1259\n",
      "Loss: tensor(0.1272, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1260\n",
      "Loss: tensor(0.1272, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1261\n",
      "Loss: tensor(0.1272, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1262\n",
      "Loss: tensor(0.1271, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1263\n",
      "Loss: tensor(0.1271, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1264\n",
      "Loss: tensor(0.1271, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1265\n",
      "Loss: tensor(0.1271, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1266\n",
      "Loss: tensor(0.1271, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1267\n",
      "Loss: tensor(0.1271, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1268\n",
      "Loss: tensor(0.1271, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1269\n",
      "Loss: tensor(0.1271, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1270\n",
      "Loss: tensor(0.1271, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1271\n",
      "Loss: tensor(0.1271, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1272\n",
      "Loss: tensor(0.1271, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1273\n",
      "Loss: tensor(0.1271, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1274\n",
      "Loss: tensor(0.1271, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1275\n",
      "Loss: tensor(0.1271, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1276\n",
      "Loss: tensor(0.1271, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1277\n",
      "Loss: tensor(0.1271, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1278\n",
      "Loss: tensor(0.1271, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1279\n",
      "Loss: tensor(0.1271, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1280\n",
      "Loss: tensor(0.1271, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1281\n",
      "Loss: tensor(0.1271, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1282\n",
      "Loss: tensor(0.1271, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1283\n",
      "Loss: tensor(0.1271, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1284\n",
      "Loss: tensor(0.1271, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1285\n",
      "Loss: tensor(0.1271, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1286\n",
      "Loss: tensor(0.1271, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1287\n",
      "Loss: tensor(0.1271, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1288\n",
      "Loss: tensor(0.1271, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1289\n",
      "Loss: tensor(0.1271, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1290\n",
      "Loss: tensor(0.1271, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1291\n",
      "Loss: tensor(0.1271, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1292\n",
      "Loss: tensor(0.1271, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1293\n",
      "Loss: tensor(0.1271, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1294\n",
      "Loss: tensor(0.1271, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1295\n",
      "Loss: tensor(0.1271, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1296\n",
      "Loss: tensor(0.1271, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1297\n",
      "Loss: tensor(0.1271, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1298\n",
      "Loss: tensor(0.1271, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1299\n",
      "Loss: tensor(0.1271, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1300\n",
      "Loss: tensor(0.1271, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1301\n",
      "Loss: tensor(0.1271, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1302\n",
      "Loss: tensor(0.1271, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1303\n",
      "Loss: tensor(0.1271, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1304\n",
      "Loss: tensor(0.1271, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1305\n",
      "Loss: tensor(0.1271, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1306\n",
      "Loss: tensor(0.1270, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1307\n",
      "Loss: tensor(0.1270, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1308\n",
      "Loss: tensor(0.1270, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1309\n",
      "Loss: tensor(0.1270, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1310\n",
      "Loss: tensor(0.1270, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1311\n",
      "Loss: tensor(0.1270, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1312\n",
      "Loss: tensor(0.1270, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1313\n",
      "Loss: tensor(0.1270, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1314\n",
      "Loss: tensor(0.1270, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1315\n",
      "Loss: tensor(0.1270, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1316\n",
      "Loss: tensor(0.1270, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1317\n",
      "Loss: tensor(0.1270, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1318\n",
      "Loss: tensor(0.1270, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1319\n",
      "Loss: tensor(0.1270, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1320\n",
      "Loss: tensor(0.1270, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1321\n",
      "Loss: tensor(0.1270, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1322\n",
      "Loss: tensor(0.1270, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1323\n",
      "Loss: tensor(0.1270, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1324\n",
      "Loss: tensor(0.1270, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1325\n",
      "Loss: tensor(0.1270, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1326\n",
      "Loss: tensor(0.1270, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1327\n",
      "Loss: tensor(0.1270, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1328\n",
      "Loss: tensor(0.1270, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1329\n",
      "Loss: tensor(0.1270, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1330\n",
      "Loss: tensor(0.1270, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1331\n",
      "Loss: tensor(0.1270, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1332\n",
      "Loss: tensor(0.1270, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1333\n",
      "Loss: tensor(0.1270, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1334\n",
      "Loss: tensor(0.1270, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1335\n",
      "Loss: tensor(0.1270, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1336\n",
      "Loss: tensor(0.1270, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1337\n",
      "Loss: tensor(0.1270, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1338\n",
      "Loss: tensor(0.1270, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1339\n",
      "Loss: tensor(0.1270, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1340\n",
      "Loss: tensor(0.1270, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1341\n",
      "Loss: tensor(0.1270, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1342\n",
      "Loss: tensor(0.1270, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1343\n",
      "Loss: tensor(0.1270, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1344\n",
      "Loss: tensor(0.1270, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1345\n",
      "Loss: tensor(0.1270, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1346\n",
      "Loss: tensor(0.1270, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1347\n",
      "Loss: tensor(0.1270, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1348\n",
      "Loss: tensor(0.1270, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1349\n",
      "Loss: tensor(0.1270, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1350\n",
      "Loss: tensor(0.1270, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1351\n",
      "Loss: tensor(0.1270, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1352\n",
      "Loss: tensor(0.1270, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1353\n",
      "Loss: tensor(0.1269, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1354\n",
      "Loss: tensor(0.1269, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1355\n",
      "Loss: tensor(0.1269, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1356\n",
      "Loss: tensor(0.1269, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1357\n",
      "Loss: tensor(0.1269, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1358\n",
      "Loss: tensor(0.1269, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1359\n",
      "Loss: tensor(0.1269, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1360\n",
      "Loss: tensor(0.1269, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1361\n",
      "Loss: tensor(0.1269, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1362\n",
      "Loss: tensor(0.1269, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1363\n",
      "Loss: tensor(0.1269, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1364\n",
      "Loss: tensor(0.1269, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1365\n",
      "Loss: tensor(0.1269, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1366\n",
      "Loss: tensor(0.1269, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1367\n",
      "Loss: tensor(0.1269, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1368\n",
      "Loss: tensor(0.1269, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1369\n",
      "Loss: tensor(0.1269, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1370\n",
      "Loss: tensor(0.1269, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1371\n",
      "Loss: tensor(0.1269, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1372\n",
      "Loss: tensor(0.1269, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1373\n",
      "Loss: tensor(0.1269, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1374\n",
      "Loss: tensor(0.1269, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1375\n",
      "Loss: tensor(0.1269, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1376\n",
      "Loss: tensor(0.1269, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1377\n",
      "Loss: tensor(0.1269, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1378\n",
      "Loss: tensor(0.1269, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1379\n",
      "Loss: tensor(0.1269, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1380\n",
      "Loss: tensor(0.1269, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1381\n",
      "Loss: tensor(0.1269, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1382\n",
      "Loss: tensor(0.1269, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1383\n",
      "Loss: tensor(0.1269, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1384\n",
      "Loss: tensor(0.1269, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1385\n",
      "Loss: tensor(0.1269, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1386\n",
      "Loss: tensor(0.1269, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1387\n",
      "Loss: tensor(0.1269, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1388\n",
      "Loss: tensor(0.1269, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1389\n",
      "Loss: tensor(0.1269, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1390\n",
      "Loss: tensor(0.1269, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1391\n",
      "Loss: tensor(0.1269, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1392\n",
      "Loss: tensor(0.1269, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1393\n",
      "Loss: tensor(0.1269, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1394\n",
      "Loss: tensor(0.1269, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1395\n",
      "Loss: tensor(0.1269, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1396\n",
      "Loss: tensor(0.1269, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1397\n",
      "Loss: tensor(0.1269, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1398\n",
      "Loss: tensor(0.1269, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1399\n",
      "Loss: tensor(0.1269, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1400\n",
      "Loss: tensor(0.1269, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1401\n",
      "Loss: tensor(0.1269, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1402\n",
      "Loss: tensor(0.1269, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1403\n",
      "Loss: tensor(0.1268, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1404\n",
      "Loss: tensor(0.1268, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1405\n",
      "Loss: tensor(0.1268, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1406\n",
      "Loss: tensor(0.1268, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1407\n",
      "Loss: tensor(0.1268, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1408\n",
      "Loss: tensor(0.1268, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1409\n",
      "Loss: tensor(0.1268, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1410\n",
      "Loss: tensor(0.1268, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1411\n",
      "Loss: tensor(0.1268, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1412\n",
      "Loss: tensor(0.1268, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1413\n",
      "Loss: tensor(0.1268, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1414\n",
      "Loss: tensor(0.1268, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1415\n",
      "Loss: tensor(0.1268, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1416\n",
      "Loss: tensor(0.1268, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1417\n",
      "Loss: tensor(0.1268, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1418\n",
      "Loss: tensor(0.1268, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1419\n",
      "Loss: tensor(0.1268, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1420\n",
      "Loss: tensor(0.1268, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1421\n",
      "Loss: tensor(0.1268, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1422\n",
      "Loss: tensor(0.1268, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1423\n",
      "Loss: tensor(0.1268, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1424\n",
      "Loss: tensor(0.1268, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1425\n",
      "Loss: tensor(0.1268, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1426\n",
      "Loss: tensor(0.1268, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1427\n",
      "Loss: tensor(0.1268, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1428\n",
      "Loss: tensor(0.1268, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1429\n",
      "Loss: tensor(0.1268, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1430\n",
      "Loss: tensor(0.1268, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1431\n",
      "Loss: tensor(0.1268, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1432\n",
      "Loss: tensor(0.1268, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1433\n",
      "Loss: tensor(0.1268, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1434\n",
      "Loss: tensor(0.1268, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1435\n",
      "Loss: tensor(0.1268, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1436\n",
      "Loss: tensor(0.1268, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1437\n",
      "Loss: tensor(0.1268, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1438\n",
      "Loss: tensor(0.1268, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1439\n",
      "Loss: tensor(0.1268, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1440\n",
      "Loss: tensor(0.1268, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1441\n",
      "Loss: tensor(0.1268, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1442\n",
      "Loss: tensor(0.1268, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1443\n",
      "Loss: tensor(0.1268, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1444\n",
      "Loss: tensor(0.1268, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1445\n",
      "Loss: tensor(0.1268, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1446\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor(0.1268, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1447\n",
      "Loss: tensor(0.1268, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1448\n",
      "Loss: tensor(0.1268, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1449\n",
      "Loss: tensor(0.1268, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1450\n",
      "Loss: tensor(0.1268, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1451\n",
      "Loss: tensor(0.1268, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1452\n",
      "Loss: tensor(0.1268, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1453\n",
      "Loss: tensor(0.1268, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1454\n",
      "Loss: tensor(0.1268, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1455\n",
      "Loss: tensor(0.1268, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1456\n",
      "Loss: tensor(0.1267, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1457\n",
      "Loss: tensor(0.1267, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1458\n",
      "Loss: tensor(0.1267, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1459\n",
      "Loss: tensor(0.1267, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1460\n",
      "Loss: tensor(0.1267, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1461\n",
      "Loss: tensor(0.1267, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1462\n",
      "Loss: tensor(0.1267, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1463\n",
      "Loss: tensor(0.1267, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1464\n",
      "Loss: tensor(0.1267, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1465\n",
      "Loss: tensor(0.1267, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1466\n",
      "Loss: tensor(0.1267, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1467\n",
      "Loss: tensor(0.1267, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1468\n",
      "Loss: tensor(0.1267, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1469\n",
      "Loss: tensor(0.1267, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1470\n",
      "Loss: tensor(0.1267, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1471\n",
      "Loss: tensor(0.1267, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1472\n",
      "Loss: tensor(0.1267, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1473\n",
      "Loss: tensor(0.1267, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1474\n",
      "Loss: tensor(0.1267, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1475\n",
      "Loss: tensor(0.1267, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1476\n",
      "Loss: tensor(0.1267, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1477\n",
      "Loss: tensor(0.1267, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1478\n",
      "Loss: tensor(0.1267, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1479\n",
      "Loss: tensor(0.1267, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1480\n",
      "Loss: tensor(0.1267, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1481\n",
      "Loss: tensor(0.1267, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1482\n",
      "Loss: tensor(0.1267, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1483\n",
      "Loss: tensor(0.1267, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1484\n",
      "Loss: tensor(0.1267, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1485\n",
      "Loss: tensor(0.1267, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1486\n",
      "Loss: tensor(0.1267, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1487\n",
      "Loss: tensor(0.1267, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1488\n",
      "Loss: tensor(0.1267, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1489\n",
      "Loss: tensor(0.1267, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1490\n",
      "Loss: tensor(0.1267, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1491\n",
      "Loss: tensor(0.1267, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1492\n",
      "Loss: tensor(0.1267, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1493\n",
      "Loss: tensor(0.1267, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1494\n",
      "Loss: tensor(0.1267, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1495\n",
      "Loss: tensor(0.1267, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1496\n",
      "Loss: tensor(0.1267, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1497\n",
      "Loss: tensor(0.1267, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1498\n",
      "Loss: tensor(0.1267, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1499\n",
      "Loss: tensor(0.1267, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1500\n",
      "Loss: tensor(0.1267, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1501\n",
      "Loss: tensor(0.1267, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1502\n",
      "Loss: tensor(0.1267, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1503\n",
      "Loss: tensor(0.1267, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1504\n",
      "Loss: tensor(0.1267, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1505\n",
      "Loss: tensor(0.1267, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1506\n",
      "Loss: tensor(0.1267, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1507\n",
      "Loss: tensor(0.1267, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1508\n",
      "Loss: tensor(0.1267, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1509\n",
      "Loss: tensor(0.1267, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1510\n",
      "Loss: tensor(0.1267, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1511\n",
      "Loss: tensor(0.1267, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1512\n",
      "Loss: tensor(0.1267, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1513\n",
      "Loss: tensor(0.1267, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1514\n",
      "Loss: tensor(0.1266, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1515\n",
      "Loss: tensor(0.1266, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1516\n",
      "Loss: tensor(0.1266, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1517\n",
      "Loss: tensor(0.1266, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1518\n",
      "Loss: tensor(0.1266, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1519\n",
      "Loss: tensor(0.1266, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1520\n",
      "Loss: tensor(0.1266, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1521\n",
      "Loss: tensor(0.1266, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1522\n",
      "Loss: tensor(0.1266, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1523\n",
      "Loss: tensor(0.1266, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1524\n",
      "Loss: tensor(0.1266, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1525\n",
      "Loss: tensor(0.1266, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1526\n",
      "Loss: tensor(0.1266, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1527\n",
      "Loss: tensor(0.1266, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1528\n",
      "Loss: tensor(0.1266, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1529\n",
      "Loss: tensor(0.1266, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1530\n",
      "Loss: tensor(0.1266, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1531\n",
      "Loss: tensor(0.1266, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1532\n",
      "Loss: tensor(0.1266, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1533\n",
      "Loss: tensor(0.1266, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1534\n",
      "Loss: tensor(0.1266, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1535\n",
      "Loss: tensor(0.1266, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1536\n",
      "Loss: tensor(0.1266, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1537\n",
      "Loss: tensor(0.1266, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1538\n",
      "Loss: tensor(0.1266, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1539\n",
      "Loss: tensor(0.1266, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1540\n",
      "Loss: tensor(0.1266, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1541\n",
      "Loss: tensor(0.1266, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1542\n",
      "Loss: tensor(0.1266, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1543\n",
      "Loss: tensor(0.1266, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1544\n",
      "Loss: tensor(0.1266, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1545\n",
      "Loss: tensor(0.1266, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1546\n",
      "Loss: tensor(0.1266, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1547\n",
      "Loss: tensor(0.1266, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1548\n",
      "Loss: tensor(0.1266, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1549\n",
      "Loss: tensor(0.1266, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1550\n",
      "Loss: tensor(0.1266, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1551\n",
      "Loss: tensor(0.1266, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1552\n",
      "Loss: tensor(0.1266, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1553\n",
      "Loss: tensor(0.1266, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1554\n",
      "Loss: tensor(0.1266, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1555\n",
      "Loss: tensor(0.1266, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1556\n",
      "Loss: tensor(0.1266, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1557\n",
      "Loss: tensor(0.1266, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1558\n",
      "Loss: tensor(0.1266, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1559\n",
      "Loss: tensor(0.1266, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1560\n",
      "Loss: tensor(0.1266, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1561\n",
      "Loss: tensor(0.1266, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1562\n",
      "Loss: tensor(0.1266, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1563\n",
      "Loss: tensor(0.1266, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1564\n",
      "Loss: tensor(0.1266, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1565\n",
      "Loss: tensor(0.1266, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1566\n",
      "Loss: tensor(0.1266, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1567\n",
      "Loss: tensor(0.1266, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1568\n",
      "Loss: tensor(0.1266, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1569\n",
      "Loss: tensor(0.1266, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1570\n",
      "Loss: tensor(0.1266, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1571\n",
      "Loss: tensor(0.1266, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1572\n",
      "Loss: tensor(0.1266, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1573\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor(0.1266, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1574\n",
      "Loss: tensor(0.1266, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1575\n",
      "Loss: tensor(0.1266, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1576\n",
      "Loss: tensor(0.1266, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1577\n",
      "Loss: tensor(0.1265, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1578\n",
      "Loss: tensor(0.1265, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1579\n",
      "Loss: tensor(0.1265, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1580\n",
      "Loss: tensor(0.1265, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1581\n",
      "Loss: tensor(0.1265, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1582\n",
      "Loss: tensor(0.1265, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1583\n",
      "Loss: tensor(0.1265, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1584\n",
      "Loss: tensor(0.1265, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1585\n",
      "Loss: tensor(0.1265, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1586\n",
      "Loss: tensor(0.1265, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1587\n",
      "Loss: tensor(0.1265, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1588\n",
      "Loss: tensor(0.1265, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1589\n",
      "Loss: tensor(0.1265, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1590\n",
      "Loss: tensor(0.1265, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1591\n",
      "Loss: tensor(0.1265, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1592\n",
      "Loss: tensor(0.1265, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1593\n",
      "Loss: tensor(0.1265, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1594\n",
      "Loss: tensor(0.1265, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1595\n",
      "Loss: tensor(0.1265, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1596\n",
      "Loss: tensor(0.1265, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1597\n",
      "Loss: tensor(0.1265, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1598\n",
      "Loss: tensor(0.1265, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1599\n",
      "Loss: tensor(0.1265, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1600\n",
      "Loss: tensor(0.1265, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1601\n",
      "Loss: tensor(0.1265, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1602\n",
      "Loss: tensor(0.1265, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1603\n",
      "Loss: tensor(0.1265, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1604\n",
      "Loss: tensor(0.1265, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1605\n",
      "Loss: tensor(0.1265, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1606\n",
      "Loss: tensor(0.1265, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1607\n",
      "Loss: tensor(0.1265, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1608\n",
      "Loss: tensor(0.1265, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1609\n",
      "Loss: tensor(0.1265, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1610\n",
      "Loss: tensor(0.1265, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1611\n",
      "Loss: tensor(0.1265, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1612\n",
      "Loss: tensor(0.1265, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1613\n",
      "Loss: tensor(0.1265, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1614\n",
      "Loss: tensor(0.1265, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1615\n",
      "Loss: tensor(0.1265, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1616\n",
      "Loss: tensor(0.1265, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1617\n",
      "Loss: tensor(0.1265, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1618\n",
      "Loss: tensor(0.1265, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1619\n",
      "Loss: tensor(0.1265, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1620\n",
      "Loss: tensor(0.1265, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1621\n",
      "Loss: tensor(0.1265, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1622\n",
      "Loss: tensor(0.1265, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1623\n",
      "Loss: tensor(0.1265, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1624\n",
      "Loss: tensor(0.1265, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1625\n",
      "Loss: tensor(0.1265, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1626\n",
      "Loss: tensor(0.1265, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1627\n",
      "Loss: tensor(0.1265, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1628\n",
      "Loss: tensor(0.1265, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1629\n",
      "Loss: tensor(0.1265, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1630\n",
      "Loss: tensor(0.1265, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1631\n",
      "Loss: tensor(0.1265, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1632\n",
      "Loss: tensor(0.1265, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1633\n",
      "Loss: tensor(0.1265, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1634\n",
      "Loss: tensor(0.1265, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1635\n",
      "Loss: tensor(0.1265, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1636\n",
      "Loss: tensor(0.1265, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1637\n",
      "Loss: tensor(0.1265, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1638\n",
      "Loss: tensor(0.1265, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1639\n",
      "Loss: tensor(0.1265, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1640\n",
      "Loss: tensor(0.1265, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1641\n",
      "Loss: tensor(0.1265, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1642\n",
      "Loss: tensor(0.1265, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1643\n",
      "Loss: tensor(0.1265, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1644\n",
      "Loss: tensor(0.1264, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1645\n",
      "Loss: tensor(0.1264, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1646\n",
      "Loss: tensor(0.1264, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1647\n",
      "Loss: tensor(0.1264, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1648\n",
      "Loss: tensor(0.1264, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1649\n",
      "Loss: tensor(0.1264, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1650\n",
      "Loss: tensor(0.1264, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1651\n",
      "Loss: tensor(0.1264, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1652\n",
      "Loss: tensor(0.1264, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1653\n",
      "Loss: tensor(0.1264, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1654\n",
      "Loss: tensor(0.1264, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1655\n",
      "Loss: tensor(0.1264, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1656\n",
      "Loss: tensor(0.1264, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1657\n",
      "Loss: tensor(0.1264, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1658\n",
      "Loss: tensor(0.1264, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1659\n",
      "Loss: tensor(0.1264, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1660\n",
      "Loss: tensor(0.1264, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1661\n",
      "Loss: tensor(0.1264, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1662\n",
      "Loss: tensor(0.1264, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1663\n",
      "Loss: tensor(0.1264, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1664\n",
      "Loss: tensor(0.1264, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1665\n",
      "Loss: tensor(0.1264, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1666\n",
      "Loss: tensor(0.1264, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1667\n",
      "Loss: tensor(0.1264, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1668\n",
      "Loss: tensor(0.1264, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1669\n",
      "Loss: tensor(0.1264, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1670\n",
      "Loss: tensor(0.1264, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1671\n",
      "Loss: tensor(0.1264, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1672\n",
      "Loss: tensor(0.1264, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1673\n",
      "Loss: tensor(0.1264, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1674\n",
      "Loss: tensor(0.1264, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1675\n",
      "Loss: tensor(0.1264, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1676\n",
      "Loss: tensor(0.1264, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1677\n",
      "Loss: tensor(0.1264, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1678\n",
      "Loss: tensor(0.1264, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1679\n",
      "Loss: tensor(0.1264, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1680\n",
      "Loss: tensor(0.1264, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1681\n",
      "Loss: tensor(0.1264, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1682\n",
      "Loss: tensor(0.1264, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1683\n",
      "Loss: tensor(0.1264, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1684\n",
      "Loss: tensor(0.1264, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1685\n",
      "Loss: tensor(0.1264, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1686\n",
      "Loss: tensor(0.1264, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1687\n",
      "Loss: tensor(0.1264, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1688\n",
      "Loss: tensor(0.1264, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1689\n",
      "Loss: tensor(0.1264, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1690\n",
      "Loss: tensor(0.1264, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1691\n",
      "Loss: tensor(0.1264, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1692\n",
      "Loss: tensor(0.1264, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1693\n",
      "Loss: tensor(0.1264, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1694\n",
      "Loss: tensor(0.1264, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1695\n",
      "Loss: tensor(0.1264, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1696\n",
      "Loss: tensor(0.1264, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1697\n",
      "Loss: tensor(0.1264, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1698\n",
      "Loss: tensor(0.1264, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1699\n",
      "Loss: tensor(0.1264, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1700\n",
      "Loss: tensor(0.1264, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1701\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor(0.1264, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1702\n",
      "Loss: tensor(0.1264, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1703\n",
      "Loss: tensor(0.1264, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1704\n",
      "Loss: tensor(0.1264, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1705\n",
      "Loss: tensor(0.1264, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1706\n",
      "Loss: tensor(0.1264, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1707\n",
      "Loss: tensor(0.1264, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1708\n",
      "Loss: tensor(0.1264, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1709\n",
      "Loss: tensor(0.1264, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1710\n",
      "Loss: tensor(0.1264, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1711\n",
      "Loss: tensor(0.1264, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1712\n",
      "Loss: tensor(0.1264, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1713\n",
      "Loss: tensor(0.1264, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1714\n",
      "Loss: tensor(0.1264, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1715\n",
      "Loss: tensor(0.1264, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1716\n",
      "Loss: tensor(0.1264, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1717\n",
      "Loss: tensor(0.1263, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1718\n",
      "Loss: tensor(0.1263, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1719\n",
      "Loss: tensor(0.1263, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1720\n",
      "Loss: tensor(0.1263, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1721\n",
      "Loss: tensor(0.1263, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1722\n",
      "Loss: tensor(0.1263, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1723\n",
      "Loss: tensor(0.1263, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1724\n",
      "Loss: tensor(0.1263, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1725\n",
      "Loss: tensor(0.1263, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1726\n",
      "Loss: tensor(0.1263, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1727\n",
      "Loss: tensor(0.1263, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1728\n",
      "Loss: tensor(0.1263, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1729\n",
      "Loss: tensor(0.1263, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1730\n",
      "Loss: tensor(0.1263, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1731\n",
      "Loss: tensor(0.1263, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1732\n",
      "Loss: tensor(0.1263, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1733\n",
      "Loss: tensor(0.1263, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1734\n",
      "Loss: tensor(0.1263, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1735\n",
      "Loss: tensor(0.1263, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1736\n",
      "Loss: tensor(0.1263, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1737\n",
      "Loss: tensor(0.1263, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1738\n",
      "Loss: tensor(0.1263, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1739\n",
      "Loss: tensor(0.1263, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1740\n",
      "Loss: tensor(0.1263, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1741\n",
      "Loss: tensor(0.1263, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1742\n",
      "Loss: tensor(0.1263, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1743\n",
      "Loss: tensor(0.1263, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1744\n",
      "Loss: tensor(0.1263, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1745\n",
      "Loss: tensor(0.1263, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1746\n",
      "Loss: tensor(0.1263, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1747\n",
      "Loss: tensor(0.1263, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1748\n",
      "Loss: tensor(0.1263, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1749\n",
      "Loss: tensor(0.1263, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1750\n",
      "Loss: tensor(0.1263, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1751\n",
      "Loss: tensor(0.1263, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1752\n",
      "Loss: tensor(0.1263, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1753\n",
      "Loss: tensor(0.1263, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1754\n",
      "Loss: tensor(0.1263, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1755\n",
      "Loss: tensor(0.1263, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1756\n",
      "Loss: tensor(0.1263, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1757\n",
      "Loss: tensor(0.1263, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1758\n",
      "Loss: tensor(0.1263, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1759\n",
      "Loss: tensor(0.1263, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1760\n",
      "Loss: tensor(0.1263, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1761\n",
      "Loss: tensor(0.1263, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1762\n",
      "Loss: tensor(0.1263, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1763\n",
      "Loss: tensor(0.1263, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1764\n",
      "Loss: tensor(0.1263, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1765\n",
      "Loss: tensor(0.1263, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1766\n",
      "Loss: tensor(0.1263, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1767\n",
      "Loss: tensor(0.1263, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1768\n",
      "Loss: tensor(0.1263, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1769\n",
      "Loss: tensor(0.1263, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1770\n",
      "Loss: tensor(0.1263, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1771\n",
      "Loss: tensor(0.1263, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1772\n",
      "Loss: tensor(0.1263, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1773\n",
      "Loss: tensor(0.1263, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1774\n",
      "Loss: tensor(0.1263, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1775\n",
      "Loss: tensor(0.1263, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1776\n",
      "Loss: tensor(0.1263, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1777\n",
      "Loss: tensor(0.1263, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1778\n",
      "Loss: tensor(0.1263, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1779\n",
      "Loss: tensor(0.1263, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1780\n",
      "Loss: tensor(0.1263, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1781\n",
      "Loss: tensor(0.1263, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1782\n",
      "Loss: tensor(0.1263, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1783\n",
      "Loss: tensor(0.1263, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1784\n",
      "Loss: tensor(0.1263, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1785\n",
      "Loss: tensor(0.1263, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1786\n",
      "Loss: tensor(0.1263, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1787\n",
      "Loss: tensor(0.1263, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1788\n",
      "Loss: tensor(0.1263, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1789\n",
      "Loss: tensor(0.1263, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1790\n",
      "Loss: tensor(0.1263, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1791\n",
      "Loss: tensor(0.1263, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1792\n",
      "Loss: tensor(0.1263, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1793\n",
      "Loss: tensor(0.1262, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1794\n",
      "Loss: tensor(0.1262, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1795\n",
      "Loss: tensor(0.1262, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1796\n",
      "Loss: tensor(0.1262, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1797\n",
      "Loss: tensor(0.1262, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1798\n",
      "Loss: tensor(0.1262, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1799\n",
      "Loss: tensor(0.1262, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1800\n",
      "Loss: tensor(0.1262, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1801\n",
      "Loss: tensor(0.1262, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1802\n",
      "Loss: tensor(0.1262, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1803\n",
      "Loss: tensor(0.1262, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1804\n",
      "Loss: tensor(0.1262, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1805\n",
      "Loss: tensor(0.1262, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1806\n",
      "Loss: tensor(0.1262, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1807\n",
      "Loss: tensor(0.1262, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1808\n",
      "Loss: tensor(0.1262, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1809\n",
      "Loss: tensor(0.1262, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1810\n",
      "Loss: tensor(0.1262, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1811\n",
      "Loss: tensor(0.1262, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1812\n",
      "Loss: tensor(0.1262, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1813\n",
      "Loss: tensor(0.1262, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1814\n",
      "Loss: tensor(0.1262, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1815\n",
      "Loss: tensor(0.1262, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1816\n",
      "Loss: tensor(0.1262, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1817\n",
      "Loss: tensor(0.1262, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1818\n",
      "Loss: tensor(0.1262, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1819\n",
      "Loss: tensor(0.1262, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1820\n",
      "Loss: tensor(0.1262, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1821\n",
      "Loss: tensor(0.1262, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1822\n",
      "Loss: tensor(0.1262, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1823\n",
      "Loss: tensor(0.1262, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1824\n",
      "Loss: tensor(0.1262, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1825\n",
      "Loss: tensor(0.1262, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1826\n",
      "Loss: tensor(0.1262, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1827\n",
      "Loss: tensor(0.1262, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1828\n",
      "Loss: tensor(0.1262, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1829\n",
      "Loss: tensor(0.1262, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1830\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor(0.1262, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1831\n",
      "Loss: tensor(0.1262, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1832\n",
      "Loss: tensor(0.1262, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1833\n",
      "Loss: tensor(0.1262, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1834\n",
      "Loss: tensor(0.1262, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1835\n",
      "Loss: tensor(0.1262, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1836\n",
      "Loss: tensor(0.1262, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1837\n",
      "Loss: tensor(0.1262, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1838\n",
      "Loss: tensor(0.1262, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1839\n",
      "Loss: tensor(0.1262, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1840\n",
      "Loss: tensor(0.1262, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1841\n",
      "Loss: tensor(0.1262, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1842\n",
      "Loss: tensor(0.1262, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1843\n",
      "Loss: tensor(0.1262, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1844\n",
      "Loss: tensor(0.1262, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1845\n",
      "Loss: tensor(0.1262, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1846\n",
      "Loss: tensor(0.1262, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1847\n",
      "Loss: tensor(0.1262, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1848\n",
      "Loss: tensor(0.1262, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1849\n",
      "Loss: tensor(0.1262, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1850\n",
      "Loss: tensor(0.1262, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1851\n",
      "Loss: tensor(0.1262, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1852\n",
      "Loss: tensor(0.1262, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1853\n",
      "Loss: tensor(0.1262, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1854\n",
      "Loss: tensor(0.1262, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1855\n",
      "Loss: tensor(0.1262, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1856\n",
      "Loss: tensor(0.1262, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1857\n",
      "Loss: tensor(0.1262, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1858\n",
      "Loss: tensor(0.1262, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1859\n",
      "Loss: tensor(0.1262, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1860\n",
      "Loss: tensor(0.1262, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1861\n",
      "Loss: tensor(0.1262, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1862\n",
      "Loss: tensor(0.1262, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1863\n",
      "Loss: tensor(0.1262, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1864\n",
      "Loss: tensor(0.1262, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1865\n",
      "Loss: tensor(0.1262, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1866\n",
      "Loss: tensor(0.1261, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1867\n",
      "Loss: tensor(0.1261, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1868\n",
      "Loss: tensor(0.1261, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1869\n",
      "Loss: tensor(0.1261, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1870\n",
      "Loss: tensor(0.1261, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1871\n",
      "Loss: tensor(0.1261, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1872\n",
      "Loss: tensor(0.1261, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1873\n",
      "Loss: tensor(0.1261, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1874\n",
      "Loss: tensor(0.1261, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1875\n",
      "Loss: tensor(0.1261, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1876\n",
      "Loss: tensor(0.1261, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1877\n",
      "Loss: tensor(0.1261, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1878\n",
      "Loss: tensor(0.1261, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1879\n",
      "Loss: tensor(0.1261, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1880\n",
      "Loss: tensor(0.1261, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1881\n",
      "Loss: tensor(0.1261, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1882\n",
      "Loss: tensor(0.1261, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1883\n",
      "Loss: tensor(0.1261, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1884\n",
      "Loss: tensor(0.1261, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1885\n",
      "Loss: tensor(0.1261, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1886\n",
      "Loss: tensor(0.1261, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1887\n",
      "Loss: tensor(0.1261, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1888\n",
      "Loss: tensor(0.1261, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1889\n",
      "Loss: tensor(0.1261, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1890\n",
      "Loss: tensor(0.1261, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1891\n",
      "Loss: tensor(0.1261, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1892\n",
      "Loss: tensor(0.1261, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1893\n",
      "Loss: tensor(0.1261, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1894\n",
      "Loss: tensor(0.1261, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1895\n",
      "Loss: tensor(0.1261, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1896\n",
      "Loss: tensor(0.1261, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1897\n",
      "Loss: tensor(0.1261, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1898\n",
      "Loss: tensor(0.1261, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1899\n",
      "Loss: tensor(0.1261, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1900\n",
      "Loss: tensor(0.1261, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1901\n",
      "Loss: tensor(0.1261, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1902\n",
      "Loss: tensor(0.1261, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1903\n",
      "Loss: tensor(0.1261, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1904\n",
      "Loss: tensor(0.1261, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1905\n",
      "Loss: tensor(0.1261, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1906\n",
      "Loss: tensor(0.1261, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1907\n",
      "Loss: tensor(0.1261, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1908\n",
      "Loss: tensor(0.1261, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1909\n",
      "Loss: tensor(0.1261, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1910\n",
      "Loss: tensor(0.1261, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1911\n",
      "Loss: tensor(0.1261, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1912\n",
      "Loss: tensor(0.1261, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1913\n",
      "Loss: tensor(0.1261, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1914\n",
      "Loss: tensor(0.1261, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1915\n",
      "Loss: tensor(0.1261, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1916\n",
      "Loss: tensor(0.1261, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1917\n",
      "Loss: tensor(0.1261, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1918\n",
      "Loss: tensor(0.1261, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1919\n",
      "Loss: tensor(0.1261, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1920\n",
      "Loss: tensor(0.1261, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1921\n",
      "Loss: tensor(0.1261, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1922\n",
      "Loss: tensor(0.1261, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1923\n",
      "Loss: tensor(0.1261, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1924\n",
      "Loss: tensor(0.1261, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1925\n",
      "Loss: tensor(0.1261, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1926\n",
      "Loss: tensor(0.1261, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1927\n",
      "Loss: tensor(0.1261, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1928\n",
      "Loss: tensor(0.1261, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1929\n",
      "Loss: tensor(0.1261, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1930\n",
      "Loss: tensor(0.1261, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1931\n",
      "Loss: tensor(0.1261, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1932\n",
      "Loss: tensor(0.1261, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1933\n",
      "Loss: tensor(0.1261, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1934\n",
      "Loss: tensor(0.1260, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1935\n",
      "Loss: tensor(0.1260, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1936\n",
      "Loss: tensor(0.1260, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1937\n",
      "Loss: tensor(0.1260, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1938\n",
      "Loss: tensor(0.1260, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1939\n",
      "Loss: tensor(0.1260, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1940\n",
      "Loss: tensor(0.1260, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1941\n",
      "Loss: tensor(0.1260, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1942\n",
      "Loss: tensor(0.1260, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1943\n",
      "Loss: tensor(0.1260, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1944\n",
      "Loss: tensor(0.1260, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1945\n",
      "Loss: tensor(0.1260, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1946\n",
      "Loss: tensor(0.1260, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1947\n",
      "Loss: tensor(0.1260, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1948\n",
      "Loss: tensor(0.1260, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1949\n",
      "Loss: tensor(0.1260, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1950\n",
      "Loss: tensor(0.1260, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1951\n",
      "Loss: tensor(0.1260, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1952\n",
      "Loss: tensor(0.1260, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1953\n",
      "Loss: tensor(0.1260, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1954\n",
      "Loss: tensor(0.1260, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1955\n",
      "Loss: tensor(0.1260, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1956\n",
      "Loss: tensor(0.1260, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1957\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor(0.1260, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1958\n",
      "Loss: tensor(0.1260, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1959\n",
      "Loss: tensor(0.1260, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1960\n",
      "Loss: tensor(0.1260, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1961\n",
      "Loss: tensor(0.1260, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1962\n",
      "Loss: tensor(0.1260, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1963\n",
      "Loss: tensor(0.1260, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1964\n",
      "Loss: tensor(0.1260, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1965\n",
      "Loss: tensor(0.1260, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1966\n",
      "Loss: tensor(0.1260, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1967\n",
      "Loss: tensor(0.1260, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1968\n",
      "Loss: tensor(0.1260, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1969\n",
      "Loss: tensor(0.1260, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1970\n",
      "Loss: tensor(0.1260, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1971\n",
      "Loss: tensor(0.1260, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1972\n",
      "Loss: tensor(0.1260, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1973\n",
      "Loss: tensor(0.1260, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1974\n",
      "Loss: tensor(0.1260, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1975\n",
      "Loss: tensor(0.1260, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1976\n",
      "Loss: tensor(0.1260, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1977\n",
      "Loss: tensor(0.1260, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1978\n",
      "Loss: tensor(0.1260, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1979\n",
      "Loss: tensor(0.1260, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1980\n",
      "Loss: tensor(0.1260, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1981\n",
      "Loss: tensor(0.1260, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1982\n",
      "Loss: tensor(0.1260, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1983\n",
      "Loss: tensor(0.1260, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1984\n",
      "Loss: tensor(0.1260, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1985\n",
      "Loss: tensor(0.1260, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1986\n",
      "Loss: tensor(0.1260, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1987\n",
      "Loss: tensor(0.1260, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1988\n",
      "Loss: tensor(0.1260, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1989\n",
      "Loss: tensor(0.1260, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1990\n",
      "Loss: tensor(0.1260, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1991\n",
      "Loss: tensor(0.1260, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1992\n",
      "Loss: tensor(0.1260, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1993\n",
      "Loss: tensor(0.1260, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1994\n",
      "Loss: tensor(0.1260, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1995\n",
      "Loss: tensor(0.1260, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1996\n",
      "Loss: tensor(0.1260, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1997\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1998\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1999\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2000\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2001\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2002\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2003\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2004\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2005\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2006\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2007\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2008\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2009\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2010\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2011\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2012\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2013\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2014\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2015\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2016\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2017\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2018\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2019\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2020\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2021\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2022\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2023\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2024\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2025\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2026\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2027\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2028\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2029\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2030\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2031\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2032\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2033\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2034\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2035\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2036\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2037\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2038\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2039\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2040\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2041\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2042\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2043\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2044\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2045\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2046\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2047\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2048\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2049\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2050\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2051\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2052\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2053\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2054\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2055\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2056\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2057\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2058\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2059\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2060\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2061\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2062\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2063\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2064\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2065\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2066\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2067\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2068\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2069\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2070\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2071\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2072\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2073\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2074\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2075\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2076\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2077\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2078\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2079\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2080\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2081\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2082\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2083\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2084\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2085\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2086\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2087\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2088\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2089\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2090\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2091\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2092\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2093\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2094\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2095\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2096\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2097\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2098\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2099\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2100\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2101\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2102\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2103\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2104\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2105\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2106\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2107\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2108\n",
      "Loss: tensor(0.1257, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2109\n",
      "Loss: tensor(0.1257, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2110\n",
      "Loss: tensor(0.1257, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2111\n",
      "Loss: tensor(0.1257, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2112\n",
      "Loss: tensor(0.1257, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2113\n",
      "Loss: tensor(0.1257, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2114\n",
      "Loss: tensor(0.1257, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2115\n",
      "Loss: tensor(0.1257, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2116\n",
      "Loss: tensor(0.1257, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2117\n",
      "Loss: tensor(0.1257, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2118\n",
      "Loss: tensor(0.1257, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2119\n",
      "Loss: tensor(0.1257, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2120\n",
      "Loss: tensor(0.1257, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2121\n",
      "Loss: tensor(0.1257, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2122\n",
      "Loss: tensor(0.1257, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2123\n",
      "Loss: tensor(0.1257, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2124\n",
      "Loss: tensor(0.1257, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2125\n",
      "Loss: tensor(0.1257, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2126\n",
      "Loss: tensor(0.1257, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2127\n",
      "Loss: tensor(0.1257, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2128\n",
      "Loss: tensor(0.1257, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2129\n",
      "Loss: tensor(0.1257, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2130\n",
      "Loss: tensor(0.1257, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2131\n",
      "Loss: tensor(0.1257, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2132\n",
      "Loss: tensor(0.1257, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2133\n",
      "Loss: tensor(0.1257, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2134\n",
      "Loss: tensor(0.1257, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2135\n",
      "Loss: tensor(0.1257, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2136\n",
      "Loss: tensor(0.1257, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2137\n",
      "Loss: tensor(0.1257, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2138\n",
      "Loss: tensor(0.1257, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2139\n",
      "Loss: tensor(0.1257, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2140\n",
      "Loss: tensor(0.1257, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2141\n",
      "Loss: tensor(0.1257, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2142\n",
      "Loss: tensor(0.1257, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2143\n",
      "Loss: tensor(0.1257, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2144\n",
      "Loss: tensor(0.1257, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2145\n",
      "Loss: tensor(0.1257, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2146\n",
      "Loss: tensor(0.1257, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2147\n",
      "Loss: tensor(0.1257, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2148\n",
      "Loss: tensor(0.1257, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2149\n",
      "Loss: tensor(0.1257, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2150\n",
      "Loss: tensor(0.1257, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2151\n",
      "Loss: tensor(0.1257, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2152\n",
      "Loss: tensor(0.1257, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2153\n",
      "Loss: tensor(0.1257, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2154\n",
      "Loss: tensor(0.1257, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2155\n",
      "Loss: tensor(0.1257, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2156\n",
      "Loss: tensor(0.1257, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2157\n",
      "Loss: tensor(0.1257, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2158\n",
      "Loss: tensor(0.1256, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2159\n",
      "Loss: tensor(0.1256, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2160\n",
      "Loss: tensor(0.1256, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2161\n",
      "Loss: tensor(0.1256, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2162\n",
      "Loss: tensor(0.1256, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2163\n",
      "Loss: tensor(0.1256, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2164\n",
      "Loss: tensor(0.1256, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2165\n",
      "Loss: tensor(0.1256, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2166\n",
      "Loss: tensor(0.1256, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2167\n",
      "Loss: tensor(0.1256, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2168\n",
      "Loss: tensor(0.1256, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2169\n",
      "Loss: tensor(0.1256, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2170\n",
      "Loss: tensor(0.1256, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2171\n",
      "Loss: tensor(0.1256, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2172\n",
      "Loss: tensor(0.1256, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2173\n",
      "Loss: tensor(0.1256, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2174\n",
      "Loss: tensor(0.1256, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2175\n",
      "Loss: tensor(0.1256, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2176\n",
      "Loss: tensor(0.1256, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2177\n",
      "Loss: tensor(0.1256, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2178\n",
      "Loss: tensor(0.1256, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2179\n",
      "Loss: tensor(0.1256, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2180\n",
      "Loss: tensor(0.1256, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2181\n",
      "Loss: tensor(0.1256, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2182\n",
      "Loss: tensor(0.1256, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2183\n",
      "Loss: tensor(0.1256, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2184\n",
      "Loss: tensor(0.1256, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2185\n",
      "Loss: tensor(0.1256, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2186\n",
      "Loss: tensor(0.1256, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2187\n",
      "Loss: tensor(0.1256, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2188\n",
      "Loss: tensor(0.1256, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2189\n",
      "Loss: tensor(0.1256, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2190\n",
      "Loss: tensor(0.1256, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2191\n",
      "Loss: tensor(0.1256, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2192\n",
      "Loss: tensor(0.1256, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2193\n",
      "Loss: tensor(0.1256, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2194\n",
      "Loss: tensor(0.1256, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2195\n",
      "Loss: tensor(0.1256, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2196\n",
      "Loss: tensor(0.1256, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2197\n",
      "Loss: tensor(0.1256, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2198\n",
      "Loss: tensor(0.1256, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2199\n",
      "Loss: tensor(0.1256, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2200\n",
      "Loss: tensor(0.1256, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2201\n",
      "Loss: tensor(0.1256, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2202\n",
      "Loss: tensor(0.1256, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2203\n",
      "Loss: tensor(0.1256, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2204\n",
      "Loss: tensor(0.1256, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2205\n",
      "Loss: tensor(0.1256, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2206\n",
      "Loss: tensor(0.1255, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2207\n",
      "Loss: tensor(0.1255, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2208\n",
      "Loss: tensor(0.1255, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2209\n",
      "Loss: tensor(0.1255, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2210\n",
      "Loss: tensor(0.1255, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2211\n",
      "Loss: tensor(0.1255, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2212\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor(0.1255, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2213\n",
      "Loss: tensor(0.1255, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2214\n",
      "Loss: tensor(0.1255, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2215\n",
      "Loss: tensor(0.1255, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2216\n",
      "Loss: tensor(0.1255, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2217\n",
      "Loss: tensor(0.1255, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2218\n",
      "Loss: tensor(0.1255, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2219\n",
      "Loss: tensor(0.1255, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2220\n",
      "Loss: tensor(0.1255, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2221\n",
      "Loss: tensor(0.1255, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2222\n",
      "Loss: tensor(0.1255, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2223\n",
      "Loss: tensor(0.1255, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2224\n",
      "Loss: tensor(0.1255, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2225\n",
      "Loss: tensor(0.1255, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2226\n",
      "Loss: tensor(0.1255, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2227\n",
      "Loss: tensor(0.1255, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2228\n",
      "Loss: tensor(0.1255, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2229\n",
      "Loss: tensor(0.1255, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2230\n",
      "Loss: tensor(0.1255, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2231\n",
      "Loss: tensor(0.1255, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2232\n",
      "Loss: tensor(0.1255, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2233\n",
      "Loss: tensor(0.1255, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2234\n",
      "Loss: tensor(0.1255, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2235\n",
      "Loss: tensor(0.1255, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2236\n",
      "Loss: tensor(0.1255, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2237\n",
      "Loss: tensor(0.1255, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2238\n",
      "Loss: tensor(0.1255, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2239\n",
      "Loss: tensor(0.1255, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2240\n",
      "Loss: tensor(0.1255, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2241\n",
      "Loss: tensor(0.1255, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2242\n",
      "Loss: tensor(0.1255, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2243\n",
      "Loss: tensor(0.1255, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2244\n",
      "Loss: tensor(0.1255, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2245\n",
      "Loss: tensor(0.1255, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2246\n",
      "Loss: tensor(0.1255, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2247\n",
      "Loss: tensor(0.1255, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2248\n",
      "Loss: tensor(0.1255, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2249\n",
      "Loss: tensor(0.1255, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2250\n",
      "Loss: tensor(0.1255, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2251\n",
      "Loss: tensor(0.1255, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2252\n",
      "Loss: tensor(0.1254, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2253\n",
      "Loss: tensor(0.1254, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2254\n",
      "Loss: tensor(0.1254, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2255\n",
      "Loss: tensor(0.1254, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2256\n",
      "Loss: tensor(0.1254, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2257\n",
      "Loss: tensor(0.1254, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2258\n",
      "Loss: tensor(0.1254, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2259\n",
      "Loss: tensor(0.1254, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2260\n",
      "Loss: tensor(0.1254, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2261\n",
      "Loss: tensor(0.1254, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2262\n",
      "Loss: tensor(0.1254, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2263\n",
      "Loss: tensor(0.1254, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2264\n",
      "Loss: tensor(0.1254, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2265\n",
      "Loss: tensor(0.1254, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2266\n",
      "Loss: tensor(0.1254, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2267\n",
      "Loss: tensor(0.1254, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2268\n",
      "Loss: tensor(0.1254, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2269\n",
      "Loss: tensor(0.1254, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2270\n",
      "Loss: tensor(0.1254, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2271\n",
      "Loss: tensor(0.1254, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2272\n",
      "Loss: tensor(0.1254, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2273\n",
      "Loss: tensor(0.1254, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2274\n",
      "Loss: tensor(0.1254, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2275\n",
      "Loss: tensor(0.1254, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2276\n",
      "Loss: tensor(0.1254, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2277\n",
      "Loss: tensor(0.1254, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2278\n",
      "Loss: tensor(0.1254, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2279\n",
      "Loss: tensor(0.1254, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2280\n",
      "Loss: tensor(0.1254, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2281\n",
      "Loss: tensor(0.1254, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2282\n",
      "Loss: tensor(0.1254, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2283\n",
      "Loss: tensor(0.1254, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2284\n",
      "Loss: tensor(0.1254, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2285\n",
      "Loss: tensor(0.1254, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2286\n",
      "Loss: tensor(0.1254, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2287\n",
      "Loss: tensor(0.1254, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2288\n",
      "Loss: tensor(0.1254, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2289\n",
      "Loss: tensor(0.1254, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2290\n",
      "Loss: tensor(0.1254, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2291\n",
      "Loss: tensor(0.1254, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2292\n",
      "Loss: tensor(0.1254, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2293\n",
      "Loss: tensor(0.1254, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2294\n",
      "Loss: tensor(0.1254, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2295\n",
      "Loss: tensor(0.1253, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2296\n",
      "Loss: tensor(0.1253, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2297\n",
      "Loss: tensor(0.1253, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2298\n",
      "Loss: tensor(0.1253, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2299\n",
      "Loss: tensor(0.1253, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2300\n",
      "Loss: tensor(0.1253, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2301\n",
      "Loss: tensor(0.1253, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2302\n",
      "Loss: tensor(0.1253, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2303\n",
      "Loss: tensor(0.1253, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2304\n",
      "Loss: tensor(0.1253, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2305\n",
      "Loss: tensor(0.1253, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2306\n",
      "Loss: tensor(0.1253, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2307\n",
      "Loss: tensor(0.1253, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2308\n",
      "Loss: tensor(0.1253, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2309\n",
      "Loss: tensor(0.1253, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2310\n",
      "Loss: tensor(0.1253, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2311\n",
      "Loss: tensor(0.1253, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2312\n",
      "Loss: tensor(0.1253, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2313\n",
      "Loss: tensor(0.1253, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2314\n",
      "Loss: tensor(0.1253, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2315\n",
      "Loss: tensor(0.1253, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2316\n",
      "Loss: tensor(0.1253, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2317\n",
      "Loss: tensor(0.1253, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2318\n",
      "Loss: tensor(0.1253, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2319\n",
      "Loss: tensor(0.1253, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2320\n",
      "Loss: tensor(0.1253, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2321\n",
      "Loss: tensor(0.1253, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2322\n",
      "Loss: tensor(0.1253, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2323\n",
      "Loss: tensor(0.1253, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2324\n",
      "Loss: tensor(0.1253, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2325\n",
      "Loss: tensor(0.1253, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2326\n",
      "Loss: tensor(0.1253, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2327\n",
      "Loss: tensor(0.1253, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2328\n",
      "Loss: tensor(0.1253, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2329\n",
      "Loss: tensor(0.1253, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2330\n",
      "Loss: tensor(0.1253, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2331\n",
      "Loss: tensor(0.1253, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2332\n",
      "Loss: tensor(0.1253, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2333\n",
      "Loss: tensor(0.1253, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2334\n",
      "Loss: tensor(0.1253, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2335\n",
      "Loss: tensor(0.1252, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2336\n",
      "Loss: tensor(0.1252, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2337\n",
      "Loss: tensor(0.1252, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2338\n",
      "Loss: tensor(0.1252, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2339\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor(0.1252, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2340\n",
      "Loss: tensor(0.1252, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2341\n",
      "Loss: tensor(0.1252, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2342\n",
      "Loss: tensor(0.1252, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2343\n",
      "Loss: tensor(0.1252, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2344\n",
      "Loss: tensor(0.1252, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2345\n",
      "Loss: tensor(0.1252, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2346\n",
      "Loss: tensor(0.1252, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2347\n",
      "Loss: tensor(0.1252, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2348\n",
      "Loss: tensor(0.1252, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2349\n",
      "Loss: tensor(0.1252, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2350\n",
      "Loss: tensor(0.1252, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2351\n",
      "Loss: tensor(0.1252, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2352\n",
      "Loss: tensor(0.1252, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2353\n",
      "Loss: tensor(0.1252, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2354\n",
      "Loss: tensor(0.1252, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2355\n",
      "Loss: tensor(0.1252, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2356\n",
      "Loss: tensor(0.1252, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2357\n",
      "Loss: tensor(0.1252, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2358\n",
      "Loss: tensor(0.1252, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2359\n",
      "Loss: tensor(0.1252, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2360\n",
      "Loss: tensor(0.1252, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2361\n",
      "Loss: tensor(0.1252, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2362\n",
      "Loss: tensor(0.1252, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2363\n",
      "Loss: tensor(0.1252, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2364\n",
      "Loss: tensor(0.1252, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2365\n",
      "Loss: tensor(0.1252, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2366\n",
      "Loss: tensor(0.1252, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2367\n",
      "Loss: tensor(0.1252, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2368\n",
      "Loss: tensor(0.1252, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2369\n",
      "Loss: tensor(0.1252, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2370\n",
      "Loss: tensor(0.1252, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2371\n",
      "Loss: tensor(0.1252, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2372\n",
      "Loss: tensor(0.1252, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2373\n",
      "Loss: tensor(0.1251, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2374\n",
      "Loss: tensor(0.1251, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2375\n",
      "Loss: tensor(0.1251, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2376\n",
      "Loss: tensor(0.1251, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2377\n",
      "Loss: tensor(0.1251, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2378\n",
      "Loss: tensor(0.1251, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2379\n",
      "Loss: tensor(0.1251, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2380\n",
      "Loss: tensor(0.1251, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2381\n",
      "Loss: tensor(0.1251, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2382\n",
      "Loss: tensor(0.1251, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2383\n",
      "Loss: tensor(0.1251, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2384\n",
      "Loss: tensor(0.1251, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2385\n",
      "Loss: tensor(0.1251, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2386\n",
      "Loss: tensor(0.1251, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2387\n",
      "Loss: tensor(0.1251, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2388\n",
      "Loss: tensor(0.1251, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2389\n",
      "Loss: tensor(0.1251, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2390\n",
      "Loss: tensor(0.1251, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2391\n",
      "Loss: tensor(0.1251, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2392\n",
      "Loss: tensor(0.1251, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2393\n",
      "Loss: tensor(0.1251, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2394\n",
      "Loss: tensor(0.1251, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2395\n",
      "Loss: tensor(0.1251, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2396\n",
      "Loss: tensor(0.1251, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2397\n",
      "Loss: tensor(0.1251, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2398\n",
      "Loss: tensor(0.1251, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2399\n",
      "Loss: tensor(0.1251, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2400\n",
      "Loss: tensor(0.1251, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2401\n",
      "Loss: tensor(0.1251, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2402\n",
      "Loss: tensor(0.1251, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2403\n",
      "Loss: tensor(0.1251, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2404\n",
      "Loss: tensor(0.1251, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2405\n",
      "Loss: tensor(0.1251, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2406\n",
      "Loss: tensor(0.1251, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2407\n",
      "Loss: tensor(0.1250, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2408\n",
      "Loss: tensor(0.1250, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2409\n",
      "Loss: tensor(0.1250, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2410\n",
      "Loss: tensor(0.1250, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2411\n",
      "Loss: tensor(0.1250, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2412\n",
      "Loss: tensor(0.1250, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2413\n",
      "Loss: tensor(0.1250, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2414\n",
      "Loss: tensor(0.1250, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2415\n",
      "Loss: tensor(0.1250, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2416\n",
      "Loss: tensor(0.1250, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2417\n",
      "Loss: tensor(0.1250, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2418\n",
      "Loss: tensor(0.1250, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2419\n",
      "Loss: tensor(0.1250, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2420\n",
      "Loss: tensor(0.1250, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2421\n",
      "Loss: tensor(0.1250, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2422\n",
      "Loss: tensor(0.1250, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2423\n",
      "Loss: tensor(0.1250, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2424\n",
      "Loss: tensor(0.1250, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2425\n",
      "Loss: tensor(0.1250, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2426\n",
      "Loss: tensor(0.1250, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2427\n",
      "Loss: tensor(0.1250, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2428\n",
      "Loss: tensor(0.1250, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2429\n",
      "Loss: tensor(0.1250, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2430\n",
      "Loss: tensor(0.1250, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2431\n",
      "Loss: tensor(0.1250, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2432\n",
      "Loss: tensor(0.1250, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2433\n",
      "Loss: tensor(0.1250, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2434\n",
      "Loss: tensor(0.1250, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2435\n",
      "Loss: tensor(0.1250, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2436\n",
      "Loss: tensor(0.1250, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2437\n",
      "Loss: tensor(0.1250, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2438\n",
      "Loss: tensor(0.1249, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2439\n",
      "Loss: tensor(0.1249, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2440\n",
      "Loss: tensor(0.1249, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2441\n",
      "Loss: tensor(0.1249, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2442\n",
      "Loss: tensor(0.1249, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2443\n",
      "Loss: tensor(0.1249, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2444\n",
      "Loss: tensor(0.1249, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2445\n",
      "Loss: tensor(0.1249, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2446\n",
      "Loss: tensor(0.1249, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2447\n",
      "Loss: tensor(0.1249, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2448\n",
      "Loss: tensor(0.1249, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2449\n",
      "Loss: tensor(0.1249, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2450\n",
      "Loss: tensor(0.1249, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2451\n",
      "Loss: tensor(0.1249, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2452\n",
      "Loss: tensor(0.1249, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2453\n",
      "Loss: tensor(0.1249, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2454\n",
      "Loss: tensor(0.1249, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2455\n",
      "Loss: tensor(0.1249, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2456\n",
      "Loss: tensor(0.1249, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2457\n",
      "Loss: tensor(0.1249, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2458\n",
      "Loss: tensor(0.1249, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2459\n",
      "Loss: tensor(0.1249, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2460\n",
      "Loss: tensor(0.1249, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2461\n",
      "Loss: tensor(0.1249, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2462\n",
      "Loss: tensor(0.1249, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2463\n",
      "Loss: tensor(0.1249, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2464\n",
      "Loss: tensor(0.1249, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2465\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor(0.1249, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2466\n",
      "Loss: tensor(0.1249, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2467\n",
      "Loss: tensor(0.1248, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2468\n",
      "Loss: tensor(0.1248, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2469\n",
      "Loss: tensor(0.1248, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2470\n",
      "Loss: tensor(0.1248, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2471\n",
      "Loss: tensor(0.1248, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2472\n",
      "Loss: tensor(0.1248, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2473\n",
      "Loss: tensor(0.1248, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2474\n",
      "Loss: tensor(0.1248, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2475\n",
      "Loss: tensor(0.1248, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2476\n",
      "Loss: tensor(0.1248, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2477\n",
      "Loss: tensor(0.1248, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2478\n",
      "Loss: tensor(0.1248, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2479\n",
      "Loss: tensor(0.1248, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2480\n",
      "Loss: tensor(0.1248, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2481\n",
      "Loss: tensor(0.1248, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2482\n",
      "Loss: tensor(0.1248, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2483\n",
      "Loss: tensor(0.1248, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2484\n",
      "Loss: tensor(0.1248, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2485\n",
      "Loss: tensor(0.1248, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2486\n",
      "Loss: tensor(0.1248, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2487\n",
      "Loss: tensor(0.1248, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2488\n",
      "Loss: tensor(0.1248, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2489\n",
      "Loss: tensor(0.1248, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2490\n",
      "Loss: tensor(0.1248, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2491\n",
      "Loss: tensor(0.1248, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2492\n",
      "Loss: tensor(0.1248, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2493\n",
      "Loss: tensor(0.1248, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2494\n",
      "Loss: tensor(0.1248, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2495\n",
      "Loss: tensor(0.1247, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2496\n",
      "Loss: tensor(0.1247, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2497\n",
      "Loss: tensor(0.1247, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2498\n",
      "Loss: tensor(0.1247, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2499\n",
      "Loss: tensor(0.1247, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2500\n",
      "Loss: tensor(0.1247, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2501\n",
      "Loss: tensor(0.1247, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2502\n",
      "Loss: tensor(0.1247, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2503\n",
      "Loss: tensor(0.1247, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2504\n",
      "Loss: tensor(0.1247, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2505\n",
      "Loss: tensor(0.1247, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2506\n",
      "Loss: tensor(0.1247, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2507\n",
      "Loss: tensor(0.1247, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2508\n",
      "Loss: tensor(0.1247, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2509\n",
      "Loss: tensor(0.1247, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2510\n",
      "Loss: tensor(0.1247, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2511\n",
      "Loss: tensor(0.1247, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2512\n",
      "Loss: tensor(0.1247, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2513\n",
      "Loss: tensor(0.1247, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2514\n",
      "Loss: tensor(0.1247, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2515\n",
      "Loss: tensor(0.1247, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2516\n",
      "Loss: tensor(0.1247, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2517\n",
      "Loss: tensor(0.1247, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2518\n",
      "Loss: tensor(0.1247, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2519\n",
      "Loss: tensor(0.1247, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2520\n",
      "Loss: tensor(0.1246, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2521\n",
      "Loss: tensor(0.1246, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2522\n",
      "Loss: tensor(0.1246, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2523\n",
      "Loss: tensor(0.1246, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2524\n",
      "Loss: tensor(0.1246, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2525\n",
      "Loss: tensor(0.1246, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2526\n",
      "Loss: tensor(0.1246, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2527\n",
      "Loss: tensor(0.1246, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2528\n",
      "Loss: tensor(0.1246, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2529\n",
      "Loss: tensor(0.1246, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2530\n",
      "Loss: tensor(0.1246, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2531\n",
      "Loss: tensor(0.1246, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2532\n",
      "Loss: tensor(0.1246, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2533\n",
      "Loss: tensor(0.1246, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2534\n",
      "Loss: tensor(0.1246, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2535\n",
      "Loss: tensor(0.1246, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2536\n",
      "Loss: tensor(0.1246, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2537\n",
      "Loss: tensor(0.1246, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2538\n",
      "Loss: tensor(0.1246, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2539\n",
      "Loss: tensor(0.1246, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2540\n",
      "Loss: tensor(0.1246, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2541\n",
      "Loss: tensor(0.1246, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2542\n",
      "Loss: tensor(0.1246, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2543\n",
      "Loss: tensor(0.1246, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2544\n",
      "Loss: tensor(0.1246, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2545\n",
      "Loss: tensor(0.1245, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2546\n",
      "Loss: tensor(0.1245, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2547\n",
      "Loss: tensor(0.1245, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2548\n",
      "Loss: tensor(0.1245, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2549\n",
      "Loss: tensor(0.1245, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2550\n",
      "Loss: tensor(0.1245, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2551\n",
      "Loss: tensor(0.1245, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2552\n",
      "Loss: tensor(0.1245, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2553\n",
      "Loss: tensor(0.1245, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2554\n",
      "Loss: tensor(0.1245, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2555\n",
      "Loss: tensor(0.1245, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2556\n",
      "Loss: tensor(0.1245, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2557\n",
      "Loss: tensor(0.1245, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2558\n",
      "Loss: tensor(0.1245, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2559\n",
      "Loss: tensor(0.1245, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2560\n",
      "Loss: tensor(0.1245, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2561\n",
      "Loss: tensor(0.1245, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2562\n",
      "Loss: tensor(0.1245, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2563\n",
      "Loss: tensor(0.1245, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2564\n",
      "Loss: tensor(0.1245, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2565\n",
      "Loss: tensor(0.1245, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2566\n",
      "Loss: tensor(0.1245, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2567\n",
      "Loss: tensor(0.1245, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2568\n",
      "Loss: tensor(0.1245, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2569\n",
      "Loss: tensor(0.1244, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2570\n",
      "Loss: tensor(0.1244, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2571\n",
      "Loss: tensor(0.1244, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2572\n",
      "Loss: tensor(0.1244, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2573\n",
      "Loss: tensor(0.1244, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2574\n",
      "Loss: tensor(0.1244, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2575\n",
      "Loss: tensor(0.1244, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2576\n",
      "Loss: tensor(0.1244, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2577\n",
      "Loss: tensor(0.1244, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2578\n",
      "Loss: tensor(0.1244, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2579\n",
      "Loss: tensor(0.1244, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2580\n",
      "Loss: tensor(0.1244, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2581\n",
      "Loss: tensor(0.1244, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2582\n",
      "Loss: tensor(0.1244, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2583\n",
      "Loss: tensor(0.1244, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2584\n",
      "Loss: tensor(0.1244, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2585\n",
      "Loss: tensor(0.1244, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2586\n",
      "Loss: tensor(0.1244, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2587\n",
      "Loss: tensor(0.1244, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2588\n",
      "Loss: tensor(0.1244, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2589\n",
      "Loss: tensor(0.1244, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2590\n",
      "Loss: tensor(0.1244, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2591\n",
      "Loss: tensor(0.1244, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2592\n",
      "Loss: tensor(0.1243, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2593\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor(0.1243, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2594\n",
      "Loss: tensor(0.1243, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2595\n",
      "Loss: tensor(0.1243, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2596\n",
      "Loss: tensor(0.1243, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2597\n",
      "Loss: tensor(0.1243, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2598\n",
      "Loss: tensor(0.1243, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2599\n",
      "Loss: tensor(0.1243, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2600\n",
      "Loss: tensor(0.1243, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2601\n",
      "Loss: tensor(0.1243, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2602\n",
      "Loss: tensor(0.1243, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2603\n",
      "Loss: tensor(0.1243, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2604\n",
      "Loss: tensor(0.1243, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2605\n",
      "Loss: tensor(0.1243, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2606\n",
      "Loss: tensor(0.1243, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2607\n",
      "Loss: tensor(0.1243, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2608\n",
      "Loss: tensor(0.1243, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2609\n",
      "Loss: tensor(0.1243, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2610\n",
      "Loss: tensor(0.1243, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2611\n",
      "Loss: tensor(0.1243, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2612\n",
      "Loss: tensor(0.1243, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2613\n",
      "Loss: tensor(0.1243, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2614\n",
      "Loss: tensor(0.1242, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2615\n",
      "Loss: tensor(0.1242, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2616\n",
      "Loss: tensor(0.1242, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2617\n",
      "Loss: tensor(0.1242, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2618\n",
      "Loss: tensor(0.1242, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2619\n",
      "Loss: tensor(0.1242, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2620\n",
      "Loss: tensor(0.1242, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2621\n",
      "Loss: tensor(0.1242, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2622\n",
      "Loss: tensor(0.1242, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2623\n",
      "Loss: tensor(0.1242, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2624\n",
      "Loss: tensor(0.1242, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2625\n",
      "Loss: tensor(0.1242, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2626\n",
      "Loss: tensor(0.1242, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2627\n",
      "Loss: tensor(0.1242, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2628\n",
      "Loss: tensor(0.1242, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2629\n",
      "Loss: tensor(0.1242, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2630\n",
      "Loss: tensor(0.1242, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2631\n",
      "Loss: tensor(0.1242, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2632\n",
      "Loss: tensor(0.1242, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2633\n",
      "Loss: tensor(0.1242, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2634\n",
      "Loss: tensor(0.1242, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2635\n",
      "Loss: tensor(0.1242, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2636\n",
      "Loss: tensor(0.1241, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2637\n",
      "Loss: tensor(0.1241, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2638\n",
      "Loss: tensor(0.1241, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2639\n",
      "Loss: tensor(0.1241, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2640\n",
      "Loss: tensor(0.1241, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2641\n",
      "Loss: tensor(0.1241, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2642\n",
      "Loss: tensor(0.1241, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2643\n",
      "Loss: tensor(0.1241, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2644\n",
      "Loss: tensor(0.1241, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2645\n",
      "Loss: tensor(0.1241, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2646\n",
      "Loss: tensor(0.1241, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2647\n",
      "Loss: tensor(0.1241, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2648\n",
      "Loss: tensor(0.1241, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2649\n",
      "Loss: tensor(0.1241, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2650\n",
      "Loss: tensor(0.1241, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2651\n",
      "Loss: tensor(0.1241, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2652\n",
      "Loss: tensor(0.1241, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2653\n",
      "Loss: tensor(0.1241, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2654\n",
      "Loss: tensor(0.1241, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2655\n",
      "Loss: tensor(0.1241, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2656\n",
      "Loss: tensor(0.1240, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2657\n",
      "Loss: tensor(0.1240, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2658\n",
      "Loss: tensor(0.1240, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2659\n",
      "Loss: tensor(0.1240, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2660\n",
      "Loss: tensor(0.1240, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2661\n",
      "Loss: tensor(0.1240, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2662\n",
      "Loss: tensor(0.1240, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2663\n",
      "Loss: tensor(0.1240, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2664\n",
      "Loss: tensor(0.1240, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2665\n",
      "Loss: tensor(0.1240, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2666\n",
      "Loss: tensor(0.1240, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2667\n",
      "Loss: tensor(0.1240, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2668\n",
      "Loss: tensor(0.1240, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2669\n",
      "Loss: tensor(0.1240, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2670\n",
      "Loss: tensor(0.1240, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2671\n",
      "Loss: tensor(0.1240, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2672\n",
      "Loss: tensor(0.1240, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2673\n",
      "Loss: tensor(0.1240, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2674\n",
      "Loss: tensor(0.1240, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2675\n",
      "Loss: tensor(0.1240, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2676\n",
      "Loss: tensor(0.1239, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2677\n",
      "Loss: tensor(0.1239, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2678\n",
      "Loss: tensor(0.1239, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2679\n",
      "Loss: tensor(0.1239, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2680\n",
      "Loss: tensor(0.1239, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2681\n",
      "Loss: tensor(0.1239, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2682\n",
      "Loss: tensor(0.1239, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2683\n",
      "Loss: tensor(0.1239, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2684\n",
      "Loss: tensor(0.1239, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2685\n",
      "Loss: tensor(0.1239, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2686\n",
      "Loss: tensor(0.1239, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2687\n",
      "Loss: tensor(0.1239, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2688\n",
      "Loss: tensor(0.1239, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2689\n",
      "Loss: tensor(0.1239, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2690\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor(0.1239, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2691\n",
      "Loss: tensor(0.1239, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2692\n",
      "Loss: tensor(0.1239, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2693\n",
      "Loss: tensor(0.1239, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2694\n",
      "Loss: tensor(0.1238, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2695\n",
      "Loss: tensor(0.1238, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2696\n",
      "Loss: tensor(0.1238, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2697\n",
      "Loss: tensor(0.1238, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2698\n",
      "Loss: tensor(0.1238, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2699\n",
      "Loss: tensor(0.1238, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2700\n",
      "Loss: tensor(0.1238, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2701\n",
      "Loss: tensor(0.1238, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2702\n",
      "Loss: tensor(0.1238, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2703\n",
      "Loss: tensor(0.1238, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2704\n",
      "Loss: tensor(0.1238, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2705\n",
      "Loss: tensor(0.1238, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2706\n",
      "Loss: tensor(0.1238, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2707\n",
      "Loss: tensor(0.1238, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2708\n",
      "Loss: tensor(0.1238, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2709\n",
      "Loss: tensor(0.1238, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2710\n",
      "Loss: tensor(0.1238, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2711\n",
      "Loss: tensor(0.1238, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2712\n",
      "Loss: tensor(0.1237, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2713\n",
      "Loss: tensor(0.1237, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2714\n",
      "Loss: tensor(0.1237, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2715\n",
      "Loss: tensor(0.1237, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2716\n",
      "Loss: tensor(0.1237, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2717\n",
      "Loss: tensor(0.1237, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2718\n",
      "Loss: tensor(0.1237, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2719\n",
      "Loss: tensor(0.1237, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2720\n",
      "Loss: tensor(0.1237, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2721\n",
      "Loss: tensor(0.1237, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2722\n",
      "Loss: tensor(0.1237, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2723\n",
      "Loss: tensor(0.1237, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2724\n",
      "Loss: tensor(0.1237, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2725\n",
      "Loss: tensor(0.1237, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2726\n",
      "Loss: tensor(0.1237, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2727\n",
      "Loss: tensor(0.1237, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2728\n",
      "Loss: tensor(0.1237, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2729\n",
      "Loss: tensor(0.1236, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2730\n",
      "Loss: tensor(0.1236, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2731\n",
      "Loss: tensor(0.1236, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2732\n",
      "Loss: tensor(0.1236, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2733\n",
      "Loss: tensor(0.1236, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2734\n",
      "Loss: tensor(0.1236, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2735\n",
      "Loss: tensor(0.1236, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2736\n",
      "Loss: tensor(0.1236, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2737\n",
      "Loss: tensor(0.1236, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2738\n",
      "Loss: tensor(0.1236, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2739\n",
      "Loss: tensor(0.1236, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2740\n",
      "Loss: tensor(0.1236, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2741\n",
      "Loss: tensor(0.1236, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2742\n",
      "Loss: tensor(0.1236, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2743\n",
      "Loss: tensor(0.1236, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2744\n",
      "Loss: tensor(0.1236, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2745\n",
      "Loss: tensor(0.1235, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2746\n",
      "Loss: tensor(0.1235, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2747\n",
      "Loss: tensor(0.1235, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2748\n",
      "Loss: tensor(0.1235, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2749\n",
      "Loss: tensor(0.1235, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2750\n",
      "Loss: tensor(0.1235, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2751\n",
      "Loss: tensor(0.1235, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2752\n",
      "Loss: tensor(0.1235, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2753\n",
      "Loss: tensor(0.1235, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2754\n",
      "Loss: tensor(0.1235, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2755\n",
      "Loss: tensor(0.1235, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2756\n",
      "Loss: tensor(0.1235, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2757\n",
      "Loss: tensor(0.1235, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2758\n",
      "Loss: tensor(0.1235, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2759\n",
      "Loss: tensor(0.1235, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2760\n",
      "Loss: tensor(0.1235, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2761\n",
      "Loss: tensor(0.1234, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2762\n",
      "Loss: tensor(0.1234, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2763\n",
      "Loss: tensor(0.1234, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2764\n",
      "Loss: tensor(0.1234, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2765\n",
      "Loss: tensor(0.1234, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2766\n",
      "Loss: tensor(0.1234, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2767\n",
      "Loss: tensor(0.1234, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2768\n",
      "Loss: tensor(0.1234, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2769\n",
      "Loss: tensor(0.1234, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2770\n",
      "Loss: tensor(0.1234, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2771\n",
      "Loss: tensor(0.1234, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2772\n",
      "Loss: tensor(0.1234, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2773\n",
      "Loss: tensor(0.1234, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2774\n",
      "Loss: tensor(0.1234, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2775\n",
      "Loss: tensor(0.1234, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2776\n",
      "Loss: tensor(0.1233, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2777\n",
      "Loss: tensor(0.1233, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2778\n",
      "Loss: tensor(0.1233, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2779\n",
      "Loss: tensor(0.1233, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2780\n",
      "Loss: tensor(0.1233, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2781\n",
      "Loss: tensor(0.1233, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2782\n",
      "Loss: tensor(0.1233, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2783\n",
      "Loss: tensor(0.1233, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2784\n",
      "Loss: tensor(0.1233, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2785\n",
      "Loss: tensor(0.1233, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2786\n",
      "Loss: tensor(0.1233, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2787\n",
      "Loss: tensor(0.1233, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2788\n",
      "Loss: tensor(0.1233, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2789\n",
      "Loss: tensor(0.1233, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2790\n",
      "Loss: tensor(0.1232, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2791\n",
      "Loss: tensor(0.1232, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2792\n",
      "Loss: tensor(0.1232, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2793\n",
      "Loss: tensor(0.1232, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2794\n",
      "Loss: tensor(0.1232, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2795\n",
      "Loss: tensor(0.1232, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2796\n",
      "Loss: tensor(0.1232, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2797\n",
      "Loss: tensor(0.1232, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2798\n",
      "Loss: tensor(0.1232, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2799\n",
      "Loss: tensor(0.1232, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2800\n",
      "Loss: tensor(0.1232, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2801\n",
      "Loss: tensor(0.1232, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2802\n",
      "Loss: tensor(0.1232, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2803\n",
      "Loss: tensor(0.1232, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2804\n",
      "Loss: tensor(0.1231, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2805\n",
      "Loss: tensor(0.1231, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2806\n",
      "Loss: tensor(0.1231, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2807\n",
      "Loss: tensor(0.1231, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2808\n",
      "Loss: tensor(0.1231, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2809\n",
      "Loss: tensor(0.1231, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2810\n",
      "Loss: tensor(0.1231, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2811\n",
      "Loss: tensor(0.1231, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2812\n",
      "Loss: tensor(0.1231, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2813\n",
      "Loss: tensor(0.1231, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2814\n",
      "Loss: tensor(0.1231, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2815\n",
      "Loss: tensor(0.1231, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2816\n",
      "Loss: tensor(0.1231, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2817\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor(0.1230, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2818\n",
      "Loss: tensor(0.1230, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2819\n",
      "Loss: tensor(0.1230, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2820\n",
      "Loss: tensor(0.1230, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2821\n",
      "Loss: tensor(0.1230, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2822\n",
      "Loss: tensor(0.1230, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2823\n",
      "Loss: tensor(0.1230, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2824\n",
      "Loss: tensor(0.1230, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2825\n",
      "Loss: tensor(0.1230, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2826\n",
      "Loss: tensor(0.1230, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2827\n",
      "Loss: tensor(0.1230, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2828\n",
      "Loss: tensor(0.1230, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2829\n",
      "Loss: tensor(0.1230, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2830\n",
      "Loss: tensor(0.1229, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2831\n",
      "Loss: tensor(0.1229, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2832\n",
      "Loss: tensor(0.1229, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2833\n",
      "Loss: tensor(0.1229, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2834\n",
      "Loss: tensor(0.1229, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2835\n",
      "Loss: tensor(0.1229, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2836\n",
      "Loss: tensor(0.1229, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2837\n",
      "Loss: tensor(0.1229, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2838\n",
      "Loss: tensor(0.1229, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2839\n",
      "Loss: tensor(0.1229, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2840\n",
      "Loss: tensor(0.1229, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2841\n",
      "Loss: tensor(0.1229, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2842\n",
      "Loss: tensor(0.1228, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2843\n",
      "Loss: tensor(0.1228, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2844\n",
      "Loss: tensor(0.1228, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2845\n",
      "Loss: tensor(0.1228, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2846\n",
      "Loss: tensor(0.1228, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2847\n",
      "Loss: tensor(0.1228, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2848\n",
      "Loss: tensor(0.1228, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2849\n",
      "Loss: tensor(0.1228, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2850\n",
      "Loss: tensor(0.1228, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2851\n",
      "Loss: tensor(0.1228, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2852\n",
      "Loss: tensor(0.1228, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2853\n",
      "Loss: tensor(0.1228, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2854\n",
      "Loss: tensor(0.1227, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2855\n",
      "Loss: tensor(0.1227, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2856\n",
      "Loss: tensor(0.1227, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2857\n",
      "Loss: tensor(0.1227, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2858\n",
      "Loss: tensor(0.1227, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2859\n",
      "Loss: tensor(0.1227, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2860\n",
      "Loss: tensor(0.1227, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2861\n",
      "Loss: tensor(0.1227, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2862\n",
      "Loss: tensor(0.1227, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2863\n",
      "Loss: tensor(0.1227, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2864\n",
      "Loss: tensor(0.1227, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2865\n",
      "Loss: tensor(0.1227, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2866\n",
      "Loss: tensor(0.1226, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2867\n",
      "Loss: tensor(0.1226, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2868\n",
      "Loss: tensor(0.1226, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2869\n",
      "Loss: tensor(0.1226, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2870\n",
      "Loss: tensor(0.1226, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2871\n",
      "Loss: tensor(0.1226, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2872\n",
      "Loss: tensor(0.1226, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2873\n",
      "Loss: tensor(0.1226, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2874\n",
      "Loss: tensor(0.1226, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2875\n",
      "Loss: tensor(0.1226, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2876\n",
      "Loss: tensor(0.1226, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2877\n",
      "Loss: tensor(0.1225, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2878\n",
      "Loss: tensor(0.1225, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2879\n",
      "Loss: tensor(0.1225, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2880\n",
      "Loss: tensor(0.1225, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2881\n",
      "Loss: tensor(0.1225, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2882\n",
      "Loss: tensor(0.1225, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2883\n",
      "Loss: tensor(0.1225, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2884\n",
      "Loss: tensor(0.1225, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2885\n",
      "Loss: tensor(0.1225, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2886\n",
      "Loss: tensor(0.1225, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2887\n",
      "Loss: tensor(0.1225, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2888\n",
      "Loss: tensor(0.1225, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2889\n",
      "Loss: tensor(0.1224, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2890\n",
      "Loss: tensor(0.1224, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2891\n",
      "Loss: tensor(0.1224, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2892\n",
      "Loss: tensor(0.1224, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2893\n",
      "Loss: tensor(0.1224, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2894\n",
      "Loss: tensor(0.1224, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2895\n",
      "Loss: tensor(0.1224, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2896\n",
      "Loss: tensor(0.1224, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2897\n",
      "Loss: tensor(0.1224, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2898\n",
      "Loss: tensor(0.1224, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2899\n",
      "Loss: tensor(0.1224, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2900\n",
      "Loss: tensor(0.1223, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2901\n",
      "Loss: tensor(0.1223, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2902\n",
      "Loss: tensor(0.1223, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2903\n",
      "Loss: tensor(0.1223, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2904\n",
      "Loss: tensor(0.1223, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2905\n",
      "Loss: tensor(0.1223, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2906\n",
      "Loss: tensor(0.1223, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2907\n",
      "Loss: tensor(0.1223, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2908\n",
      "Loss: tensor(0.1223, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2909\n",
      "Loss: tensor(0.1223, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2910\n",
      "Loss: tensor(0.1223, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2911\n",
      "Loss: tensor(0.1222, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2912\n",
      "Loss: tensor(0.1222, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2913\n",
      "Loss: tensor(0.1222, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2914\n",
      "Loss: tensor(0.1222, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2915\n",
      "Loss: tensor(0.1222, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2916\n",
      "Loss: tensor(0.1222, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2917\n",
      "Loss: tensor(0.1222, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2918\n",
      "Loss: tensor(0.1222, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2919\n",
      "Loss: tensor(0.1222, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2920\n",
      "Loss: tensor(0.1222, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2921\n",
      "Loss: tensor(0.1222, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2922\n",
      "Loss: tensor(0.1221, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2923\n",
      "Loss: tensor(0.1221, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2924\n",
      "Loss: tensor(0.1221, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2925\n",
      "Loss: tensor(0.1221, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2926\n",
      "Loss: tensor(0.1221, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2927\n",
      "Loss: tensor(0.1221, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2928\n",
      "Loss: tensor(0.1221, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2929\n",
      "Loss: tensor(0.1221, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2930\n",
      "Loss: tensor(0.1221, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2931\n",
      "Loss: tensor(0.1221, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2932\n",
      "Loss: tensor(0.1221, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2933\n",
      "Loss: tensor(0.1220, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2934\n",
      "Loss: tensor(0.1220, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2935\n",
      "Loss: tensor(0.1220, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2936\n",
      "Loss: tensor(0.1220, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2937\n",
      "Loss: tensor(0.1220, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2938\n",
      "Loss: tensor(0.1220, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2939\n",
      "Loss: tensor(0.1220, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2940\n",
      "Loss: tensor(0.1220, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2941\n",
      "Loss: tensor(0.1220, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2942\n",
      "Loss: tensor(0.1220, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2943\n",
      "Loss: tensor(0.1219, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2944\n",
      "Loss: tensor(0.1219, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2945\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor(0.1219, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2946\n",
      "Loss: tensor(0.1219, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2947\n",
      "Loss: tensor(0.1219, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2948\n",
      "Loss: tensor(0.1219, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2949\n",
      "Loss: tensor(0.1219, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2950\n",
      "Loss: tensor(0.1219, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2951\n",
      "Loss: tensor(0.1219, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2952\n",
      "Loss: tensor(0.1219, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2953\n",
      "Loss: tensor(0.1218, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2954\n",
      "Loss: tensor(0.1218, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2955\n",
      "Loss: tensor(0.1218, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2956\n",
      "Loss: tensor(0.1218, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2957\n",
      "Loss: tensor(0.1218, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2958\n",
      "Loss: tensor(0.1218, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2959\n",
      "Loss: tensor(0.1218, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2960\n",
      "Loss: tensor(0.1218, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2961\n",
      "Loss: tensor(0.1218, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2962\n",
      "Loss: tensor(0.1218, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2963\n",
      "Loss: tensor(0.1217, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2964\n",
      "Loss: tensor(0.1217, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2965\n",
      "Loss: tensor(0.1217, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2966\n",
      "Loss: tensor(0.1217, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2967\n",
      "Loss: tensor(0.1217, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2968\n",
      "Loss: tensor(0.1217, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2969\n",
      "Loss: tensor(0.1217, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2970\n",
      "Loss: tensor(0.1217, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2971\n",
      "Loss: tensor(0.1217, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2972\n",
      "Loss: tensor(0.1217, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2973\n",
      "Loss: tensor(0.1216, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2974\n",
      "Loss: tensor(0.1216, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2975\n",
      "Loss: tensor(0.1216, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2976\n",
      "Loss: tensor(0.1216, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2977\n",
      "Loss: tensor(0.1216, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2978\n",
      "Loss: tensor(0.1216, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2979\n",
      "Loss: tensor(0.1216, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2980\n",
      "Loss: tensor(0.1216, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2981\n",
      "Loss: tensor(0.1216, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2982\n",
      "Loss: tensor(0.1216, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2983\n",
      "Loss: tensor(0.1215, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2984\n",
      "Loss: tensor(0.1215, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2985\n",
      "Loss: tensor(0.1215, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2986\n",
      "Loss: tensor(0.1215, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2987\n",
      "Loss: tensor(0.1215, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2988\n",
      "Loss: tensor(0.1215, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2989\n",
      "Loss: tensor(0.1215, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2990\n",
      "Loss: tensor(0.1215, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2991\n",
      "Loss: tensor(0.1215, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2992\n",
      "Loss: tensor(0.1215, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2993\n",
      "Loss: tensor(0.1214, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2994\n",
      "Loss: tensor(0.1214, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2995\n",
      "Loss: tensor(0.1214, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2996\n",
      "Loss: tensor(0.1214, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2997\n",
      "Loss: tensor(0.1214, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2998\n",
      "Loss: tensor(0.1214, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2999\n",
      "Loss: tensor(0.1214, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3000\n",
      "Loss: tensor(0.1214, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3001\n",
      "Loss: tensor(0.1214, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3002\n",
      "Loss: tensor(0.1214, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3003\n",
      "Loss: tensor(0.1214, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3004\n",
      "Loss: tensor(0.1213, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3005\n",
      "Loss: tensor(0.1213, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3006\n",
      "Loss: tensor(0.1213, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3007\n",
      "Loss: tensor(0.1213, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3008\n",
      "Loss: tensor(0.1213, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3009\n",
      "Loss: tensor(0.1213, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3010\n",
      "Loss: tensor(0.1213, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3011\n",
      "Loss: tensor(0.1213, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3012\n",
      "Loss: tensor(0.1212, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3013\n",
      "Loss: tensor(0.1212, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3014\n",
      "Loss: tensor(0.1212, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3015\n",
      "Loss: tensor(0.1212, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3016\n",
      "Loss: tensor(0.1212, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3017\n",
      "Loss: tensor(0.1212, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3018\n",
      "Loss: tensor(0.1212, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3019\n",
      "Loss: tensor(0.1212, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3020\n",
      "Loss: tensor(0.1212, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3021\n",
      "Loss: tensor(0.1212, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3022\n",
      "Loss: tensor(0.1211, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3023\n",
      "Loss: tensor(0.1211, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3024\n",
      "Loss: tensor(0.1211, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3025\n",
      "Loss: tensor(0.1211, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3026\n",
      "Loss: tensor(0.1211, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3027\n",
      "Loss: tensor(0.1211, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3028\n",
      "Loss: tensor(0.1211, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3029\n",
      "Loss: tensor(0.1211, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3030\n",
      "Loss: tensor(0.1211, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3031\n",
      "Loss: tensor(0.1211, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3032\n",
      "Loss: tensor(0.1210, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3033\n",
      "Loss: tensor(0.1210, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3034\n",
      "Loss: tensor(0.1210, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3035\n",
      "Loss: tensor(0.1210, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3036\n",
      "Loss: tensor(0.1210, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3037\n",
      "Loss: tensor(0.1210, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3038\n",
      "Loss: tensor(0.1210, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3039\n",
      "Loss: tensor(0.1210, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3040\n",
      "Loss: tensor(0.1210, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3041\n",
      "Loss: tensor(0.1209, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3042\n",
      "Loss: tensor(0.1209, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3043\n",
      "Loss: tensor(0.1209, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3044\n",
      "Loss: tensor(0.1209, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3045\n",
      "Loss: tensor(0.1209, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3046\n",
      "Loss: tensor(0.1209, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3047\n",
      "Loss: tensor(0.1209, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3048\n",
      "Loss: tensor(0.1209, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3049\n",
      "Loss: tensor(0.1209, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3050\n",
      "Loss: tensor(0.1209, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3051\n",
      "Loss: tensor(0.1208, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3052\n",
      "Loss: tensor(0.1208, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3053\n",
      "Loss: tensor(0.1208, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3054\n",
      "Loss: tensor(0.1208, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3055\n",
      "Loss: tensor(0.1208, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3056\n",
      "Loss: tensor(0.1208, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3057\n",
      "Loss: tensor(0.1208, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3058\n",
      "Loss: tensor(0.1208, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3059\n",
      "Loss: tensor(0.1208, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3060\n",
      "Loss: tensor(0.1207, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3061\n",
      "Loss: tensor(0.1207, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3062\n",
      "Loss: tensor(0.1207, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3063\n",
      "Loss: tensor(0.1207, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3064\n",
      "Loss: tensor(0.1207, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3065\n",
      "Loss: tensor(0.1207, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3066\n",
      "Loss: tensor(0.1207, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3067\n",
      "Loss: tensor(0.1207, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3068\n",
      "Loss: tensor(0.1207, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3069\n",
      "Loss: tensor(0.1207, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3070\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor(0.1206, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3071\n",
      "Loss: tensor(0.1206, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3072\n",
      "Loss: tensor(0.1206, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3073\n",
      "Loss: tensor(0.1206, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3074\n",
      "Loss: tensor(0.1206, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3075\n",
      "Loss: tensor(0.1206, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3076\n",
      "Loss: tensor(0.1206, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3077\n",
      "Loss: tensor(0.1206, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3078\n",
      "Loss: tensor(0.1206, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3079\n",
      "Loss: tensor(0.1205, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3080\n",
      "Loss: tensor(0.1205, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3081\n",
      "Loss: tensor(0.1205, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3082\n",
      "Loss: tensor(0.1205, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3083\n",
      "Loss: tensor(0.1205, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3084\n",
      "Loss: tensor(0.1205, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3085\n",
      "Loss: tensor(0.1205, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3086\n",
      "Loss: tensor(0.1205, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3087\n",
      "Loss: tensor(0.1205, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3088\n",
      "Loss: tensor(0.1204, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3089\n",
      "Loss: tensor(0.1204, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3090\n",
      "Loss: tensor(0.1204, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3091\n",
      "Loss: tensor(0.1204, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3092\n",
      "Loss: tensor(0.1204, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3093\n",
      "Loss: tensor(0.1204, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3094\n",
      "Loss: tensor(0.1204, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3095\n",
      "Loss: tensor(0.1204, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3096\n",
      "Loss: tensor(0.1204, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3097\n",
      "Loss: tensor(0.1204, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3098\n",
      "Loss: tensor(0.1203, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3099\n",
      "Loss: tensor(0.1203, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3100\n",
      "Loss: tensor(0.1203, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3101\n",
      "Loss: tensor(0.1203, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3102\n",
      "Loss: tensor(0.1203, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3103\n",
      "Loss: tensor(0.1203, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3104\n",
      "Loss: tensor(0.1203, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3105\n",
      "Loss: tensor(0.1203, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3106\n",
      "Loss: tensor(0.1203, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3107\n",
      "Loss: tensor(0.1202, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3108\n",
      "Loss: tensor(0.1202, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3109\n",
      "Loss: tensor(0.1202, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3110\n",
      "Loss: tensor(0.1202, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3111\n",
      "Loss: tensor(0.1202, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3112\n",
      "Loss: tensor(0.1202, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3113\n",
      "Loss: tensor(0.1202, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3114\n",
      "Loss: tensor(0.1202, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3115\n",
      "Loss: tensor(0.1202, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3116\n",
      "Loss: tensor(0.1201, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3117\n",
      "Loss: tensor(0.1201, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3118\n",
      "Loss: tensor(0.1201, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3119\n",
      "Loss: tensor(0.1201, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3120\n",
      "Loss: tensor(0.1201, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3121\n",
      "Loss: tensor(0.1201, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3122\n",
      "Loss: tensor(0.1201, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3123\n",
      "Loss: tensor(0.1201, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3124\n",
      "Loss: tensor(0.1201, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3125\n",
      "Loss: tensor(0.1200, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3126\n",
      "Loss: tensor(0.1200, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3127\n",
      "Loss: tensor(0.1200, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3128\n",
      "Loss: tensor(0.1200, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3129\n",
      "Loss: tensor(0.1200, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3130\n",
      "Loss: tensor(0.1200, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3131\n",
      "Loss: tensor(0.1200, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3132\n",
      "Loss: tensor(0.1200, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3133\n",
      "Loss: tensor(0.1200, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3134\n",
      "Loss: tensor(0.1199, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3135\n",
      "Loss: tensor(0.1199, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3136\n",
      "Loss: tensor(0.1199, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3137\n",
      "Loss: tensor(0.1199, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3138\n",
      "Loss: tensor(0.1199, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3139\n",
      "Loss: tensor(0.1199, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3140\n",
      "Loss: tensor(0.1199, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3141\n",
      "Loss: tensor(0.1199, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3142\n",
      "Loss: tensor(0.1199, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3143\n",
      "Loss: tensor(0.1198, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3144\n",
      "Loss: tensor(0.1198, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3145\n",
      "Loss: tensor(0.1198, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3146\n",
      "Loss: tensor(0.1198, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3147\n",
      "Loss: tensor(0.1198, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3148\n",
      "Loss: tensor(0.1198, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3149\n",
      "Loss: tensor(0.1198, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3150\n",
      "Loss: tensor(0.1198, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3151\n",
      "Loss: tensor(0.1198, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3152\n",
      "Loss: tensor(0.1197, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3153\n",
      "Loss: tensor(0.1197, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3154\n",
      "Loss: tensor(0.1197, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3155\n",
      "Loss: tensor(0.1197, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3156\n",
      "Loss: tensor(0.1197, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3157\n",
      "Loss: tensor(0.1197, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3158\n",
      "Loss: tensor(0.1197, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3159\n",
      "Loss: tensor(0.1197, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3160\n",
      "Loss: tensor(0.1197, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3161\n",
      "Loss: tensor(0.1196, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3162\n",
      "Loss: tensor(0.1196, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3163\n",
      "Loss: tensor(0.1196, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3164\n",
      "Loss: tensor(0.1196, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3165\n",
      "Loss: tensor(0.1196, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3166\n",
      "Loss: tensor(0.1196, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3167\n",
      "Loss: tensor(0.1196, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3168\n",
      "Loss: tensor(0.1196, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3169\n",
      "Loss: tensor(0.1196, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3170\n",
      "Loss: tensor(0.1195, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3171\n",
      "Loss: tensor(0.1195, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3172\n",
      "Loss: tensor(0.1195, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3173\n",
      "Loss: tensor(0.1195, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3174\n",
      "Loss: tensor(0.1195, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3175\n",
      "Loss: tensor(0.1195, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3176\n",
      "Loss: tensor(0.1195, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3177\n",
      "Loss: tensor(0.1195, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3178\n",
      "Loss: tensor(0.1195, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3179\n",
      "Loss: tensor(0.1194, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3180\n",
      "Loss: tensor(0.1194, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3181\n",
      "Loss: tensor(0.1194, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3182\n",
      "Loss: tensor(0.1194, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3183\n",
      "Loss: tensor(0.1194, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3184\n",
      "Loss: tensor(0.1194, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3185\n",
      "Loss: tensor(0.1194, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3186\n",
      "Loss: tensor(0.1194, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3187\n",
      "Loss: tensor(0.1194, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3188\n",
      "Loss: tensor(0.1193, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3189\n",
      "Loss: tensor(0.1193, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3190\n",
      "Loss: tensor(0.1193, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3191\n",
      "Loss: tensor(0.1193, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3192\n",
      "Loss: tensor(0.1193, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3193\n",
      "Loss: tensor(0.1193, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3194\n",
      "Loss: tensor(0.1193, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3195\n",
      "Loss: tensor(0.1193, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3196\n",
      "Loss: tensor(0.1192, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3197\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor(0.1192, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3198\n",
      "Loss: tensor(0.1192, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3199\n",
      "Loss: tensor(0.1192, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3200\n",
      "Loss: tensor(0.1192, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3201\n",
      "Loss: tensor(0.1192, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3202\n",
      "Loss: tensor(0.1192, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3203\n",
      "Loss: tensor(0.1192, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3204\n",
      "Loss: tensor(0.1192, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3205\n",
      "Loss: tensor(0.1191, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3206\n",
      "Loss: tensor(0.1191, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3207\n",
      "Loss: tensor(0.1191, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3208\n",
      "Loss: tensor(0.1191, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3209\n",
      "Loss: tensor(0.1191, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3210\n",
      "Loss: tensor(0.1191, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3211\n",
      "Loss: tensor(0.1191, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3212\n",
      "Loss: tensor(0.1191, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3213\n",
      "Loss: tensor(0.1191, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3214\n",
      "Loss: tensor(0.1190, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3215\n",
      "Loss: tensor(0.1190, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3216\n",
      "Loss: tensor(0.1190, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3217\n",
      "Loss: tensor(0.1190, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3218\n",
      "Loss: tensor(0.1190, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3219\n",
      "Loss: tensor(0.1190, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3220\n",
      "Loss: tensor(0.1190, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3221\n",
      "Loss: tensor(0.1190, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3222\n",
      "Loss: tensor(0.1189, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3223\n",
      "Loss: tensor(0.1189, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3224\n",
      "Loss: tensor(0.1189, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3225\n",
      "Loss: tensor(0.1189, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3226\n",
      "Loss: tensor(0.1189, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3227\n",
      "Loss: tensor(0.1189, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3228\n",
      "Loss: tensor(0.1189, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3229\n",
      "Loss: tensor(0.1189, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3230\n",
      "Loss: tensor(0.1189, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3231\n",
      "Loss: tensor(0.1188, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3232\n",
      "Loss: tensor(0.1188, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3233\n",
      "Loss: tensor(0.1188, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3234\n",
      "Loss: tensor(0.1188, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3235\n",
      "Loss: tensor(0.1188, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3236\n",
      "Loss: tensor(0.1188, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3237\n",
      "Loss: tensor(0.1188, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3238\n",
      "Loss: tensor(0.1188, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3239\n",
      "Loss: tensor(0.1188, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3240\n",
      "Loss: tensor(0.1187, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3241\n",
      "Loss: tensor(0.1187, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3242\n",
      "Loss: tensor(0.1187, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3243\n",
      "Loss: tensor(0.1187, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3244\n",
      "Loss: tensor(0.1187, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3245\n",
      "Loss: tensor(0.1187, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3246\n",
      "Loss: tensor(0.1187, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3247\n",
      "Loss: tensor(0.1187, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3248\n",
      "Loss: tensor(0.1186, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3249\n",
      "Loss: tensor(0.1186, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3250\n",
      "Loss: tensor(0.1186, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3251\n",
      "Loss: tensor(0.1186, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3252\n",
      "Loss: tensor(0.1186, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3253\n",
      "Loss: tensor(0.1186, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3254\n",
      "Loss: tensor(0.1186, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3255\n",
      "Loss: tensor(0.1186, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3256\n",
      "Loss: tensor(0.1185, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3257\n",
      "Loss: tensor(0.1185, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3258\n",
      "Loss: tensor(0.1185, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3259\n",
      "Loss: tensor(0.1185, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3260\n",
      "Loss: tensor(0.1185, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3261\n",
      "Loss: tensor(0.1185, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3262\n",
      "Loss: tensor(0.1185, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3263\n",
      "Loss: tensor(0.1185, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3264\n",
      "Loss: tensor(0.1185, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3265\n",
      "Loss: tensor(0.1184, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3266\n",
      "Loss: tensor(0.1184, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3267\n",
      "Loss: tensor(0.1184, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3268\n",
      "Loss: tensor(0.1184, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3269\n",
      "Loss: tensor(0.1184, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3270\n",
      "Loss: tensor(0.1184, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3271\n",
      "Loss: tensor(0.1184, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3272\n",
      "Loss: tensor(0.1184, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3273\n",
      "Loss: tensor(0.1183, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3274\n",
      "Loss: tensor(0.1183, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3275\n",
      "Loss: tensor(0.1183, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3276\n",
      "Loss: tensor(0.1183, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3277\n",
      "Loss: tensor(0.1183, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3278\n",
      "Loss: tensor(0.1183, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3279\n",
      "Loss: tensor(0.1183, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3280\n",
      "Loss: tensor(0.1183, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3281\n",
      "Loss: tensor(0.1183, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3282\n",
      "Loss: tensor(0.1182, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3283\n",
      "Loss: tensor(0.1182, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3284\n",
      "Loss: tensor(0.1182, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3285\n",
      "Loss: tensor(0.1182, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3286\n",
      "Loss: tensor(0.1182, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3287\n",
      "Loss: tensor(0.1182, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3288\n",
      "Loss: tensor(0.1182, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3289\n",
      "Loss: tensor(0.1182, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3290\n",
      "Loss: tensor(0.1181, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3291\n",
      "Loss: tensor(0.1181, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3292\n",
      "Loss: tensor(0.1181, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3293\n",
      "Loss: tensor(0.1181, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3294\n",
      "Loss: tensor(0.1181, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3295\n",
      "Loss: tensor(0.1181, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3296\n",
      "Loss: tensor(0.1181, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3297\n",
      "Loss: tensor(0.1181, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3298\n",
      "Loss: tensor(0.1180, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3299\n",
      "Loss: tensor(0.1180, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3300\n",
      "Loss: tensor(0.1180, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3301\n",
      "Loss: tensor(0.1180, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3302\n",
      "Loss: tensor(0.1180, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3303\n",
      "Loss: tensor(0.1180, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3304\n",
      "Loss: tensor(0.1180, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3305\n",
      "Loss: tensor(0.1180, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3306\n",
      "Loss: tensor(0.1179, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3307\n",
      "Loss: tensor(0.1179, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3308\n",
      "Loss: tensor(0.1179, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3309\n",
      "Loss: tensor(0.1179, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3310\n",
      "Loss: tensor(0.1179, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3311\n",
      "Loss: tensor(0.1179, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3312\n",
      "Loss: tensor(0.1179, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3313\n",
      "Loss: tensor(0.1179, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3314\n",
      "Loss: tensor(0.1178, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3315\n",
      "Loss: tensor(0.1178, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3316\n",
      "Loss: tensor(0.1178, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3317\n",
      "Loss: tensor(0.1178, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3318\n",
      "Loss: tensor(0.1178, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3319\n",
      "Loss: tensor(0.1178, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3320\n",
      "Loss: tensor(0.1178, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3321\n",
      "Loss: tensor(0.1178, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3322\n",
      "Loss: tensor(0.1177, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3323\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor(0.1177, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3324\n",
      "Loss: tensor(0.1177, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3325\n",
      "Loss: tensor(0.1177, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3326\n",
      "Loss: tensor(0.1177, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3327\n",
      "Loss: tensor(0.1177, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3328\n",
      "Loss: tensor(0.1177, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3329\n",
      "Loss: tensor(0.1177, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3330\n",
      "Loss: tensor(0.1177, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3331\n",
      "Loss: tensor(0.1177, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3332\n",
      "Loss: tensor(0.1177, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3333\n",
      "Loss: tensor(0.1177, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3334\n",
      "Loss: tensor(0.1176, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3335\n",
      "Loss: tensor(0.1176, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3336\n",
      "Loss: tensor(0.1176, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3337\n",
      "Loss: tensor(0.1176, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3338\n",
      "Loss: tensor(0.1176, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3339\n",
      "Loss: tensor(0.1175, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3340\n",
      "Loss: tensor(0.1175, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3341\n",
      "Loss: tensor(0.1175, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3342\n",
      "Loss: tensor(0.1175, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3343\n",
      "Loss: tensor(0.1175, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3344\n",
      "Loss: tensor(0.1175, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3345\n",
      "Loss: tensor(0.1175, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3346\n",
      "Loss: tensor(0.1175, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3347\n",
      "Loss: tensor(0.1174, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3348\n",
      "Loss: tensor(0.1174, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3349\n",
      "Loss: tensor(0.1174, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3350\n",
      "Loss: tensor(0.1174, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3351\n",
      "Loss: tensor(0.1174, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3352\n",
      "Loss: tensor(0.1174, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3353\n",
      "Loss: tensor(0.1174, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3354\n",
      "Loss: tensor(0.1173, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3355\n",
      "Loss: tensor(0.1173, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3356\n",
      "Loss: tensor(0.1173, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3357\n",
      "Loss: tensor(0.1173, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3358\n",
      "Loss: tensor(0.1173, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3359\n",
      "Loss: tensor(0.1173, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3360\n",
      "Loss: tensor(0.1173, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3361\n",
      "Loss: tensor(0.1173, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3362\n",
      "Loss: tensor(0.1172, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3363\n",
      "Loss: tensor(0.1172, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3364\n",
      "Loss: tensor(0.1172, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3365\n",
      "Loss: tensor(0.1172, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3366\n",
      "Loss: tensor(0.1172, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3367\n",
      "Loss: tensor(0.1172, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3368\n",
      "Loss: tensor(0.1172, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3369\n",
      "Loss: tensor(0.1172, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3370\n",
      "Loss: tensor(0.1171, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3371\n",
      "Loss: tensor(0.1171, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3372\n",
      "Loss: tensor(0.1171, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3373\n",
      "Loss: tensor(0.1171, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3374\n",
      "Loss: tensor(0.1171, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3375\n",
      "Loss: tensor(0.1171, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3376\n",
      "Loss: tensor(0.1171, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3377\n",
      "Loss: tensor(0.1171, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3378\n",
      "Loss: tensor(0.1170, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3379\n",
      "Loss: tensor(0.1170, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3380\n",
      "Loss: tensor(0.1170, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3381\n",
      "Loss: tensor(0.1170, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3382\n",
      "Loss: tensor(0.1170, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3383\n",
      "Loss: tensor(0.1170, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3384\n",
      "Loss: tensor(0.1170, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3385\n",
      "Loss: tensor(0.1170, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3386\n",
      "Loss: tensor(0.1169, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3387\n",
      "Loss: tensor(0.1169, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3388\n",
      "Loss: tensor(0.1169, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3389\n",
      "Loss: tensor(0.1169, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3390\n",
      "Loss: tensor(0.1169, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3391\n",
      "Loss: tensor(0.1169, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3392\n",
      "Loss: tensor(0.1169, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3393\n",
      "Loss: tensor(0.1169, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3394\n",
      "Loss: tensor(0.1168, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3395\n",
      "Loss: tensor(0.1168, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3396\n",
      "Loss: tensor(0.1168, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3397\n",
      "Loss: tensor(0.1168, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3398\n",
      "Loss: tensor(0.1168, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3399\n",
      "Loss: tensor(0.1168, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3400\n",
      "Loss: tensor(0.1168, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3401\n",
      "Loss: tensor(0.1168, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3402\n",
      "Loss: tensor(0.1167, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3403\n",
      "Loss: tensor(0.1167, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3404\n",
      "Loss: tensor(0.1167, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3405\n",
      "Loss: tensor(0.1167, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3406\n",
      "Loss: tensor(0.1167, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3407\n",
      "Loss: tensor(0.1167, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3408\n",
      "Loss: tensor(0.1167, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3409\n",
      "Loss: tensor(0.1167, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3410\n",
      "Loss: tensor(0.1166, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3411\n",
      "Loss: tensor(0.1166, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3412\n",
      "Loss: tensor(0.1166, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3413\n",
      "Loss: tensor(0.1166, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3414\n",
      "Loss: tensor(0.1166, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3415\n",
      "Loss: tensor(0.1166, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3416\n",
      "Loss: tensor(0.1166, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3417\n",
      "Loss: tensor(0.1166, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3418\n",
      "Loss: tensor(0.1165, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3419\n",
      "Loss: tensor(0.1165, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3420\n",
      "Loss: tensor(0.1165, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3421\n",
      "Loss: tensor(0.1165, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3422\n",
      "Loss: tensor(0.1165, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3423\n",
      "Loss: tensor(0.1165, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3424\n",
      "Loss: tensor(0.1165, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3425\n",
      "Loss: tensor(0.1165, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3426\n",
      "Loss: tensor(0.1164, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3427\n",
      "Loss: tensor(0.1164, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3428\n",
      "Loss: tensor(0.1164, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3429\n",
      "Loss: tensor(0.1164, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3430\n",
      "Loss: tensor(0.1164, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3431\n",
      "Loss: tensor(0.1164, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3432\n",
      "Loss: tensor(0.1164, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3433\n",
      "Loss: tensor(0.1164, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3434\n",
      "Loss: tensor(0.1163, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3435\n",
      "Loss: tensor(0.1163, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3436\n",
      "Loss: tensor(0.1163, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3437\n",
      "Loss: tensor(0.1163, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3438\n",
      "Loss: tensor(0.1163, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3439\n",
      "Loss: tensor(0.1163, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3440\n",
      "Loss: tensor(0.1163, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3441\n",
      "Loss: tensor(0.1162, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3442\n",
      "Loss: tensor(0.1162, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3443\n",
      "Loss: tensor(0.1162, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3444\n",
      "Loss: tensor(0.1162, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3445\n",
      "Loss: tensor(0.1162, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3446\n",
      "Loss: tensor(0.1162, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3447\n",
      "Loss: tensor(0.1162, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3448\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor(0.1162, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3449\n",
      "Loss: tensor(0.1161, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3450\n",
      "Loss: tensor(0.1161, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3451\n",
      "Loss: tensor(0.1161, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3452\n",
      "Loss: tensor(0.1161, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3453\n",
      "Loss: tensor(0.1161, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3454\n",
      "Loss: tensor(0.1161, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3455\n",
      "Loss: tensor(0.1161, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3456\n",
      "Loss: tensor(0.1161, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3457\n",
      "Loss: tensor(0.1161, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3458\n",
      "Loss: tensor(0.1160, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3459\n",
      "Loss: tensor(0.1160, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3460\n",
      "Loss: tensor(0.1160, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3461\n",
      "Loss: tensor(0.1160, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3462\n",
      "Loss: tensor(0.1160, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3463\n",
      "Loss: tensor(0.1160, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3464\n",
      "Loss: tensor(0.1160, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3465\n",
      "Loss: tensor(0.1159, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3466\n",
      "Loss: tensor(0.1159, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3467\n",
      "Loss: tensor(0.1159, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3468\n",
      "Loss: tensor(0.1159, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3469\n",
      "Loss: tensor(0.1159, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3470\n",
      "Loss: tensor(0.1159, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3471\n",
      "Loss: tensor(0.1159, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3472\n",
      "Loss: tensor(0.1159, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3473\n",
      "Loss: tensor(0.1158, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3474\n",
      "Loss: tensor(0.1158, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3475\n",
      "Loss: tensor(0.1158, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3476\n",
      "Loss: tensor(0.1158, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3477\n",
      "Loss: tensor(0.1158, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3478\n",
      "Loss: tensor(0.1158, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3479\n",
      "Loss: tensor(0.1158, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3480\n",
      "Loss: tensor(0.1157, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3481\n",
      "Loss: tensor(0.1157, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3482\n",
      "Loss: tensor(0.1157, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3483\n",
      "Loss: tensor(0.1157, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3484\n",
      "Loss: tensor(0.1157, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3485\n",
      "Loss: tensor(0.1157, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3486\n",
      "Loss: tensor(0.1157, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3487\n",
      "Loss: tensor(0.1157, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3488\n",
      "Loss: tensor(0.1156, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3489\n",
      "Loss: tensor(0.1156, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3490\n",
      "Loss: tensor(0.1156, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3491\n",
      "Loss: tensor(0.1156, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3492\n",
      "Loss: tensor(0.1156, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3493\n",
      "Loss: tensor(0.1156, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3494\n",
      "Loss: tensor(0.1156, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3495\n",
      "Loss: tensor(0.1156, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3496\n",
      "Loss: tensor(0.1155, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3497\n",
      "Loss: tensor(0.1155, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3498\n",
      "Loss: tensor(0.1155, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3499\n",
      "Loss: tensor(0.1155, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3500\n",
      "Loss: tensor(0.1155, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3501\n",
      "Loss: tensor(0.1155, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3502\n",
      "Loss: tensor(0.1155, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3503\n",
      "Loss: tensor(0.1155, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3504\n",
      "Loss: tensor(0.1154, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3505\n",
      "Loss: tensor(0.1154, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3506\n",
      "Loss: tensor(0.1154, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3507\n",
      "Loss: tensor(0.1154, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3508\n",
      "Loss: tensor(0.1154, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3509\n",
      "Loss: tensor(0.1154, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3510\n",
      "Loss: tensor(0.1154, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3511\n",
      "Loss: tensor(0.1153, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3512\n",
      "Loss: tensor(0.1153, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3513\n",
      "Loss: tensor(0.1153, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3514\n",
      "Loss: tensor(0.1153, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3515\n",
      "Loss: tensor(0.1153, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3516\n",
      "Loss: tensor(0.1153, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3517\n",
      "Loss: tensor(0.1153, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3518\n",
      "Loss: tensor(0.1153, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3519\n",
      "Loss: tensor(0.1152, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3520\n",
      "Loss: tensor(0.1152, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3521\n",
      "Loss: tensor(0.1152, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3522\n",
      "Loss: tensor(0.1152, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3523\n",
      "Loss: tensor(0.1152, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3524\n",
      "Loss: tensor(0.1152, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3525\n",
      "Loss: tensor(0.1152, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3526\n",
      "Loss: tensor(0.1152, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3527\n",
      "Loss: tensor(0.1151, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3528\n",
      "Loss: tensor(0.1151, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3529\n",
      "Loss: tensor(0.1151, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3530\n",
      "Loss: tensor(0.1151, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3531\n",
      "Loss: tensor(0.1151, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3532\n",
      "Loss: tensor(0.1151, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3533\n",
      "Loss: tensor(0.1151, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3534\n",
      "Loss: tensor(0.1151, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3535\n",
      "Loss: tensor(0.1151, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3536\n",
      "Loss: tensor(0.1150, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3537\n",
      "Loss: tensor(0.1150, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3538\n",
      "Loss: tensor(0.1150, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3539\n",
      "Loss: tensor(0.1150, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3540\n",
      "Loss: tensor(0.1150, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3541\n",
      "Loss: tensor(0.1150, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3542\n",
      "Loss: tensor(0.1150, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3543\n",
      "Loss: tensor(0.1149, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3544\n",
      "Loss: tensor(0.1149, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3545\n",
      "Loss: tensor(0.1149, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3546\n",
      "Loss: tensor(0.1149, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3547\n",
      "Loss: tensor(0.1149, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3548\n",
      "Loss: tensor(0.1149, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3549\n",
      "Loss: tensor(0.1149, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3550\n",
      "Loss: tensor(0.1148, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3551\n",
      "Loss: tensor(0.1148, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3552\n",
      "Loss: tensor(0.1148, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3553\n",
      "Loss: tensor(0.1148, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3554\n",
      "Loss: tensor(0.1148, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3555\n",
      "Loss: tensor(0.1148, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3556\n",
      "Loss: tensor(0.1148, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3557\n",
      "Loss: tensor(0.1148, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3558\n",
      "Loss: tensor(0.1147, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3559\n",
      "Loss: tensor(0.1147, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3560\n",
      "Loss: tensor(0.1147, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3561\n",
      "Loss: tensor(0.1147, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3562\n",
      "Loss: tensor(0.1147, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3563\n",
      "Loss: tensor(0.1147, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3564\n",
      "Loss: tensor(0.1147, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3565\n",
      "Loss: tensor(0.1147, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3566\n",
      "Loss: tensor(0.1146, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3567\n",
      "Loss: tensor(0.1146, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3568\n",
      "Loss: tensor(0.1146, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3569\n",
      "Loss: tensor(0.1146, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3570\n",
      "Loss: tensor(0.1146, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3571\n",
      "Loss: tensor(0.1146, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3572\n",
      "Loss: tensor(0.1146, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3573\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor(0.1145, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3574\n",
      "Loss: tensor(0.1145, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3575\n",
      "Loss: tensor(0.1145, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3576\n",
      "Loss: tensor(0.1145, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3577\n",
      "Loss: tensor(0.1145, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3578\n",
      "Loss: tensor(0.1145, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3579\n",
      "Loss: tensor(0.1145, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3580\n",
      "Loss: tensor(0.1145, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3581\n",
      "Loss: tensor(0.1144, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3582\n",
      "Loss: tensor(0.1144, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3583\n",
      "Loss: tensor(0.1144, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3584\n",
      "Loss: tensor(0.1144, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3585\n",
      "Loss: tensor(0.1144, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3586\n",
      "Loss: tensor(0.1144, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3587\n",
      "Loss: tensor(0.1144, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3588\n",
      "Loss: tensor(0.1144, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3589\n",
      "Loss: tensor(0.1143, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3590\n",
      "Loss: tensor(0.1143, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3591\n",
      "Loss: tensor(0.1143, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3592\n",
      "Loss: tensor(0.1143, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3593\n",
      "Loss: tensor(0.1143, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3594\n",
      "Loss: tensor(0.1143, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3595\n",
      "Loss: tensor(0.1143, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3596\n",
      "Loss: tensor(0.1142, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3597\n",
      "Loss: tensor(0.1142, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3598\n",
      "Loss: tensor(0.1142, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3599\n",
      "Loss: tensor(0.1142, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3600\n",
      "Loss: tensor(0.1142, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3601\n",
      "Loss: tensor(0.1142, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3602\n",
      "Loss: tensor(0.1142, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3603\n",
      "Loss: tensor(0.1142, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3604\n",
      "Loss: tensor(0.1141, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3605\n",
      "Loss: tensor(0.1141, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3606\n",
      "Loss: tensor(0.1141, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3607\n",
      "Loss: tensor(0.1141, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3608\n",
      "Loss: tensor(0.1141, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3609\n",
      "Loss: tensor(0.1141, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3610\n",
      "Loss: tensor(0.1141, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3611\n",
      "Loss: tensor(0.1141, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3612\n",
      "Loss: tensor(0.1140, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3613\n",
      "Loss: tensor(0.1140, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3614\n",
      "Loss: tensor(0.1140, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3615\n",
      "Loss: tensor(0.1140, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3616\n",
      "Loss: tensor(0.1140, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3617\n",
      "Loss: tensor(0.1140, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3618\n",
      "Loss: tensor(0.1140, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3619\n",
      "Loss: tensor(0.1139, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3620\n",
      "Loss: tensor(0.1139, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3621\n",
      "Loss: tensor(0.1139, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3622\n",
      "Loss: tensor(0.1139, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3623\n",
      "Loss: tensor(0.1139, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3624\n",
      "Loss: tensor(0.1139, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3625\n",
      "Loss: tensor(0.1139, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3626\n",
      "Loss: tensor(0.1139, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3627\n",
      "Loss: tensor(0.1138, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3628\n",
      "Loss: tensor(0.1138, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3629\n",
      "Loss: tensor(0.1138, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3630\n",
      "Loss: tensor(0.1138, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3631\n",
      "Loss: tensor(0.1138, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3632\n",
      "Loss: tensor(0.1138, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3633\n",
      "Loss: tensor(0.1138, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3634\n",
      "Loss: tensor(0.1138, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3635\n",
      "Loss: tensor(0.1137, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3636\n",
      "Loss: tensor(0.1137, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3637\n",
      "Loss: tensor(0.1137, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3638\n",
      "Loss: tensor(0.1137, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3639\n",
      "Loss: tensor(0.1137, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3640\n",
      "Loss: tensor(0.1137, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3641\n",
      "Loss: tensor(0.1137, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3642\n",
      "Loss: tensor(0.1137, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3643\n",
      "Loss: tensor(0.1136, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3644\n",
      "Loss: tensor(0.1136, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3645\n",
      "Loss: tensor(0.1136, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3646\n",
      "Loss: tensor(0.1136, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3647\n",
      "Loss: tensor(0.1136, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3648\n",
      "Loss: tensor(0.1136, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3649\n",
      "Loss: tensor(0.1136, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3650\n",
      "Loss: tensor(0.1135, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3651\n",
      "Loss: tensor(0.1135, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3652\n",
      "Loss: tensor(0.1135, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3653\n",
      "Loss: tensor(0.1135, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3654\n",
      "Loss: tensor(0.1135, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3655\n",
      "Loss: tensor(0.1135, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3656\n",
      "Loss: tensor(0.1135, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3657\n",
      "Loss: tensor(0.1135, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3658\n",
      "Loss: tensor(0.1134, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3659\n",
      "Loss: tensor(0.1134, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3660\n",
      "Loss: tensor(0.1134, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3661\n",
      "Loss: tensor(0.1134, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3662\n",
      "Loss: tensor(0.1134, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3663\n",
      "Loss: tensor(0.1134, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3664\n",
      "Loss: tensor(0.1134, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3665\n",
      "Loss: tensor(0.1133, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3666\n",
      "Loss: tensor(0.1133, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3667\n",
      "Loss: tensor(0.1133, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3668\n",
      "Loss: tensor(0.1133, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3669\n",
      "Loss: tensor(0.1133, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3670\n",
      "Loss: tensor(0.1133, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3671\n",
      "Loss: tensor(0.1133, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3672\n",
      "Loss: tensor(0.1133, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3673\n",
      "Loss: tensor(0.1132, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3674\n",
      "Loss: tensor(0.1132, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3675\n",
      "Loss: tensor(0.1132, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3676\n",
      "Loss: tensor(0.1132, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3677\n",
      "Loss: tensor(0.1132, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3678\n",
      "Loss: tensor(0.1132, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3679\n",
      "Loss: tensor(0.1132, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3680\n",
      "Loss: tensor(0.1132, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3681\n",
      "Loss: tensor(0.1132, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3682\n",
      "Loss: tensor(0.1131, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3683\n",
      "Loss: tensor(0.1131, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3684\n",
      "Loss: tensor(0.1131, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3685\n",
      "Loss: tensor(0.1131, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3686\n",
      "Loss: tensor(0.1131, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3687\n",
      "Loss: tensor(0.1131, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3688\n",
      "Loss: tensor(0.1130, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3689\n",
      "Loss: tensor(0.1130, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3690\n",
      "Loss: tensor(0.1130, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3691\n",
      "Loss: tensor(0.1130, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3692\n",
      "Loss: tensor(0.1130, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3693\n",
      "Loss: tensor(0.1130, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3694\n",
      "Loss: tensor(0.1130, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3695\n",
      "Loss: tensor(0.1130, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3696\n",
      "Loss: tensor(0.1129, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3697\n",
      "Loss: tensor(0.1129, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3698\n",
      "Loss: tensor(0.1129, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3699\n",
      "Loss: tensor(0.1129, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor(0.1129, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3701\n",
      "Loss: tensor(0.1129, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3702\n",
      "Loss: tensor(0.1129, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3703\n",
      "Loss: tensor(0.1129, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3704\n",
      "Loss: tensor(0.1128, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3705\n",
      "Loss: tensor(0.1128, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3706\n",
      "Loss: tensor(0.1128, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3707\n",
      "Loss: tensor(0.1128, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3708\n",
      "Loss: tensor(0.1128, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3709\n",
      "Loss: tensor(0.1128, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3710\n",
      "Loss: tensor(0.1128, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3711\n",
      "Loss: tensor(0.1128, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3712\n",
      "Loss: tensor(0.1127, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3713\n",
      "Loss: tensor(0.1127, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3714\n",
      "Loss: tensor(0.1127, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3715\n",
      "Loss: tensor(0.1127, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3716\n",
      "Loss: tensor(0.1127, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3717\n",
      "Loss: tensor(0.1127, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3718\n",
      "Loss: tensor(0.1127, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3719\n",
      "Loss: tensor(0.1126, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3720\n",
      "Loss: tensor(0.1126, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3721\n",
      "Loss: tensor(0.1126, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3722\n",
      "Loss: tensor(0.1126, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3723\n",
      "Loss: tensor(0.1126, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3724\n",
      "Loss: tensor(0.1126, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3725\n",
      "Loss: tensor(0.1126, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3726\n",
      "Loss: tensor(0.1126, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3727\n",
      "Loss: tensor(0.1125, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3728\n",
      "Loss: tensor(0.1125, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3729\n",
      "Loss: tensor(0.1125, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3730\n",
      "Loss: tensor(0.1125, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3731\n",
      "Loss: tensor(0.1125, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3732\n",
      "Loss: tensor(0.1125, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3733\n",
      "Loss: tensor(0.1125, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3734\n",
      "Loss: tensor(0.1125, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3735\n",
      "Loss: tensor(0.1124, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3736\n",
      "Loss: tensor(0.1124, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3737\n",
      "Loss: tensor(0.1124, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3738\n",
      "Loss: tensor(0.1124, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3739\n",
      "Loss: tensor(0.1124, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3740\n",
      "Loss: tensor(0.1124, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3741\n",
      "Loss: tensor(0.1124, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3742\n",
      "Loss: tensor(0.1124, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3743\n",
      "Loss: tensor(0.1123, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3744\n",
      "Loss: tensor(0.1123, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3745\n",
      "Loss: tensor(0.1123, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3746\n",
      "Loss: tensor(0.1123, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3747\n",
      "Loss: tensor(0.1123, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3748\n",
      "Loss: tensor(0.1123, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3749\n",
      "Loss: tensor(0.1123, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3750\n",
      "Loss: tensor(0.1122, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3751\n",
      "Loss: tensor(0.1122, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3752\n",
      "Loss: tensor(0.1122, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3753\n",
      "Loss: tensor(0.1122, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3754\n",
      "Loss: tensor(0.1122, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3755\n",
      "Loss: tensor(0.1122, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3756\n",
      "Loss: tensor(0.1122, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3757\n",
      "Loss: tensor(0.1122, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3758\n",
      "Loss: tensor(0.1122, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3759\n",
      "Loss: tensor(0.1121, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3760\n",
      "Loss: tensor(0.1121, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3761\n",
      "Loss: tensor(0.1121, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3762\n",
      "Loss: tensor(0.1121, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3763\n",
      "Loss: tensor(0.1121, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3764\n",
      "Loss: tensor(0.1121, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3765\n",
      "Loss: tensor(0.1121, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3766\n",
      "Loss: tensor(0.1120, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3767\n",
      "Loss: tensor(0.1120, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3768\n",
      "Loss: tensor(0.1120, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3769\n",
      "Loss: tensor(0.1120, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3770\n",
      "Loss: tensor(0.1120, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3771\n",
      "Loss: tensor(0.1120, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3772\n",
      "Loss: tensor(0.1120, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3773\n",
      "Loss: tensor(0.1120, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3774\n",
      "Loss: tensor(0.1119, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3775\n",
      "Loss: tensor(0.1119, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3776\n",
      "Loss: tensor(0.1119, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3777\n",
      "Loss: tensor(0.1119, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3778\n",
      "Loss: tensor(0.1119, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3779\n",
      "Loss: tensor(0.1119, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3780\n",
      "Loss: tensor(0.1119, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3781\n",
      "Loss: tensor(0.1119, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3782\n",
      "Loss: tensor(0.1118, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3783\n",
      "Loss: tensor(0.1118, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3784\n",
      "Loss: tensor(0.1118, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3785\n",
      "Loss: tensor(0.1118, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3786\n",
      "Loss: tensor(0.1118, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3787\n",
      "Loss: tensor(0.1118, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3788\n",
      "Loss: tensor(0.1118, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3789\n",
      "Loss: tensor(0.1117, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3790\n",
      "Loss: tensor(0.1117, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3791\n",
      "Loss: tensor(0.1117, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3792\n",
      "Loss: tensor(0.1117, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3793\n",
      "Loss: tensor(0.1117, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3794\n",
      "Loss: tensor(0.1117, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3795\n",
      "Loss: tensor(0.1117, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3796\n",
      "Loss: tensor(0.1117, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3797\n",
      "Loss: tensor(0.1116, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3798\n",
      "Loss: tensor(0.1116, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3799\n",
      "Loss: tensor(0.1116, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3800\n",
      "Loss: tensor(0.1116, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3801\n",
      "Loss: tensor(0.1116, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3802\n",
      "Loss: tensor(0.1116, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3803\n",
      "Loss: tensor(0.1116, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3804\n",
      "Loss: tensor(0.1116, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3805\n",
      "Loss: tensor(0.1115, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3806\n",
      "Loss: tensor(0.1115, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3807\n",
      "Loss: tensor(0.1115, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3808\n",
      "Loss: tensor(0.1115, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3809\n",
      "Loss: tensor(0.1115, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3810\n",
      "Loss: tensor(0.1115, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3811\n",
      "Loss: tensor(0.1115, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3812\n",
      "Loss: tensor(0.1115, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3813\n",
      "Loss: tensor(0.1114, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3814\n",
      "Loss: tensor(0.1114, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3815\n",
      "Loss: tensor(0.1114, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3816\n",
      "Loss: tensor(0.1114, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3817\n",
      "Loss: tensor(0.1114, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3818\n",
      "Loss: tensor(0.1114, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3819\n",
      "Loss: tensor(0.1114, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3820\n",
      "Loss: tensor(0.1114, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3821\n",
      "Loss: tensor(0.1114, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3822\n",
      "Loss: tensor(0.1113, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3823\n",
      "Loss: tensor(0.1113, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3824\n",
      "Loss: tensor(0.1113, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3825\n",
      "Loss: tensor(0.1113, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3826\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor(0.1113, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3827\n",
      "Loss: tensor(0.1113, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3828\n",
      "Loss: tensor(0.1113, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3829\n",
      "Loss: tensor(0.1112, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3830\n",
      "Loss: tensor(0.1112, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3831\n",
      "Loss: tensor(0.1112, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3832\n",
      "Loss: tensor(0.1112, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3833\n",
      "Loss: tensor(0.1112, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3834\n",
      "Loss: tensor(0.1112, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3835\n",
      "Loss: tensor(0.1112, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3836\n",
      "Loss: tensor(0.1112, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3837\n",
      "Loss: tensor(0.1111, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3838\n",
      "Loss: tensor(0.1111, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3839\n",
      "Loss: tensor(0.1111, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3840\n",
      "Loss: tensor(0.1111, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3841\n",
      "Loss: tensor(0.1111, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3842\n",
      "Loss: tensor(0.1111, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3843\n",
      "Loss: tensor(0.1111, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3844\n",
      "Loss: tensor(0.1111, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3845\n",
      "Loss: tensor(0.1110, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3846\n",
      "Loss: tensor(0.1110, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3847\n",
      "Loss: tensor(0.1110, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3848\n",
      "Loss: tensor(0.1110, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3849\n",
      "Loss: tensor(0.1110, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3850\n",
      "Loss: tensor(0.1110, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3851\n",
      "Loss: tensor(0.1110, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3852\n",
      "Loss: tensor(0.1110, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3853\n",
      "Loss: tensor(0.1109, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3854\n",
      "Loss: tensor(0.1109, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3855\n",
      "Loss: tensor(0.1109, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3856\n",
      "Loss: tensor(0.1109, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3857\n",
      "Loss: tensor(0.1109, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3858\n",
      "Loss: tensor(0.1109, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3859\n",
      "Loss: tensor(0.1109, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3860\n",
      "Loss: tensor(0.1109, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3861\n",
      "Loss: tensor(0.1109, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3862\n",
      "Loss: tensor(0.1109, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3863\n",
      "Loss: tensor(0.1108, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3864\n",
      "Loss: tensor(0.1108, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3865\n",
      "Loss: tensor(0.1108, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3866\n",
      "Loss: tensor(0.1108, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3867\n",
      "Loss: tensor(0.1108, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3868\n",
      "Loss: tensor(0.1108, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3869\n",
      "Loss: tensor(0.1107, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3870\n",
      "Loss: tensor(0.1107, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3871\n",
      "Loss: tensor(0.1107, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3872\n",
      "Loss: tensor(0.1107, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3873\n",
      "Loss: tensor(0.1107, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3874\n",
      "Loss: tensor(0.1107, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3875\n",
      "Loss: tensor(0.1107, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3876\n",
      "Loss: tensor(0.1107, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3877\n",
      "Loss: tensor(0.1107, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3878\n",
      "Loss: tensor(0.1106, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3879\n",
      "Loss: tensor(0.1106, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3880\n",
      "Loss: tensor(0.1106, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3881\n",
      "Loss: tensor(0.1106, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3882\n",
      "Loss: tensor(0.1106, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3883\n",
      "Loss: tensor(0.1106, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3884\n",
      "Loss: tensor(0.1106, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3885\n",
      "Loss: tensor(0.1106, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3886\n",
      "Loss: tensor(0.1105, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3887\n",
      "Loss: tensor(0.1105, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3888\n",
      "Loss: tensor(0.1105, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3889\n",
      "Loss: tensor(0.1105, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3890\n",
      "Loss: tensor(0.1105, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3891\n",
      "Loss: tensor(0.1105, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3892\n",
      "Loss: tensor(0.1105, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3893\n",
      "Loss: tensor(0.1105, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3894\n",
      "Loss: tensor(0.1104, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3895\n",
      "Loss: tensor(0.1104, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3896\n",
      "Loss: tensor(0.1104, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3897\n",
      "Loss: tensor(0.1104, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3898\n",
      "Loss: tensor(0.1104, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3899\n",
      "Loss: tensor(0.1104, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3900\n",
      "Loss: tensor(0.1104, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3901\n",
      "Loss: tensor(0.1104, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3902\n",
      "Loss: tensor(0.1104, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3903\n",
      "Loss: tensor(0.1103, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3904\n",
      "Loss: tensor(0.1103, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3905\n",
      "Loss: tensor(0.1103, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3906\n",
      "Loss: tensor(0.1103, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3907\n",
      "Loss: tensor(0.1103, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3908\n",
      "Loss: tensor(0.1103, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3909\n",
      "Loss: tensor(0.1103, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3910\n",
      "Loss: tensor(0.1103, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3911\n",
      "Loss: tensor(0.1102, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3912\n",
      "Loss: tensor(0.1102, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3913\n",
      "Loss: tensor(0.1102, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3914\n",
      "Loss: tensor(0.1102, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3915\n",
      "Loss: tensor(0.1102, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3916\n",
      "Loss: tensor(0.1102, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3917\n",
      "Loss: tensor(0.1102, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3918\n",
      "Loss: tensor(0.1102, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3919\n",
      "Loss: tensor(0.1101, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3920\n",
      "Loss: tensor(0.1101, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3921\n",
      "Loss: tensor(0.1101, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3922\n",
      "Loss: tensor(0.1101, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3923\n",
      "Loss: tensor(0.1101, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3924\n",
      "Loss: tensor(0.1101, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3925\n",
      "Loss: tensor(0.1101, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3926\n",
      "Loss: tensor(0.1101, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3927\n",
      "Loss: tensor(0.1101, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3928\n",
      "Loss: tensor(0.1100, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3929\n",
      "Loss: tensor(0.1100, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3930\n",
      "Loss: tensor(0.1100, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3931\n",
      "Loss: tensor(0.1100, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3932\n",
      "Loss: tensor(0.1100, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3933\n",
      "Loss: tensor(0.1100, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3934\n",
      "Loss: tensor(0.1100, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3935\n",
      "Loss: tensor(0.1100, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3936\n",
      "Loss: tensor(0.1099, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3937\n",
      "Loss: tensor(0.1099, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3938\n",
      "Loss: tensor(0.1099, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3939\n",
      "Loss: tensor(0.1099, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3940\n",
      "Loss: tensor(0.1099, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3941\n",
      "Loss: tensor(0.1099, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3942\n",
      "Loss: tensor(0.1099, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3943\n",
      "Loss: tensor(0.1099, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3944\n",
      "Loss: tensor(0.1099, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3945\n",
      "Loss: tensor(0.1098, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3946\n",
      "Loss: tensor(0.1098, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3947\n",
      "Loss: tensor(0.1098, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3948\n",
      "Loss: tensor(0.1098, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3949\n",
      "Loss: tensor(0.1098, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3950\n",
      "Loss: tensor(0.1098, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3951\n",
      "Loss: tensor(0.1098, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3952\n",
      "Loss: tensor(0.1098, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3953\n",
      "Loss: tensor(0.1098, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3954\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor(0.1098, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3955\n",
      "Loss: tensor(0.1098, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3956\n",
      "Loss: tensor(0.1098, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3957\n",
      "Loss: tensor(0.1098, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3958\n",
      "Loss: tensor(0.1097, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3959\n",
      "Loss: tensor(0.1097, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3960\n",
      "Loss: tensor(0.1097, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3961\n",
      "Loss: tensor(0.1097, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3962\n",
      "Loss: tensor(0.1097, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3963\n",
      "Loss: tensor(0.1096, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3964\n",
      "Loss: tensor(0.1096, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3965\n",
      "Loss: tensor(0.1096, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3966\n",
      "Loss: tensor(0.1096, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3967\n",
      "Loss: tensor(0.1096, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3968\n",
      "Loss: tensor(0.1096, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3969\n",
      "Loss: tensor(0.1096, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3970\n",
      "Loss: tensor(0.1096, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3971\n",
      "Loss: tensor(0.1095, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3972\n",
      "Loss: tensor(0.1095, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3973\n",
      "Loss: tensor(0.1095, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3974\n",
      "Loss: tensor(0.1095, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3975\n",
      "Loss: tensor(0.1095, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3976\n",
      "Loss: tensor(0.1095, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3977\n",
      "Loss: tensor(0.1095, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3978\n",
      "Loss: tensor(0.1095, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3979\n",
      "Loss: tensor(0.1094, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3980\n",
      "Loss: tensor(0.1094, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3981\n",
      "Loss: tensor(0.1094, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3982\n",
      "Loss: tensor(0.1094, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3983\n",
      "Loss: tensor(0.1094, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3984\n",
      "Loss: tensor(0.1094, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3985\n",
      "Loss: tensor(0.1094, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3986\n",
      "Loss: tensor(0.1094, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3987\n",
      "Loss: tensor(0.1094, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3988\n",
      "Loss: tensor(0.1093, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3989\n",
      "Loss: tensor(0.1093, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3990\n",
      "Loss: tensor(0.1093, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3991\n",
      "Loss: tensor(0.1093, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3992\n",
      "Loss: tensor(0.1093, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3993\n",
      "Loss: tensor(0.1093, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3994\n",
      "Loss: tensor(0.1093, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3995\n",
      "Loss: tensor(0.1093, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3996\n",
      "Loss: tensor(0.1093, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3997\n",
      "Loss: tensor(0.1092, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3998\n",
      "Loss: tensor(0.1092, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3999\n",
      "Loss: tensor(0.1092, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4000\n",
      "Loss: tensor(0.1092, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4001\n",
      "Loss: tensor(0.1092, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4002\n",
      "Loss: tensor(0.1092, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4003\n",
      "Loss: tensor(0.1092, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4004\n",
      "Loss: tensor(0.1092, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4005\n",
      "Loss: tensor(0.1092, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4006\n",
      "Loss: tensor(0.1091, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4007\n",
      "Loss: tensor(0.1091, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4008\n",
      "Loss: tensor(0.1091, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4009\n",
      "Loss: tensor(0.1091, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4010\n",
      "Loss: tensor(0.1091, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4011\n",
      "Loss: tensor(0.1091, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4012\n",
      "Loss: tensor(0.1091, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4013\n",
      "Loss: tensor(0.1091, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4014\n",
      "Loss: tensor(0.1091, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4015\n",
      "Loss: tensor(0.1090, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4016\n",
      "Loss: tensor(0.1090, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4017\n",
      "Loss: tensor(0.1090, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4018\n",
      "Loss: tensor(0.1090, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4019\n",
      "Loss: tensor(0.1090, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4020\n",
      "Loss: tensor(0.1090, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4021\n",
      "Loss: tensor(0.1090, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4022\n",
      "Loss: tensor(0.1090, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4023\n",
      "Loss: tensor(0.1090, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4024\n",
      "Loss: tensor(0.1089, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4025\n",
      "Loss: tensor(0.1089, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4026\n",
      "Loss: tensor(0.1089, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4027\n",
      "Loss: tensor(0.1089, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4028\n",
      "Loss: tensor(0.1089, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4029\n",
      "Loss: tensor(0.1089, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4030\n",
      "Loss: tensor(0.1089, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4031\n",
      "Loss: tensor(0.1089, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4032\n",
      "Loss: tensor(0.1089, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4033\n",
      "Loss: tensor(0.1089, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4034\n",
      "Loss: tensor(0.1089, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4035\n",
      "Loss: tensor(0.1088, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4036\n",
      "Loss: tensor(0.1088, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4037\n",
      "Loss: tensor(0.1088, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4038\n",
      "Loss: tensor(0.1088, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4039\n",
      "Loss: tensor(0.1088, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4040\n",
      "Loss: tensor(0.1088, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4041\n",
      "Loss: tensor(0.1088, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4042\n",
      "Loss: tensor(0.1088, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4043\n",
      "Loss: tensor(0.1087, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4044\n",
      "Loss: tensor(0.1087, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4045\n",
      "Loss: tensor(0.1087, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4046\n",
      "Loss: tensor(0.1087, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4047\n",
      "Loss: tensor(0.1087, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4048\n",
      "Loss: tensor(0.1087, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4049\n",
      "Loss: tensor(0.1087, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4050\n",
      "Loss: tensor(0.1087, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4051\n",
      "Loss: tensor(0.1087, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4052\n",
      "Loss: tensor(0.1086, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4053\n",
      "Loss: tensor(0.1086, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4054\n",
      "Loss: tensor(0.1086, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4055\n",
      "Loss: tensor(0.1086, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4056\n",
      "Loss: tensor(0.1086, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4057\n",
      "Loss: tensor(0.1086, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4058\n",
      "Loss: tensor(0.1086, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4059\n",
      "Loss: tensor(0.1086, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4060\n",
      "Loss: tensor(0.1086, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4061\n",
      "Loss: tensor(0.1085, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4062\n",
      "Loss: tensor(0.1085, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4063\n",
      "Loss: tensor(0.1085, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4064\n",
      "Loss: tensor(0.1085, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4065\n",
      "Loss: tensor(0.1085, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4066\n",
      "Loss: tensor(0.1085, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4067\n",
      "Loss: tensor(0.1085, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4068\n",
      "Loss: tensor(0.1085, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4069\n",
      "Loss: tensor(0.1085, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4070\n",
      "Loss: tensor(0.1084, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4071\n",
      "Loss: tensor(0.1084, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4072\n",
      "Loss: tensor(0.1084, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4073\n",
      "Loss: tensor(0.1084, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4074\n",
      "Loss: tensor(0.1084, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4075\n",
      "Loss: tensor(0.1084, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4076\n",
      "Loss: tensor(0.1084, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4077\n",
      "Loss: tensor(0.1084, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4078\n",
      "Loss: tensor(0.1084, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4079\n",
      "Loss: tensor(0.1084, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4080\n",
      "Loss: tensor(0.1083, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4081\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor(0.1083, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4082\n",
      "Loss: tensor(0.1083, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4083\n",
      "Loss: tensor(0.1083, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4084\n",
      "Loss: tensor(0.1083, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4085\n",
      "Loss: tensor(0.1083, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4086\n",
      "Loss: tensor(0.1083, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4087\n",
      "Loss: tensor(0.1083, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4088\n",
      "Loss: tensor(0.1083, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4089\n",
      "Loss: tensor(0.1082, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4090\n",
      "Loss: tensor(0.1082, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4091\n",
      "Loss: tensor(0.1082, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4092\n",
      "Loss: tensor(0.1082, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4093\n",
      "Loss: tensor(0.1082, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4094\n",
      "Loss: tensor(0.1082, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4095\n",
      "Loss: tensor(0.1082, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4096\n",
      "Loss: tensor(0.1082, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4097\n",
      "Loss: tensor(0.1082, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4098\n",
      "Loss: tensor(0.1082, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4099\n",
      "Loss: tensor(0.1081, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4100\n",
      "Loss: tensor(0.1081, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4101\n",
      "Loss: tensor(0.1081, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4102\n",
      "Loss: tensor(0.1081, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4103\n",
      "Loss: tensor(0.1081, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4104\n",
      "Loss: tensor(0.1081, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4105\n",
      "Loss: tensor(0.1081, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4106\n",
      "Loss: tensor(0.1081, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4107\n",
      "Loss: tensor(0.1081, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4108\n",
      "Loss: tensor(0.1081, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4109\n",
      "Loss: tensor(0.1080, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4110\n",
      "Loss: tensor(0.1080, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4111\n",
      "Loss: tensor(0.1080, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4112\n",
      "Loss: tensor(0.1080, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4113\n",
      "Loss: tensor(0.1080, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4114\n",
      "Loss: tensor(0.1080, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4115\n",
      "Loss: tensor(0.1080, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4116\n",
      "Loss: tensor(0.1080, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4117\n",
      "Loss: tensor(0.1080, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4118\n",
      "Loss: tensor(0.1079, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4119\n",
      "Loss: tensor(0.1079, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4120\n",
      "Loss: tensor(0.1079, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4121\n",
      "Loss: tensor(0.1079, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4122\n",
      "Loss: tensor(0.1079, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4123\n",
      "Loss: tensor(0.1079, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4124\n",
      "Loss: tensor(0.1079, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4125\n",
      "Loss: tensor(0.1079, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4126\n",
      "Loss: tensor(0.1079, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4127\n",
      "Loss: tensor(0.1079, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4128\n",
      "Loss: tensor(0.1078, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4129\n",
      "Loss: tensor(0.1078, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4130\n",
      "Loss: tensor(0.1078, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4131\n",
      "Loss: tensor(0.1078, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4132\n",
      "Loss: tensor(0.1078, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4133\n",
      "Loss: tensor(0.1078, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4134\n",
      "Loss: tensor(0.1078, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4135\n",
      "Loss: tensor(0.1078, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4136\n",
      "Loss: tensor(0.1078, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4137\n",
      "Loss: tensor(0.1078, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4138\n",
      "Loss: tensor(0.1077, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4139\n",
      "Loss: tensor(0.1077, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4140\n",
      "Loss: tensor(0.1077, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4141\n",
      "Loss: tensor(0.1077, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4142\n",
      "Loss: tensor(0.1077, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4143\n",
      "Loss: tensor(0.1077, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4144\n",
      "Loss: tensor(0.1077, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4145\n",
      "Loss: tensor(0.1077, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4146\n",
      "Loss: tensor(0.1077, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4147\n",
      "Loss: tensor(0.1077, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4148\n",
      "Loss: tensor(0.1076, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4149\n",
      "Loss: tensor(0.1076, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4150\n",
      "Loss: tensor(0.1076, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4151\n",
      "Loss: tensor(0.1076, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4152\n",
      "Loss: tensor(0.1076, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4153\n",
      "Loss: tensor(0.1076, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4154\n",
      "Loss: tensor(0.1076, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4155\n",
      "Loss: tensor(0.1076, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4156\n",
      "Loss: tensor(0.1076, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4157\n",
      "Loss: tensor(0.1076, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4158\n",
      "Loss: tensor(0.1076, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4159\n",
      "Loss: tensor(0.1076, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4160\n",
      "Loss: tensor(0.1076, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4161\n",
      "Loss: tensor(0.1076, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4162\n",
      "Loss: tensor(0.1076, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4163\n",
      "Loss: tensor(0.1075, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4164\n",
      "Loss: tensor(0.1075, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4165\n",
      "Loss: tensor(0.1075, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4166\n",
      "Loss: tensor(0.1075, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4167\n",
      "Loss: tensor(0.1075, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4168\n",
      "Loss: tensor(0.1075, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4169\n",
      "Loss: tensor(0.1074, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4170\n",
      "Loss: tensor(0.1074, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4171\n",
      "Loss: tensor(0.1074, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4172\n",
      "Loss: tensor(0.1074, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4173\n",
      "Loss: tensor(0.1074, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4174\n",
      "Loss: tensor(0.1074, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4175\n",
      "Loss: tensor(0.1074, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4176\n",
      "Loss: tensor(0.1074, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4177\n",
      "Loss: tensor(0.1074, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4178\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor(0.1074, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4179\n",
      "Loss: tensor(0.1073, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4180\n",
      "Loss: tensor(0.1073, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4181\n",
      "Loss: tensor(0.1073, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4182\n",
      "Loss: tensor(0.1073, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4183\n",
      "Loss: tensor(0.1073, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4184\n",
      "Loss: tensor(0.1073, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4185\n",
      "Loss: tensor(0.1073, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4186\n",
      "Loss: tensor(0.1073, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4187\n",
      "Loss: tensor(0.1073, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4188\n",
      "Loss: tensor(0.1073, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4189\n",
      "Loss: tensor(0.1072, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4190\n",
      "Loss: tensor(0.1072, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4191\n",
      "Loss: tensor(0.1072, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4192\n",
      "Loss: tensor(0.1072, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4193\n",
      "Loss: tensor(0.1072, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4194\n",
      "Loss: tensor(0.1072, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4195\n",
      "Loss: tensor(0.1072, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4196\n",
      "Loss: tensor(0.1072, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4197\n",
      "Loss: tensor(0.1072, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4198\n",
      "Loss: tensor(0.1072, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4199\n",
      "Loss: tensor(0.1071, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4200\n",
      "Loss: tensor(0.1071, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4201\n",
      "Loss: tensor(0.1071, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4202\n",
      "Loss: tensor(0.1071, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4203\n",
      "Loss: tensor(0.1071, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4204\n",
      "Loss: tensor(0.1071, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4205\n",
      "Loss: tensor(0.1071, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4206\n",
      "Loss: tensor(0.1071, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4207\n",
      "Loss: tensor(0.1071, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4208\n",
      "Loss: tensor(0.1071, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4209\n",
      "Loss: tensor(0.1071, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4210\n",
      "Loss: tensor(0.1070, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4211\n",
      "Loss: tensor(0.1070, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4212\n",
      "Loss: tensor(0.1070, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4213\n",
      "Loss: tensor(0.1070, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4214\n",
      "Loss: tensor(0.1070, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4215\n",
      "Loss: tensor(0.1070, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4216\n",
      "Loss: tensor(0.1070, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4217\n",
      "Loss: tensor(0.1070, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4218\n",
      "Loss: tensor(0.1070, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4219\n",
      "Loss: tensor(0.1070, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4220\n",
      "Loss: tensor(0.1069, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4221\n",
      "Loss: tensor(0.1069, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4222\n",
      "Loss: tensor(0.1069, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4223\n",
      "Loss: tensor(0.1069, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4224\n",
      "Loss: tensor(0.1069, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4225\n",
      "Loss: tensor(0.1069, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4226\n",
      "Loss: tensor(0.1069, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4227\n",
      "Loss: tensor(0.1069, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4228\n",
      "Loss: tensor(0.1069, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4229\n",
      "Loss: tensor(0.1069, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4230\n",
      "Loss: tensor(0.1069, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4231\n",
      "Loss: tensor(0.1068, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4232\n",
      "Loss: tensor(0.1068, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4233\n",
      "Loss: tensor(0.1068, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4234\n",
      "Loss: tensor(0.1068, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4235\n",
      "Loss: tensor(0.1068, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4236\n",
      "Loss: tensor(0.1068, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4237\n",
      "Loss: tensor(0.1068, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4238\n",
      "Loss: tensor(0.1068, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4239\n",
      "Loss: tensor(0.1068, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4240\n",
      "Loss: tensor(0.1068, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4241\n",
      "Loss: tensor(0.1068, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4242\n",
      "Loss: tensor(0.1067, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4243\n",
      "Loss: tensor(0.1067, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4244\n",
      "Loss: tensor(0.1067, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4245\n",
      "Loss: tensor(0.1067, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4246\n",
      "Loss: tensor(0.1067, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4247\n",
      "Loss: tensor(0.1067, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4248\n",
      "Loss: tensor(0.1067, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4249\n",
      "Loss: tensor(0.1067, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4250\n",
      "Loss: tensor(0.1067, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4251\n",
      "Loss: tensor(0.1067, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4252\n",
      "Loss: tensor(0.1067, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4253\n",
      "Loss: tensor(0.1066, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4254\n",
      "Loss: tensor(0.1066, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4255\n",
      "Loss: tensor(0.1066, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4256\n",
      "Loss: tensor(0.1066, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4257\n",
      "Loss: tensor(0.1066, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4258\n",
      "Loss: tensor(0.1066, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4259\n",
      "Loss: tensor(0.1066, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4260\n",
      "Loss: tensor(0.1066, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4261\n",
      "Loss: tensor(0.1066, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4262\n",
      "Loss: tensor(0.1066, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4263\n",
      "Loss: tensor(0.1066, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4264\n",
      "Loss: tensor(0.1065, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4265\n",
      "Loss: tensor(0.1065, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4266\n",
      "Loss: tensor(0.1065, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4267\n",
      "Loss: tensor(0.1065, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4268\n",
      "Loss: tensor(0.1065, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4269\n",
      "Loss: tensor(0.1065, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4270\n",
      "Loss: tensor(0.1065, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4271\n",
      "Loss: tensor(0.1065, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4272\n",
      "Loss: tensor(0.1065, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4273\n",
      "Loss: tensor(0.1065, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4274\n",
      "Loss: tensor(0.1065, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4275\n",
      "Loss: tensor(0.1064, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4276\n",
      "Loss: tensor(0.1064, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4277\n",
      "Loss: tensor(0.1064, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4278\n",
      "Loss: tensor(0.1064, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4279\n",
      "Loss: tensor(0.1064, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4280\n",
      "Loss: tensor(0.1064, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4281\n",
      "Loss: tensor(0.1064, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4282\n",
      "Loss: tensor(0.1064, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4283\n",
      "Loss: tensor(0.1064, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4284\n",
      "Loss: tensor(0.1064, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4285\n",
      "Loss: tensor(0.1064, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4286\n",
      "Loss: tensor(0.1064, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4287\n",
      "Loss: tensor(0.1063, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4288\n",
      "Loss: tensor(0.1063, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4289\n",
      "Loss: tensor(0.1063, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4290\n",
      "Loss: tensor(0.1063, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4291\n",
      "Loss: tensor(0.1063, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4292\n",
      "Loss: tensor(0.1063, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4293\n",
      "Loss: tensor(0.1063, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4294\n",
      "Loss: tensor(0.1063, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4295\n",
      "Loss: tensor(0.1063, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4296\n",
      "Loss: tensor(0.1063, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4297\n",
      "Loss: tensor(0.1063, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4298\n",
      "Loss: tensor(0.1062, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4299\n",
      "Loss: tensor(0.1062, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4300\n",
      "Loss: tensor(0.1062, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4301\n",
      "Loss: tensor(0.1062, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4302\n",
      "Loss: tensor(0.1062, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4303\n",
      "Loss: tensor(0.1062, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4304\n",
      "Loss: tensor(0.1062, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4305\n",
      "Loss: tensor(0.1062, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4306\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor(0.1062, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4307\n",
      "Loss: tensor(0.1062, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4308\n",
      "Loss: tensor(0.1062, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4309\n",
      "Loss: tensor(0.1061, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4310\n",
      "Loss: tensor(0.1061, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4311\n",
      "Loss: tensor(0.1061, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4312\n",
      "Loss: tensor(0.1061, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4313\n",
      "Loss: tensor(0.1061, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4314\n",
      "Loss: tensor(0.1061, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4315\n",
      "Loss: tensor(0.1061, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4316\n",
      "Loss: tensor(0.1061, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4317\n",
      "Loss: tensor(0.1061, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4318\n",
      "Loss: tensor(0.1061, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4319\n",
      "Loss: tensor(0.1061, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4320\n",
      "Loss: tensor(0.1061, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4321\n",
      "Loss: tensor(0.1060, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4322\n",
      "Loss: tensor(0.1060, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4323\n",
      "Loss: tensor(0.1060, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4324\n",
      "Loss: tensor(0.1060, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4325\n",
      "Loss: tensor(0.1060, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4326\n",
      "Loss: tensor(0.1060, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4327\n",
      "Loss: tensor(0.1060, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4328\n",
      "Loss: tensor(0.1060, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4329\n",
      "Loss: tensor(0.1060, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4330\n",
      "Loss: tensor(0.1060, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4331\n",
      "Loss: tensor(0.1060, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4332\n",
      "Loss: tensor(0.1060, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4333\n",
      "Loss: tensor(0.1059, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4334\n",
      "Loss: tensor(0.1059, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4335\n",
      "Loss: tensor(0.1059, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4336\n",
      "Loss: tensor(0.1059, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4337\n",
      "Loss: tensor(0.1059, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4338\n",
      "Loss: tensor(0.1059, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4339\n",
      "Loss: tensor(0.1059, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4340\n",
      "Loss: tensor(0.1059, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4341\n",
      "Loss: tensor(0.1059, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4342\n",
      "Loss: tensor(0.1059, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4343\n",
      "Loss: tensor(0.1059, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4344\n",
      "Loss: tensor(0.1059, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4345\n",
      "Loss: tensor(0.1058, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4346\n",
      "Loss: tensor(0.1058, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4347\n",
      "Loss: tensor(0.1058, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4348\n",
      "Loss: tensor(0.1058, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4349\n",
      "Loss: tensor(0.1058, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4350\n",
      "Loss: tensor(0.1058, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4351\n",
      "Loss: tensor(0.1058, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4352\n",
      "Loss: tensor(0.1058, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4353\n",
      "Loss: tensor(0.1058, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4354\n",
      "Loss: tensor(0.1058, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4355\n",
      "Loss: tensor(0.1058, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4356\n",
      "Loss: tensor(0.1058, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4357\n",
      "Loss: tensor(0.1057, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4358\n",
      "Loss: tensor(0.1057, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4359\n",
      "Loss: tensor(0.1057, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4360\n",
      "Loss: tensor(0.1057, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4361\n",
      "Loss: tensor(0.1057, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4362\n",
      "Loss: tensor(0.1057, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4363\n",
      "Loss: tensor(0.1057, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4364\n",
      "Loss: tensor(0.1057, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4365\n",
      "Loss: tensor(0.1057, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4366\n",
      "Loss: tensor(0.1057, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4367\n",
      "Loss: tensor(0.1057, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4368\n",
      "Loss: tensor(0.1057, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4369\n",
      "Loss: tensor(0.1056, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4370\n",
      "Loss: tensor(0.1056, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4371\n",
      "Loss: tensor(0.1056, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4372\n",
      "Loss: tensor(0.1056, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4373\n",
      "Loss: tensor(0.1056, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4374\n",
      "Loss: tensor(0.1056, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4375\n",
      "Loss: tensor(0.1056, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4376\n",
      "Loss: tensor(0.1056, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4377\n",
      "Loss: tensor(0.1056, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4378\n",
      "Loss: tensor(0.1056, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4379\n",
      "Loss: tensor(0.1056, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4380\n",
      "Loss: tensor(0.1056, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4381\n",
      "Loss: tensor(0.1056, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4382\n",
      "Loss: tensor(0.1056, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4383\n",
      "Loss: tensor(0.1056, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4384\n",
      "Loss: tensor(0.1056, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4385\n",
      "Loss: tensor(0.1056, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4386\n",
      "Loss: tensor(0.1056, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4387\n",
      "Loss: tensor(0.1055, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4388\n",
      "Loss: tensor(0.1055, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4389\n",
      "Loss: tensor(0.1055, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4390\n",
      "Loss: tensor(0.1055, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4391\n",
      "Loss: tensor(0.1055, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4392\n",
      "Loss: tensor(0.1055, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4393\n",
      "Loss: tensor(0.1055, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4394\n",
      "Loss: tensor(0.1054, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4395\n",
      "Loss: tensor(0.1054, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4396\n",
      "Loss: tensor(0.1054, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4397\n",
      "Loss: tensor(0.1054, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4398\n",
      "Loss: tensor(0.1054, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4399\n",
      "Loss: tensor(0.1054, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4400\n",
      "Loss: tensor(0.1054, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4401\n",
      "Loss: tensor(0.1054, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4402\n",
      "Loss: tensor(0.1054, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4403\n",
      "Loss: tensor(0.1054, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4404\n",
      "Loss: tensor(0.1054, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4405\n",
      "Loss: tensor(0.1054, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4406\n",
      "Loss: tensor(0.1054, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4407\n",
      "Loss: tensor(0.1053, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4408\n",
      "Loss: tensor(0.1053, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4409\n",
      "Loss: tensor(0.1053, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4410\n",
      "Loss: tensor(0.1053, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4411\n",
      "Loss: tensor(0.1053, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4412\n",
      "Loss: tensor(0.1053, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4413\n",
      "Loss: tensor(0.1053, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4414\n",
      "Loss: tensor(0.1053, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4415\n",
      "Loss: tensor(0.1053, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4416\n",
      "Loss: tensor(0.1053, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4417\n",
      "Loss: tensor(0.1053, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4418\n",
      "Loss: tensor(0.1053, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4419\n",
      "Loss: tensor(0.1052, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4420\n",
      "Loss: tensor(0.1052, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4421\n",
      "Loss: tensor(0.1052, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4422\n",
      "Loss: tensor(0.1052, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4423\n",
      "Loss: tensor(0.1052, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4424\n",
      "Loss: tensor(0.1052, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4425\n",
      "Loss: tensor(0.1052, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4426\n",
      "Loss: tensor(0.1052, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4427\n",
      "Loss: tensor(0.1052, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4428\n",
      "Loss: tensor(0.1052, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4429\n",
      "Loss: tensor(0.1052, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4430\n",
      "Loss: tensor(0.1052, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4431\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor(0.1052, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4432\n",
      "Loss: tensor(0.1051, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4433\n",
      "Loss: tensor(0.1051, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4434\n",
      "Loss: tensor(0.1051, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4435\n",
      "Loss: tensor(0.1051, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4436\n",
      "Loss: tensor(0.1051, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4437\n",
      "Loss: tensor(0.1051, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4438\n",
      "Loss: tensor(0.1051, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4439\n",
      "Loss: tensor(0.1051, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4440\n",
      "Loss: tensor(0.1051, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4441\n",
      "Loss: tensor(0.1051, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4442\n",
      "Loss: tensor(0.1051, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4443\n",
      "Loss: tensor(0.1051, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4444\n",
      "Loss: tensor(0.1051, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4445\n",
      "Loss: tensor(0.1050, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4446\n",
      "Loss: tensor(0.1050, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4447\n",
      "Loss: tensor(0.1050, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4448\n",
      "Loss: tensor(0.1050, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4449\n",
      "Loss: tensor(0.1050, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4450\n",
      "Loss: tensor(0.1050, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4451\n",
      "Loss: tensor(0.1050, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4452\n",
      "Loss: tensor(0.1050, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4453\n",
      "Loss: tensor(0.1050, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4454\n",
      "Loss: tensor(0.1050, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4455\n",
      "Loss: tensor(0.1050, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4456\n",
      "Loss: tensor(0.1050, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4457\n",
      "Loss: tensor(0.1050, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4458\n",
      "Loss: tensor(0.1049, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4459\n",
      "Loss: tensor(0.1049, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4460\n",
      "Loss: tensor(0.1049, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4461\n",
      "Loss: tensor(0.1049, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4462\n",
      "Loss: tensor(0.1049, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4463\n",
      "Loss: tensor(0.1049, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4464\n",
      "Loss: tensor(0.1049, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4465\n",
      "Loss: tensor(0.1049, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4466\n",
      "Loss: tensor(0.1049, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4467\n",
      "Loss: tensor(0.1049, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4468\n",
      "Loss: tensor(0.1049, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4469\n",
      "Loss: tensor(0.1049, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4470\n",
      "Loss: tensor(0.1049, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4471\n",
      "Loss: tensor(0.1049, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4472\n",
      "Loss: tensor(0.1049, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4473\n",
      "Loss: tensor(0.1049, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4474\n",
      "Loss: tensor(0.1049, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4475\n",
      "Loss: tensor(0.1048, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4476\n",
      "Loss: tensor(0.1048, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4477\n",
      "Loss: tensor(0.1048, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4478\n",
      "Loss: tensor(0.1048, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4479\n",
      "Loss: tensor(0.1048, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4480\n",
      "Loss: tensor(0.1048, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4481\n",
      "Loss: tensor(0.1048, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4482\n",
      "Loss: tensor(0.1048, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4483\n",
      "Loss: tensor(0.1048, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4484\n",
      "Loss: tensor(0.1048, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4485\n",
      "Loss: tensor(0.1048, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4486\n",
      "Loss: tensor(0.1047, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4487\n",
      "Loss: tensor(0.1047, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4488\n",
      "Loss: tensor(0.1047, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4489\n",
      "Loss: tensor(0.1047, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4490\n",
      "Loss: tensor(0.1047, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4491\n",
      "Loss: tensor(0.1047, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4492\n",
      "Loss: tensor(0.1047, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4493\n",
      "Loss: tensor(0.1047, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4494\n",
      "Loss: tensor(0.1047, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4495\n",
      "Loss: tensor(0.1047, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4496\n",
      "Loss: tensor(0.1047, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4497\n",
      "Loss: tensor(0.1047, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4498\n",
      "Loss: tensor(0.1047, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4499\n",
      "Loss: tensor(0.1046, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4500\n",
      "Loss: tensor(0.1046, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4501\n",
      "Loss: tensor(0.1046, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4502\n",
      "Loss: tensor(0.1046, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4503\n",
      "Loss: tensor(0.1046, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4504\n",
      "Loss: tensor(0.1046, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4505\n",
      "Loss: tensor(0.1046, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4506\n",
      "Loss: tensor(0.1046, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4507\n",
      "Loss: tensor(0.1046, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4508\n",
      "Loss: tensor(0.1046, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4509\n",
      "Loss: tensor(0.1046, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4510\n",
      "Loss: tensor(0.1046, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4511\n",
      "Loss: tensor(0.1046, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4512\n",
      "Loss: tensor(0.1046, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4513\n",
      "Loss: tensor(0.1045, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4514\n",
      "Loss: tensor(0.1045, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4515\n",
      "Loss: tensor(0.1045, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4516\n",
      "Loss: tensor(0.1045, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4517\n",
      "Loss: tensor(0.1045, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4518\n",
      "Loss: tensor(0.1045, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4519\n",
      "Loss: tensor(0.1045, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4520\n",
      "Loss: tensor(0.1045, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4521\n",
      "Loss: tensor(0.1045, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4522\n",
      "Loss: tensor(0.1045, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4523\n",
      "Loss: tensor(0.1045, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4524\n",
      "Loss: tensor(0.1045, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4525\n",
      "Loss: tensor(0.1045, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4526\n",
      "Loss: tensor(0.1045, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4527\n",
      "Loss: tensor(0.1044, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4528\n",
      "Loss: tensor(0.1044, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4529\n",
      "Loss: tensor(0.1044, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4530\n",
      "Loss: tensor(0.1044, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4531\n",
      "Loss: tensor(0.1044, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4532\n",
      "Loss: tensor(0.1044, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4533\n",
      "Loss: tensor(0.1044, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4534\n",
      "Loss: tensor(0.1044, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4535\n",
      "Loss: tensor(0.1044, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4536\n",
      "Loss: tensor(0.1044, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4537\n",
      "Loss: tensor(0.1044, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4538\n",
      "Loss: tensor(0.1044, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4539\n",
      "Loss: tensor(0.1044, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4540\n",
      "Loss: tensor(0.1044, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4541\n",
      "Loss: tensor(0.1044, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4542\n",
      "Loss: tensor(0.1043, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4543\n",
      "Loss: tensor(0.1043, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4544\n",
      "Loss: tensor(0.1043, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4545\n",
      "Loss: tensor(0.1043, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4546\n",
      "Loss: tensor(0.1043, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4547\n",
      "Loss: tensor(0.1043, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4548\n",
      "Loss: tensor(0.1043, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4549\n",
      "Loss: tensor(0.1043, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4550\n",
      "Loss: tensor(0.1043, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4551\n",
      "Loss: tensor(0.1043, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4552\n",
      "Loss: tensor(0.1043, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4553\n",
      "Loss: tensor(0.1043, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4554\n",
      "Loss: tensor(0.1043, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4555\n",
      "Loss: tensor(0.1043, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4556\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor(0.1042, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4557\n",
      "Loss: tensor(0.1042, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4558\n",
      "Loss: tensor(0.1042, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4559\n",
      "Loss: tensor(0.1042, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4560\n",
      "Loss: tensor(0.1042, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4561\n",
      "Loss: tensor(0.1042, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4562\n",
      "Loss: tensor(0.1042, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4563\n",
      "Loss: tensor(0.1042, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4564\n",
      "Loss: tensor(0.1042, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4565\n",
      "Loss: tensor(0.1042, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4566\n",
      "Loss: tensor(0.1042, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4567\n",
      "Loss: tensor(0.1042, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4568\n",
      "Loss: tensor(0.1042, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4569\n",
      "Loss: tensor(0.1042, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4570\n",
      "Loss: tensor(0.1042, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4571\n",
      "Loss: tensor(0.1041, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4572\n",
      "Loss: tensor(0.1041, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4573\n",
      "Loss: tensor(0.1041, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4574\n",
      "Loss: tensor(0.1041, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4575\n",
      "Loss: tensor(0.1041, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4576\n",
      "Loss: tensor(0.1041, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4577\n",
      "Loss: tensor(0.1041, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4578\n",
      "Loss: tensor(0.1041, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4579\n",
      "Loss: tensor(0.1041, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4580\n",
      "Loss: tensor(0.1041, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4581\n",
      "Loss: tensor(0.1041, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4582\n",
      "Loss: tensor(0.1041, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4583\n",
      "Loss: tensor(0.1041, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4584\n",
      "Loss: tensor(0.1041, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4585\n",
      "Loss: tensor(0.1040, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4586\n",
      "Loss: tensor(0.1040, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4587\n",
      "Loss: tensor(0.1040, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4588\n",
      "Loss: tensor(0.1040, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4589\n",
      "Loss: tensor(0.1040, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4590\n",
      "Loss: tensor(0.1040, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4591\n",
      "Loss: tensor(0.1040, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4592\n",
      "Loss: tensor(0.1040, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4593\n",
      "Loss: tensor(0.1040, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4594\n",
      "Loss: tensor(0.1040, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4595\n",
      "Loss: tensor(0.1040, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4596\n",
      "Loss: tensor(0.1040, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4597\n",
      "Loss: tensor(0.1040, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4598\n",
      "Loss: tensor(0.1040, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4599\n",
      "Loss: tensor(0.1040, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4600\n",
      "Loss: tensor(0.1040, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4601\n",
      "Loss: tensor(0.1039, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4602\n",
      "Loss: tensor(0.1039, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4603\n",
      "Loss: tensor(0.1039, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4604\n",
      "Loss: tensor(0.1039, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4605\n",
      "Loss: tensor(0.1039, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4606\n",
      "Loss: tensor(0.1039, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4607\n",
      "Loss: tensor(0.1039, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4608\n",
      "Loss: tensor(0.1039, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4609\n",
      "Loss: tensor(0.1039, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4610\n",
      "Loss: tensor(0.1039, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4611\n",
      "Loss: tensor(0.1039, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4612\n",
      "Loss: tensor(0.1039, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4613\n",
      "Loss: tensor(0.1039, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4614\n",
      "Loss: tensor(0.1039, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4615\n",
      "Loss: tensor(0.1039, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4616\n",
      "Loss: tensor(0.1039, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4617\n",
      "Loss: tensor(0.1038, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4618\n",
      "Loss: tensor(0.1038, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4619\n",
      "Loss: tensor(0.1038, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4620\n",
      "Loss: tensor(0.1038, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4621\n",
      "Loss: tensor(0.1038, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4622\n",
      "Loss: tensor(0.1038, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4623\n",
      "Loss: tensor(0.1038, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4624\n",
      "Loss: tensor(0.1038, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4625\n",
      "Loss: tensor(0.1038, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4626\n",
      "Loss: tensor(0.1038, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4627\n",
      "Loss: tensor(0.1038, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4628\n",
      "Loss: tensor(0.1038, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4629\n",
      "Loss: tensor(0.1038, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4630\n",
      "Loss: tensor(0.1038, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4631\n",
      "Loss: tensor(0.1037, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4632\n",
      "Loss: tensor(0.1037, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4633\n",
      "Loss: tensor(0.1037, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4634\n",
      "Loss: tensor(0.1037, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4635\n",
      "Loss: tensor(0.1037, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4636\n",
      "Loss: tensor(0.1037, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4637\n",
      "Loss: tensor(0.1037, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4638\n",
      "Loss: tensor(0.1037, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4639\n",
      "Loss: tensor(0.1037, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4640\n",
      "Loss: tensor(0.1037, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4641\n",
      "Loss: tensor(0.1037, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4642\n",
      "Loss: tensor(0.1037, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4643\n",
      "Loss: tensor(0.1037, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4644\n",
      "Loss: tensor(0.1037, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4645\n",
      "Loss: tensor(0.1037, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4646\n",
      "Loss: tensor(0.1037, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4647\n",
      "Loss: tensor(0.1036, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4648\n",
      "Loss: tensor(0.1036, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4649\n",
      "Loss: tensor(0.1036, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4650\n",
      "Loss: tensor(0.1036, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4651\n",
      "Loss: tensor(0.1036, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4652\n",
      "Loss: tensor(0.1036, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4653\n",
      "Loss: tensor(0.1036, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4654\n",
      "Loss: tensor(0.1036, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4655\n",
      "Loss: tensor(0.1036, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4656\n",
      "Loss: tensor(0.1036, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4657\n",
      "Loss: tensor(0.1036, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4658\n",
      "Loss: tensor(0.1036, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4659\n",
      "Loss: tensor(0.1036, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4660\n",
      "Loss: tensor(0.1036, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4661\n",
      "Loss: tensor(0.1036, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4662\n",
      "Loss: tensor(0.1036, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4663\n",
      "Loss: tensor(0.1035, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4664\n",
      "Loss: tensor(0.1035, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4665\n",
      "Loss: tensor(0.1035, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4666\n",
      "Loss: tensor(0.1035, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4667\n",
      "Loss: tensor(0.1035, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4668\n",
      "Loss: tensor(0.1035, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4669\n",
      "Loss: tensor(0.1035, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4670\n",
      "Loss: tensor(0.1035, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4671\n",
      "Loss: tensor(0.1035, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4672\n",
      "Loss: tensor(0.1035, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4673\n",
      "Loss: tensor(0.1035, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4674\n",
      "Loss: tensor(0.1035, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4675\n",
      "Loss: tensor(0.1035, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4676\n",
      "Loss: tensor(0.1035, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4677\n",
      "Loss: tensor(0.1035, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4678\n",
      "Loss: tensor(0.1035, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4679\n",
      "Loss: tensor(0.1035, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4680\n",
      "Loss: tensor(0.1035, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4681\n",
      "Loss: tensor(0.1035, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4682\n",
      "Loss: tensor(0.1035, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4683\n",
      "Loss: tensor(0.1035, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4684\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor(0.1035, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4685\n",
      "Loss: tensor(0.1034, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4686\n",
      "Loss: tensor(0.1034, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4687\n",
      "Loss: tensor(0.1034, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4688\n",
      "Loss: tensor(0.1034, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4689\n",
      "Loss: tensor(0.1034, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4690\n",
      "Loss: tensor(0.1034, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4691\n",
      "Loss: tensor(0.1034, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4692\n",
      "Loss: tensor(0.1034, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4693\n",
      "Loss: tensor(0.1034, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4694\n",
      "Loss: tensor(0.1034, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4695\n",
      "Loss: tensor(0.1034, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4696\n",
      "Loss: tensor(0.1033, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4697\n",
      "Loss: tensor(0.1033, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4698\n",
      "Loss: tensor(0.1033, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4699\n",
      "Loss: tensor(0.1033, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4700\n",
      "Loss: tensor(0.1033, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4701\n",
      "Loss: tensor(0.1033, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4702\n",
      "Loss: tensor(0.1033, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4703\n",
      "Loss: tensor(0.1033, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4704\n",
      "Loss: tensor(0.1033, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4705\n",
      "Loss: tensor(0.1033, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4706\n",
      "Loss: tensor(0.1033, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4707\n",
      "Loss: tensor(0.1033, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4708\n",
      "Loss: tensor(0.1033, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4709\n",
      "Loss: tensor(0.1033, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4710\n",
      "Loss: tensor(0.1033, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4711\n",
      "Loss: tensor(0.1033, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4712\n",
      "Loss: tensor(0.1033, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4713\n",
      "Loss: tensor(0.1032, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4714\n",
      "Loss: tensor(0.1032, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4715\n",
      "Loss: tensor(0.1032, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4716\n",
      "Loss: tensor(0.1032, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4717\n",
      "Loss: tensor(0.1032, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4718\n",
      "Loss: tensor(0.1032, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4719\n",
      "Loss: tensor(0.1032, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4720\n",
      "Loss: tensor(0.1032, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4721\n",
      "Loss: tensor(0.1032, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4722\n",
      "Loss: tensor(0.1032, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4723\n",
      "Loss: tensor(0.1032, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4724\n",
      "Loss: tensor(0.1032, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4725\n",
      "Loss: tensor(0.1032, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4726\n",
      "Loss: tensor(0.1032, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4727\n",
      "Loss: tensor(0.1032, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4728\n",
      "Loss: tensor(0.1032, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4729\n",
      "Loss: tensor(0.1031, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4730\n",
      "Loss: tensor(0.1031, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4731\n",
      "Loss: tensor(0.1031, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4732\n",
      "Loss: tensor(0.1031, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4733\n",
      "Loss: tensor(0.1031, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4734\n",
      "Loss: tensor(0.1031, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4735\n",
      "Loss: tensor(0.1031, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4736\n",
      "Loss: tensor(0.1031, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4737\n",
      "Loss: tensor(0.1031, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4738\n",
      "Loss: tensor(0.1031, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4739\n",
      "Loss: tensor(0.1031, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4740\n",
      "Loss: tensor(0.1031, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4741\n",
      "Loss: tensor(0.1031, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4742\n",
      "Loss: tensor(0.1031, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4743\n",
      "Loss: tensor(0.1031, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4744\n",
      "Loss: tensor(0.1031, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4745\n",
      "Loss: tensor(0.1031, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4746\n",
      "Loss: tensor(0.1031, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4747\n",
      "Loss: tensor(0.1030, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4748\n",
      "Loss: tensor(0.1030, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4749\n",
      "Loss: tensor(0.1030, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4750\n",
      "Loss: tensor(0.1030, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4751\n",
      "Loss: tensor(0.1030, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4752\n",
      "Loss: tensor(0.1030, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4753\n",
      "Loss: tensor(0.1030, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4754\n",
      "Loss: tensor(0.1030, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4755\n",
      "Loss: tensor(0.1030, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4756\n",
      "Loss: tensor(0.1030, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4757\n",
      "Loss: tensor(0.1030, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4758\n",
      "Loss: tensor(0.1030, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4759\n",
      "Loss: tensor(0.1030, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4760\n",
      "Loss: tensor(0.1030, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4761\n",
      "Loss: tensor(0.1030, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4762\n",
      "Loss: tensor(0.1030, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4763\n",
      "Loss: tensor(0.1030, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4764\n",
      "Loss: tensor(0.1029, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4765\n",
      "Loss: tensor(0.1029, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4766\n",
      "Loss: tensor(0.1029, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4767\n",
      "Loss: tensor(0.1029, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4768\n",
      "Loss: tensor(0.1029, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4769\n",
      "Loss: tensor(0.1029, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4770\n",
      "Loss: tensor(0.1029, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4771\n",
      "Loss: tensor(0.1029, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4772\n",
      "Loss: tensor(0.1029, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4773\n",
      "Loss: tensor(0.1029, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4774\n",
      "Loss: tensor(0.1029, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4775\n",
      "Loss: tensor(0.1029, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4776\n",
      "Loss: tensor(0.1029, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4777\n",
      "Loss: tensor(0.1029, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4778\n",
      "Loss: tensor(0.1029, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4779\n",
      "Loss: tensor(0.1029, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4780\n",
      "Loss: tensor(0.1029, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4781\n",
      "Loss: tensor(0.1029, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4782\n",
      "Loss: tensor(0.1028, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4783\n",
      "Loss: tensor(0.1028, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4784\n",
      "Loss: tensor(0.1028, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4785\n",
      "Loss: tensor(0.1028, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4786\n",
      "Loss: tensor(0.1028, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4787\n",
      "Loss: tensor(0.1028, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4788\n",
      "Loss: tensor(0.1028, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4789\n",
      "Loss: tensor(0.1028, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4790\n",
      "Loss: tensor(0.1028, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4791\n",
      "Loss: tensor(0.1028, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4792\n",
      "Loss: tensor(0.1028, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4793\n",
      "Loss: tensor(0.1028, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4794\n",
      "Loss: tensor(0.1028, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4795\n",
      "Loss: tensor(0.1028, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4796\n",
      "Loss: tensor(0.1028, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4797\n",
      "Loss: tensor(0.1028, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4798\n",
      "Loss: tensor(0.1028, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4799\n",
      "Loss: tensor(0.1028, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4800\n",
      "Loss: tensor(0.1027, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4801\n",
      "Loss: tensor(0.1027, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4802\n",
      "Loss: tensor(0.1027, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4803\n",
      "Loss: tensor(0.1027, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4804\n",
      "Loss: tensor(0.1027, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4805\n",
      "Loss: tensor(0.1027, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4806\n",
      "Loss: tensor(0.1027, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4807\n",
      "Loss: tensor(0.1027, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4808\n",
      "Loss: tensor(0.1027, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4809\n",
      "Loss: tensor(0.1027, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4810\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor(0.1027, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4811\n",
      "Loss: tensor(0.1027, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4812\n",
      "Loss: tensor(0.1027, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4813\n",
      "Loss: tensor(0.1027, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4814\n",
      "Loss: tensor(0.1027, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4815\n",
      "Loss: tensor(0.1027, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4816\n",
      "Loss: tensor(0.1027, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4817\n",
      "Loss: tensor(0.1027, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4818\n",
      "Loss: tensor(0.1027, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4819\n",
      "Loss: tensor(0.1027, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4820\n",
      "Loss: tensor(0.1027, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4821\n",
      "Loss: tensor(0.1027, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4822\n",
      "Loss: tensor(0.1027, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4823\n",
      "Loss: tensor(0.1026, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4824\n",
      "Loss: tensor(0.1026, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4825\n",
      "Loss: tensor(0.1026, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4826\n",
      "Loss: tensor(0.1026, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4827\n",
      "Loss: tensor(0.1026, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4828\n",
      "Loss: tensor(0.1026, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4829\n",
      "Loss: tensor(0.1026, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4830\n",
      "Loss: tensor(0.1026, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4831\n",
      "Loss: tensor(0.1026, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4832\n",
      "Loss: tensor(0.1026, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4833\n",
      "Loss: tensor(0.1026, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4834\n",
      "Loss: tensor(0.1026, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4835\n",
      "Loss: tensor(0.1026, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4836\n",
      "Loss: tensor(0.1026, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4837\n",
      "Loss: tensor(0.1026, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4838\n",
      "Loss: tensor(0.1025, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4839\n",
      "Loss: tensor(0.1025, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4840\n",
      "Loss: tensor(0.1025, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4841\n",
      "Loss: tensor(0.1025, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4842\n",
      "Loss: tensor(0.1025, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4843\n",
      "Loss: tensor(0.1025, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4844\n",
      "Loss: tensor(0.1025, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4845\n",
      "Loss: tensor(0.1025, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4846\n",
      "Loss: tensor(0.1025, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4847\n",
      "Loss: tensor(0.1025, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4848\n",
      "Loss: tensor(0.1025, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4849\n",
      "Loss: tensor(0.1025, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4850\n",
      "Loss: tensor(0.1025, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4851\n",
      "Loss: tensor(0.1025, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4852\n",
      "Loss: tensor(0.1025, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4853\n",
      "Loss: tensor(0.1025, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4854\n",
      "Loss: tensor(0.1025, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4855\n",
      "Loss: tensor(0.1025, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4856\n",
      "Loss: tensor(0.1024, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4857\n",
      "Loss: tensor(0.1024, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4858\n",
      "Loss: tensor(0.1024, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4859\n",
      "Loss: tensor(0.1024, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4860\n",
      "Loss: tensor(0.1024, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4861\n",
      "Loss: tensor(0.1024, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4862\n",
      "Loss: tensor(0.1024, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4863\n",
      "Loss: tensor(0.1024, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4864\n",
      "Loss: tensor(0.1024, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4865\n",
      "Loss: tensor(0.1024, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4866\n",
      "Loss: tensor(0.1024, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4867\n",
      "Loss: tensor(0.1024, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4868\n",
      "Loss: tensor(0.1024, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4869\n",
      "Loss: tensor(0.1024, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4870\n",
      "Loss: tensor(0.1024, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4871\n",
      "Loss: tensor(0.1024, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4872\n",
      "Loss: tensor(0.1024, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4873\n",
      "Loss: tensor(0.1024, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4874\n",
      "Loss: tensor(0.1024, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4875\n",
      "Loss: tensor(0.1024, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4876\n",
      "Loss: tensor(0.1023, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4877\n",
      "Loss: tensor(0.1023, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4878\n",
      "Loss: tensor(0.1023, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4879\n",
      "Loss: tensor(0.1023, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4880\n",
      "Loss: tensor(0.1023, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4881\n",
      "Loss: tensor(0.1023, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4882\n",
      "Loss: tensor(0.1023, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4883\n",
      "Loss: tensor(0.1023, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4884\n",
      "Loss: tensor(0.1023, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4885\n",
      "Loss: tensor(0.1023, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4886\n",
      "Loss: tensor(0.1023, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4887\n",
      "Loss: tensor(0.1023, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4888\n",
      "Loss: tensor(0.1023, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4889\n",
      "Loss: tensor(0.1023, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4890\n",
      "Loss: tensor(0.1023, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4891\n",
      "Loss: tensor(0.1023, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4892\n",
      "Loss: tensor(0.1023, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4893\n",
      "Loss: tensor(0.1023, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4894\n",
      "Loss: tensor(0.1023, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4895\n",
      "Loss: tensor(0.1023, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4896\n",
      "Loss: tensor(0.1023, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4897\n",
      "Loss: tensor(0.1023, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4898\n",
      "Loss: tensor(0.1023, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4899\n",
      "Loss: tensor(0.1023, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4900\n",
      "Loss: tensor(0.1023, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4901\n",
      "Loss: tensor(0.1022, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4902\n",
      "Loss: tensor(0.1022, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4903\n",
      "Loss: tensor(0.1022, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4904\n",
      "Loss: tensor(0.1022, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4905\n",
      "Loss: tensor(0.1022, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4906\n",
      "Loss: tensor(0.1022, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4907\n",
      "Loss: tensor(0.1022, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4908\n",
      "Loss: tensor(0.1022, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4909\n",
      "Loss: tensor(0.1022, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4910\n",
      "Loss: tensor(0.1022, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4911\n",
      "Loss: tensor(0.1022, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4912\n",
      "Loss: tensor(0.1022, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4913\n",
      "Loss: tensor(0.1022, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4914\n",
      "Loss: tensor(0.1022, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4915\n",
      "Loss: tensor(0.1022, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4916\n",
      "Loss: tensor(0.1021, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4917\n",
      "Loss: tensor(0.1021, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4918\n",
      "Loss: tensor(0.1021, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4919\n",
      "Loss: tensor(0.1021, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4920\n",
      "Loss: tensor(0.1021, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4921\n",
      "Loss: tensor(0.1021, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4922\n",
      "Loss: tensor(0.1021, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4923\n",
      "Loss: tensor(0.1021, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4924\n",
      "Loss: tensor(0.1021, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4925\n",
      "Loss: tensor(0.1021, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4926\n",
      "Loss: tensor(0.1021, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4927\n",
      "Loss: tensor(0.1021, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4928\n",
      "Loss: tensor(0.1021, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4929\n",
      "Loss: tensor(0.1021, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4930\n",
      "Loss: tensor(0.1021, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4931\n",
      "Loss: tensor(0.1021, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4932\n",
      "Loss: tensor(0.1021, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4933\n",
      "Loss: tensor(0.1021, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4934\n",
      "Loss: tensor(0.1021, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4935\n",
      "Loss: tensor(0.1021, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4936\n",
      "Loss: tensor(0.1020, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4937\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor(0.1020, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4938\n",
      "Loss: tensor(0.1020, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4939\n",
      "Loss: tensor(0.1020, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4940\n",
      "Loss: tensor(0.1020, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4941\n",
      "Loss: tensor(0.1020, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4942\n",
      "Loss: tensor(0.1020, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4943\n",
      "Loss: tensor(0.1020, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4944\n",
      "Loss: tensor(0.1020, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4945\n",
      "Loss: tensor(0.1020, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4946\n",
      "Loss: tensor(0.1020, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4947\n",
      "Loss: tensor(0.1020, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4948\n",
      "Loss: tensor(0.1020, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4949\n",
      "Loss: tensor(0.1020, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4950\n",
      "Loss: tensor(0.1020, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4951\n",
      "Loss: tensor(0.1020, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4952\n",
      "Loss: tensor(0.1020, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4953\n",
      "Loss: tensor(0.1020, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4954\n",
      "Loss: tensor(0.1020, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4955\n",
      "Loss: tensor(0.1020, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4956\n",
      "Loss: tensor(0.1020, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4957\n",
      "Loss: tensor(0.1019, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4958\n",
      "Loss: tensor(0.1019, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4959\n",
      "Loss: tensor(0.1019, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4960\n",
      "Loss: tensor(0.1019, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4961\n",
      "Loss: tensor(0.1019, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4962\n",
      "Loss: tensor(0.1019, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4963\n",
      "Loss: tensor(0.1019, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4964\n",
      "Loss: tensor(0.1019, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4965\n",
      "Loss: tensor(0.1019, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4966\n",
      "Loss: tensor(0.1019, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4967\n",
      "Loss: tensor(0.1019, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4968\n",
      "Loss: tensor(0.1019, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4969\n",
      "Loss: tensor(0.1019, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4970\n",
      "Loss: tensor(0.1019, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4971\n",
      "Loss: tensor(0.1019, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4972\n",
      "Loss: tensor(0.1019, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4973\n",
      "Loss: tensor(0.1019, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4974\n",
      "Loss: tensor(0.1019, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4975\n",
      "Loss: tensor(0.1019, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4976\n",
      "Loss: tensor(0.1019, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4977\n",
      "Loss: tensor(0.1019, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4978\n",
      "Loss: tensor(0.1019, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4979\n",
      "Loss: tensor(0.1018, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4980\n",
      "Loss: tensor(0.1018, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4981\n",
      "Loss: tensor(0.1018, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4982\n",
      "Loss: tensor(0.1018, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4983\n",
      "Loss: tensor(0.1018, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4984\n",
      "Loss: tensor(0.1018, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4985\n",
      "Loss: tensor(0.1018, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4986\n",
      "Loss: tensor(0.1018, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4987\n",
      "Loss: tensor(0.1018, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4988\n",
      "Loss: tensor(0.1018, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4989\n",
      "Loss: tensor(0.1018, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4990\n",
      "Loss: tensor(0.1018, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4991\n",
      "Loss: tensor(0.1018, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4992\n",
      "Loss: tensor(0.1018, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4993\n",
      "Loss: tensor(0.1018, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4994\n",
      "Loss: tensor(0.1018, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4995\n",
      "Loss: tensor(0.1018, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4996\n",
      "Loss: tensor(0.1018, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4997\n",
      "Loss: tensor(0.1018, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4998\n",
      "Loss: tensor(0.1018, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4999\n",
      "Loss: tensor(0.1018, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5000\n",
      "Loss: tensor(0.1018, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5001\n",
      "Loss: tensor(0.1017, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5002\n",
      "Loss: tensor(0.1017, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5003\n",
      "Loss: tensor(0.1017, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5004\n",
      "Loss: tensor(0.1017, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5005\n",
      "Loss: tensor(0.1017, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5006\n",
      "Loss: tensor(0.1017, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5007\n",
      "Loss: tensor(0.1017, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5008\n",
      "Loss: tensor(0.1017, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5009\n",
      "Loss: tensor(0.1017, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5010\n",
      "Loss: tensor(0.1017, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5011\n",
      "Loss: tensor(0.1017, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5012\n",
      "Loss: tensor(0.1017, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5013\n",
      "Loss: tensor(0.1017, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5014\n",
      "Loss: tensor(0.1017, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5015\n",
      "Loss: tensor(0.1017, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5016\n",
      "Loss: tensor(0.1017, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5017\n",
      "Loss: tensor(0.1017, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5018\n",
      "Loss: tensor(0.1017, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5019\n",
      "Loss: tensor(0.1017, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5020\n",
      "Loss: tensor(0.1017, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5021\n",
      "Loss: tensor(0.1017, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5022\n",
      "Loss: tensor(0.1017, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5023\n",
      "Loss: tensor(0.1017, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5024\n",
      "Loss: tensor(0.1016, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5025\n",
      "Loss: tensor(0.1016, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5026\n",
      "Loss: tensor(0.1016, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5027\n",
      "Loss: tensor(0.1016, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5028\n",
      "Loss: tensor(0.1016, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5029\n",
      "Loss: tensor(0.1016, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5030\n",
      "Loss: tensor(0.1016, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5031\n",
      "Loss: tensor(0.1016, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5032\n",
      "Loss: tensor(0.1016, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5033\n",
      "Loss: tensor(0.1016, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5034\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor(0.1016, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5035\n",
      "Loss: tensor(0.1016, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5036\n",
      "Loss: tensor(0.1016, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5037\n",
      "Loss: tensor(0.1016, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5038\n",
      "Loss: tensor(0.1016, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5039\n",
      "Loss: tensor(0.1016, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5040\n",
      "Loss: tensor(0.1016, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5041\n",
      "Loss: tensor(0.1016, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5042\n",
      "Loss: tensor(0.1016, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5043\n",
      "Loss: tensor(0.1016, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5044\n",
      "Loss: tensor(0.1016, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5045\n",
      "Loss: tensor(0.1016, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5046\n",
      "Loss: tensor(0.1016, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5047\n",
      "Loss: tensor(0.1015, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5048\n",
      "Loss: tensor(0.1015, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5049\n",
      "Loss: tensor(0.1015, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5050\n",
      "Loss: tensor(0.1015, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5051\n",
      "Loss: tensor(0.1015, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5052\n",
      "Loss: tensor(0.1015, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5053\n",
      "Loss: tensor(0.1015, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5054\n",
      "Loss: tensor(0.1015, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5055\n",
      "Loss: tensor(0.1015, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5056\n",
      "Loss: tensor(0.1015, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5057\n",
      "Loss: tensor(0.1015, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5058\n",
      "Loss: tensor(0.1015, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5059\n",
      "Loss: tensor(0.1015, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5060\n",
      "Loss: tensor(0.1015, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5061\n",
      "Loss: tensor(0.1015, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5062\n",
      "Loss: tensor(0.1015, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5063\n",
      "Loss: tensor(0.1015, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5064\n",
      "Loss: tensor(0.1015, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5065\n",
      "Loss: tensor(0.1015, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5066\n",
      "Loss: tensor(0.1015, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5067\n",
      "Loss: tensor(0.1015, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5068\n",
      "Loss: tensor(0.1015, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5069\n",
      "Loss: tensor(0.1015, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5070\n",
      "Loss: tensor(0.1014, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5071\n",
      "Loss: tensor(0.1014, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5072\n",
      "Loss: tensor(0.1014, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5073\n",
      "Loss: tensor(0.1014, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5074\n",
      "Loss: tensor(0.1014, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5075\n",
      "Loss: tensor(0.1014, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5076\n",
      "Loss: tensor(0.1014, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5077\n",
      "Loss: tensor(0.1014, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5078\n",
      "Loss: tensor(0.1014, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5079\n",
      "Loss: tensor(0.1014, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5080\n",
      "Loss: tensor(0.1014, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5081\n",
      "Loss: tensor(0.1014, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5082\n",
      "Loss: tensor(0.1014, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5083\n",
      "Loss: tensor(0.1014, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5084\n",
      "Loss: tensor(0.1014, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5085\n",
      "Loss: tensor(0.1014, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5086\n",
      "Loss: tensor(0.1014, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5087\n",
      "Loss: tensor(0.1014, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5088\n",
      "Loss: tensor(0.1014, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5089\n",
      "Loss: tensor(0.1014, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5090\n",
      "Loss: tensor(0.1014, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5091\n",
      "Loss: tensor(0.1014, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5092\n",
      "Loss: tensor(0.1014, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5093\n",
      "Loss: tensor(0.1014, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5094\n",
      "Loss: tensor(0.1014, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5095\n",
      "Loss: tensor(0.1013, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5096\n",
      "Loss: tensor(0.1013, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5097\n",
      "Loss: tensor(0.1013, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5098\n",
      "Loss: tensor(0.1013, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5099\n",
      "Loss: tensor(0.1013, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5100\n",
      "Loss: tensor(0.1013, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5101\n",
      "Loss: tensor(0.1013, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5102\n",
      "Loss: tensor(0.1013, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5103\n",
      "Loss: tensor(0.1013, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5104\n",
      "Loss: tensor(0.1013, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5105\n",
      "Loss: tensor(0.1013, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5106\n",
      "Loss: tensor(0.1013, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5107\n",
      "Loss: tensor(0.1013, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5108\n",
      "Loss: tensor(0.1013, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5109\n",
      "Loss: tensor(0.1013, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5110\n",
      "Loss: tensor(0.1013, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5111\n",
      "Loss: tensor(0.1013, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5112\n",
      "Loss: tensor(0.1013, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5113\n",
      "Loss: tensor(0.1013, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5114\n",
      "Loss: tensor(0.1013, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5115\n",
      "Loss: tensor(0.1013, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5116\n",
      "Loss: tensor(0.1013, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5117\n",
      "Loss: tensor(0.1013, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5118\n",
      "Loss: tensor(0.1013, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5119\n",
      "Loss: tensor(0.1013, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5120\n",
      "Loss: tensor(0.1012, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5121\n",
      "Loss: tensor(0.1012, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5122\n",
      "Loss: tensor(0.1012, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5123\n",
      "Loss: tensor(0.1012, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5124\n",
      "Loss: tensor(0.1012, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5125\n",
      "Loss: tensor(0.1012, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5126\n",
      "Loss: tensor(0.1012, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5127\n",
      "Loss: tensor(0.1012, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5128\n",
      "Loss: tensor(0.1012, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5129\n",
      "Loss: tensor(0.1012, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5130\n",
      "Loss: tensor(0.1012, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5131\n",
      "Loss: tensor(0.1012, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5132\n",
      "Loss: tensor(0.1012, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5133\n",
      "Loss: tensor(0.1012, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5134\n",
      "Loss: tensor(0.1012, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5135\n",
      "Loss: tensor(0.1012, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5136\n",
      "Loss: tensor(0.1012, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5137\n",
      "Loss: tensor(0.1012, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5138\n",
      "Loss: tensor(0.1012, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5139\n",
      "Loss: tensor(0.1012, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5140\n",
      "Loss: tensor(0.1012, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5141\n",
      "Loss: tensor(0.1012, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5142\n",
      "Loss: tensor(0.1012, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5143\n",
      "Loss: tensor(0.1012, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5144\n",
      "Loss: tensor(0.1012, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5145\n",
      "Loss: tensor(0.1012, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5146\n",
      "Loss: tensor(0.1011, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5147\n",
      "Loss: tensor(0.1011, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5148\n",
      "Loss: tensor(0.1011, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5149\n",
      "Loss: tensor(0.1011, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5150\n",
      "Loss: tensor(0.1011, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5151\n",
      "Loss: tensor(0.1011, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5152\n",
      "Loss: tensor(0.1011, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5153\n",
      "Loss: tensor(0.1011, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5154\n",
      "Loss: tensor(0.1011, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5155\n",
      "Loss: tensor(0.1011, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5156\n",
      "Loss: tensor(0.1011, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5157\n",
      "Loss: tensor(0.1011, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5158\n",
      "Loss: tensor(0.1011, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5159\n",
      "Loss: tensor(0.1011, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5160\n",
      "Loss: tensor(0.1011, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5161\n",
      "Loss: tensor(0.1011, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5162\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor(0.1011, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5163\n",
      "Loss: tensor(0.1011, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5164\n",
      "Loss: tensor(0.1011, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5165\n",
      "Loss: tensor(0.1011, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5166\n",
      "Loss: tensor(0.1011, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5167\n",
      "Loss: tensor(0.1011, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5168\n",
      "Loss: tensor(0.1011, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5169\n",
      "Loss: tensor(0.1011, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5170\n",
      "Loss: tensor(0.1011, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5171\n",
      "Loss: tensor(0.1011, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5172\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5173\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5174\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5175\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5176\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5177\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5178\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5179\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5180\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5181\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5182\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5183\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5184\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5185\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5186\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5187\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5188\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5189\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5190\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5191\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5192\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5193\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5194\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5195\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5196\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5197\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5198\n",
      "Loss: tensor(0.1010, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5199\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5200\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5201\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5202\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5203\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5204\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5205\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5206\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5207\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5208\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5209\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5210\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5211\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5212\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5213\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5214\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5215\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5216\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5217\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5218\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5219\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5220\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5221\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5222\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5223\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5224\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5225\n",
      "Loss: tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5226\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5227\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5228\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5229\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5230\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5231\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5232\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5233\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5234\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5235\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5236\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5237\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5238\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5239\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5240\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5241\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5242\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5243\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5244\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5245\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5246\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5247\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5248\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5249\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5250\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5251\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5252\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5253\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5254\n",
      "Loss: tensor(0.1008, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5255\n",
      "Loss: tensor(0.1007, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5256\n",
      "Loss: tensor(0.1007, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5257\n",
      "Loss: tensor(0.1007, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5258\n",
      "Loss: tensor(0.1007, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5259\n",
      "Loss: tensor(0.1007, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5260\n",
      "Loss: tensor(0.1007, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5261\n",
      "Loss: tensor(0.1007, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5262\n",
      "Loss: tensor(0.1007, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5263\n",
      "Loss: tensor(0.1007, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5264\n",
      "Loss: tensor(0.1007, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5265\n",
      "Loss: tensor(0.1007, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5266\n",
      "Loss: tensor(0.1007, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5267\n",
      "Loss: tensor(0.1007, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5268\n",
      "Loss: tensor(0.1007, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5269\n",
      "Loss: tensor(0.1007, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5270\n",
      "Loss: tensor(0.1007, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5271\n",
      "Loss: tensor(0.1007, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5272\n",
      "Loss: tensor(0.1007, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5273\n",
      "Loss: tensor(0.1007, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5274\n",
      "Loss: tensor(0.1007, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5275\n",
      "Loss: tensor(0.1007, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5276\n",
      "Loss: tensor(0.1007, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5277\n",
      "Loss: tensor(0.1007, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5278\n",
      "Loss: tensor(0.1007, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5279\n",
      "Loss: tensor(0.1007, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5280\n",
      "Loss: tensor(0.1007, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5281\n",
      "Loss: tensor(0.1007, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5282\n",
      "Loss: tensor(0.1007, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5283\n",
      "Loss: tensor(0.1007, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5284\n",
      "Loss: tensor(0.1007, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5285\n",
      "Loss: tensor(0.1007, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5286\n",
      "Loss: tensor(0.1007, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5287\n",
      "Loss: tensor(0.1006, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5288\n",
      "Loss: tensor(0.1006, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5289\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor(0.1006, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5290\n",
      "Loss: tensor(0.1006, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5291\n",
      "Loss: tensor(0.1006, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5292\n",
      "Loss: tensor(0.1006, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5293\n",
      "Loss: tensor(0.1006, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5294\n",
      "Loss: tensor(0.1006, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5295\n",
      "Loss: tensor(0.1006, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5296\n",
      "Loss: tensor(0.1006, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5297\n",
      "Loss: tensor(0.1006, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5298\n",
      "Loss: tensor(0.1006, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5299\n",
      "Loss: tensor(0.1006, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5300\n",
      "Loss: tensor(0.1006, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5301\n",
      "Loss: tensor(0.1006, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5302\n",
      "Loss: tensor(0.1006, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5303\n",
      "Loss: tensor(0.1006, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5304\n",
      "Loss: tensor(0.1006, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5305\n",
      "Loss: tensor(0.1006, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5306\n",
      "Loss: tensor(0.1006, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5307\n",
      "Loss: tensor(0.1006, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5308\n",
      "Loss: tensor(0.1006, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5309\n",
      "Loss: tensor(0.1006, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5310\n",
      "Loss: tensor(0.1006, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5311\n",
      "Loss: tensor(0.1006, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5312\n",
      "Loss: tensor(0.1006, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5313\n",
      "Loss: tensor(0.1006, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5314\n",
      "Loss: tensor(0.1006, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5315\n",
      "Loss: tensor(0.1005, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5316\n",
      "Loss: tensor(0.1005, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5317\n",
      "Loss: tensor(0.1005, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5318\n",
      "Loss: tensor(0.1005, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5319\n",
      "Loss: tensor(0.1005, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5320\n",
      "Loss: tensor(0.1005, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5321\n",
      "Loss: tensor(0.1005, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5322\n",
      "Loss: tensor(0.1005, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5323\n",
      "Loss: tensor(0.1005, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5324\n",
      "Loss: tensor(0.1005, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5325\n",
      "Loss: tensor(0.1005, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5326\n",
      "Loss: tensor(0.1005, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5327\n",
      "Loss: tensor(0.1005, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5328\n",
      "Loss: tensor(0.1005, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5329\n",
      "Loss: tensor(0.1005, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5330\n",
      "Loss: tensor(0.1005, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5331\n",
      "Loss: tensor(0.1005, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5332\n",
      "Loss: tensor(0.1005, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5333\n",
      "Loss: tensor(0.1005, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5334\n",
      "Loss: tensor(0.1005, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5335\n",
      "Loss: tensor(0.1005, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5336\n",
      "Loss: tensor(0.1005, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5337\n",
      "Loss: tensor(0.1005, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5338\n",
      "Loss: tensor(0.1005, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5339\n",
      "Loss: tensor(0.1005, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5340\n",
      "Loss: tensor(0.1005, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5341\n",
      "Loss: tensor(0.1005, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5342\n",
      "Loss: tensor(0.1005, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5343\n",
      "Loss: tensor(0.1005, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5344\n",
      "Loss: tensor(0.1005, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5345\n",
      "Loss: tensor(0.1005, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5346\n",
      "Loss: tensor(0.1005, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5347\n",
      "Loss: tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5348\n",
      "Loss: tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5349\n",
      "Loss: tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5350\n",
      "Loss: tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5351\n",
      "Loss: tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5352\n",
      "Loss: tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5353\n",
      "Loss: tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5354\n",
      "Loss: tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5355\n",
      "Loss: tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5356\n",
      "Loss: tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5357\n",
      "Loss: tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5358\n",
      "Loss: tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5359\n",
      "Loss: tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5360\n",
      "Loss: tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5361\n",
      "Loss: tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5362\n",
      "Loss: tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5363\n",
      "Loss: tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5364\n",
      "Loss: tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5365\n",
      "Loss: tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5366\n",
      "Loss: tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5367\n",
      "Loss: tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5368\n",
      "Loss: tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5369\n",
      "Loss: tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5370\n",
      "Loss: tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5371\n",
      "Loss: tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5372\n",
      "Loss: tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5373\n",
      "Loss: tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5374\n",
      "Loss: tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5375\n",
      "Loss: tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5376\n",
      "Loss: tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5377\n",
      "Loss: tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5378\n",
      "Loss: tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5379\n",
      "Loss: tensor(0.1004, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5380\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5381\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5382\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5383\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5384\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5385\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5386\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5387\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5388\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5389\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5390\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5391\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5392\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5393\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5394\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5395\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5396\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5397\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5398\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5399\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5400\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5401\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5402\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5403\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5404\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5405\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5406\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5407\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5408\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5409\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5410\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5411\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5412\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5413\n",
      "Loss: tensor(0.1003, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5414\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5415\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5416\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5417\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5418\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5419\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5420\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5421\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5422\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5423\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5424\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5425\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5426\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5427\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5428\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5429\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5430\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5431\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5432\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5433\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5434\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5435\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5436\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5437\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5438\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5439\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5440\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5441\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5442\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5443\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5444\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5445\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5446\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5447\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5448\n",
      "Loss: tensor(0.1002, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5449\n",
      "Loss: tensor(0.1001, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5450\n",
      "Loss: tensor(0.1001, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5451\n",
      "Loss: tensor(0.1001, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5452\n",
      "Loss: tensor(0.1001, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5453\n",
      "Loss: tensor(0.1001, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5454\n",
      "Loss: tensor(0.1001, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5455\n",
      "Loss: tensor(0.1001, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5456\n",
      "Loss: tensor(0.1001, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5457\n",
      "Loss: tensor(0.1001, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5458\n",
      "Loss: tensor(0.1001, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5459\n",
      "Loss: tensor(0.1001, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5460\n",
      "Loss: tensor(0.1001, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5461\n",
      "Loss: tensor(0.1001, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5462\n",
      "Loss: tensor(0.1001, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5463\n",
      "Loss: tensor(0.1001, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5464\n",
      "Loss: tensor(0.1001, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5465\n",
      "Loss: tensor(0.1001, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5466\n",
      "Loss: tensor(0.1001, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5467\n",
      "Loss: tensor(0.1001, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5468\n",
      "Loss: tensor(0.1001, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5469\n",
      "Loss: tensor(0.1001, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5470\n",
      "Loss: tensor(0.1001, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5471\n",
      "Loss: tensor(0.1001, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5472\n",
      "Loss: tensor(0.1001, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5473\n",
      "Loss: tensor(0.1001, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5474\n",
      "Loss: tensor(0.1001, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5475\n",
      "Loss: tensor(0.1001, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5476\n",
      "Loss: tensor(0.1001, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5477\n",
      "Loss: tensor(0.1001, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5478\n",
      "Loss: tensor(0.1001, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5479\n",
      "Loss: tensor(0.1001, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5480\n",
      "Loss: tensor(0.1001, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5481\n",
      "Loss: tensor(0.1001, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5482\n",
      "Loss: tensor(0.1001, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5483\n",
      "Loss: tensor(0.1001, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5484\n",
      "Loss: tensor(0.1001, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5485\n",
      "Loss: tensor(0.1000, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5486\n",
      "Loss: tensor(0.1000, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5487\n",
      "Loss: tensor(0.1000, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5488\n",
      "Loss: tensor(0.1000, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5489\n",
      "Loss: tensor(0.1000, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5490\n",
      "Loss: tensor(0.1000, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5491\n",
      "Loss: tensor(0.1000, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5492\n",
      "Loss: tensor(0.1000, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5493\n",
      "Loss: tensor(0.1000, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5494\n",
      "Loss: tensor(0.1000, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5495\n",
      "Loss: tensor(0.1000, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5496\n",
      "Loss: tensor(0.1000, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5497\n",
      "Loss: tensor(0.1000, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5498\n",
      "Loss: tensor(0.1000, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5499\n",
      "Loss: tensor(0.1000, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5500\n",
      "Loss: tensor(0.1000, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5501\n",
      "Loss: tensor(0.1000, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5502\n",
      "Loss: tensor(0.1000, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5503\n",
      "Loss: tensor(0.1000, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5504\n",
      "Loss: tensor(0.1000, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5505\n",
      "Loss: tensor(0.1000, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5506\n",
      "Loss: tensor(0.1000, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5507\n",
      "Loss: tensor(0.1000, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5508\n",
      "Loss: tensor(0.1000, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5509\n",
      "Loss: tensor(0.1000, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5510\n",
      "Loss: tensor(0.1000, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5511\n",
      "Loss: tensor(0.1000, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5512\n",
      "Loss: tensor(0.1000, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5513\n",
      "Loss: tensor(0.1000, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5514\n",
      "Loss: tensor(0.1000, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5515\n",
      "Loss: tensor(0.1000, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5516\n",
      "Loss: tensor(0.1000, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5517\n",
      "Loss: tensor(0.1000, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5518\n",
      "Loss: tensor(0.1000, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5519\n",
      "Loss: tensor(0.1000, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5520\n",
      "Loss: tensor(0.1000, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5521\n",
      "Loss: tensor(0.1000, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5522\n",
      "Loss: tensor(0.1000, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5523\n",
      "Loss: tensor(0.0999, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5524\n",
      "Loss: tensor(0.1000, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5525\n",
      "Loss: tensor(0.1000, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5526\n",
      "Loss: tensor(0.1000, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5527\n",
      "Loss: tensor(0.0999, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5528\n",
      "Loss: tensor(0.0999, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5529\n",
      "Loss: tensor(0.0999, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5530\n",
      "Loss: tensor(0.0999, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5531\n",
      "Loss: tensor(0.0999, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5532\n",
      "Loss: tensor(0.0999, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5533\n",
      "Loss: tensor(0.0999, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5534\n",
      "Loss: tensor(0.0999, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5535\n",
      "Loss: tensor(0.0999, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5536\n",
      "Loss: tensor(0.0999, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5537\n",
      "Loss: tensor(0.0999, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5538\n",
      "Loss: tensor(0.0999, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5539\n",
      "Loss: tensor(0.0999, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5540\n",
      "Loss: tensor(0.0999, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5541\n",
      "Loss: tensor(0.0999, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5542\n",
      "Loss: tensor(0.0999, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5543\n",
      "Loss: tensor(0.0999, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5544\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor(0.0999, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5545\n",
      "Loss: tensor(0.0999, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5546\n",
      "Loss: tensor(0.0999, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5547\n",
      "Loss: tensor(0.0999, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5548\n",
      "Loss: tensor(0.0999, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5549\n",
      "Loss: tensor(0.0999, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5550\n",
      "Loss: tensor(0.0999, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5551\n",
      "Loss: tensor(0.0999, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5552\n",
      "Loss: tensor(0.0999, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5553\n",
      "Loss: tensor(0.0999, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5554\n",
      "Loss: tensor(0.0999, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5555\n",
      "Loss: tensor(0.0999, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5556\n",
      "Loss: tensor(0.0999, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5557\n",
      "Loss: tensor(0.0999, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5558\n",
      "Loss: tensor(0.0999, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5559\n",
      "Loss: tensor(0.0999, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5560\n",
      "Loss: tensor(0.0999, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5561\n",
      "Loss: tensor(0.0998, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5562\n",
      "Loss: tensor(0.0998, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5563\n",
      "Loss: tensor(0.0998, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5564\n",
      "Loss: tensor(0.0998, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5565\n",
      "Loss: tensor(0.0998, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5566\n",
      "Loss: tensor(0.0998, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5567\n",
      "Loss: tensor(0.0998, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5568\n",
      "Loss: tensor(0.0998, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5569\n",
      "Loss: tensor(0.0998, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5570\n",
      "Loss: tensor(0.0998, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5571\n",
      "Loss: tensor(0.0998, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5572\n",
      "Loss: tensor(0.0998, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5573\n",
      "Loss: tensor(0.0998, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5574\n",
      "Loss: tensor(0.0998, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5575\n",
      "Loss: tensor(0.0998, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5576\n",
      "Loss: tensor(0.0998, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5577\n",
      "Loss: tensor(0.0998, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5578\n",
      "Loss: tensor(0.0998, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5579\n",
      "Loss: tensor(0.0998, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5580\n",
      "Loss: tensor(0.0998, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5581\n",
      "Loss: tensor(0.0998, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5582\n",
      "Loss: tensor(0.0998, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5583\n",
      "Loss: tensor(0.0998, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5584\n",
      "Loss: tensor(0.0998, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5585\n",
      "Loss: tensor(0.0998, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5586\n",
      "Loss: tensor(0.0998, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5587\n",
      "Loss: tensor(0.0998, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5588\n",
      "Loss: tensor(0.0998, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5589\n",
      "Loss: tensor(0.0998, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5590\n",
      "Loss: tensor(0.0998, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5591\n",
      "Loss: tensor(0.0998, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5592\n",
      "Loss: tensor(0.0998, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5593\n",
      "Loss: tensor(0.0998, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5594\n",
      "Loss: tensor(0.0998, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5595\n",
      "Loss: tensor(0.0998, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5596\n",
      "Loss: tensor(0.0998, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5597\n",
      "Loss: tensor(0.0998, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5598\n",
      "Loss: tensor(0.0998, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5599\n",
      "Loss: tensor(0.0998, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5600\n",
      "Loss: tensor(0.0998, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5601\n",
      "Loss: tensor(0.0998, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5602\n",
      "Loss: tensor(0.0998, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5603\n",
      "Loss: tensor(0.0997, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5604\n",
      "Loss: tensor(0.0997, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5605\n",
      "Loss: tensor(0.0997, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5606\n",
      "Loss: tensor(0.0997, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5607\n",
      "Loss: tensor(0.0997, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5608\n",
      "Loss: tensor(0.0997, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5609\n",
      "Loss: tensor(0.0997, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5610\n",
      "Loss: tensor(0.0997, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5611\n",
      "Loss: tensor(0.0997, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5612\n",
      "Loss: tensor(0.0997, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5613\n",
      "Loss: tensor(0.0997, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5614\n",
      "Loss: tensor(0.0997, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5615\n",
      "Loss: tensor(0.0997, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5616\n",
      "Loss: tensor(0.0997, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5617\n",
      "Loss: tensor(0.0997, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5618\n",
      "Loss: tensor(0.0997, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5619\n",
      "Loss: tensor(0.0997, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5620\n",
      "Loss: tensor(0.0997, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5621\n",
      "Loss: tensor(0.0997, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5622\n",
      "Loss: tensor(0.0997, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5623\n",
      "Loss: tensor(0.0997, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5624\n",
      "Loss: tensor(0.0997, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5625\n",
      "Loss: tensor(0.0997, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5626\n",
      "Loss: tensor(0.0997, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5627\n",
      "Loss: tensor(0.0997, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5628\n",
      "Loss: tensor(0.0997, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5629\n",
      "Loss: tensor(0.0997, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5630\n",
      "Loss: tensor(0.0997, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5631\n",
      "Loss: tensor(0.0997, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5632\n",
      "Loss: tensor(0.0997, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5633\n",
      "Loss: tensor(0.0997, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5634\n",
      "Loss: tensor(0.0997, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5635\n",
      "Loss: tensor(0.0997, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5636\n",
      "Loss: tensor(0.0997, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5637\n",
      "Loss: tensor(0.0997, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5638\n",
      "Loss: tensor(0.0997, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5639\n",
      "Loss: tensor(0.0997, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5640\n",
      "Loss: tensor(0.0997, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5641\n",
      "Loss: tensor(0.0997, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5642\n",
      "Loss: tensor(0.0997, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5643\n",
      "Loss: tensor(0.0996, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5644\n",
      "Loss: tensor(0.0996, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5645\n",
      "Loss: tensor(0.0996, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5646\n",
      "Loss: tensor(0.0996, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5647\n",
      "Loss: tensor(0.0996, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5648\n",
      "Loss: tensor(0.0996, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5649\n",
      "Loss: tensor(0.0996, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5650\n",
      "Loss: tensor(0.0996, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5651\n",
      "Loss: tensor(0.0996, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5652\n",
      "Loss: tensor(0.0996, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5653\n",
      "Loss: tensor(0.0996, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5654\n",
      "Loss: tensor(0.0996, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5655\n",
      "Loss: tensor(0.0996, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5656\n",
      "Loss: tensor(0.0996, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5657\n",
      "Loss: tensor(0.0996, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5658\n",
      "Loss: tensor(0.0996, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5659\n",
      "Loss: tensor(0.0996, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5660\n",
      "Loss: tensor(0.0996, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5661\n",
      "Loss: tensor(0.0996, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5662\n",
      "Loss: tensor(0.0996, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5663\n",
      "Loss: tensor(0.0996, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5664\n",
      "Loss: tensor(0.0996, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5665\n",
      "Loss: tensor(0.0996, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5666\n",
      "Loss: tensor(0.0996, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5667\n",
      "Loss: tensor(0.0996, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5668\n",
      "Loss: tensor(0.0996, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5669\n",
      "Loss: tensor(0.0996, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5670\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor(0.0996, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5671\n",
      "Loss: tensor(0.0996, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5672\n",
      "Loss: tensor(0.0996, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5673\n",
      "Loss: tensor(0.0996, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5674\n",
      "Loss: tensor(0.0996, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5675\n",
      "Loss: tensor(0.0996, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5676\n",
      "Loss: tensor(0.0996, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5677\n",
      "Loss: tensor(0.0996, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5678\n",
      "Loss: tensor(0.0996, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5679\n",
      "Loss: tensor(0.0996, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5680\n",
      "Loss: tensor(0.0996, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5681\n",
      "Loss: tensor(0.0996, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5682\n",
      "Loss: tensor(0.0996, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5683\n",
      "Loss: tensor(0.0996, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5684\n",
      "Loss: tensor(0.0996, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5685\n",
      "Loss: tensor(0.0995, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5686\n",
      "Loss: tensor(0.0995, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5687\n",
      "Loss: tensor(0.0995, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5688\n",
      "Loss: tensor(0.0995, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5689\n",
      "Loss: tensor(0.0995, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5690\n",
      "Loss: tensor(0.0995, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5691\n",
      "Loss: tensor(0.0995, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5692\n",
      "Loss: tensor(0.0995, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5693\n",
      "Loss: tensor(0.0995, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5694\n",
      "Loss: tensor(0.0995, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5695\n",
      "Loss: tensor(0.0995, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5696\n",
      "Loss: tensor(0.0995, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5697\n",
      "Loss: tensor(0.0995, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5698\n",
      "Loss: tensor(0.0995, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5699\n",
      "Loss: tensor(0.0995, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5700\n",
      "Loss: tensor(0.0995, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5701\n",
      "Loss: tensor(0.0995, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5702\n",
      "Loss: tensor(0.0995, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5703\n",
      "Loss: tensor(0.0995, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5704\n",
      "Loss: tensor(0.0995, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5705\n",
      "Loss: tensor(0.0995, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5706\n",
      "Loss: tensor(0.0995, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5707\n",
      "Loss: tensor(0.0995, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5708\n",
      "Loss: tensor(0.0995, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5709\n",
      "Loss: tensor(0.0995, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5710\n",
      "Loss: tensor(0.0995, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5711\n",
      "Loss: tensor(0.0995, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5712\n",
      "Loss: tensor(0.0995, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5713\n",
      "Loss: tensor(0.0995, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5714\n",
      "Loss: tensor(0.0995, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5715\n",
      "Loss: tensor(0.0995, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5716\n",
      "Loss: tensor(0.0995, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5717\n",
      "Loss: tensor(0.0995, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5718\n",
      "Loss: tensor(0.0995, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5719\n",
      "Loss: tensor(0.0995, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5720\n",
      "Loss: tensor(0.0995, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5721\n",
      "Loss: tensor(0.0995, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5722\n",
      "Loss: tensor(0.0995, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5723\n",
      "Loss: tensor(0.0995, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5724\n",
      "Loss: tensor(0.0995, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5725\n",
      "Loss: tensor(0.0995, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5726\n",
      "Loss: tensor(0.0995, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5727\n",
      "Loss: tensor(0.0995, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5728\n",
      "Loss: tensor(0.0995, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5729\n",
      "Loss: tensor(0.0995, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5730\n",
      "Loss: tensor(0.0994, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5731\n",
      "Loss: tensor(0.0994, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5732\n",
      "Loss: tensor(0.0994, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5733\n",
      "Loss: tensor(0.0994, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5734\n",
      "Loss: tensor(0.0994, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5735\n",
      "Loss: tensor(0.0994, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5736\n",
      "Loss: tensor(0.0994, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5737\n",
      "Loss: tensor(0.0994, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5738\n",
      "Loss: tensor(0.0994, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5739\n",
      "Loss: tensor(0.0994, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5740\n",
      "Loss: tensor(0.0994, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5741\n",
      "Loss: tensor(0.0994, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5742\n",
      "Loss: tensor(0.0994, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5743\n",
      "Loss: tensor(0.0994, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5744\n",
      "Loss: tensor(0.0994, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5745\n",
      "Loss: tensor(0.0994, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5746\n",
      "Loss: tensor(0.0994, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5747\n",
      "Loss: tensor(0.0994, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5748\n",
      "Loss: tensor(0.0994, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5749\n",
      "Loss: tensor(0.0994, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5750\n",
      "Loss: tensor(0.0994, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5751\n",
      "Loss: tensor(0.0994, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5752\n",
      "Loss: tensor(0.0994, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5753\n",
      "Loss: tensor(0.0994, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5754\n",
      "Loss: tensor(0.0994, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5755\n",
      "Loss: tensor(0.0994, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5756\n",
      "Loss: tensor(0.0994, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5757\n",
      "Loss: tensor(0.0994, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5758\n",
      "Loss: tensor(0.0994, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5759\n",
      "Loss: tensor(0.0994, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5760\n",
      "Loss: tensor(0.0994, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5761\n",
      "Loss: tensor(0.0994, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5762\n",
      "Loss: tensor(0.0994, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5763\n",
      "Loss: tensor(0.0994, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5764\n",
      "Loss: tensor(0.0994, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5765\n",
      "Loss: tensor(0.0994, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5766\n",
      "Loss: tensor(0.0994, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5767\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor(0.0994, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5768\n",
      "Loss: tensor(0.0994, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5769\n",
      "Loss: tensor(0.0994, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5770\n",
      "Loss: tensor(0.0994, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5771\n",
      "Loss: tensor(0.0994, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5772\n",
      "Loss: tensor(0.0994, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5773\n",
      "Loss: tensor(0.0994, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5774\n",
      "Loss: tensor(0.0993, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5775\n",
      "Loss: tensor(0.0993, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5776\n",
      "Loss: tensor(0.0993, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5777\n",
      "Loss: tensor(0.0993, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5778\n",
      "Loss: tensor(0.0993, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5779\n",
      "Loss: tensor(0.0993, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5780\n",
      "Loss: tensor(0.0993, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5781\n",
      "Loss: tensor(0.0993, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5782\n",
      "Loss: tensor(0.0993, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5783\n",
      "Loss: tensor(0.0993, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5784\n",
      "Loss: tensor(0.0993, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5785\n",
      "Loss: tensor(0.0993, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5786\n",
      "Loss: tensor(0.0993, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5787\n",
      "Loss: tensor(0.0993, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5788\n",
      "Loss: tensor(0.0993, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5789\n",
      "Loss: tensor(0.0993, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5790\n",
      "Loss: tensor(0.0993, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5791\n",
      "Loss: tensor(0.0993, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5792\n",
      "Loss: tensor(0.0993, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5793\n",
      "Loss: tensor(0.0993, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5794\n",
      "Loss: tensor(0.0993, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5795\n",
      "Loss: tensor(0.0993, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5796\n",
      "Loss: tensor(0.0993, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5797\n",
      "Loss: tensor(0.0993, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5798\n",
      "Loss: tensor(0.0993, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5799\n",
      "Loss: tensor(0.0993, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5800\n",
      "Loss: tensor(0.0993, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5801\n",
      "Loss: tensor(0.0993, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5802\n",
      "Loss: tensor(0.0993, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5803\n",
      "Loss: tensor(0.0993, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5804\n",
      "Loss: tensor(0.0993, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5805\n",
      "Loss: tensor(0.0993, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5806\n",
      "Loss: tensor(0.0993, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5807\n",
      "Loss: tensor(0.0993, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5808\n",
      "Loss: tensor(0.0993, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5809\n",
      "Loss: tensor(0.0993, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5810\n",
      "Loss: tensor(0.0993, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5811\n",
      "Loss: tensor(0.0993, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5812\n",
      "Loss: tensor(0.0993, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5813\n",
      "Loss: tensor(0.0993, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5814\n",
      "Loss: tensor(0.0993, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5815\n",
      "Loss: tensor(0.0993, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5816\n",
      "Loss: tensor(0.0993, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5817\n",
      "Loss: tensor(0.0993, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5818\n",
      "Loss: tensor(0.0993, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5819\n",
      "Loss: tensor(0.0993, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5820\n",
      "Loss: tensor(0.0993, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5821\n",
      "Loss: tensor(0.0993, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5822\n",
      "Loss: tensor(0.0992, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5823\n",
      "Loss: tensor(0.0992, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5824\n",
      "Loss: tensor(0.0992, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5825\n",
      "Loss: tensor(0.0992, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5826\n",
      "Loss: tensor(0.0992, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5827\n",
      "Loss: tensor(0.0992, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5828\n",
      "Loss: tensor(0.0992, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5829\n",
      "Loss: tensor(0.0992, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5830\n",
      "Loss: tensor(0.0992, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5831\n",
      "Loss: tensor(0.0992, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5832\n",
      "Loss: tensor(0.0992, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5833\n",
      "Loss: tensor(0.0992, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5834\n",
      "Loss: tensor(0.0992, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5835\n",
      "Loss: tensor(0.0992, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5836\n",
      "Loss: tensor(0.0992, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5837\n",
      "Loss: tensor(0.0992, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5838\n",
      "Loss: tensor(0.0992, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5839\n",
      "Loss: tensor(0.0992, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5840\n",
      "Loss: tensor(0.0992, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5841\n",
      "Loss: tensor(0.0992, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5842\n",
      "Loss: tensor(0.0992, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5843\n",
      "Loss: tensor(0.0992, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5844\n",
      "Loss: tensor(0.0992, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5845\n",
      "Loss: tensor(0.0992, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5846\n",
      "Loss: tensor(0.0992, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5847\n",
      "Loss: tensor(0.0992, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5848\n",
      "Loss: tensor(0.0992, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5849\n",
      "Loss: tensor(0.0992, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5850\n",
      "Loss: tensor(0.0992, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5851\n",
      "Loss: tensor(0.0992, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5852\n",
      "Loss: tensor(0.0992, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5853\n",
      "Loss: tensor(0.0992, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5854\n",
      "Loss: tensor(0.0992, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5855\n",
      "Loss: tensor(0.0992, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5856\n",
      "Loss: tensor(0.0992, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5857\n",
      "Loss: tensor(0.0992, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5858\n",
      "Loss: tensor(0.0992, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5859\n",
      "Loss: tensor(0.0992, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5860\n",
      "Loss: tensor(0.0992, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5861\n",
      "Loss: tensor(0.0992, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5862\n",
      "Loss: tensor(0.0992, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5863\n",
      "Loss: tensor(0.0992, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5864\n",
      "Loss: tensor(0.0992, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5865\n",
      "Loss: tensor(0.0992, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5866\n",
      "Loss: tensor(0.0992, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5867\n",
      "Loss: tensor(0.0992, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5868\n",
      "Loss: tensor(0.0992, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5869\n",
      "Loss: tensor(0.0992, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5870\n",
      "Loss: tensor(0.0991, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5871\n",
      "Loss: tensor(0.0991, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5872\n",
      "Loss: tensor(0.0991, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5873\n",
      "Loss: tensor(0.0991, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5874\n",
      "Loss: tensor(0.0991, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5875\n",
      "Loss: tensor(0.0991, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5876\n",
      "Loss: tensor(0.0991, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5877\n",
      "Loss: tensor(0.0991, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5878\n",
      "Loss: tensor(0.0991, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5879\n",
      "Loss: tensor(0.0991, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5880\n",
      "Loss: tensor(0.0991, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5881\n",
      "Loss: tensor(0.0991, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5882\n",
      "Loss: tensor(0.0991, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5883\n",
      "Loss: tensor(0.0991, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5884\n",
      "Loss: tensor(0.0991, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5885\n",
      "Loss: tensor(0.0991, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5886\n",
      "Loss: tensor(0.0991, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5887\n",
      "Loss: tensor(0.0991, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5888\n",
      "Loss: tensor(0.0991, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5889\n",
      "Loss: tensor(0.0991, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5890\n",
      "Loss: tensor(0.0991, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5891\n",
      "Loss: tensor(0.0991, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5892\n",
      "Loss: tensor(0.0991, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5893\n",
      "Loss: tensor(0.0991, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5894\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor(0.0991, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5895\n",
      "Loss: tensor(0.0991, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5896\n",
      "Loss: tensor(0.0991, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5897\n",
      "Loss: tensor(0.0991, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5898\n",
      "Loss: tensor(0.0991, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5899\n",
      "Loss: tensor(0.0991, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5900\n",
      "Loss: tensor(0.0991, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5901\n",
      "Loss: tensor(0.0991, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5902\n",
      "Loss: tensor(0.0991, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5903\n",
      "Loss: tensor(0.0991, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5904\n",
      "Loss: tensor(0.0991, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5905\n",
      "Loss: tensor(0.0991, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5906\n",
      "Loss: tensor(0.0991, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5907\n",
      "Loss: tensor(0.0991, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5908\n",
      "Loss: tensor(0.0991, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5909\n",
      "Loss: tensor(0.0991, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5910\n",
      "Loss: tensor(0.0991, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5911\n",
      "Loss: tensor(0.0991, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5912\n",
      "Loss: tensor(0.0991, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5913\n",
      "Loss: tensor(0.0991, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5914\n",
      "Loss: tensor(0.0991, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5915\n",
      "Loss: tensor(0.0991, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5916\n",
      "Loss: tensor(0.0991, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5917\n",
      "Loss: tensor(0.0991, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5918\n",
      "Loss: tensor(0.0991, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5919\n",
      "Loss: tensor(0.0991, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5920\n",
      "Loss: tensor(0.0991, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5921\n",
      "Loss: tensor(0.0991, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5922\n",
      "Loss: tensor(0.0991, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5923\n",
      "Loss: tensor(0.0991, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5924\n",
      "Loss: tensor(0.0990, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5925\n",
      "Loss: tensor(0.0990, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5926\n",
      "Loss: tensor(0.0990, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5927\n",
      "Loss: tensor(0.0990, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5928\n",
      "Loss: tensor(0.0990, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5929\n",
      "Loss: tensor(0.0990, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5930\n",
      "Loss: tensor(0.0990, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5931\n",
      "Loss: tensor(0.0990, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5932\n",
      "Loss: tensor(0.0990, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5933\n",
      "Loss: tensor(0.0990, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5934\n",
      "Loss: tensor(0.0990, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5935\n",
      "Loss: tensor(0.0990, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5936\n",
      "Loss: tensor(0.0990, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5937\n",
      "Loss: tensor(0.0990, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5938\n",
      "Loss: tensor(0.0990, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5939\n",
      "Loss: tensor(0.0990, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5940\n",
      "Loss: tensor(0.0990, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5941\n",
      "Loss: tensor(0.0990, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5942\n",
      "Loss: tensor(0.0990, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5943\n",
      "Loss: tensor(0.0990, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5944\n",
      "Loss: tensor(0.0990, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5945\n",
      "Loss: tensor(0.0990, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5946\n",
      "Loss: tensor(0.0990, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5947\n",
      "Loss: tensor(0.0990, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5948\n",
      "Loss: tensor(0.0990, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5949\n",
      "Loss: tensor(0.0990, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5950\n",
      "Loss: tensor(0.0990, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5951\n",
      "Loss: tensor(0.0990, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5952\n",
      "Loss: tensor(0.0990, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5953\n",
      "Loss: tensor(0.0990, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5954\n",
      "Loss: tensor(0.0990, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5955\n",
      "Loss: tensor(0.0990, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5956\n",
      "Loss: tensor(0.0990, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5957\n",
      "Loss: tensor(0.0990, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5958\n",
      "Loss: tensor(0.0990, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5959\n",
      "Loss: tensor(0.0990, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5960\n",
      "Loss: tensor(0.0990, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5961\n",
      "Loss: tensor(0.0990, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5962\n",
      "Loss: tensor(0.0990, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5963\n",
      "Loss: tensor(0.0990, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5964\n",
      "Loss: tensor(0.0990, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5965\n",
      "Loss: tensor(0.0990, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5966\n",
      "Loss: tensor(0.0990, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5967\n",
      "Loss: tensor(0.0990, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5968\n",
      "Loss: tensor(0.0990, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5969\n",
      "Loss: tensor(0.0990, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5970\n",
      "Loss: tensor(0.0990, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5971\n",
      "Loss: tensor(0.0990, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5972\n",
      "Loss: tensor(0.0990, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5973\n",
      "Loss: tensor(0.0990, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5974\n",
      "Loss: tensor(0.0990, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5975\n",
      "Loss: tensor(0.0990, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5976\n",
      "Loss: tensor(0.0990, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5977\n",
      "Loss: tensor(0.0990, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5978\n",
      "Loss: tensor(0.0990, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5979\n",
      "Loss: tensor(0.0989, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5980\n",
      "Loss: tensor(0.0989, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5981\n",
      "Loss: tensor(0.0989, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5982\n",
      "Loss: tensor(0.0989, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5983\n",
      "Loss: tensor(0.0989, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5984\n",
      "Loss: tensor(0.0989, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5985\n",
      "Loss: tensor(0.0989, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5986\n",
      "Loss: tensor(0.0989, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5987\n",
      "Loss: tensor(0.0989, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5988\n",
      "Loss: tensor(0.0989, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5989\n",
      "Loss: tensor(0.0989, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5990\n",
      "Loss: tensor(0.0989, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5991\n",
      "Loss: tensor(0.0989, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5992\n",
      "Loss: tensor(0.0989, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5993\n",
      "Loss: tensor(0.0989, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5994\n",
      "Loss: tensor(0.0989, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5995\n",
      "Loss: tensor(0.0989, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5996\n",
      "Loss: tensor(0.0989, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5997\n",
      "Loss: tensor(0.0989, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5998\n",
      "Loss: tensor(0.0989, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5999\n",
      "Loss: tensor(0.0989, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6000\n",
      "Loss: tensor(0.0989, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6001\n",
      "Loss: tensor(0.0989, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6002\n",
      "Loss: tensor(0.0989, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6003\n",
      "Loss: tensor(0.0989, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6004\n",
      "Loss: tensor(0.0989, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6005\n",
      "Loss: tensor(0.0989, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6006\n",
      "Loss: tensor(0.0989, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6007\n",
      "Loss: tensor(0.0989, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6008\n",
      "Loss: tensor(0.0989, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6009\n",
      "Loss: tensor(0.0989, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6010\n",
      "Loss: tensor(0.0989, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6011\n",
      "Loss: tensor(0.0989, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6012\n",
      "Loss: tensor(0.0989, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6013\n",
      "Loss: tensor(0.0989, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6014\n",
      "Loss: tensor(0.0989, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6015\n",
      "Loss: tensor(0.0989, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6016\n",
      "Loss: tensor(0.0989, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6017\n",
      "Loss: tensor(0.0989, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6018\n",
      "Loss: tensor(0.0989, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6019\n",
      "Loss: tensor(0.0989, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6020\n",
      "Loss: tensor(0.0989, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6021\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor(0.0989, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6022\n",
      "Loss: tensor(0.0989, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6023\n",
      "Loss: tensor(0.0989, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6024\n",
      "Loss: tensor(0.0989, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6025\n",
      "Loss: tensor(0.0989, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6026\n",
      "Loss: tensor(0.0989, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6027\n",
      "Loss: tensor(0.0989, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6028\n",
      "Loss: tensor(0.0988, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6029\n",
      "Loss: tensor(0.0988, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6030\n",
      "Loss: tensor(0.0988, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6031\n",
      "Loss: tensor(0.0988, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6032\n",
      "Loss: tensor(0.0988, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6033\n",
      "Loss: tensor(0.0988, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6034\n",
      "Loss: tensor(0.0988, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6035\n",
      "Loss: tensor(0.0988, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6036\n",
      "Loss: tensor(0.0988, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6037\n",
      "Loss: tensor(0.0988, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6038\n",
      "Loss: tensor(0.0988, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6039\n",
      "Loss: tensor(0.0988, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6040\n",
      "Loss: tensor(0.0988, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6041\n",
      "Loss: tensor(0.0988, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6042\n",
      "Loss: tensor(0.0988, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6043\n",
      "Loss: tensor(0.0988, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6044\n",
      "Loss: tensor(0.0988, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6045\n",
      "Loss: tensor(0.0988, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6046\n",
      "Loss: tensor(0.0988, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6047\n",
      "Loss: tensor(0.0988, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6048\n",
      "Loss: tensor(0.0988, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6049\n",
      "Loss: tensor(0.0988, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6050\n",
      "Loss: tensor(0.0988, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6051\n",
      "Loss: tensor(0.0988, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6052\n",
      "Loss: tensor(0.0988, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6053\n",
      "Loss: tensor(0.0988, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6054\n",
      "Loss: tensor(0.0988, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6055\n",
      "Loss: tensor(0.0988, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6056\n",
      "Loss: tensor(0.0988, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6057\n",
      "Loss: tensor(0.0988, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6058\n",
      "Loss: tensor(0.0988, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6059\n",
      "Loss: tensor(0.0988, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6060\n",
      "Loss: tensor(0.0988, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6061\n",
      "Loss: tensor(0.0988, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6062\n",
      "Loss: tensor(0.0988, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6063\n",
      "Loss: tensor(0.0988, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6064\n",
      "Loss: tensor(0.0988, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6065\n",
      "Loss: tensor(0.0988, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6066\n",
      "Loss: tensor(0.0988, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6067\n",
      "Loss: tensor(0.0988, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6068\n",
      "Loss: tensor(0.0988, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6069\n",
      "Loss: tensor(0.0988, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6070\n",
      "Loss: tensor(0.0988, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6071\n",
      "Loss: tensor(0.0988, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6072\n",
      "Loss: tensor(0.0988, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6073\n",
      "Loss: tensor(0.0988, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6074\n",
      "Loss: tensor(0.0988, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6075\n",
      "Loss: tensor(0.0988, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6076\n",
      "Loss: tensor(0.0988, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6077\n",
      "Loss: tensor(0.0988, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6078\n",
      "Loss: tensor(0.0988, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6079\n",
      "Loss: tensor(0.0988, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6080\n",
      "Loss: tensor(0.0988, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6081\n",
      "Loss: tensor(0.0988, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6082\n",
      "Loss: tensor(0.0988, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6083\n",
      "Loss: tensor(0.0988, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6084\n",
      "Loss: tensor(0.0988, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6085\n",
      "Loss: tensor(0.0988, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6086\n",
      "Loss: tensor(0.0987, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6087\n",
      "Loss: tensor(0.0987, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6088\n",
      "Loss: tensor(0.0987, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6089\n",
      "Loss: tensor(0.0987, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6090\n",
      "Loss: tensor(0.0987, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6091\n",
      "Loss: tensor(0.0987, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6092\n",
      "Loss: tensor(0.0987, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6093\n",
      "Loss: tensor(0.0987, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6094\n",
      "Loss: tensor(0.0987, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6095\n",
      "Loss: tensor(0.0987, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6096\n",
      "Loss: tensor(0.0987, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6097\n",
      "Loss: tensor(0.0987, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6098\n",
      "Loss: tensor(0.0987, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6099\n",
      "Loss: tensor(0.0987, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6100\n",
      "Loss: tensor(0.0987, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6101\n",
      "Loss: tensor(0.0987, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6102\n",
      "Loss: tensor(0.0987, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6103\n",
      "Loss: tensor(0.0987, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6104\n",
      "Loss: tensor(0.0987, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6105\n",
      "Loss: tensor(0.0987, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6106\n",
      "Loss: tensor(0.0987, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6107\n",
      "Loss: tensor(0.0987, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6108\n",
      "Loss: tensor(0.0987, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6109\n",
      "Loss: tensor(0.0987, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6110\n",
      "Loss: tensor(0.0987, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6111\n",
      "Loss: tensor(0.0987, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6112\n",
      "Loss: tensor(0.0987, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6113\n",
      "Loss: tensor(0.0987, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6114\n",
      "Loss: tensor(0.0987, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6115\n",
      "Loss: tensor(0.0987, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6116\n",
      "Loss: tensor(0.0987, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6117\n",
      "Loss: tensor(0.0987, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6118\n",
      "Loss: tensor(0.0987, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6119\n",
      "Loss: tensor(0.0987, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6120\n",
      "Loss: tensor(0.0987, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6121\n",
      "Loss: tensor(0.0987, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6122\n",
      "Loss: tensor(0.0987, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6123\n",
      "Loss: tensor(0.0987, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6124\n",
      "Loss: tensor(0.0987, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6125\n",
      "Loss: tensor(0.0987, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6126\n",
      "Loss: tensor(0.0987, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6127\n",
      "Loss: tensor(0.0987, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6128\n",
      "Loss: tensor(0.0987, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6129\n",
      "Loss: tensor(0.0987, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6130\n",
      "Loss: tensor(0.0987, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6131\n",
      "Loss: tensor(0.0987, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6132\n",
      "Loss: tensor(0.0987, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6133\n",
      "Loss: tensor(0.0987, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6134\n",
      "Loss: tensor(0.0987, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6135\n",
      "Loss: tensor(0.0987, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6136\n",
      "Loss: tensor(0.0987, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6137\n",
      "Loss: tensor(0.0987, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6138\n",
      "Loss: tensor(0.0987, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6139\n",
      "Loss: tensor(0.0987, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6140\n",
      "Loss: tensor(0.0987, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6141\n",
      "Loss: tensor(0.0987, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6142\n",
      "Loss: tensor(0.0987, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6143\n",
      "Loss: tensor(0.0987, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6144\n",
      "Loss: tensor(0.0987, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6145\n",
      "Loss: tensor(0.0987, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6146\n",
      "Loss: tensor(0.0987, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6147\n",
      "Loss: tensor(0.0987, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6148\n",
      "Loss: tensor(0.0987, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6149\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor(0.0987, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6150\n",
      "Loss: tensor(0.0987, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6151\n",
      "Loss: tensor(0.0986, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6152\n",
      "Loss: tensor(0.0986, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6153\n",
      "Loss: tensor(0.0986, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6154\n",
      "Loss: tensor(0.0986, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6155\n",
      "Loss: tensor(0.0986, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6156\n",
      "Loss: tensor(0.0986, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6157\n",
      "Loss: tensor(0.0986, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6158\n",
      "Loss: tensor(0.0986, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6159\n",
      "Loss: tensor(0.0986, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6160\n",
      "Loss: tensor(0.0986, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6161\n",
      "Loss: tensor(0.0986, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6162\n",
      "Loss: tensor(0.0986, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6163\n",
      "Loss: tensor(0.0986, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6164\n",
      "Loss: tensor(0.0986, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6165\n",
      "Loss: tensor(0.0986, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6166\n",
      "Loss: tensor(0.0986, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6167\n",
      "Loss: tensor(0.0986, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6168\n",
      "Loss: tensor(0.0986, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6169\n",
      "Loss: tensor(0.0986, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6170\n",
      "Loss: tensor(0.0986, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6171\n",
      "Loss: tensor(0.0986, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6172\n",
      "Loss: tensor(0.0986, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6173\n",
      "Loss: tensor(0.0986, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6174\n",
      "Loss: tensor(0.0986, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6175\n",
      "Loss: tensor(0.0986, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6176\n",
      "Loss: tensor(0.0986, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6177\n",
      "Loss: tensor(0.0986, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6178\n",
      "Loss: tensor(0.0986, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6179\n",
      "Loss: tensor(0.0986, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6180\n",
      "Loss: tensor(0.0986, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6181\n",
      "Loss: tensor(0.0986, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6182\n",
      "Loss: tensor(0.0986, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6183\n",
      "Loss: tensor(0.0986, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6184\n",
      "Loss: tensor(0.0986, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6185\n",
      "Loss: tensor(0.0986, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6186\n",
      "Loss: tensor(0.0986, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6187\n",
      "Loss: tensor(0.0986, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6188\n",
      "Loss: tensor(0.0986, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6189\n",
      "Loss: tensor(0.0986, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6190\n",
      "Loss: tensor(0.0986, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6191\n",
      "Loss: tensor(0.0986, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6192\n",
      "Loss: tensor(0.0986, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6193\n",
      "Loss: tensor(0.0986, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6194\n",
      "Loss: tensor(0.0986, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6195\n",
      "Loss: tensor(0.0986, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6196\n",
      "Loss: tensor(0.0986, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6197\n",
      "Loss: tensor(0.0986, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6198\n",
      "Loss: tensor(0.0986, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6199\n",
      "Loss: tensor(0.0986, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6200\n",
      "Loss: tensor(0.0986, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6201\n",
      "Loss: tensor(0.0986, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6202\n",
      "Loss: tensor(0.0986, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6203\n",
      "Loss: tensor(0.0986, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6204\n",
      "Loss: tensor(0.0986, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6205\n",
      "Loss: tensor(0.0986, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6206\n",
      "Loss: tensor(0.0986, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6207\n",
      "Loss: tensor(0.0985, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6208\n",
      "Loss: tensor(0.0985, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6209\n",
      "Loss: tensor(0.0985, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6210\n",
      "Loss: tensor(0.0985, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6211\n",
      "Loss: tensor(0.0985, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6212\n",
      "Loss: tensor(0.0985, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6213\n",
      "Loss: tensor(0.0985, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6214\n",
      "Loss: tensor(0.0985, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6215\n",
      "Loss: tensor(0.0985, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6216\n",
      "Loss: tensor(0.0985, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6217\n",
      "Loss: tensor(0.0985, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6218\n",
      "Loss: tensor(0.0985, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6219\n",
      "Loss: tensor(0.0985, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6220\n",
      "Loss: tensor(0.0985, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6221\n",
      "Loss: tensor(0.0985, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6222\n",
      "Loss: tensor(0.0985, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6223\n",
      "Loss: tensor(0.0985, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6224\n",
      "Loss: tensor(0.0985, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6225\n",
      "Loss: tensor(0.0985, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6226\n",
      "Loss: tensor(0.0985, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6227\n",
      "Loss: tensor(0.0985, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6228\n",
      "Loss: tensor(0.0985, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6229\n",
      "Loss: tensor(0.0985, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6230\n",
      "Loss: tensor(0.0985, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6231\n",
      "Loss: tensor(0.0985, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6232\n",
      "Loss: tensor(0.0985, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6233\n",
      "Loss: tensor(0.0985, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6234\n",
      "Loss: tensor(0.0985, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6235\n",
      "Loss: tensor(0.0985, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6236\n",
      "Loss: tensor(0.0985, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6237\n",
      "Loss: tensor(0.0985, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6238\n",
      "Loss: tensor(0.0985, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6239\n",
      "Loss: tensor(0.0985, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6240\n",
      "Loss: tensor(0.0985, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6241\n",
      "Loss: tensor(0.0985, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6242\n",
      "Loss: tensor(0.0985, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6243\n",
      "Loss: tensor(0.0985, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6244\n",
      "Loss: tensor(0.0985, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6245\n",
      "Loss: tensor(0.0985, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6246\n",
      "Loss: tensor(0.0985, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6247\n",
      "Loss: tensor(0.0985, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6248\n",
      "Loss: tensor(0.0985, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6249\n",
      "Loss: tensor(0.0985, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6250\n",
      "Loss: tensor(0.0985, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6251\n",
      "Loss: tensor(0.0985, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6252\n",
      "Loss: tensor(0.0985, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6253\n",
      "Loss: tensor(0.0985, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6254\n",
      "Loss: tensor(0.0985, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6255\n",
      "Loss: tensor(0.0985, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6256\n",
      "Loss: tensor(0.0985, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6257\n",
      "Loss: tensor(0.0985, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6258\n",
      "Loss: tensor(0.0985, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6259\n",
      "Loss: tensor(0.0985, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6260\n",
      "Loss: tensor(0.0985, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6261\n",
      "Loss: tensor(0.0985, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6262\n",
      "Loss: tensor(0.0985, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6263\n",
      "Loss: tensor(0.0985, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6264\n",
      "Loss: tensor(0.0985, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6265\n",
      "Loss: tensor(0.0985, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6266\n",
      "Loss: tensor(0.0985, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6267\n",
      "Loss: tensor(0.0985, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6268\n",
      "Loss: tensor(0.0985, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6269\n",
      "Loss: tensor(0.0985, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6270\n",
      "Loss: tensor(0.0985, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6271\n",
      "Loss: tensor(0.0985, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6272\n",
      "Loss: tensor(0.0985, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6273\n",
      "Loss: tensor(0.0985, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6274\n",
      "Loss: tensor(0.0985, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6275\n",
      "Loss: tensor(0.0984, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6276\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor(0.0984, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6277\n",
      "Loss: tensor(0.0984, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6278\n",
      "Loss: tensor(0.0984, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6279\n",
      "Loss: tensor(0.0984, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6280\n",
      "Loss: tensor(0.0984, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6281\n",
      "Loss: tensor(0.0984, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6282\n",
      "Loss: tensor(0.0984, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6283\n",
      "Loss: tensor(0.0984, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6284\n",
      "Loss: tensor(0.0984, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6285\n",
      "Loss: tensor(0.0984, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6286\n",
      "Loss: tensor(0.0984, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6287\n",
      "Loss: tensor(0.0984, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6288\n",
      "Loss: tensor(0.0984, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6289\n",
      "Loss: tensor(0.0984, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6290\n",
      "Loss: tensor(0.0984, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6291\n",
      "Loss: tensor(0.0984, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6292\n",
      "Loss: tensor(0.0984, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6293\n",
      "Loss: tensor(0.0984, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6294\n",
      "Loss: tensor(0.0984, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6295\n",
      "Loss: tensor(0.0984, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6296\n",
      "Loss: tensor(0.0984, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6297\n",
      "Loss: tensor(0.0984, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6298\n",
      "Loss: tensor(0.0984, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6299\n",
      "Loss: tensor(0.0984, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6300\n",
      "Loss: tensor(0.0984, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6301\n",
      "Loss: tensor(0.0984, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6302\n",
      "Loss: tensor(0.0984, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6303\n",
      "Loss: tensor(0.0984, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6304\n",
      "Loss: tensor(0.0984, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6305\n",
      "Loss: tensor(0.0984, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6306\n",
      "Loss: tensor(0.0984, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6307\n",
      "Loss: tensor(0.0984, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6308\n",
      "Loss: tensor(0.0984, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6309\n",
      "Loss: tensor(0.0984, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6310\n",
      "Loss: tensor(0.0984, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6311\n",
      "Loss: tensor(0.0984, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6312\n",
      "Loss: tensor(0.0984, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6313\n",
      "Loss: tensor(0.0984, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6314\n",
      "Loss: tensor(0.0984, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6315\n",
      "Loss: tensor(0.0984, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6316\n",
      "Loss: tensor(0.0984, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6317\n",
      "Loss: tensor(0.0984, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6318\n",
      "Loss: tensor(0.0984, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6319\n",
      "Loss: tensor(0.0984, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6320\n",
      "Loss: tensor(0.0984, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6321\n",
      "Loss: tensor(0.0984, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6322\n",
      "Loss: tensor(0.0984, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6323\n",
      "Loss: tensor(0.0984, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6324\n",
      "Loss: tensor(0.0984, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6325\n",
      "Loss: tensor(0.0984, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6326\n",
      "Loss: tensor(0.0984, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6327\n",
      "Loss: tensor(0.0984, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6328\n",
      "Loss: tensor(0.0984, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6329\n",
      "Loss: tensor(0.0984, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6330\n",
      "Loss: tensor(0.0984, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6331\n",
      "Loss: tensor(0.0984, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6332\n",
      "Loss: tensor(0.0984, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6333\n",
      "Loss: tensor(0.0984, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6334\n",
      "Loss: tensor(0.0984, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6335\n",
      "Loss: tensor(0.0984, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6336\n",
      "Loss: tensor(0.0983, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6337\n",
      "Loss: tensor(0.0983, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6338\n",
      "Loss: tensor(0.0983, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6339\n",
      "Loss: tensor(0.0983, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6340\n",
      "Loss: tensor(0.0983, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6341\n",
      "Loss: tensor(0.0983, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6342\n",
      "Loss: tensor(0.0983, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6343\n",
      "Loss: tensor(0.0983, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6344\n",
      "Loss: tensor(0.0983, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6345\n",
      "Loss: tensor(0.0983, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6346\n",
      "Loss: tensor(0.0983, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6347\n",
      "Loss: tensor(0.0983, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6348\n",
      "Loss: tensor(0.0983, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6349\n",
      "Loss: tensor(0.0983, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6350\n",
      "Loss: tensor(0.0983, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6351\n",
      "Loss: tensor(0.0983, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6352\n",
      "Loss: tensor(0.0983, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6353\n",
      "Loss: tensor(0.0983, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6354\n",
      "Loss: tensor(0.0983, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6355\n",
      "Loss: tensor(0.0983, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6356\n",
      "Loss: tensor(0.0983, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6357\n",
      "Loss: tensor(0.0983, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6358\n",
      "Loss: tensor(0.0983, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6359\n",
      "Loss: tensor(0.0983, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6360\n",
      "Loss: tensor(0.0983, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6361\n",
      "Loss: tensor(0.0983, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6362\n",
      "Loss: tensor(0.0983, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6363\n",
      "Loss: tensor(0.0983, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6364\n",
      "Loss: tensor(0.0983, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6365\n",
      "Loss: tensor(0.0983, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6366\n",
      "Loss: tensor(0.0983, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6367\n",
      "Loss: tensor(0.0983, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6368\n",
      "Loss: tensor(0.0983, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6369\n",
      "Loss: tensor(0.0983, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6370\n",
      "Loss: tensor(0.0983, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6371\n",
      "Loss: tensor(0.0983, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6372\n",
      "Loss: tensor(0.0983, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6373\n",
      "Loss: tensor(0.0983, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6374\n",
      "Loss: tensor(0.0983, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6375\n",
      "Loss: tensor(0.0983, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6376\n",
      "Loss: tensor(0.0983, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6377\n",
      "Loss: tensor(0.0983, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6378\n",
      "Loss: tensor(0.0983, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6379\n",
      "Loss: tensor(0.0983, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6380\n",
      "Loss: tensor(0.0983, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6381\n",
      "Loss: tensor(0.0983, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6382\n",
      "Loss: tensor(0.0983, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6383\n",
      "Loss: tensor(0.0983, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6384\n",
      "Loss: tensor(0.0983, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6385\n",
      "Loss: tensor(0.0983, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6386\n",
      "Loss: tensor(0.0983, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6387\n",
      "Loss: tensor(0.0983, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6388\n",
      "Loss: tensor(0.0983, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6389\n",
      "Loss: tensor(0.0983, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6390\n",
      "Loss: tensor(0.0983, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6391\n",
      "Loss: tensor(0.0983, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6392\n",
      "Loss: tensor(0.0983, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6393\n",
      "Loss: tensor(0.0983, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6394\n",
      "Loss: tensor(0.0983, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6395\n",
      "Loss: tensor(0.0983, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6396\n",
      "Loss: tensor(0.0983, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6397\n",
      "Loss: tensor(0.0983, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6398\n",
      "Loss: tensor(0.0983, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6399\n",
      "Loss: tensor(0.0983, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor(0.0983, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6401\n",
      "Loss: tensor(0.0983, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6402\n",
      "Loss: tensor(0.0983, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6403\n",
      "Loss: tensor(0.0983, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6404\n",
      "Loss: tensor(0.0983, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6405\n",
      "Loss: tensor(0.0983, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6406\n",
      "Loss: tensor(0.0983, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6407\n",
      "Loss: tensor(0.0982, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6408\n",
      "Loss: tensor(0.0982, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6409\n",
      "Loss: tensor(0.0982, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6410\n",
      "Loss: tensor(0.0982, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6411\n",
      "Loss: tensor(0.0982, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6412\n",
      "Loss: tensor(0.0982, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6413\n",
      "Loss: tensor(0.0982, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6414\n",
      "Loss: tensor(0.0982, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6415\n",
      "Loss: tensor(0.0982, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6416\n",
      "Loss: tensor(0.0982, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6417\n",
      "Loss: tensor(0.0982, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6418\n",
      "Loss: tensor(0.0982, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6419\n",
      "Loss: tensor(0.0982, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6420\n",
      "Loss: tensor(0.0982, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6421\n",
      "Loss: tensor(0.0982, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6422\n",
      "Loss: tensor(0.0982, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6423\n",
      "Loss: tensor(0.0982, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6424\n",
      "Loss: tensor(0.0982, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6425\n",
      "Loss: tensor(0.0982, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6426\n",
      "Loss: tensor(0.0982, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6427\n",
      "Loss: tensor(0.0982, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6428\n",
      "Loss: tensor(0.0982, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6429\n",
      "Loss: tensor(0.0982, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6430\n",
      "Loss: tensor(0.0982, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6431\n",
      "Loss: tensor(0.0982, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6432\n",
      "Loss: tensor(0.0982, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6433\n",
      "Loss: tensor(0.0982, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6434\n",
      "Loss: tensor(0.0982, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6435\n",
      "Loss: tensor(0.0982, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6436\n",
      "Loss: tensor(0.0982, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6437\n",
      "Loss: tensor(0.0982, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6438\n",
      "Loss: tensor(0.0982, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6439\n",
      "Loss: tensor(0.0982, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6440\n",
      "Loss: tensor(0.0982, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6441\n",
      "Loss: tensor(0.0982, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6442\n",
      "Loss: tensor(0.0982, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6443\n",
      "Loss: tensor(0.0982, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6444\n",
      "Loss: tensor(0.0982, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6445\n",
      "Loss: tensor(0.0982, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6446\n",
      "Loss: tensor(0.0982, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6447\n",
      "Loss: tensor(0.0982, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6448\n",
      "Loss: tensor(0.0982, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6449\n",
      "Loss: tensor(0.0982, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6450\n",
      "Loss: tensor(0.0982, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6451\n",
      "Loss: tensor(0.0982, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6452\n",
      "Loss: tensor(0.0982, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6453\n",
      "Loss: tensor(0.0982, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6454\n",
      "Loss: tensor(0.0982, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6455\n",
      "Loss: tensor(0.0982, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6456\n",
      "Loss: tensor(0.0982, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6457\n",
      "Loss: tensor(0.0982, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6458\n",
      "Loss: tensor(0.0982, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6459\n",
      "Loss: tensor(0.0982, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6460\n",
      "Loss: tensor(0.0982, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6461\n",
      "Loss: tensor(0.0982, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6462\n",
      "Loss: tensor(0.0982, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6463\n",
      "Loss: tensor(0.0982, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6464\n",
      "Loss: tensor(0.0982, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6465\n",
      "Loss: tensor(0.0982, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6466\n",
      "Loss: tensor(0.0982, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6467\n",
      "Loss: tensor(0.0982, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6468\n",
      "Loss: tensor(0.0982, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6469\n",
      "Loss: tensor(0.0982, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6470\n",
      "Loss: tensor(0.0982, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6471\n",
      "Loss: tensor(0.0982, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6472\n",
      "Loss: tensor(0.0982, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6473\n",
      "Loss: tensor(0.0982, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6474\n",
      "Loss: tensor(0.0982, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6475\n",
      "Loss: tensor(0.0981, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6476\n",
      "Loss: tensor(0.0981, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6477\n",
      "Loss: tensor(0.0981, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6478\n",
      "Loss: tensor(0.0981, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6479\n",
      "Loss: tensor(0.0981, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6480\n",
      "Loss: tensor(0.0981, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6481\n",
      "Loss: tensor(0.0981, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6482\n",
      "Loss: tensor(0.0981, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6483\n",
      "Loss: tensor(0.0981, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6484\n",
      "Loss: tensor(0.0981, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6485\n",
      "Loss: tensor(0.0981, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6486\n",
      "Loss: tensor(0.0981, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6487\n",
      "Loss: tensor(0.0981, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6488\n",
      "Loss: tensor(0.0981, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6489\n",
      "Loss: tensor(0.0981, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6490\n",
      "Loss: tensor(0.0981, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6491\n",
      "Loss: tensor(0.0981, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6492\n",
      "Loss: tensor(0.0981, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6493\n",
      "Loss: tensor(0.0981, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6494\n",
      "Loss: tensor(0.0981, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6495\n",
      "Loss: tensor(0.0981, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6496\n",
      "Loss: tensor(0.0981, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6497\n",
      "Loss: tensor(0.0981, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6498\n",
      "Loss: tensor(0.0981, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6499\n",
      "Loss: tensor(0.0981, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6500\n",
      "Loss: tensor(0.0981, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6501\n",
      "Loss: tensor(0.0981, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6502\n",
      "Loss: tensor(0.0981, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6503\n",
      "Loss: tensor(0.0981, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6504\n",
      "Loss: tensor(0.0981, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6505\n",
      "Loss: tensor(0.0981, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6506\n",
      "Loss: tensor(0.0981, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6507\n",
      "Loss: tensor(0.0981, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6508\n",
      "Loss: tensor(0.0981, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6509\n",
      "Loss: tensor(0.0981, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6510\n",
      "Loss: tensor(0.0981, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6511\n",
      "Loss: tensor(0.0981, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6512\n",
      "Loss: tensor(0.0981, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6513\n",
      "Loss: tensor(0.0981, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6514\n",
      "Loss: tensor(0.0981, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6515\n",
      "Loss: tensor(0.0981, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6516\n",
      "Loss: tensor(0.0981, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6517\n",
      "Loss: tensor(0.0981, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6518\n",
      "Loss: tensor(0.0981, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6519\n",
      "Loss: tensor(0.0981, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6520\n",
      "Loss: tensor(0.0981, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6521\n",
      "Loss: tensor(0.0981, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6522\n",
      "Loss: tensor(0.0981, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6523\n",
      "Loss: tensor(0.0981, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6524\n",
      "Loss: tensor(0.0981, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6525\n",
      "Loss: tensor(0.0981, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6526\n",
      "Loss: tensor(0.0981, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6527\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor(0.0981, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6528\n",
      "Loss: tensor(0.0981, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6529\n",
      "Loss: tensor(0.0981, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6530\n",
      "Loss: tensor(0.0981, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6531\n",
      "Loss: tensor(0.0981, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6532\n",
      "Loss: tensor(0.0981, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6533\n",
      "Loss: tensor(0.0981, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6534\n",
      "Loss: tensor(0.0981, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6535\n",
      "Loss: tensor(0.0981, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6536\n",
      "Loss: tensor(0.0981, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6537\n",
      "Loss: tensor(0.0981, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6538\n",
      "Loss: tensor(0.0981, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6539\n",
      "Loss: tensor(0.0981, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6540\n",
      "Loss: tensor(0.0981, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6541\n",
      "Loss: tensor(0.0981, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6542\n",
      "Loss: tensor(0.0981, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6543\n",
      "Loss: tensor(0.0981, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6544\n",
      "Loss: tensor(0.0981, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6545\n",
      "Loss: tensor(0.0981, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6546\n",
      "Loss: tensor(0.0980, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6547\n",
      "Loss: tensor(0.0980, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6548\n",
      "Loss: tensor(0.0980, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6549\n",
      "Loss: tensor(0.0980, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6550\n",
      "Loss: tensor(0.0980, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6551\n",
      "Loss: tensor(0.0980, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6552\n",
      "Loss: tensor(0.0980, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6553\n",
      "Loss: tensor(0.0980, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6554\n",
      "Loss: tensor(0.0980, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6555\n",
      "Loss: tensor(0.0980, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6556\n",
      "Loss: tensor(0.0980, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6557\n",
      "Loss: tensor(0.0980, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6558\n",
      "Loss: tensor(0.0980, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6559\n",
      "Loss: tensor(0.0980, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6560\n",
      "Loss: tensor(0.0980, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6561\n",
      "Loss: tensor(0.0980, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6562\n",
      "Loss: tensor(0.0980, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6563\n",
      "Loss: tensor(0.0980, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6564\n",
      "Loss: tensor(0.0980, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6565\n",
      "Loss: tensor(0.0980, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6566\n",
      "Loss: tensor(0.0980, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6567\n",
      "Loss: tensor(0.0980, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6568\n",
      "Loss: tensor(0.0980, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6569\n",
      "Loss: tensor(0.0980, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6570\n",
      "Loss: tensor(0.0980, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6571\n",
      "Loss: tensor(0.0980, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6572\n",
      "Loss: tensor(0.0980, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6573\n",
      "Loss: tensor(0.0980, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6574\n",
      "Loss: tensor(0.0980, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6575\n",
      "Loss: tensor(0.0980, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6576\n",
      "Loss: tensor(0.0980, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6577\n",
      "Loss: tensor(0.0980, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6578\n",
      "Loss: tensor(0.0980, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6579\n",
      "Loss: tensor(0.0980, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6580\n",
      "Loss: tensor(0.0980, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6581\n",
      "Loss: tensor(0.0980, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6582\n",
      "Loss: tensor(0.0980, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6583\n",
      "Loss: tensor(0.0980, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6584\n",
      "Loss: tensor(0.0980, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6585\n",
      "Loss: tensor(0.0980, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6586\n",
      "Loss: tensor(0.0980, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6587\n",
      "Loss: tensor(0.0980, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6588\n",
      "Loss: tensor(0.0980, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6589\n",
      "Loss: tensor(0.0980, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6590\n",
      "Loss: tensor(0.0980, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6591\n",
      "Loss: tensor(0.0980, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6592\n",
      "Loss: tensor(0.0980, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6593\n",
      "Loss: tensor(0.0980, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6594\n",
      "Loss: tensor(0.0980, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6595\n",
      "Loss: tensor(0.0980, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6596\n",
      "Loss: tensor(0.0980, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6597\n",
      "Loss: tensor(0.0980, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6598\n",
      "Loss: tensor(0.0980, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6599\n",
      "Loss: tensor(0.0980, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6600\n",
      "Loss: tensor(0.0980, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6601\n",
      "Loss: tensor(0.0980, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6602\n",
      "Loss: tensor(0.0980, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6603\n",
      "Loss: tensor(0.0980, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6604\n",
      "Loss: tensor(0.0980, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6605\n",
      "Loss: tensor(0.0980, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6606\n",
      "Loss: tensor(0.0980, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6607\n",
      "Loss: tensor(0.0980, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6608\n",
      "Loss: tensor(0.0980, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6609\n",
      "Loss: tensor(0.0980, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6610\n",
      "Loss: tensor(0.0980, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6611\n",
      "Loss: tensor(0.0980, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6612\n",
      "Loss: tensor(0.0980, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6613\n",
      "Loss: tensor(0.0980, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6614\n",
      "Loss: tensor(0.0980, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6615\n",
      "Loss: tensor(0.0980, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6616\n",
      "Loss: tensor(0.0980, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6617\n",
      "Loss: tensor(0.0980, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6618\n",
      "Loss: tensor(0.0980, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6619\n",
      "Loss: tensor(0.0979, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6620\n",
      "Loss: tensor(0.0979, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6621\n",
      "Loss: tensor(0.0979, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6622\n",
      "Loss: tensor(0.0979, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6623\n",
      "Loss: tensor(0.0979, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6624\n",
      "Loss: tensor(0.0979, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6625\n",
      "Loss: tensor(0.0979, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6626\n",
      "Loss: tensor(0.0979, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6627\n",
      "Loss: tensor(0.0979, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6628\n",
      "Loss: tensor(0.0979, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6629\n",
      "Loss: tensor(0.0979, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6630\n",
      "Loss: tensor(0.0979, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6631\n",
      "Loss: tensor(0.0979, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6632\n",
      "Loss: tensor(0.0979, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6633\n",
      "Loss: tensor(0.0979, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6634\n",
      "Loss: tensor(0.0979, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6635\n",
      "Loss: tensor(0.0979, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6636\n",
      "Loss: tensor(0.0979, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6637\n",
      "Loss: tensor(0.0979, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6638\n",
      "Loss: tensor(0.0979, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6639\n",
      "Loss: tensor(0.0980, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6640\n",
      "Loss: tensor(0.0980, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6641\n",
      "Loss: tensor(0.0979, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6642\n",
      "Loss: tensor(0.0979, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6643\n",
      "Loss: tensor(0.0979, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6644\n",
      "Loss: tensor(0.0979, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6645\n",
      "Loss: tensor(0.0979, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6646\n",
      "Loss: tensor(0.0979, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6647\n",
      "Loss: tensor(0.0979, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6648\n",
      "Loss: tensor(0.0979, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6649\n",
      "Loss: tensor(0.0979, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6650\n",
      "Loss: tensor(0.0979, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6651\n",
      "Loss: tensor(0.0979, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6652\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor(0.0979, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6653\n",
      "Loss: tensor(0.0979, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6654\n",
      "Loss: tensor(0.0979, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6655\n",
      "Loss: tensor(0.0979, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6656\n",
      "Loss: tensor(0.0979, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6657\n",
      "Loss: tensor(0.0979, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6658\n",
      "Loss: tensor(0.0979, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6659\n",
      "Loss: tensor(0.0979, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6660\n",
      "Loss: tensor(0.0979, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6661\n",
      "Loss: tensor(0.0979, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6662\n",
      "Loss: tensor(0.0979, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6663\n",
      "Loss: tensor(0.0979, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6664\n",
      "Loss: tensor(0.0979, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6665\n",
      "Loss: tensor(0.0979, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6666\n",
      "Loss: tensor(0.0979, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6667\n",
      "Loss: tensor(0.0979, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6668\n",
      "Loss: tensor(0.0979, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6669\n",
      "Loss: tensor(0.0979, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6670\n",
      "Loss: tensor(0.0979, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6671\n",
      "Loss: tensor(0.0979, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6672\n",
      "Loss: tensor(0.0979, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6673\n",
      "Loss: tensor(0.0979, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6674\n",
      "Loss: tensor(0.0979, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6675\n",
      "Loss: tensor(0.0979, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6676\n",
      "Loss: tensor(0.0979, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6677\n",
      "Loss: tensor(0.0979, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6678\n",
      "Loss: tensor(0.0979, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6679\n",
      "Loss: tensor(0.0979, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6680\n",
      "Loss: tensor(0.0979, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6681\n",
      "Loss: tensor(0.0979, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6682\n",
      "Loss: tensor(0.0979, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6683\n",
      "Loss: tensor(0.0979, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6684\n",
      "Loss: tensor(0.0979, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6685\n",
      "Loss: tensor(0.0979, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6686\n",
      "Loss: tensor(0.0979, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6687\n",
      "Loss: tensor(0.0979, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6688\n",
      "Loss: tensor(0.0979, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6689\n",
      "Loss: tensor(0.0979, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6690\n",
      "Loss: tensor(0.0979, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6691\n",
      "Loss: tensor(0.0979, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6692\n",
      "Loss: tensor(0.0979, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6693\n",
      "Loss: tensor(0.0978, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6694\n",
      "Loss: tensor(0.0978, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6695\n",
      "Loss: tensor(0.0978, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6696\n",
      "Loss: tensor(0.0978, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6697\n",
      "Loss: tensor(0.0978, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6698\n",
      "Loss: tensor(0.0978, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6699\n",
      "Loss: tensor(0.0978, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6700\n",
      "Loss: tensor(0.0978, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6701\n",
      "Loss: tensor(0.0978, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6702\n",
      "Loss: tensor(0.0978, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6703\n",
      "Loss: tensor(0.0978, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6704\n",
      "Loss: tensor(0.0978, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6705\n",
      "Loss: tensor(0.0978, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6706\n",
      "Loss: tensor(0.0978, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6707\n",
      "Loss: tensor(0.0978, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6708\n",
      "Loss: tensor(0.0978, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6709\n",
      "Loss: tensor(0.0978, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6710\n",
      "Loss: tensor(0.0978, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6711\n",
      "Loss: tensor(0.0978, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6712\n",
      "Loss: tensor(0.0978, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6713\n",
      "Loss: tensor(0.0978, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6714\n",
      "Loss: tensor(0.0978, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6715\n",
      "Loss: tensor(0.0978, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6716\n",
      "Loss: tensor(0.0978, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6717\n",
      "Loss: tensor(0.0978, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6718\n",
      "Loss: tensor(0.0978, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6719\n",
      "Loss: tensor(0.0978, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6720\n",
      "Loss: tensor(0.0978, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6721\n",
      "Loss: tensor(0.0978, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6722\n",
      "Loss: tensor(0.0978, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6723\n",
      "Loss: tensor(0.0978, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6724\n",
      "Loss: tensor(0.0978, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6725\n",
      "Loss: tensor(0.0978, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6726\n",
      "Loss: tensor(0.0978, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6727\n",
      "Loss: tensor(0.0978, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6728\n",
      "Loss: tensor(0.0978, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6729\n",
      "Loss: tensor(0.0978, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6730\n",
      "Loss: tensor(0.0978, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6731\n",
      "Loss: tensor(0.0978, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6732\n",
      "Loss: tensor(0.0978, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6733\n",
      "Loss: tensor(0.0978, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6734\n",
      "Loss: tensor(0.0978, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6735\n",
      "Loss: tensor(0.0978, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6736\n",
      "Loss: tensor(0.0978, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6737\n",
      "Loss: tensor(0.0978, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6738\n",
      "Loss: tensor(0.0978, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6739\n",
      "Loss: tensor(0.0978, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6740\n",
      "Loss: tensor(0.0978, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6741\n",
      "Loss: tensor(0.0978, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6742\n",
      "Loss: tensor(0.0978, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6743\n",
      "Loss: tensor(0.0978, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6744\n",
      "Loss: tensor(0.0978, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6745\n",
      "Loss: tensor(0.0978, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6746\n",
      "Loss: tensor(0.0978, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6747\n",
      "Loss: tensor(0.0978, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6748\n",
      "Loss: tensor(0.0978, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6749\n",
      "Loss: tensor(0.0978, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6750\n",
      "Loss: tensor(0.0978, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6751\n",
      "Loss: tensor(0.0978, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6752\n",
      "Loss: tensor(0.0978, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6753\n",
      "Loss: tensor(0.0978, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6754\n",
      "Loss: tensor(0.0978, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6755\n",
      "Loss: tensor(0.0978, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6756\n",
      "Loss: tensor(0.0978, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6757\n",
      "Loss: tensor(0.0978, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6758\n",
      "Loss: tensor(0.0978, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6759\n",
      "Loss: tensor(0.0978, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6760\n",
      "Loss: tensor(0.0978, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6761\n",
      "Loss: tensor(0.0978, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6762\n",
      "Loss: tensor(0.0978, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6763\n",
      "Loss: tensor(0.0978, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6764\n",
      "Loss: tensor(0.0978, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6765\n",
      "Loss: tensor(0.0978, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6766\n",
      "Loss: tensor(0.0978, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6767\n",
      "Loss: tensor(0.0978, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6768\n",
      "Loss: tensor(0.0978, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6769\n",
      "Loss: tensor(0.0978, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6770\n",
      "Loss: tensor(0.0978, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6771\n",
      "Loss: tensor(0.0977, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6772\n",
      "Loss: tensor(0.0977, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6773\n",
      "Loss: tensor(0.0977, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6774\n",
      "Loss: tensor(0.0977, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6775\n",
      "Loss: tensor(0.0977, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6776\n",
      "Loss: tensor(0.0977, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6777\n",
      "Loss: tensor(0.0977, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6778\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor(0.0977, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6779\n",
      "Loss: tensor(0.0977, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6780\n",
      "Loss: tensor(0.0977, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6781\n",
      "Loss: tensor(0.0977, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6782\n",
      "Loss: tensor(0.0977, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6783\n",
      "Loss: tensor(0.0977, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6784\n",
      "Loss: tensor(0.0977, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6785\n",
      "Loss: tensor(0.0977, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6786\n",
      "Loss: tensor(0.0977, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6787\n",
      "Loss: tensor(0.0977, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6788\n",
      "Loss: tensor(0.0977, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6789\n",
      "Loss: tensor(0.0977, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6790\n",
      "Loss: tensor(0.0977, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6791\n",
      "Loss: tensor(0.0977, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6792\n",
      "Loss: tensor(0.0977, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6793\n",
      "Loss: tensor(0.0977, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6794\n",
      "Loss: tensor(0.0977, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6795\n",
      "Loss: tensor(0.0977, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6796\n",
      "Loss: tensor(0.0977, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6797\n",
      "Loss: tensor(0.0977, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6798\n",
      "Loss: tensor(0.0977, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6799\n",
      "Loss: tensor(0.0977, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6800\n",
      "Loss: tensor(0.0977, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6801\n",
      "Loss: tensor(0.0977, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6802\n",
      "Loss: tensor(0.0977, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6803\n",
      "Loss: tensor(0.0977, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6804\n",
      "Loss: tensor(0.0977, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6805\n",
      "Loss: tensor(0.0977, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6806\n",
      "Loss: tensor(0.0977, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6807\n",
      "Loss: tensor(0.0977, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6808\n",
      "Loss: tensor(0.0977, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6809\n",
      "Loss: tensor(0.0977, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6810\n",
      "Loss: tensor(0.0977, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6811\n",
      "Loss: tensor(0.0977, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6812\n",
      "Loss: tensor(0.0977, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6813\n",
      "Loss: tensor(0.0977, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6814\n",
      "Loss: tensor(0.0977, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6815\n",
      "Loss: tensor(0.0977, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6816\n",
      "Loss: tensor(0.0977, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6817\n",
      "Loss: tensor(0.0977, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6818\n",
      "Loss: tensor(0.0977, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6819\n",
      "Loss: tensor(0.0977, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6820\n",
      "Loss: tensor(0.0977, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6821\n",
      "Loss: tensor(0.0977, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6822\n",
      "Loss: tensor(0.0977, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6823\n",
      "Loss: tensor(0.0977, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6824\n",
      "Loss: tensor(0.0977, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6825\n",
      "Loss: tensor(0.0977, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6826\n",
      "Loss: tensor(0.0977, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6827\n",
      "Loss: tensor(0.0977, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6828\n",
      "Loss: tensor(0.0977, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6829\n",
      "Loss: tensor(0.0977, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6830\n",
      "Loss: tensor(0.0977, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6831\n",
      "Loss: tensor(0.0977, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6832\n",
      "Loss: tensor(0.0977, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6833\n",
      "Loss: tensor(0.0977, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6834\n",
      "Loss: tensor(0.0977, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6835\n",
      "Loss: tensor(0.0977, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6836\n",
      "Loss: tensor(0.0977, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6837\n",
      "Loss: tensor(0.0977, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6838\n",
      "Loss: tensor(0.0977, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6839\n",
      "Loss: tensor(0.0977, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6840\n",
      "Loss: tensor(0.0977, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6841\n",
      "Loss: tensor(0.0977, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6842\n",
      "Loss: tensor(0.0977, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6843\n",
      "Loss: tensor(0.0977, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6844\n",
      "Loss: tensor(0.0977, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6845\n",
      "Loss: tensor(0.0976, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6846\n",
      "Loss: tensor(0.0976, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6847\n",
      "Loss: tensor(0.0976, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6848\n",
      "Loss: tensor(0.0976, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6849\n",
      "Loss: tensor(0.0976, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6850\n",
      "Loss: tensor(0.0976, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6851\n",
      "Loss: tensor(0.0976, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6852\n",
      "Loss: tensor(0.0976, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6853\n",
      "Loss: tensor(0.0976, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6854\n",
      "Loss: tensor(0.0976, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6855\n",
      "Loss: tensor(0.0976, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6856\n",
      "Loss: tensor(0.0976, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6857\n",
      "Loss: tensor(0.0976, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6858\n",
      "Loss: tensor(0.0976, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6859\n",
      "Loss: tensor(0.0976, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6860\n",
      "Loss: tensor(0.0976, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6861\n",
      "Loss: tensor(0.0976, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6862\n",
      "Loss: tensor(0.0976, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6863\n",
      "Loss: tensor(0.0976, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6864\n",
      "Loss: tensor(0.0976, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6865\n",
      "Loss: tensor(0.0976, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6866\n",
      "Loss: tensor(0.0976, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6867\n",
      "Loss: tensor(0.0976, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6868\n",
      "Loss: tensor(0.0976, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6869\n",
      "Loss: tensor(0.0976, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6870\n",
      "Loss: tensor(0.0976, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6871\n",
      "Loss: tensor(0.0976, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6872\n",
      "Loss: tensor(0.0976, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6873\n",
      "Loss: tensor(0.0976, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6874\n",
      "Loss: tensor(0.0976, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6875\n",
      "Loss: tensor(0.0976, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6876\n",
      "Loss: tensor(0.0976, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6877\n",
      "Loss: tensor(0.0976, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6878\n",
      "Loss: tensor(0.0976, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6879\n",
      "Loss: tensor(0.0976, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6880\n",
      "Loss: tensor(0.0976, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6881\n",
      "Loss: tensor(0.0976, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6882\n",
      "Loss: tensor(0.0976, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6883\n",
      "Loss: tensor(0.0976, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6884\n",
      "Loss: tensor(0.0976, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6885\n",
      "Loss: tensor(0.0976, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6886\n",
      "Loss: tensor(0.0976, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6887\n",
      "Loss: tensor(0.0976, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6888\n",
      "Loss: tensor(0.0976, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6889\n",
      "Loss: tensor(0.0976, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6890\n",
      "Loss: tensor(0.0976, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6891\n",
      "Loss: tensor(0.0976, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6892\n",
      "Loss: tensor(0.0976, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6893\n",
      "Loss: tensor(0.0976, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6894\n",
      "Loss: tensor(0.0976, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6895\n",
      "Loss: tensor(0.0976, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6896\n",
      "Loss: tensor(0.0976, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6897\n",
      "Loss: tensor(0.0976, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6898\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor(0.0976, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6899\n",
      "Loss: tensor(0.0976, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6900\n",
      "Loss: tensor(0.0976, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6901\n",
      "Loss: tensor(0.0976, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6902\n",
      "Loss: tensor(0.0976, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6903\n",
      "Loss: tensor(0.0976, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6904\n",
      "Loss: tensor(0.0976, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6905\n",
      "Loss: tensor(0.0976, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6906\n",
      "Loss: tensor(0.0976, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6907\n",
      "Loss: tensor(0.0976, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6908\n",
      "Loss: tensor(0.0976, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6909\n",
      "Loss: tensor(0.0976, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6910\n",
      "Loss: tensor(0.0976, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6911\n",
      "Loss: tensor(0.0976, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6912\n",
      "Loss: tensor(0.0976, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6913\n",
      "Loss: tensor(0.0976, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6914\n",
      "Loss: tensor(0.0976, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6915\n",
      "Loss: tensor(0.0976, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6916\n",
      "Loss: tensor(0.0976, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6917\n",
      "Loss: tensor(0.0976, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6918\n",
      "Loss: tensor(0.0976, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6919\n",
      "Loss: tensor(0.0976, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6920\n",
      "Loss: tensor(0.0976, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6921\n",
      "Loss: tensor(0.0976, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6922\n",
      "Loss: tensor(0.0976, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6923\n",
      "Loss: tensor(0.0976, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6924\n",
      "Loss: tensor(0.0975, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6925\n",
      "Loss: tensor(0.0975, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6926\n",
      "Loss: tensor(0.0975, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6927\n",
      "Loss: tensor(0.0975, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6928\n",
      "Loss: tensor(0.0975, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6929\n",
      "Loss: tensor(0.0975, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6930\n",
      "Loss: tensor(0.0975, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6931\n",
      "Loss: tensor(0.0975, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6932\n",
      "Loss: tensor(0.0975, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6933\n",
      "Loss: tensor(0.0975, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6934\n",
      "Loss: tensor(0.0975, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6935\n",
      "Loss: tensor(0.0975, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6936\n",
      "Loss: tensor(0.0975, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6937\n",
      "Loss: tensor(0.0975, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6938\n",
      "Loss: tensor(0.0975, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6939\n",
      "Loss: tensor(0.0975, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6940\n",
      "Loss: tensor(0.0975, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6941\n",
      "Loss: tensor(0.0975, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6942\n",
      "Loss: tensor(0.0975, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6943\n",
      "Loss: tensor(0.0975, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6944\n",
      "Loss: tensor(0.0975, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6945\n",
      "Loss: tensor(0.0975, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6946\n",
      "Loss: tensor(0.0975, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6947\n",
      "Loss: tensor(0.0975, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6948\n",
      "Loss: tensor(0.0975, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6949\n",
      "Loss: tensor(0.0975, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6950\n",
      "Loss: tensor(0.0975, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6951\n",
      "Loss: tensor(0.0975, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6952\n",
      "Loss: tensor(0.0975, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6953\n",
      "Loss: tensor(0.0975, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6954\n",
      "Loss: tensor(0.0975, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6955\n",
      "Loss: tensor(0.0975, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6956\n",
      "Loss: tensor(0.0975, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6957\n",
      "Loss: tensor(0.0975, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6958\n",
      "Loss: tensor(0.0975, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6959\n",
      "Loss: tensor(0.0975, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6960\n",
      "Loss: tensor(0.0975, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6961\n",
      "Loss: tensor(0.0975, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6962\n",
      "Loss: tensor(0.0975, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6963\n",
      "Loss: tensor(0.0975, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6964\n",
      "Loss: tensor(0.0975, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6965\n",
      "Loss: tensor(0.0975, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6966\n",
      "Loss: tensor(0.0975, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6967\n",
      "Loss: tensor(0.0975, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6968\n",
      "Loss: tensor(0.0975, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6969\n",
      "Loss: tensor(0.0975, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6970\n",
      "Loss: tensor(0.0975, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6971\n",
      "Loss: tensor(0.0975, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6972\n",
      "Loss: tensor(0.0975, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6973\n",
      "Loss: tensor(0.0975, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6974\n",
      "Loss: tensor(0.0975, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6975\n",
      "Loss: tensor(0.0975, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6976\n",
      "Loss: tensor(0.0975, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6977\n",
      "Loss: tensor(0.0975, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6978\n",
      "Loss: tensor(0.0975, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6979\n",
      "Loss: tensor(0.0975, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6980\n",
      "Loss: tensor(0.0975, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6981\n",
      "Loss: tensor(0.0975, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6982\n",
      "Loss: tensor(0.0975, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6983\n",
      "Loss: tensor(0.0975, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6984\n",
      "Loss: tensor(0.0975, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6985\n",
      "Loss: tensor(0.0975, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6986\n",
      "Loss: tensor(0.0975, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6987\n",
      "Loss: tensor(0.0975, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6988\n",
      "Loss: tensor(0.0975, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6989\n",
      "Loss: tensor(0.0975, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6990\n",
      "Loss: tensor(0.0975, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6991\n",
      "Loss: tensor(0.0975, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6992\n",
      "Loss: tensor(0.0975, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6993\n",
      "Loss: tensor(0.0975, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6994\n",
      "Loss: tensor(0.0975, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6995\n",
      "Loss: tensor(0.0975, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6996\n",
      "Loss: tensor(0.0975, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6997\n",
      "Loss: tensor(0.0975, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6998\n",
      "Loss: tensor(0.0975, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6999\n",
      "Loss: tensor(0.0975, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7000\n",
      "Loss: tensor(0.0975, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7001\n",
      "Loss: tensor(0.0975, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7002\n",
      "Loss: tensor(0.0975, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7003\n",
      "Loss: tensor(0.0975, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7004\n",
      "Loss: tensor(0.0975, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7005\n",
      "Loss: tensor(0.0975, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7006\n",
      "Loss: tensor(0.0975, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7007\n",
      "Loss: tensor(0.0975, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7008\n",
      "Loss: tensor(0.0975, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7009\n",
      "Loss: tensor(0.0975, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7010\n",
      "Loss: tensor(0.0974, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7011\n",
      "Loss: tensor(0.0974, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7012\n",
      "Loss: tensor(0.0974, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7013\n",
      "Loss: tensor(0.0974, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7014\n",
      "Loss: tensor(0.0974, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7015\n",
      "Loss: tensor(0.0974, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7016\n",
      "Loss: tensor(0.0974, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7017\n",
      "Loss: tensor(0.0974, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7018\n",
      "Loss: tensor(0.0974, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7019\n",
      "Loss: tensor(0.0974, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7020\n",
      "Loss: tensor(0.0974, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7021\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor(0.0974, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7022\n",
      "Loss: tensor(0.0974, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7023\n",
      "Loss: tensor(0.0974, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7024\n",
      "Loss: tensor(0.0974, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7025\n",
      "Loss: tensor(0.0974, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7026\n",
      "Loss: tensor(0.0974, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7027\n",
      "Loss: tensor(0.0974, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7028\n",
      "Loss: tensor(0.0974, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7029\n",
      "Loss: tensor(0.0974, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7030\n",
      "Loss: tensor(0.0974, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7031\n",
      "Loss: tensor(0.0974, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7032\n",
      "Loss: tensor(0.0974, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7033\n",
      "Loss: tensor(0.0974, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7034\n",
      "Loss: tensor(0.0974, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7035\n",
      "Loss: tensor(0.0974, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7036\n",
      "Loss: tensor(0.0974, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7037\n",
      "Loss: tensor(0.0974, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7038\n",
      "Loss: tensor(0.0974, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7039\n",
      "Loss: tensor(0.0974, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7040\n",
      "Loss: tensor(0.0974, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7041\n",
      "Loss: tensor(0.0974, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7042\n",
      "Loss: tensor(0.0974, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7043\n",
      "Loss: tensor(0.0974, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7044\n",
      "Loss: tensor(0.0974, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7045\n",
      "Loss: tensor(0.0974, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7046\n",
      "Loss: tensor(0.0974, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7047\n",
      "Loss: tensor(0.0974, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7048\n",
      "Loss: tensor(0.0974, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7049\n",
      "Loss: tensor(0.0974, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7050\n",
      "Loss: tensor(0.0974, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7051\n",
      "Loss: tensor(0.0974, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7052\n",
      "Loss: tensor(0.0974, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7053\n",
      "Loss: tensor(0.0974, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7054\n",
      "Loss: tensor(0.0974, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7055\n",
      "Loss: tensor(0.0974, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7056\n",
      "Loss: tensor(0.0974, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7057\n",
      "Loss: tensor(0.0974, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7058\n",
      "Loss: tensor(0.0974, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7059\n",
      "Loss: tensor(0.0974, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7060\n",
      "Loss: tensor(0.0974, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7061\n",
      "Loss: tensor(0.0974, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7062\n",
      "Loss: tensor(0.0974, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7063\n",
      "Loss: tensor(0.0974, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7064\n",
      "Loss: tensor(0.0974, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7065\n",
      "Loss: tensor(0.0974, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7066\n",
      "Loss: tensor(0.0974, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7067\n",
      "Loss: tensor(0.0974, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7068\n",
      "Loss: tensor(0.0974, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7069\n",
      "Loss: tensor(0.0974, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7070\n",
      "Loss: tensor(0.0974, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7071\n",
      "Loss: tensor(0.0974, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7072\n",
      "Loss: tensor(0.0974, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7073\n",
      "Loss: tensor(0.0974, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7074\n",
      "Loss: tensor(0.0974, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7075\n",
      "Loss: tensor(0.0974, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7076\n",
      "Loss: tensor(0.0974, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7077\n",
      "Loss: tensor(0.0974, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7078\n",
      "Loss: tensor(0.0974, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7079\n",
      "Loss: tensor(0.0974, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7080\n",
      "Loss: tensor(0.0974, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7081\n",
      "Loss: tensor(0.0974, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7082\n",
      "Loss: tensor(0.0974, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7083\n",
      "Loss: tensor(0.0974, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7084\n",
      "Loss: tensor(0.0974, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7085\n",
      "Loss: tensor(0.0974, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7086\n",
      "Loss: tensor(0.0974, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7087\n",
      "Loss: tensor(0.0974, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7088\n",
      "Loss: tensor(0.0974, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7089\n",
      "Loss: tensor(0.0974, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7090\n",
      "Loss: tensor(0.0974, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7091\n",
      "Loss: tensor(0.0974, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7092\n",
      "Loss: tensor(0.0974, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7093\n",
      "Loss: tensor(0.0973, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7094\n",
      "Loss: tensor(0.0973, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7095\n",
      "Loss: tensor(0.0973, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7096\n",
      "Loss: tensor(0.0973, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7097\n",
      "Loss: tensor(0.0973, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7098\n",
      "Loss: tensor(0.0973, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7099\n",
      "Loss: tensor(0.0973, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7100\n",
      "Loss: tensor(0.0973, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7101\n",
      "Loss: tensor(0.0973, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7102\n",
      "Loss: tensor(0.0973, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7103\n",
      "Loss: tensor(0.0973, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7104\n",
      "Loss: tensor(0.0973, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7105\n",
      "Loss: tensor(0.0973, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7106\n",
      "Loss: tensor(0.0973, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7107\n",
      "Loss: tensor(0.0973, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7108\n",
      "Loss: tensor(0.0973, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7109\n",
      "Loss: tensor(0.0973, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7110\n",
      "Loss: tensor(0.0973, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7111\n",
      "Loss: tensor(0.0973, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7112\n",
      "Loss: tensor(0.0973, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7113\n",
      "Loss: tensor(0.0973, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7114\n",
      "Loss: tensor(0.0973, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7115\n",
      "Loss: tensor(0.0973, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7116\n",
      "Loss: tensor(0.0973, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7117\n",
      "Loss: tensor(0.0973, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7118\n",
      "Loss: tensor(0.0973, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7119\n",
      "Loss: tensor(0.0973, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7120\n",
      "Loss: tensor(0.0973, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7121\n",
      "Loss: tensor(0.0973, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7122\n",
      "Loss: tensor(0.0973, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7123\n",
      "Loss: tensor(0.0973, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7124\n",
      "Loss: tensor(0.0973, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7125\n",
      "Loss: tensor(0.0973, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7126\n",
      "Loss: tensor(0.0973, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7127\n",
      "Loss: tensor(0.0973, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7128\n",
      "Loss: tensor(0.0973, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7129\n",
      "Loss: tensor(0.0973, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7130\n",
      "Loss: tensor(0.0973, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7131\n",
      "Loss: tensor(0.0973, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7132\n",
      "Loss: tensor(0.0973, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7133\n",
      "Loss: tensor(0.0973, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7134\n",
      "Loss: tensor(0.0973, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7135\n",
      "Loss: tensor(0.0973, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7136\n",
      "Loss: tensor(0.0973, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7137\n",
      "Loss: tensor(0.0973, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7138\n",
      "Loss: tensor(0.0973, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7139\n",
      "Loss: tensor(0.0973, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7140\n",
      "Loss: tensor(0.0973, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7141\n",
      "Loss: tensor(0.0973, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7142\n",
      "Loss: tensor(0.0973, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7143\n",
      "Loss: tensor(0.0973, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7144\n",
      "Loss: tensor(0.0973, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7145\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor(0.0973, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7146\n",
      "Loss: tensor(0.0973, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7147\n",
      "Loss: tensor(0.0973, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7148\n",
      "Loss: tensor(0.0973, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7149\n",
      "Loss: tensor(0.0973, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7150\n",
      "Loss: tensor(0.0973, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7151\n",
      "Loss: tensor(0.0973, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7152\n",
      "Loss: tensor(0.0973, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7153\n",
      "Loss: tensor(0.0973, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7154\n",
      "Loss: tensor(0.0973, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7155\n",
      "Loss: tensor(0.0973, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7156\n",
      "Loss: tensor(0.0973, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7157\n",
      "Loss: tensor(0.0973, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7158\n",
      "Loss: tensor(0.0973, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7159\n",
      "Loss: tensor(0.0973, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7160\n",
      "Loss: tensor(0.0973, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7161\n",
      "Loss: tensor(0.0973, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7162\n",
      "Loss: tensor(0.0973, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7163\n",
      "Loss: tensor(0.0973, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7164\n",
      "Loss: tensor(0.0973, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7165\n",
      "Loss: tensor(0.0973, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7166\n",
      "Loss: tensor(0.0973, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7167\n",
      "Loss: tensor(0.0973, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7168\n",
      "Loss: tensor(0.0973, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7169\n",
      "Loss: tensor(0.0973, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7170\n",
      "Loss: tensor(0.0973, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7171\n",
      "Loss: tensor(0.0973, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7172\n",
      "Loss: tensor(0.0973, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7173\n",
      "Loss: tensor(0.0973, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7174\n",
      "Loss: tensor(0.0973, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7175\n",
      "Loss: tensor(0.0973, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7176\n",
      "Loss: tensor(0.0973, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7177\n",
      "Loss: tensor(0.0973, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7178\n",
      "Loss: tensor(0.0973, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7179\n",
      "Loss: tensor(0.0973, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7180\n",
      "Loss: tensor(0.0973, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7181\n",
      "Loss: tensor(0.0973, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7182\n",
      "Loss: tensor(0.0973, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7183\n",
      "Loss: tensor(0.0973, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7184\n",
      "Loss: tensor(0.0972, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7185\n",
      "Loss: tensor(0.0972, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7186\n",
      "Loss: tensor(0.0972, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7187\n",
      "Loss: tensor(0.0972, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7188\n",
      "Loss: tensor(0.0972, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7189\n",
      "Loss: tensor(0.0972, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7190\n",
      "Loss: tensor(0.0972, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7191\n",
      "Loss: tensor(0.0972, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7192\n",
      "Loss: tensor(0.0972, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7193\n",
      "Loss: tensor(0.0972, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7194\n",
      "Loss: tensor(0.0972, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7195\n",
      "Loss: tensor(0.0972, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7196\n",
      "Loss: tensor(0.0972, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7197\n",
      "Loss: tensor(0.0972, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7198\n",
      "Loss: tensor(0.0972, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7199\n",
      "Loss: tensor(0.0972, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7200\n",
      "Loss: tensor(0.0972, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7201\n",
      "Loss: tensor(0.0972, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7202\n",
      "Loss: tensor(0.0972, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7203\n",
      "Loss: tensor(0.0972, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7204\n",
      "Loss: tensor(0.0972, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7205\n",
      "Loss: tensor(0.0972, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7206\n",
      "Loss: tensor(0.0972, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7207\n",
      "Loss: tensor(0.0972, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7208\n",
      "Loss: tensor(0.0972, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7209\n",
      "Loss: tensor(0.0972, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7210\n",
      "Loss: tensor(0.0972, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7211\n",
      "Loss: tensor(0.0972, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7212\n",
      "Loss: tensor(0.0972, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7213\n",
      "Loss: tensor(0.0972, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7214\n",
      "Loss: tensor(0.0972, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7215\n",
      "Loss: tensor(0.0972, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7216\n",
      "Loss: tensor(0.0972, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7217\n",
      "Loss: tensor(0.0972, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7218\n",
      "Loss: tensor(0.0972, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7219\n",
      "Loss: tensor(0.0972, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7220\n",
      "Loss: tensor(0.0972, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7221\n",
      "Loss: tensor(0.0972, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7222\n",
      "Loss: tensor(0.0972, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7223\n",
      "Loss: tensor(0.0972, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7224\n",
      "Loss: tensor(0.0972, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7225\n",
      "Loss: tensor(0.0972, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7226\n",
      "Loss: tensor(0.0972, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7227\n",
      "Loss: tensor(0.0972, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7228\n",
      "Loss: tensor(0.0972, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7229\n",
      "Loss: tensor(0.0972, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7230\n",
      "Loss: tensor(0.0972, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7231\n",
      "Loss: tensor(0.0972, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7232\n",
      "Loss: tensor(0.0972, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7233\n",
      "Loss: tensor(0.0972, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7234\n",
      "Loss: tensor(0.0972, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7235\n",
      "Loss: tensor(0.0972, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7236\n",
      "Loss: tensor(0.0972, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7237\n",
      "Loss: tensor(0.0972, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7238\n",
      "Loss: tensor(0.0972, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7239\n",
      "Loss: tensor(0.0972, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7240\n",
      "Loss: tensor(0.0972, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7241\n",
      "Loss: tensor(0.0972, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7242\n",
      "Loss: tensor(0.0972, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7243\n",
      "Loss: tensor(0.0972, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7244\n",
      "Loss: tensor(0.0972, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7245\n",
      "Loss: tensor(0.0972, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7246\n",
      "Loss: tensor(0.0972, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7247\n",
      "Loss: tensor(0.0972, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7248\n",
      "Loss: tensor(0.0972, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7249\n",
      "Loss: tensor(0.0972, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7250\n",
      "Loss: tensor(0.0972, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7251\n",
      "Loss: tensor(0.0972, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7252\n",
      "Loss: tensor(0.0972, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7253\n",
      "Loss: tensor(0.0972, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7254\n",
      "Loss: tensor(0.0972, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7255\n",
      "Loss: tensor(0.0972, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7256\n",
      "Loss: tensor(0.0972, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7257\n",
      "Loss: tensor(0.0972, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7258\n",
      "Loss: tensor(0.0972, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7259\n",
      "Loss: tensor(0.0972, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7260\n",
      "Loss: tensor(0.0972, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7261\n",
      "Loss: tensor(0.0972, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7262\n",
      "Loss: tensor(0.0972, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7263\n",
      "Loss: tensor(0.0972, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7264\n",
      "Loss: tensor(0.0972, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7265\n",
      "Loss: tensor(0.0972, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7266\n",
      "Loss: tensor(0.0972, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7267\n",
      "Loss: tensor(0.0972, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7268\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor(0.0972, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7269\n",
      "Loss: tensor(0.0972, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7270\n",
      "Loss: tensor(0.0972, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7271\n",
      "Loss: tensor(0.0972, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7272\n",
      "Loss: tensor(0.0972, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7273\n",
      "Loss: tensor(0.0972, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7274\n",
      "Loss: tensor(0.0972, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7275\n",
      "Loss: tensor(0.0972, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7276\n",
      "Loss: tensor(0.0972, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7277\n",
      "Loss: tensor(0.0972, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7278\n",
      "Loss: tensor(0.0971, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7279\n",
      "Loss: tensor(0.0971, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7280\n",
      "Loss: tensor(0.0971, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7281\n",
      "Loss: tensor(0.0971, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7282\n",
      "Loss: tensor(0.0971, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7283\n",
      "Loss: tensor(0.0971, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7284\n",
      "Loss: tensor(0.0971, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7285\n",
      "Loss: tensor(0.0971, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7286\n",
      "Loss: tensor(0.0971, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7287\n",
      "Loss: tensor(0.0971, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7288\n",
      "Loss: tensor(0.0971, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7289\n",
      "Loss: tensor(0.0971, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7290\n",
      "Loss: tensor(0.0971, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7291\n",
      "Loss: tensor(0.0971, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7292\n",
      "Loss: tensor(0.0971, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7293\n",
      "Loss: tensor(0.0971, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7294\n",
      "Loss: tensor(0.0971, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7295\n",
      "Loss: tensor(0.0971, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7296\n",
      "Loss: tensor(0.0971, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7297\n",
      "Loss: tensor(0.0971, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7298\n",
      "Loss: tensor(0.0971, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7299\n",
      "Loss: tensor(0.0971, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7300\n",
      "Loss: tensor(0.0971, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7301\n",
      "Loss: tensor(0.0971, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7302\n",
      "Loss: tensor(0.0971, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7303\n",
      "Loss: tensor(0.0971, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7304\n",
      "Loss: tensor(0.0971, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7305\n",
      "Loss: tensor(0.0971, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7306\n",
      "Loss: tensor(0.0971, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7307\n",
      "Loss: tensor(0.0971, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7308\n",
      "Loss: tensor(0.0971, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7309\n",
      "Loss: tensor(0.0971, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7310\n",
      "Loss: tensor(0.0971, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7311\n",
      "Loss: tensor(0.0971, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7312\n",
      "Loss: tensor(0.0971, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7313\n",
      "Loss: tensor(0.0971, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7314\n",
      "Loss: tensor(0.0971, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7315\n",
      "Loss: tensor(0.0971, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7316\n",
      "Loss: tensor(0.0971, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7317\n",
      "Loss: tensor(0.0971, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7318\n",
      "Loss: tensor(0.0971, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7319\n",
      "Loss: tensor(0.0971, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7320\n",
      "Loss: tensor(0.0971, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7321\n",
      "Loss: tensor(0.0971, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7322\n",
      "Loss: tensor(0.0971, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7323\n",
      "Loss: tensor(0.0971, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7324\n",
      "Loss: tensor(0.0971, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7325\n",
      "Loss: tensor(0.0971, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7326\n",
      "Loss: tensor(0.0971, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7327\n",
      "Loss: tensor(0.0971, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7328\n",
      "Loss: tensor(0.0971, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7329\n",
      "Loss: tensor(0.0971, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7330\n",
      "Loss: tensor(0.0971, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7331\n",
      "Loss: tensor(0.0971, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7332\n",
      "Loss: tensor(0.0971, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7333\n",
      "Loss: tensor(0.0971, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7334\n",
      "Loss: tensor(0.0971, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7335\n",
      "Loss: tensor(0.0971, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7336\n",
      "Loss: tensor(0.0971, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7337\n",
      "Loss: tensor(0.0971, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7338\n",
      "Loss: tensor(0.0971, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7339\n",
      "Loss: tensor(0.0971, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7340\n",
      "Loss: tensor(0.0971, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7341\n",
      "Loss: tensor(0.0971, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7342\n",
      "Loss: tensor(0.0971, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7343\n",
      "Loss: tensor(0.0971, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7344\n",
      "Loss: tensor(0.0971, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7345\n",
      "Loss: tensor(0.0971, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7346\n",
      "Loss: tensor(0.0971, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7347\n",
      "Loss: tensor(0.0971, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7348\n",
      "Loss: tensor(0.0971, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7349\n",
      "Loss: tensor(0.0971, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7350\n",
      "Loss: tensor(0.0971, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7351\n",
      "Loss: tensor(0.0971, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7352\n",
      "Loss: tensor(0.0971, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7353\n",
      "Loss: tensor(0.0971, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7354\n",
      "Loss: tensor(0.0971, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7355\n",
      "Loss: tensor(0.0971, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7356\n",
      "Loss: tensor(0.0971, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7357\n",
      "Loss: tensor(0.0971, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7358\n",
      "Loss: tensor(0.0971, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7359\n",
      "Loss: tensor(0.0971, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7360\n",
      "Loss: tensor(0.0971, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7361\n",
      "Loss: tensor(0.0971, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7362\n",
      "Loss: tensor(0.0971, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7363\n",
      "Loss: tensor(0.0971, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7364\n",
      "Loss: tensor(0.0971, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7365\n",
      "Loss: tensor(0.0971, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7366\n",
      "Loss: tensor(0.0971, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7367\n",
      "Loss: tensor(0.0971, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7368\n",
      "Loss: tensor(0.0971, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7369\n",
      "Loss: tensor(0.0971, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7370\n",
      "Loss: tensor(0.0971, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7371\n",
      "Loss: tensor(0.0971, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7372\n",
      "Loss: tensor(0.0971, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7373\n",
      "Loss: tensor(0.0971, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7374\n",
      "Loss: tensor(0.0971, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7375\n",
      "Loss: tensor(0.0971, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7376\n",
      "Loss: tensor(0.0971, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7377\n",
      "Loss: tensor(0.0970, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7378\n",
      "Loss: tensor(0.0970, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7379\n",
      "Loss: tensor(0.0971, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7380\n",
      "Loss: tensor(0.0971, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7381\n",
      "Loss: tensor(0.0970, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7382\n",
      "Loss: tensor(0.0970, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7383\n",
      "Loss: tensor(0.0970, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7384\n",
      "Loss: tensor(0.0970, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7385\n",
      "Loss: tensor(0.0970, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7386\n",
      "Loss: tensor(0.0970, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7387\n",
      "Loss: tensor(0.0970, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7388\n",
      "Loss: tensor(0.0970, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7389\n",
      "Loss: tensor(0.0970, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7390\n",
      "Loss: tensor(0.0970, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7391\n",
      "Loss: tensor(0.0970, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7392\n",
      "Loss: tensor(0.0970, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7393\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor(0.0970, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7394\n",
      "Loss: tensor(0.0970, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7395\n",
      "Loss: tensor(0.0970, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7396\n",
      "Loss: tensor(0.0970, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7397\n",
      "Loss: tensor(0.0970, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7398\n",
      "Loss: tensor(0.0970, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7399\n",
      "Loss: tensor(0.0970, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7400\n",
      "Loss: tensor(0.0970, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7401\n",
      "Loss: tensor(0.0970, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7402\n",
      "Loss: tensor(0.0970, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7403\n",
      "Loss: tensor(0.0970, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7404\n",
      "Loss: tensor(0.0970, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7405\n",
      "Loss: tensor(0.0970, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7406\n",
      "Loss: tensor(0.0970, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7407\n",
      "Loss: tensor(0.0970, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7408\n",
      "Loss: tensor(0.0970, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7409\n",
      "Loss: tensor(0.0970, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7410\n",
      "Loss: tensor(0.0970, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7411\n",
      "Loss: tensor(0.0970, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7412\n",
      "Loss: tensor(0.0970, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7413\n",
      "Loss: tensor(0.0970, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7414\n",
      "Loss: tensor(0.0970, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7415\n",
      "Loss: tensor(0.0970, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7416\n",
      "Loss: tensor(0.0970, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7417\n",
      "Loss: tensor(0.0970, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7418\n",
      "Loss: tensor(0.0970, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7419\n",
      "Loss: tensor(0.0970, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7420\n",
      "Loss: tensor(0.0970, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7421\n",
      "Loss: tensor(0.0970, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7422\n",
      "Loss: tensor(0.0970, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7423\n",
      "Loss: tensor(0.0970, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7424\n",
      "Loss: tensor(0.0970, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7425\n",
      "Loss: tensor(0.0970, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7426\n",
      "Loss: tensor(0.0970, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7427\n",
      "Loss: tensor(0.0970, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7428\n",
      "Loss: tensor(0.0970, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7429\n",
      "Loss: tensor(0.0970, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7430\n",
      "Loss: tensor(0.0970, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7431\n",
      "Loss: tensor(0.0970, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7432\n",
      "Loss: tensor(0.0970, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7433\n",
      "Loss: tensor(0.0970, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7434\n",
      "Loss: tensor(0.0970, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7435\n",
      "Loss: tensor(0.0970, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7436\n",
      "Loss: tensor(0.0970, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7437\n",
      "Loss: tensor(0.0970, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7438\n",
      "Loss: tensor(0.0970, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7439\n",
      "Loss: tensor(0.0970, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7440\n",
      "Loss: tensor(0.0970, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7441\n",
      "Loss: tensor(0.0970, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7442\n",
      "Loss: tensor(0.0970, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7443\n",
      "Loss: tensor(0.0970, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7444\n",
      "Loss: tensor(0.0970, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7445\n",
      "Loss: tensor(0.0970, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7446\n",
      "Loss: tensor(0.0970, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7447\n",
      "Loss: tensor(0.0970, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7448\n",
      "Loss: tensor(0.0970, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7449\n",
      "Loss: tensor(0.0970, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7450\n",
      "Loss: tensor(0.0970, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7451\n",
      "Loss: tensor(0.0970, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7452\n",
      "Loss: tensor(0.0970, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7453\n",
      "Loss: tensor(0.0970, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7454\n",
      "Loss: tensor(0.0970, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7455\n",
      "Loss: tensor(0.0970, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7456\n",
      "Loss: tensor(0.0970, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7457\n",
      "Loss: tensor(0.0970, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7458\n",
      "Loss: tensor(0.0970, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7459\n",
      "Loss: tensor(0.0970, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7460\n",
      "Loss: tensor(0.0970, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7461\n",
      "Loss: tensor(0.0970, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7462\n",
      "Loss: tensor(0.0970, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7463\n",
      "Loss: tensor(0.0970, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7464\n",
      "Loss: tensor(0.0970, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7465\n",
      "Loss: tensor(0.0970, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7466\n",
      "Loss: tensor(0.0970, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7467\n",
      "Loss: tensor(0.0970, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7468\n",
      "Loss: tensor(0.0970, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7469\n",
      "Loss: tensor(0.0970, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7470\n",
      "Loss: tensor(0.0970, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7471\n",
      "Loss: tensor(0.0970, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7472\n",
      "Loss: tensor(0.0970, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7473\n",
      "Loss: tensor(0.0970, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7474\n",
      "Loss: tensor(0.0970, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7475\n",
      "Loss: tensor(0.0970, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7476\n",
      "Loss: tensor(0.0970, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7477\n",
      "Loss: tensor(0.0969, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7478\n",
      "Loss: tensor(0.0969, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7479\n",
      "Loss: tensor(0.0969, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7480\n",
      "Loss: tensor(0.0969, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7481\n",
      "Loss: tensor(0.0969, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7482\n",
      "Loss: tensor(0.0969, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7483\n",
      "Loss: tensor(0.0969, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7484\n",
      "Loss: tensor(0.0969, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7485\n",
      "Loss: tensor(0.0969, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7486\n",
      "Loss: tensor(0.0969, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7487\n",
      "Loss: tensor(0.0969, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7488\n",
      "Loss: tensor(0.0969, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7489\n",
      "Loss: tensor(0.0969, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7490\n",
      "Loss: tensor(0.0969, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7491\n",
      "Loss: tensor(0.0969, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7492\n",
      "Loss: tensor(0.0969, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7493\n",
      "Loss: tensor(0.0969, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7494\n",
      "Loss: tensor(0.0969, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7495\n",
      "Loss: tensor(0.0969, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7496\n",
      "Loss: tensor(0.0969, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7497\n",
      "Loss: tensor(0.0969, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7498\n",
      "Loss: tensor(0.0969, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7499\n",
      "Loss: tensor(0.0969, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7500\n",
      "Loss: tensor(0.0969, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7501\n",
      "Loss: tensor(0.0969, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7502\n",
      "Loss: tensor(0.0969, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7503\n",
      "Loss: tensor(0.0969, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7504\n",
      "Loss: tensor(0.0969, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7505\n",
      "Loss: tensor(0.0969, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7506\n",
      "Loss: tensor(0.0969, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7507\n",
      "Loss: tensor(0.0969, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7508\n",
      "Loss: tensor(0.0969, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7509\n",
      "Loss: tensor(0.0969, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7510\n",
      "Loss: tensor(0.0969, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7511\n",
      "Loss: tensor(0.0969, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7512\n",
      "Loss: tensor(0.0969, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7513\n",
      "Loss: tensor(0.0969, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7514\n",
      "Loss: tensor(0.0969, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7515\n",
      "Loss: tensor(0.0969, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7516\n",
      "Loss: tensor(0.0969, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7517\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor(0.0969, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7518\n",
      "Loss: tensor(0.0969, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7519\n",
      "Loss: tensor(0.0969, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7520\n",
      "Loss: tensor(0.0969, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7521\n",
      "Loss: tensor(0.0969, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7522\n",
      "Loss: tensor(0.0969, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7523\n",
      "Loss: tensor(0.0969, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7524\n",
      "Loss: tensor(0.0969, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7525\n",
      "Loss: tensor(0.0969, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7526\n",
      "Loss: tensor(0.0969, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7527\n",
      "Loss: tensor(0.0969, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7528\n",
      "Loss: tensor(0.0969, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7529\n",
      "Loss: tensor(0.0969, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7530\n",
      "Loss: tensor(0.0969, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7531\n",
      "Loss: tensor(0.0969, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7532\n",
      "Loss: tensor(0.0969, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7533\n",
      "Loss: tensor(0.0969, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7534\n",
      "Loss: tensor(0.0969, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7535\n",
      "Loss: tensor(0.0969, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7536\n",
      "Loss: tensor(0.0969, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7537\n",
      "Loss: tensor(0.0969, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7538\n",
      "Loss: tensor(0.0969, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7539\n",
      "Loss: tensor(0.0969, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7540\n",
      "Loss: tensor(0.0969, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7541\n",
      "Loss: tensor(0.0969, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7542\n",
      "Loss: tensor(0.0969, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7543\n",
      "Loss: tensor(0.0969, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7544\n",
      "Loss: tensor(0.0969, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7545\n",
      "Loss: tensor(0.0969, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7546\n",
      "Loss: tensor(0.0969, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7547\n",
      "Loss: tensor(0.0969, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7548\n",
      "Loss: tensor(0.0969, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7549\n",
      "Loss: tensor(0.0969, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7550\n",
      "Loss: tensor(0.0969, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7551\n",
      "Loss: tensor(0.0969, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7552\n",
      "Loss: tensor(0.0969, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7553\n",
      "Loss: tensor(0.0969, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7554\n",
      "Loss: tensor(0.0969, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7555\n",
      "Loss: tensor(0.0969, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7556\n",
      "Loss: tensor(0.0969, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7557\n",
      "Loss: tensor(0.0969, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7558\n",
      "Loss: tensor(0.0969, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7559\n",
      "Loss: tensor(0.0969, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7560\n",
      "Loss: tensor(0.0969, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7561\n",
      "Loss: tensor(0.0969, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7562\n",
      "Loss: tensor(0.0969, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7563\n",
      "Loss: tensor(0.0969, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7564\n",
      "Loss: tensor(0.0969, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7565\n",
      "Loss: tensor(0.0969, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7566\n",
      "Loss: tensor(0.0969, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7567\n",
      "Loss: tensor(0.0969, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7568\n",
      "Loss: tensor(0.0969, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7569\n",
      "Loss: tensor(0.0969, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7570\n",
      "Loss: tensor(0.0969, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7571\n",
      "Loss: tensor(0.0969, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7572\n",
      "Loss: tensor(0.0969, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7573\n",
      "Loss: tensor(0.0969, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7574\n",
      "Loss: tensor(0.0969, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7575\n",
      "Loss: tensor(0.0969, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7576\n",
      "Loss: tensor(0.0968, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7577\n",
      "Loss: tensor(0.0968, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7578\n",
      "Loss: tensor(0.0968, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7579\n",
      "Loss: tensor(0.0968, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7580\n",
      "Loss: tensor(0.0968, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7581\n",
      "Loss: tensor(0.0968, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7582\n",
      "Loss: tensor(0.0968, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7583\n",
      "Loss: tensor(0.0968, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7584\n",
      "Loss: tensor(0.0968, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7585\n",
      "Loss: tensor(0.0968, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7586\n",
      "Loss: tensor(0.0968, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7587\n",
      "Loss: tensor(0.0969, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7588\n",
      "Loss: tensor(0.0969, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7589\n",
      "Loss: tensor(0.0969, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7590\n",
      "Loss: tensor(0.0969, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7591\n",
      "Loss: tensor(0.0969, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7592\n",
      "Loss: tensor(0.0969, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7593\n",
      "Loss: tensor(0.0969, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7594\n",
      "Loss: tensor(0.0968, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7595\n",
      "Loss: tensor(0.0968, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7596\n",
      "Loss: tensor(0.0968, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7597\n",
      "Loss: tensor(0.0968, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7598\n",
      "Loss: tensor(0.0968, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7599\n",
      "Loss: tensor(0.0968, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7600\n",
      "Loss: tensor(0.0968, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7601\n",
      "Loss: tensor(0.0968, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7602\n",
      "Loss: tensor(0.0968, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7603\n",
      "Loss: tensor(0.0968, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7604\n",
      "Loss: tensor(0.0968, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7605\n",
      "Loss: tensor(0.0968, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7606\n",
      "Loss: tensor(0.0968, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7607\n",
      "Loss: tensor(0.0968, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7608\n",
      "Loss: tensor(0.0968, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7609\n",
      "Loss: tensor(0.0968, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7610\n",
      "Loss: tensor(0.0968, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7611\n",
      "Loss: tensor(0.0968, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7612\n",
      "Loss: tensor(0.0968, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7613\n",
      "Loss: tensor(0.0968, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7614\n",
      "Loss: tensor(0.0968, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7615\n",
      "Loss: tensor(0.0968, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7616\n",
      "Loss: tensor(0.0968, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7617\n",
      "Loss: tensor(0.0968, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7618\n",
      "Loss: tensor(0.0968, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7619\n",
      "Loss: tensor(0.0968, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7620\n",
      "Loss: tensor(0.0968, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7621\n",
      "Loss: tensor(0.0968, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7622\n",
      "Loss: tensor(0.0968, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7623\n",
      "Loss: tensor(0.0968, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7624\n",
      "Loss: tensor(0.0968, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7625\n",
      "Loss: tensor(0.0968, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7626\n",
      "Loss: tensor(0.0968, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7627\n",
      "Loss: tensor(0.0968, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7628\n",
      "Loss: tensor(0.0968, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7629\n",
      "Loss: tensor(0.0968, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7630\n",
      "Loss: tensor(0.0968, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7631\n",
      "Loss: tensor(0.0968, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7632\n",
      "Loss: tensor(0.0968, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7633\n",
      "Loss: tensor(0.0968, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7634\n",
      "Loss: tensor(0.0968, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7635\n",
      "Loss: tensor(0.0968, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7636\n",
      "Loss: tensor(0.0968, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7637\n",
      "Loss: tensor(0.0968, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7638\n",
      "Loss: tensor(0.0968, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7639\n",
      "Loss: tensor(0.0968, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7640\n",
      "Loss: tensor(0.0968, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7641\n",
      "Loss: tensor(0.0968, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7642\n",
      "Loss: tensor(0.0968, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7643\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor(0.0968, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7644\n",
      "Loss: tensor(0.0968, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7645\n",
      "Loss: tensor(0.0968, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7646\n",
      "Loss: tensor(0.0968, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7647\n",
      "Loss: tensor(0.0968, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7648\n",
      "Loss: tensor(0.0968, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7649\n",
      "Loss: tensor(0.0968, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7650\n",
      "Loss: tensor(0.0968, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7651\n",
      "Loss: tensor(0.0968, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7652\n",
      "Loss: tensor(0.0968, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7653\n",
      "Loss: tensor(0.0968, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7654\n",
      "Loss: tensor(0.0968, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7655\n",
      "Loss: tensor(0.0968, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7656\n",
      "Loss: tensor(0.0968, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7657\n",
      "Loss: tensor(0.0968, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7658\n",
      "Loss: tensor(0.0968, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7659\n",
      "Loss: tensor(0.0968, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7660\n",
      "Loss: tensor(0.0968, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7661\n",
      "Loss: tensor(0.0968, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7662\n",
      "Loss: tensor(0.0968, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7663\n",
      "Loss: tensor(0.0968, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7664\n",
      "Loss: tensor(0.0968, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7665\n",
      "Loss: tensor(0.0968, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7666\n",
      "Loss: tensor(0.0968, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7667\n",
      "Loss: tensor(0.0968, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7668\n",
      "Loss: tensor(0.0968, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7669\n",
      "Loss: tensor(0.0968, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7670\n",
      "Loss: tensor(0.0968, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7671\n",
      "Loss: tensor(0.0968, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7672\n",
      "Loss: tensor(0.0968, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7673\n",
      "Loss: tensor(0.0968, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7674\n",
      "Loss: tensor(0.0968, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7675\n",
      "Loss: tensor(0.0968, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7676\n",
      "Loss: tensor(0.0968, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7677\n",
      "Loss: tensor(0.0968, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7678\n",
      "Loss: tensor(0.0968, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7679\n",
      "Loss: tensor(0.0967, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7680\n",
      "Loss: tensor(0.0967, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7681\n",
      "Loss: tensor(0.0967, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7682\n",
      "Loss: tensor(0.0967, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7683\n",
      "Loss: tensor(0.0967, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7684\n",
      "Loss: tensor(0.0967, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7685\n",
      "Loss: tensor(0.0967, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7686\n",
      "Loss: tensor(0.0967, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7687\n",
      "Loss: tensor(0.0967, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7688\n",
      "Loss: tensor(0.0967, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7689\n",
      "Loss: tensor(0.0967, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7690\n",
      "Loss: tensor(0.0967, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7691\n",
      "Loss: tensor(0.0967, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7692\n",
      "Loss: tensor(0.0967, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7693\n",
      "Loss: tensor(0.0967, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7694\n",
      "Loss: tensor(0.0967, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7695\n",
      "Loss: tensor(0.0967, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7696\n",
      "Loss: tensor(0.0967, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7697\n",
      "Loss: tensor(0.0967, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7698\n",
      "Loss: tensor(0.0967, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7699\n",
      "Loss: tensor(0.0967, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7700\n",
      "Loss: tensor(0.0967, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7701\n",
      "Loss: tensor(0.0967, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7702\n",
      "Loss: tensor(0.0967, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7703\n",
      "Loss: tensor(0.0967, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7704\n",
      "Loss: tensor(0.0967, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7705\n",
      "Loss: tensor(0.0967, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7706\n",
      "Loss: tensor(0.0967, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7707\n",
      "Loss: tensor(0.0967, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7708\n",
      "Loss: tensor(0.0967, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7709\n",
      "Loss: tensor(0.0967, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7710\n",
      "Loss: tensor(0.0967, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7711\n",
      "Loss: tensor(0.0967, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7712\n",
      "Loss: tensor(0.0967, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7713\n",
      "Loss: tensor(0.0967, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7714\n",
      "Loss: tensor(0.0967, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7715\n",
      "Loss: tensor(0.0967, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7716\n",
      "Loss: tensor(0.0967, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7717\n",
      "Loss: tensor(0.0967, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7718\n",
      "Loss: tensor(0.0967, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7719\n",
      "Loss: tensor(0.0967, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7720\n",
      "Loss: tensor(0.0967, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7721\n",
      "Loss: tensor(0.0967, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7722\n",
      "Loss: tensor(0.0967, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7723\n",
      "Loss: tensor(0.0967, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7724\n",
      "Loss: tensor(0.0967, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7725\n",
      "Loss: tensor(0.0967, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7726\n",
      "Loss: tensor(0.0967, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7727\n",
      "Loss: tensor(0.0967, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7728\n",
      "Loss: tensor(0.0967, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7729\n",
      "Loss: tensor(0.0967, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7730\n",
      "Loss: tensor(0.0967, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7731\n",
      "Loss: tensor(0.0967, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7732\n",
      "Loss: tensor(0.0967, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7733\n",
      "Loss: tensor(0.0967, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7734\n",
      "Loss: tensor(0.0967, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7735\n",
      "Loss: tensor(0.0967, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7736\n",
      "Loss: tensor(0.0967, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7737\n",
      "Loss: tensor(0.0967, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7738\n",
      "Loss: tensor(0.0967, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7739\n",
      "Loss: tensor(0.0967, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7740\n",
      "Loss: tensor(0.0967, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7741\n",
      "Loss: tensor(0.0967, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7742\n",
      "Loss: tensor(0.0967, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7743\n",
      "Loss: tensor(0.0967, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7744\n",
      "Loss: tensor(0.0967, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7745\n",
      "Loss: tensor(0.0967, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7746\n",
      "Loss: tensor(0.0967, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7747\n",
      "Loss: tensor(0.0967, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7748\n",
      "Loss: tensor(0.0967, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7749\n",
      "Loss: tensor(0.0967, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7750\n",
      "Loss: tensor(0.0967, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7751\n",
      "Loss: tensor(0.0967, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7752\n",
      "Loss: tensor(0.0967, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7753\n",
      "Loss: tensor(0.0967, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7754\n",
      "Loss: tensor(0.0967, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7755\n",
      "Loss: tensor(0.0967, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7756\n",
      "Loss: tensor(0.0967, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7757\n",
      "Loss: tensor(0.0967, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7758\n",
      "Loss: tensor(0.0967, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7759\n",
      "Loss: tensor(0.0967, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7760\n",
      "Loss: tensor(0.0967, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7761\n",
      "Loss: tensor(0.0967, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7762\n",
      "Loss: tensor(0.0967, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7763\n",
      "Loss: tensor(0.0967, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7764\n",
      "Loss: tensor(0.0967, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7765\n",
      "Loss: tensor(0.0967, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7766\n",
      "Loss: tensor(0.0967, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7767\n",
      "Loss: tensor(0.0967, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7768\n",
      "Loss: tensor(0.0967, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7769\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor(0.0967, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7770\n",
      "Loss: tensor(0.0967, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7771\n",
      "Loss: tensor(0.0967, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7772\n",
      "Loss: tensor(0.0967, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7773\n",
      "Loss: tensor(0.0967, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7774\n",
      "Loss: tensor(0.0967, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7775\n",
      "Loss: tensor(0.0967, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7776\n",
      "Loss: tensor(0.0967, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7777\n",
      "Loss: tensor(0.0967, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7778\n",
      "Loss: tensor(0.0967, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7779\n",
      "Loss: tensor(0.0967, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7780\n",
      "Loss: tensor(0.0967, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7781\n",
      "Loss: tensor(0.0967, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7782\n",
      "Loss: tensor(0.0967, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7783\n",
      "Loss: tensor(0.0966, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7784\n",
      "Loss: tensor(0.0966, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7785\n",
      "Loss: tensor(0.0966, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7786\n",
      "Loss: tensor(0.0966, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7787\n",
      "Loss: tensor(0.0966, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7788\n",
      "Loss: tensor(0.0966, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7789\n",
      "Loss: tensor(0.0966, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7790\n",
      "Loss: tensor(0.0966, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7791\n",
      "Loss: tensor(0.0966, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7792\n",
      "Loss: tensor(0.0966, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7793\n",
      "Loss: tensor(0.0966, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7794\n",
      "Loss: tensor(0.0966, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7795\n",
      "Loss: tensor(0.0966, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7796\n",
      "Loss: tensor(0.0966, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7797\n",
      "Loss: tensor(0.0966, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7798\n",
      "Loss: tensor(0.0966, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7799\n",
      "Loss: tensor(0.0966, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7800\n",
      "Loss: tensor(0.0966, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7801\n",
      "Loss: tensor(0.0966, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7802\n",
      "Loss: tensor(0.0966, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7803\n",
      "Loss: tensor(0.0966, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7804\n",
      "Loss: tensor(0.0966, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7805\n",
      "Loss: tensor(0.0966, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7806\n",
      "Loss: tensor(0.0966, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7807\n",
      "Loss: tensor(0.0966, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7808\n",
      "Loss: tensor(0.0966, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7809\n",
      "Loss: tensor(0.0966, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7810\n",
      "Loss: tensor(0.0966, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7811\n",
      "Loss: tensor(0.0966, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7812\n",
      "Loss: tensor(0.0966, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7813\n",
      "Loss: tensor(0.0966, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7814\n",
      "Loss: tensor(0.0966, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7815\n",
      "Loss: tensor(0.0966, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7816\n",
      "Loss: tensor(0.0966, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7817\n",
      "Loss: tensor(0.0966, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7818\n",
      "Loss: tensor(0.0966, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7819\n",
      "Loss: tensor(0.0966, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7820\n",
      "Loss: tensor(0.0966, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7821\n",
      "Loss: tensor(0.0966, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7822\n",
      "Loss: tensor(0.0966, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7823\n",
      "Loss: tensor(0.0966, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7824\n",
      "Loss: tensor(0.0966, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7825\n",
      "Loss: tensor(0.0966, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7826\n",
      "Loss: tensor(0.0966, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7827\n",
      "Loss: tensor(0.0966, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7828\n",
      "Loss: tensor(0.0966, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7829\n",
      "Loss: tensor(0.0966, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7830\n",
      "Loss: tensor(0.0966, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7831\n",
      "Loss: tensor(0.0966, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7832\n",
      "Loss: tensor(0.0966, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7833\n",
      "Loss: tensor(0.0966, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7834\n",
      "Loss: tensor(0.0966, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7835\n",
      "Loss: tensor(0.0966, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7836\n",
      "Loss: tensor(0.0966, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7837\n",
      "Loss: tensor(0.0966, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7838\n",
      "Loss: tensor(0.0966, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7839\n",
      "Loss: tensor(0.0966, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7840\n",
      "Loss: tensor(0.0966, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7841\n",
      "Loss: tensor(0.0966, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7842\n",
      "Loss: tensor(0.0966, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7843\n",
      "Loss: tensor(0.0966, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7844\n",
      "Loss: tensor(0.0966, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7845\n",
      "Loss: tensor(0.0966, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7846\n",
      "Loss: tensor(0.0966, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7847\n",
      "Loss: tensor(0.0966, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7848\n",
      "Loss: tensor(0.0966, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7849\n",
      "Loss: tensor(0.0966, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7850\n",
      "Loss: tensor(0.0966, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7851\n",
      "Loss: tensor(0.0966, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7852\n",
      "Loss: tensor(0.0966, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7853\n",
      "Loss: tensor(0.0966, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7854\n",
      "Loss: tensor(0.0966, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7855\n",
      "Loss: tensor(0.0966, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7856\n",
      "Loss: tensor(0.0966, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7857\n",
      "Loss: tensor(0.0966, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7858\n",
      "Loss: tensor(0.0966, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7859\n",
      "Loss: tensor(0.0966, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7860\n",
      "Loss: tensor(0.0966, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7861\n",
      "Loss: tensor(0.0966, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7862\n",
      "Loss: tensor(0.0966, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7863\n",
      "Loss: tensor(0.0966, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7864\n",
      "Loss: tensor(0.0966, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7865\n",
      "Loss: tensor(0.0966, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7866\n",
      "Loss: tensor(0.0966, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7867\n",
      "Loss: tensor(0.0966, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7868\n",
      "Loss: tensor(0.0966, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7869\n",
      "Loss: tensor(0.0966, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7870\n",
      "Loss: tensor(0.0966, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7871\n",
      "Loss: tensor(0.0966, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7872\n",
      "Loss: tensor(0.0966, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7873\n",
      "Loss: tensor(0.0966, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7874\n",
      "Loss: tensor(0.0966, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7875\n",
      "Loss: tensor(0.0966, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7876\n",
      "Loss: tensor(0.0966, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7877\n",
      "Loss: tensor(0.0966, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7878\n",
      "Loss: tensor(0.0966, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7879\n",
      "Loss: tensor(0.0966, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7880\n",
      "Loss: tensor(0.0966, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7881\n",
      "Loss: tensor(0.0966, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7882\n",
      "Loss: tensor(0.0966, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7883\n",
      "Loss: tensor(0.0966, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7884\n",
      "Loss: tensor(0.0966, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7885\n",
      "Loss: tensor(0.0966, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7886\n",
      "Loss: tensor(0.0966, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7887\n",
      "Loss: tensor(0.0966, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7888\n",
      "Loss: tensor(0.0966, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7889\n",
      "Loss: tensor(0.0966, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7890\n",
      "Loss: tensor(0.0966, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7891\n",
      "Loss: tensor(0.0966, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7892\n",
      "Loss: tensor(0.0965, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7893\n",
      "Loss: tensor(0.0965, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7894\n",
      "Loss: tensor(0.0965, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7895\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor(0.0965, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7896\n",
      "Loss: tensor(0.0965, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7897\n",
      "Loss: tensor(0.0965, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7898\n",
      "Loss: tensor(0.0965, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7899\n",
      "Loss: tensor(0.0965, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7900\n",
      "Loss: tensor(0.0965, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7901\n",
      "Loss: tensor(0.0965, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7902\n",
      "Loss: tensor(0.0965, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7903\n",
      "Loss: tensor(0.0965, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7904\n",
      "Loss: tensor(0.0965, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7905\n",
      "Loss: tensor(0.0965, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7906\n",
      "Loss: tensor(0.0965, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7907\n",
      "Loss: tensor(0.0965, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7908\n",
      "Loss: tensor(0.0965, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7909\n",
      "Loss: tensor(0.0965, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7910\n",
      "Loss: tensor(0.0965, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7911\n",
      "Loss: tensor(0.0965, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7912\n",
      "Loss: tensor(0.0965, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7913\n",
      "Loss: tensor(0.0965, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7914\n",
      "Loss: tensor(0.0965, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7915\n",
      "Loss: tensor(0.0965, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7916\n",
      "Loss: tensor(0.0965, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7917\n",
      "Loss: tensor(0.0965, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7918\n",
      "Loss: tensor(0.0965, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7919\n",
      "Loss: tensor(0.0965, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7920\n",
      "Loss: tensor(0.0965, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7921\n",
      "Loss: tensor(0.0965, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7922\n",
      "Loss: tensor(0.0965, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7923\n",
      "Loss: tensor(0.0965, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7924\n",
      "Loss: tensor(0.0965, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7925\n",
      "Loss: tensor(0.0965, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7926\n",
      "Loss: tensor(0.0965, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7927\n",
      "Loss: tensor(0.0965, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7928\n",
      "Loss: tensor(0.0965, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7929\n",
      "Loss: tensor(0.0965, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7930\n",
      "Loss: tensor(0.0965, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7931\n",
      "Loss: tensor(0.0965, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7932\n",
      "Loss: tensor(0.0965, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7933\n",
      "Loss: tensor(0.0965, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7934\n",
      "Loss: tensor(0.0965, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7935\n",
      "Loss: tensor(0.0965, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7936\n",
      "Loss: tensor(0.0965, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7937\n",
      "Loss: tensor(0.0965, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7938\n",
      "Loss: tensor(0.0965, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7939\n",
      "Loss: tensor(0.0965, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7940\n",
      "Loss: tensor(0.0965, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7941\n",
      "Loss: tensor(0.0965, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7942\n",
      "Loss: tensor(0.0965, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7943\n",
      "Loss: tensor(0.0965, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7944\n",
      "Loss: tensor(0.0965, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7945\n",
      "Loss: tensor(0.0965, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7946\n",
      "Loss: tensor(0.0965, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7947\n",
      "Loss: tensor(0.0965, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7948\n",
      "Loss: tensor(0.0965, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7949\n",
      "Loss: tensor(0.0965, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7950\n",
      "Loss: tensor(0.0965, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7951\n",
      "Loss: tensor(0.0965, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7952\n",
      "Loss: tensor(0.0965, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7953\n",
      "Loss: tensor(0.0965, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7954\n",
      "Loss: tensor(0.0965, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7955\n",
      "Loss: tensor(0.0965, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7956\n",
      "Loss: tensor(0.0965, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7957\n",
      "Loss: tensor(0.0965, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7958\n",
      "Loss: tensor(0.0965, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7959\n",
      "Loss: tensor(0.0965, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7960\n",
      "Loss: tensor(0.0965, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7961\n",
      "Loss: tensor(0.0965, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7962\n",
      "Loss: tensor(0.0965, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7963\n",
      "Loss: tensor(0.0965, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7964\n",
      "Loss: tensor(0.0965, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7965\n",
      "Loss: tensor(0.0965, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7966\n",
      "Loss: tensor(0.0965, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7967\n",
      "Loss: tensor(0.0965, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7968\n",
      "Loss: tensor(0.0965, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7969\n",
      "Loss: tensor(0.0965, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7970\n",
      "Loss: tensor(0.0965, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7971\n",
      "Loss: tensor(0.0965, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7972\n",
      "Loss: tensor(0.0965, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7973\n",
      "Loss: tensor(0.0965, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7974\n",
      "Loss: tensor(0.0965, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7975\n",
      "Loss: tensor(0.0965, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7976\n",
      "Loss: tensor(0.0965, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7977\n",
      "Loss: tensor(0.0965, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7978\n",
      "Loss: tensor(0.0965, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7979\n",
      "Loss: tensor(0.0965, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7980\n",
      "Loss: tensor(0.0965, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7981\n",
      "Loss: tensor(0.0965, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7982\n",
      "Loss: tensor(0.0965, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7983\n",
      "Loss: tensor(0.0965, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7984\n",
      "Loss: tensor(0.0965, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7985\n",
      "Loss: tensor(0.0965, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7986\n",
      "Loss: tensor(0.0965, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7987\n",
      "Loss: tensor(0.0965, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7988\n",
      "Loss: tensor(0.0965, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7989\n",
      "Loss: tensor(0.0965, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7990\n",
      "Loss: tensor(0.0965, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7991\n",
      "Loss: tensor(0.0965, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7992\n",
      "Loss: tensor(0.0965, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7993\n",
      "Loss: tensor(0.0965, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7994\n",
      "Loss: tensor(0.0965, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7995\n",
      "Loss: tensor(0.0965, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7996\n",
      "Loss: tensor(0.0965, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7997\n",
      "Loss: tensor(0.0965, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7998\n",
      "Loss: tensor(0.0965, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7999\n",
      "Loss: tensor(0.0965, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8000\n",
      "Loss: tensor(0.0965, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8001\n",
      "Loss: tensor(0.0965, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8002\n",
      "Loss: tensor(0.0965, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8003\n",
      "Loss: tensor(0.0964, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8004\n",
      "Loss: tensor(0.0964, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8005\n",
      "Loss: tensor(0.0964, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8006\n",
      "Loss: tensor(0.0964, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8007\n",
      "Loss: tensor(0.0964, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8008\n",
      "Loss: tensor(0.0964, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8009\n",
      "Loss: tensor(0.0964, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8010\n",
      "Loss: tensor(0.0964, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8011\n",
      "Loss: tensor(0.0964, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8012\n",
      "Loss: tensor(0.0964, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8013\n",
      "Loss: tensor(0.0964, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8014\n",
      "Loss: tensor(0.0964, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8015\n",
      "Loss: tensor(0.0964, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8016\n",
      "Loss: tensor(0.0964, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8017\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor(0.0964, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8018\n",
      "Loss: tensor(0.0964, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8019\n",
      "Loss: tensor(0.0964, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8020\n",
      "Loss: tensor(0.0964, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8021\n",
      "Loss: tensor(0.0965, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8022\n",
      "Loss: tensor(0.0965, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8023\n",
      "Loss: tensor(0.0965, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8024\n",
      "Loss: tensor(0.0965, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8025\n",
      "Loss: tensor(0.0965, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8026\n",
      "Loss: tensor(0.0965, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8027\n",
      "Loss: tensor(0.0964, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8028\n",
      "Loss: tensor(0.0964, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8029\n",
      "Loss: tensor(0.0964, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8030\n",
      "Loss: tensor(0.0964, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8031\n",
      "Loss: tensor(0.0964, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8032\n",
      "Loss: tensor(0.0964, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8033\n",
      "Loss: tensor(0.0964, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8034\n",
      "Loss: tensor(0.0964, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8035\n",
      "Loss: tensor(0.0964, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8036\n",
      "Loss: tensor(0.0964, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8037\n",
      "Loss: tensor(0.0964, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8038\n",
      "Loss: tensor(0.0964, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8039\n",
      "Loss: tensor(0.0964, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8040\n",
      "Loss: tensor(0.0964, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8041\n",
      "Loss: tensor(0.0964, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8042\n",
      "Loss: tensor(0.0964, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8043\n",
      "Loss: tensor(0.0964, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8044\n",
      "Loss: tensor(0.0964, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8045\n",
      "Loss: tensor(0.0964, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8046\n",
      "Loss: tensor(0.0964, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8047\n",
      "Loss: tensor(0.0964, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8048\n",
      "Loss: tensor(0.0964, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8049\n",
      "Loss: tensor(0.0964, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8050\n",
      "Loss: tensor(0.0964, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8051\n",
      "Loss: tensor(0.0964, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8052\n",
      "Loss: tensor(0.0964, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8053\n",
      "Loss: tensor(0.0964, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8054\n",
      "Loss: tensor(0.0964, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8055\n",
      "Loss: tensor(0.0964, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8056\n",
      "Loss: tensor(0.0964, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8057\n",
      "Loss: tensor(0.0964, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8058\n",
      "Loss: tensor(0.0964, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8059\n",
      "Loss: tensor(0.0964, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8060\n",
      "Loss: tensor(0.0964, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8061\n",
      "Loss: tensor(0.0964, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8062\n",
      "Loss: tensor(0.0964, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8063\n",
      "Loss: tensor(0.0964, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8064\n",
      "Loss: tensor(0.0964, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8065\n",
      "Loss: tensor(0.0964, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8066\n",
      "Loss: tensor(0.0964, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8067\n",
      "Loss: tensor(0.0964, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8068\n",
      "Loss: tensor(0.0964, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8069\n",
      "Loss: tensor(0.0964, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8070\n",
      "Loss: tensor(0.0964, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8071\n",
      "Loss: tensor(0.0964, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8072\n",
      "Loss: tensor(0.0964, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8073\n",
      "Loss: tensor(0.0964, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8074\n",
      "Loss: tensor(0.0964, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8075\n",
      "Loss: tensor(0.0964, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8076\n",
      "Loss: tensor(0.0964, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8077\n",
      "Loss: tensor(0.0964, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8078\n",
      "Loss: tensor(0.0964, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8079\n",
      "Loss: tensor(0.0964, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8080\n",
      "Loss: tensor(0.0964, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8081\n",
      "Loss: tensor(0.0964, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8082\n",
      "Loss: tensor(0.0964, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8083\n",
      "Loss: tensor(0.0964, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8084\n",
      "Loss: tensor(0.0964, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8085\n",
      "Loss: tensor(0.0964, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8086\n",
      "Loss: tensor(0.0964, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8087\n",
      "Loss: tensor(0.0964, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8088\n",
      "Loss: tensor(0.0964, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8089\n",
      "Loss: tensor(0.0964, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8090\n",
      "Loss: tensor(0.0964, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8091\n",
      "Loss: tensor(0.0964, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8092\n",
      "Loss: tensor(0.0964, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8093\n",
      "Loss: tensor(0.0964, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8094\n",
      "Loss: tensor(0.0964, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8095\n",
      "Loss: tensor(0.0964, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8096\n",
      "Loss: tensor(0.0964, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8097\n",
      "Loss: tensor(0.0964, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8098\n",
      "Loss: tensor(0.0964, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8099\n",
      "Loss: tensor(0.0964, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8100\n",
      "Loss: tensor(0.0964, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8101\n",
      "Loss: tensor(0.0964, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8102\n",
      "Loss: tensor(0.0964, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8103\n",
      "Loss: tensor(0.0964, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8104\n",
      "Loss: tensor(0.0964, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8105\n",
      "Loss: tensor(0.0964, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8106\n",
      "Loss: tensor(0.0964, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8107\n",
      "Loss: tensor(0.0964, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8108\n",
      "Loss: tensor(0.0964, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8109\n",
      "Loss: tensor(0.0964, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8110\n",
      "Loss: tensor(0.0964, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8111\n",
      "Loss: tensor(0.0964, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8112\n",
      "Loss: tensor(0.0964, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8113\n",
      "Loss: tensor(0.0964, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8114\n",
      "Loss: tensor(0.0964, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8115\n",
      "Loss: tensor(0.0964, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8116\n",
      "Loss: tensor(0.0964, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8117\n",
      "Loss: tensor(0.0964, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8118\n",
      "Loss: tensor(0.0964, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8119\n",
      "Loss: tensor(0.0964, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8120\n",
      "Loss: tensor(0.0964, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8121\n",
      "Loss: tensor(0.0964, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8122\n",
      "Loss: tensor(0.0964, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8123\n",
      "Loss: tensor(0.0964, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8124\n",
      "Loss: tensor(0.0964, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8125\n",
      "Loss: tensor(0.0964, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8126\n",
      "Loss: tensor(0.0964, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8127\n",
      "Loss: tensor(0.0964, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8128\n",
      "Loss: tensor(0.0963, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8129\n",
      "Loss: tensor(0.0963, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8130\n",
      "Loss: tensor(0.0963, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8131\n",
      "Loss: tensor(0.0963, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8132\n",
      "Loss: tensor(0.0964, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8133\n",
      "Loss: tensor(0.0964, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8134\n",
      "Loss: tensor(0.0963, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8135\n",
      "Loss: tensor(0.0963, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8136\n",
      "Loss: tensor(0.0963, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8137\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor(0.0963, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8138\n",
      "Loss: tensor(0.0963, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8139\n",
      "Loss: tensor(0.0963, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8140\n",
      "Loss: tensor(0.0963, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8141\n",
      "Loss: tensor(0.0963, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8142\n",
      "Loss: tensor(0.0963, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8143\n",
      "Loss: tensor(0.0963, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8144\n",
      "Loss: tensor(0.0963, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8145\n",
      "Loss: tensor(0.0963, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8146\n",
      "Loss: tensor(0.0963, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8147\n",
      "Loss: tensor(0.0963, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8148\n",
      "Loss: tensor(0.0963, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8149\n",
      "Loss: tensor(0.0963, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8150\n",
      "Loss: tensor(0.0963, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8151\n",
      "Loss: tensor(0.0963, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8152\n",
      "Loss: tensor(0.0963, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8153\n",
      "Loss: tensor(0.0963, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8154\n",
      "Loss: tensor(0.0963, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8155\n",
      "Loss: tensor(0.0963, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8156\n",
      "Loss: tensor(0.0963, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8157\n",
      "Loss: tensor(0.0963, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8158\n",
      "Loss: tensor(0.0963, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8159\n",
      "Loss: tensor(0.0963, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8160\n",
      "Loss: tensor(0.0963, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8161\n",
      "Loss: tensor(0.0963, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8162\n",
      "Loss: tensor(0.0963, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8163\n",
      "Loss: tensor(0.0963, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8164\n",
      "Loss: tensor(0.0963, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8165\n",
      "Loss: tensor(0.0963, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8166\n",
      "Loss: tensor(0.0963, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8167\n",
      "Loss: tensor(0.0963, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8168\n",
      "Loss: tensor(0.0963, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8169\n",
      "Loss: tensor(0.0963, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8170\n",
      "Loss: tensor(0.0963, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8171\n",
      "Loss: tensor(0.0963, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8172\n",
      "Loss: tensor(0.0963, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8173\n",
      "Loss: tensor(0.0963, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8174\n",
      "Loss: tensor(0.0963, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8175\n",
      "Loss: tensor(0.0963, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8176\n",
      "Loss: tensor(0.0963, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8177\n",
      "Loss: tensor(0.0963, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8178\n",
      "Loss: tensor(0.0963, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8179\n",
      "Loss: tensor(0.0963, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8180\n",
      "Loss: tensor(0.0963, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8181\n",
      "Loss: tensor(0.0963, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8182\n",
      "Loss: tensor(0.0963, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8183\n",
      "Loss: tensor(0.0963, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8184\n",
      "Loss: tensor(0.0963, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8185\n",
      "Loss: tensor(0.0963, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8186\n",
      "Loss: tensor(0.0963, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8187\n",
      "Loss: tensor(0.0963, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8188\n",
      "Loss: tensor(0.0963, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8189\n",
      "Loss: tensor(0.0963, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8190\n",
      "Loss: tensor(0.0963, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8191\n",
      "Loss: tensor(0.0963, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8192\n",
      "Loss: tensor(0.0963, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8193\n",
      "Loss: tensor(0.0963, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8194\n",
      "Loss: tensor(0.0963, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8195\n",
      "Loss: tensor(0.0963, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8196\n",
      "Loss: tensor(0.0963, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8197\n",
      "Loss: tensor(0.0963, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8198\n",
      "Loss: tensor(0.0963, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8199\n",
      "Loss: tensor(0.0963, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8200\n",
      "Loss: tensor(0.0963, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8201\n",
      "Loss: tensor(0.0963, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8202\n",
      "Loss: tensor(0.0963, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8203\n",
      "Loss: tensor(0.0963, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8204\n",
      "Loss: tensor(0.0963, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8205\n",
      "Loss: tensor(0.0963, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8206\n",
      "Loss: tensor(0.0963, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8207\n",
      "Loss: tensor(0.0963, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8208\n",
      "Loss: tensor(0.0963, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8209\n",
      "Loss: tensor(0.0963, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8210\n",
      "Loss: tensor(0.0963, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8211\n",
      "Loss: tensor(0.0963, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8212\n",
      "Loss: tensor(0.0963, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8213\n",
      "Loss: tensor(0.0963, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8214\n",
      "Loss: tensor(0.0963, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8215\n",
      "Loss: tensor(0.0963, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8216\n",
      "Loss: tensor(0.0963, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8217\n",
      "Loss: tensor(0.0963, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8218\n",
      "Loss: tensor(0.0963, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8219\n",
      "Loss: tensor(0.0963, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8220\n",
      "Loss: tensor(0.0963, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8221\n",
      "Loss: tensor(0.0963, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8222\n",
      "Loss: tensor(0.0963, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8223\n",
      "Loss: tensor(0.0963, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8224\n",
      "Loss: tensor(0.0963, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8225\n",
      "Loss: tensor(0.0963, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8226\n",
      "Loss: tensor(0.0963, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8227\n",
      "Loss: tensor(0.0963, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8228\n",
      "Loss: tensor(0.0963, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8229\n",
      "Loss: tensor(0.0963, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8230\n",
      "Loss: tensor(0.0963, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8231\n",
      "Loss: tensor(0.0963, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8232\n",
      "Loss: tensor(0.0963, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8233\n",
      "Loss: tensor(0.0963, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8234\n",
      "Loss: tensor(0.0963, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8235\n",
      "Loss: tensor(0.0963, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8236\n",
      "Loss: tensor(0.0963, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8237\n",
      "Loss: tensor(0.0963, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8238\n",
      "Loss: tensor(0.0963, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8239\n",
      "Loss: tensor(0.0962, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8240\n",
      "Loss: tensor(0.0962, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8241\n",
      "Loss: tensor(0.0962, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8242\n",
      "Loss: tensor(0.0962, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8243\n",
      "Loss: tensor(0.0962, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8244\n",
      "Loss: tensor(0.0962, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8245\n",
      "Loss: tensor(0.0963, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8246\n",
      "Loss: tensor(0.0963, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8247\n",
      "Loss: tensor(0.0963, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8248\n",
      "Loss: tensor(0.0963, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8249\n",
      "Loss: tensor(0.0963, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8250\n",
      "Loss: tensor(0.0963, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8251\n",
      "Loss: tensor(0.0963, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8252\n",
      "Loss: tensor(0.0963, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8253\n",
      "Loss: tensor(0.0963, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8254\n",
      "Loss: tensor(0.0962, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8255\n",
      "Loss: tensor(0.0962, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8256\n",
      "Loss: tensor(0.0962, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8257\n",
      "Loss: tensor(0.0962, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8258\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor(0.0962, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8259\n",
      "Loss: tensor(0.0962, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8260\n",
      "Loss: tensor(0.0962, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8261\n",
      "Loss: tensor(0.0962, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8262\n",
      "Loss: tensor(0.0962, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8263\n",
      "Loss: tensor(0.0962, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8264\n",
      "Loss: tensor(0.0962, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8265\n",
      "Loss: tensor(0.0962, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8266\n",
      "Loss: tensor(0.0962, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8267\n",
      "Loss: tensor(0.0962, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8268\n",
      "Loss: tensor(0.0962, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8269\n",
      "Loss: tensor(0.0962, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8270\n",
      "Loss: tensor(0.0962, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8271\n",
      "Loss: tensor(0.0962, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8272\n",
      "Loss: tensor(0.0962, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8273\n",
      "Loss: tensor(0.0962, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8274\n",
      "Loss: tensor(0.0962, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8275\n",
      "Loss: tensor(0.0962, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8276\n",
      "Loss: tensor(0.0962, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8277\n",
      "Loss: tensor(0.0962, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8278\n",
      "Loss: tensor(0.0962, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8279\n",
      "Loss: tensor(0.0962, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8280\n",
      "Loss: tensor(0.0962, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8281\n",
      "Loss: tensor(0.0962, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8282\n",
      "Loss: tensor(0.0962, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8283\n",
      "Loss: tensor(0.0962, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8284\n",
      "Loss: tensor(0.0962, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8285\n",
      "Loss: tensor(0.0962, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8286\n",
      "Loss: tensor(0.0962, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8287\n",
      "Loss: tensor(0.0962, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8288\n",
      "Loss: tensor(0.0962, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8289\n",
      "Loss: tensor(0.0962, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8290\n",
      "Loss: tensor(0.0962, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8291\n",
      "Loss: tensor(0.0962, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8292\n",
      "Loss: tensor(0.0962, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8293\n",
      "Loss: tensor(0.0962, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8294\n",
      "Loss: tensor(0.0962, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8295\n",
      "Loss: tensor(0.0962, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8296\n",
      "Loss: tensor(0.0962, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8297\n",
      "Loss: tensor(0.0962, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8298\n",
      "Loss: tensor(0.0962, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8299\n",
      "Loss: tensor(0.0962, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8300\n",
      "Loss: tensor(0.0962, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8301\n",
      "Loss: tensor(0.0962, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8302\n",
      "Loss: tensor(0.0962, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8303\n",
      "Loss: tensor(0.0962, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8304\n",
      "Loss: tensor(0.0962, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8305\n",
      "Loss: tensor(0.0962, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8306\n",
      "Loss: tensor(0.0962, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8307\n",
      "Loss: tensor(0.0962, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8308\n",
      "Loss: tensor(0.0962, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8309\n",
      "Loss: tensor(0.0962, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8310\n",
      "Loss: tensor(0.0962, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8311\n",
      "Loss: tensor(0.0962, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8312\n",
      "Loss: tensor(0.0962, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8313\n",
      "Loss: tensor(0.0962, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8314\n",
      "Loss: tensor(0.0962, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8315\n",
      "Loss: tensor(0.0962, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8316\n",
      "Loss: tensor(0.0962, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8317\n",
      "Loss: tensor(0.0962, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8318\n",
      "Loss: tensor(0.0962, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8319\n",
      "Loss: tensor(0.0962, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8320\n",
      "Loss: tensor(0.0962, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8321\n",
      "Loss: tensor(0.0962, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8322\n",
      "Loss: tensor(0.0962, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8323\n",
      "Loss: tensor(0.0962, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8324\n",
      "Loss: tensor(0.0962, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8325\n",
      "Loss: tensor(0.0962, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8326\n",
      "Loss: tensor(0.0962, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8327\n",
      "Loss: tensor(0.0962, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8328\n",
      "Loss: tensor(0.0962, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8329\n",
      "Loss: tensor(0.0962, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8330\n",
      "Loss: tensor(0.0962, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8331\n",
      "Loss: tensor(0.0962, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8332\n",
      "Loss: tensor(0.0962, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8333\n",
      "Loss: tensor(0.0962, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8334\n",
      "Loss: tensor(0.0962, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8335\n",
      "Loss: tensor(0.0962, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8336\n",
      "Loss: tensor(0.0962, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8337\n",
      "Loss: tensor(0.0962, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8338\n",
      "Loss: tensor(0.0962, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8339\n",
      "Loss: tensor(0.0962, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8340\n",
      "Loss: tensor(0.0962, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8341\n",
      "Loss: tensor(0.0962, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8342\n",
      "Loss: tensor(0.0962, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8343\n",
      "Loss: tensor(0.0962, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8344\n",
      "Loss: tensor(0.0962, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8345\n",
      "Loss: tensor(0.0962, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8346\n",
      "Loss: tensor(0.0962, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8347\n",
      "Loss: tensor(0.0962, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8348\n",
      "Loss: tensor(0.0962, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8349\n",
      "Loss: tensor(0.0961, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8350\n",
      "Loss: tensor(0.0961, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8351\n",
      "Loss: tensor(0.0961, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8352\n",
      "Loss: tensor(0.0961, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8353\n",
      "Loss: tensor(0.0961, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8354\n",
      "Loss: tensor(0.0961, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8355\n",
      "Loss: tensor(0.0961, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8356\n",
      "Loss: tensor(0.0961, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8357\n",
      "Loss: tensor(0.0961, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8358\n",
      "Loss: tensor(0.0961, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8359\n",
      "Loss: tensor(0.0961, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8360\n",
      "Loss: tensor(0.0961, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8361\n",
      "Loss: tensor(0.0961, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8362\n",
      "Loss: tensor(0.0961, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8363\n",
      "Loss: tensor(0.0961, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8364\n",
      "Loss: tensor(0.0961, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8365\n",
      "Loss: tensor(0.0961, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8366\n",
      "Loss: tensor(0.0961, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8367\n",
      "Loss: tensor(0.0961, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8368\n",
      "Loss: tensor(0.0961, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8369\n",
      "Loss: tensor(0.0961, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8370\n",
      "Loss: tensor(0.0961, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8371\n",
      "Loss: tensor(0.0961, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8372\n",
      "Loss: tensor(0.0962, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8373\n",
      "Loss: tensor(0.0962, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8374\n",
      "Loss: tensor(0.0962, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8375\n",
      "Loss: tensor(0.0961, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8376\n",
      "Loss: tensor(0.0961, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8377\n",
      "Loss: tensor(0.0961, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8378\n",
      "Loss: tensor(0.0961, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8379\n",
      "Loss: tensor(0.0961, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8380\n",
      "Loss: tensor(0.0961, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8381\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor(0.0961, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8382\n",
      "Loss: tensor(0.0961, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8383\n",
      "Loss: tensor(0.0961, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8384\n",
      "Loss: tensor(0.0961, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8385\n",
      "Loss: tensor(0.0961, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8386\n",
      "Loss: tensor(0.0961, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8387\n",
      "Loss: tensor(0.0961, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8388\n",
      "Loss: tensor(0.0961, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8389\n",
      "Loss: tensor(0.0961, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8390\n",
      "Loss: tensor(0.0961, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8391\n",
      "Loss: tensor(0.0961, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8392\n",
      "Loss: tensor(0.0961, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8393\n",
      "Loss: tensor(0.0961, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8394\n",
      "Loss: tensor(0.0961, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8395\n",
      "Loss: tensor(0.0961, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8396\n",
      "Loss: tensor(0.0961, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8397\n",
      "Loss: tensor(0.0961, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8398\n",
      "Loss: tensor(0.0961, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8399\n",
      "Loss: tensor(0.0961, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8400\n",
      "Loss: tensor(0.0961, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8401\n",
      "Loss: tensor(0.0961, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8402\n",
      "Loss: tensor(0.0961, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8403\n",
      "Loss: tensor(0.0961, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8404\n",
      "Loss: tensor(0.0961, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8405\n",
      "Loss: tensor(0.0961, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8406\n",
      "Loss: tensor(0.0961, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8407\n",
      "Loss: tensor(0.0961, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8408\n",
      "Loss: tensor(0.0961, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8409\n",
      "Loss: tensor(0.0961, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8410\n",
      "Loss: tensor(0.0961, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8411\n",
      "Loss: tensor(0.0961, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8412\n",
      "Loss: tensor(0.0961, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8413\n",
      "Loss: tensor(0.0961, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8414\n",
      "Loss: tensor(0.0961, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8415\n",
      "Loss: tensor(0.0961, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8416\n",
      "Loss: tensor(0.0961, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8417\n",
      "Loss: tensor(0.0961, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8418\n",
      "Loss: tensor(0.0961, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8419\n",
      "Loss: tensor(0.0961, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8420\n",
      "Loss: tensor(0.0961, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8421\n",
      "Loss: tensor(0.0961, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8422\n",
      "Loss: tensor(0.0961, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8423\n",
      "Loss: tensor(0.0961, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8424\n",
      "Loss: tensor(0.0961, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8425\n",
      "Loss: tensor(0.0961, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8426\n",
      "Loss: tensor(0.0961, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8427\n",
      "Loss: tensor(0.0961, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8428\n",
      "Loss: tensor(0.0961, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8429\n",
      "Loss: tensor(0.0961, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8430\n",
      "Loss: tensor(0.0961, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8431\n",
      "Loss: tensor(0.0961, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8432\n",
      "Loss: tensor(0.0961, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8433\n",
      "Loss: tensor(0.0961, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8434\n",
      "Loss: tensor(0.0961, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8435\n",
      "Loss: tensor(0.0961, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8436\n",
      "Loss: tensor(0.0961, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8437\n",
      "Loss: tensor(0.0961, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8438\n",
      "Loss: tensor(0.0961, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8439\n",
      "Loss: tensor(0.0961, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8440\n",
      "Loss: tensor(0.0961, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8441\n",
      "Loss: tensor(0.0961, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8442\n",
      "Loss: tensor(0.0961, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8443\n",
      "Loss: tensor(0.0961, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8444\n",
      "Loss: tensor(0.0961, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8445\n",
      "Loss: tensor(0.0961, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8446\n",
      "Loss: tensor(0.0961, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8447\n",
      "Loss: tensor(0.0961, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8448\n",
      "Loss: tensor(0.0961, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8449\n",
      "Loss: tensor(0.0961, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8450\n",
      "Loss: tensor(0.0961, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8451\n",
      "Loss: tensor(0.0961, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8452\n",
      "Loss: tensor(0.0961, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8453\n",
      "Loss: tensor(0.0961, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8454\n",
      "Loss: tensor(0.0961, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8455\n",
      "Loss: tensor(0.0961, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8456\n",
      "Loss: tensor(0.0961, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8457\n",
      "Loss: tensor(0.0960, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8458\n",
      "Loss: tensor(0.0960, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8459\n",
      "Loss: tensor(0.0960, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8460\n",
      "Loss: tensor(0.0961, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8461\n",
      "Loss: tensor(0.0961, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8462\n",
      "Loss: tensor(0.0961, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8463\n",
      "Loss: tensor(0.0961, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8464\n",
      "Loss: tensor(0.0960, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8465\n",
      "Loss: tensor(0.0960, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8466\n",
      "Loss: tensor(0.0960, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8467\n",
      "Loss: tensor(0.0960, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8468\n",
      "Loss: tensor(0.0960, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8469\n",
      "Loss: tensor(0.0960, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8470\n",
      "Loss: tensor(0.0960, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8471\n",
      "Loss: tensor(0.0960, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8472\n",
      "Loss: tensor(0.0960, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8473\n",
      "Loss: tensor(0.0960, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8474\n",
      "Loss: tensor(0.0960, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8475\n",
      "Loss: tensor(0.0960, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8476\n",
      "Loss: tensor(0.0960, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8477\n",
      "Loss: tensor(0.0960, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8478\n",
      "Loss: tensor(0.0960, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8479\n",
      "Loss: tensor(0.0960, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8480\n",
      "Loss: tensor(0.0960, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8481\n",
      "Loss: tensor(0.0960, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8482\n",
      "Loss: tensor(0.0960, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8483\n",
      "Loss: tensor(0.0960, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8484\n",
      "Loss: tensor(0.0960, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8485\n",
      "Loss: tensor(0.0960, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8486\n",
      "Loss: tensor(0.0960, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8487\n",
      "Loss: tensor(0.0960, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8488\n",
      "Loss: tensor(0.0960, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8489\n",
      "Loss: tensor(0.0960, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8490\n",
      "Loss: tensor(0.0960, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8491\n",
      "Loss: tensor(0.0960, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8492\n",
      "Loss: tensor(0.0960, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8493\n",
      "Loss: tensor(0.0960, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8494\n",
      "Loss: tensor(0.0960, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8495\n",
      "Loss: tensor(0.0960, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8496\n",
      "Loss: tensor(0.0960, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8497\n",
      "Loss: tensor(0.0960, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8498\n",
      "Loss: tensor(0.0960, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8499\n",
      "Loss: tensor(0.0960, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8500\n",
      "Loss: tensor(0.0960, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8501\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor(0.0960, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8502\n",
      "Loss: tensor(0.0960, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8503\n",
      "Loss: tensor(0.0960, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8504\n",
      "Loss: tensor(0.0960, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8505\n",
      "Loss: tensor(0.0960, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8506\n",
      "Loss: tensor(0.0960, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8507\n",
      "Loss: tensor(0.0960, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8508\n",
      "Loss: tensor(0.0960, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8509\n",
      "Loss: tensor(0.0960, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8510\n",
      "Loss: tensor(0.0960, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8511\n",
      "Loss: tensor(0.0960, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8512\n",
      "Loss: tensor(0.0960, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8513\n",
      "Loss: tensor(0.0960, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8514\n",
      "Loss: tensor(0.0960, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8515\n",
      "Loss: tensor(0.0960, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8516\n",
      "Loss: tensor(0.0960, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8517\n",
      "Loss: tensor(0.0960, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8518\n",
      "Loss: tensor(0.0960, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8519\n",
      "Loss: tensor(0.0960, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8520\n",
      "Loss: tensor(0.0960, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8521\n",
      "Loss: tensor(0.0960, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8522\n",
      "Loss: tensor(0.0960, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8523\n",
      "Loss: tensor(0.0960, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8524\n",
      "Loss: tensor(0.0960, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8525\n",
      "Loss: tensor(0.0960, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8526\n",
      "Loss: tensor(0.0960, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8527\n",
      "Loss: tensor(0.0960, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8528\n",
      "Loss: tensor(0.0960, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8529\n",
      "Loss: tensor(0.0960, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8530\n",
      "Loss: tensor(0.0960, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8531\n",
      "Loss: tensor(0.0960, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8532\n",
      "Loss: tensor(0.0960, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8533\n",
      "Loss: tensor(0.0960, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8534\n",
      "Loss: tensor(0.0960, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8535\n",
      "Loss: tensor(0.0960, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8536\n",
      "Loss: tensor(0.0960, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8537\n",
      "Loss: tensor(0.0960, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8538\n",
      "Loss: tensor(0.0960, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8539\n",
      "Loss: tensor(0.0960, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8540\n",
      "Loss: tensor(0.0960, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8541\n",
      "Loss: tensor(0.0960, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8542\n",
      "Loss: tensor(0.0960, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8543\n",
      "Loss: tensor(0.0960, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8544\n",
      "Loss: tensor(0.0960, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8545\n",
      "Loss: tensor(0.0960, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8546\n",
      "Loss: tensor(0.0960, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8547\n",
      "Loss: tensor(0.0960, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8548\n",
      "Loss: tensor(0.0960, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8549\n",
      "Loss: tensor(0.0960, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8550\n",
      "Loss: tensor(0.0960, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8551\n",
      "Loss: tensor(0.0960, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8552\n",
      "Loss: tensor(0.0960, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8553\n",
      "Loss: tensor(0.0960, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8554\n",
      "Loss: tensor(0.0960, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8555\n",
      "Loss: tensor(0.0960, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8556\n",
      "Loss: tensor(0.0960, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8557\n",
      "Loss: tensor(0.0960, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8558\n",
      "Loss: tensor(0.0960, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8559\n",
      "Loss: tensor(0.0960, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8560\n",
      "Loss: tensor(0.0960, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8561\n",
      "Loss: tensor(0.0960, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8562\n",
      "Loss: tensor(0.0960, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8563\n",
      "Loss: tensor(0.0960, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8564\n",
      "Loss: tensor(0.0960, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8565\n",
      "Loss: tensor(0.0960, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8566\n",
      "Loss: tensor(0.0960, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8567\n",
      "Loss: tensor(0.0960, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8568\n",
      "Loss: tensor(0.0960, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8569\n",
      "Loss: tensor(0.0960, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8570\n",
      "Loss: tensor(0.0960, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8571\n",
      "Loss: tensor(0.0960, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8572\n",
      "Loss: tensor(0.0960, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8573\n",
      "Loss: tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8574\n",
      "Loss: tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8575\n",
      "Loss: tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8576\n",
      "Loss: tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8577\n",
      "Loss: tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8578\n",
      "Loss: tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8579\n",
      "Loss: tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8580\n",
      "Loss: tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8581\n",
      "Loss: tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8582\n",
      "Loss: tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8583\n",
      "Loss: tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8584\n",
      "Loss: tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8585\n",
      "Loss: tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8586\n",
      "Loss: tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8587\n",
      "Loss: tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8588\n",
      "Loss: tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8589\n",
      "Loss: tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8590\n",
      "Loss: tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8591\n",
      "Loss: tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8592\n",
      "Loss: tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8593\n",
      "Loss: tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8594\n",
      "Loss: tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8595\n",
      "Loss: tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8596\n",
      "Loss: tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8597\n",
      "Loss: tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8598\n",
      "Loss: tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8599\n",
      "Loss: tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8600\n",
      "Loss: tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8601\n",
      "Loss: tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8602\n",
      "Loss: tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8603\n",
      "Loss: tensor(0.0960, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8604\n",
      "Loss: tensor(0.0960, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8605\n",
      "Loss: tensor(0.0960, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8606\n",
      "Loss: tensor(0.0960, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8607\n",
      "Loss: tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8608\n",
      "Loss: tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8609\n",
      "Loss: tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8610\n",
      "Loss: tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8611\n",
      "Loss: tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8612\n",
      "Loss: tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8613\n",
      "Loss: tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8614\n",
      "Loss: tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8615\n",
      "Loss: tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8616\n",
      "Loss: tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8617\n",
      "Loss: tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8618\n",
      "Loss: tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8619\n",
      "Loss: tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8620\n",
      "Loss: tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8621\n",
      "Loss: tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8622\n",
      "Loss: tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8623\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8624\n",
      "Loss: tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8625\n",
      "Loss: tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8626\n",
      "Loss: tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8627\n",
      "Loss: tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8628\n",
      "Loss: tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8629\n",
      "Loss: tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8630\n",
      "Loss: tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8631\n",
      "Loss: tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8632\n",
      "Loss: tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8633\n",
      "Loss: tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8634\n",
      "Loss: tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8635\n",
      "Loss: tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8636\n",
      "Loss: tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8637\n",
      "Loss: tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8638\n",
      "Loss: tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8639\n",
      "Loss: tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8640\n",
      "Loss: tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8641\n",
      "Loss: tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8642\n",
      "Loss: tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8643\n",
      "Loss: tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8644\n",
      "Loss: tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8645\n",
      "Loss: tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8646\n",
      "Loss: tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8647\n",
      "Loss: tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8648\n",
      "Loss: tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8649\n",
      "Loss: tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8650\n",
      "Loss: tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8651\n",
      "Loss: tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8652\n",
      "Loss: tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8653\n",
      "Loss: tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8654\n",
      "Loss: tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8655\n",
      "Loss: tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8656\n",
      "Loss: tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8657\n",
      "Loss: tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8658\n",
      "Loss: tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8659\n",
      "Loss: tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8660\n",
      "Loss: tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8661\n",
      "Loss: tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8662\n",
      "Loss: tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8663\n",
      "Loss: tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8664\n",
      "Loss: tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8665\n",
      "Loss: tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8666\n",
      "Loss: tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8667\n",
      "Loss: tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8668\n",
      "Loss: tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8669\n",
      "Loss: tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8670\n",
      "Loss: tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8671\n",
      "Loss: tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8672\n",
      "Loss: tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8673\n",
      "Loss: tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8674\n",
      "Loss: tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8675\n",
      "Loss: tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8676\n",
      "Loss: tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8677\n",
      "Loss: tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8678\n",
      "Loss: tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8679\n",
      "Loss: tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8680\n",
      "Loss: tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8681\n",
      "Loss: tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8682\n",
      "Loss: tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8683\n",
      "Loss: tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8684\n",
      "Loss: tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8685\n",
      "Loss: tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8686\n",
      "Loss: tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8687\n",
      "Loss: tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8688\n",
      "Loss: tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8689\n",
      "Loss: tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8690\n",
      "Loss: tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8691\n",
      "Loss: tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8692\n",
      "Loss: tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8693\n",
      "Loss: tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8694\n",
      "Loss: tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8695\n",
      "Loss: tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8696\n",
      "Loss: tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8697\n",
      "Loss: tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8698\n",
      "Loss: tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8699\n",
      "Loss: tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8700\n",
      "Loss: tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8701\n",
      "Loss: tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8702\n",
      "Loss: tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8703\n",
      "Loss: tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8704\n",
      "Loss: tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8705\n",
      "Loss: tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8706\n",
      "Loss: tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8707\n",
      "Loss: tensor(0.0959, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8708\n",
      "Loss: tensor(0.0958, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8709\n",
      "Loss: tensor(0.0958, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8710\n",
      "Loss: tensor(0.0958, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8711\n",
      "Loss: tensor(0.0958, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8712\n",
      "Loss: tensor(0.0958, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8713\n",
      "Loss: tensor(0.0958, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8714\n",
      "Loss: tensor(0.0958, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8715\n",
      "Loss: tensor(0.0958, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8716\n",
      "Loss: tensor(0.0958, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8717\n",
      "Loss: tensor(0.0958, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8718\n",
      "Loss: tensor(0.0958, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8719\n",
      "Loss: tensor(0.0958, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8720\n",
      "Loss: tensor(0.0958, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8721\n",
      "Loss: tensor(0.0958, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8722\n",
      "Loss: tensor(0.0958, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8723\n",
      "Loss: tensor(0.0958, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8724\n",
      "Loss: tensor(0.0958, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8725\n",
      "Loss: tensor(0.0958, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8726\n",
      "Loss: tensor(0.0958, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8727\n",
      "Loss: tensor(0.0958, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8728\n",
      "Loss: tensor(0.0958, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8729\n",
      "Loss: tensor(0.0958, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8730\n",
      "Loss: tensor(0.0958, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8731\n",
      "Loss: tensor(0.0958, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8732\n",
      "Loss: tensor(0.0958, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8733\n",
      "Loss: tensor(0.0958, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8734\n",
      "Loss: tensor(0.0958, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8735\n",
      "Loss: tensor(0.0958, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8736\n",
      "Loss: tensor(0.0958, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8737\n",
      "Loss: tensor(0.0958, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8738\n",
      "Loss: tensor(0.0958, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8739\n",
      "Loss: tensor(0.0958, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8740\n",
      "Loss: tensor(0.0958, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8741\n",
      "Loss: tensor(0.0958, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8742\n",
      "Loss: tensor(0.0958, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8743\n",
      "Loss: tensor(0.0958, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8744\n",
      "Loss: tensor(0.0958, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8745\n",
      "Loss: tensor(0.0958, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8746\n",
      "Loss: tensor(0.0958, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8747\n",
      "Loss: tensor(0.0958, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8748\n",
      "Loss: tensor(0.0958, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8749\n",
      "Loss: tensor(0.0958, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8750\n",
      "Loss: tensor(0.0958, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8751\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor(0.0958, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8752\n",
      "Loss: tensor(0.0958, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8753\n",
      "Loss: tensor(0.0958, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8754\n",
      "Loss: tensor(0.0958, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8755\n",
      "Loss: tensor(0.0958, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8756\n",
      "Loss: tensor(0.0958, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8757\n",
      "Loss: tensor(0.0958, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8758\n",
      "Loss: tensor(0.0958, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8759\n",
      "Loss: tensor(0.0958, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8760\n",
      "Loss: tensor(0.0958, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8761\n",
      "Loss: tensor(0.0958, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8762\n",
      "Loss: tensor(0.0958, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8763\n",
      "Loss: tensor(0.0958, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8764\n",
      "Loss: tensor(0.0958, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8765\n",
      "Loss: tensor(0.0958, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8766\n",
      "Loss: tensor(0.0958, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8767\n",
      "Loss: tensor(0.0958, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8768\n",
      "Loss: tensor(0.0958, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8769\n",
      "Loss: tensor(0.0958, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8770\n",
      "Loss: tensor(0.0958, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8771\n",
      "Loss: tensor(0.0958, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8772\n",
      "Loss: tensor(0.0958, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8773\n",
      "Loss: tensor(0.0958, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8774\n",
      "Loss: tensor(0.0958, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8775\n",
      "Loss: tensor(0.0958, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8776\n",
      "Loss: tensor(0.0958, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8777\n",
      "Loss: tensor(0.0958, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8778\n",
      "Loss: tensor(0.0958, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8779\n",
      "Loss: tensor(0.0958, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8780\n",
      "Loss: tensor(0.0958, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8781\n",
      "Loss: tensor(0.0958, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8782\n",
      "Loss: tensor(0.0958, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8783\n",
      "Loss: tensor(0.0958, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8784\n",
      "Loss: tensor(0.0958, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8785\n",
      "Loss: tensor(0.0958, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8786\n",
      "Loss: tensor(0.0958, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8787\n",
      "Loss: tensor(0.0958, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8788\n",
      "Loss: tensor(0.0958, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8789\n",
      "Loss: tensor(0.0958, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8790\n",
      "Loss: tensor(0.0958, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8791\n",
      "Loss: tensor(0.0958, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8792\n",
      "Loss: tensor(0.0958, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8793\n",
      "Loss: tensor(0.0958, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8794\n",
      "Loss: tensor(0.0958, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8795\n",
      "Loss: tensor(0.0958, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8796\n",
      "Loss: tensor(0.0958, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8797\n",
      "Loss: tensor(0.0958, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8798\n",
      "Loss: tensor(0.0958, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8799\n",
      "Loss: tensor(0.0958, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8800\n",
      "Loss: tensor(0.0958, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8801\n",
      "Loss: tensor(0.0958, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8802\n",
      "Loss: tensor(0.0958, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8803\n",
      "Loss: tensor(0.0958, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8804\n",
      "Loss: tensor(0.0958, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8805\n",
      "Loss: tensor(0.0958, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8806\n",
      "Loss: tensor(0.0958, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8807\n",
      "Loss: tensor(0.0958, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8808\n",
      "Loss: tensor(0.0958, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8809\n",
      "Loss: tensor(0.0958, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8810\n",
      "Loss: tensor(0.0958, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8811\n",
      "Loss: tensor(0.0958, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8812\n",
      "Loss: tensor(0.0958, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8813\n",
      "Loss: tensor(0.0958, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8814\n",
      "Loss: tensor(0.0958, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8815\n",
      "Loss: tensor(0.0958, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8816\n",
      "Loss: tensor(0.0958, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8817\n",
      "Loss: tensor(0.0958, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8818\n",
      "Loss: tensor(0.0958, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8819\n",
      "Loss: tensor(0.0958, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8820\n",
      "Loss: tensor(0.0958, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8821\n",
      "Loss: tensor(0.0958, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8822\n",
      "Loss: tensor(0.0958, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8823\n",
      "Loss: tensor(0.0958, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8824\n",
      "Loss: tensor(0.0958, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8825\n",
      "Loss: tensor(0.0958, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8826\n",
      "Loss: tensor(0.0958, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8827\n",
      "Loss: tensor(0.0958, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8828\n",
      "Loss: tensor(0.0958, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8829\n",
      "Loss: tensor(0.0958, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8830\n",
      "Loss: tensor(0.0958, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8831\n",
      "Loss: tensor(0.0958, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8832\n",
      "Loss: tensor(0.0958, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8833\n",
      "Loss: tensor(0.0958, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8834\n",
      "Loss: tensor(0.0958, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8835\n",
      "Loss: tensor(0.0958, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8836\n",
      "Loss: tensor(0.0958, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8837\n",
      "Loss: tensor(0.0958, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8838\n",
      "Loss: tensor(0.0958, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8839\n",
      "Loss: tensor(0.0958, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8840\n",
      "Loss: tensor(0.0958, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8841\n",
      "Loss: tensor(0.0957, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8842\n",
      "Loss: tensor(0.0957, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8843\n",
      "Loss: tensor(0.0957, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8844\n",
      "Loss: tensor(0.0957, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8845\n",
      "Loss: tensor(0.0957, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8846\n",
      "Loss: tensor(0.0957, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8847\n",
      "Loss: tensor(0.0957, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8848\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor(0.0957, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8849\n",
      "Loss: tensor(0.0957, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8850\n",
      "Loss: tensor(0.0957, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8851\n",
      "Loss: tensor(0.0957, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8852\n",
      "Loss: tensor(0.0957, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8853\n",
      "Loss: tensor(0.0957, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8854\n",
      "Loss: tensor(0.0957, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8855\n",
      "Loss: tensor(0.0957, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8856\n",
      "Loss: tensor(0.0957, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8857\n",
      "Loss: tensor(0.0957, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8858\n",
      "Loss: tensor(0.0957, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8859\n",
      "Loss: tensor(0.0957, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8860\n",
      "Loss: tensor(0.0957, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8861\n",
      "Loss: tensor(0.0957, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8862\n",
      "Loss: tensor(0.0957, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8863\n",
      "Loss: tensor(0.0957, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8864\n",
      "Loss: tensor(0.0957, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8865\n",
      "Loss: tensor(0.0957, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8866\n",
      "Loss: tensor(0.0957, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8867\n",
      "Loss: tensor(0.0957, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8868\n",
      "Loss: tensor(0.0957, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8869\n",
      "Loss: tensor(0.0957, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8870\n",
      "Loss: tensor(0.0957, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8871\n",
      "Loss: tensor(0.0957, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8872\n",
      "Loss: tensor(0.0957, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8873\n",
      "Loss: tensor(0.0957, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8874\n",
      "Loss: tensor(0.0957, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8875\n",
      "Loss: tensor(0.0957, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8876\n",
      "Loss: tensor(0.0957, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8877\n",
      "Loss: tensor(0.0957, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8878\n",
      "Loss: tensor(0.0957, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8879\n",
      "Loss: tensor(0.0957, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8880\n",
      "Loss: tensor(0.0957, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8881\n",
      "Loss: tensor(0.0957, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8882\n",
      "Loss: tensor(0.0957, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8883\n",
      "Loss: tensor(0.0957, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8884\n",
      "Loss: tensor(0.0957, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8885\n",
      "Loss: tensor(0.0957, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8886\n",
      "Loss: tensor(0.0957, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8887\n",
      "Loss: tensor(0.0957, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8888\n",
      "Loss: tensor(0.0957, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8889\n",
      "Loss: tensor(0.0957, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8890\n",
      "Loss: tensor(0.0957, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8891\n",
      "Loss: tensor(0.0957, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8892\n",
      "Loss: tensor(0.0957, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8893\n",
      "Loss: tensor(0.0957, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8894\n",
      "Loss: tensor(0.0957, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8895\n",
      "Loss: tensor(0.0957, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8896\n",
      "Loss: tensor(0.0957, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8897\n",
      "Loss: tensor(0.0957, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8898\n",
      "Loss: tensor(0.0957, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8899\n",
      "Loss: tensor(0.0957, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8900\n",
      "Loss: tensor(0.0957, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8901\n",
      "Loss: tensor(0.0957, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8902\n",
      "Loss: tensor(0.0957, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8903\n",
      "Loss: tensor(0.0957, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8904\n",
      "Loss: tensor(0.0957, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8905\n",
      "Loss: tensor(0.0957, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8906\n",
      "Loss: tensor(0.0957, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8907\n",
      "Loss: tensor(0.0957, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8908\n",
      "Loss: tensor(0.0957, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8909\n",
      "Loss: tensor(0.0957, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8910\n",
      "Loss: tensor(0.0957, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8911\n",
      "Loss: tensor(0.0957, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8912\n",
      "Loss: tensor(0.0957, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8913\n",
      "Loss: tensor(0.0957, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8914\n",
      "Loss: tensor(0.0957, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8915\n",
      "Loss: tensor(0.0957, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8916\n",
      "Loss: tensor(0.0957, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8917\n",
      "Loss: tensor(0.0957, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8918\n",
      "Loss: tensor(0.0957, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8919\n",
      "Loss: tensor(0.0957, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8920\n",
      "Loss: tensor(0.0957, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8921\n",
      "Loss: tensor(0.0957, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8922\n",
      "Loss: tensor(0.0957, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8923\n",
      "Loss: tensor(0.0957, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8924\n",
      "Loss: tensor(0.0957, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8925\n",
      "Loss: tensor(0.0957, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8926\n",
      "Loss: tensor(0.0957, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8927\n",
      "Loss: tensor(0.0957, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8928\n",
      "Loss: tensor(0.0957, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8929\n",
      "Loss: tensor(0.0957, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8930\n",
      "Loss: tensor(0.0957, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8931\n",
      "Loss: tensor(0.0957, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8932\n",
      "Loss: tensor(0.0957, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8933\n",
      "Loss: tensor(0.0957, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8934\n",
      "Loss: tensor(0.0957, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8935\n",
      "Loss: tensor(0.0957, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8936\n",
      "Loss: tensor(0.0957, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8937\n",
      "Loss: tensor(0.0957, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8938\n",
      "Loss: tensor(0.0957, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8939\n",
      "Loss: tensor(0.0957, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8940\n",
      "Loss: tensor(0.0957, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8941\n",
      "Loss: tensor(0.0957, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8942\n",
      "Loss: tensor(0.0957, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8943\n",
      "Loss: tensor(0.0957, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8944\n",
      "Loss: tensor(0.0957, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8945\n",
      "Loss: tensor(0.0957, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8946\n",
      "Loss: tensor(0.0957, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8947\n",
      "Loss: tensor(0.0957, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8948\n",
      "Loss: tensor(0.0957, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8949\n",
      "Loss: tensor(0.0957, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8950\n",
      "Loss: tensor(0.0957, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8951\n",
      "Loss: tensor(0.0957, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8952\n",
      "Loss: tensor(0.0957, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8953\n",
      "Loss: tensor(0.0957, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8954\n",
      "Loss: tensor(0.0957, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8955\n",
      "Loss: tensor(0.0957, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8956\n",
      "Loss: tensor(0.0957, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8957\n",
      "Loss: tensor(0.0957, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8958\n",
      "Loss: tensor(0.0957, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8959\n",
      "Loss: tensor(0.0957, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8960\n",
      "Loss: tensor(0.0957, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8961\n",
      "Loss: tensor(0.0957, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8962\n",
      "Loss: tensor(0.0957, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8963\n",
      "Loss: tensor(0.0957, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8964\n",
      "Loss: tensor(0.0957, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8965\n",
      "Loss: tensor(0.0957, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8966\n",
      "Loss: tensor(0.0957, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8967\n",
      "Loss: tensor(0.0957, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8968\n",
      "Loss: tensor(0.0957, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8969\n",
      "Loss: tensor(0.0957, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8970\n",
      "Loss: tensor(0.0957, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8971\n",
      "Loss: tensor(0.0957, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8972\n",
      "Loss: tensor(0.0957, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8973\n",
      "Loss: tensor(0.0956, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8974\n",
      "Loss: tensor(0.0956, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8975\n",
      "Loss: tensor(0.0956, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8976\n",
      "Loss: tensor(0.0956, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8977\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor(0.0956, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8978\n",
      "Loss: tensor(0.0956, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8979\n",
      "Loss: tensor(0.0956, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8980\n",
      "Loss: tensor(0.0956, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8981\n",
      "Loss: tensor(0.0956, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8982\n",
      "Loss: tensor(0.0956, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8983\n",
      "Loss: tensor(0.0956, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8984\n",
      "Loss: tensor(0.0956, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8985\n",
      "Loss: tensor(0.0956, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8986\n",
      "Loss: tensor(0.0956, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8987\n",
      "Loss: tensor(0.0956, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8988\n",
      "Loss: tensor(0.0956, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8989\n",
      "Loss: tensor(0.0956, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8990\n",
      "Loss: tensor(0.0956, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8991\n",
      "Loss: tensor(0.0956, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8992\n",
      "Loss: tensor(0.0956, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8993\n",
      "Loss: tensor(0.0956, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8994\n",
      "Loss: tensor(0.0956, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8995\n",
      "Loss: tensor(0.0956, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8996\n",
      "Loss: tensor(0.0956, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8997\n",
      "Loss: tensor(0.0956, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8998\n",
      "Loss: tensor(0.0956, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8999\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(9000):  \n",
    "        \n",
    "    optimizer.zero_grad()   # zero the gradient buffers\n",
    "    output = net(input.float())\n",
    "\n",
    "    loss = criterion(output, targets)\n",
    "    print('Loss:', loss, ' at epoch:', epoch)\n",
    "\n",
    "    loss.backward()  #backprop\n",
    "    optimizer.step()    # Does the update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load previously saved FCNN model \n",
    "\n",
    "stage='NNetwork/'\n",
    "SavesDirectory='./TunedModels/'+model_class+'/'+model_version+\"/\"+stage\n",
    "#PATH = SavesDirectory+'Tanh_MSE_adam4940.pth'\n",
    "\n",
    "net = Net()\n",
    "net.load_state_dict(torch.load(PATH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 2 2 4 4 5 3 4 1 4 5 5 4 4 3 4 3 1 5 3 3 3 4 1 1 1 5 5 4 4 5 1 0 4 1 0 3 3 3 2 1 3 2 1 2 2 4 1 1 2 4 4 4 1 5 4 2 2 1 1 4 1 4 2 4 5 4 2 4 5 4 1 5 5 4 1 4 5 4 4 2 2 2 5 4 5 5 1 3 4 4 5 3 4 1 0 0 0 0 5 2 2 2 1 5 5 5 1 5 5 5 5 5 5 5 5 5 5 5 5 5 3 3 3 4 3 3 3 3 1 1 4 1 3 2 3 3 3 2 3 5 1 4 2 2 5 1 2 1 2 5 4 1 4 5 1 1 1 1 1 5 1 1 1 0 1 1 1 1 0 1 1 1 1 3 3 2 2 2 2 3 4 5 4 4 4 4 0 2 2 0 3 3 4 2 2 2 4 2 2 2 2 3 2 2 2 1 2 2 2 2 1 1 1 2 2 2 2 2 4 4 4 4 1 3 0 0 5 5 3 3 5 2 3 3 1 2 1 2 1 1 2 1 1 1 2 1 2 2 2 2 3 3 3 3 4 4 2 2 2 2 2 2 3 1 1 3 3 3 1 1 1 1 2 3 3 0 3 3 2 3 5 2 4 4 4 3 3 3 3 4 4 4 0 1 5 5 5 5 5 0 3 0 0 0 0 1 4 3 4 1 3 2 4 4 4 3 3 3 4 1 2 2 1 0 0 0 3 5 0 0 0 0 0 5 5 4 4 1 3 3 5 3 3 3 3 3 3 3 3 4 2 1 1 1 1 4 3 4 3 3 3 3 3 0 4 4 4 4 4 3 3 1 1 2 2 4 3 3 5 4 4 4 1 5 1 4 1 4 4 4 1 4 5 5 1 2 3 3 5 5 5 5 4 5 5 1 4 4 4 4 1 4 2 5 2 2 5 5 3 1 1 1 1 4 2 4 5 4 3 4 3 5 5 5 3 3 5 5 3 3 5 4 5 3 3 5 3 5 4 4 5 3 4 4 5 3 3 3 3 5 4 5 3 5 4 5 4 3 1 5 5 4 3 4 5 3 5 3 4 3 5 3 1 3 5 3 5 5 5 3 5 4 3 3 5 3 3 5 4 3 5 3 3 3 1 5 5 3 3 3 3 3 3 5 4 3 5 5 5 5 3 3 5 4 3 5 5 5 3 3 3 3 1 3 1 3 3 3 3 3 5 4 3 3 3 1 3 3 3 3 1 4 3 3 5 3 5 5 4 3 3 5 4 5 5 5 5 4 3 5 4 3 5 5 5 3 5 3 5 5 3 3 3 3 5 1 5 1 1 5 3 5 3 3 1 5 3 4 1 1 3 3 4 4 5 3 3 5 3 3 5 3 4 4 5 3 3 3 3 5 5 3 3 5 3 3 3 4 3 5 1 5 3 3 3 3 5 3 4 5 3 4 4 4 3 5 5 3 5 4 3 3 3 4 5 5 5 4 4 3 3 3 1 5 1 3 3 1 3 3 4 4 3 3 3 3 4 3 3 5 3 3 1 3 1 3 3 5 4 5 3 3 3 4 4 3 4 4 3 3 5 4 3 3 3 3 3 4 3 3 5 3 4 5 3 3 3 3 3 5 5 3 3 3 5 4 5 4 3 3 3 5 1 5 5 3 5 3 5 4 3 3 3 5 4 3 5 3 3 3 3 4 3 5 4 3 3 4 1 3 3 4 1 3 3 3 3 3 3 3 1 3 3 5 5 3 3 5 3 5 4 3 3 5 3 5 3 5 3 3 3 3 4 4 3 4 3 3 3 4 5 5 4 4 3 4 4 3 3 5 5 4 3 3 3 4 4 5 5 4 5 4 4 3 5 3 4 4 5 3 4 5 4 5 4 3 4 5 3 3 3 4 5 4 5 3 1 3 3 4 5 3 4 4 3 5 3 3 3 5 3 4 4 3 5 4 4 4 3 3 3 4 3 4 3 4 4 4 4 4 4 3 4 4 5 3 5 4 3 3 4 5 3 4 3 4 3 3 4 3 3 3 3 3 5 4 0 4 4 4 4 2 2 4 4 0 4 4 4 2 3 4 3 3 3 4 2 2 2 2 4 4 2 3 3 3 5 4 4 1 4 5 4 1 1 4 4 1 1 3 0 3 3 1 1 4 1 1 5 5 0 3 5 5 5 5 1 1 5 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 3 1 5 1 2 2 4 4 4 4 4 4 4 4 4 4 2 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 2 4 4 4 4 2 4 2 4 1 2 4 4 4 4 1 4 2 4 4 4 4 4 4 4 4 4 2 4 4 4 2 2 4 5 4 2 4 2 4 4 4 4 4 4 2 4 4 2 4 4 4 1 4 4 4 2 4 4 4 2 3 3 0 0 1 2 2 3 5 1 4 4 4 4 4 1 1 3 4 2 5 0 0 0 5 0 0 5 4 4 2 5 5 5 0 1 3 5 4 4 0 3 3 3 3 3 3 3 3 3 5 3 5 5 3 3 3 0 4 4 5 3 3 3 3 3 3 2 2 3 3 2 4 4 4 4 5 4 3 5 3 0 2 2 2 5 4 4 4 4 2 2 4 4 1 1 4 4 4 4 4 4 1 1 1 1 5 1 1 4 5 3 5 4 3 3 4 4 4 3 4 3 4 4 3 3 3 4 3 3 3 4 4 4 3 3 4 0 1 1 1 1 4 4 4 1 1 4 1 4 1 1 4 1 4 4 4 3 4 4 4 4 1 4 0 1 2 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 1 5 4 4 3 0 0 4 4 4 4 4 0 0 5 3 4 4 4 4 4 4 5 1 2 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 3 0 0 0 1 0 0 0 0 0 0 3 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 3 5 4 5 1 5 5 4 2 3 3 2 3 3 3 3 4 4 4 3 4 4 4 4 4 1 4 4 4 4 4 2 4 4 5 5 2 5 5 4 5 5 5 5 3 5 5 3 3 3 5 5 4 4 3 2 1 1 1 1 5 5 3 3 4 5 3 5 5 3 5 3 3 3 5 5 5 2 3 3 5 5 3 5 1 1 5 5 5 5 1 5 5 3 4 5 2 1 1 1 3 5 0 4 4 3 3 3 1 2 0 2 0 4 4 4 1 1 1 3 1 2 2 1 0 0 4 5 5 5 5 5 2 5 5 1 1 1 1 1 5 4 1 5 5 5 1 1 1 3 4 5 2 2 4 1 3 0 0 5 3 1 1 1 2 5 3 2 3 1 1 1 5 5 5 2 2 3 2 1 0 2 3 3 4 1 5 5 5 5 3 5 2 5 3 3 2 5 5 0 5 2 4 3 3 2 2 0 4 4 1 2 3 5 5 1 5 4 2 5 2 2 2 2 2 4 1 1 4 4 1 1 5 1 4 4 1 4 5 1 1 1 1 3 4 1 1 1 2 4 3 4 4 3 5 4 5 2 3 5 5 2 3 4 4 5 4 5 1 5 5 5 1 1 0 0 0 3 3 1 3 4 4 4 4 4 3 0 5 3 5 4 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 5 0 2 2 2 2 4 3 1 3 2 2 4 2 3 3 1 1 4 4 5 3 4 3 3 1 5 2 3 3 1 3 3 5 2 3 5 3 3 5 3 3 3 3 5 3 1 3 5 5 2 3 5 3 5 2 3 2 3 5 3 5 2 3 3 5 2 3 3 2 2 3 3 3 2 4 2 2 2 2 2 2 3 2 3 3 2 2 2 3 2 3 1 5 5 5 5 5 5 5 5 3 0 0 1 3 3 4 5 4 4 4 5 3 3 2 1 1 1 5 5 4 3 5 1 1 1 1 1 4 4 4 4 1 4 3 1 1 1 1 0 5 5 3 5 3 3 1 3 3 1 1 1 3 5 5 3 3 5 1 3 5 5 5 1 1 3 5 3 5 5 5 5 3 3 5 3 5 1 3 1 5 5 3 5 3 3 3 1 5 3 5 5 5 3 5 3 3 3 5 5 3 1 3 5 3 5 5 5 1 1 1 1 1 1 3 2 1 5 2 1 4 3 4 4 4 4 4 3 4 0 1 3 3 3 1 1 4 4 2 2 2 2 1 2 2 2 2 2 5 0 4 1 1 1 3 1 2 5 5 4 4 4 4 4 4 5 4 3 0 3 3 5 5 5 0 3 5 1 0 0 1 4 5 5 5 1 3 3 0 1 4 4 4 4 3 3 2 0 3 1 3 5 3 3 2 5 5 5 5 5 5 1 2 3 3 3 3 3 2 3 1 5 0 3 3 3 5 5 1 5 3 3 3 1 2 2 2 4 3 4 4 2 1 4 4 1 2 3 3 3 3 3 1 3 2 3 1 2 3 1 1 1 1 2 2 1 1 2 2 1 2 5 0 4 3 4 4 4 3 4 3 5 3 2 2 3 5 4 4 4 0 0 5 2 2 0 3 3 4 4 4 0 4 4 3 4 5 1 3 4 2 3 4 1 2 2 2 5 4 2 2 2 4 5 3 2 0 2 2 2 2 2 1 4 1 1 1 2 2 3 1 4 5 1 5 4 4 5 4 5 4 4 1 4 4 4 4 4 5 5 4 4 4 2 2 2 2 2 4 3 2 0 3 3 0 2 2 4 4 2 5 0 2 2 2 2 2 2 2 2 2 2 2 2 3 2 2 4 3 1 2 0 3 5 4 0 1 1 2 5 4 3 4 4 3 3 4 1 1 2 2 0 2 2 5 3 3 1 3 3 0 0 2 2 5 1 4 4 4 4 2 4 4 1 0 4 1 4 4 1 4 4 0 0 4 4 2 1 4 5 4 3 4 2 2 5 2 2 0 2 4 5 3 0 5 4 0 5 5 5 1 5 1 2 2 2 2 2 1 1 1 2 5 5 5 5 2 4 1 4 1 1 1 4 4 1 5 5 5 4 3 4 2 2 2 4 3 1 1 3 4 4 3 4 4 3 3 3 4 4 3 3 4 4 4 3 4 4 4 5 2 3 5 5 5 5 4 5 3 2 5 5 2 5 5 5 5 4 2 3 3 5 5 5 5 5 5 5 3 5 5 5 5 5 1 4 1 1 1 1 1 1 1 1 1 3 4 3 3 5 3 3 3 3 3 3 3 3 3 5 3 1 3 1 3 3 3 0 3 0 0 0 0 0 5 1 4 4 3 4 4 2 5 2 2 2 2 2 2 2 3 4 5 2 4 4 2 2 4 2 4 0 2 4 3 4 2 4 3 5 5 2 1 3 3 1 1 4 3 3 2 3 2 1 1 5 5 5 4 5 5 5 4 5 2 5 5 5 5 1 4 4 1 1 4 1 5 4 4 4 4 4 1 4 4 4 3 4 4 4 4 4 4 4 4 4 4 1 4 3 4 4 4 4 1 4 4 4 4 3 4 4 4 4 4 4 3 3 3 3 1 3 3 3 5 5 5 5 2 4 4 1 2 2 0 2 2 2 2 2 2 2 2 2 2 2 2 0 0 2 2 2 2 2 0 2 2 2 1 0 0 0 0 2 3 3 3 5 4 3 5 5 3 3 3 3 3 3 3 3 3 3 3 3 3 2 5 3 3 2 3 3 3 2 2 2 2 2 2 5 3 3 3 1 1 3 3 5 5 3 3 5 5 5 1 5 5 5 5 5 5 5 5 5 5 5 1 5 5 5 3 1 1 1 1 1 4 4 5 5 4 4 4 4 1 5 4 5 4 4 4 1 1 1 0 5 2 2 1 1 1 5 2 1 1 2 2 2 1 3 1 1 5 0 2 4 4 0 4 4 3 4 4 1 4 3 4 1 5 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 1 1 1 1 1 1 1 1 3 1 3 1 3 1 1 1 1 1 1 1 1 1 1 1 4 1 1 1 1 3 1 3 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 1 1 1 1 1 3 3 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 3 1 1 1 1 1 1 1 1 1 1 1 1 3 1 1 4 1 1 1 1 1 1 1 3 1 1 1 1 1 1 1 3 1 1 1 1 1 1 1 1 1 1 1 1 1 1 3 1 1 1 3 4 1 1 1 1 1 3 1 3 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 3 1 1 3 1 1 1 1 1 1 1 3 1 3 1 1 1 1 1 1 1 3 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 1 3 1 1 1 1 1 1 1 1 3 1 1 3 1 1 1 1 1 1 1 3 1 1 1 1 1 3 1 1 1 1 1 1 1 1 1 3 1 1 1 3 1 1 1 1 1 0 1 4 4 4 4 4 1 4 1 5 3 3 3 3 3 3 5 1 5 4 4 4 4 3 4 4 1 4 3 4 1 5 1 0 4 4 4 5 5 4 3 1 1 2 3 5 3 3 3 5 1 1 2 2 4 4 4 4 4 4 5 5 1 4 3 1 1 2 1 5 1 2 3 4 5 4 3 3 0 2 2 4 5 5 4 1 5 1 5 5 0 4 2 1 3 4 4 1 3 3 5 5 5 5 1 5 1 5 5 5 5 4 5 1 5 4 5 1 1 3 3 1 4 1 1 2 1 1 5 5 1 5 5 5 5 0 2 3 0 3 3 2 3 4 3 3 3 0 4 5 4 3 4 5 3 4 3 3 3 3 1 1 1 4 1 4 4 5 3 3 5 5 1 2 2 5 3 4 3 5 3 5 4 4 3 4 3 3 4 2 5 0 5 5 2 3 1 4 2 2 2 3 3 3 3 3 3 1 3 3 4 2 3 2 2 2 2 1 3 2 2 4 2 2 2 2 1 3 5 5 2 2 2 5 5 5 5 2 5 1 2 1 2 1 4 4 3 3 3 5 5 5 1 1 3 2 3 5 1 1 1 5 0 4 1 1 1 4 3 5 5 4 4 0 4 1 3 3 5 1 5 0 2 2 2 2 2 3 3 3 3 3 3 3 3 0 3 0 3 0 3 3 3 0 3 0 3 3 1 3 0 0 0 3 3 3 0 0 0 0 0 0 0 3 3 3 0 3 1 0 0 0 3 0 0 0 3 3 3 3 0 0 3 0 0 3 0 0 0 0 0 3 0 0 0 3 0 0 0 0 0 0 0 0 0 0 0 5 4 3 1 3 1 0 3 3 4 1 2 4 2 1 4 0 4 4 4 2 3 4 3 2 1 2 4 2 0 0 0 2 3 2 2 2 2 2 3 2 4 1 2 4 3 0 3 2 1 1 1 1 4 1 1 1 4 3 1 2 3 3 3 3 3 3 3 3 4 3 2 1 1 5 4 5 3 3 5 3 4 2 3 1 3 0 2 1 5 1 3 2 3 4 2 5 4 3 0 1 4 4 4 5 4 5 5 4 5 1 5 5 1 1 1 2 0 1 2 2 2 3 3 4 1 2 2 2 5 5 5 4 2 2 5 2 2 2 2 4 4 2 2 3 3 3 5 4 4 1 2 4 4 4 1 4 4 4 4 4 4 4 3 4 4 4 0 0 3 5 5 0 0 4 4 3 2 4 4 4 4 3 4 3 2 5 4 1 4 5 5 5 5 5 5 5 5 1 5 1 1 5 1 1 5 1 2 2 3 1 1 3 3 3 3 3 3 3 3 3 3 3 3 3 2 1 1 4 4 5 5 5 1 4 1 4 5 5 1 5 5 1 5 5 5 5 5 5 5 1 5 5 2 1 5 5 5 2 5 5 5 3 3 2 4 3 4 1 3 4 3 2 5 5 3 3 3 1 5 3 5 1 1 3 3 3 3 3 3 1 1 4 1 1 5 1 1 3 4 5 5 4 4 4 4 5 5 5 5 5 5 4 3 3 3 0 4 1 0 0 0 0 5 1 0 3 3 0 0 3 0 0 0 0 1 3 5 1 4 1 1 1 3 1 1 5 1 5 4 1 2 1 3 5 1 4 1 3 3 0 0 0 0 0 0 0 4 0 3 2 2 5 2 3 1 1 1 1 3 5 5 5 0 5 5 2 2 2 5 5 5 2 5 0 2 5 5 5 5 2 5 5 2 3 5 5 5 5 0 5 5 0 5 2 4 2 2 5 2 2 1 1 2 2 1 1 4 1 5 3 1 1 4 5 5 5 5 1 2 1 4 3 5 3 1 1 2 5 3 5 5 3 2 2 3 3 3 3 3 3 4 5 3 3 3 3 1 3 0 1 1 1 1 4 0 1 1 1 4 1 4 4 4 4 1 4 4 4 4 4 4 2 2 2 1 3 0 5 3 2 0 5 5 4 1 2 5 1 5 5 2 2 1 3 4 4 4 4 3 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 3 4 0 5 3 5 5 5 5 5 3 5 5 5 5 3 5 5 5 3 3 5 5 5 3 3 5 5 3 5 3 5 3 5 5 3 3 3 3 3 3 3 5 3 5 3 5 3 3 3 3 3 5 3 5 5 5 3 5 5 5 3 5 3 5 3 3 5 3 5 3 3 3 5 5 5 5 3 5 5 3 5 5 5 5 5 5 5 5 3 5 5 5 3 5 5 3 5 3 3 5 5 5 3 5 5 5 4 5 5 3 5 3 3 5 3 5 5 3 5 3 3 5 5 5 5 3 3 3 5 5 3 3 5 5 3 5 3 5 3 5 5 5 5 5 5 3 5 5 3 5 3 5 3 3 5 3 3 3 3 5 5 5 3 5 3 5 3 3 3 5 3 5 5 5 3 5 5 3 3 5 5 5 3 5 3 5 3 3 5 3 5 3 3 3 5 5 3 5 3 3 5 3 5 3 5 3 3"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 5 5 3 3 5 3 5 5 5 5 3 5 5 5 5 5 3 5 5 3 5 3 5 3 3 3 3 5 3 3 1 4 4 4 4 1 1 2 2 3 3 3 3 1 3 3 1 1 1 4 1 1 1 1 5 1 4 3 5 5 4 5 0 1 5 3 4 3 2 4 1 5 1 1 1 3 1 4 4 5 4 4 5 4 5 4 1 4 4 4 2 2 5 4 1 3 1 5 5 5 5 4 5 5 1 4 2 5 5 5 4 5 2 1 5 1 3 2 4 2 2 2 2 2 3 5 5 5 5 1 3 1 5 5 5 5 5 3 0 0 0 3 4 5 4 5 4 4 5 3 2 0 2 2 2 2 4 1 1 1 4 4 4 3 4 3 3 3 4 4 4 5 5 3 5 5 1 5 4 3 1 1 4 2 2 3 2 4 2 5 5 2 3 2 4 2 1 2 4 2 5 5 0 2 5 2 3 5 4 2 4 5 5 0 4 4 0 0 0 0 0 4 1 3 3 3 5 3 3 3 3 1 1 2 5 5 3 5 2 2 4 4 4 3 2 5 4 2 4 3 5 5 4 4 5 2 2 2 2 5 2 2 3 3 2 4 2 2 5 5 2 5 2 2 2 2 2 3 2 2 4 4 5 5 3 5 2 3 2 2 2 2 2 2 5 5 1 1 1 1 1 4 4 3 3 5 5 4 3 1 3 4 1 4 4 4 1 5 4 2 2 0 0 0 0 4 5 5 3 2 2 3 3 3 1 2 4 5 5 5 5 0 0 0 3 3 3 4 4 4 5 4 4 4 4 4 4 4 4 4 4 3 3 1 1 3 4 3 4 5 5 5 5 3 3 3 5 0 0 0 4 4 5 1 1 1 3 3 3 3 3 2 2 2 2 2 4 4 4 4 5 1 4 1 4 3 5 3 3 4 5 5 1 1 4 4 1 2 4 3 4 4 1 1 4 2 5 0 0 0 0 4 3 3 3 2 1 5 2 2 2 2 1 1 2 1 1 3 4 4 5 2 2 1 4 4 5 4 3 4 5 5 3 5 5 5 5 5 1 0 3 3 3 3 1 3 2 5 4 4 4 4 4 4 4 4 4 4 4 4 2 5 5 2 5 4 3 4 2 2 2 4 2 3 3 2 4 3 2 3 3 2 3 2 2 1 1 4 1 1 1 1 1 1 3 3 1 3 3 5 2 4 4 4 4 4 4 3 3 3 5 5 0 0 2 2 2 2 3 5 5 5 5 0 2 3 2 2 2 2 2 3 3 3 3 3 3 3 3 3 1 3 3 5 1 5 3 3 1 3 3 3 3 3 3 3 5 4 5 5 5 3 3 3 3 3 3 3 1 5 3 5 3 3 3 3 3 3 3 3 3 3 1 3 3 5 3 3 3 5 3 1 3 0 3 4 2 1 1 2 3 3 1 2 4 5 1 5 3 5 3 5 1 4 4 3 5 5 5 5 5 4 1 1 3 5 1 4 1 1 4 1 2 2 2 3 3 3 3 1 1 1 1 1 1 5 4 2 2 4 5 1 1 5 1 1 1 5 5 1 1 1 1 1 1 1 5 5 5 1 5 1 1 5 5 1 1 1 1 1 1 1 1 5 1 1 1 5 5 5 1 1 1 1 5 1 1 1 1 5 1 4 3 4 5 2 4 3 1 0 1 1 1 0 4 0 4 4 4 3 5 3 5 5 5 5 5 5 5 5 5 3 5 5 5 5 3 5 5 5 5 3 5 1 1 1 1 1 2 2 2 5 5 4 5 4 5 4 4 4 4 5 4 4 4 3 1 5 1 1 1 1 4 1 5 1 5 5 5 5 5 2 5 5 5 4 5 5 5 5 2 4 5 5 5 5 5 5 2 5 5 4 5 5 4 4 1 3 4 4 5 5 5 4 5 5 1 4 4 4 4 1 1 2 4 5 5 1 3 3 4 4 3 5 4 1 1 1 4 5 3 0 3 4 1 1 1 1 5 5 3 3 4 5 3 5 5 5 3 1 3 1 1 1 3 2 5 1 5 5 5 3 3 1 5 1 1 1 3 2 1 1 1 3 5 1 1 4 5 5 4 4 5 5 4 5 1 3 1 1 5 4 1 5 1 5 1 1 1 5 5 5 1 5 5 1 1 1 1 1 5 1 1 3 2 1 1 3 5 5 3 1 1 1 1 1 5 3 1 1 1 1 1 4 1 1 1 3 5 1 4 1 5 5 5 4 5 1 1 1 5 1 1 1 5 1 1 1 1 3 5 4 4 1 3 1 4 5 4 4 5 3 5 1 1 4 5 3 4 1 5 5 1 3 1 2 3 3 0 0 1 2 1 5 3 5 4 5 3 5 3 4 5 3 1 5 5 5 5 4 5 3 3 5 3 5 5 2 0 0 3 5 5 5 5 3 5 3 2 2 1 1 1 3 0 5 2 2 2 2 2 3 3 4 1 2 5 2 5 5 5 2 4 3 4 5 5 1 2 0 2 2 2 3 2 4 5 3 3 3 3 3 4 4 3 2 4 4 4 4 4 1 2 2 4 4 1 0 3 4 4 3 5 4 3 1 4 4 1 1 1 1 1 4 4 5 4 4 1 1 1 4 4 4 4 3 3 3 3 5 5 4 3 2 2 5 1 1 3 1 1 4 4 4 4 3 2 2 2 1 1 1 4 3 3 2 1 5 4 4 5 5 5 5 3 3 5 0 0 0 0 1 0 5 1 5 0 0 5 5 0 5 5 4 0 3 5 3 4 5 3 2 3 4 3 5 2 3 2 3 5 5 5 3 2 2 4 3 3 3 0 3 1 1 2 1 4 3 5 5 5 5 5 5 5 4 3 3 4 3 1 0 2 4 5 1 1 4 4 4 4 2 3 5 3 5 5 2 3 3 2 4 3 1 3 1 5 1 1 1 4 4 4 4 1 4 4 4 1 1 1 4 5 4 4 4 3 4 5 5 4 4 5 4 4 3 2 2 0 0 4 4 4 5 5 1 3 3 3 1 3 3 5 1 4 0 1 4 5 2 4 4 4 4 0 4 4 1 3 2 4 5 3 3 2 4 2 2 0 2 5 4 1 5 5 5 3 3 1 5 5 5 4 4 1 3 3 4 4 4 4 4 2 2 3 1 5 5 5 5 3 3 3 3 1 3 3 5 2 1 2 2 1 1 2 1 4 1 4 4 4 4 5 2 4 1 1 1 1 1 1 1 1 1 1 1 1 1 1 5 1 1 1 1 1 4 1 5 1 1 5 5 1 1 5 5 5 1 1 1 1 1 2 2 2 1 2 4 4 1 4 3 1 4 0 1 1 1 1 4 4 3 5 5 2 5 3 3 5 0 4 5 4 1 4 4 5 2 3 1 2 2 1 5 5 5 3 0 0 1 1 1 2 2 4 2 3 3 3 5 5 5 5 4 4 4 4 1 2 4 5 5 2 2 3 3 3 3 2 4 2 3 3 5 1 3 5 5 2 1 1 1 1 5 1 5 5 1 4 1 5 5 1 2 1 1 1 5 1 3 1 5 5 5 5 4 1 1 1 1 1 1 4 4 0 0 1 3 5 4 2 4 1 1 4 5 4 5 5 3 3 5 5 1 1 4 3 4 2 2 2 3 2 1 1 1 1 5 3 5 3 3 3 3 5 4 4 4 0 0 2 4 5 2 3 1 5 4 5 5 3 1 5 3 0 2 1 3 1 1 1 1 3 5 5 5 3 3 1 3 3 3 2 1 3 2 2 4 4 0 4 1 1 3 3 5 5 5 4 4 2 4 1 4 5 1 1 5 4 5 1 4 4 4 4 1 1 5 5 4 4 4 1 3 1 3 3 4 3 3 4 5 0 2 4 2 3 3 1 4 4 4 4 5 4 4 5 5 4 4 2 2 3 3 2 2 0 3 3 3 1 3 5 5 5 0 0 0 2 5 2 5 1 5 5 3 4 1 1 1 1 4 4 4 0 4 4 1 1 1 1 1 1 1 1 4 5 0 4 0 2 4 4 4 4 4 4 2 4 0 3 5 5 5 5 3 4 5 2 4 0 4 4 4 5 4 4 4 4 1 5 5 1 5 2 3 3 5 4 4 4 4 4 5 3 4 4 1 5 5 5 2 5 3 2 3 3 1 1 3 3 3 1 5 2 1 2 3 1 3 5 3 3 2 3 3 3 3 2 5 2 2 5 2 4 3 3 5 3 1 2 2 3 2 2 1 3 3 2 3 2 5 3 2 3 5 1 3 3 2 2 2 1 3 3 1 2 3 3 4 2 2 5 3 3 5 3 2 5 3 5 4 2 3 2 4 5 3 3 5 5 3 2 2 2 3 2 3 2 2 4 5 2 2 5 5 2 2 3 2 1 2 2 5 1 4 5 4 3 4 4 4 3 3 3 5 4 5 4 4 4 1 3 5 5 2 5 3 2 3 3 3 5 5 4 4 4 4 2 3 4 4 4 3 0 3 1 3 5 4 2 4 1 4 4 5 5 1 5 5 5 3 3 3 5 2 2 4 1 1 1 1 1 2 1 4 4 4 1 1 5 5 3 4 4 5 2 2 1 1 4 5 2 1 2 2 5 3 5 5 5 5 5 3 3 5 5 5 5 5 5 5 5 3 2 2 5 2 4 1 1 2 2 5 5 2 4 3 2 5 3 3 3 3 3 3 3 3 3 3 3 3 3 4 1 2 1 3 3 3 3 3 3 3 3 3 3 3 4 3 3 3 3 0 3 3 3 3 3 3 3 3 3 3 3 3 1 5 4 2 4 4 4 5 5 5 1 1 5 3 3 5 3 3 3 3 3 1 3 3 4 4 5 2 4 4 4 4 4 4 1 4 2 5 2 2 2 5 5 2 2 2 3 2 2 3 1 4 5 3 5 2 1 4 1 3 3 5 3 5 0 5 1 1 4 1 5 5 5 1 1 1 5 5 5 4 5 5 5 5 4 5 3 2 2 1 4 1 5 4 0 5 2 5 5 1 4 1 4 1 3 3 5 2 2 4 2 2 4 5 5 4 4 4 5 4 3 4 1 4 4 4 1 4 1 4 4 1 5 5 3 5 1 2 2 5 2 2 2 2 3 1 0 0 4 5 0 0 0 5 0 5 3 5 3 3 3 2 2 4 3 3 3 2 3 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 5 5 3 5 1 3 4 2 2 2 2 4 3 4 5 4 4 4 4 4 5 3 3 2 0 0 5 1 1 1 3 2 3 3 3 3 3 2 3 3 3 3 5 5 4 4 4 4 1 3 3 0 4 1 1 1 1 5 5 5 5 3 5 2 5 5 2 2 5 5 2 2 2 2 3 3 5 5 5 1 2 2 5 5 5 3 5 5 2 2 3 2 5 1 2 1 1 3 4 4 4 5 3 5 5 5 5 5 3 3 1 3 1 1 3 1 1 1 1 3 3 3 3 3 1 1 3 3 1 3 1 3 1 3 3 4 5 5 0 3 5 2 5 2 4 0 3 2 5 0 5 5 2 0 3 1 3 1 4 3 3 5 4 5 4 3 1 5 1 2 1 3 1 4 5 1 1 1 1 3 3 1 1 4 2 1 2 3 4 1 2 4 2 2 2 1 1 2 1 2 1 4 3 5 3 5 3 3 5 5 3 1 3 5 3 0 3 3 3 5 5 3 5 5 3 1 1 1 1 3 5 3 3 1 3 3 1 3 1 1 1 3 3 3 5 3 1 3 3 3 3 3 1 3 3 3 5 3 1 3 5 3 3 3 3 1 1 1 1 1 5 3 3 1 3 1 1 1 3 1 3 3 5 5 3 3 3 3 3 0 3 5 3 3 1 3 3 1 5 3 0 1 1 3 3 5 3 3 5 5 3 3 3 3 1 3 3 3 1 0 3 3 5 1 1 1 1 3 1 0 1 3 3 3 3 1 1 3 5 3 3 3 3 1 3 3 5 1 1 3 5 1 3 5 1 3 1 1 3 3 3 3 5 3 3 1 3 3 1 1 3 1 3 3 3 4 4 1 4 1 1 1 1 0 2 2 2 5 4 5 5 5 5 5 5 1 1 1 5 5 5 1 1 5 0 0 0 4 5 1 0 0 5 5 5 4 0 5 4 1 2 2 3 5 3 3 3 3 3 3 3 3 3 1 3 3 3 3 3 3 3 3 3 3 5 1 3 0 5 5 5 4 4 4 4 2 0 2 2 2 5 5 5 3 1 2 5 1 5 5 3 3 5 5 5 5 5 1 5 5 5 5 5 3 5 5 3 1 3 5 5 5 2 3 5 5 3 3 3 5 5 0 0 3 4 4 4 3 5 0 1 5 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 2 0 2 2 2 2 2 2 5 1 4 4 1 1 0 0 2 0 1 0 1 1 1 5 1 1 1 5 1 1 5 0 4 1 4 4 2 2 1 1 2 2 1 1 5 5 3 2 2 2 2 3 2 3 4 4 4 3 2 2 2 5 5 5 1 4 3 3 4 0 3 1 3 1 3 3 3 3 3 3 3 1 1 1 3 1 0 3 3 1 3 3 1 3 3 3 1 0 3 1 1 3 1 3 1 5 3 3 3 0 3 1 0 3 0 3 3 2 3 3 1 3 3 1 3 3 0 3 3 3 1 3 3 3 3 3 0 0 0 3 1 1 5 2 5 2 5 5 5 1 1 1 1 5 0 1 1 4 2 1 5 4 4 4 1 4 5 5 5 1 3 2 2 3 3 4 5 4 5 1 1 1 1 1 0 0 4 5 2 3 3 4 3 0 0 0 0 3 4 1 1 1 1 2 2 2 5 2 5 2 0 0 2 0 5 2 1 0 1 2 2 3 1 3 4 2 2 4 4 4 3 5 5 3 4 4 1 5 3 4 1 5 4 3 3 1 4 2 3 3 2 5 2 2 2 3 3 3 0 2 2 2 4 3 3 0 3 4 4 3 5 3 0 1 1 4 4 4 1 4 4 3 3 1 3 3 4 0 0 0 5 5 5 2 0 2 2 2 1 2 2 2 5 0 3 4 2 0 3 3 3 3 3 3 3 4 4 4 2 4 4 4 4 2 2 5 3 3 3 3 3 4 4 2 2 2 5 2 0 2 4 2 4 2 1 2 3 2 5 2 2 2 2 1 1 1 5 1 1 1 1 1 1 1 1 1 1 1 1 4 1 1 1 5 1 1 5 5 0 4 5 5 5 3 1 5 5 5 5 4 4 5 4 5 0 4 1 1 1 2 2 3 2 2 3 3 3 2 2 5 2 2 2 2 3 2 2 3 2 3 2 2 2 2 2 2 2 3 3 2 4 3 2 3 5 3 3 3 1 3 3 5 2 3 2 5 2 2 5 2 2 2 4 5 4 5 2 3 5 3 3 4 2 2 4 2 4 2 2 3 3 4 5 5 5 3 4 2 1 1 1 4 4 4 3 4 4 4 4 1 4 4 1 3 1 3 3 3 5 0 0 5 4 4 0 4 0 2 3 4 1 2 2 5 2 2 2 3 5 1 3 3 3 3 1 2 1 1 1 1 1 4 1 1 1 1 1 1 4 2 2 1 1 3 3 3 3 5 3 0 4 5 5 5 0 5 2 2 3 1 3 3 3 1 2 5 5 5 5 3 1 5 0 3 3 3 3 3 3 3 0 3 5 5 0 0 3 2 5 5 2 0 3 2 2 2 3 5 5 2 2 1 1 2 3 4 1 5 1 4 3 1 2 5 2 4 1 1 4 4 4 2 1 1 1 2 1 1 3 1 1 3 1 2 4 2 2 2 4 4 3 4 2 5 2 2 1 2 1 1 1 0 4 4 4 4 3 3 5 5 3 5 1 5 5 1 5 4 3 4 5 4 3 5 4 5 1 3 1 1 5 5 5 5 3 5 3 5 5 5 1 3 5 2 1 1 3 5 5 5 5 4 5 5 5 5 5 5 0 2 0 5 5 1 3 3 3 1 0 5 4 3 1 4 1 3 4 0 2 1 1 3 3 4 3 3 3 3 1 4 3 2 1 4 2 5 0 0 3 1 3 1 1 3 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3 3 2 3 3 2 3 3 3 3 2 3 0 3 3 3 0 2 3 4 3 3 3 3 3 3 3 3 3 3 3 3 3 1 3 0 3 3 3 3 3 3 3 1 0 2 2 1 2 2 2 2 3 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 1 2 2 2 2 0 5 4 2 2 2 2 2 2 4 4 2 2 2 3 2 2 3 0 2 2 0 4 3 0 3 3 3 3 4 5 3 3 2 4 0 1 5 3 5 3 4 2 4 2 5 3 1 4 1 5 2 2 5 4 3 1 1 1 1 1 2 1 1 3 0 5 5 2 2 2 0 2 3 1 1 2 3 5 3 3 3 1 1 5 1 3 5 3 5 3 3 3 5 5 3 3 3 1 1 3 3 3 5 5 5 3 3 1 5 0 3 5 3 5 3 1 1 3 1 3 1 3 5 1 5 0 3 1 3 5 3 3 3 5 5 1 3 3 3 3 5 3 3 3 3 1 1 1 5 3 5 3 3 1 1 0 3 3 3 5 3 3 1 0 3 1 3 5 5 3 3 3 5 3 5 3 5 5 5 1 3 5 3 5 1 1 5 5 5 5 3 3 5 3 3 1 5 5 3 3 3 3 3 5 5 5 1 3 1 3 1 1 5 5 3 3 3 1 4 1 3 1 3 1 3 1 3 3 3 1 1 3 3 1 1 1 1 1 1 3 1 3 1 1 1 1 3 1 1 1 1 3 1 1 1 1 1 3 5 3 1 1 1 1 1 3 3 3 1 5 3 3 3 3 3 1 3 3 3 3 1 3 3 3 5 3 3 3 1 1 3 3 1 3 3 1 3 3 3 3 3 3 3 3 3 3 5 3 1 3 3 3 3 3 1 1 1 3 3 3 1 3 3 5 3 3 3 3 3 3 3 1 3 3 3 3 3 1 3 3 5 3 3 1 5 3 3 3 3 3 3 3 1 0 3 3 3 3 3 3 3 3 3 3 3 3 1 3 3 3 3 3 1 1 3 3 1 1 3 5 2 1 1 5 4 3 3 5 3 5 3 3 0 4 1 3 5 2 1 4 5 1 3 4 5 5 1 5 5 5 5 3 3 5 2 2 1 1 1 1 1 5 3 1 4 2 1 4 5 4 5 1 5 5 3 5 4 1 1 4 4 3 3 4"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 4 5 5 2 0 2 1 4 1 4 4 4 4 4 4 4 5 2 3 5 3 5 5 3 5 3 5 5 3 5 5 5 5 5 5 5 5 5 5 3 5 5 5 3 5 5 1 5 5 5 5 5 5 2 2 5 5 1 4 4 3 3 1 3 1 4 4 4 2 5 4 1 1 4 5 5 0 5 5 3 0 2 1 4 2 3 3 1 1 5 2 5 3 2 2 5 5 4 4 2 3 2 2 2 2 2 2 2 2 3 3 3 2 3 3 2 3 2 3 4 2 2 2 2 2 2 3 2 2 2 2 2 2 3 3 3 1 1 1 2 2 4 2 3 5 5 1 5 3 3 4 3 1 3 4 4 3 3 1 5 1 1 5 3 1 5 3 4 1 5 5 1 1 3 1 1 1 4 4 5 5 4 4 4 5 4 4 5 1 4 2 5 0 3 4 0 4 4 4 2 4 2 2 3 3 3 3 3 3 5 3 4 3 3 1 1 5 3 3 3 3 5 3 3 3 3 3 1 3 1 1 3 1 3 3 5 3 1 1 1 3 5 1 1 3 3 1 1 1 4 5 5 5 5 5 5 1 1 0 1 0 0 1 1 1 1 0 1 0 0 0 2 1 1 1 0 0 1 0 0 1 1 1 0 1 1 2 1 0 0 1 1 5 1 4 1 4 3 3 3 3 4 1 3 3 3 3 3 1 4 3 4 3 1 3 5 2 5 5 5 5 5 5 5 5 1 4 1 1 3 3 3 3 3 5 3 3 3 3 2 5 5 1 3 0 5 5 5 2 4 0 0 0 1 1 3 3 4 4 4 1 5 4 3 4 1 1 5 1 1 1 1 1 1 1 1 1 5 5 1 1 1 1 1 1 5 1 1 1 1 5 1 1 5 5 1 1 1 1 5 1 1 1 1 1 1 1 5 5 1 1 1 1 1 5 1 4 3 5 2 3 3 5 4 4 3 3 4 4 4 3 3 4 4 2 4 2 1 1 4 4 2 4 2 2 2 4 4 1 1 2 1 4 5 3 3 0 2 4 3 4 3 1 2 2 4 2 4 3 2 3 4 3 3 4 3 1 1 3 3 1 1 1 1 1 1 1 3 1 1 4 4 3 3 3 1 1 1 4 1 1 1 3 3 1 4 1 3 1 1 3 4 4 1 3 3 4 3 3 1 4 4 1 1 4 4 1 1 3 4 3 3 4 1 1 1 4 3 1 3 4 3 4 3 1 1 4 4 3 4 1 4 4 4 5 3 1 1 3 4 4 3 3 1 1 4 1 4 4 1 1 1 1 3 4 4 3 1 4 3 4 4 1 4 3 4 3 4 1 3 4 1 4 3 4 4 1 1 3 4 1 4 4 4 4 4 1 1 4 3 4 3 3 3 3 3 3 3 0 3 0 1 1 5 1 1 1 5 3 4 5 5 5 4 2 5 5 5 3 3 5 4 2 1 4 3 4 4 3 3 1 3 3 3 3 3 3 3 3 3 5 5 2 2 2 0 3 3 3 3 5 5 3 2 2 2 2 2 4 4 2 0 2 2 2 2 4 4 4 5 4 4 5 5 5 5 5 4 5 4 5 5 5 1 5 4 5 5 5 5 5 5 1 1 2 2 1 3 3 3 5 5 5 5 5 5 5 5 5 1 5 5 5 5 5 5 5 5 5 5 5 5 4 4 3 2 2 3 3 5 3 4 5 3 3 1 1 2 2 2 3 3 3 5 5 1 1 5 0 0 3 1 4 1 5 0 3 3 4 4 4 4 4 0 0 3 3 3 5 0 0 1 0 0 0 0 1 1 0 1 3 0 2 0 1 1 0 2 2 5 4 5 3 3 3 4 4 4 4 1 4 4 1 5 2 5 1 3 5 5 2 4 5 2 1 2 2 2 2 4 3 1 1 4 2 4 3 4 3 3 4 3 3 4 4 4 4 0 5 4 4 3 4 3 2 5 5 5 5 4 4 4 5 1 1 3 3 5 0 0 3 2 2 3 3 3 4 1 5 3 3 5 4 4 3 3 3 3 3 3 0 5 5 4 5 1 4 4 2 2 4 5 4 4 4 4 1 1 1 4 1 2 2 1 3 1 5 3 4 1 1 1 1 1 1 3 2 1 4 1 4 3 1 1 5 1 1 3 1 4 5 3 1 1 1 5 5 5 1 5 4 4 1 1 1 2 4 3 3 3 3 3 3 3 3 3 1 3 3 4 4 5 3 3 4 1 3 4 2 1 1 1 4 3 3 3 3 3 4 1 2 1 2 2 2 2 3 2 2 2 1 2 2 1 2 2 2 3 3 2 2 2 2 2 2 2 4 2 2 2 2 4 2 1 2 2 1 2 2 3 2 3 2 5 1 2 1 2 2 2 2 2 2 2 2 3 2 1 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 1 2 3 2 2 2 2 3 2 1 2 2 5 3 2 3 3 3 0 5 1 2 3 3 3 4 3 3 4 3 3 3 3 3 3 3 3 3 3 3 1 2 5 2 2 2 1 1 1 3 1 3 0 5 2 1 2 5 2 2 5 2 2 2 2 2 2 2 2 2 2 2 2 2 2 5 2 2 2 2 5 5 5 2 1 5 2 2 4 4 4 1 4 4 4 2 3 4 1 4 5 5 3 1 3 1 3 5 2 2 2 1 1 4 2 2 2 4 3 3 1 1 1 0 4 2 2 4 3 4 4 4 4 2 4 4 4 1 5 5 1 3 3 3 4 3 4 3 3 3 3 3 3 3 3 3 3 5 4 4 3 3 3 3 3 3 3 0 3 5 3 3 3 3 3 3 3 3 3 3 5 5 4 4 4 4 5 2 5 3 4 4 1 4 4 1 4 4 4 1 1 4 1 4 4 4 4 4 4 4 4 4 5 4 2 5 2 4 3 5 5 5 4 3 5 3 4 3 3 3 3 3 3 3 3 3 3 3 3 3 1 3 0 3 4 3 4 3 4 3 1 4 2 4 4 3 3 4 5 5 5 1 2 4 2 2 1 1 1 2 1 2 1 2 5 2 2 3 3 5 2 5 5 5 5 5 5 3 4 4 4 4 1 1 5 5 4 1 0 3 1 1 1 3 1 2 1 1 1 4 1 2 1 1 1 1 1 4 1 1 1 2 1 2 1 4 3 1 5 1 1 1 3 3 4 3 3 3 3 3 4 4 3 4 4 1 4 2 1 4 1 1 4 1 1 4 2 3 3 1 0 1 1 3 3 1 5 2 2 2 3 2 3 3 2 2 1 2 3 0 1 1 0 0 0 4 0 0 5 4 0 0 4 2 2 2 2 1 4 4 4 3 3 2 4 0 4 1 2 2 2 2 2 2 2 2 2 1 2 2 2 3 4 2 2 2 2 1 5 4 5 4 4 2 4 4 5 5 5 1 5 4 5 3 4 3 4 2 3 2 0 4 1 3 1 4 4 4 0 1 4 4 4 0 0 3 3 3 5 2 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 5 3 0 5 5 4 4 5 1 3 3 3 3 3 3 3 1 3 3 0 0 3 1 1 1 5 3 5 5 3 3 2 3 2 2 2 0 4 0 2 2 2 2 2 2 1 4 3 4 4 4 3 4 4 3 4 4 3 4 3 4 4 3 3 4 0 3 3 1 1 5 3 3 4 0 0 5 5 0 1 4 4 1 3 3 3 1 4 4 4 4 3 4 1 4 4 4 2 4 1 2 1 3 2 3 4 3 3 2 3 1 1 3 1 5 4 5 0 2 4 2 3 4 2 1 4 2 2 2 2 5 5 0 0 0 0 0 0 1 5 5 5 2 5 5 3 1 3 3 3 4 1 5 5 5 0 4 4 4 3 4 Correct: 5310 out of: 10099\n",
      "Accuracy of the network :  52.57946331319933\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "countCorrect0=0\n",
    "countCorrect1=0\n",
    "count0=0\n",
    "count1=0\n",
    "labels=pd.read_excel('train-clean-Reputation.xlsx' )\n",
    "\n",
    "Y=[]  #target\n",
    "Pred=[]  #predicted\n",
    "\n",
    "with torch.no_grad():\n",
    "    for row in range(len(input)):\n",
    "        outputs = net(input[row,:].float())\n",
    "        result=0\n",
    "        total+=1\n",
    "        if outputs[0]<outputs[1]:result=1\n",
    "        if outputs[result]<outputs[2]:result=2\n",
    "        if outputs[result]<outputs[3]:result=3\n",
    "        if outputs[result]<outputs[4]:result=4\n",
    "        if outputs[result]<outputs[5]:result=5\n",
    "        \n",
    "        if TrainLables.iloc[row,result]==1: correct+=1\n",
    "        \n",
    "        Y.append(labels.iloc[row])\n",
    "        Pred.append(result)\n",
    "        \n",
    "        print(result, end=' ')\n",
    "        \n",
    "    \n",
    "print('Correct:', correct, 'out of:', total )\n",
    "print('Accuracy of the network : ',( 100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0227, -0.4304, -0.8096],\n",
       "        [ 0.0050,  0.0000,  0.0100,  ...,  0.6821, -0.2678, -0.8721],\n",
       "        [ 0.0000,  0.0000,  0.0050,  ...,  0.2155, -0.6494, -0.8389],\n",
       "        ...,\n",
       "        [ 0.0000,  0.0000,  0.0150,  ...,  0.5742,  0.6602,  0.7427],\n",
       "        [ 0.0000,  0.0000,  0.0000,  ...,  0.3728,  0.5864,  0.4331],\n",
       "        [ 0.0000,  0.0000,  0.0000,  ...,  0.4082,  0.6440,  0.5386]],\n",
       "       dtype=torch.float64)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the validation data\n",
    "\n",
    "ValidData=pd.read_excel('valid-clean-Reputation.xlsx' )\n",
    "ValidData=ValidData.iloc[:,:-1].astype(float)\n",
    "ValidData=ValidData/200\n",
    "\n",
    "SavesDirectory='./TunedModels/'+model_class+'/'+model_version+\"/Saves/\"\n",
    "TF_Output=pd.read_csv( SavesDirectory+'evalOut.tsv', sep='\\t')\n",
    "\n",
    "ValidData=pd.concat([ValidData,TF_Output], axis=1)\n",
    "\n",
    "\n",
    "ValidData=torch.tensor(ValidData.values)\n",
    "ValidData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1267</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1268</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1269</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1270</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1271</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1272 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0  1  2  3  4  5\n",
       "0     0  0  0  1  0  0\n",
       "1     0  0  1  0  0  0\n",
       "2     0  0  0  1  0  0\n",
       "3     0  0  0  0  1  0\n",
       "4     0  0  0  0  0  1\n",
       "...  .. .. .. .. .. ..\n",
       "1267  0  0  0  0  0  1\n",
       "1268  0  0  0  1  0  0\n",
       "1269  0  0  1  0  0  0\n",
       "1270  0  0  0  0  1  0\n",
       "1271  0  0  0  1  0  0\n",
       "\n",
       "[1272 rows x 6 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels=pd.read_excel('valid-clean-Reputation.xlsx' )\n",
    "\n",
    "labels=labels.iloc[:,-1] \n",
    "labelsOneHot=pd.get_dummies(labels)\n",
    "labelsOneHot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0, 0, 1, 0, 0],\n",
       "        [0, 0, 1, 0, 0, 0],\n",
       "        [0, 0, 0, 1, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 1, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 1, 0],\n",
       "        [0, 0, 0, 1, 0, 0]], dtype=torch.uint8)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ValidLables =torch.tensor(labelsOneHot.values)\n",
    "ValidLables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 2 3 2 5 1 5 4 5 2 3 5 1 1 2 4 2 2 2 1 1 0 1 2 4 2 1 1 0 5 4 2 3 0 1 3 3 3 3 3 5 4 3 1 3 3 5 3 5 3 4 5 5 1 5 5 5 3 3 5 5 5 4 5 5 4 5 3 3 4 3 3 5 5 5 4 4 1 3 3 4 5 3 3 3 3 3 3 3 1 3 5 3 3 4 4 4 4 1 3 3 5 1 3 4 3 3 2 1 3 1 1 2 4 4 4 4 1 4 2 2 4 2 2 1 5 4 1 1 3 4 5 4 3 3 5 3 2 3 4 3 1 1 1 3 4 2 4 5 0 0 0 0 0 0 0 0 0 0 0 0 1 5 5 1 5 2 3 3 1 5 1 5 4 5 5 1 4 4 5 5 5 3 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 3 2 3 1 1 4 4 5 5 3 2 2 2 3 3 2 3 3 5 0 1 1 2 3 4 3 3 3 5 5 1 3 5 5 3 5 3 3 5 5 3 4 4 2 1 5 4 1 4 3 4 4 3 3 1 1 4 5 3 1 1 4 4 2 1 2 2 2 3 2 2 4 5 4 1 2 0 4 2 4 1 4 4 4 0 2 0 4 5 2 0 0 3 3 3 0 3 3 3 2 1 2 4 4 4 4 1 1 3 2 4 1 4 1 1 4 4 5 1 2 0 2 3 3 3 3 3 5 5 5 4 3 2 4 4 2 5 3 1 1 1 1 1 1 1 3 1 1 1 3 1 1 1 1 1 1 1 1 1 1 1 3 3 1 1 3 1 3 4 3 3 1 1 3 1 1 4 4 4 2 0 4 5 4 1 5 3 4 5 3 2 2 2 4 2 2 5 5 1 2 5 2 1 3 0 4 2 4 3 3 1 3 3 0 3 0 0 0 0 5 3 4 2 2 2 1 2 2 2 5 3 5 1 2 5 1 3 1 4 3 2 3 2 5 2 2 3 4 4 5 5 4 1 1 3 3 2 2 2 5 5 1 4 3 5 5 5 0 4 3 4 0 5 2 2 2 2 1 1 4 3 1 5 3 3 0 1 4 4 3 5 1 1 1 3 5 3 5 3 5 3 3 3 5 5 5 5 5 3 5 5 5 5 3 3 5 5 5 5 3 3 2 3 5 0 1 5 3 3 3 3 3 1 3 4 1 5 3 5 2 4 4 5 4 1 2 4 0 4 5 2 4 4 2 2 3 5 1 1 2 4 3 3 1 2 0 1 3 4 3 1 5 4 3 3 5 3 4 1 5 5 2 4 2 2 4 3 4 4 0 0 3 3 3 5 2 4 4 4 2 3 4 1 4 4 1 1 1 1 1 1 5 5 5 5 5 5 5 4 4 1 4 3 4 5 5 4 5 4 4 5 5 5 5 0 1 4 4 3 5 1 5 5 5 1 4 4 5 1 5 5 5 1 1 1 1 5 2 5 4 5 5 1 1 4 3 0 2 2 4 3 4 2 3 4 3 1 2 4 0 5 2 1 1 1 2 4 4 4 4 4 4 4 2 1 2 4 0 2 3 4 4 1 5 5 1 1 2 1 3 5 2 4 5 5 5 4 3 1 1 1 1 1 4 1 4 1 1 1 1 2 4 4 3 1 1 5 1 5 4 4 0 3 4 3 5 1 4 4 3 1 4 1 4 5 3 5 5 4 2 2 3 1 2 3 3 3 2 3 1 2 5 3 5 4 1 2 1 2 2 3 3 4 3 1 4 4 3 1 3 1 2 1 5 2 1 3 3 3 1 3 3 4 5 4 5 0 1 3 5 3 5 5 2 2 5 5 4 1 1 1 4 4 2 3 2 0 5 3 1 1 1 1 1 1 1 1 2 3 3 1 5 5 5 5 1 1 3 3 3 1 3 3 0 3 3 1 2 3 1 5 5 5 1 3 1 3 3 1 1 3 3 3 3 1 3 5 2 1 2 3 0 3 3 3 1 1 5 5 1 3 5 5 3 2 2 2 2 0 0 3 1 1 2 0 1 3 1 0 1 1 0 3 5 3 4 0 4 1 4 0 1 1 3 5 5 2 4 3 2 4 4 1 3 3 3 2 1 2 2 4 2 5 2 4 2 3 5 5 2 2 2 2 3 5 2 5 0 5 4 3 3 1 5 4 2 4 0 1 2 1 2 5 1 5 5 3 5 5 5 5 5 3 3 5 4 1 4 3 3 3 3 3 3 3 1 2 2 2 2 2 4 3 4 5 3 1 5 1 0 3 5 5 1 3 5 1 3 0 3 3 3 5 5 1 3 5 1 1 3 5 1 3 3 3 3 3 3 5 3 1 3 2 5 4 3 1 3 3 5 5 5 5 5 5 5 5 1 3 5 1 2 5 0 3 2 2 2 2 2 2 4 5 1 5 3 3 3 2 3 1 3 1 1 1 4 1 1 3 3 1 3 1 3 5 5 1 0 4 1 1 1 1 1 5 5 1 5 5 3 3 3 1 1 1 1 3 3 4 4 4 3 1 4 3 1 3 3 5 5 1 2 4 5 5 1 5 5 5 5 1 2 3 1 4 2 1 4 4 3 3 3 5 3 4 1 1 5 5 1 3 1 3 3 3 3 2 2 2 2 2 2 1 1 2 2 2 3 4 1 0 2 4 1 2 1 2 5 2 5 2 5 1 4 2 3 3 3 3 3 3 4 1 1 3 3 4 3 4 3 1 0 0 2 3 3 5 0 1 1 2 1 2 1 3 5 2 0 0 4 4 2 2 3 4 5 5 4 4 3 1 1 0 0 0 4 3 1 1 3 3 2 2 0 4 4 4 4 4 5 3 4 4 3 Correct: 627 out of: 1272\n",
      "Accuracy of the network :  49.29245283018868\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "countCorrect0=0\n",
    "countCorrect1=0\n",
    "count0=0\n",
    "count1=0\n",
    "\n",
    "Y=[]  #target\n",
    "Pred=[]  #predicted\n",
    "\n",
    "with torch.no_grad():\n",
    "    for row in range(len(ValidData)):\n",
    "        outputs = net(ValidData[row,:].float())\n",
    "        result=0\n",
    "        total+=1\n",
    "        if outputs[0]<outputs[1]:result=1\n",
    "        if outputs[result]<outputs[2]:result=2\n",
    "        if outputs[result]<outputs[3]:result=3\n",
    "        if outputs[result]<outputs[4]:result=4\n",
    "        if outputs[result]<outputs[5]:result=5\n",
    "        \n",
    "        if labelsOneHot.iloc[row,result]==1: correct+=1\n",
    "        \n",
    "        Y.append(labels.iloc[row])\n",
    "        Pred.append(result)\n",
    "        \n",
    "        print(result, end=' ')\n",
    "        \n",
    "    \n",
    "print('Correct:', correct, 'out of:', total )\n",
    "print('Accuracy of the network : ',( 100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0000,  0.0050,  0.0100,  ..., -0.2830, -0.7202, -0.7490],\n",
       "        [ 0.0000,  0.0050,  0.0100,  ...,  0.9106,  0.5190, -0.1346],\n",
       "        [ 0.0000,  0.0050,  0.0100,  ..., -0.1864, -0.5518, -0.2109],\n",
       "        ...,\n",
       "        [ 0.0000,  0.0000,  0.0050,  ...,  0.4900, -0.1476, -0.6836],\n",
       "        [ 0.0050,  0.0000,  0.0000,  ...,  0.4495,  0.2683, -0.0373],\n",
       "        [ 0.0000,  0.0000,  0.0000,  ...,  0.2419,  0.0121, -0.2137]],\n",
       "       dtype=torch.float64)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the test data\n",
    "\n",
    "TestData=pd.read_excel('test-clean-Reputation.xlsx' )\n",
    "TestData=TestData.iloc[:,:-1].astype(float)\n",
    "TestData=TestData/200\n",
    "\n",
    "SavesDirectory='./TunedModels/'+model_class+'/'+model_version+\"/Saves/\"\n",
    "TF_Output=pd.read_csv( SavesDirectory+'testOut.tsv', sep='\\t')\n",
    "\n",
    "TestData=pd.concat([TestData,TF_Output], axis=1)\n",
    "\n",
    "\n",
    "TestData=torch.tensor(TestData.values)\n",
    "TestData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0, 0, 0, 1, 0],\n",
       "        [0, 0, 0, 0, 1, 0],\n",
       "        [0, 0, 1, 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 1, 0, 0, 0],\n",
       "        [1, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 1, 0, 0]], dtype=torch.uint8)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels=pd.read_excel('test-clean-Reputation.xlsx' )\n",
    "\n",
    "labels=labels.iloc[:,-1] \n",
    "labelsOneHot=pd.get_dummies(labels)\n",
    "labelsOneHot\n",
    "\n",
    "TestLables =torch.tensor(labelsOneHot.values)\n",
    "TestLables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 3 3 2 3 5 4 4 2 3 5 5 5 3 3 1 1 1 1 1 1 1 4 2 2 2 1 3 2 2 3 1 1 2 1 2 2 3 3 2 3 3 1 0 4 2 1 3 3 1 3 4 1 5 0 2 5 4 5 5 3 5 5 3 5 4 5 3 5 5 5 5 3 3 5 3 3 5 3 5 3 5 3 5 5 3 3 3 4 3 4 3 3 4 3 3 3 5 3 3 3 3 5 4 4 4 3 3 4 4 4 4 4 4 4 3 3 3 5 4 3 3 1 5 1 4 4 4 4 2 2 4 4 4 3 3 3 2 2 3 0 2 3 3 1 1 4 4 4 4 4 5 5 3 5 4 3 3 0 0 0 0 0 0 0 0 0 3 4 3 3 5 3 5 5 1 5 2 5 3 5 3 0 3 1 0 5 2 1 1 3 1 0 4 4 3 1 5 5 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 4 0 3 3 5 3 3 5 2 5 3 5 1 4 1 3 3 3 1 5 3 3 3 3 3 5 3 3 3 4 4 4 4 2 4 1 1 5 0 0 4 3 3 5 5 1 5 1 3 4 3 2 2 0 4 4 2 2 2 0 4 1 4 4 2 3 4 1 1 4 1 1 4 2 3 5 3 3 3 3 1 2 4 2 4 0 5 5 2 1 5 3 1 4 3 3 0 2 2 2 0 2 2 3 3 3 3 3 3 3 3 2 3 5 5 5 1 1 4 2 4 1 4 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 3 3 1 1 1 1 1 1 3 1 1 1 1 1 1 1 1 1 4 4 4 4 1 4 3 2 1 2 2 5 2 2 3 4 1 1 3 5 3 2 2 4 2 1 1 2 1 3 3 3 4 3 3 2 4 1 3 3 0 3 0 3 0 3 0 3 0 0 3 5 3 4 2 1 2 1 2 5 1 3 2 3 2 5 2 2 4 4 5 1 5 4 4 3 1 5 2 5 5 5 3 1 2 3 3 4 5 4 3 0 3 3 3 0 0 1 4 4 5 3 2 1 3 5 5 2 0 5 3 2 5 5 2 3 3 5 3 3 2 4 1 5 4 1 1 4 5 5 5 5 5 5 5 3 5 3 3 3 5 5 5 5 5 5 3 5 5 5 3 3 3 3 3 5 5 3 3 3 3 2 4 4 4 4 5 5 1 5 4 1 2 5 5 5 5 4 1 2 4 5 5 4 4 3 3 5 4 3 3 4 3 2 2 3 5 1 4 4 2 1 3 4 1 0 1 4 4 3 3 2 3 1 1 5 1 4 5 5 5 5 4 1 1 3 3 5 3 3 1 3 3 5 1 3 5 1 1 1 5 1 1 1 1 1 1 1 1 5 3 1 5 5 5 2 4 5 5 5 5 5 4 1 4 4 4 4 5 3 4 3 3 3 2 3 4 5 5 1 5 3 5 3 1 1 5 3 1 3 3 1 1 1 4 2 3 5 5 5 5 3 5 5 2 2 2 5 3 0 1 0 5 4 0 3 5 5 4 3 4 4 3 5 1 4 0 2 5 1 4 5 2 3 1 3 4 4 2 5 1 1 1 4 4 4 4 3 5 4 4 4 5 3 1 1 5 4 1 4 4 5 1 1 3 5 2 5 3 3 1 5 4 4 3 4 5 4 5 4 5 0 2 4 1 5 0 4 4 1 5 4 3 5 2 3 2 5 1 5 2 3 1 5 5 4 4 3 2 0 3 4 5 3 1 1 4 4 5 5 1 5 5 2 3 3 2 3 3 3 3 3 5 0 4 1 5 2 2 4 3 2 1 3 5 4 4 1 2 5 1 4 2 1 1 1 1 1 1 1 1 2 5 1 1 0 2 0 4 1 2 1 1 3 1 3 3 4 4 1 4 2 3 5 3 1 3 1 3 1 1 3 3 3 3 1 3 3 3 2 2 4 3 4 2 5 5 5 1 2 2 2 2 2 0 1 1 0 1 2 2 3 4 3 3 3 1 5 3 3 5 4 5 4 0 0 0 0 4 2 4 1 3 2 3 4 1 5 4 4 1 3 2 4 5 1 4 2 3 3 3 5 2 2 5 5 3 2 4 4 3 0 5 3 1 1 1 1 0 3 0 3 2 2 2 4 4 3 2 5 1 5 4 4 5 1 1 1 0 1 1 1 1 1 1 2 4 0 3 0 3 3 2 2 2 2 0 3 5 4 5 3 3 1 1 3 1 5 3 3 5 3 1 3 0 1 3 3 5 3 1 1 3 3 1 1 1 3 2 1 1 3 1 3 3 3 3 3 3 3 1 1 3 1 3 3 3 3 1 3 4 3 4 1 4 5 1 4 4 2 5 5 3 5 3 1 4 3 2 3 3 5 3 5 5 2 3 3 1 5 1 1 4 1 1 0 3 3 3 1 1 4 3 5 3 4 3 5 1 1 1 1 1 1 2 1 2 0 4 1 1 1 1 1 3 4 3 4 3 5 3 1 1 4 1 3 3 3 0 1 1 5 5 1 2 2 4 5 5 0 5 3 5 5 5 5 3 2 3 3 1 5 0 0 1 2 1 4 1 1 2 1 1 0 3 1 1 4 2 3 3 5 5 5 3 3 4 1 2 2 1 2 2 2 1 2 1 2 2 2 2 2 2 3 1 1 2 2 4 2 4 2 4 1 3 3 5 3 3 3 5 4 4 1 4 4 1 1 1 1 5 3 1 1 1 1 5 4 3 1 2 0 4 3 4 2 3 4 1 0 2 0 0 0 2 0 2 2 5 2 1 1 4 4 3 4 3 1 1 1 5 2 3 3 Correct: 620 out of: 1255\n",
      "Accuracy of the network :  49.40239043824701\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "\n",
    "Y=[]  #target\n",
    "Pred=[]  #predicted\n",
    "\n",
    "with torch.no_grad():\n",
    "    for row in range(len(TestData)):\n",
    "        outputs = net(TestData[row,:].float())\n",
    "        result=0\n",
    "        total+=1\n",
    "        if outputs[0]<outputs[1]:result=1\n",
    "        if outputs[result]<outputs[2]:result=2\n",
    "        if outputs[result]<outputs[3]:result=3\n",
    "        if outputs[result]<outputs[4]:result=4\n",
    "        if outputs[result]<outputs[5]:result=5\n",
    "        \n",
    "        if labelsOneHot.iloc[row,result]==1: correct+=1\n",
    "        \n",
    "        Y.append(labels.iloc[row])\n",
    "        Pred.append(result)\n",
    "        \n",
    "        print(result, end=' ')\n",
    "        \n",
    "    \n",
    "print('Correct:', correct, 'out of:', total )\n",
    "print('Accuracy of the network : ',( 100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 54  19   3  11   2   2]\n",
      " [ 14 134  25  27  16  17]\n",
      " [ 12  35  82  58  14  20]\n",
      " [  2  31  16 137  31  38]\n",
      " [  0  26  22  58 106  37]\n",
      " [  3  26  12  27  31 107]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics \n",
    "print(metrics.confusion_matrix(Y,Pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Pants       0.64      0.59      0.61        91\n",
      "       False       0.49      0.58      0.53       233\n",
      " Barely-True       0.51      0.37      0.43       221\n",
      "   Half-True       0.43      0.54      0.48       255\n",
      " Mostly-True       0.53      0.43      0.47       249\n",
      "        True       0.48      0.52      0.50       206\n",
      "\n",
      "    accuracy                           0.49      1255\n",
      "   macro avg       0.51      0.50      0.50      1255\n",
      "weighted avg       0.50      0.49      0.49      1255\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "target_names = ['Pants', 'False', 'Barely-True','Half-True','Mostly-True','True']\n",
    "\n",
    "print(metrics.classification_report(Y, Pred,target_names =target_names))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the FCNN model\n",
    "\n",
    "stage='NNetwork/'\n",
    "SavesDirectory='./TunedModels/'+model_class+'/'+model_version+\"/\"+stage\n",
    "#PATH = SavesDirectory+'Tanh_MSE_adam4940.pth'\n",
    "\n",
    "torch.save(net.state_dict(), PATH)\n",
    "\n",
    "# more on saving pytorch networks: https://pytorch.org/docs/stable/notes/serialization.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
