{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we first do the classification using the transformer This is our first classification task.\n",
    "\n",
    "The output classification vector from the transformer is saved to be used by the FCNN This is our second classification task.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing necessary libraries\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import sklearn\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from simpletransformers.classification import ClassificationModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the dataset\n",
    "\n",
    "Some pre-processing to the dataset has already been done in preparation for various tests, so this processing is not from scratch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# procedure for getting the data sets and formatting them for the transformer\n",
    " \n",
    "\n",
    "def prepareDataset( filename):\n",
    "     \n",
    "    ReadSet=pd.read_excel(filename )\n",
    "\n",
    "    ReadSet['text']=ReadSet['Statement']\n",
    "    ReadSet['labels']=ReadSet['Label']\n",
    "    \n",
    "    ReadSet=ReadSet.drop(['ID','Label','Statement','Subject','Speaker','Job','From','Affiliation','PantsTotal','NotRealTotal','BarelyTotal','HalfTotal','MostlyTotal' ,'RealTotal','Context'],axis=1)\n",
    "    \n",
    "\n",
    "    return ReadSet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>President Obama is a Muslim.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>An independent payment advisory board created ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>U.S. Sen. Bill Nelson was the deciding vote fo...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Large phone companies and their trade associat...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RIPTA has really some of the fullest buses for...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10094</th>\n",
       "      <td>The Georgia Dome has returned $10 billion in e...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10095</th>\n",
       "      <td>Then-Gov. Carl Sanders put 56 percent of the s...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10096</th>\n",
       "      <td>Nathan Deal saved the HOPE scholarship program.</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10097</th>\n",
       "      <td>John Faso took money from fossil fuel companie...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10098</th>\n",
       "      <td>With the exception of slavery and the Chinese ...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10099 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  labels\n",
       "0                           President Obama is a Muslim.       0\n",
       "1      An independent payment advisory board created ...       0\n",
       "2      U.S. Sen. Bill Nelson was the deciding vote fo...       2\n",
       "3      Large phone companies and their trade associat...       4\n",
       "4      RIPTA has really some of the fullest buses for...       4\n",
       "...                                                  ...     ...\n",
       "10094  The Georgia Dome has returned $10 billion in e...       1\n",
       "10095  Then-Gov. Carl Sanders put 56 percent of the s...       4\n",
       "10096    Nathan Deal saved the HOPE scholarship program.       4\n",
       "10097  John Faso took money from fossil fuel companie...       3\n",
       "10098  With the exception of slavery and the Chinese ...       4\n",
       "\n",
       "[10099 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# preparing the training dataset\n",
    "train=prepareDataset( 'train-clean.xlsx')\n",
    "# and display for inspecting\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>New Jerseys once-broken pension system is now ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The new health care law will cut $500 billion ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>For thousands of public employees, Wisconsin G...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Because as a Senator Toomey stood up for Wall ...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The governors budget proposal reduces the stat...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1267</th>\n",
       "      <td>You can import as many hemp products into this...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1268</th>\n",
       "      <td>Says when Republicans took over the state legi...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1269</th>\n",
       "      <td>Wisconsin's laws ranked the worst in the world...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1270</th>\n",
       "      <td>There currently are 825,000 student stations s...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1271</th>\n",
       "      <td>Black people are eight times more likely to be...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1272 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  labels\n",
       "0     New Jerseys once-broken pension system is now ...       3\n",
       "1     The new health care law will cut $500 billion ...       2\n",
       "2     For thousands of public employees, Wisconsin G...       3\n",
       "3     Because as a Senator Toomey stood up for Wall ...       4\n",
       "4     The governors budget proposal reduces the stat...       5\n",
       "...                                                 ...     ...\n",
       "1267  You can import as many hemp products into this...       5\n",
       "1268  Says when Republicans took over the state legi...       3\n",
       "1269  Wisconsin's laws ranked the worst in the world...       2\n",
       "1270  There currently are 825,000 student stations s...       4\n",
       "1271  Black people are eight times more likely to be...       3\n",
       "\n",
       "[1272 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# preparing the evaluation/validation dataset\n",
    "Eval=prepareDataset('valid-clean.xlsx')\n",
    "# and display for inspecting\n",
    "Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>In a lawsuit between private citizens, a Flori...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Obama-Nelson economic record: Job creation   a...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Says George LeMieux even compared Marco Rubio ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Gene Green is the NRAs favorite Democrat in Co...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>In labor negotiations with city employees, Mil...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1250</th>\n",
       "      <td>Says Milwaukee County Executive Chris Abele sp...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1251</th>\n",
       "      <td>The words subhuman mongrel, which Ted Nugent c...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1252</th>\n",
       "      <td>California's Prop 55 prevents $4 billion in ne...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1253</th>\n",
       "      <td>Says One of the states largest governments mad...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1254</th>\n",
       "      <td>Expanding the sale of full-strength beer and w...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1255 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  labels\n",
       "0     In a lawsuit between private citizens, a Flori...       4\n",
       "1     Obama-Nelson economic record: Job creation   a...       4\n",
       "2     Says George LeMieux even compared Marco Rubio ...       2\n",
       "3     Gene Green is the NRAs favorite Democrat in Co...       2\n",
       "4     In labor negotiations with city employees, Mil...       2\n",
       "...                                                 ...     ...\n",
       "1250  Says Milwaukee County Executive Chris Abele sp...       1\n",
       "1251  The words subhuman mongrel, which Ted Nugent c...       5\n",
       "1252  California's Prop 55 prevents $4 billion in ne...       2\n",
       "1253  Says One of the states largest governments mad...       0\n",
       "1254  Expanding the sale of full-strength beer and w...       3\n",
       "\n",
       "[1255 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# preparing the test set dataset\n",
    "test=prepareDataset('test-clean.xlsx')\n",
    "test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up the transformer for fine tuning\n",
    "\n",
    "This is where changes are done to optimise the model\n",
    "\n",
    "The simpletransformers library is the quickest way to do this at the time of writing. \n",
    "For more information on the settings and their default value go here:\n",
    "https://github.com/ThilinaRajapakse/simpletransformers#default-settings \n",
    "\n",
    "###### Please do read that reference before changing any parameters. Don't try to be a hero!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model variables were set up: \n"
     ]
    }
   ],
   "source": [
    "#Set the model being used here\n",
    "model_class='albert'  # bert or roberta or albert\n",
    "model_version='albert-large-v2' #bert-base-cased, roberta-base, roberta-large, albert-base-v2 OR albert-large-v2\n",
    "\n",
    "\n",
    "output_folder='./TunedModels/'+model_class+'/'+model_version+\"/\"\n",
    "cache_directory= \"./TunedModels/\"+model_class+\"/\"+model_version+\"/cache/\"\n",
    "labels_count=6  # the number of classification classes\n",
    "\n",
    "print('model variables were set up: ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G:\\0 finalThesis\\CleanedText\n",
      "./TunedModels/albert/albert-large-v2/\n",
      "./TunedModels/albert/albert-large-v2/cache/\n"
     ]
    }
   ],
   "source": [
    "# use this to test if writing to the directories is working\n",
    "\n",
    "import os\n",
    "print(os.getcwd())\n",
    "print(output_folder)\n",
    "print(cache_directory)\n",
    "\n",
    "testWrite=train.head(30)\n",
    " \n",
    "testWrite.to_csv(output_folder+'DeleteThisToo.tsv', sep='\\t')\n",
    "testWrite.to_csv(cache_directory+'DeleteThisToo.tsv', sep='\\t')\n",
    "\n",
    "del(testWrite)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "save_every_steps=1285\n",
    "# assuming training batch size of 8\n",
    "# any number above 1284 saves the model only at every epoch\n",
    "# Saving the model mid training very often will consume disk space fast\n",
    "\n",
    "train_args={\n",
    "    \"output_dir\":output_folder,\n",
    "    \"cache_dir\":cache_directory,\n",
    "    'reprocess_input_data': True,\n",
    "    'overwrite_output_dir': True,\n",
    "    'num_train_epochs': 1,\n",
    "    \"save_steps\": save_every_steps, \n",
    "    \"learning_rate\": 1.2e-5,\n",
    "    \"train_batch_size\": 64,\n",
    "    \"eval_batch_size\": 16,\n",
    "    \"evaluate_during_training_steps\": 5,\n",
    "    \"max_seq_length\": 100,\n",
    "    \"n_gpu\": 1,\n",
    "}\n",
    "\n",
    "# Create a ClassificationModel\n",
    "model = ClassificationModel(model_class, model_version, num_labels=labels_count, args=train_args) \n",
    "\n",
    "# You can set class weights by using the optional weight argument"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading a saved model (based on above args{})\n",
    "\n",
    "If you stopped training you can continue training from a previously saved check point.\n",
    "The next cell allows you to load a model from any checkpoint.\n",
    "The number of epochs in the train_args{} will be done and continue tuning from your checkpoint.\n",
    "\n",
    "###### HOWEVER\n",
    "It will overwrite previous checkpoints!\n",
    "Example:  If you load an epoch-3 checkpoint, the epoch-1 checkpoint will be overwritten by the 4th epoch and it will be equivalent to a 4th epoch even if you have epoch-1 in the name.\n",
    "###### SO BE CAREFUL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model, please wait...\n",
      "model in use is : ./TunedModels/albert/albert-large-v2/checkpoint-316-epoch-2\n"
     ]
    }
   ],
   "source": [
    "# loading a previously saved model based on this particular Transformer Class and model_name\n",
    "\n",
    "# loading the checkpoint that gave the best result\n",
    "CheckPoint='checkpoint-316-epoch-2'  #epoch 2\n",
    "\n",
    "\n",
    "preSavedCheckpoint=output_folder+CheckPoint\n",
    "\n",
    "print('Loading model, please wait...')\n",
    "model = ClassificationModel( model_class, preSavedCheckpoint, num_labels=labels_count, args=train_args) \n",
    "print('model in use is :', preSavedCheckpoint )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the Transformer\n",
    "\n",
    "Skip the next cell if you want to skip the training and go directly to the evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting to features started. Cache is not used.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3c7635b74aa47308ad6841f65e2e7ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=10099.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.\n",
      "\n",
      "Defaults for this optimization level are:\n",
      "enabled                : True\n",
      "opt_level              : O1\n",
      "cast_model_type        : None\n",
      "patch_torch_functions  : True\n",
      "keep_batchnorm_fp32    : None\n",
      "master_weights         : None\n",
      "loss_scale             : dynamic\n",
      "Processing user overrides (additional kwargs that are not None)...\n",
      "After processing overrides, optimization options are:\n",
      "enabled                : True\n",
      "opt_level              : O1\n",
      "cast_model_type        : None\n",
      "patch_torch_functions  : True\n",
      "keep_batchnorm_fp32    : None\n",
      "master_weights         : None\n",
      "loss_scale             : dynamic\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4901a7a97ba64ebda9b22f64142e0126",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch', max=1.0, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c58761f6fc646e7825428fd0be0e64e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Current iteration', max=158.0, style=ProgressStyle(descri…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running loss: 1.658109Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n",
      "Running loss: 1.735714Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 16384.0\n",
      "Running loss: 1.625402Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8192.0\n",
      "Running loss: 1.748201\n",
      "\n",
      "Training of albert model complete. Saved to ./TunedModels/albert/albert-large-v2/.\n",
      "Training time:  0:03:07.161133\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "current_time = datetime.now()\n",
    "model.train_model(train)\n",
    "print(\"Training time: \", datetime.now() - current_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating the training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features loaded from cache at ./TunedModels/albert/albert-large-v2/cache/cached_dev_albert_100_6_10099\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11a2e1a420414b9ab83ab55cbce99627",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=632.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{'mcc': 0.14302343923293323, 'acc': 0.30300029705911474, 'eval_loss': 1.6455843840973288}\n",
      "Features loaded from cache at ./TunedModels/albert/albert-large-v2/cache/cached_dev_albert_100_6_1272\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e72a378869246b283b5d7c205946c86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=80.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{'mcc': 0.07267173158242483, 'acc': 0.24842767295597484, 'eval_loss': 1.7028664216399192}\n",
      "Features loaded from cache at ./TunedModels/albert/albert-large-v2/cache/cached_dev_albert_100_6_1255\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91fcde278dd64f17ad459b6228fe15b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=79.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{'mcc': 0.07538753483067408, 'acc': 0.250996015936255, 'eval_loss': 1.6997072953212111}\n",
      "Training Result: 0.30300029705911474\n",
      "Eval Result: 0.24842767295597484\n",
      "Test Set Result: 0.250996015936255\n"
     ]
    }
   ],
   "source": [
    "TrainResult, TrainModel_outputs, wrong_predictions = model.eval_model(train, acc=sklearn.metrics.accuracy_score)\n",
    "\n",
    "EvalResult, EvalModel_outputs, wrong_predictions = model.eval_model(Eval, acc=sklearn.metrics.accuracy_score)\n",
    "\n",
    "TestResult, TestModel_outputs, wrong_predictions = model.eval_model(test, acc=sklearn.metrics.accuracy_score)\n",
    "\n",
    "print('Training Result:', TrainResult['acc'])\n",
    "#print('Model Out:', TrainModel_outputs)\n",
    "\n",
    "print('Eval Result:', EvalResult['acc'])\n",
    "#print('Model Out:', EvalModel_outputs)\n",
    "\n",
    "print('Test Set Result:', TestResult['acc'])\n",
    "#print('Model Out:', TestModel_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.01067352  0.47070312  0.32421875 -0.16882324 -0.38891602 -0.03646851] 1   4 \n",
      "[-1.1787109   0.37060547 -0.06860352  0.4416504   0.5527344   0.3251953 ] 4   4 Match 1\n",
      "\n",
      "[-0.60498047  0.35058594  0.19274902  0.13439941  0.05429077 -0.19616699] 1   2 \n",
      "[-0.6972656   0.03170776  0.06051636  0.609375    0.16479492  0.00113297] 3   2 \n",
      "[-0.10852051  0.15368652  0.2565918   0.2607422  -0.38989258 -0.42163086] 3   2 \n",
      "[-1.4775391   0.11663818 -0.15234375  0.6484375   1.0341797   0.578125  ] 4   5 \n",
      "[-0.19213867  0.27661133  0.3256836   0.16809082 -0.4038086  -0.47485352] 2   3 \n",
      "[-0.32055664  0.06652832  0.26782227  0.3515625  -0.23376465 -0.5761719 ] 3   2 \n",
      "[-0.22595215  0.42041016  0.18652344 -0.01853943 -0.28076172 -0.16564941] 1   1 Match 2\n",
      "\n",
      "[-0.05224609  0.11279297  0.31567383  0.22253418 -0.37231445 -0.6254883 ] 2   0 \n",
      "[-1.5654297  -0.0082016  -0.27661133  0.57128906  0.9892578   0.85839844] 4   5 \n",
      "[-0.11102295  0.38256836  0.29125977 -0.03808594 -0.3791504  -0.33569336] 1   2 \n",
      "[-1.6376953  -0.05612183 -0.39453125  0.6401367   1.1044922   0.75097656] 4   5 \n",
      "[-1.2724609   0.27001953 -0.03939819  0.5107422   0.6738281   0.4934082 ] 4   5 \n",
      "[-1.2978516   0.24243164  0.11627197  0.5888672   0.6586914   0.3388672 ] 4   3 \n",
      "[-1.7265625  -0.265625   -0.3330078   0.5073242   1.0527344   0.97314453] 4   1 \n",
      "[-0.5991211   0.3659668   0.14086914  0.1541748   0.04428101 -0.02407837] 1   0 \n",
      "[-0.3305664   0.3408203   0.24243164  0.01074219 -0.27539062 -0.2602539 ] 1   1 Match 3\n",
      "\n",
      "[-1.46875     0.09466553 -0.22265625  0.515625    0.73828125  0.68115234] 4   1 \n",
      "[-0.44677734  0.01733398  0.3623047   0.71972656 -0.08673096 -0.28833008] 3   2 \n",
      "[-0.72802734  0.1303711   0.33422852  0.7441406   0.12561035 -0.41870117] 3   1 \n",
      "[-0.07537842  0.42895508  0.2211914  -0.09356689 -0.4519043  -0.08776855] 1   0 \n",
      "[-1.4941406  -0.12347412 -0.08666992  0.84521484  1.0234375   0.7866211 ] 4   4 Match 4\n",
      "\n",
      "[-0.3852539   0.29516602  0.37280273  0.18530273 -0.18225098 -0.12249756] 2   2 Match 5\n",
      "\n",
      "[-1.3828125   0.19091797  0.06744385  0.9638672   0.56933594 -0.1381836 ] 3   2 \n",
      "[-1.2011719   0.24414062 -0.06994629  0.27246094  0.50878906  0.7055664 ] 5   4 \n",
      "[-0.4453125   0.18823242  0.45703125  0.4165039  -0.23950195 -0.4621582 ] 2   1 \n",
      "[-1.2382812   0.02059937  0.11608887  0.8930664   0.54052734 -0.06616211] 3   3 Match 6\n",
      "\n",
      "[-0.55322266  0.22485352  0.3425293   0.46826172 -0.07312012 -0.36743164] 3   0 \n",
      "[-1.4960938   0.17944336 -0.05221558  0.7207031   0.95458984  0.44970703] 4   2 \n",
      "[-1.4355469e+00  3.4106445e-01 -4.0650368e-04  4.9536133e-01\n",
      "  6.4648438e-01  3.2910156e-01] 4   3 \n",
      "[-0.9394531   0.14147949  0.25634766  0.76220703  0.31396484 -0.23413086] 3   1 \n",
      "[-0.32348633  0.07727051  0.22729492  0.47998047 -0.10797119 -0.359375  ] 3   1 \n",
      "[-0.7631836   0.08728027  0.29614258  0.7763672   0.13964844 -0.29370117] 3   1 \n",
      "[-1.1318359   0.12268066  0.1784668   0.9345703   0.32348633 -0.20166016] 3   1 \n",
      "[ 0.07177734  0.3383789   0.2763672  -0.15881348 -0.48339844 -0.19067383] 1   2 \n",
      "[-1.1103516   0.05358887  0.2783203   1.0107422   0.36401367 -0.21435547] 3   2 \n",
      "[ 0.04299927  0.16040039  0.3449707   0.23327637 -0.5361328  -0.59765625] 2   3 \n",
      "[-1.3984375   0.13134766 -0.07458496  0.72558594  0.87597656  0.23217773] 4   4 Match 7\n",
      "\n",
      "[-1.3867188   0.28808594 -0.00300026  0.6015625   0.7739258   0.390625  ] 4   2 \n",
      "[-1.5605469  -0.03396606 -0.375       0.4255371   0.96240234  0.7573242 ] 4   5 \n",
      "[-1.2255859   0.2631836  -0.10125732  0.42285156  0.64453125  0.45483398] 4   2 \n",
      "[-1.0625      0.29638672  0.19958496  0.42822266  0.42822266  0.3022461 ] 3   1 \n",
      "[-0.43798828  0.43066406  0.35253906  0.05551147 -0.13098145 -0.02850342] 1   0 \n",
      "[-1.5546875   0.23779297 -0.08288574  0.6616211   0.88378906  0.4790039 ] 4   2 \n",
      "[-0.41577148  0.2783203   0.25463867  0.40673828 -0.1427002  -0.40795898] 3   2 \n",
      "[-1.421875   -0.07647705 -0.14526367  0.76416016  0.9667969   0.43115234] 4   1 \n",
      "[-0.3791504   0.27734375  0.19348145  0.2133789  -0.11712646 -0.18774414] 1   3 \n",
      "[-0.42358398  0.29638672  0.19494629  0.16625977 -0.17297363 -0.3251953 ] 1   3 \n",
      "[-1.2910156   0.24108887  0.09002686  0.9458008   0.68066406  0.0418396 ] 3   1 \n",
      "[-0.5834961   0.42358398  0.16967773  0.0411377   0.00266266  0.06817627] 1   2 \n",
      "[-1.3779297   0.07171631 -0.09344482  0.6386719   0.9003906   0.4880371 ] 4   3 \n",
      "[-0.6020508   0.4206543   0.12182617  0.03768921  0.01087189  0.17224121] 1   2 \n",
      "[-1.6855469  -0.0025692  -0.1809082   0.73095703  1.0214844   0.64208984] 4   5 \n",
      "[ 0.0042038   0.2631836   0.3076172   0.05038452 -0.52197266 -0.51123047] 2   0 \n",
      "[-1.5         0.11517334 -0.14013672  0.5810547   1.0673828   0.65478516] 4   5 \n",
      "[-0.23779297  0.32861328  0.22265625  0.05917358 -0.29907227 -0.5131836 ] 1   5 \n",
      "[-0.578125    0.01413727  0.16455078  0.66845703 -0.00915527 -0.34423828] 3   1 \n",
      "[-0.2998047   0.24169922  0.25683594  0.1508789  -0.30322266 -0.35083008] 2   3 \n",
      "[-0.5371094   0.49609375  0.12634277 -0.1763916  -0.04769897  0.20471191] 1   1 Match 8\n",
      "\n",
      "[-0.5004883   0.23583984  0.32836914  0.48291016 -0.08532715 -0.4519043 ] 3   2 \n",
      "[-0.7006836   0.33813477  0.2084961   0.30151367  0.00802612 -0.19848633] 1   5 \n",
      "[-1.2675781   0.20422363  0.15930176  0.83203125  0.59521484 -0.00880432] 3   5 \n",
      "[-0.8852539   0.17590332  0.28222656  0.81933594  0.19519043 -0.25317383] 3   2 \n",
      "[-0.21105957  0.32617188  0.3540039   0.14794922 -0.29052734 -0.36499023] 2   5 \n",
      "[-1.1318359   0.20458984 -0.04507446  0.30639648  0.61035156  0.40942383] 4   5 \n",
      "[-0.6220703   0.2878418   0.30493164  0.37890625  0.06176758 -0.33325195] 3   5 \n",
      "[-0.8457031  -0.04528809  0.23376465  0.75390625  0.2211914  -0.12298584] 3   2 \n",
      "[ 0.05981445  0.36450195  0.19042969 -0.09161377 -0.51123047 -0.6064453 ] 1   1 Match 9\n",
      "\n",
      "[-0.21948242  0.19714355  0.3581543   0.28808594 -0.35986328 -0.5541992 ] 2   3 \n",
      "[-1.5722656   0.02531433 -0.3857422   0.3605957   0.9995117   0.8676758 ] 4   1 \n",
      "[-0.59521484  0.47998047  0.19140625  0.15063477  0.0042038  -0.05599976] 1   3 \n",
      "[-0.33496094  0.3930664   0.20275879  0.10986328 -0.16333008 -0.20446777] 1   3 \n",
      "[-1.3144531   0.02938843  0.14465332  1.0390625   0.6225586   0.12237549] 3   5 \n",
      "[-0.20605469  0.41137695 -0.01073456 -0.21484375 -0.32299805 -0.2590332 ] 1   4 \n",
      "[-0.67285156  0.25585938  0.19360352  0.28759766  0.05133057  0.02127075] 3   1 \n",
      "[ 0.01218414  0.41503906  0.21484375 -0.18945312 -0.48706055 -0.44262695] 1   5 \n",
      "[-1.5009766   0.0489502  -0.26831055  0.24035645  0.8881836   1.0546875 ] 5   4 \n",
      "[-1.1347656e+00  2.9565430e-01  1.0449219e-01  6.0205078e-01\n",
      "  4.2407227e-01  2.1827221e-04] 3   3 Match 10\n",
      "\n",
      "[-1.2880859   0.28051758  0.019104    0.6230469   0.62841797  0.17419434] 4   1 \n",
      "[-1.4414062  -0.1459961  -0.0044899   0.88134766  0.87890625  0.546875  ] 3   4 \n",
      "[-1.390625    0.22607422  0.0177002   0.8022461   0.60839844 -0.08404541] 3   3 Match 11\n",
      "\n",
      "[-0.51708984  0.45458984  0.17041016  0.03695679 -0.00434875  0.06689453] 1   4 \n",
      "[-0.88671875  0.5488281   0.14770508  0.11468506  0.27124023  0.19921875] 1   3 \n",
      "[-0.48168945  0.50390625  0.24987793 -0.01771545 -0.06500244 -0.01576233] 1   2 \n",
      "[-0.88720703  0.23632812  0.05886841  0.5566406   0.24084473 -0.01540375] 3   4 \n",
      "[-0.98095703 -0.0553894   0.25146484  0.8417969   0.37719727 -0.01780701] 3   4 \n",
      "[-0.7973633   0.3605957   0.24560547  0.5517578   0.13183594 -0.28076172] 3   1 \n",
      "[-1.6083984   0.01942444 -0.28979492  0.60498047  1.0595703   0.7338867 ] 4   5 \n",
      "[-1.4169922   0.02235413 -0.04608154  0.95703125  0.81640625  0.45263672] 3   4 \n",
      "[-1.4306641   0.02696228 -0.21582031  0.5214844   1.0830078   0.5654297 ] 4   4 Match 12\n",
      "\n",
      "[-0.9448242   0.27954102  0.25463867  0.63964844  0.22399902 -0.33374023] 3   5 \n",
      "[-1.1943359  -0.08856201 -0.15625     0.56640625  0.40234375  0.44750977] 3   1 \n",
      "[-1.7900391  -0.16564941 -0.43237305  0.54833984  1.1025391   0.9140625 ] 4   3 \n",
      "[-1.5751953  -0.05789185 -0.09912109  0.9458008   0.88964844  0.40454102] 3   3 Match 13\n",
      "\n",
      "[-1.5458984   0.13183594 -0.12463379  0.7133789   0.8125      0.5336914 ] 4   3 \n",
      "[-0.16430664  0.40844727  0.25463867 -0.00266457 -0.37231445 -0.28979492] 1   4 \n",
      "[-0.9135742   0.26782227  0.32128906  0.51220703  0.19470215 -0.07159424] 3   3 Match 14\n",
      "\n",
      "[-0.46557617  0.2849121   0.37573242  0.30273438 -0.11529541 -0.23754883] 2   4 \n",
      "[-0.15405273  0.44360352  0.2232666  -0.14501953 -0.44677734 -0.33032227] 1   4 \n",
      "[-0.02624512  0.2409668   0.25952148  0.14697266 -0.3972168  -0.6298828 ] 2   3 \n",
      "[-0.4387207   0.01012421  0.21374512  0.36254883 -0.16882324 -0.32617188] 3   4 \n",
      "[-0.7006836   0.50683594  0.07446289 -0.07507324  0.09533691  0.4333496 ] 1   3 \n",
      "[-1.2314453  -0.07885742 -0.18005371  0.37841797  0.45214844  0.6455078 ] 5   5 Match 15\n",
      "\n",
      "[-1.2441406   0.15942383 -0.09240723  0.36401367  0.89160156  0.47680664] 4   4 Match 16\n",
      "\n",
      "[-1.3876953  0.2199707 -0.0051651  0.6713867  0.8051758  0.2775879] 4   4 Match 17\n",
      "\n",
      "[ 0.01399231  0.2286377   0.17236328  0.1328125  -0.39379883 -0.5756836 ] 1   2 \n",
      "[-0.625       0.5029297   0.15661621 -0.08709717  0.05862427  0.44726562] 1   2 \n",
      "[-1.4736328  -0.35180664 -0.01860046  0.8828125   1.1298828   0.9248047 ] 4   3 \n",
      "[-1.6464844  -0.05886841 -0.33911133  0.7319336   0.9848633   0.4807129 ] 4   3 \n",
      "[-1.3271484   0.28271484 -0.02812195  0.5966797   0.5961914   0.5917969 ] 3   4 \n",
      "[-1.5498047   0.17370605 -0.22424316  0.46679688  0.99316406  0.7836914 ] 4   4 Match 18\n",
      "\n",
      "[-1.5214844   0.06982422 -0.25512695  0.3815918   0.9736328   0.9243164 ] 4   4 Match 19\n",
      "\n",
      "[-1.1923828   0.43701172 -0.0737915   0.33544922  0.4724121   0.28466797] 4   4 Match 20\n",
      "\n",
      "[-1.4707031   0.18762207 -0.20349121  0.3190918   0.9477539   0.8618164 ] 4   4 Match 21\n",
      "\n",
      "[-0.328125    0.36010742  0.08227539 -0.08428955 -0.3618164  -0.00921631] 1   2 \n",
      "[-1.5576172  -0.05401611 -0.4326172   0.32910156  1.0302734   0.8823242 ] 4   4 Match 22\n",
      "\n",
      "[-0.07971191  0.2783203   0.29467773  0.05633545 -0.4111328  -0.24414062] 2   3 \n",
      "[-0.3720703   0.23425293  0.38842773  0.37597656 -0.26538086 -0.46191406] 2   5 \n",
      "[-1.1269531   0.28466797  0.10943604  0.54541016  0.57910156  0.1463623 ] 4   3 \n",
      "[-0.83496094 -0.19250488  0.05130005  0.7451172   0.3100586   0.17834473] 3   3 Match 23\n",
      "\n",
      "[-0.73535156 -0.18896484  0.2602539   0.9321289   0.22973633 -0.1381836 ] 3   3 Match 24\n",
      "\n",
      "[-1.2158203   0.29663086 -0.04788208  0.3618164   0.65185547  0.6777344 ] 5   1 \n",
      "[-0.87597656  0.24890137  0.19482422  0.49121094  0.28515625  0.01358032] 3   5 \n",
      "[-0.43774414  0.18493652  0.22851562  0.36132812 -0.07659912 -0.2861328 ] 3   0 \n",
      "[-1.4638672   0.00591278 -0.4025879   0.22485352  0.9213867   0.92529297] 5   1 \n",
      "[-1.4560547  -0.05606079 -0.11767578  0.5292969   0.8774414   0.6015625 ] 4   5 \n",
      "[-1.5        -0.4802246  -0.0690918   0.6738281   1.1289062   0.95703125] 4   4 Match 25\n",
      "\n",
      "[-1.7539062   0.00993347 -0.31811523  0.4501953   1.0732422   0.9477539 ] 4   4 Match 26\n",
      "\n",
      "[-1.0986328   0.29296875  0.14624023  0.51904297  0.52197266  0.10919189] 4   4 Match 27\n",
      "\n",
      "[-0.36523438  0.33544922  0.2388916   0.26708984 -0.20336914 -0.3503418 ] 1   2 \n",
      "[-1.59375     0.04678345 -0.2084961   0.61328125  1.0800781   0.8540039 ] 4   4 Match 28\n",
      "\n",
      "[-1.5253906   0.16320801 -0.1685791   0.6254883   0.9946289   0.61328125] 4   4 Match 29\n",
      "\n",
      "[-0.8754883  -0.00949097  0.28808594  0.74121094  0.25512695 -0.16784668] 3   4 \n",
      "[-0.6303711   0.32421875  0.3256836   0.27368164 -0.07830811 -0.20788574] 2   3 \n",
      "[-1.0585938  -0.3413086   0.18078613  1.0566406   0.6147461   0.2434082 ] 3   5 \n",
      "[-0.3515625   0.23022461  0.15429688  0.27539062 -0.25390625 -0.5805664 ] 3   2 \n",
      "[-0.83935547  0.07647705  0.11175537  0.5917969   0.17456055  0.05999756] 3   4 \n",
      "[ 0.1352539   0.29248047  0.33666992 -0.02792358 -0.52685547 -0.54785156] 2   2 Match 30\n",
      "\n",
      "[-0.6430664   0.19226074  0.16174316  0.62158203  0.09509277 -0.41845703] 3   2 \n",
      "[-1.5605469   0.02464294 -0.2841797   0.2915039   0.7792969   0.95654297] 5   0 \n",
      "[ 0.27856445  0.2709961   0.28833008 -0.13659668 -0.5620117  -0.6699219 ] 2   1 \n",
      "[-0.53564453  0.2619629   0.22888184  0.11669922 -0.15783691  0.10882568] 1   5 \n",
      "[-0.11688232  0.18493652  0.4086914   0.26538086 -0.42089844 -0.62109375] 2   3 \n",
      "[-0.7529297   0.32763672  0.19995117  0.265625    0.17834473  0.13415527] 1   2 \n",
      "[-0.5332031   0.6069336   0.09472656 -0.2631836  -0.06234741  0.3100586 ] 1   3 \n",
      "[-0.19091797  0.17224121  0.2376709   0.14746094 -0.36132812 -0.3930664 ] 2   4 \n",
      "[-1.578125    0.00894928 -0.26538086  0.85009766  1.1220703   0.62597656] 4   4 Match 31\n",
      "\n",
      "[-1.2685547  -0.23291016 -0.13269043  0.83447266  0.7675781   0.59472656] 3   1 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.5600586   0.35351562  0.23461914  0.2878418  -0.04327393 -0.04568481] 1   5 \n",
      "[-0.5698242   0.4091797   0.15148926  0.05392456  0.01408386  0.06030273] 1   4 \n",
      "[-1.6152344  -0.03231812 -0.26733398  0.7421875   1.1738281   0.66308594] 4   5 \n",
      "[-1.5820312   0.0440979  -0.29296875  0.671875    0.8510742   0.7919922 ] 4   5 \n",
      "[-0.68310547  0.16101074  0.16186523  0.31103516 -0.0305481  -0.03083801] 3   4 \n",
      "[-1.6083984  -0.11114502 -0.32836914  0.26049805  0.94433594  0.83984375] 4   4 Match 32\n",
      "\n",
      "[-1.4199219   0.05966187 -0.24157715  0.42651367  1.046875    0.8979492 ] 4   2 \n",
      "[ 0.01751709  0.31030273  0.26171875  0.06848145 -0.5209961  -0.61035156] 1   2 \n",
      "[-1.5576172   0.12103271 -0.17749023  0.5571289   0.97753906  0.66845703] 4   4 Match 33\n",
      "\n",
      "[ 0.05511475  0.14318848  0.30297852  0.26464844 -0.45166016 -0.58984375] 2   0 \n",
      "[-0.11395264  0.24743652  0.39233398  0.06719971 -0.4345703  -0.5361328 ] 2   0 \n",
      "[ 0.18920898  0.26171875  0.2685547   0.01145935 -0.5649414  -0.7519531 ] 2   0 \n",
      "[-0.07714844  0.4855957   0.27978516 -0.22155762 -0.3388672  -0.02929688] 1   5 \n",
      "[-0.13879395  0.11315918  0.3725586   0.35791016 -0.36083984 -0.796875  ] 2   1 \n",
      "[-1.2587891   0.1619873   0.1451416   0.71972656  0.6713867   0.18383789] 3   1 \n",
      "[-1.1542969   0.45703125  0.03158569  0.05187988  0.4296875   0.7963867 ] 5   0 \n",
      "[-0.09118652  0.22265625  0.39770508  0.17944336 -0.46533203 -0.5053711 ] 2   0 \n",
      "[-0.22753906  0.4243164   0.12359619 -0.15588379 -0.29882812 -0.17578125] 1   0 \n",
      "[-1.5605469   0.18884277 -0.18371582  0.6791992   0.9038086   0.5385742 ] 4   4 Match 34\n",
      "\n",
      "[-1.3769531   0.09594727  0.18359375  0.8388672   0.5498047   0.01056671] 3   4 \n",
      "[-0.37548828  0.27026367  0.30200195  0.38012695 -0.11291504 -0.31445312] 3   3 Match 35\n",
      "\n",
      "[-1.3320312  -0.08410645 -0.05322266  0.79589844  0.7792969   0.6386719 ] 3   3 Match 36\n",
      "\n",
      "[-0.9345703   0.41088867  0.12213135  0.34545898  0.2602539   0.03646851] 1   5 \n",
      "[-1.2167969   0.2487793   0.16845703  0.8300781   0.65722656  0.06494141] 3   3 Match 37\n",
      "\n",
      "[-1.4716797  -0.08764648 -0.37353516  0.23864746  0.8964844   1.0351562 ] 5   5 Match 38\n",
      "\n",
      "[-1.3857422  -0.02037048 -0.19360352  0.69384766  0.89404297  0.6513672 ] 4   5 \n",
      "[-1.5927734   0.24316406 -0.1973877   0.40576172  1.0341797   0.7519531 ] 4   1 \n",
      "[-1.578125   -0.15661621 -0.19494629  0.7944336   1.1064453   0.92089844] 4   5 \n",
      "[-0.35595703  0.28051758 -0.046875   -0.11132812 -0.07403564 -0.15710449] 1   2 \n",
      "[-1.640625   -0.08752441 -0.4194336   0.37719727  1.1083984   0.9604492 ] 4   4 Match 39\n",
      "\n",
      "[-1.2939453   0.17358398  0.0269165   0.80566406  0.65527344  0.26245117] 3   3 Match 40\n",
      "\n",
      "[-1.3330078   0.10308838  0.12780762  0.8359375   0.6357422   0.1394043 ] 3   5 \n",
      "[-0.7573242   0.35913086  0.23571777  0.4555664   0.14624023 -0.01433563] 3   0 \n",
      "[-0.73779297  0.1619873   0.3564453   0.7084961   0.02378845 -0.4020996 ] 3   0 \n",
      "[-0.71777344  0.15161133  0.0612793   0.39575195 -0.0567627   0.06378174] 3   2 \n",
      "[-1.359375    0.15576172 -0.21850586  0.17114258  0.5698242   0.86328125] 5   4 \n",
      "[-0.39624023  0.4777832   0.13720703 -0.15075684 -0.21643066 -0.11193848] 1   0 \n",
      "[-1.4707031   0.24194336 -0.1973877   0.34838867  0.75341797  0.82128906] 5   5 Match 41\n",
      "\n",
      "[-0.00826263  0.21228027  0.31689453  0.16491699 -0.44018555 -0.68408203] 2   2 Match 42\n",
      "\n",
      "[ 0.14929199  0.45654297  0.22033691 -0.3293457  -0.5498047  -0.12768555] 1   1 Match 43\n",
      "\n",
      "[ 2.4682617e-01  5.0488281e-01  3.2519531e-01 -3.9379883e-01\n",
      " -4.6386719e-01 -2.2351742e-04] 1   5 \n",
      "[-1.2724609   0.2685547  -0.05432129  0.4946289   0.6665039   0.5209961 ] 4   2 \n",
      "[-0.04263306  0.39819336  0.32714844 -0.21166992 -0.55126953 -0.22473145] 1   5 \n",
      "[-0.90478516  0.3137207   0.18188477  0.7915039   0.33935547 -0.41674805] 3   0 \n",
      "[-1.4404297  -0.24536133 -0.01600647  1.1015625   0.88427734  0.5786133 ] 3   4 \n",
      "[-1.7353516  -0.0791626  -0.3215332   0.50341797  0.96191406  0.7080078 ] 4   4 Match 44\n",
      "\n",
      "[-0.7392578   0.10449219  0.29711914  0.7446289   0.0425415  -0.3022461 ] 3   4 \n",
      "[-0.74658203  0.16516113  0.33398438  0.5283203   0.07489014 -0.3112793 ] 3   3 Match 45\n",
      "\n",
      "[-0.7080078   0.5307617   0.18164062 -0.15588379  0.15930176  0.52685547] 1   5 \n",
      "[-0.16662598  0.33007812  0.20178223  0.01708984 -0.27539062 -0.19787598] 1   5 \n",
      "[-0.5102539   0.17370605  0.40283203  0.5126953  -0.12573242 -0.5253906 ] 3   2 \n",
      "[-0.34594727  0.49072266  0.21118164 -0.05093384 -0.23059082 -0.1459961 ] 1   5 \n",
      "[-1.5429688  -0.16845703 -0.26171875  0.5913086   0.89697266  0.8461914 ] 4   5 \n",
      "[ 0.22521973  0.38623047  0.2388916  -0.21728516 -0.59472656 -0.49731445] 1   1 Match 46\n",
      "\n",
      "[-1.1347656   0.20019531  0.19030762  0.63134766  0.4453125   0.08978271] 3   1 \n",
      "[-0.23986816  0.26586914  0.3005371   0.2548828  -0.30737305 -0.58154297] 2   0 \n",
      "[-0.04266357  0.44384766  0.33374023 -0.2052002  -0.4375     -0.01461029] 1   2 \n",
      "[-0.53271484  0.32910156  0.26489258  0.28930664 -0.05950928 -0.27270508] 1   0 \n",
      "[-0.21582031  0.30688477  0.3647461   0.18933105 -0.3305664  -0.3310547 ] 2   0 \n",
      "[-0.29370117  0.41625977  0.23657227 -0.14025879 -0.35375977 -0.0949707 ] 1   0 \n",
      "[-0.42529297  0.36254883  0.33251953  0.18408203 -0.1348877  -0.22717285] 1   0 \n",
      "[-0.41479492  0.13317871  0.3125      0.6870117  -0.1239624  -0.44189453] 3   1 \n",
      "[-0.26342773  0.23632812  0.21948242  0.10839844 -0.2626953  -0.08404541] 1   0 \n",
      "[-1.6201172  -0.3713379  -0.19165039  0.7783203   1.0859375   0.94433594] 4   1 \n",
      "[-0.32885742  0.21606445  0.3347168   0.35595703 -0.32055664 -0.6064453 ] 3   2 \n",
      "[-0.08282471  0.15490723  0.18701172  0.25878906 -0.30639648 -0.35766602] 3   2 \n",
      "[-1.3457031   0.22058105 -0.265625    0.05166626  0.73535156  0.91552734] 5   4 \n",
      "[ 0.24902344  0.19067383  0.20605469  0.07781982 -0.6503906  -0.8276367 ] 0   0 Match 47\n",
      "\n",
      "[-0.9033203  -0.05395508  0.09100342  0.68603516  0.20703125 -0.06774902] 3   2 \n",
      "[-1.0673828   0.2548828   0.03982544  0.6171875   0.3256836  -0.34228516] 3   5 \n",
      "[-1.2060547   0.29858398 -0.14172363  0.09625244  0.7133789   0.7939453 ] 5   5 Match 48\n",
      "\n",
      "[-1.6816406  -0.13122559 -0.32299805  0.34692383  0.96533203  0.8725586 ] 4   4 Match 49\n",
      "\n",
      "[-0.50683594  0.39160156  0.19970703  0.02156067 -0.07598877  0.12902832] 1   5 \n",
      "[-1.2636719  -0.3203125  -0.08282471  0.5488281   0.5888672   0.6689453 ] 5   2 \n",
      "[-0.8256836   0.23278809  0.24133301  0.62890625  0.20922852 -0.29248047] 3   4 \n",
      "[-0.39526367  0.4987793   0.24707031 -0.08361816 -0.18798828  0.00856781] 1   2 \n",
      "[-1.1943359   0.09057617  0.03274536  0.8876953   0.5131836   0.08996582] 3   3 Match 50\n",
      "\n",
      "[-1.6542969  -0.08569336 -0.45239258  0.49145508  1.0195312   0.7529297 ] 4   5 \n",
      "[-1.0957031   0.3486328   0.1262207   0.42773438  0.58935547  0.15307617] 4   1 \n",
      "[-1.6210938  -0.05187988 -0.34692383  0.5395508   1.1435547   0.83496094] 4   1 \n",
      "[ 0.05285645  0.3449707   0.24584961 -0.03829956 -0.42993164 -0.45458984] 1   3 \n",
      "[-0.8486328   0.22509766  0.03985596  0.46923828  0.21826172  0.17480469] 3   3 Match 51\n",
      "\n",
      "[-1.5039062  -0.09527588 -0.24316406  0.75390625  0.9926758   0.71728516] 4   0 \n",
      "[-0.28100586  0.11358643  0.29541016  0.20996094 -0.28198242 -0.27563477] 2   2 Match 52\n",
      "\n",
      "[-0.85058594  0.36499023  0.0737915   0.23522949  0.18566895  0.25732422] 1   5 \n",
      "[-1.6992188  -0.17834473 -0.35595703  0.4987793   1.1044922   0.81152344] 4   3 \n",
      "[-1.3691406  -0.3059082   0.05142212  0.99560547  1.0214844   0.61279297] 4   1 \n",
      "[-0.86035156  0.28833008  0.14929199  0.5541992   0.2824707  -0.07513428] 3   3 Match 53\n",
      "\n",
      "[-0.6582031   0.1550293   0.19470215  0.43286133  0.18005371 -0.07855225] 3   0 \n",
      "[-1.625      -0.12524414 -0.2746582   0.7241211   1.1230469   0.85791016] 4   3 \n",
      "[-1.4746094  -0.1194458  -0.15283203  0.8847656   0.89501953  0.640625  ] 4   3 \n",
      "[-1.6259766  -0.07330322 -0.32861328  0.609375    1.0371094   0.76416016] 4   4 Match 54\n",
      "\n",
      "[-0.28808594 -0.05697632  0.26049805  0.4169922  -0.18920898 -0.17810059] 3   3 Match 55\n",
      "\n",
      "[-0.10394287  0.27441406  0.17321777 -0.01350403 -0.47216797 -0.3251953 ] 1   3 \n",
      "[-0.13330078  0.18200684  0.33618164  0.1973877  -0.4194336  -0.6303711 ] 2   3 \n",
      "[-1.5732422   0.16882324 -0.01462555  0.91259766  0.984375    0.5004883 ] 4   4 Match 56\n",
      "\n",
      "[-0.8364258   0.34228516  0.13562012  0.18225098  0.16931152  0.34838867] 5   4 \n",
      "[-1.4775391   0.29833984 -0.00946808  0.5493164   0.86279297  0.5283203 ] 4   4 Match 57\n",
      "\n",
      "[-1.1162109   0.01774597  0.17468262  0.9189453   0.3713379   0.07489014] 3   3 Match 58\n",
      "\n",
      "[-0.02043152  0.23303223  0.3684082   0.10040283 -0.42895508 -0.49926758] 2   2 Match 59\n",
      "\n",
      "[-0.8330078   0.26708984  0.26538086  0.53564453  0.2010498  -0.15771484] 3   5 \n",
      "[-0.18566895  0.3696289   0.21044922 -0.07653809 -0.42626953 -0.09838867] 1   2 \n",
      "[-1.0488281   0.29589844 -0.03005981  0.39941406  0.45947266  0.3955078 ] 4   4 Match 60\n",
      "\n",
      "[-1.4462891   0.0224762  -0.04104614  0.91748047  0.8378906   0.46118164] 3   4 \n",
      "[-0.13305664  0.27929688  0.22399902  0.06213379 -0.3876953  -0.4440918 ] 1   2 \n",
      "[-0.6582031   0.5673828   0.08416748 -0.01326752  0.18859863  0.203125  ] 1   0 \n",
      "[-0.60009766  0.44848633  0.05090332 -0.17346191 -0.01265717  0.43652344] 1   4 \n",
      "[-0.56396484  0.2446289   0.21960449  0.3647461  -0.04992676 -0.18310547] 3   3 Match 61\n",
      "\n",
      "[-1.6132812   0.03442383 -0.1496582   0.75        0.86376953  0.65625   ] 4   4 Match 62\n",
      "\n",
      "[-1.5917969  -0.24401855 -0.2199707   0.7631836   1.1015625   0.7817383 ] 4   2 \n",
      "[-1.5097656   0.31176758 -0.36010742  0.0994873   0.87841797  0.73583984] 4   5 \n",
      "[-1.6103516  -0.13208008 -0.44458008  0.30786133  1.0058594   0.8720703 ] 4   1 \n",
      "[-0.640625    0.59716797  0.06243896 -0.12561035  0.16809082  0.42211914] 1   5 \n",
      "[-1.5253906  -0.15661621 -0.3083496   0.5444336   0.92871094  0.73779297] 4   1 \n",
      "[-1.6289062  -0.03286743 -0.2619629   0.57421875  0.9301758   0.66748047] 4   4 Match 63\n",
      "\n",
      "[-1.3056641   0.30395508 -0.12060547  0.59228516  0.8613281   0.22155762] 4   4 Match 64\n",
      "\n",
      "[-0.99365234  0.10058594  0.28198242  0.84033203  0.36279297 -0.21081543] 3   3 Match 65\n",
      "\n",
      "[-1.3652344   0.10693359  0.07623291  0.74365234  0.6899414   0.22607422] 3   4 \n",
      "[-0.30639648  0.28442383  0.38598633  0.38671875 -0.31298828 -0.53515625] 3   2 \n",
      "[-0.30273438  0.39379883  0.34326172  0.11309814 -0.29833984 -0.29663086] 1   0 \n",
      "[-1.5537109   0.01290894 -0.37963867  0.5449219   0.88720703  0.77001953] 4   1 \n",
      "[-1.2304688   0.16247559  0.05130005  0.8808594   0.5698242  -0.04150391] 3   4 \n",
      "[-1.0986328   0.36889648 -0.05764771  0.0340271   0.23510742  0.67285156] 5   1 \n",
      "[-1.3203125   0.21765137  0.03649902  0.5913086   0.5541992   0.34375   ] 3   2 \n",
      "[-0.57373047  0.20397949  0.39331055  0.41967773 -0.06958008 -0.46166992] 3   2 \n",
      "[-0.1161499   0.24291992  0.234375    0.14050293 -0.42456055 -0.68408203] 1   1 Match 66\n",
      "\n",
      "[-0.52001953  0.4567871   0.06549072  0.11560059 -0.0236969  -0.23913574] 1   4 \n",
      "[-0.8466797   0.32714844  0.21923828  0.28881836  0.18847656  0.00215721] 1   1 Match 67\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[-1.2509766   0.37402344 -0.05151367  0.5102539   0.61572266  0.23095703] 4   5 \n",
      "[-1.2539062   0.27978516  0.10839844  0.7001953   0.5888672  -0.01829529] 3   4 \n",
      "[-0.9506836   0.06726074  0.32861328  0.7944336   0.29248047 -0.26782227] 3   3 Match 68\n",
      "\n",
      "[-1.3652344  -0.15759277 -0.02818298  1.0556641   0.75097656  0.50878906] 3   2 \n",
      "[-1.5175781   0.02452087 -0.03079224  0.8613281   0.9501953   0.62841797] 4   4 Match 69\n",
      "\n",
      "[-0.6879883   0.20080566  0.34057617  0.47509766  0.03158569 -0.30615234] 3   4 \n",
      "[-1.5615234   0.07592773 -0.31274414  0.18811035  0.90722656  1.0126953 ] 5   1 \n",
      "[-1.4248047  -0.06573486 -0.0473938   0.71972656  0.5571289   0.5629883 ] 3   4 \n",
      "[ 0.1541748   0.21643066  0.24743652 -0.0066452  -0.52978516 -0.6401367 ] 2   1 \n",
      "[-0.14343262  0.53759766  0.12017822 -0.37280273 -0.3359375   0.25756836] 1   1 Match 70\n",
      "\n",
      "[-1.5527344  -0.0592041  -0.3479004   0.37182617  0.9458008   1.0195312 ] 5   4 \n",
      "[-0.37817383  0.21875     0.37597656  0.23730469 -0.30249023 -0.40356445] 2   5 \n",
      "[-0.58251953  0.21557617  0.18664551  0.25732422 -0.19641113 -0.16784668] 3   3 Match 71\n",
      "\n",
      "[-1.7587891  -0.14477539 -0.44750977  0.3972168   1.0205078   0.8803711 ] 4   5 \n",
      "[-1.6503906  -0.0703125  -0.2980957   0.6279297   1.1347656   0.86083984] 4   3 \n",
      "[-1.0351562   0.30810547  0.31152344  0.55029297  0.3564453  -0.01889038] 3   4 \n",
      "[-0.9589844   0.15112305  0.2602539   0.5864258   0.28100586 -0.11407471] 3   4 \n",
      "[-1.4179688   0.23474121 -0.13378906  0.40649414  0.671875    0.6533203 ] 4   1 \n",
      "[-1.4033203  -0.0160675   0.00618362  0.93066406  0.7402344   0.3708496 ] 3   1 \n",
      "[-0.47705078  0.2590332   0.18933105  0.26708984 -0.13977051 -0.12597656] 3   2 \n",
      "[-1.1894531   0.22436523  0.02151489  0.69677734  0.63134766  0.29296875] 3   4 \n",
      "[-0.51416016  0.16003418  0.24865723  0.38842773 -0.00737381 -0.30908203] 3   3 Match 72\n",
      "\n",
      "[-0.38476562  0.59814453  0.06945801 -0.4243164  -0.19494629  0.14001465] 1   2 \n",
      "[-0.6459961   0.44604492  0.16003418  0.06384277  0.10028076  0.24121094] 1   0 \n",
      "[-1.1308594   0.36206055  0.09118652  0.5449219   0.48046875 -0.05395508] 3   5 \n",
      "[-1.453125    0.21643066 -0.20690918  0.38061523  0.7788086   0.7919922 ] 5   1 \n",
      "[-0.25341797  0.21350098  0.24328613  0.12902832 -0.3486328  -0.30737305] 2   2 Match 73\n",
      "\n",
      "[-1.4599609   0.22094727 -0.19848633  0.6303711   0.9321289   0.6796875 ] 4   1 \n",
      "[-1.3515625  -0.02313232 -0.13830566  0.8955078   0.5541992   0.12414551] 3   5 \n",
      "[-0.7011719   0.39770508  0.22338867  0.05819702  0.23156738  0.39990234] 5   3 \n",
      "[ 0.3449707   0.40698242  0.31176758 -0.2998047  -0.7109375  -0.44213867] 1   1 Match 74\n",
      "\n",
      "[-1.4375      0.07952881 -0.13049316  0.49194336  0.8779297   0.8417969 ] 4   4 Match 75\n",
      "\n",
      "[-0.46484375  0.25561523  0.28710938  0.39624023 -0.20239258 -0.5102539 ] 3   4 \n",
      "[-0.05667114  0.2800293   0.35742188  0.08221436 -0.45239258 -0.4326172 ] 2   3 \n",
      "[-0.29516602  0.4248047   0.24963379  0.11010742 -0.26611328 -0.28808594] 1   0 \n",
      "[-1.2480469   0.06219482 -0.03366089  0.85498047  0.69677734  0.26220703] 3   3 Match 76\n",
      "\n",
      "[-0.4621582  -0.08740234  0.28881836  0.8730469  -0.11853027 -0.5859375 ] 3   2 \n",
      "[-0.20031738  0.25268555  0.42749023  0.2841797  -0.40893555 -0.47680664] 2   4 \n",
      "[ 0.39794922  0.24841309  0.3486328  -0.05279541 -0.7011719  -0.7167969 ] 0   0 Match 77\n",
      "\n",
      "[-0.79052734  0.3100586   0.20349121  0.42895508  0.09014893 -0.171875  ] 3   2 \n",
      "[-0.63623047  0.28271484  0.15942383  0.24023438  0.01176453 -0.04696655] 1   2 \n",
      "[ 0.43652344  0.21374512  0.2397461  -0.04141235 -0.7504883  -0.95947266] 0   2 \n",
      "[-1.3242188   0.05935669  0.0140686   0.52246094  0.8256836   0.53759766] 4   3 \n",
      "[-0.51416016  0.13452148  0.20751953  0.2878418   0.0176239  -0.15820312] 3   5 \n",
      "[-0.71435547  0.03823853  0.2668457   0.62890625  0.07843018 -0.21142578] 3   2 \n",
      "[-1.2802734  -0.1619873   0.06280518  1.1357422   0.6425781   0.00466919] 3   3 Match 78\n",
      "\n",
      "[-0.34179688  0.02531433  0.14074707  0.60546875 -0.10845947 -0.36669922] 3   3 Match 79\n",
      "\n",
      "[-0.10864258  0.32470703  0.39624023  0.04571533 -0.36791992 -0.33984375] 2   3 \n",
      "[-0.6694336   0.27270508  0.2208252   0.1772461  -0.00666428 -0.1439209 ] 1   3 \n",
      "[-0.2487793   0.3720703   0.30932617 -0.01387787 -0.3310547  -0.19555664] 1   1 Match 80\n",
      "\n",
      "[-0.3293457   0.55126953 -0.02653503 -0.4338379  -0.12670898  0.10388184] 1   3 \n",
      "[-0.7055664   0.4177246   0.09777832  0.03439331  0.1973877   0.29956055] 1   5 \n",
      "[-1.0224609   0.17041016  0.18603516  0.95166016  0.3227539  -0.2602539 ] 3   1 \n",
      "[-1.0761719   0.25585938  0.10552979  0.6088867   0.3779297   0.20031738] 3   5 \n",
      "[-1.5791016  -0.08306885 -0.19348145  0.8100586   1.0166016   0.6064453 ] 4   1 \n",
      "[-1.4697266  -0.18676758 -0.11456299  1.0458984   1.0273438   0.5644531 ] 3   3 Match 81\n",
      "\n",
      "[-1.3994141   0.12585449 -0.10498047  0.5209961   0.921875    0.67285156] 4   4 Match 82\n",
      "\n",
      "[-0.46826172  0.3400879   0.2775879   0.21069336 -0.16772461 -0.12609863] 1   2 \n",
      "[-0.99609375  0.33544922  0.14074707  0.5917969   0.29467773  0.01902771] 3   4 \n",
      "[-0.16296387  0.48950195  0.1899414  -0.12219238 -0.3466797  -0.1574707 ] 1   1 Match 83\n",
      "\n",
      "[-1.6757812  -0.11010742 -0.38745117  0.47558594  1.0800781   0.8857422 ] 4   4 Match 84\n",
      "\n",
      "[-0.05725098  0.39794922  0.2758789  -0.11761475 -0.55810547 -0.50097656] 1   1 Match 85\n",
      "\n",
      "[-0.51904297  0.31958008  0.37451172  0.32983398 -0.2088623  -0.4855957 ] 2   2 Match 86\n",
      "\n",
      "[ 0.09973145  0.25952148  0.38867188  0.09851074 -0.5883789  -0.68603516] 2   0 \n",
      "[-1.2099609   0.14465332 -0.06222534  0.67626953  0.65527344  0.3864746 ] 3   5 \n",
      "[-0.07489014  0.52246094  0.19665527 -0.22094727 -0.4650879  -0.36450195] 1   2 \n",
      "[-0.1003418   0.12304688  0.08251953  0.07434082 -0.4248047  -0.27514648] 1   3 \n",
      "[-0.06677246  0.25634766  0.15710449  0.12524414 -0.38232422 -0.5019531 ] 1   0 \n",
      "[-1.515625    0.24145508 -0.17138672  0.47265625  0.90283203  0.6430664 ] 4   3 \n",
      "[-0.08447266  0.47729492  0.1586914  -0.29370117 -0.32666016 -0.08361816] 1   5 \n",
      "[ 0.20629883  0.27197266  0.3774414  -0.06054688 -0.5830078  -0.5205078 ] 2   5 \n",
      "[ 0.17492676  0.3947754   0.28833008 -0.11828613 -0.5444336  -0.35766602] 1   2 \n",
      "[-0.00842285  0.3359375   0.2841797  -0.01008606 -0.5102539  -0.43701172] 1   2 \n",
      "[-1.0400391   0.265625    0.0012064   0.24316406  0.5073242   0.38061523] 4   1 \n",
      "[-0.68115234  0.44555664  0.28100586  0.14807129  0.00422287 -0.10015869] 1   2 \n",
      "[-0.11004639  0.24536133  0.21826172  0.10498047 -0.43164062 -0.35107422] 1   2 \n",
      "[-1.6972656  -0.22558594 -0.2824707   0.6225586   1.1533203   0.8769531 ] 4   3 \n",
      "[-1.5771484  -0.40014648 -0.21508789  0.66552734  1.0664062   0.7939453 ] 4   3 \n",
      "[ 0.06378174  0.33862305  0.30566406  0.02285767 -0.5053711  -0.37304688] 1   3 \n",
      "[ 0.15539551  0.21960449  0.24389648  0.06793213 -0.5917969  -0.7651367 ] 2   3 \n",
      "[-0.54589844  0.23266602  0.30004883  0.43139648 -0.10357666 -0.48168945] 3   2 \n",
      "[-1.3720703   0.06213379 -0.1307373   0.86328125  0.78466797  0.3503418 ] 3   0 \n",
      "[-0.5175781  -0.02598572  0.1920166   0.6826172   0.09838867 -0.15515137] 3   3 Match 87\n",
      "\n",
      "[-0.35986328  0.40966797  0.27172852 -0.00220108 -0.1381836  -0.14038086] 1   2 \n",
      "[-0.6699219  -0.02053833  0.06774902  0.5415039   0.08526611  0.02017212] 3   4 \n",
      "[-7.2509766e-01  1.1116266e-04  2.5830078e-01  7.7050781e-01\n",
      "  7.5744629e-02 -2.9101562e-01] 3   4 \n",
      "[-0.11022949  0.38208008  0.22937012  0.01558685 -0.39624023 -0.30322266] 1   1 Match 88\n",
      "\n",
      "[ 0.15429688  0.39672852  0.3737793  -0.10601807 -0.48828125 -0.3112793 ] 1   2 \n",
      "[-1.2246094   0.09320068  0.09552002  0.66015625  0.62939453  0.41455078] 3   0 \n",
      "[-0.2064209   0.51464844  0.1418457  -0.25708008 -0.32885742 -0.16638184] 1   5 \n",
      "[ 0.08624268  0.40185547  0.28173828 -0.0758667  -0.5385742  -0.44580078] 1   4 \n",
      "[-1.5927734  -0.13391113 -0.3630371   0.4716797   0.8574219   0.85839844] 5   4 \n",
      "[-1.5292969   0.09753418 -0.13793945  0.50390625  0.7939453   0.72216797] 4   2 \n",
      "[-0.04971313  0.47875977 -0.00972748 -0.42456055 -0.43676758 -0.17382812] 1   1 Match 89\n",
      "\n",
      "[-0.52246094  0.41845703  0.01704407 -0.15429688 -0.02108765 -0.11987305] 1   5 \n",
      "[-1.5527344  -0.13842773 -0.39941406  0.45751953  1.0742188   1.0175781 ] 4   1 \n",
      "[-1.6503906  -0.3798828  -0.33984375  0.83203125  1.2460938   0.7338867 ] 4   4 Match 90\n",
      "\n",
      "[-1.3876953   0.2980957  -0.07727051  0.3564453   1.0292969   0.5756836 ] 4   3 \n",
      "[-0.13354492  0.47827148  0.1270752  -0.23364258 -0.34326172  0.04324341] 1   1 Match 91\n",
      "\n",
      "[-0.05133057  0.12976074  0.38891602  0.32958984 -0.43798828 -0.74365234] 2   3 \n",
      "[-1.1855469   0.21716309  0.22692871  0.65527344  0.44018555  0.05065918] 3   3 Match 92\n",
      "\n",
      "[-0.68896484  0.25634766  0.29223633  0.6044922   0.05685425 -0.2697754 ] 3   2 \n",
      "[ 0.12597656  0.2939453   0.42285156  0.00596619 -0.47094727 -0.328125  ] 2   1 \n",
      "[-0.81103516  0.16638184  0.2746582   0.7055664   0.12585449 -0.21594238] 3   2 \n",
      "[-0.08056641  0.44067383  0.25268555 -0.07183838 -0.44482422 -0.3942871 ] 1   1 Match 93\n",
      "\n",
      "[-1.6308594  -0.12219238 -0.38330078  0.30688477  0.9794922   1.1064453 ] 5   5 Match 94\n",
      "\n",
      "[-0.9375      0.16699219  0.35131836  0.57714844  0.2512207  -0.22875977] 3   2 \n",
      "[-0.5917969   0.25756836  0.21447754  0.38549805 -0.03485107 -0.32861328] 3   2 \n",
      "[-0.4477539   0.39941406  0.37963867  0.42211914 -0.14929199 -0.48168945] 3   2 \n",
      "[-1.6269531  -0.13586426 -0.12731934  0.82421875  0.99072266  0.82910156] 4   4 Match 95\n",
      "\n",
      "[-0.48339844  0.28979492  0.28979492  0.27563477 -0.17248535 -0.31347656] 1   1 Match 96\n",
      "\n",
      "[-0.94628906  0.18847656  0.1574707   0.71972656  0.4086914  -0.12322998] 3   4 \n",
      "[-0.7792969   0.44995117  0.08111572  0.14196777  0.28125     0.10015869] 1   3 \n",
      "[-1.453125    0.02653503 -0.31640625  0.14123535  0.95654297  1.0234375 ] 5   5 Match 97\n",
      "\n",
      "[-1.5830078   0.05526733 -0.2088623   0.8222656   1.0185547   0.6699219 ] 4   3 \n",
      "[-1.0527344   0.27148438  0.02426147  0.18273926  0.46069336  0.5336914 ] 5   2 \n",
      "[-0.6044922  -0.08422852  0.14807129  0.25048828 -0.09759521 -0.2565918 ] 3   2 \n",
      "[-0.90478516  0.31640625  0.13183594  0.35668945  0.22167969 -0.07006836] 3   1 \n",
      "[-1.2099609   0.22766113  0.00579071  0.7392578   0.5883789   0.12335205] 3   1 \n",
      "[-1.5556641   0.02626038 -0.22570801  0.59472656  0.82910156  0.8198242 ] 4   5 \n",
      "[-1.0654297   0.36791992  0.06066895  0.54833984  0.44750977 -0.02377319] 3   3 Match 98\n",
      "\n",
      "[-0.22229004  0.3942871   0.21374512  0.03726196 -0.30444336 -0.28564453] 1   2 \n",
      "[ 0.22241211  0.32958984  0.24584961 -0.06069946 -0.6508789  -0.6123047 ] 1   0 \n",
      "[-1.3271484  -0.01713562 -0.04473877  0.8959961   0.62890625  0.48266602] 3   3 Match 99\n",
      "\n",
      "[-0.40039062  0.2758789   0.24804688 -0.00353432 -0.24975586 -0.05255127] 1   2 \n",
      "[-1.1484375   0.20300293  0.10186768  0.8901367   0.48608398 -0.04818726] 3   1 \n",
      "[-1.6171875  -0.12841797 -0.2746582   0.7758789   1.0058594   0.6801758 ] 4   2 \n",
      "[-0.8461914   0.1541748   0.15771484  0.71191406  0.3173828  -0.1315918 ] 3   3 Match 100\n",
      "\n",
      "[-0.38110352  0.3503418   0.34692383  0.1352539  -0.26904297 -0.20959473] 1   3 \n",
      "[-1.6552734   0.0244751  -0.38598633  0.31933594  0.87158203  0.8676758 ] 4   2 \n",
      "[-1.3134766   0.09893799  0.07696533  0.9038086   0.66748047  0.11523438] 3   4 \n",
      "[-0.41333008  0.40771484  0.23999023  0.01033783 -0.15649414  0.01189423] 1   1 Match 101\n",
      "\n",
      "[-0.44335938  0.36889648  0.22302246  0.3466797  -0.02867126 -0.01832581] 1   3 \n",
      "[-1.5429688  -0.42236328 -0.18786621  0.7080078   1.2617188   0.8486328 ] 4   3 \n",
      "[-0.43725586  0.38745117  0.1998291   0.02160645 -0.17700195 -0.11334229] 1   1 Match 102\n",
      "\n",
      "[-1.2167969   0.08074951  0.1005249   0.8701172   0.35668945 -0.0793457 ] 3   1 \n",
      "[-1.0947266  -0.18847656  0.2019043   1.0097656   0.53271484 -0.01628113] 3   0 \n",
      "[-1.1689453   0.18737793 -0.02377319  0.39990234  0.7294922   0.3762207 ] 4   1 \n",
      "[-0.29174805  0.24157715  0.28198242  0.17944336 -0.2697754  -0.28076172] 2   0 \n",
      "[-1.5625     -0.11895752 -0.16845703  0.91552734  0.890625    0.5996094 ] 3   0 \n",
      "[-0.47827148  0.45288086  0.11645508  0.01829529 -0.08746338 -0.22033691] 1   2 \n",
      "[-1.5996094  -0.3388672  -0.15148926  0.90722656  1.0380859   0.8720703 ] 4   0 \n",
      "[ 0.14172363  0.36279297  0.30297852 -0.05996704 -0.5522461  -0.14550781] 1   0 \n",
      "[-1.0908203   0.17614746  0.23962402  0.7807617   0.45288086 -0.03482056] 3   1 \n",
      "[-1.4394531  -0.02003479 -0.14013672  0.7788086   0.9970703   0.6699219 ] 4   1 \n",
      "[-1.4375      0.15734863 -0.09625244  0.5234375   0.8774414   0.6894531 ] 4   5 \n",
      "[-0.8540039   0.31591797  0.328125    0.6308594   0.15136719 -0.13110352] 3   3 Match 103\n",
      "\n",
      "[-1.4160156   0.1616211  -0.02127075  0.6381836   0.86035156  0.5229492 ] 4   3 \n",
      "[-0.40942383  0.4038086   0.22595215  0.11157227 -0.16235352 -0.29858398] 1   2 \n",
      "[-0.72998047  0.29052734  0.27294922  0.34716797  0.08374023 -0.24804688] 3   2 \n",
      "[-1.171875    0.10070801  0.07537842  0.8046875   0.35839844  0.02905273] 3   4 \n",
      "[-0.5410156   0.29589844  0.24853516  0.3569336  -0.06164551 -0.35009766] 3   2 \n",
      "[-0.62060547  0.3894043   0.12768555  0.10968018  0.14172363  0.12939453] 1   2 \n",
      "[-1.5244141  -0.02438354 -0.1071167   0.9736328   0.7480469   0.3005371 ] 3   5 \n",
      "[ 0.21813965  0.36010742  0.32788086 -0.15808105 -0.6767578  -0.35375977] 1   1 Match 104\n",
      "\n",
      "[ 0.0088501   0.2890625   0.25512695  0.02810669 -0.37304688 -0.42871094] 1   1 Match 105\n",
      "\n",
      "[-0.10632324  0.1628418   0.39819336  0.32006836 -0.27734375 -0.60791016] 2   2 Match 106\n",
      "\n",
      "[-1.3408203   0.26342773 -0.09368896  0.58251953  0.79541016  0.21850586] 4   3 \n",
      "[-0.02401733  0.37768555  0.2590332  -0.00648499 -0.5019531  -0.58740234] 1   0 \n",
      "[-1.0419922   0.24609375  0.01568604  0.3552246   0.48779297  0.29638672] 4   5 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.16625977  0.5288086   0.34960938 -0.2697754  -0.43774414  0.0166626 ] 1   4 \n",
      "[-0.33325195  0.15014648  0.26049805  0.35180664 -0.21508789 -0.5126953 ] 3   3 Match 107\n",
      "\n",
      "[-0.72021484  0.33520508  0.26293945  0.3017578   0.01560974 -0.25195312] 1   5 \n",
      "[-0.48217773  0.19824219  0.3474121   0.49194336 -0.10888672 -0.40161133] 3   4 \n",
      "[-1.5673828  -0.15185547 -0.27270508  0.5371094   1.0166016   0.9296875 ] 4   5 \n",
      "[-0.16320801  0.22460938  0.30200195  0.12054443 -0.4609375  -0.47729492] 2   0 \n",
      "[-1.0175781   0.34375     0.13623047  0.5600586   0.3305664  -0.09289551] 3   4 \n",
      "[-1.7392578  -0.16125488 -0.44458008  0.83935547  1.1386719   0.71972656] 4   5 \n",
      "[ 0.14916992  0.3479004   0.18237305 -0.14587402 -0.57373047 -0.5336914 ] 1   4 \n",
      "[-0.60791016  0.38232422  0.20507812  0.09613037  0.00637054  0.20239258] 1   3 \n",
      "[-0.01229095  0.39672852  0.24414062 -0.10919189 -0.42773438 -0.20031738] 1   2 \n",
      "[-1.4570312   0.07067871 -0.14807129  0.71533203  0.8803711   0.7192383 ] 4   4 Match 108\n",
      "\n",
      "[-0.70996094 -0.03863525  0.17797852  0.7114258   0.00935364 -0.22741699] 3   2 \n",
      "[-1.4042969   0.08148193 -0.03417969  0.9370117   0.7939453   0.11962891] 3   2 \n",
      "[-1.5419922  -0.12524414 -0.33129883  0.4140625   0.97998047  0.99121094] 5   5 Match 109\n",
      "\n",
      "[-1.5625     -0.18432617 -0.09869385  0.9350586   0.8149414   0.5234375 ] 3   4 \n",
      "[ 0.18896484  0.30566406  0.34814453 -0.1418457  -0.5996094  -0.35302734] 2   3 \n",
      "[-0.05303955  0.32104492  0.24401855  0.10314941 -0.4489746  -0.5541992 ] 1   1 Match 110\n",
      "\n",
      "[-0.15649414  0.56103516  0.11474609 -0.27075195 -0.40551758 -0.1303711 ] 1   2 \n",
      "[-1.4892578  -0.00724411 -0.15808105  0.7963867   1.0458984   0.67041016] 4   3 \n",
      "[-1.5117188   0.14208984 -0.26831055  0.32983398  0.6542969   1.0078125 ] 5   3 \n",
      "[-1.5302734  -0.20471191 -0.37548828  0.3659668   0.99658203  0.91259766] 4   3 \n",
      "[-1.3339844   0.17150879 -0.0430603   0.78564453  0.7915039   0.3503418 ] 4   4 Match 111\n",
      "\n",
      "[-1.1630859   0.19091797  0.1550293   0.71435547  0.5566406   0.05307007] 3   5 \n",
      "[-0.27075195  0.27978516  0.1821289   0.24780273 -0.20800781 -0.41064453] 1   2 \n",
      "[-0.10162354  0.1821289   0.47485352  0.28833008 -0.42993164 -0.59765625] 2   0 \n",
      "[-1.3925781   0.10345459 -0.13427734  0.6010742   0.9765625   0.42382812] 4   1 \n",
      "[-1.578125   -0.20544434 -0.2553711   0.76171875  1.1523438   0.79833984] 4   2 \n",
      "[-1.4472656  -0.08624268 -0.03479004  1.1044922   0.9057617   0.5175781 ] 3   2 \n",
      "[-0.30395508  0.43017578  0.28564453 -0.06063843 -0.296875   -0.10900879] 1   0 \n",
      "[-0.11938477  0.30932617  0.21374512 -0.06256104 -0.40283203 -0.3269043 ] 1   0 \n",
      "[-0.02461243  0.64208984  0.24914551 -0.35668945 -0.32592773  0.2208252 ] 1   1 Match 112\n",
      "\n",
      "[-1.2158203   0.17346191  0.14123535  0.8100586   0.56152344  0.14453125] 3   5 \n",
      "[-1.3378906   0.3720703  -0.1126709   0.35180664  0.7338867   0.5415039 ] 4   5 \n",
      "[-1.5761719   0.10137939 -0.16601562  0.75390625  0.93359375  0.5463867 ] 4   5 \n",
      "[-0.2512207   0.11669922  0.41625977  0.47998047 -0.32763672 -0.6328125 ] 3   2 \n",
      "[ 0.24987793  0.28295898  0.2006836  -0.1005249  -0.5317383  -0.69189453] 1   3 \n",
      "[-0.21948242  0.52001953  0.2722168  -0.26171875 -0.26220703  0.10498047] 1   3 \n",
      "[-1.5830078  -0.06201172 -0.27392578  0.6381836   0.93066406  0.8222656 ] 4   4 Match 113\n",
      "\n",
      "[-1.4628906  -0.10723877 -0.09075928  0.91259766  0.89404297  0.68847656] 3   4 \n",
      "[-0.81884766  0.13842773  0.2619629   0.6611328   0.24975586 -0.2631836 ] 3   3 Match 114\n",
      "\n",
      "[-0.46606445  0.25268555  0.2253418   0.24804688 -0.12261963 -0.36914062] 1   5 \n",
      "[ 0.12432861  0.48950195  0.28515625 -0.24121094 -0.58691406 -0.32421875] 1   2 \n",
      "[-1.0664062   0.3215332   0.04052734  0.31298828  0.40234375  0.36865234] 4   3 \n",
      "[-1.4208984  -0.16809082  0.04870605  1.0800781   1.          0.578125  ] 3   4 \n",
      "[-0.35498047  0.15466309  0.39379883  0.5107422  -0.2722168  -0.6074219 ] 3   2 \n",
      "[-0.31811523  0.47094727  0.04904175 -0.29589844 -0.25146484  0.06817627] 1   5 \n",
      "[-0.13769531  0.1694336   0.14807129  0.33862305 -0.31445312 -0.5209961 ] 3   5 \n",
      "[-1.2529297   0.42773438 -0.04000854  0.34692383  0.72021484  0.45947266] 4   2 \n",
      "[-0.76904297  0.36889648  0.1940918   0.32177734  0.07049561 -0.14257812] 1   3 \n",
      "[-0.50927734  0.06051636  0.1138916   0.42700195 -0.02516174 -0.15283203] 3   1 \n",
      "[-1.4980469  -0.18774414 -0.35620117  0.5727539   1.0263672   0.8847656 ] 4   5 \n",
      "[-1.1181641   0.19482422  0.1784668   0.9272461   0.4572754  -0.11151123] 3   3 Match 115\n",
      "\n",
      "[-1.3310547  -0.14050293  0.02586365  1.1992188   0.79541016  0.38989258] 3   4 \n",
      "[-0.5185547   0.5283203   0.13330078 -0.09039307 -0.11346436 -0.03344727] 1   2 \n",
      "[-1.3857422   0.31762695 -0.06964111  0.26171875  0.5473633   0.7988281 ] 5   4 \n",
      "[-0.02908325  0.35058594  0.28271484 -0.07537842 -0.53027344 -0.45825195] 1   2 \n",
      "[-1.6025391  -0.32763672 -0.34228516  0.73535156  1.1289062   0.7519531 ] 4   5 \n",
      "[-1.5458984   0.06750488 -0.24121094  0.5292969   0.95166016  0.7504883 ] 4   3 \n",
      "[ 0.02290344  0.40112305  0.23413086 -0.09143066 -0.43164062 -0.15332031] 1   1 Match 116\n",
      "\n",
      "[-0.19494629  0.16503906  0.2626953   0.3623047  -0.24719238 -0.52978516] 3   3 Match 117\n",
      "\n",
      "[-0.0546875   0.27246094  0.2286377   0.27490234 -0.38867188 -0.47802734] 3   4 \n",
      "[-1.0917969   0.2524414   0.10656738  0.63427734  0.3461914  -0.17492676] 3   5 \n",
      "[-1.5029297  -0.41967773 -0.2841797   0.59521484  1.0107422   0.7104492 ] 4   3 \n",
      "[-0.36132812  0.40893555  0.12915039 -0.01651001 -0.1496582  -0.19299316] 1   5 \n",
      "[-0.44702148  0.2902832   0.29418945  0.16833496 -0.1673584  -0.17492676] 2   3 \n",
      "[-0.63183594  0.19396973  0.35717773  0.3786621  -0.11706543 -0.29345703] 3   5 \n",
      "[-0.6308594   0.14868164 -0.0276947   0.32373047  0.09680176  0.05187988] 3   4 \n",
      "[-0.63378906  0.31469727  0.20361328  0.06518555 -0.05627441  0.06982422] 1   3 \n",
      "[-0.6660156   0.30639648  0.09454346  0.18640137  0.03034973  0.30249023] 1   5 \n",
      "[-0.39282227  0.4296875   0.25878906  0.12878418 -0.15930176 -0.20214844] 1   3 \n",
      "[-0.86816406  0.2553711   0.2524414   0.6542969   0.10223389 -0.42041016] 3   2 \n",
      "[-0.5883789   0.14367676  0.21276855  0.58154297  0.05361938 -0.33374023] 3   2 \n",
      "[-0.26342773  0.25708008  0.24267578  0.25341797 -0.1899414  -0.26293945] 1   2 \n",
      "[-0.578125    0.32373047  0.19152832  0.30664062 -0.11437988 -0.3059082 ] 1   1 Match 118\n",
      "\n",
      "[-1.3710938  -0.15930176 -0.03970337  1.09375     0.9819336   0.5888672 ] 3   4 \n",
      "[-0.00424576  0.2944336   0.25585938 -0.01776123 -0.46801758 -0.40161133] 1   2 \n",
      "[-1.5234375  -0.04602051 -0.32666016  0.5175781   0.984375    0.7524414 ] 4   1 \n",
      "[-0.70214844  0.3076172   0.12481689  0.38623047  0.10772705 -0.17163086] 3   5 \n",
      "[-1.6601562  -0.13415527 -0.4621582   0.41479492  1.1113281   0.8828125 ] 4   3 \n",
      "[-0.984375    0.2244873   0.2376709   0.80078125  0.4272461  -0.07507324] 3   3 Match 119\n",
      "\n",
      "[-1.0703125   0.47998047 -0.01213074  0.20092773  0.5991211   0.52441406] 4   2 \n",
      "[-1.5224609  -0.06665039 -0.22937012  0.7011719   1.0517578   0.5654297 ] 4   3 \n",
      "[-0.01907349 -0.15686035 -0.4091797  -0.02244568 -0.6274414  -0.8881836 ] 0   5 \n",
      "[-0.33618164  0.41674805  0.28955078  0.02590942 -0.21887207 -0.04598999] 1   4 \n",
      "[-1.1210938   0.19763184  0.20776367  0.82373047  0.52441406  0.01911926] 3   5 \n",
      "[-1.4472656   0.19030762 -0.06713867  0.5722656   0.8378906   0.66064453] 4   2 \n",
      "[-0.3552246   0.17297363  0.40307617  0.43774414 -0.26220703 -0.5751953 ] 3   5 \n",
      "[ 0.15490723  0.26220703  0.3322754   0.04898071 -0.6064453  -0.5288086 ] 2   3 \n",
      "[-0.47558594  0.4572754   0.27514648  0.04040527 -0.0369873   0.00439072] 1   4 \n",
      "[ 0.02035522  0.41845703  0.36499023 -0.11364746 -0.50439453 -0.29882812] 1   3 \n",
      "[-0.13427734  0.39868164  0.33911133 -0.17041016 -0.27954102 -0.29101562] 1   2 \n",
      "[-0.26367188  0.24572754  0.26513672  0.22424316 -0.32421875 -0.609375  ] 2   5 \n",
      "[-0.05462646  0.25341797  0.38085938  0.13586426 -0.46704102 -0.5444336 ] 2   3 \n",
      "[-1.2509766   0.01693726 -0.1427002   0.38842773  0.47387695  0.6879883 ] 5   3 \n",
      "[-0.40820312 -0.1459961   0.26220703  0.6738281  -0.11254883 -0.33422852] 3   2 \n",
      "[-1.2216797   0.37158203 -0.18640137  0.15332031  0.62109375  0.67333984] 5   0 \n",
      "[-0.17077637  0.41137695  0.32592773 -0.03884888 -0.3227539  -0.31176758] 1   4 \n",
      "[-0.8442383   0.1973877   0.29785156  0.6333008   0.15979004 -0.12841797] 3   4 \n",
      "[-1.109375    0.2454834   0.01646423  0.41455078  0.6035156   0.47558594] 4   4 Match 120\n",
      "\n",
      "[-0.6245117   0.56152344  0.12347412 -0.19213867  0.21484375  0.5336914 ] 1   1 Match 121\n",
      "\n",
      "[-1.6044922  -0.35620117 -0.25219727  0.61376953  1.1308594   0.84375   ] 4   3 \n",
      "[-0.5         0.46948242  0.11541748 -0.06732178 -0.17883301  0.13781738] 1   1 Match 122\n",
      "\n",
      "[-0.80908203  0.53027344 -0.04269409 -0.18530273  0.28393555  0.55908203] 5   5 Match 123\n",
      "\n",
      "[-1.5664062  -0.03259277 -0.10479736  0.87597656  0.80078125  0.4362793 ] 3   3 Match 124\n",
      "\n",
      "[-1.0429688   0.45385742 -0.01499939  0.1237793   0.48999023  0.31298828] 4   1 \n",
      "[-0.40234375  0.3022461   0.21032715  0.14953613 -0.12011719 -0.03031921] 1   2 \n",
      "[-1.2509766   0.1772461   0.29785156  0.7416992   0.46850586  0.11383057] 3   5 \n",
      "[-0.9716797   0.25634766  0.09344482  0.53759766  0.21508789  0.06057739] 3   3 Match 125\n",
      "\n",
      "[-1.0341797   0.3552246  -0.06884766  0.19946289  0.28320312  0.3737793 ] 5   5 Match 126\n",
      "\n",
      "[-1.6728516  -0.11157227 -0.21911621  0.6972656   1.0576172   0.9291992 ] 4   5 \n",
      "[-1.7011719  -0.10900879 -0.16687012  0.81884766  1.1181641   0.71191406] 4   5 \n",
      "[-0.27001953  0.2631836   0.26708984  0.26464844 -0.27807617 -0.42749023] 2   1 \n",
      "[ 0.04537964  0.43066406  0.2758789  -0.06069946 -0.45214844 -0.47216797] 1   4 \n",
      "[-1.2841797   0.14526367  0.19177246  0.77441406  0.6459961   0.13806152] 3   1 \n",
      "[-1.4667969   0.10723877 -0.12976074  0.5283203   0.87890625  0.62841797] 4   4 Match 127\n",
      "\n",
      "[-1.7099609  -0.09350586 -0.23864746  0.6508789   0.98339844  0.61083984] 4   5 \n",
      "[-1.5566406  -0.23339844 -0.13122559  0.8515625   1.0703125   0.82128906] 4   2 \n",
      "[-1.6484375  -0.14526367 -0.27270508  0.6582031   0.9433594   0.8251953 ] 4   4 Match 128\n",
      "\n",
      "[-0.25268555  0.26000977  0.26171875  0.17004395 -0.27905273 -0.359375  ] 2   4 \n",
      "[-1.4433594  -0.21813965 -0.16430664  0.85302734  0.82958984  0.76220703] 3   5 \n",
      "[-1.3261719   0.16174316  0.01837158  0.75927734  0.69091797  0.5410156 ] 3   4 \n",
      "[-1.4179688   0.05245972 -0.06469727  0.75927734  0.91308594  0.54248047] 4   4 Match 129\n",
      "\n",
      "[-0.8173828   0.15258789  0.3137207   0.7832031   0.12890625 -0.3232422 ] 3   2 \n",
      "[-1.5224609  -0.04852295 -0.1685791   0.90185547  0.9716797   0.7373047 ] 4   4 Match 130\n",
      "\n",
      "[-1.6494141  -0.18383789 -0.34448242  0.5800781   1.0195312   0.859375  ] 4   4 Match 131\n",
      "\n",
      "[-1.296875    0.15185547 -0.04241943  0.7314453   0.7036133   0.33520508] 3   3 Match 132\n",
      "\n",
      "[-0.6933594   0.5810547   0.07543945 -0.16687012 -0.04763794  0.14099121] 1   4 \n",
      "[-0.0267334   0.5444336   0.26367188 -0.31176758 -0.36767578 -0.02516174] 1   4 \n",
      "[-1.0136719   0.2421875   0.20092773  0.6357422   0.36547852  0.03640747] 3   3 Match 133\n",
      "\n",
      "[-1.65625    -0.16882324 -0.27490234  0.8491211   1.0878906   0.81152344] 4   1 \n",
      "[-1.3251953   0.06750488  0.01079559  0.70703125  0.83203125  0.43920898] 4   1 \n",
      "[-1.4638672  -0.02824402 -0.05789185  0.87646484  0.9316406   0.3569336 ] 4   4 Match 134\n",
      "\n",
      "[-0.5786133   0.16918945  0.24230957  0.5859375  -0.05484009 -0.5527344 ] 3   4 \n",
      "[-0.64990234  0.49560547  0.18078613 -0.10540771  0.01020813  0.16516113] 1   1 Match 135\n",
      "\n",
      "[-0.51220703  0.5761719   0.24743652 -0.10803223  0.00449753  0.1817627 ] 1   1 Match 136\n",
      "\n",
      "[-1.4375     -0.359375   -0.10321045  0.94384766  0.97998047  0.7915039 ] 4   4 Match 137\n",
      "\n",
      "[-1.5566406   0.01646423 -0.18859863  0.7988281   1.0380859   0.69970703] 4   4 Match 138\n",
      "\n",
      "[-0.08569336  0.33911133  0.2607422  -0.00778198 -0.4465332  -0.4892578 ] 1   0 \n",
      "[ 0.23742676  0.3486328   0.23815918 -0.10070801 -0.6015625  -0.65234375] 1   0 \n",
      "[ 0.3803711   0.40551758  0.29101562 -0.23730469 -0.6826172  -0.4729004 ] 1   2 \n",
      "[-1.6210938  -0.00842285 -0.25756836  0.5317383   0.9819336   0.81884766] 4   1 \n",
      "[-1.5976562  -0.02792358 -0.32910156  0.60546875  1.0449219   0.61621094] 4   1 \n",
      "[-1.4492188   0.07696533 -0.01499176  0.8017578   0.8071289   0.51171875] 4   4 Match 139\n",
      "\n",
      "[-1.4609375   0.02514648 -0.05386353  0.7558594   0.95654297  0.70751953] 4   3 \n",
      "[-0.9970703   0.33789062  0.17016602  0.29345703  0.39111328  0.19677734] 4   5 \n",
      "[-1.7119141  -0.25805664 -0.23339844  0.8022461   1.0537109   0.9165039 ] 4   4 Match 140\n",
      "\n",
      "[-1.0927734   0.4116211  -0.11859131  0.00680161  0.515625    0.87353516] 5   1 \n",
      "[-0.7626953   0.23413086  0.36889648  0.46264648  0.05752563 -0.17553711] 3   1 \n",
      "[-1.5791016  -0.14660645 -0.48413086  0.25683594  0.96191406  1.0078125 ] 5   5 Match 141\n",
      "\n",
      "[-0.09771729  0.4411621   0.31958008 -0.10375977 -0.32714844  0.04504395] 1   1 Match 142\n",
      "\n",
      "[-1.53125     0.11791992 -0.01406097  0.9814453   0.8330078   0.15270996] 3   5 \n",
      "[-1.515625    0.01849365 -0.32250977  0.13000488  0.8984375   1.015625  ] 5   4 \n",
      "[ 0.22363281  0.28564453  0.42260742 -0.02243042 -0.58984375 -0.42993164] 2   5 \n",
      "[-1.203125    0.2919922  -0.02827454  0.3166504   0.5004883   0.4387207 ] 4   5 \n",
      "[ 0.052948    0.26416016  0.3828125   0.07128906 -0.56689453 -0.5317383 ] 2   4 \n",
      "[-1.4365234   0.05609131 -0.20788574  0.6557617   0.87402344  0.71875   ] 4   4 Match 143\n",
      "\n",
      "[-0.30908203  0.29541016  0.16149902  0.12408447 -0.2142334  -0.28027344] 1   1 Match 144\n",
      "\n",
      "[ 0.01384735  0.36694336  0.22143555 -0.09796143 -0.4946289  -0.37060547] 1   4 \n",
      "[-0.00750732  0.46362305  0.33129883 -0.21081543 -0.55566406 -0.23059082] 1   2 \n",
      "[-1.1611328   0.296875    0.12634277  0.6254883   0.37573242 -0.09661865] 3   3 Match 145\n",
      "\n",
      "[-1.5458984   0.02833557 -0.2692871   0.50439453  0.94921875  0.97265625] 5   4 \n",
      "[-1.5341797  -0.04440308 -0.21826172  0.56689453  1.1240234   0.85253906] 4   4 Match 146\n",
      "\n",
      "[-1.3349609   0.27514648  0.07244873  0.69873047  0.87939453  0.31347656] 4   4 Match 147\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.93652344  0.3334961   0.05453491  0.27319336  0.28857422  0.203125  ] 1   1 Match 148\n",
      "\n",
      "[-1.5683594   0.24060059 -0.44604492  0.20654297  0.9428711   0.7602539 ] 4   4 Match 149\n",
      "\n",
      "[-0.9477539   0.2800293   0.12988281  0.35302734  0.32885742  0.23083496] 3   3 Match 150\n",
      "\n",
      "[-0.06048584  0.28295898  0.265625    0.06192017 -0.39770508 -0.46801758] 1   5 \n",
      "[-0.70751953  0.34375     0.10137939  0.35058594  0.06542969 -0.19616699] 3   1 \n",
      "[-1.0859375   0.22827148  0.21142578  0.6171875   0.37231445  0.007164  ] 3   3 Match 151\n",
      "\n",
      "[-0.1194458   0.51220703  0.21398926 -0.2211914  -0.4543457  -0.0189209 ] 1   3 \n",
      "[-0.59375     0.5932617   0.03277588 -0.25854492 -0.02330017  0.37231445] 1   5 \n",
      "[ 0.04257202  0.26171875  0.3815918   0.13244629 -0.50341797 -0.56591797] 2   2 Match 152\n",
      "\n",
      "[-0.21032715  0.13916016  0.30419922  0.34594727 -0.36279297 -0.56689453] 3   1 \n",
      "[-0.77978516  0.4206543  -0.04702759  0.00408554  0.08380127  0.23547363] 1   5 \n",
      "[-0.2788086   0.29663086  0.4404297   0.31054688 -0.25439453 -0.40625   ] 2   1 \n",
      "[-0.39453125  0.2775879   0.1706543   0.30908203 -0.17578125 -0.32495117] 3   5 \n",
      "[-1.0615234   0.36694336  0.15661621  0.40112305  0.34106445  0.07458496] 3   3 Match 153\n",
      "\n",
      "[-0.46264648  0.37451172  0.1706543   0.02947998 -0.01707458 -0.03933716] 1   1 Match 154\n",
      "\n",
      "[-0.5019531   0.26660156  0.32128906  0.39575195 -0.1352539  -0.5332031 ] 3   2 \n",
      "[-0.87402344  0.30688477  0.0085907   0.29296875  0.28710938  0.39111328] 5   1 \n",
      "[-0.81884766  0.2685547   0.21386719  0.45629883  0.17297363 -0.20910645] 3   3 Match 155\n",
      "\n",
      "[-0.20288086  0.47143555  0.21960449 -0.15014648 -0.35009766 -0.02702332] 1   1 Match 156\n",
      "\n",
      "[-7.8076172e-01  4.7729492e-01  9.8083496e-02 -6.0081482e-05\n",
      "  2.1972656e-01  4.8901367e-01] 5   5 Match 157\n",
      "\n",
      "[-1.0097656   0.24121094  0.13195801  0.41601562  0.44677734  0.15222168] 4   5 \n",
      "[-1.3310547   0.0406189  -0.19567871  0.56689453  0.8598633   0.60058594] 4   1 \n",
      "[-1.4658203   0.09259033 -0.17297363  0.5620117   0.75927734  0.64746094] 4   3 \n",
      "[-1.2421875   0.00590897  0.05929565  0.89501953  0.5942383   0.11968994] 3   3 Match 158\n",
      "\n",
      "[-1.5214844   0.11523438 -0.2133789   0.5830078   1.0332031   0.71435547] 4   4 Match 159\n",
      "\n",
      "[-0.828125    0.14685059  0.2878418   0.6621094   0.08874512 -0.3293457 ] 3   3 Match 160\n",
      "\n",
      "[-0.41625977  0.30395508  0.29736328  0.265625   -0.21716309 -0.39331055] 1   1 Match 161\n",
      "\n",
      "[-1.3515625   0.22875977 -0.17089844  0.3474121   0.7397461   0.91552734] 5   5 Match 162\n",
      "\n",
      "[-1.6142578  -0.01647949 -0.34423828  0.6660156   1.1689453   0.84228516] 4   2 \n",
      "[-1.5966797  -0.19274902 -0.42333984  0.5419922   0.9873047   0.81640625] 4   4 Match 163\n",
      "\n",
      "[-0.8520508   0.5493164  -0.02453613 -0.05505371  0.2454834   0.2902832 ] 1   5 \n",
      "[-0.48413086  0.25878906  0.18811035  0.48657227 -0.05386353 -0.43579102] 3   0 \n",
      "[-1.359375   -0.24291992 -0.0352478   1.0185547   0.83935547  0.3803711 ] 3   4 \n",
      "[ 0.2524414   0.4519043   0.24572754 -0.24816895 -0.6430664  -0.48291016] 1   4 \n",
      "[-0.28686523  0.2565918   0.26367188  0.22058105 -0.2607422  -0.37890625] 2   4 \n",
      "[-0.19934082  0.31030273  0.22180176  0.1484375  -0.29907227 -0.36132812] 1   3 \n",
      "[-0.93847656  0.3671875   0.22802734  0.51953125  0.2998047  -0.04800415] 3   4 \n",
      "[-0.890625    0.4243164   0.1875      0.515625    0.31933594 -0.17590332] 3   2 \n",
      "[-1.7128906  -0.20947266 -0.41088867  0.43701172  1.1357422   0.9169922 ] 4   5 \n",
      "[-0.4921875   0.11657715  0.27441406  0.6401367  -0.11547852 -0.47631836] 3   4 \n",
      "[-1.5888672  -0.02236938 -0.17858887  0.80126953  1.0195312   0.5761719 ] 4   5 \n",
      "[-1.6035156  -0.17736816 -0.37158203  0.33325195  0.9321289   0.8808594 ] 4   3 \n",
      "[-1.3466797   0.11889648 -0.01876831  0.5258789   0.7285156   0.47045898] 4   3 \n",
      "[-1.53125    -0.09417725 -0.3215332   0.56347656  1.0566406   0.92041016] 4   4 Match 164\n",
      "\n",
      "[-0.4819336   0.20837402  0.28295898  0.49414062 -0.13806152 -0.52685547] 3   3 Match 165\n",
      "\n",
      "[-0.5800781   0.21105957  0.3503418   0.58154297 -0.10534668 -0.4650879 ] 3   5 \n",
      "[-0.34057617  0.28955078  0.30908203  0.15734863 -0.14660645 -0.03747559] 2   5 \n",
      "[-0.23278809  0.08398438  0.30004883  0.37182617 -0.2602539  -0.30078125] 3   5 \n",
      "[-0.8847656  -0.2512207   0.2319336   0.9213867   0.26367188 -0.10552979] 3   5 \n",
      "[-0.38378906  0.25073242  0.18603516  0.26123047 -0.0994873  -0.37280273] 3   4 \n",
      "[-1.2246094   0.15405273  0.01239777  0.5883789   0.5107422   0.40478516] 3   2 \n",
      "[-1.5009766   0.05761719 -0.0609436   0.921875    0.7861328   0.42773438] 3   4 \n",
      "[-0.6508789   0.29174805  0.18103027  0.3137207  -0.02046204 -0.29663086] 3   2 \n",
      "[-1.5654297  -0.01017761 -0.1652832   0.6953125   0.99316406  0.6665039 ] 4   1 \n",
      "[-0.87646484  0.25512695  0.15539551  0.77001953  0.28344727 -0.29711914] 3   3 Match 166\n",
      "\n",
      "[-0.48413086  0.25463867  0.38305664  0.5126953  -0.14660645 -0.2602539 ] 3   5 \n",
      "[-1.4550781   0.09234619  0.01116943  0.70703125  0.59765625  0.38452148] 3   4 \n",
      "[-0.31835938  0.09875488  0.29589844  0.32006836 -0.2355957  -0.6191406 ] 3   3 Match 167\n",
      "\n",
      "[-0.51464844  0.14855957  0.12585449  0.51123047 -0.08996582 -0.13122559] 3   4 \n",
      "[-0.92089844 -0.12121582  0.29248047  0.7988281   0.34960938 -0.1394043 ] 3   3 Match 168\n",
      "\n",
      "[-0.06707764  0.20739746  0.28735352  0.21887207 -0.42871094 -0.703125  ] 2   4 \n",
      "[-1.4570312   0.10009766 -0.24255371  0.3959961   0.8417969   0.76904297] 4   5 \n",
      "[-0.22998047  0.09014893  0.31054688  0.5932617  -0.1295166  -0.55566406] 3   2 \n",
      "[ 0.10241699  0.2758789   0.26000977  0.05316162 -0.48779297 -0.8125    ] 1   5 \n",
      "[-0.69091797  0.32617188  0.21923828  0.46606445  0.12817383 -0.39770508] 3   4 \n",
      "[-1.1367188   0.47314453 -0.03005981  0.15209961  0.4189453   0.5317383 ] 5   2 \n",
      "[ 0.06121826  0.29492188  0.22143555  0.03594971 -0.53515625 -0.6220703 ] 1   3 \n",
      "[-1.6191406   0.0073204  -0.26757812  0.38378906  1.0029297   1.0146484 ] 5   2 \n",
      "[-0.5732422   0.18591309  0.2442627   0.4807129  -0.09692383 -0.34228516] 3   5 \n",
      "[-1.5273438   0.09112549 -0.23876953  0.49829102  0.87939453  0.86572266] 4   5 \n",
      "[-0.24291992  0.43920898  0.25341797 -0.09301758 -0.2788086  -0.18688965] 1   4 \n",
      "[-1.4951172   0.3046875  -0.21276855  0.23046875  1.0234375   0.79052734] 4   3 \n",
      "[-1.5869141   0.0473938  -0.28857422  0.5415039   1.03125     0.98046875] 4   5 \n",
      "[-1.3261719  -0.23828125  0.05917358  0.8486328   0.67822266  0.52978516] 3   5 \n",
      "[-1.4648438   0.18334961 -0.17041016  0.44091797  0.97216797  0.81640625] 4   2 \n",
      "[-0.04919434  0.31054688  0.32592773 -0.07385254 -0.5332031  -0.44628906] 2   2 Match 169\n",
      "\n",
      "[-0.67333984  0.29174805  0.125       0.2232666   0.04269409  0.10211182] 1   4 \n",
      "[-1.0966797   0.36621094 -0.23205566  0.01834106  0.5053711   0.6430664 ] 5   4 \n",
      "[ 0.00287247  0.20776367  0.31958008  0.14135742 -0.47045898 -0.5942383 ] 2   1 \n",
      "[ 0.13061523  0.19677734  0.24182129  0.2142334  -0.52978516 -0.7421875 ] 2   2 Match 170\n",
      "\n",
      "[-1.1943359   0.17358398  0.05007935  0.7685547   0.4506836  -0.04388428] 3   0 \n",
      "[-0.3076172   0.08612061  0.25683594  0.36132812 -0.22277832 -0.31420898] 3   2 \n",
      "[-1.4003906   0.22741699 -0.07348633  0.82373047  0.75927734  0.03381348] 3   4 \n",
      "[-1.4619141   0.03823853 -0.08807373  0.9555664   0.71240234  0.03372192] 3   2 \n",
      "[-0.65185547  0.33398438  0.32104492  0.46166992  0.00541687 -0.32348633] 3   0 \n",
      "[-0.3190918   0.4362793   0.14477539 -0.12646484 -0.1640625  -0.09521484] 1   3 \n",
      "[-1.6044922  -0.19824219 -0.31982422  0.49072266  0.9980469   0.79345703] 4   5 \n",
      "[ 0.08148193  0.3947754   0.28686523 -0.09509277 -0.5986328  -0.42797852] 1   5 \n",
      "[-0.7895508   0.12902832  0.29711914  0.8120117   0.17077637 -0.39697266] 3   5 \n",
      "[-0.2097168   0.36694336  0.3310547   0.02909851 -0.30541992 -0.13317871] 1   2 \n",
      "[-0.3671875   0.11291504  0.3720703   0.5649414  -0.2758789  -0.6118164 ] 3   4 \n",
      "[-1.1611328   0.27026367  0.04067993  0.36767578  0.4345703   0.66552734] 5   3 \n",
      "[-0.3400879   0.5620117   0.16064453 -0.21911621 -0.17175293 -0.10644531] 1   3 \n",
      "[-1.0625      0.22302246  0.18920898  0.7680664   0.43896484 -0.12963867] 3   5 \n",
      "[-0.1986084   0.10583496  0.21459961  0.35717773 -0.26245117 -0.32836914] 3   4 \n",
      "[-1.6142578   0.1842041  -0.0892334   0.67285156  0.9770508   0.6611328 ] 4   5 \n",
      "[ 0.14123535  0.49243164  0.33618164 -0.25585938 -0.4946289  -0.01489258] 1   0 \n",
      "[-1.2568359   0.5107422  -0.10137939  0.10144043  0.5571289   0.7080078 ] 5   2 \n",
      "[-1.6337891  -0.28051758 -0.37475586  0.6015625   1.1748047   0.83935547] 4   5 \n",
      "[-0.15734863  0.32006836  0.32958984  0.12670898 -0.38745117 -0.58935547] 2   1 \n",
      "[-1.6533203  -0.45581055 -0.375       0.5683594   1.1669922   0.9321289 ] 4   5 \n",
      "[-1.5888672  -0.19250488 -0.18908691  0.8725586   1.1201172   0.8779297 ] 4   4 Match 171\n",
      "\n",
      "[-1.0253906   0.31103516  0.12426758  0.67822266  0.44604492 -0.0803833 ] 3   1 \n",
      "[-1.3525391   0.17370605 -0.24169922  0.52001953  0.69091797  0.6376953 ] 4   1 \n",
      "[ 0.06192017  0.4169922   0.23254395 -0.11853027 -0.484375   -0.42944336] 1   4 \n",
      "[-1.1669922   0.26489258  0.04592896  0.32958984  0.58203125  0.3232422 ] 4   3 \n",
      "[-1.5917969  -0.12988281 -0.26513672  0.734375    1.0859375   0.8017578 ] 4   3 \n",
      "[-0.31396484  0.2680664   0.31298828  0.33032227 -0.23242188 -0.38964844] 3   4 \n",
      "[-0.8129883   0.12756348  0.32421875  0.76416016  0.04663086 -0.35742188] 3   2 \n",
      "[-1.4863281   0.09094238 -0.04931641  0.640625    0.9169922   0.7729492 ] 4   4 Match 172\n",
      "\n",
      "[-0.49658203  0.25048828  0.3046875   0.30541992 -0.12548828 -0.3869629 ] 3   2 \n",
      "[-0.01261139  0.27856445  0.27490234  0.05111694 -0.5214844  -0.5488281 ] 1   1 Match 173\n",
      "\n",
      "[-0.8173828   0.38989258  0.08538818 -0.02290344  0.1116333   0.31347656] 1   0 \n",
      "[-1.5761719  -0.30932617 -0.3017578   0.5175781   1.0244141   0.96484375] 4   4 Match 174\n",
      "\n",
      "[-1.5976562   0.02746582 -0.38427734  0.29101562  1.0351562   0.94921875] 4   1 \n",
      "[-1.5058594  -0.0368042  -0.11047363  0.7246094   1.0068359   0.75      ] 4   5 \n",
      "[-1.4130859  -0.16674805 -0.29638672  0.48657227  0.81884766  0.88134766] 5   4 \n",
      "[-1.4082031   0.17248535 -0.07019043  0.64941406  0.8808594   0.6333008 ] 4   2 \n",
      "[-1.6787109  -0.2607422  -0.42871094  0.5283203   0.98339844  0.8876953 ] 4   4 Match 175\n",
      "\n",
      "[-0.9428711   0.1616211   0.00959015  0.5917969   0.34350586  0.2524414 ] 3   4 \n",
      "[-1.1513672   0.44799805  0.0425415   0.27319336  0.46142578  0.3239746 ] 4   4 Match 176\n",
      "\n",
      "[-1.6015625   0.15710449 -0.3425293   0.58154297  0.93896484  0.80810547] 4   4 Match 177\n",
      "\n",
      "[-1.3173828   0.00421143 -0.0385437   0.7919922   0.79003906  0.4724121 ] 3   3 Match 178\n",
      "\n",
      "[-1.2539062   0.1652832   0.02835083  0.75146484  0.67333984  0.12054443] 3   1 \n",
      "[-0.640625    0.5136719   0.10882568 -0.17224121  0.03610229  0.19970703] 1   1 Match 179\n",
      "\n",
      "[-0.53515625  0.12878418  0.2866211   0.72558594 -0.09222412 -0.47827148] 3   1 \n",
      "[-0.8041992   0.45410156  0.05215454  0.0892334   0.25146484  0.3515625 ] 1   1 Match 180\n",
      "\n",
      "[-0.15454102  0.06921387  0.14868164  0.25195312 -0.32470703 -0.40454102] 3   4 \n",
      "[ 0.28881836  0.3395996   0.3215332  -0.1694336  -0.56689453 -0.2619629 ] 1   1 Match 181\n",
      "\n",
      "[-0.703125    0.24023438  0.36206055  0.59033203  0.07305908 -0.3071289 ] 3   4 \n",
      "[-1.5117188   0.08276367 -0.16015625  0.34838867  0.7426758   1.046875  ] 5   4 \n",
      "[-0.7050781   0.08862305  0.35791016  0.6894531   0.02684021 -0.51904297] 3   4 \n",
      "[-0.77978516  0.12445068  0.07617188  0.4182129   0.20812988 -0.06896973] 3   1 \n",
      "[-1.1425781   0.16235352  0.09490967  0.80859375  0.5229492   0.00998688] 3   2 \n",
      "[-0.8022461   0.24865723  0.3305664   0.58154297  0.06652832 -0.24194336] 3   5 \n",
      "[-1.3369141   0.15576172 -0.17797852  0.36767578  0.77246094  0.7363281 ] 4   3 \n",
      "[-0.7167969  -0.01500702  0.07910156  0.46044922  0.16137695 -0.04669189] 3   2 \n",
      "[-1.5458984  -0.01876831 -0.24047852  0.5966797   0.71972656  0.7338867 ] 5   5 Match 182\n",
      "\n",
      "[-1.5117188  -0.24450684 -0.16235352  1.0195312   0.9995117   0.6772461 ] 3   1 \n",
      "[-1.6484375  -0.20153809 -0.41064453  0.5722656   1.1328125   0.9692383 ] 4   3 \n",
      "[ 0.19665527  0.38916016  0.22790527 -0.26245117 -0.55566406 -0.31323242] 1   1 Match 183\n",
      "\n",
      "[-1.5537109  -0.07019043 -0.43579102  0.31054688  1.1240234   0.82470703] 4   5 \n",
      "[-0.49072266  0.35351562  0.20092773  0.17028809 -0.02033997 -0.1430664 ] 1   3 \n",
      "[-1.3027344  -0.19567871 -0.18249512  0.7675781   0.7475586   0.52490234] 3   4 \n",
      "[-1.4580078   0.23205566 -0.13916016  0.31713867  0.77978516  0.8364258 ] 5   5 Match 184\n",
      "\n",
      "[-1.6757812  -0.21606445 -0.31054688  0.5776367   1.0634766   0.77001953] 4   4 Match 185\n",
      "\n",
      "[-1.609375   -0.08172607 -0.27783203  0.6513672   1.0810547   0.74365234] 4   5 \n",
      "[-0.07128906  0.41674805  0.20751953 -0.17932129 -0.4326172  -0.33520508] 1   5 \n",
      "[-1.5703125  -0.17810059 -0.25439453  0.86376953  1.1523438   0.75097656] 4   5 \n",
      "[-1.5605469   0.1137085  -0.06137085  0.8222656   0.99609375  0.58251953] 4   4 Match 186\n",
      "\n",
      "[-1.3115234   0.23632812 -0.0692749   0.4736328   0.87841797  0.6015625 ] 4   5 \n",
      "[ 0.06878662  0.48999023  0.23266602 -0.26220703 -0.41748047 -0.02784729] 1   0 \n",
      "[-1.4296875  -0.09771729  0.0546875   1.0341797   0.69140625  0.13623047] 3   2 \n",
      "[-1.4580078  -0.03634644 -0.07012939  0.9326172   0.8671875   0.4050293 ] 3   5 \n",
      "[-1.4501953   0.19335938 -0.16052246  0.2680664   0.99072266  0.76171875] 4   1 \n",
      "[-0.9638672   0.49731445 -0.0411377   0.02108765  0.2841797   0.43554688] 1   2 \n",
      "[-0.12084961  0.16699219  0.29370117  0.37231445 -0.36572266 -0.6376953 ] 3   2 \n",
      "[-1.015625    0.32836914  0.12420654  0.3864746   0.41259766  0.09075928] 4   1 \n",
      "[-0.6738281   0.26000977  0.36938477  0.39331055 -0.05270386 -0.28027344] 3   2 \n",
      "[-1.5136719   0.14453125 -0.13562012  0.640625    0.8540039   0.7114258 ] 4   1 \n",
      "[-1.5029297   0.15258789 -0.25561523  0.38842773  0.9916992   0.73779297] 4   5 \n",
      "[-1.2597656   0.17236328 -0.1038208   0.57470703  0.7949219   0.17126465] 4   3 \n",
      "[-1.4199219  -0.05688477 -0.17297363  0.9350586   0.9135742   0.29614258] 3   4 \n",
      "[-1.5712891  -0.05273438 -0.30419922  0.5463867   1.0761719   0.96533203] 4   3 \n",
      "[-0.14575195  0.30029297  0.2770996   0.12115479 -0.3227539  -0.41918945] 1   4 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.1796875   0.45922852  0.01660156  0.10687256  0.5229492   0.65185547] 5   3 \n",
      "[ 0.2553711   0.390625    0.27978516 -0.14453125 -0.65722656 -0.57666016] 1   3 \n",
      "[-0.49365234  0.5620117   0.12176514 -0.08538818 -0.01138306  0.00963593] 1   2 \n",
      "[-0.28320312  0.3894043   0.30932617  0.21398926 -0.19848633 -0.38427734] 1   1 Match 187\n",
      "\n",
      "[-1.0214844   0.32080078  0.07983398  0.5126953   0.3605957   0.13049316] 3   3 Match 188\n",
      "\n",
      "[-0.00250244  0.34936523  0.28881836 -0.02270508 -0.43481445 -0.54248047] 1   4 \n",
      "[-1.2353516   0.3720703  -0.07659912  0.22790527  0.5751953   0.359375  ] 4   4 Match 189\n",
      "\n",
      "[-1.28125     0.17736816  0.05169678  0.5307617   0.49853516  0.5839844 ] 5   4 \n",
      "[-1.2109375   0.20727539 -0.13647461  0.0531311   0.45898438  0.9501953 ] 5   2 \n",
      "[-1.6123047   0.11309814 -0.27441406  0.34277344  1.0683594   0.86083984] 4   5 \n",
      "[-1.1083984   0.36132812 -0.15454102  0.17236328  0.5083008   0.47021484] 4   4 Match 190\n",
      "\n",
      "[ 0.17236328  0.5053711   0.25952148 -0.32470703 -0.51220703 -0.2578125 ] 1   4 \n",
      "[-1.3164062   0.15795898 -0.0141983   0.67578125  0.7807617   0.49731445] 4   3 \n",
      "[-0.87890625 -0.12286377  0.03866577  0.79833984  0.3857422  -0.12054443] 3   2 \n",
      "[ 0.13903809  0.29736328  0.24707031 -0.07745361 -0.5786133  -0.5180664 ] 1   0 \n",
      "[-1.6025391   0.01896667 -0.42016602  0.34765625  1.1904297   0.90527344] 4   3 \n",
      "[-0.8120117   0.17053223  0.2854004   0.6411133   0.11315918 -0.25390625] 3   4 \n",
      "[-1.5         0.14013672 -0.25756836  0.33496094  0.91308594  0.9111328 ] 4   2 \n",
      "[-1.203125    0.23510742  0.0958252   0.58496094  0.5839844   0.1484375 ] 3   3 Match 191\n",
      "\n",
      "[-0.20678711  0.5371094   0.13720703 -0.22216797 -0.26757812 -0.12902832] 1   4 \n",
      "[-0.77734375  0.24987793  0.3100586   0.48706055  0.16845703 -0.09295654] 3   1 \n",
      "[-0.81396484  0.0960083   0.2915039   0.61279297  0.12261963 -0.21936035] 3   2 \n",
      "[-1.5302734  -0.01473236 -0.14770508  0.63134766  1.0732422   0.76708984] 4   4 Match 192\n",
      "\n",
      "[-1.1982422   0.4189453   0.02815247  0.5751953   0.58154297 -0.05081177] 4   2 \n",
      "[-0.48095703  0.42041016  0.25219727  0.02296448 -0.2019043  -0.20874023] 1   5 \n",
      "[-0.90234375  0.26660156  0.10534668  0.50927734  0.29101562 -0.09796143] 3   5 \n",
      "[-1.1113281   0.18225098 -0.04434204  0.4892578   0.6503906   0.20581055] 4   4 Match 193\n",
      "\n",
      "[-0.8901367   0.39892578  0.14050293  0.34057617  0.14416504 -0.10351562] 1   5 \n",
      "[-0.29492188  0.09326172  0.30297852  0.30688477 -0.24597168 -0.609375  ] 3   2 \n",
      "[-0.18457031  0.3347168   0.32617188  0.13549805 -0.4169922  -0.40820312] 1   3 \n",
      "[-1.5175781   0.01646423 -0.15429688  0.90185547  0.9321289   0.43652344] 4   4 Match 194\n",
      "\n",
      "[-0.9863281   0.21398926  0.05981445  0.45996094  0.3400879   0.14648438] 3   3 Match 195\n",
      "\n",
      "[-1.5732422  -0.03915405 -0.28710938  0.58251953  0.9604492   0.69091797] 4   3 \n",
      "[-0.9033203   0.3540039   0.17077637  0.39868164  0.21606445 -0.03082275] 3   4 \n",
      "[-1.6240234  -0.14819336 -0.32104492  0.6635742   0.9848633   0.75927734] 4   3 \n",
      "[-0.75683594  0.32080078  0.20141602  0.38793945  0.08087158 -0.11889648] 3   2 \n",
      "[-1.3955078   0.09057617 -0.05413818  0.83154297  0.80322266  0.42016602] 3   4 \n",
      "[-0.46899414  0.4777832   0.25561523  0.05026245 -0.1953125   0.06591797] 1   3 \n",
      "[-6.3183594e-01  1.3769531e-01  3.0200195e-01  5.0048828e-01\n",
      " -2.5701523e-04 -3.5693359e-01] 3   0 \n",
      "[-0.9589844   0.41430664 -0.17932129 -0.1204834   0.20629883  0.45385742] 5   1 \n",
      "[-0.55371094  0.36450195  0.2763672   0.17004395 -0.12585449 -0.21179199] 1   1 Match 196\n",
      "\n",
      "[-0.9711914   0.36035156 -0.01413727  0.12976074  0.4777832   0.55371094] 5   5 Match 197\n",
      "\n",
      "[-0.87060547  0.18811035  0.2631836   0.69921875  0.19445801 -0.33203125] 3   5 \n",
      "[-0.86376953  0.42626953  0.27514648  0.31054688  0.1694336  -0.06054688] 1   2 \n",
      "[-0.99902344  0.25317383  0.20324707  0.5864258   0.3161621  -0.03768921] 3   4 \n",
      "[-1.5429688  -0.20288086 -0.2590332   0.6645508   0.8588867   0.8520508 ] 4   3 \n",
      "[-1.3583984  -0.01548767 -0.06500244  0.82910156  0.7866211   0.23583984] 3   2 \n",
      "[-0.39331055  0.4453125   0.27856445  0.05728149 -0.22692871 -0.22509766] 1   1 Match 198\n",
      "\n",
      "[-1.4082031   0.09326172 -0.3034668   0.42333984  0.9921875   0.76464844] 4   3 \n",
      "[-1.3134766  -0.28588867  0.04003906  1.0107422   0.87597656  0.58984375] 3   1 \n",
      "[-1.1777344   0.27246094 -0.0045433   0.44335938  0.5786133  -0.07214355] 4   4 Match 199\n",
      "\n",
      "[-1.0595703   0.16113281 -0.07159424  0.31762695  0.22851562  0.65527344] 5   3 \n",
      "[-0.53515625  0.33984375  0.12670898  0.16809082  0.00054836 -0.03353882] 1   2 \n",
      "[-0.06414795  0.31762695  0.37329102  0.07751465 -0.44091797 -0.30786133] 2   0 \n",
      "[-0.10992432  0.47192383  0.16796875 -0.2211914  -0.2565918   0.10571289] 1   5 \n",
      "[-0.3256836   0.35668945  0.34521484  0.20800781 -0.2927246  -0.38964844] 1   1 Match 200\n",
      "\n",
      "[-0.80615234  0.22607422  0.23632812  0.44335938  0.14099121 -0.2512207 ] 3   4 \n",
      "[-0.33081055  0.35595703  0.26953125 -0.01931763 -0.34033203 -0.18017578] 1   4 \n",
      "[-1.2783203   0.11151123  0.00970459  0.9326172   0.80029297  0.23864746] 3   1 \n",
      "[-0.10864258  0.27416992  0.22851562  0.19787598 -0.31420898 -0.36791992] 1   0 \n",
      "[-0.39038086  0.07012939  0.26098633  0.47680664 -0.12719727 -0.24829102] 3   1 \n",
      "[-1.5498047  -0.15771484 -0.33325195  0.30444336  0.88720703  0.7397461 ] 4   0 \n",
      "[-1.25        0.3017578   0.04464722  0.64941406  0.62890625  0.18920898] 3   3 Match 201\n",
      "\n",
      "[-0.04684448  0.30566406  0.14562988 -0.02404785 -0.52197266 -0.27612305] 1   1 Match 202\n",
      "\n",
      "[-1.3173828  -0.04150391 -0.10980225  0.29125977  0.45117188  0.65966797] 5   4 \n",
      "[-0.9355469   0.06008911  0.18151855  0.79833984  0.22180176 -0.27416992] 3   0 \n",
      "[-0.55322266  0.1505127   0.3215332   0.62402344 -0.09771729 -0.5620117 ] 3   5 \n",
      "[-1.4511719   0.09844971 -0.26049805  0.2685547   0.89404297  0.9038086 ] 5   2 \n",
      "[-0.4494629   0.625       0.22644043 -0.1640625   0.01872253  0.3190918 ] 1   5 \n",
      "[-0.73095703  0.23913574  0.2211914   0.5366211   0.21899414 -0.23217773] 3   1 \n",
      "[-1.1621094   0.31469727 -0.06835938  0.18884277  0.6826172   0.7836914 ] 5   0 \n",
      "[-0.9472656   0.03213501 -0.11065674  0.25390625  0.12115479  0.47338867] 5   2 \n",
      "[ 0.17980957  0.36035156  0.18676758 -0.23266602 -0.61865234 -0.41845703] 1   0 \n",
      "[-0.69921875  0.5996094   0.14941406 -0.07843018  0.15539551  0.30151367] 1   2 \n",
      "[ 0.24169922  0.25073242  0.21166992 -0.06015015 -0.671875   -0.69433594] 1   1 Match 203\n",
      "\n",
      "[-0.41796875  0.21032715  0.1484375   0.22790527 -0.14416504 -0.17028809] 3   1 \n",
      "[-1.0830078   0.07641602  0.19335938  0.8232422   0.4296875  -0.0980835 ] 3   1 \n",
      "[-0.5488281   0.30322266  0.19238281  0.17492676 -0.03488159  0.01042938] 1   5 \n",
      "[-0.08746338  0.32299805  0.21789551 -0.00704193 -0.453125   -0.51708984] 1   2 \n",
      "[-0.31958008  0.3173828   0.27026367  0.22814941 -0.27929688 -0.49829102] 1   2 \n",
      "[-1.34375     0.26635742 -0.09375     0.2800293   0.76953125  0.94677734] 5   2 \n",
      "[-1.5732422  -0.06002808 -0.2849121   0.3479004   1.0908203   0.87841797] 4   3 \n",
      "[-0.3215332   0.20532227  0.24719238  0.29638672 -0.21044922 -0.29638672] 3   4 \n",
      "[-1.4462891   0.12023926  0.05169678  0.90722656  0.8491211   0.41088867] 3   4 \n",
      "[-0.50634766  0.51708984  0.0914917  -0.20678711 -0.15649414  0.1217041 ] 1   5 \n",
      "[-1.5625      0.21191406 -0.27978516  0.37841797  0.77197266  0.7451172 ] 4   5 \n",
      "[-0.5395508   0.33374023  0.1842041   0.05725098 -0.09460449 -0.01974487] 1   2 \n",
      "[-0.95458984  0.15014648  0.10803223  0.7475586   0.2619629  -0.07556152] 3   3 Match 204\n",
      "\n",
      "[-1.1650391   0.01776123  0.00463486  0.52685547  0.3479004   0.5239258 ] 3   4 \n",
      "[-0.27929688  0.24658203  0.19250488  0.11645508 -0.2421875  -0.29882812] 1   3 \n",
      "[-0.7885742   0.43920898  0.15454102 -0.02766418  0.23583984  0.55029297] 5   1 \n",
      "[-0.19921875  0.1270752   0.32543945  0.37451172 -0.33374023 -0.5527344 ] 3   5 \n",
      "[ 0.05493164  0.24621582  0.24731445  0.07751465 -0.48339844 -0.5439453 ] 2   1 \n",
      "[-0.80126953  0.22265625  0.4099121   0.5205078   0.20666504 -0.13757324] 3   2 \n",
      "[-0.03210449  0.33935547  0.31640625  0.00756836 -0.47509766 -0.57666016] 1   4 \n",
      "[-1.3789062   0.08636475  0.0082016   0.9663086   0.6147461  -0.07141113] 3   1 \n",
      "[-0.96533203 -0.08349609  0.18518066  1.1083984   0.32861328 -0.2619629 ] 3   3 Match 205\n",
      "\n",
      "[-1.0292969   0.16540527 -0.07403564  0.19482422  0.24633789  0.5703125 ] 5   2 \n",
      "[-0.89453125  0.45361328  0.17651367  0.15100098  0.18933105  0.20874023] 1   1 Match 206\n",
      "\n",
      "[-0.24060059  0.40844727  0.27905273 -0.01074219 -0.37060547 -0.33666992] 1   4 \n",
      "[-0.30249023  0.39868164  0.24084473  0.23498535 -0.25805664 -0.38720703] 1   2 \n",
      "[-1.1572266   0.22607422  0.22058105  0.8208008   0.39892578 -0.06414795] 3   1 \n",
      "[-1.6015625   0.13647461 -0.25854492  0.69677734  1.0849609   0.5966797 ] 4   3 \n",
      "[-1.5332031   0.1652832  -0.13439941  0.6557617   0.9604492   0.50341797] 4   4 Match 207\n",
      "\n",
      "[-0.04534912  0.17053223  0.3322754   0.26538086 -0.39990234 -0.51220703] 2   1 \n",
      "[-1.1054688   0.19873047  0.04046631  0.5698242   0.49243164  0.2109375 ] 3   2 \n",
      "[-1.3164062   0.12976074 -0.0076561   0.86279297  0.81591797  0.27075195] 3   4 \n",
      "[-0.6142578   0.4362793   0.21276855  0.0668335  -0.01311493 -0.00554276] 1   1 Match 208\n",
      "\n",
      "[-1.3945312  -0.01847839 -0.05447388  0.9301758   0.97558594  0.5751953 ] 4   4 Match 209\n",
      "\n",
      "[-0.16223145  0.1673584   0.2902832   0.41381836 -0.34985352 -0.7133789 ] 3   1 \n",
      "[-1.5605469  -0.12597656 -0.40820312  0.34106445  0.99121094  0.8173828 ] 4   5 \n",
      "[-1.53125    -0.01004791 -0.16040039  0.84375     0.9238281   0.5522461 ] 4   5 \n",
      "[-1.6357422  -0.21765137 -0.3564453   0.68847656  1.1171875   0.8540039 ] 4   3 \n",
      "[-0.46972656  0.3173828   0.1586914   0.12365723 -0.06152344 -0.09466553] 1   1 Match 210\n",
      "\n",
      "[-1.2451172   0.34545898  0.05722046  0.5048828   0.64453125  0.25073242] 4   2 \n",
      "[-0.6640625   0.2890625   0.25976562  0.5576172   0.07318115 -0.43579102] 3   1 \n",
      "[-0.9501953   0.29907227  0.29248047  0.5854492   0.14831543 -0.16491699] 3   5 \n",
      "[-0.8720703   0.24243164  0.33007812  0.50097656  0.06756592 -0.3251953 ] 3   1 \n",
      "[-0.55371094  0.1171875   0.27612305  0.5678711  -0.09936523 -0.53027344] 3   2 \n",
      "[-0.8105469   0.46264648  0.12011719  0.23083496  0.22387695  0.20910645] 1   2 \n",
      "[-0.31054688  0.10845947  0.28076172  0.3930664  -0.24621582 -0.50341797] 3   4 \n",
      "[-1.0390625   0.08935547  0.2890625   0.7270508   0.30737305 -0.18383789] 3   2 \n",
      "[ 0.03237915  0.27319336  0.2607422   0.11956787 -0.47924805 -0.61376953] 1   2 \n",
      "[-0.49609375  0.21179199  0.28637695  0.46679688 -0.12176514 -0.4880371 ] 3   5 \n",
      "[-0.6352539   0.20043945  0.3972168   0.50097656 -0.0569458  -0.3876953 ] 3   3 Match 211\n",
      "\n",
      "[-1.1845703   0.1887207   0.15686035  0.90722656  0.43359375 -0.05978394] 3   2 \n",
      "[-1.4726562   0.2841797  -0.11572266  0.48168945  0.62353516  0.50390625] 4   3 \n",
      "[-1.5107422  -0.13293457 -0.1295166   0.9448242   0.9819336   0.61328125] 4   4 Match 212\n",
      "\n",
      "[-1.0146484   0.01908875  0.07525635  0.7270508   0.23254395  0.11590576] 3   2 \n",
      "[-1.5107422   0.10961914 -0.10693359  0.9296875   0.9423828   0.47729492] 4   1 \n",
      "[-1.5410156   0.00971985 -0.14465332  0.64990234  0.9404297   0.8535156 ] 4   4 Match 213\n",
      "\n",
      "[-0.19470215  0.5996094   0.0546875  -0.32421875 -0.30737305 -0.16638184] 1   1 Match 214\n",
      "\n",
      "[-0.43432617  0.61376953  0.09625244 -0.25170898 -0.10369873 -0.02986145] 1   3 \n",
      "[-1.1728516   0.22546387  0.12054443  0.7910156   0.5527344   0.05740356] 3   5 \n",
      "[-0.8779297   0.28173828  0.2541504   0.5234375   0.17504883 -0.23669434] 3   3 Match 215\n",
      "\n",
      "[-1.6552734  -0.18786621 -0.32299805  0.6298828   1.0087891   0.81689453] 4   5 \n",
      "[-0.14575195  0.25585938  0.37597656  0.05227661 -0.38891602 -0.4243164 ] 2   3 \n",
      "[-1.4658203   0.14831543 -0.08361816  0.7553711   0.86865234  0.46240234] 4   5 \n",
      "[-1.4267578e+00  9.6130371e-02  5.2785873e-04  9.4384766e-01\n",
      "  7.9980469e-01  2.9687500e-01] 3   4 \n",
      "[-0.25219727  0.20922852  0.453125    0.3227539  -0.3017578  -0.52441406] 2   0 \n",
      "[-1.1357422   0.30786133  0.1050415   0.6616211   0.4753418   0.00406647] 3   1 \n",
      "[-0.22937012  0.4152832   0.22595215  0.07965088 -0.29736328 -0.27929688] 1   1 Match 216\n",
      "\n",
      "[-0.8544922   0.2265625   0.25073242  0.5449219   0.05508423 -0.22436523] 3   0 \n",
      "[-0.7519531   0.2980957   0.07147217  0.27563477  0.1270752   0.23730469] 1   4 \n",
      "[ 0.14282227  0.24975586  0.37939453  0.10772705 -0.6357422  -0.57714844] 2   3 \n",
      "[-1.5927734   0.00383759 -0.39282227  0.29907227  0.91796875  0.7939453 ] 4   4 Match 217\n",
      "\n",
      "[-1.0048828   0.4645996   0.06854248  0.13269043  0.4128418   0.42358398] 1   1 Match 218\n",
      "\n",
      "[-1.4970703  -0.27685547 -0.12133789  0.79052734  1.1777344   0.953125  ] 4   3 \n",
      "[-1.4863281   0.03933716 -0.11480713  0.75878906  1.0107422   0.6044922 ] 4   3 \n",
      "[-1.6552734  -0.09118652 -0.37841797  0.4501953   0.9819336   0.91503906] 4   3 \n",
      "[-1.6689453  -0.17175293 -0.43725586  0.4729004   0.9560547   0.79833984] 4   4 Match 219\n",
      "\n",
      "[-0.73828125  0.40429688  0.08410645  0.04763794  0.15698242  0.28564453] 1   5 \n",
      "[-1.6191406  -0.0461731  -0.38623047  0.3779297   0.9921875   0.9477539 ] 4   4 Match 220\n",
      "\n",
      "[-1.5458984  -0.27441406 -0.32592773  0.3178711   0.94677734  0.7998047 ] 4   5 \n",
      "[-1.3867188   0.24243164 -0.11090088  0.62060547  0.8520508   0.3034668 ] 4   3 \n",
      "[-0.20568848  0.6171875   0.1274414  -0.33496094 -0.28637695 -0.00608063] 1   3 \n",
      "[ 1.9091797e-01  3.1396484e-01  2.8149414e-01  1.6665459e-04\n",
      " -6.0693359e-01 -5.8105469e-01] 1   4 \n",
      "[-1.1523438  -0.00307846 -0.12335205  0.23059082  0.2692871   0.63427734] 5   2 \n",
      "[-1.5429688   0.0083313  -0.34448242  0.5073242   1.0068359   0.71972656] 4   4 Match 221\n",
      "\n",
      "[-0.92822266  0.36645508  0.18127441  0.27905273  0.24450684  0.17956543] 1   3 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.0576172   0.2861328   0.13696289  0.6435547   0.42504883  0.02970886] 3   3 Match 222\n",
      "\n",
      "[-1.6142578  -0.20629883 -0.1229248   0.6977539   1.0185547   0.73876953] 4   2 \n",
      "[-0.80566406  0.01686096  0.12963867  0.8647461   0.22814941 -0.1661377 ] 3   2 \n",
      "[-1.4853516  -0.1673584  -0.19262695  1.0048828   0.92578125  0.63427734] 3   4 \n",
      "[-1.0244141   0.4128418   0.10821533  0.47973633  0.3515625  -0.00804138] 3   2 \n",
      "[-1.0654297   0.32055664  0.03009033  0.5234375   0.4477539   0.02850342] 3   5 \n",
      "[-0.7080078   0.6591797   0.05465698 -0.19421387  0.0802002   0.51171875] 1   1 Match 223\n",
      "\n",
      "[-0.22485352  0.2277832   0.30419922  0.40527344 -0.37426758 -0.6323242 ] 3   4 \n",
      "[-0.13879395  0.2824707   0.28833008  0.17150879 -0.46044922 -0.46679688] 2   2 Match 224\n",
      "\n",
      "[-0.33691406  0.484375    0.08258057 -0.14099121 -0.20117188 -0.07470703] 1   4 \n",
      "[-0.84375     0.3322754  -0.04031372  0.20141602  0.43676758  0.63623047] 5   5 Match 225\n",
      "\n",
      "[-0.44360352  0.3317871   0.16381836  0.20227051 -0.07196045  0.02046204] 1   3 \n",
      "[-0.7739258   0.23010254  0.26586914  0.40844727  0.03634644 -0.22265625] 3   2 \n",
      "[-1.2490234   0.28710938  0.03726196  0.6699219   0.6796875   0.08233643] 4   5 \n",
      "[-1.5146484   0.02378845 -0.04721069  0.76904297  0.8691406   0.5415039 ] 4   4 Match 226\n",
      "\n",
      "[-0.4987793   0.11218262  0.31689453  0.73046875 -0.12597656 -0.5986328 ] 3   3 Match 227\n",
      "\n",
      "[-0.7573242   0.3852539   0.1508789   0.17834473  0.0793457   0.06860352] 1   0 \n",
      "[-1.34375     0.01852417  0.03781128  0.76171875  0.97265625  0.49243164] 4   5 \n",
      "[-0.9375      0.54003906  0.02464294 -0.04473877  0.38720703  0.5058594 ] 1   3 \n",
      "[-0.8198242   0.40283203 -0.10839844 -0.1295166   0.112854    0.48632812] 5   1 \n",
      "[-0.06658936  0.04800415  0.2775879   0.47387695 -0.33203125 -0.78466797] 3   3 Match 228\n",
      "\n",
      "[-0.34179688  0.31762695  0.31079102  0.2553711  -0.24108887 -0.3347168 ] 1   1 Match 229\n",
      "\n",
      "[-0.3894043   0.4814453   0.2553711   0.08178711 -0.16015625 -0.07989502] 1   1 Match 230\n",
      "\n",
      "[ 0.11193848  0.45947266  0.2746582  -0.2290039  -0.53271484 -0.31176758] 1   0 \n",
      "[-0.31201172  0.24865723  0.3479004   0.3774414  -0.19702148 -0.55371094] 3   2 \n",
      "[-0.07373047  0.32836914  0.23010254 -0.03790283 -0.37402344 -0.40405273] 1   0 \n",
      "[-0.20666504  0.32250977  0.18835449  0.1126709  -0.3227539  -0.38330078] 1   3 \n",
      "[ 0.3786621   0.40161133  0.23840332 -0.29492188 -0.6689453  -0.6308594 ] 1   5 \n",
      "[-0.16235352  0.22595215  0.44580078  0.12939453 -0.3557129  -0.36791992] 2   1 \n",
      "[-0.71240234  0.36572266  0.16186523  0.06951904  0.13586426  0.06811523] 1   2 \n",
      "[-1.3613281   0.2705078  -0.1270752   0.39648438  0.79052734  0.7236328 ] 4   3 \n",
      "[-1.5732422  -0.31298828 -0.24230957  0.8442383   1.1953125   0.81396484] 4   4 Match 231\n",
      "\n",
      "[-0.6982422   0.05783081  0.26245117  0.7089844   0.1274414  -0.2076416 ] 3   5 \n",
      "[ 0.22692871  0.2692871   0.3059082  -0.02095032 -0.56347656 -0.56933594] 2   4 \n",
      "[-1.6328125  -0.19934082 -0.33496094  0.56103516  1.0996094   0.9399414 ] 4   1 \n",
      "[-1.2685547e+00  2.7416992e-01  1.2561035e-01  6.7382812e-01\n",
      "  5.0048828e-01 -9.5987320e-04] 3   1 \n",
      "[-1.0390625   0.33544922  0.07244873  0.3840332   0.4260254   0.17126465] 4   1 \n",
      "[-1.3193359  -0.19702148 -0.15344238  0.9667969   0.71972656  0.43432617] 3   3 Match 232\n",
      "\n",
      "[-1.1220703   0.2277832   0.12463379  0.63378906  0.5048828   0.15576172] 3   5 \n",
      "[-0.62158203  0.37597656  0.17602539  0.11187744  0.02058411 -0.06011963] 1   5 \n",
      "[-1.1503906   0.22973633  0.12792969  0.82177734  0.44555664 -0.10241699] 3   3 Match 233\n",
      "\n",
      "[-1.5576172   0.09436035 -0.30029297  0.46850586  0.9770508   0.85009766] 4   1 \n",
      "[-0.7011719   0.3623047   0.30419922  0.43896484  0.06945801 -0.3569336 ] 3   1 \n",
      "[-0.3762207   0.16357422  0.2932129   0.31933594 -0.19665527 -0.5732422 ] 3   3 Match 234\n",
      "\n",
      "[-0.19311523  0.3474121   0.16540527  0.04492188 -0.2944336  -0.38623047] 1   1 Match 235\n",
      "\n",
      "[-0.3173828   0.1842041   0.30908203  0.41015625 -0.19226074 -0.4440918 ] 3   1 \n",
      "[-0.34521484  0.32885742  0.19030762  0.26293945 -0.16223145 -0.3984375 ] 1   1 Match 236\n",
      "\n",
      "[-0.62841797  0.20397949  0.0692749   0.640625    0.03149414 -0.3269043 ] 3   1 \n",
      "[-0.1895752   0.48535156  0.21569824 -0.1574707  -0.35839844 -0.18078613] 1   3 \n",
      "[-0.38891602  0.39526367  0.18603516 -0.00293541 -0.2446289  -0.15771484] 1   1 Match 237\n",
      "\n",
      "[-1.3496094   0.2052002  -0.21618652  0.2376709   0.95703125  0.8208008 ] 4   2 \n",
      "[-1.4443359   0.21447754 -0.02018738  0.6640625   0.8457031   0.34106445] 4   4 Match 238\n",
      "\n",
      "[ 0.08331299  0.3010254   0.29492188  0.02407837 -0.47387695 -0.51660156] 1   3 \n",
      "[-1.3857422  -0.21142578 -0.12438965  1.0390625   0.7402344   0.4255371 ] 3   3 Match 239\n",
      "\n",
      "[ 0.22399902  0.16723633  0.20666504  0.12451172 -0.5385742  -0.7426758 ] 0   0 Match 240\n",
      "\n",
      "[-0.9526367  -0.09191895  0.28808594  1.0439453   0.3017578  -0.39575195] 3   3 Match 241\n",
      "\n",
      "[-0.73828125  0.24645996  0.28344727  0.52734375  0.05764771 -0.3083496 ] 3   3 Match 242\n",
      "\n",
      "[-1.5283203   0.21240234 -0.02391052  0.64453125  0.9008789   0.44482422] 4   1 \n",
      "[-0.17553711  0.27978516  0.32299805  0.20898438 -0.25927734 -0.29760742] 2   3 \n",
      "[-1.0166016   0.32299805  0.29174805  0.48583984  0.30615234  0.03829956] 3   3 Match 243\n",
      "\n",
      "[-0.06567383  0.37524414  0.31884766 -0.0519104  -0.47216797 -0.4321289 ] 1   1 Match 244\n",
      "\n",
      "[ 0.1751709   0.21569824  0.38208008  0.10803223 -0.6464844  -0.64746094] 2   1 \n",
      "[-0.59375     0.24621582  0.47094727  0.46044922  0.01152802 -0.23742676] 2   0 \n",
      "[-0.9790039   0.3684082   0.09436035  0.25390625  0.29956055  0.19616699] 1   5 \n",
      "[-1.4277344   0.01794434 -0.12902832  0.6689453   0.75        0.6191406 ] 4   5 \n",
      "[-1.4980469  -0.32592773 -0.16662598  1.0380859   1.0185547   0.53808594] 3   5 \n",
      "[-1.2480469   0.41308594 -0.05102539  0.44360352  0.7285156   0.1784668 ] 4   3 \n",
      "[-1.3339844   0.39941406 -0.08422852  0.45629883  0.7138672   0.37573242] 4   3 \n",
      "[-0.35839844  0.22521973  0.12158203  0.23999023 -0.1394043  -0.18847656] 3   3 Match 245\n",
      "\n",
      "[-1.34375     0.23608398  0.0219574   0.5605469   0.71240234  0.7685547 ] 5   1 \n",
      "[-1.4658203  -0.35546875 -0.03198242  0.9707031   1.0410156   0.79052734] 4   2 \n",
      "[ 0.20910645  0.3947754   0.28076172 -0.11602783 -0.6230469  -0.546875  ] 1   1 Match 246\n",
      "\n",
      "[-1.4814453   0.12890625 -0.09851074  0.44970703  0.9926758   1.0009766 ] 5   3 \n",
      "[-1.1269531  -0.03622437  0.08831787  0.8935547   0.48242188  0.13842773] 3   4 \n",
      "[-0.47314453  0.3815918   0.30615234  0.02784729 -0.05560303  0.07788086] 1   0 \n",
      "[-1.5117188   0.05105591 -0.27001953  0.46533203  0.9946289   0.9277344 ] 4   4 Match 247\n",
      "\n",
      "[-1.4423828   0.00305176 -0.09960938  0.7236328   0.94140625  0.39794922] 4   4 Match 248\n",
      "\n",
      "[-1.5761719   0.06744385 -0.13598633  0.6298828   1.0068359   0.83935547] 4   5 \n",
      "[-1.5224609  -0.02755737 -0.11566162  1.0302734   0.8955078   0.45263672] 3   3 Match 249\n",
      "\n",
      "[-0.3466797   0.44921875  0.1328125  -0.13598633 -0.32080078 -0.12322998] 1   0 \n",
      "[ 0.11499023  0.23168945  0.27954102  0.04089355 -0.58740234 -0.74316406] 2   3 \n",
      "[-0.7607422   0.10754395  0.24829102  0.6845703   0.3791504  -0.24304199] 3   0 \n",
      "[-1.5927734  -0.03625488 -0.23608398  0.72021484  1.0107422   0.77490234] 4   3 \n",
      "[-1.4951172   0.06640625 -0.22155762  0.18969727  0.83447266  0.9614258 ] 5   5 Match 250\n",
      "\n",
      "[-1.7548828  -0.27807617 -0.3581543   0.66748047  1.0585938   0.6015625 ] 4   2 \n",
      "[-0.7739258   0.4008789   0.24853516  0.3400879   0.12255859 -0.28735352] 1   5 \n",
      "[-1.5107422   0.29711914 -0.22094727  0.41186523  0.9458008   0.7529297 ] 4   1 \n",
      "[-1.4238281   0.22131348 -0.14196777  0.46264648  0.8300781   0.7709961 ] 4   2 \n",
      "[-1.5810547  -0.14611816 -0.20483398  0.81347656  1.1279297   0.77441406] 4   5 \n",
      "[-0.5839844   0.3269043   0.2980957   0.21875    -0.06222534 -0.09680176] 1   1 Match 251\n",
      "\n",
      "[-0.6245117   0.2619629   0.25463867  0.42456055  0.05700684 -0.28808594] 3   1 \n",
      "[-1.0654297   0.1862793   0.15002441  0.7495117   0.42236328  0.00515747] 3   4 \n",
      "[-1.5976562  -0.12988281 -0.45922852  0.18701172  1.1005859   1.0273438 ] 4   5 \n",
      "[-0.4296875   0.23571777  0.33007812  0.24975586 -0.15527344 -0.4482422 ] 2   1 \n",
      "[ 0.08172607  0.42016602  0.14233398 -0.19921875 -0.59765625 -0.49389648] 1   3 \n",
      "[-1.1220703   0.28979492 -0.02435303  0.4411621   0.43652344  0.3239746 ] 3   1 \n",
      "[-1.2802734   0.26391602  0.05535889  0.8491211   0.70703125  0.00374794] 3   2 \n",
      "[-0.64941406  0.4116211   0.18664551  0.14050293  0.12194824  0.07647705] 1   2 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.3046875   0.21008301  0.00323486  0.47192383  0.72216797  0.6645508 ] 4   4 Match 252\n",
      "\n",
      "[-1.2060547   0.11273193  0.08459473  0.65966797  0.61279297  0.5161133 ] 3   4 \n",
      "[-1.5810547  -0.06030273 -0.2746582   0.6381836   1.0595703   0.6958008 ] 4   2 \n",
      "[-1.5283203  -0.28076172 -0.07025146  1.046875    1.0390625   0.69677734] 3   3 Match 253\n",
      "\n",
      "[-1.5576172  -0.11279297 -0.3959961   0.2434082   1.0097656   1.0527344 ] 5   4 \n",
      "[-1.4541016  -0.08612061 -0.11938477  0.95751953  1.0927734   0.7216797 ] 4   3 \n",
      "[-1.5488281  -0.12817383 -0.40283203  0.49121094  1.0517578   0.9165039 ] 4   2 \n",
      "[-0.6123047   0.30273438  0.05001831  0.3791504   0.21679688 -0.24365234] 3   2 \n",
      "[-0.5751953   0.1694336   0.28173828  0.5288086  -0.06768799 -0.5649414 ] 3   2 \n",
      "[-1.4521484   0.18286133  0.07147217  0.79785156  0.7553711   0.2758789 ] 3   4 \n",
      "[-0.6972656   0.30810547  0.03092957  0.23156738 -0.05999756  0.04559326] 1   2 \n",
      "[-0.23474121  0.1583252   0.29296875  0.36572266 -0.3076172  -0.49658203] 3   3 Match 254\n",
      "\n",
      "[-1.3408203  -0.3095703   0.05325317  1.1259766   0.79052734  0.39770508] 3   1 \n",
      "[-0.49145508  0.13195801  0.2631836   0.45288086 -0.10070801 -0.3388672 ] 3   3 Match 255\n",
      "\n",
      "[-0.25952148  0.42260742  0.30664062  0.11578369 -0.34814453 -0.40820312] 1   2 \n",
      "[-0.58203125  0.5332031   0.04605103 -0.06689453 -0.0280304   0.03065491] 1   1 Match 256\n",
      "\n",
      "[-0.5517578   0.32641602  0.37329102  0.25317383 -0.19628906 -0.32006836] 2   3 \n",
      "[-0.9301758  -0.05307007  0.14025879  0.7080078   0.29516602  0.2854004 ] 3   4 \n",
      "[-0.16772461  0.25732422  0.3713379   0.1784668  -0.39208984 -0.5932617 ] 2   3 \n",
      "[-0.7207031   0.5161133   0.2208252   0.0880127   0.23364258  0.2220459 ] 1   3 \n",
      "[-0.69091797  0.29101562  0.28027344  0.47729492  0.03674316 -0.30737305] 3   1 \n",
      "[-1.1015625  -0.15466309  0.08496094  0.9975586   0.52001953  0.17871094] 3   2 \n",
      "[-0.5292969   0.45581055  0.22949219 -0.0322876  -0.06903076 -0.03372192] 1   1 Match 257\n",
      "\n",
      "[-0.47143555  0.37280273  0.11785889 -0.00839233  0.05828857  0.15002441] 1   1 Match 258\n",
      "\n",
      "[-1.5839844  -0.04562378 -0.22998047  0.93603516  1.0341797   0.67626953] 4   4 Match 259\n",
      "\n",
      "[-0.64208984  0.34033203  0.23803711  0.33789062  0.06689453  0.02841187] 1   4 \n",
      "[-1.6484375  -0.20043945 -0.36816406  0.578125    0.8847656   0.67333984] 4   5 \n",
      "[-1.0146484   0.26635742  0.01091766  0.52001953  0.3774414  -0.06378174] 3   1 \n",
      "[-0.6933594   0.25805664  0.16674805  0.23156738  0.08227539  0.18823242] 1   3 \n",
      "[-0.3918457   0.25219727  0.4074707   0.43920898 -0.2253418  -0.5209961 ] 3   3 Match 260\n",
      "\n",
      "[-1.734375   -0.10357666 -0.33398438  0.7919922   0.98583984  0.75146484] 4   5 \n",
      "[-1.4384766  -0.01950073 -0.01312256  0.9038086   0.8984375   0.49804688] 3   3 Match 261\n",
      "\n",
      "[-0.97314453  0.16906738  0.28637695  0.6352539   0.30419922 -0.08514404] 3   1 \n",
      "[-0.80908203  0.3544922  -0.18078613 -0.21899414  0.04849243  0.32128906] 1   4 \n",
      "[-1.0849609   0.11328125  0.11810303  0.6538086   0.43286133 -0.12963867] 3   3 Match 262\n",
      "\n",
      "[-0.6401367   0.35620117  0.14440918  0.27978516 -0.0824585  -0.22070312] 1   3 \n",
      "[-1.5058594  -0.36132812 -0.00416565  1.0185547   1.0078125   0.67041016] 3   3 Match 263\n",
      "\n",
      "[-1.5458984  -0.13464355 -0.37963867  0.4892578   1.1035156   0.7871094 ] 4   3 \n",
      "[-1.5498047  -0.18103027 -0.39379883  0.40112305  1.0097656   1.0185547 ] 5   4 \n",
      "[-0.5678711   0.31567383  0.15441895  0.46850586 -0.03881836 -0.43017578] 3   3 Match 264\n",
      "\n",
      "[-1.4052734   0.22351074 -0.11340332  0.47558594  0.89990234  0.61816406] 4   3 \n",
      "[ 0.00117016  0.3371582   0.2783203  -0.02764893 -0.45629883 -0.4506836 ] 1   3 \n",
      "[ 0.09210205  0.2619629   0.28076172  0.07800293 -0.5415039  -0.7114258 ] 2   2 Match 265\n",
      "\n",
      "[-1.5644531  -0.36791992 -0.12493896  0.89453125  1.1005859   0.8261719 ] 4   5 \n",
      "[-1.4384766   0.1977539  -0.06433105  0.59521484  0.6791992   0.46777344] 4   2 \n",
      "[-0.5761719   0.30371094  0.08929443  0.14440918  0.01829529  0.10723877] 1   1 Match 266\n",
      "\n",
      "[-1.1679688   0.31640625 -0.04067993  0.04415894  0.43774414  0.5878906 ] 5   2 \n",
      "[-1.2753906   0.07104492  0.04989624  0.7705078   0.56347656  0.25610352] 3   5 \n",
      "[-0.8100586   0.32177734  0.03491211  0.13415527  0.2783203   0.3203125 ] 1   1 Match 267\n",
      "\n",
      "[-1.609375   -0.08465576 -0.19128418  0.9873047   1.0380859   0.65478516] 4   5 \n",
      "[-1.5263672   0.1739502  -0.39379883  0.13342285  0.9584961   0.82470703] 4   1 \n",
      "[ 0.15466309  0.45410156  0.14855957 -0.2836914  -0.64208984 -0.4663086 ] 1   3 \n",
      "[-1.3369141   0.20983887 -0.05673218  0.28833008  1.0625      0.5498047 ] 4   0 \n",
      "[-0.59716797  0.03839111  0.18322754  0.67626953 -0.08111572 -0.43164062] 3   3 Match 268\n",
      "\n",
      "[ 0.12304688  0.34350586  0.2763672  -0.1036377  -0.5776367  -0.41064453] 1   3 \n",
      "[-0.07983398  0.26367188  0.34277344  0.20251465 -0.4020996  -0.5576172 ] 2   1 \n",
      "[-0.45166016  0.20483398  0.15014648  0.4206543  -0.01586914 -0.33398438] 3   1 \n",
      "[-1.0751953   0.37426758  0.05950928  0.38208008  0.4645996   0.1862793 ] 4   1 \n",
      "[-1.5537109   0.01280212 -0.23498535  0.42700195  0.98046875  0.72802734] 4   1 \n",
      "[-0.74121094  0.34887695  0.09082031  0.10980225 -0.02426147  0.20788574] 1   3 \n",
      "[-1.4287109  -0.07922363 -0.29614258  0.4584961   0.9589844   0.7817383 ] 4   5 \n",
      "[-0.6166992   0.43554688  0.10113525  0.04443359  0.10083008  0.04602051] 1   3 \n",
      "[-1.2109375   0.03387451 -0.04272461  0.8496094   0.80566406  0.34472656] 3   3 Match 269\n",
      "\n",
      "[-1.4794922   0.0609436  -0.19104004  0.3762207   0.9506836   0.93847656] 4   2 \n",
      "[-0.3474121  -0.03305054  0.22570801  0.4350586  -0.16186523 -0.17321777] 3   3 Match 270\n",
      "\n",
      "[ 0.01265717  0.5209961   0.29248047 -0.28588867 -0.47607422 -0.02093506] 1   4 \n",
      "[-1.2519531   0.26416016  0.04507446  0.6069336   0.63378906  0.09075928] 4   5 \n",
      "[-0.44848633  0.5253906   0.19433594 -0.18469238 -0.09106445  0.1204834 ] 1   2 \n",
      "[-0.7602539   0.2529297   0.15136719  0.29638672  0.1817627  -0.31640625] 3   1 \n",
      "[ 0.05975342  0.47436523  0.2529297  -0.25390625 -0.54052734 -0.29663086] 1   1 Match 271\n",
      "\n",
      "[-0.39624023  0.27246094  0.30615234  0.2841797  -0.1862793  -0.29956055] 2   1 \n",
      "[-0.46826172  0.14611816  0.44995117  0.58203125 -0.17016602 -0.58935547] 3   2 \n",
      "[-1.3671875   0.10418701 -0.10131836  0.3881836   0.9223633   0.67822266] 4   1 \n",
      "[-0.5913086   0.15466309  0.37719727  0.67041016 -0.05548096 -0.50878906] 3   2 \n",
      "[ 0.03479004  0.3293457   0.36694336  0.05941772 -0.52783203 -0.34301758] 2   0 \n",
      "[-1.4931641   0.25805664 -0.18164062  0.47485352  1.0195312   0.49658203] 4   4 Match 272\n",
      "\n",
      "[ 0.41845703  0.24243164  0.29296875 -0.11071777 -0.67529297 -0.7734375 ] 0   1 \n",
      "[-0.81396484  0.11102295  0.0848999   0.4321289   0.05804443  0.0512085 ] 3   1 \n",
      "[-0.5053711   0.17529297  0.34179688  0.5151367  -0.04937744 -0.36108398] 3   2 \n",
      "[ 0.10101318  0.35351562  0.22277832 -0.0713501  -0.55322266 -0.64453125] 1   1 Match 273\n",
      "\n",
      "[-0.7885742   0.4831543   0.12231445  0.07415771  0.18432617  0.20336914] 1   4 \n",
      "[-0.41796875  0.32373047  0.25219727  0.24353027 -0.27783203 -0.22692871] 1   3 \n",
      "[-1.515625    0.14404297 -0.11663818  0.5439453   0.8413086   0.9873047 ] 5   3 \n",
      "[-1.3574219   0.11120605 -0.04290771  0.7080078   0.703125    0.36865234] 3   3 Match 274\n",
      "\n",
      "[-1.6923828  -0.09997559 -0.40844727  0.52441406  1.0869141   0.74072266] 4   3 \n",
      "[-1.0214844   0.12194824  0.22460938  0.79345703  0.4165039  -0.15576172] 3   0 \n",
      "[-1.6035156   0.0637207  -0.3623047   0.28051758  0.88720703  0.9667969 ] 5   4 \n",
      "[-1.2177734   0.06628418  0.10894775  0.8720703   0.66796875  0.14819336] 3   2 \n",
      "[-0.00484085  0.4296875   0.18066406 -0.20605469 -0.45703125 -0.34399414] 1   3 \n",
      "[-0.25073242  0.10131836  0.31420898  0.63134766 -0.2758789  -0.5551758 ] 3   1 \n",
      "[-1.2880859   0.13354492 -0.08776855  0.59765625  0.7524414   0.6582031 ] 4   4 Match 275\n",
      "\n",
      "[-0.35424805  0.2956543   0.15661621  0.15893555 -0.2446289  -0.41259766] 1   1 Match 276\n",
      "\n",
      "[-0.4790039   0.13952637  0.32177734  0.59521484 -0.02711487 -0.45507812] 3   4 \n",
      "[-0.5576172   0.22265625  0.42163086  0.48046875 -0.16149902 -0.58691406] 3   2 \n",
      "[-1.2773438  -0.02296448  0.14953613  0.9350586   0.7128906   0.28588867] 3   3 Match 277\n",
      "\n",
      "[ 0.14562988  0.25952148  0.3190918  -0.06921387 -0.59521484 -0.46899414] 2   2 Match 278\n",
      "\n",
      "[-0.17700195  0.51171875  0.20605469 -0.20166016 -0.32348633 -0.10662842] 1   3 \n",
      "[-0.41455078  0.42285156  0.15429688  0.00656128 -0.17114258 -0.07580566] 1   1 Match 279\n",
      "\n",
      "[-1.6201172  -0.2590332  -0.18591309  0.8076172   0.9995117   0.70996094] 4   5 \n",
      "[-0.50927734  0.02671814  0.17333984  0.56884766 -0.01233673 -0.31835938] 3   5 \n",
      "[-0.7548828   0.3059082   0.31591797  0.4868164   0.06451416 -0.31884766] 3   1 \n",
      "[-1.0439453   0.31030273  0.1381836   0.37036133  0.34594727  0.15698242] 3   2 \n",
      "[-0.7597656   0.43188477  0.16540527  0.02444458  0.16638184  0.33154297] 1   1 Match 280\n",
      "\n",
      "[-1.5078125   0.15515137 -0.12420654  0.43701172  0.8671875   0.8691406 ] 5   4 \n",
      "[-1.5566406   0.02442932 -0.15161133  0.7060547   1.0048828   0.73828125] 4   3 \n",
      "[-1.6035156  -0.19616699 -0.18701172  0.6098633   0.80615234  0.8173828 ] 5   5 Match 281\n",
      "\n",
      "[ 0.14025879  0.28930664  0.20605469  0.01977539 -0.55859375 -0.65966797] 1   0 \n",
      "[-1.6416016   0.15014648 -0.22106934  0.85253906  0.87402344  0.421875  ] 4   4 Match 282\n",
      "\n",
      "[-0.4020996   0.39990234  0.1907959   0.09179688 -0.17077637 -0.10327148] 1   1 Match 283\n",
      "\n",
      "[-1.5976562  -0.14538574 -0.15686035  0.9711914   1.0253906   0.67285156] 4   2 \n",
      "[-0.39526367  0.35107422  0.2019043   0.05770874 -0.11920166 -0.27270508] 1   5 \n",
      "[-1.2255859   0.14904785 -0.01095581  0.6772461   0.50439453  0.24633789] 3   5 \n",
      "[-1.6035156  -0.01539612 -0.38842773  0.3618164   1.0332031   0.7949219 ] 4   5 \n",
      "[-1.4853516  -0.05407715 -0.08996582  0.9194336   0.91552734  0.48242188] 3   3 Match 284\n",
      "\n",
      "[-0.55371094  0.32055664  0.37353516  0.27124023 -0.04833984 -0.18945312] 2   2 Match 285\n",
      "\n",
      "[-0.09887695  0.31860352  0.3088379  -0.03384399 -0.46313477 -0.47021484] 1   3 \n",
      "[-0.23791504  0.18395996  0.41992188  0.43432617 -0.3334961  -0.60595703] 3   1 \n",
      "[-1.4960938   0.08782959 -0.1217041   0.6118164   0.95214844  0.69140625] 4   1 \n",
      "[-1.3095703   0.16345215 -0.02566528  0.73095703  0.6904297   0.12878418] 3   5 \n",
      "[-0.41723633  0.2084961   0.26464844  0.37475586 -0.08605957 -0.34277344] 3   1 \n",
      "[-0.2680664  -0.00099277  0.20275879  0.27172852 -0.3071289  -0.13891602] 3   0 \n",
      "[-1.5234375  -0.13452148 -0.14758301  0.8510742   1.0654297   0.69628906] 4   0 \n",
      "[-0.55566406  0.24401855  0.30444336  0.53515625 -0.08514404 -0.5229492 ] 3   5 \n",
      "[-0.421875    0.46289062  0.1697998  -0.01841736 -0.03234863 -0.08013916] 1   1 Match 286\n",
      "\n",
      "[-0.8364258   0.41796875  0.03016663 -0.02952576  0.18603516  0.54541016] 5   4 \n",
      "[ 0.05487061  0.35131836  0.20837402 -0.01643372 -0.5288086  -0.44262695] 1   3 \n",
      "[-1.0185547   0.2980957   0.14941406  0.58203125  0.39013672 -0.09490967] 3   1 \n",
      "[-0.859375    0.17687988  0.4182129   0.64208984  0.16113281 -0.22253418] 3   4 \n",
      "[-1.09375     0.41992188  0.23608398  0.5395508   0.45922852  0.04394531] 3   1 \n",
      "[-1.1396484   0.3088379   0.13330078  0.41601562  0.33203125  0.08776855] 3   0 \n",
      "[ 0.09558105  0.13916016  0.21777344  0.1595459  -0.5449219  -0.85595703] 2   0 \n",
      "[-0.81396484  0.35229492  0.12756348  0.17077637  0.24267578  0.08825684] 1   4 \n",
      "[-1.1523438   0.14953613  0.12597656  0.7558594   0.48950195  0.1307373 ] 3   4 \n",
      "[-0.8798828   0.03131104  0.07568359  0.5415039   0.16137695  0.20031738] 3   1 \n",
      "[-1.6005859   0.13745117 -0.19995117  0.6777344   0.8828125   0.64941406] 4   4 Match 287\n",
      "\n",
      "[-1.2246094  -0.04849243  0.17932129  0.8540039   0.59765625  0.18579102] 3   2 \n",
      "[-1.4238281  -0.03399658 -0.08166504  0.87402344  0.6850586   0.31933594] 3   1 \n",
      "[-0.12408447  0.24230957  0.3605957   0.09735107 -0.40698242 -0.4099121 ] 2   3 \n",
      "[-1.2421875   0.19848633 -0.07775879  0.76416016  0.6464844   0.11553955] 3   5 \n",
      "[-1.1484375   0.31298828  0.13696289  0.69189453  0.55126953 -0.21520996] 3   5 \n",
      "[-0.11199951  0.20959473  0.31323242  0.2758789  -0.39770508 -0.6694336 ] 2   5 \n",
      "[-0.73583984  0.18164062  0.28344727  0.45361328 -0.0035038  -0.2824707 ] 3   2 \n",
      "[-1.1220703   0.24072266  0.07519531  0.43432617  0.4506836   0.20788574] 4   3 \n",
      "[-1.6113281  -0.12683105 -0.22814941  0.72558594  1.1035156   0.65283203] 4   5 \n",
      "[-0.9526367   0.2376709  -0.04385376  0.21032715  0.421875    0.5966797 ] 5   4 \n",
      "[-1.2607422   0.1003418  -0.01617432  0.52441406  0.85595703  0.5732422 ] 4   1 \n",
      "[-0.23376465  0.16784668  0.20458984  0.20812988 -0.24475098 -0.23547363] 3   2 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.0810547   0.35888672  0.03646851  0.3774414   0.4033203   0.34814453] 4   1 \n",
      "[-0.88671875  0.23010254  0.2692871   0.5727539   0.21716309 -0.04107666] 3   2 \n",
      "[-0.79833984  0.32836914  0.1505127   0.32861328  0.20214844 -0.04464722] 3   3 Match 288\n",
      "\n",
      "[ 0.31323242  0.23303223  0.36157227  0.05444336 -0.6196289  -0.5493164 ] 2   1 \n",
      "[-0.6640625   0.24975586  0.20349121  0.43676758 -0.03083801 -0.2614746 ] 3   3 Match 289\n",
      "\n",
      "[ 0.03799438  0.3046875   0.2668457  -0.0103302  -0.5698242  -0.59472656] 1   4 \n",
      "[-0.6176758   0.31079102  0.34838867  0.25805664 -0.03222656 -0.08831787] 2   2 Match 290\n",
      "\n",
      "[-0.7739258   0.23474121  0.3959961   0.46728516  0.13000488 -0.25512695] 3   5 \n",
      "[-0.0736084   0.37817383  0.2763672  -0.06536865 -0.3869629  -0.21166992] 1   1 Match 291\n",
      "\n",
      "[-1.1054688   0.39672852  0.07867432  0.28466797  0.40063477  0.29174805] 4   4 Match 292\n",
      "\n",
      "[-0.98876953  0.08197021  0.23706055  0.81396484  0.41577148 -0.21679688] 3   4 \n",
      "[-0.7861328   0.2998047   0.14172363  0.27661133  0.13366699  0.1652832 ] 1   2 \n",
      "[-0.10552979  0.22265625  0.28344727  0.15637207 -0.43041992 -0.47485352] 2   2 Match 293\n",
      "\n",
      "[-0.31689453  0.06628418  0.28027344  0.4807129  -0.20898438 -0.38598633] 3   2 \n",
      "[ 0.15527344  0.30517578  0.35131836  0.02716064 -0.6147461  -0.5229492 ] 2   0 \n",
      "[-0.39672852  0.17663574  0.42895508  0.39501953 -0.20239258 -0.51123047] 2   1 \n",
      "[-1.3886719   0.10144043  0.17260742  0.8041992   0.7211914   0.40673828] 3   5 \n",
      "[-0.16748047  0.4765625   0.3022461  -0.09008789 -0.32788086 -0.06054688] 1   1 Match 294\n",
      "\n",
      "[-0.4729004   0.20251465  0.4423828   0.45117188 -0.14404297 -0.53466797] 3   1 \n",
      "[-1.3066406   0.35546875  0.01753235  0.4909668   0.7167969   0.48901367] 4   2 \n",
      "[-1.3437500e+00  2.1398926e-01  1.2950897e-03  7.6757812e-01\n",
      "  8.6230469e-01  3.3203125e-01] 4   4 Match 295\n",
      "\n",
      "[-1.2314453   0.3293457  -0.18518066  0.13916016  0.4909668   0.73779297] 5   2 \n",
      "[-1.6210938  0.0304718 -0.2064209  0.6484375  0.9951172  0.8911133] 4   5 \n",
      "[-1.3994141   0.16223145 -0.04953003  0.5209961   0.953125    0.7114258 ] 4   1 \n",
      "[-0.27783203  0.41381836  0.30273438 -0.16418457 -0.3774414  -0.19628906] 1   3 \n",
      "[-1.390625    0.06695557 -0.10528564  0.59521484  0.8754883   0.7163086 ] 4   3 \n",
      "[-1.6035156  -0.40185547 -0.23693848  0.76416016  1.1113281   0.7993164 ] 4   3 \n",
      "[-1.4121094   0.32202148 -0.05841064  0.63720703  0.6816406   0.47631836] 4   2 \n",
      "[-0.61572266  0.02305603  0.3190918   0.54296875  0.01465607 -0.40942383] 3   3 Match 296\n",
      "\n",
      "[ 0.4020996   0.12261963  0.2479248   0.00523376 -0.64404297 -0.83251953] 0   2 \n",
      "[-0.6972656   0.35498047  0.04006958  0.33935547  0.22277832  0.04437256] 1   5 \n",
      "[-1.6513672   0.0453186  -0.24829102  0.7680664   1.0048828   0.7036133 ] 4   4 Match 297\n",
      "\n",
      "[-1.5830078  -0.23608398 -0.37231445  0.6508789   1.0439453   0.78808594] 4   3 \n",
      "[-1.1992188   0.30737305 -0.04049683  0.2770996   0.5527344   0.64208984] 5   4 \n",
      "[-0.9628906  -0.08959961  0.28564453  0.9482422   0.29907227 -0.02320862] 3   3 Match 298\n",
      "\n",
      "[-1.4804688  -0.11889648  0.07928467  1.0263672   0.77734375  0.35986328] 3   4 \n",
      "[ 0.11132812  0.36987305  0.2607422  -0.22766113 -0.4572754  -0.25073242] 1   1 Match 299\n",
      "\n",
      "[-1.4443359   0.18310547 -0.13146973  0.7265625   1.0361328   0.5473633 ] 4   1 \n",
      "[ 0.28100586  0.28735352  0.25708008  0.00647354 -0.62597656 -0.796875  ] 1   3 \n",
      "[-0.21044922  0.29077148  0.24963379  0.1508789  -0.3947754  -0.48657227] 1   1 Match 300\n",
      "\n",
      "[-1.4912109   0.0682373  -0.1381836   0.54785156  0.9633789   0.8803711 ] 4   3 \n",
      "[-0.38623047  0.15710449  0.38085938  0.5488281  -0.27246094 -0.77978516] 3   3 Match 301\n",
      "\n",
      "[-1.1708984   0.08282471  0.22583008  0.921875    0.34399414 -0.19909668] 3   3 Match 302\n",
      "\n",
      "[-0.3564453   0.59716797  0.17028809 -0.2746582  -0.22619629  0.14208984] 1   1 Match 303\n",
      "\n",
      "[-1.0791016   0.14978027  0.20019531  0.7832031   0.3334961  -0.05715942] 3   5 \n",
      "[-0.33911133  0.32373047  0.29663086  0.14367676 -0.35302734 -0.47753906] 1   0 \n",
      "[-0.42651367  0.6503906   0.08007812 -0.30371094 -0.02857971  0.3449707 ] 1   0 \n",
      "[-1.2089844   0.21691895  0.0102005   0.6303711   0.66845703  0.18029785] 4   4 Match 304\n",
      "\n",
      "[-0.87646484  0.2841797   0.23730469  0.56591797  0.18688965 -0.26000977] 3   3 Match 305\n",
      "\n",
      "[-1.          0.31689453  0.06878662  0.25439453  0.20581055  0.27001953] 1   4 \n",
      "[-0.5751953   0.06738281  0.3371582   0.7675781  -0.05679321 -0.55566406] 3   2 \n",
      "[-1.3496094   0.20410156 -0.05963135  0.40063477  0.8120117   0.7529297 ] 4   0 \n",
      "[-1.5566406  -0.04156494 -0.05670166  0.83691406  1.0029297   0.7680664 ] 4   2 \n",
      "[-0.72509766  0.06842041  0.36743164  0.76464844  0.09020996 -0.3918457 ] 3   3 Match 306\n",
      "\n",
      "[-1.4423828   0.1472168  -0.0188446   0.5541992   0.64746094  0.35864258] 4   4 Match 307\n",
      "\n",
      "[ 0.27490234  0.27319336  0.22888184 -0.04022217 -0.62353516 -0.7910156 ] 0   1 \n",
      "[-1.2011719   0.27246094  0.09533691  0.75097656  0.6088867   0.10491943] 3   5 \n",
      "[-0.11663818  0.44335938  0.21582031 -0.2878418  -0.36450195  0.0010004 ] 1   0 \n",
      "[ 0.11950684  0.2286377   0.22790527 -0.05825806 -0.4921875  -0.6010742 ] 1   1 Match 308\n",
      "\n",
      "[-0.09777832  0.31591797  0.2763672   0.06488037 -0.4819336  -0.59472656] 1   0 \n",
      "[-1.0839844   0.05877686  0.29296875  0.7714844   0.4104004  -0.06021118] 3   4 \n",
      "[-0.61816406  0.51464844 -0.04580688 -0.33374023  0.04544067  0.4284668 ] 1   0 \n",
      "[-0.02761841  0.32348633  0.19750977 -0.15002441 -0.42236328 -0.14709473] 1   1 Match 309\n",
      "\n",
      "[-0.421875    0.19421387  0.3671875   0.4494629  -0.13647461 -0.42016602] 3   2 \n",
      "[-1.6142578  -0.0847168  -0.31152344  0.64208984  1.0986328   0.78222656] 4   2 \n",
      "[-1.5097656  -0.35742188 -0.04931641  0.84472656  1.0585938   0.9404297 ] 4   0 \n",
      "[-0.58984375  0.3137207   0.2232666   0.5078125   0.04431152 -0.5024414 ] 3   1 \n",
      "[-0.00834656  0.27075195  0.34472656  0.03601074 -0.39916992 -0.30859375] 2   2 Match 310\n",
      "\n",
      "[-1.3701172  -0.10284424  0.00599289  0.89746094  0.671875    0.3269043 ] 3   5 \n",
      "[-0.06188965  0.41674805  0.31591797 -0.0770874  -0.45458984 -0.35717773] 1   2 \n",
      "[ 0.00067759  0.27490234  0.27807617  0.13562012 -0.42333984 -0.6298828 ] 2   5 \n",
      "[-1.0380859   0.39794922  0.14379883  0.4194336   0.48706055  0.06646729] 4   5 \n",
      "[-1.3144531   0.14123535  0.04669189  0.62402344  0.63623047  0.29125977] 4   4 Match 311\n",
      "\n",
      "[-1.4775391  -0.01885986 -0.08007812  0.84765625  0.92578125  0.45385742] 4   3 \n",
      "[-1.2167969   0.0682373   0.04821777  0.54785156  0.6767578   0.38183594] 4   4 Match 312\n",
      "\n",
      "[-1.6386719  -0.1784668  -0.4206543   0.48632812  1.0244141   0.8022461 ] 4   3 \n",
      "[-0.12426758  0.3947754   0.1661377  -0.0118103  -0.4165039  -0.58496094] 1   1 Match 313\n",
      "\n",
      "[-1.5400391   0.01428986 -0.17663574  0.5708008   0.96533203  0.8984375 ] 4   1 \n",
      "[-0.1352539   0.52783203  0.25854492 -0.15466309 -0.3474121  -0.02787781] 1   1 Match 314\n",
      "\n",
      "[-0.1427002   0.21984863  0.2939453   0.21936035 -0.41601562 -0.46850586] 2   1 \n",
      "[-0.09228516  0.39990234  0.296875   -0.07116699 -0.4970703  -0.3425293 ] 1   5 \n",
      "[-0.93359375  0.28564453  0.26391602  0.54785156  0.19970703 -0.27905273] 3   2 \n",
      "[-1.4716797  -0.01512909 -0.3647461   0.23022461  0.9248047   0.8754883 ] 4   0 \n",
      "[-0.7055664   0.42163086  0.24230957  0.44702148  0.07879639 -0.33007812] 3   3 Match 315\n",
      "\n",
      "315\n"
     ]
    }
   ],
   "source": [
    "Pred=[]\n",
    "\n",
    "countCorrect=0\n",
    "\n",
    "for row in range(TestModel_outputs.shape[0]):\n",
    "    outputs=TestModel_outputs[row]\n",
    "    #print(test.iloc[row,0])\n",
    "    print(outputs, end=' ')\n",
    "    \n",
    "    result=0\n",
    "    if outputs[0]<outputs[1]:result=1\n",
    "    if outputs[result]<outputs[2]:result=2\n",
    "    if outputs[result]<outputs[3]:result=3\n",
    "    if outputs[result]<outputs[4]:result=4\n",
    "    if outputs[result]<outputs[5]:result=5\n",
    "    Pred.append(result)\n",
    "    print(result, ' ',test.iloc[row,1], end=' ')\n",
    "    if result==test.iloc[row,1]:\n",
    "        countCorrect+=1\n",
    "        print('Match',countCorrect)\n",
    "    print('')\n",
    "\n",
    "print(countCorrect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 3 38 18 20  8  4]\n",
      " [ 2 83 19 68 50 11]\n",
      " [ 2 63 18 90 35 13]\n",
      " [ 0 57 24 96 70  8]\n",
      " [ 0 39  8 83 97 22]\n",
      " [ 1 45  9 60 73 18]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "print(metrics.confusion_matrix(test['labels'],Pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Pants       0.38      0.03      0.06        91\n",
      "       False       0.26      0.36      0.30       233\n",
      " Barely-True       0.19      0.08      0.11       221\n",
      "   Half-True       0.23      0.38      0.29       255\n",
      " Mostly-True       0.29      0.39      0.33       249\n",
      "        True       0.24      0.09      0.13       206\n",
      "\n",
      "    accuracy                           0.25      1255\n",
      "   macro avg       0.26      0.22      0.20      1255\n",
      "weighted avg       0.25      0.25      0.22      1255\n",
      "\n"
     ]
    }
   ],
   "source": [
    "target_names = ['Pants', 'False', 'Barely-True','Half-True','Mostly-True','True']\n",
    "\n",
    "print(metrics.classification_report(test['labels'], Pred,target_names =target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving...\n",
      "Saving Complete on 2020-05-01 11:01:00.724276 in: ./TunedModels/albert/albert-large-v2/Saves/\n"
     ]
    }
   ],
   "source": [
    "# saving the output of the models to CSVs\n",
    "#these are 1X6 classification vectors\n",
    "\n",
    "SavesDirectory='./TunedModels/'+model_class+'/'+model_version+\"/Saves/\"\n",
    "print('Saving...')\n",
    "trainOut = pd.DataFrame(data= TrainModel_outputs )\n",
    "trainOut.to_csv(SavesDirectory+'trainOut.tsv', sep='\\t',  index=False)\n",
    "\n",
    "evalOut = pd.DataFrame(data= EvalModel_outputs )\n",
    "evalOut.to_csv(SavesDirectory+'evalOut.tsv', sep='\\t',  index=False)\n",
    "\n",
    "testOut = pd.DataFrame(data= TestModel_outputs )\n",
    "testOut.to_csv(SavesDirectory+'testOut.tsv', sep='\\t',  index=False)\n",
    "\n",
    "print('Saving Complete on',datetime.now() ,'in:', SavesDirectory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "del(model)\n",
    "#del(train,Eval,test)\n",
    "del(trainOut,evalOut,testOut)\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Adding the reputation vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section takes the output results from the transformer used above and uses it together with the speaker's reputation to enhance the classification.\n",
    "\n",
    "Before running this section it is suggested that you halt the program and start running it again from this cell. The neural net will likely have an error caused by some unreleased variable used by thr simple transformers library. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PantsTotal</th>\n",
       "      <th>NotRealTotal</th>\n",
       "      <th>BarelyTotal</th>\n",
       "      <th>HalfTotal</th>\n",
       "      <th>MostlyTotal</th>\n",
       "      <th>RealTotal</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.005</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.251709</td>\n",
       "      <td>0.507812</td>\n",
       "      <td>0.165771</td>\n",
       "      <td>-0.336426</td>\n",
       "      <td>-0.629395</td>\n",
       "      <td>-0.468018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.005</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.285400</td>\n",
       "      <td>0.240112</td>\n",
       "      <td>0.230591</td>\n",
       "      <td>0.284180</td>\n",
       "      <td>-0.336182</td>\n",
       "      <td>-0.511719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.005</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.137207</td>\n",
       "      <td>0.454590</td>\n",
       "      <td>0.310059</td>\n",
       "      <td>-0.156128</td>\n",
       "      <td>-0.430908</td>\n",
       "      <td>-0.191650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.269531</td>\n",
       "      <td>0.150269</td>\n",
       "      <td>0.098450</td>\n",
       "      <td>0.658691</td>\n",
       "      <td>0.732422</td>\n",
       "      <td>0.282959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.560547</td>\n",
       "      <td>-0.055054</td>\n",
       "      <td>-0.488525</td>\n",
       "      <td>0.243530</td>\n",
       "      <td>1.099609</td>\n",
       "      <td>0.950684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10094</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.088867</td>\n",
       "      <td>0.264404</td>\n",
       "      <td>0.211792</td>\n",
       "      <td>0.831543</td>\n",
       "      <td>0.363037</td>\n",
       "      <td>-0.169678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10095</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.488281</td>\n",
       "      <td>0.141235</td>\n",
       "      <td>0.070374</td>\n",
       "      <td>0.853027</td>\n",
       "      <td>0.795898</td>\n",
       "      <td>0.498535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10096</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.198120</td>\n",
       "      <td>0.395020</td>\n",
       "      <td>0.268311</td>\n",
       "      <td>-0.198730</td>\n",
       "      <td>-0.600586</td>\n",
       "      <td>-0.487793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10097</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.303223</td>\n",
       "      <td>0.244751</td>\n",
       "      <td>0.422363</td>\n",
       "      <td>0.350830</td>\n",
       "      <td>-0.297852</td>\n",
       "      <td>-0.516602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10098</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.222656</td>\n",
       "      <td>0.312500</td>\n",
       "      <td>-0.013275</td>\n",
       "      <td>0.397461</td>\n",
       "      <td>0.518555</td>\n",
       "      <td>0.350342</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10099 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       PantsTotal  NotRealTotal  BarelyTotal  HalfTotal  MostlyTotal  \\\n",
       "0           0.005         0.000         0.00      0.000        0.000   \n",
       "1           0.005         0.000         0.01      0.000        0.000   \n",
       "2           0.005         0.000         0.01      0.000        0.000   \n",
       "3           0.000         0.000         0.00      0.000        0.005   \n",
       "4           0.000         0.000         0.00      0.000        0.005   \n",
       "...           ...           ...          ...        ...          ...   \n",
       "10094       0.000         0.005         0.00      0.000        0.010   \n",
       "10095       0.000         0.005         0.00      0.000        0.010   \n",
       "10096       0.000         0.005         0.00      0.000        0.010   \n",
       "10097       0.000         0.000         0.00      0.005        0.000   \n",
       "10098       0.000         0.000         0.00      0.000        0.005   \n",
       "\n",
       "       RealTotal         0         1         2         3         4         5  \n",
       "0            0.0  0.251709  0.507812  0.165771 -0.336426 -0.629395 -0.468018  \n",
       "1            0.0 -0.285400  0.240112  0.230591  0.284180 -0.336182 -0.511719  \n",
       "2            0.0 -0.137207  0.454590  0.310059 -0.156128 -0.430908 -0.191650  \n",
       "3            0.0 -1.269531  0.150269  0.098450  0.658691  0.732422  0.282959  \n",
       "4            0.0 -1.560547 -0.055054 -0.488525  0.243530  1.099609  0.950684  \n",
       "...          ...       ...       ...       ...       ...       ...       ...  \n",
       "10094        0.0 -1.088867  0.264404  0.211792  0.831543  0.363037 -0.169678  \n",
       "10095        0.0 -1.488281  0.141235  0.070374  0.853027  0.795898  0.498535  \n",
       "10096        0.0  0.198120  0.395020  0.268311 -0.198730 -0.600586 -0.487793  \n",
       "10097        0.0 -0.303223  0.244751  0.422363  0.350830 -0.297852 -0.516602  \n",
       "10098        0.0 -1.222656  0.312500 -0.013275  0.397461  0.518555  0.350342  \n",
       "\n",
       "[10099 rows x 12 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "train=pd.read_excel('train-clean-Reputation.xlsx' )\n",
    "train=train.iloc[:,:-1].astype(float)\n",
    "train=train/200  #for scaling\n",
    "#train\n",
    "\n",
    "model_class='albert'  # bert or roberta or albert\n",
    "model_version='albert-large-v2' #bert-base-cased, roberta-base, roberta-large, albert-base-v2 OR albert-large-v2\n",
    "SavesDirectory='./TunedModels/'+model_class+'/'+model_version+\"/Saves/\"\n",
    "TF_Output=pd.read_csv( SavesDirectory+'trainOut.tsv', sep='\\t')\n",
    "\n",
    "train=pd.concat([train,TF_Output], axis=1)\n",
    "\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10094</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10095</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10096</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10097</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10098</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10099 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0  1  2  3  4  5\n",
       "0      1  0  0  0  0  0\n",
       "1      1  0  0  0  0  0\n",
       "2      0  0  1  0  0  0\n",
       "3      0  0  0  0  1  0\n",
       "4      0  0  0  0  1  0\n",
       "...   .. .. .. .. .. ..\n",
       "10094  0  1  0  0  0  0\n",
       "10095  0  0  0  0  1  0\n",
       "10096  0  0  0  0  1  0\n",
       "10097  0  0  0  1  0  0\n",
       "10098  0  0  0  0  1  0\n",
       "\n",
       "[10099 rows x 6 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TrainLables=pd.read_excel('train-clean-Reputation.xlsx' )\n",
    "TrainLables=TrainLables.iloc[:,-1] \n",
    "\n",
    "TrainLables=pd.get_dummies(TrainLables)\n",
    "TrainLables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0050,  0.0000,  0.0000,  ..., -0.3364, -0.6294, -0.4680],\n",
       "        [ 0.0050,  0.0000,  0.0100,  ...,  0.2842, -0.3362, -0.5117],\n",
       "        [ 0.0050,  0.0000,  0.0100,  ..., -0.1561, -0.4309, -0.1917],\n",
       "        ...,\n",
       "        [ 0.0000,  0.0050,  0.0000,  ..., -0.1987, -0.6006, -0.4878],\n",
       "        [ 0.0000,  0.0000,  0.0000,  ...,  0.3508, -0.2979, -0.5166],\n",
       "        [ 0.0000,  0.0000,  0.0000,  ...,  0.3975,  0.5186,  0.3503]],\n",
       "       dtype=torch.float64)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input=torch.tensor(train.values)\n",
    " \n",
    "input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 1., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 1., 0., 0.],\n",
       "        [0., 0., 0., 0., 1., 0.]], dtype=torch.float64)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets=torch.tensor(TrainLables.astype(float).values)\n",
    " \n",
    "targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input size: 12\n",
      "output size: 6\n"
     ]
    }
   ],
   "source": [
    " \n",
    "size= torch.tensor(input[0].size())\n",
    "InputSize=size.item()\n",
    "\n",
    "OutputSize=torch.tensor(targets[0].size()).item()\n",
    "\n",
    "print('input size:', InputSize)\n",
    "print('output size:', OutputSize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Net(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "         \n",
    "        # an affine operation: y = Wx + b\n",
    "        self.fc1 = nn.Linear(InputSize, 24)  # input size 32\n",
    "        self.fc2 = nn.Linear(24, 12)\n",
    "        self.fc3 = nn.Linear(12, OutputSize)  #classifies 'outputsize' different classes\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.tanh(self.fc1(x))\n",
    "        x = torch.tanh(self.fc2(x)) \n",
    "        x = torch.tanh(self.fc3(x)).double()\n",
    "        return x\n",
    "\n",
    "    \n",
    "\n",
    "#now we use it\n",
    "\n",
    "net = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here we  setup the neural network parameters\n",
    "# pick an optimizer (Simple Gradient Descent)\n",
    "\n",
    "learning_rate = 1e-4\n",
    "criterion = nn.MSELoss()  #computes the loss Function\n",
    "\n",
    "import torch.optim as optim\n",
    "\n",
    "# creating optimizer\n",
    "#optimizer = optim.SGD(net.parameters(), lr=learning_rate)\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor(0.0947, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 0\n",
      "Loss: tensor(0.0947, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1\n",
      "Loss: tensor(0.0947, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2\n",
      "Loss: tensor(0.0947, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3\n",
      "Loss: tensor(0.0947, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4\n",
      "Loss: tensor(0.0947, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5\n",
      "Loss: tensor(0.0947, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6\n",
      "Loss: tensor(0.0947, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7\n",
      "Loss: tensor(0.0947, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8\n",
      "Loss: tensor(0.0947, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 9\n",
      "Loss: tensor(0.0947, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 10\n",
      "Loss: tensor(0.0947, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 11\n",
      "Loss: tensor(0.0947, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 12\n",
      "Loss: tensor(0.0947, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 13\n",
      "Loss: tensor(0.0947, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 14\n",
      "Loss: tensor(0.0947, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 15\n",
      "Loss: tensor(0.0947, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 16\n",
      "Loss: tensor(0.0947, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 17\n",
      "Loss: tensor(0.0947, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 18\n",
      "Loss: tensor(0.0947, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 19\n",
      "Loss: tensor(0.0947, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 20\n",
      "Loss: tensor(0.0947, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 21\n",
      "Loss: tensor(0.0947, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 22\n",
      "Loss: tensor(0.0947, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 23\n",
      "Loss: tensor(0.0947, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 24\n",
      "Loss: tensor(0.0947, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 25\n",
      "Loss: tensor(0.0947, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 26\n",
      "Loss: tensor(0.0947, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 27\n",
      "Loss: tensor(0.0947, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 28\n",
      "Loss: tensor(0.0947, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 29\n",
      "Loss: tensor(0.0947, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 30\n",
      "Loss: tensor(0.0947, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 31\n",
      "Loss: tensor(0.0947, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 32\n",
      "Loss: tensor(0.0947, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 33\n",
      "Loss: tensor(0.0947, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 34\n",
      "Loss: tensor(0.0947, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 35\n",
      "Loss: tensor(0.0947, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 36\n",
      "Loss: tensor(0.0947, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 37\n",
      "Loss: tensor(0.0947, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 38\n",
      "Loss: tensor(0.0947, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 39\n",
      "Loss: tensor(0.0947, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 40\n",
      "Loss: tensor(0.0947, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 41\n",
      "Loss: tensor(0.0947, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 42\n",
      "Loss: tensor(0.0947, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 43\n",
      "Loss: tensor(0.0947, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 44\n",
      "Loss: tensor(0.0947, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 45\n",
      "Loss: tensor(0.0947, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 46\n",
      "Loss: tensor(0.0947, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 47\n",
      "Loss: tensor(0.0947, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 48\n",
      "Loss: tensor(0.0947, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 49\n",
      "Loss: tensor(0.0947, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 50\n",
      "Loss: tensor(0.0947, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 51\n",
      "Loss: tensor(0.0947, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 52\n",
      "Loss: tensor(0.0947, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 53\n",
      "Loss: tensor(0.0947, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 54\n",
      "Loss: tensor(0.0947, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 55\n",
      "Loss: tensor(0.0947, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 56\n",
      "Loss: tensor(0.0947, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 57\n",
      "Loss: tensor(0.0947, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 58\n",
      "Loss: tensor(0.0947, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 59\n",
      "Loss: tensor(0.0947, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 60\n",
      "Loss: tensor(0.0947, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 61\n",
      "Loss: tensor(0.0947, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 62\n",
      "Loss: tensor(0.0947, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 63\n",
      "Loss: tensor(0.0947, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 64\n",
      "Loss: tensor(0.0947, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 65\n",
      "Loss: tensor(0.0947, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 66\n",
      "Loss: tensor(0.0947, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 67\n",
      "Loss: tensor(0.0947, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 68\n",
      "Loss: tensor(0.0947, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 69\n",
      "Loss: tensor(0.0947, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 70\n",
      "Loss: tensor(0.0947, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 71\n",
      "Loss: tensor(0.0947, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 72\n",
      "Loss: tensor(0.0947, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 73\n",
      "Loss: tensor(0.0947, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 74\n",
      "Loss: tensor(0.0947, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 75\n",
      "Loss: tensor(0.0947, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 76\n",
      "Loss: tensor(0.0947, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 77\n",
      "Loss: tensor(0.0947, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 78\n",
      "Loss: tensor(0.0947, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 79\n",
      "Loss: tensor(0.0947, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 80\n",
      "Loss: tensor(0.0947, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 81\n",
      "Loss: tensor(0.0947, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 82\n",
      "Loss: tensor(0.0947, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 83\n",
      "Loss: tensor(0.0947, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 84\n",
      "Loss: tensor(0.0947, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 85\n",
      "Loss: tensor(0.0947, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 86\n",
      "Loss: tensor(0.0947, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 87\n",
      "Loss: tensor(0.0947, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 88\n",
      "Loss: tensor(0.0947, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 89\n",
      "Loss: tensor(0.0947, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 90\n",
      "Loss: tensor(0.0947, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 91\n",
      "Loss: tensor(0.0947, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 92\n",
      "Loss: tensor(0.0947, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 93\n",
      "Loss: tensor(0.0947, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 94\n",
      "Loss: tensor(0.0947, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 95\n",
      "Loss: tensor(0.0947, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 96\n",
      "Loss: tensor(0.0947, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 97\n",
      "Loss: tensor(0.0947, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 98\n",
      "Loss: tensor(0.0947, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 99\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(100):  \n",
    "        \n",
    "    optimizer.zero_grad()   # zero the gradient buffers\n",
    "    output = net(input.float())\n",
    "\n",
    "    loss = criterion(output, targets)\n",
    "    print('Loss:', loss, ' at epoch:', epoch)\n",
    "\n",
    "    loss.backward()  #backprop\n",
    "    optimizer.step()    # Does the update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load previously saved FCNN model \n",
    "\n",
    "stage='NNetwork6WayClassification/'\n",
    "SavesDirectory='./TunedModels/'+model_class+'/'+model_version+\"/\"+stage\n",
    "#PATH = SavesDirectory+'Tanh_MSE_adam4781.pth'\n",
    "\n",
    "net = Net()\n",
    "net.load_state_dict(torch.load(PATH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 2 2 4 4 5 3 3 4 3 5 5 4 4 3 3 3 3 5 3 3 1 4 1 1 1 5 1 4 4 5 1 5 4 1 0 3 5 3 4 2 2 3 3 2 2 4 1 1 2 4 4 5 4 4 4 4 1 1 2 1 4 4 4 4 4 4 4 4 1 4 1 4 4 4 1 4 4 4 4 2 2 2 5 4 5 3 1 5 5 3 5 3 4 1 0 0 0 0 5 2 5 5 1 5 5 5 5 4 5 5 5 5 5 5 5 5 5 5 5 5 3 0 3 4 3 3 3 3 1 5 4 1 3 1 3 3 3 3 3 5 1 4 1 1 4 1 1 1 4 5 4 4 4 5 1 1 1 1 1 1 1 1 2 1 2 1 1 1 1 1 1 1 1 3 3 2 2 2 2 2 2 5 4 4 4 4 0 1 2 0 3 3 2 4 1 1 4 4 2 2 2 3 3 1 3 3 1 2 3 2 3 1 3 0 2 2 2 2 4 4 4 4 1 3 0 0 4 4 3 3 5 2 3 3 2 2 2 2 1 1 2 2 1 2 2 1 1 2 2 2 3 3 3 3 4 4 4 2 2 2 2 2 2 3 1 3 3 3 1 3 1 1 2 3 3 2 2 3 3 3 5 2 4 4 4 3 1 3 3 4 3 4 0 1 5 5 5 5 5 0 3 0 2 3 3 1 4 3 4 1 3 2 4 4 1 3 3 3 4 1 1 2 1 3 0 3 3 5 3 0 3 3 0 1 5 4 4 4 2 2 5 3 3 3 3 3 2 3 3 4 2 1 4 4 1 4 3 4 1 3 2 3 3 0 4 3 3 4 4 3 3 1 3 4 2 4 2 2 4 5 3 3 3 4 1 4 3 4 4 4 1 4 4 4 1 2 3 0 5 5 5 5 4 5 5 1 4 4 4 4 1 4 2 5 5 1 5 5 3 1 1 4 1 4 2 4 5 3 3 3 3 3 3 4 2 3 5 3 3 3 3 3 4 5 5 3 4 4 4 4 5 4 4 4 5 5 3 3 1 5 4 5 3 5 4 2 3 3 4 4 3 4 4 3 3 3 5 3 4 3 5 2 3 3 5 5 5 5 5 3 4 4 3 3 5 4 2 3 5 3 5 5 5 3 1 5 5 3 3 3 3 4 3 5 3 3 4 5 5 4 4 3 4 3 4 4 5 5 4 4 3 3 4 4 3 2 3 3 4 3 5 3 5 3 2 2 4 3 3 1 3 1 3 5 4 4 2 5 4 3 4 4 4 5 5 4 1 3 4 5 4 3 4 5 3 3 4 4 4 4 3 4 4 4 5 5 1 1 1 4 3 4 3 1 5 3 3 3 5 5 3 4 4 3 5 3 3 5 3 3 5 5 4 4 4 5 3 3 3 4 3 3 4 4 3 5 3 4 5 4 5 3 3 3 3 3 4 4 5 3 4 4 4 4 1 3 4 4 4 4 3 3 3 4 4 4 4 4 4 3 3 3 5 4 3 3 3 5 3 4 4 4 3 4 5 4 4 4 3 5 3 3 3 2 3 3 5 4 4 3 3 3 3 3 4 3 4 4 3 4 4 4 4 3 4 5 4 4 3 4 4 4 4 3 3 2 3 3 4 3 4 3 3 3 4 3 5 3 4 4 4 4 1 3 3 3 4 3 3 4 3 3 3 5 5 3 3 3 3 1 3 4 3 4 4 3 3 4 2 3 3 3 3 3 3 3 3 5 1 4 3 3 4 5 1 1 3 4 3 5 3 5 4 5 3 3 3 3 3 3 3 3 4 4 2 4 3 3 3 4 1 3 4 5 3 3 3 3 4 3 3 4 4 4 4 4 4 4 4 4 4 4 4 3 3 3 4 4 4 5 4 4 4 3 4 3 5 4 3 5 4 4 4 4 1 4 1 4 3 3 4 5 3 3 3 5 5 3 4 2 4 3 4 4 4 4 4 3 4 3 4 4 4 4 4 5 3 4 4 4 3 5 4 4 4 4 3 4 4 3 4 4 4 5 3 3 3 3 3 3 4 3 4 3 5 3 0 3 3 3 4 2 4 4 4 3 3 4 4 2 2 4 3 3 3 3 2 5 1 5 4 4 2 3 3 3 5 4 4 1 1 4 4 1 1 1 1 1 1 5 0 2 2 1 1 4 1 1 5 4 0 3 5 5 5 4 1 1 5 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 3 1 5 1 1 2 4 4 3 4 4 4 4 4 4 4 2 4 3 4 4 4 4 4 4 4 4 4 4 4 4 4 4 1 2 4 4 4 4 2 4 2 4 1 2 1 4 4 4 1 4 2 4 2 4 4 4 4 4 4 4 3 1 4 4 2 2 4 4 4 2 1 3 2 2 1 4 2 4 1 4 4 4 4 1 4 3 4 3 4 4 4 4 4 3 3 3 0 0 1 1 1 3 5 1 4 1 1 1 1 1 1 3 4 2 5 3 0 3 3 3 3 5 4 4 2 5 5 5 0 1 3 5 3 3 3 3 4 3 4 3 5 4 4 3 4 4 4 4 3 4 5 3 4 4 4 3 3 3 3 3 3 2 2 4 3 4 4 4 4 4 4 4 3 5 3 0 2 2 2 5 4 4 4 4 0 0 4 1 1 4 4 4 4 4 4 4 5 5 1 5 1 5 1 5 1 3 5 4 3 4 4 4 4 4 4 4 4 4 4 3 3 4 4 3 4 4 4 4 4 3 3 0 1 1 1 1 1 4 1 1 1 4 1 4 1 1 4 1 4 4 4 4 4 4 4 4 1 3 0 1 2 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 3 1 5 4 4 4 3 3 4 1 4 5 4 4 4 4 4 4 4 4 5 4 4 5 1 2 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 5 4 4 5 5 5 4 1 3 3 4 3 3 4 3 4 4 4 4 3 4 4 4 4 4 4 4 4 4 4 2 5 4 5 5 5 5 5 4 5 5 5 5 5 4 3 4 5 4 5 5 5 4 2 2 1 1 1 1 3 5 4 3 5 3 4 4 5 3 5 5 3 4 4 1 5 1 4 3 3 4 5 5 1 1 4 5 5 5 3 3 5 1 4 1 2 1 1 1 3 5 5 4 4 3 2 2 1 2 0 2 5 4 4 4 1 1 1 3 1 1 2 1 0 0 1 5 1 5 5 5 2 5 5 1 1 1 1 1 5 4 1 5 1 5 5 1 1 3 4 5 2 4 4 4 3 0 0 3 3 1 1 1 2 5 3 2 3 1 1 1 5 5 5 1 1 3 3 4 0 2 3 3 4 1 5 5 5 5 3 5 2 5 3 3 2 5 5 0 5 3 4 2 3 2 2 0 4 4 1 2 3 5 5 1 5 4 2 5 2 2 2 2 2 4 1 1 4 4 1 1 4 2 5 1 1 1 3 1 2 5 2 3 1 1 1 1 2 5 1 5 4 3 5 4 5 3 2 3 5 5 3 4 5 4 4 4 4 5 5 5 5 5 3 1 3 3 3 1 3 4 4 3 3 4 3 0 5 3 4 4 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 3 5 5 2 2 2 2 4 3 1 3 1 1 4 2 3 0 1 1 4 4 4 3 4 3 1 1 5 2 3 3 2 3 3 5 2 5 2 3 4 3 4 4 3 2 1 3 2 3 3 2 2 3 4 2 5 3 2 2 3 2 2 5 3 3 3 1 2 3 5 4 5 3 3 4 2 4 2 3 2 3 2 3 3 3 3 3 3 2 2 3 2 3 1 5 5 5 5 5 5 5 5 3 0 0 1 2 2 4 4 4 4 2 5 2 2 2 1 1 1 3 4 5 2 5 1 1 4 1 4 3 3 4 4 4 3 3 3 1 1 1 0 5 5 3 5 3 3 3 3 3 5 1 3 4 5 3 3 5 5 1 3 5 3 3 3 3 3 1 3 5 3 4 3 3 3 4 3 1 5 3 1 3 5 3 3 3 3 3 5 4 3 5 4 3 5 5 3 3 5 5 3 3 1 3 5 5 5 5 5 1 3 1 1 1 1 5 2 1 5 5 1 4 3 3 3 4 4 4 3 4 3 1 3 3 3 1 1 4 4 2 2 1 2 2 2 2 1 1 2 5 0 1 1 1 1 1 1 2 5 5 3 4 4 4 4 4 5 4 3 3 1 3 5 5 5 0 3 5 1 0 0 1 4 5 5 5 1 3 3 0 1 0 0 4 4 3 3 2 0 3 1 3 3 3 3 2 5 5 5 5 5 5 1 2 3 3 3 3 3 2 3 1 5 0 3 3 3 4 4 1 5 3 3 3 1 5 1 5 4 3 3 3 2 1 4 4 1 2 3 3 3 3 3 1 2 2 5 1 2 1 1 1 1 2 1 1 3 3 3 2 1 2 5 0 4 3 4 3 4 4 3 3 3 5 2 2 3 5 4 4 4 0 0 5 2 2 0 3 3 4 4 3 0 4 4 3 4 5 1 3 2 2 3 1 1 2 5 2 5 4 1 2 4 4 4 3 2 0 2 2 2 2 2 1 4 1 1 1 2 2 3 1 4 5 1 5 4 4 4 4 4 4 4 1 4 4 4 4 4 4 4 4 4 4 2 2 2 2 2 4 3 2 0 3 3 0 2 2 4 3 2 5 0 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 4 3 1 2 1 1 3 4 0 1 1 2 5 4 3 4 4 2 2 4 1 1 2 2 1 1 2 5 3 3 1 3 3 0 0 0 0 5 1 4 4 4 4 2 4 4 1 0 4 1 4 4 1 4 4 0 0 3 3 2 1 4 5 3 3 3 2 2 4 2 1 2 2 4 4 1 2 4 4 3 4 1 4 3 5 1 1 2 2 2 2 1 1 1 2 5 5 5 5 1 1 1 5 5 1 1 1 4 1 5 5 5 4 3 4 2 2 2 4 3 1 3 3 4 4 3 4 4 3 3 3 3 4 4 3 3 4 4 3 4 4 2 5 2 3 5 5 5 5 4 5 2 2 2 1 2 5 5 2 2 5 2 3 3 5 5 5 5 5 3 5 5 5 5 5 2 5 1 4 2 1 1 1 1 1 1 1 1 3 4 3 3 4 3 3 1 4 1 4 5 3 3 3 1 1 3 1 1 4 1 1 3 0 3 2 1 2 5 1 4 3 3 4 2 2 5 2 5 2 2 2 2 2 3 4 5 5 4 4 2 2 4 2 4 2 2 4 3 2 2 4 3 5 1 1 5 3 3 1 1 4 3 3 2 3 2 1 1 5 4 5 4 5 5 5 4 5 1 5 5 5 5 1 4 3 3 1 4 1 5 4 4 4 4 4 2 4 1 4 4 1 4 4 4 4 4 4 4 4 4 1 4 4 4 1 4 2 1 4 4 2 4 4 2 1 4 4 4 4 3 3 3 3 1 3 4 3 5 5 5 5 2 2 2 1 0 2 2 2 2 2 2 2 0 2 0 0 0 2 0 0 0 2 2 2 2 2 0 2 0 2 1 0 0 0 0 2 3 3 5 4 3 3 3 4 3 3 5 4 5 4 2 3 3 3 3 5 4 2 3 3 4 1 3 1 3 2 1 4 2 4 2 1 1 5 3 1 3 3 3 5 5 3 3 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 3 1 1 4 1 4 4 4 5 5 4 3 3 4 1 5 4 5 4 4 4 1 1 1 0 5 2 2 1 1 1 3 2 1 1 2 1 2 1 3 1 1 5 2 0 4 4 0 4 4 3 3 3 1 4 3 3 1 5 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 4 1 1 1 1 1 1 1 1 4 1 1 1 1 1 1 1 1 1 1 1 4 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 3 0 4 0 1 1 1 0 1 0 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 0 3 1 1 1 1 4 1 1 1 1 1 1 1 1 1 1 1 0 4 0 1 4 1 1 1 0 1 1 1 4 1 1 1 1 1 0 1 2 1 3 1 1 1 1 4 0 1 0 1 1 1 3 3 0 1 4 3 1 0 1 1 1 1 1 0 4 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 3 1 1 1 1 1 1 3 3 1 3 1 1 1 1 1 1 1 4 0 1 1 1 0 1 3 1 1 1 1 1 0 1 1 1 1 4 3 1 1 1 1 1 1 4 0 1 1 1 1 0 1 1 3 1 1 4 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 4 1 1 1 1 1 1 4 1 0 0 1 1 1 1 4 4 4 4 4 3 4 1 5 3 3 3 3 3 3 5 1 5 4 4 4 4 3 4 4 4 4 4 4 4 5 1 0 4 3 4 4 4 4 3 1 1 2 3 5 3 3 3 5 1 1 2 2 4 4 4 4 4 4 1 5 1 4 3 1 1 1 1 5 1 2 3 4 4 5 3 3 0 2 2 4 4 5 4 1 4 4 5 4 0 4 2 1 3 4 4 1 3 3 3 5 5 5 1 5 5 3 4 4 4 1 4 4 1 4 5 1 1 3 3 3 3 3 1 1 1 1 1 5 5 5 5 4 5 0 4 3 3 3 3 3 3 3 3 3 3 0 3 3 3 3 4 3 3 4 3 3 3 3 1 1 1 4 1 4 3 5 3 3 5 5 1 2 2 5 3 4 3 3 5 5 4 4 3 3 3 3 4 5 5 0 5 5 1 1 1 4 2 2 2 3 3 3 3 3 3 1 3 3 4 4 3 2 2 2 2 1 3 2 3 4 2 2 2 3 0 5 5 5 2 2 1 0 5 4 2 2 5 2 2 2 2 1 4 4 2 3 3 5 5 5 1 3 3 3 3 5 1 1 1 5 0 4 1 4 1 4 3 5 4 4 4 0 4 1 3 3 5 1 5 0 2 2 2 2 2 3 4 1 3 3 0 4 3 3 0 0 4 1 1 3 0 0 4 4 5 4 1 0 1 0 0 0 3 0 0 0 3 0 0 0 0 0 3 1 0 3 0 0 0 0 1 3 3 0 1 3 3 4 0 0 3 0 0 3 0 0 0 0 0 0 0 0 0 3 0 3 0 0 0 0 0 0 0 0 0 5 4 3 1 1 1 0 2 2 4 1 2 4 2 1 4 4 3 4 4 2 3 4 3 2 2 1 4 4 2 1 2 2 3 1 5 4 3 2 4 4 4 1 1 4 3 0 0 2 1 1 4 4 4 1 1 1 4 3 1 2 3 3 3 3 3 3 3 3 4 3 2 2 1 5 3 5 5 5 3 5 5 1 3 1 3 0 2 1 5 1 3 2 2 2 2 5 2 2 0 1 4 1 5 5 5 5 1 5 5 5 5 5 3 1 1 2 0 1 1 3 1 3 3 4 1 2 2 2 5 4 4 4 2 2 4 2 2 2 2 4 4 2 2 5 5 5 5 4 3 1 2 4 4 4 1 3 4 4 3 4 4 3 3 4 4 4 0 0 3 5 5 1 1 4 4 2 2 4 4 4 4 3 4 3 5 5 4 1 5 1 5 1 5 5 5 1 5 1 5 1 5 5 1 1 5 1 5 5 3 1 1 3 3 3 3 3 3 3 3 3 3 2 2 3 2 1 1 4 1 5 5 5 3 5 1 4 5 5 1 5 2 5 5 1 2 5 5 5 5 2 5 3 2 5 5 5 1 1 5 5 5 3 3 2 4 3 4 1 3 4 3 2 4 4 2 2 3 1 5 2 5 1 1 3 3 3 3 3 3 1 1 4 1 1 4 1 1 3 4 5 5 5 4 4 4 4 5 5 5 4 5 4 2 3 3 0 4 3 0 1 1 0 1 1 0 3 3 1 1 3 3 3 0 3 1 4 1 3 4 1 1 5 3 1 1 5 1 5 4 3 2 1 3 5 1 4 1 3 3 0 0 0 0 0 0 0 4 0 3 3 3 5 3 2 3 3 2 2 3 2 2 5 2 2 5 2 2 2 5 2 2 2 3 2 3 5 5 2 5 5 5 5 2 2 5 2 5 3 0 5 5 2 5 2 4 1 2 2 2 5 1 4 0 0 1 4 4 1 5 3 1 1 4 3 3 5 5 5 1 5 3 3 4 1 3 1 5 5 3 1 5 3 1 1 3 3 3 2 4 3 5 5 3 3 5 3 4 3 0 1 1 4 1 1 1 1 1 4 1 1 4 4 4 1 4 1 4 4 4 1 4 2 2 2 1 3 3 5 2 2 0 5 5 4 1 5 5 1 5 5 5 2 1 3 4 4 2 4 3 1 1 1 3 1 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 3 4 0 4 3 4 5 5 4 4 3 4 5 3 3 5 3 5 4 5 3 3 5 3 3 3 5 4 3 5 5 5 3 3 5 4 3 3 5 3 4 4 4 4 5 3 4 5 3 3 4 3 5 3 5 5 5 5 5 5 4 3 4 5 4 4 3 3 3 4 3 3 4 5 4 4 5 3 5 5 3 4 5 5 4 5 3 5 5 3 5 4 3 3 3 5 3 4 4 5 5 5 4 3 4 4 4 5 4 3 3 5 4 5 4 5 5 5 4 4 5 5 4 5 4 4 3 5 3 4 5 3 3 4 3 3 3 3 5 3 4 5 5 4 5 5 4 5 4 3 5 4 3 5 3 5 3 3 4 3 5"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 5 5 5 5 3 5 3 3 3 3 3 5 3 3 3 4 5 4 4 5 5 3 5 4 3 4 4 2 4 1 3 4 5 4 5 4 3 3 3 3 5 3 4 4 3 3 3 5 5 3 3 4 5 4 4 5 4 3 4 5 3 5 5 4 5 3 3 4 5 3 3 5 3 5 5 3 3 1 4 4 4 4 1 1 2 2 3 3 3 1 3 3 3 1 1 4 1 5 1 1 1 5 1 4 2 5 5 4 5 1 1 3 3 4 3 2 4 1 5 1 1 1 3 1 4 2 5 4 4 5 4 5 4 4 4 5 3 3 3 5 4 4 3 1 5 5 5 5 5 3 5 1 4 2 5 5 4 4 5 2 1 5 1 3 2 2 2 2 1 1 2 3 4 4 5 5 1 3 1 4 5 5 5 5 3 5 5 1 3 3 1 5 5 4 3 5 3 2 2 2 2 2 2 4 1 4 1 2 2 4 3 4 3 3 3 4 0 4 3 3 3 5 4 1 3 5 3 1 4 4 3 2 5 3 2 2 5 5 2 3 1 2 1 1 2 3 2 5 5 0 2 5 4 5 5 4 2 4 5 1 1 4 4 0 0 0 0 0 4 1 4 3 3 4 3 2 2 3 1 1 2 4 4 4 4 4 2 4 4 4 4 4 4 4 4 4 4 2 4 4 4 4 2 2 2 2 4 4 5 4 4 2 4 2 2 4 4 3 2 3 4 5 2 4 4 2 2 4 4 4 4 4 4 4 4 4 2 4 2 2 2 4 4 1 1 3 1 3 4 4 3 3 4 5 4 3 1 3 4 4 4 4 4 4 4 4 0 4 2 2 3 4 5 5 5 3 3 1 2 3 3 1 1 4 5 5 5 5 0 0 0 3 4 4 4 4 3 5 4 4 4 4 4 4 2 4 4 4 3 3 1 2 3 4 2 3 5 5 5 5 1 3 3 5 0 0 0 3 4 5 1 1 1 3 3 3 4 3 2 2 2 2 2 4 4 4 4 5 1 4 1 4 3 3 5 4 3 3 5 1 1 4 4 5 5 4 4 4 4 4 1 0 2 5 0 1 1 0 4 3 3 2 2 1 5 1 1 5 2 1 1 2 5 2 3 1 3 5 2 1 1 4 3 4 3 3 4 5 4 2 5 5 5 3 5 1 0 3 3 1 3 1 3 2 5 4 4 4 4 4 4 4 4 4 4 4 4 2 5 5 5 2 4 3 3 2 2 2 4 2 3 3 3 5 3 2 2 3 2 3 1 4 1 1 5 1 1 5 1 1 1 1 1 1 3 3 5 5 4 4 4 4 4 4 3 3 3 5 5 2 2 4 4 2 2 3 5 3 2 5 0 2 3 2 2 2 2 2 3 3 3 3 3 5 2 3 3 3 2 1 3 3 1 5 3 3 4 3 5 2 3 3 3 3 4 3 5 3 4 3 1 1 1 3 3 3 5 3 4 3 3 1 3 3 4 3 3 3 1 1 3 3 3 3 1 3 3 4 3 2 0 3 4 2 1 1 2 3 3 1 4 4 4 1 5 3 5 3 4 1 4 3 3 3 3 4 5 5 4 1 1 3 5 4 4 1 1 4 1 2 2 2 3 3 3 4 1 1 1 1 1 1 5 4 5 5 4 3 1 1 1 5 1 1 1 1 1 5 1 1 1 1 1 1 3 5 1 3 5 1 1 5 1 5 5 1 1 1 1 1 1 1 1 1 5 5 1 1 1 1 1 5 1 1 1 1 1 1 4 3 4 5 2 4 3 3 1 3 1 1 1 4 1 4 3 4 5 5 5 5 5 3 5 5 5 5 5 3 5 5 5 5 5 3 5 3 5 5 3 5 1 1 1 1 1 2 1 1 5 4 4 4 3 4 3 3 3 3 4 4 3 5 3 1 5 1 1 1 1 2 4 5 1 5 5 5 4 5 2 5 4 5 4 5 3 5 5 4 5 5 4 5 5 5 5 4 5 5 3 5 4 4 5 2 4 4 5 5 5 5 4 5 5 4 3 4 4 2 1 2 1 4 4 5 1 4 3 4 4 4 4 4 1 1 3 4 5 3 0 3 4 1 1 1 1 5 2 3 3 1 4 2 1 4 4 4 2 3 2 1 1 3 2 4 1 5 1 1 4 1 1 1 1 1 3 2 3 4 1 2 4 4 1 1 1 1 5 3 1 4 1 4 4 4 3 3 3 5 4 1 2 3 5 1 2 1 2 1 3 4 5 4 1 5 5 3 1 2 2 4 4 3 2 4 4 2 5 4 2 1 5 1 4 1 3 2 1 1 1 3 4 1 5 1 4 4 1 1 4 5 4 1 4 1 2 1 1 1 1 2 2 4 1 4 3 2 2 2 1 1 5 1 1 2 1 5 2 4 2 4 1 1 4 5 2 1 1 4 4 1 2 1 2 3 3 1 0 1 1 3 5 3 5 5 5 1 3 3 5 5 1 1 5 4 5 3 4 5 3 3 5 3 5 5 2 0 0 3 3 5 5 5 5 5 3 2 2 1 1 1 3 0 5 2 2 2 2 1 0 3 4 1 1 5 2 5 5 5 5 5 3 4 5 5 1 2 0 2 2 2 2 2 3 4 3 3 2 2 3 4 4 3 3 4 1 3 1 4 1 4 2 3 4 1 1 3 3 4 3 3 4 3 1 4 4 1 1 1 1 1 5 5 1 4 1 1 3 1 4 4 4 4 3 3 3 3 5 5 4 3 1 1 5 1 1 3 1 1 1 3 4 4 3 4 2 2 1 1 1 4 0 3 2 1 5 4 4 4 0 4 1 3 3 4 0 0 1 0 2 0 4 1 5 1 0 4 4 0 4 5 4 0 3 5 3 4 5 3 2 3 4 2 5 5 3 2 2 5 5 5 3 2 1 4 2 2 3 0 3 1 1 2 1 4 3 5 5 5 3 5 5 3 4 3 3 4 3 1 0 2 4 5 1 1 4 3 4 3 2 3 5 3 5 3 5 4 4 3 4 5 1 3 1 5 1 4 1 4 1 4 4 1 4 4 4 1 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 5 2 0 0 4 4 4 5 5 1 3 3 3 3 3 3 3 1 4 1 0 4 5 2 1 4 3 4 4 4 4 1 3 2 4 5 3 3 2 4 5 2 0 2 5 5 1 5 3 5 1 1 3 5 1 1 5 3 1 5 3 4 2 4 4 4 0 0 3 3 5 5 5 5 3 1 3 4 3 1 3 5 2 1 2 2 1 1 3 5 4 2 4 4 4 4 5 2 4 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 4 1 4 1 1 5 1 1 1 5 1 1 1 1 1 1 1 2 2 2 1 2 4 4 1 4 4 3 4 0 1 1 1 1 4 4 3 5 5 2 5 2 2 5 5 4 5 4 1 4 4 5 2 3 1 1 1 1 4 5 5 3 1 1 1 1 1 5 5 4 1 3 3 3 5 4 5 4 4 4 4 4 4 2 4 4 5 2 2 3 3 3 3 2 4 2 1 3 5 1 1 5 1 2 1 1 1 1 1 1 5 1 1 5 5 1 5 1 2 1 1 1 5 1 3 1 1 4 4 5 4 1 1 1 1 1 1 4 3 0 0 1 3 5 4 1 4 1 1 4 1 4 5 5 3 3 5 5 1 1 4 3 2 2 2 2 3 2 1 1 4 1 5 3 5 3 3 3 3 5 4 4 4 0 0 3 4 1 3 3 1 5 5 4 4 3 1 5 3 0 2 1 3 1 1 1 1 3 5 3 3 3 5 1 1 3 3 2 1 1 2 2 4 4 0 4 1 1 3 3 5 5 5 4 3 2 1 3 4 1 1 1 4 4 5 4 4 3 4 4 1 3 4 5 4 4 4 1 3 1 3 3 1 3 3 3 1 0 2 4 2 3 3 1 4 4 4 4 4 4 4 4 4 4 4 2 2 2 2 1 1 0 3 3 3 3 3 5 5 1 3 3 3 5 1 1 5 1 5 5 3 4 1 1 1 1 4 4 3 3 3 3 1 1 1 1 1 1 1 1 5 4 0 4 0 2 2 4 4 4 4 4 2 4 0 3 5 5 5 5 3 4 4 2 4 0 4 4 4 4 4 4 4 4 3 5 5 1 5 2 2 2 5 4 4 4 4 4 4 4 4 4 1 5 5 5 1 4 4 1 3 3 2 1 3 5 1 1 4 4 3 3 4 5 4 5 4 4 3 4 4 4 4 3 4 3 3 5 3 3 3 4 1 3 1 1 1 1 2 2 2 4 3 3 1 2 4 3 2 3 1 2 3 3 2 1 2 1 4 4 1 5 1 4 3 3 3 3 4 3 3 4 2 4 2 4 4 3 3 1 4 5 2 3 4 1 4 2 1 2 3 1 4 1 2 4 4 3 3 1 1 2 1 4 1 3 3 1 5 1 4 5 4 3 4 4 3 3 3 3 5 4 5 4 3 4 1 3 5 5 2 5 3 2 3 3 3 5 4 4 4 4 4 2 3 4 4 4 3 0 3 1 3 5 4 2 4 1 4 4 5 5 1 5 5 5 2 3 2 5 5 1 4 1 1 1 1 1 3 1 5 4 3 1 3 5 5 4 5 4 4 2 2 1 1 4 5 5 1 2 2 3 3 5 5 5 5 5 3 5 5 5 3 5 5 3 5 5 3 1 1 1 1 4 1 2 3 2 5 5 2 4 3 2 5 3 3 3 3 3 3 3 3 3 3 3 3 3 3 1 2 1 3 4 3 3 4 3 3 1 4 3 3 4 3 3 3 3 3 4 3 3 4 3 3 3 3 3 3 3 3 5 5 4 2 4 4 4 5 5 3 1 1 5 3 5 5 3 3 3 2 2 0 3 3 3 4 5 2 4 4 4 4 4 4 1 4 2 5 2 5 2 4 4 2 2 2 3 5 5 3 1 4 5 3 5 2 4 3 3 3 5 5 3 5 0 5 1 1 4 1 5 5 5 1 1 4 5 5 5 5 3 5 5 1 5 4 3 1 1 1 4 1 4 4 0 5 2 5 1 3 4 3 3 3 2 3 5 1 1 4 2 2 4 5 4 4 4 4 4 3 3 1 1 4 4 4 1 4 4 4 4 1 4 5 3 5 1 2 2 5 2 2 2 2 3 1 0 0 4 5 5 5 3 5 5 5 3 3 3 3 3 5 5 4 3 3 3 2 3 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 5 5 3 1 1 3 5 5 5 5 2 4 4 4 4 5 4 4 4 4 5 3 3 2 0 0 5 1 1 1 4 2 5 3 3 3 3 5 3 1 3 3 5 5 4 4 4 4 1 5 3 5 5 1 1 1 3 5 2 4 2 3 3 2 5 2 2 2 2 3 2 2 2 2 3 3 5 5 2 2 3 2 3 2 2 3 2 5 2 2 5 2 5 2 5 1 1 3 3 3 4 5 1 5 5 5 5 5 3 3 3 3 3 3 1 3 1 1 3 1 3 1 4 1 1 3 3 1 2 3 1 1 3 1 1 4 5 5 0 3 1 4 4 4 2 4 3 2 5 1 4 5 5 1 1 3 3 3 4 3 2 5 4 5 5 5 1 5 1 2 1 3 1 4 5 1 1 1 1 4 4 2 2 2 1 2 1 4 4 1 1 4 2 2 2 4 1 2 1 4 1 2 1 3 3 3 3 3 0 5 3 2 3 4 5 1 0 3 3 3 0 1 5 3 5 3 0 5 1 3 5 4 3 1 3 3 3 4 3 3 5 1 5 0 3 3 1 4 3 4 3 1 0 3 3 4 3 3 5 3 1 3 3 3 5 3 0 0 3 1 5 5 3 3 4 2 1 3 3 0 3 3 3 1 3 5 3 3 2 0 3 5 4 3 1 4 5 1 4 3 0 3 1 4 3 3 3 3 5 4 1 3 3 3 3 3 3 3 1 3 3 3 5 3 5 1 1 4 3 3 3 3 2 5 3 5 4 1 0 3 3 3 5 4 4 3 4 1 1 3 3 3 3 4 3 5 5 5 3 3 3 0 4 3 2 0 3 3 3 0 5 5 3 3 3 2 2 1 4 1 1 1 1 0 2 1 1 5 4 5 5 5 1 5 5 1 3 5 5 5 5 1 1 5 0 1 0 4 5 1 0 0 5 5 4 4 0 5 4 4 2 2 3 5 3 3 1 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 1 3 0 5 5 5 4 4 4 4 5 2 2 2 3 5 5 5 3 4 2 5 5 5 5 5 5 5 5 5 3 5 5 4 5 3 5 4 5 5 5 5 5 4 3 3 5 2 3 5 5 5 3 3 5 4 0 0 3 4 4 4 3 5 1 1 5 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 2 2 2 2 0 2 2 2 2 2 2 2 2 2 2 3 2 2 2 2 2 5 1 4 4 4 4 2 2 1 0 4 1 1 1 2 1 1 1 1 3 1 3 5 0 4 1 4 4 2 2 1 1 1 1 1 3 5 4 3 4 2 2 4 3 4 3 4 4 4 3 1 2 3 5 5 5 1 4 3 3 4 2 3 2 1 2 3 3 3 4 3 3 3 1 2 4 3 1 2 3 3 0 4 3 3 2 3 3 3 1 0 2 3 2 2 3 2 5 3 2 2 2 3 2 3 2 1 3 3 2 3 3 3 3 3 1 3 2 0 3 3 3 0 3 3 3 3 3 1 5 1 3 1 1 5 2 5 2 4 4 4 1 1 1 1 5 0 4 1 4 2 1 5 4 4 4 1 4 5 5 5 1 3 2 2 3 3 4 5 4 5 1 1 3 1 1 1 1 4 5 2 3 3 4 3 3 0 1 3 3 4 1 1 1 1 3 3 4 5 2 4 3 2 2 2 2 5 2 1 0 1 3 2 3 3 1 4 2 2 4 4 4 3 3 3 3 5 4 1 5 3 4 1 5 4 3 3 1 4 2 3 3 1 5 2 2 2 3 3 3 0 2 2 4 4 3 3 0 3 4 4 3 5 3 0 1 4 4 1 1 1 1 4 3 1 1 3 3 4 0 0 0 5 5 4 2 0 2 2 2 2 3 2 2 5 0 3 4 2 0 3 3 3 3 3 2 2 4 4 4 2 4 3 4 4 1 4 4 3 4 3 4 3 4 4 4 4 5 5 1 0 2 4 3 4 2 3 2 2 1 5 1 1 2 2 1 1 1 5 1 1 1 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 5 4 0 4 4 5 5 5 5 5 5 5 5 5 5 5 5 5 0 4 1 1 1 4 4 3 2 2 2 4 3 4 2 3 3 2 2 3 4 2 2 3 2 3 2 2 2 2 2 2 2 4 4 2 4 3 2 4 2 3 4 4 2 2 2 4 2 4 2 4 2 2 2 2 2 4 5 5 4 5 2 3 5 3 3 4 2 5 4 2 4 2 2 3 3 5 5 5 4 2 1 2 1 4 4 3 4 3 4 4 4 4 4 4 4 5 4 4 1 3 3 3 3 5 5 4 4 3 4 4 4 2 3 4 1 2 5 5 2 3 2 3 5 1 3 3 2 3 1 2 1 1 4 1 1 1 1 1 1 1 1 1 4 2 2 1 1 3 1 3 3 5 3 0 4 5 5 5 5 3 2 2 3 1 2 3 3 1 2 5 5 5 5 3 1 5 0 3 3 2 1 3 3 2 2 3 5 5 0 0 3 5 4 4 2 2 2 2 2 2 3 5 5 2 5 1 1 2 3 4 1 5 1 4 3 1 1 1 2 1 1 1 4 4 4 2 2 1 2 2 1 1 1 1 1 4 1 2 4 4 4 1 5 4 3 4 2 4 1 4 4 2 1 1 1 0 4 4 4 4 3 2 4 5 5 5 5 5 5 1 5 5 5 1 4 4 4 5 5 5 1 1 1 1 5 4 1 5 4 1 5 5 1 1 5 4 4 1 1 1 1 5 5 5 5 3 5 5 5 5 3 3 0 2 0 5 5 1 3 3 3 1 0 5 4 3 3 4 1 3 4 0 2 1 1 3 1 5 3 3 1 3 1 3 3 2 1 4 2 5 1 1 3 1 1 1 1 3 1 1 1 1 3 1 1 1 1 1 1 1 1 2 3 3 2 3 3 3 2 3 3 3 3 3 3 3 3 3 3 2 3 4 3 3 3 3 3 3 1 1 1 3 3 3 3 1 3 3 3 1 3 3 5 3 3 3 2 2 2 2 2 2 2 2 4 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 4 2 4 1 4 4 2 2 2 2 2 2 1 4 2 3 2 2 2 2 3 0 0 0 3 3 3 3 3 3 3 3 4 5 2 3 2 4 0 1 5 3 5 3 4 2 4 5 5 3 5 1 5 5 2 2 5 4 3 1 1 1 1 1 1 1 1 3 0 5 5 5 5 2 0 2 3 1 1 2 3 5 4 2 5 0 3 5 3 3 2 4 2 5 3 3 5 5 3 3 3 5 1 4 1 5 5 3 3 3 2 3 1 2 3 5 3 4 1 5 1 3 0 3 3 5 1 5 3 2 4 2 4 3 3 5 2 1 5 3 3 3 3 3 1 3 3 1 2 2 1 1 2 2 5 3 3 3 1 2 3 0 1 5 4 4 3 1 3 3 4 1 2 3 5 3 2 3 4 4 3 0 5 3 4 4 5 4 1 5 5 3 5 2 3 3 5 4 3 1 4 4 3 3 3 3 5 3 2 1 0 4 0 3 2 5 1 4 3 4 3 3 4 1 3 1 3 1 3 1 3 3 1 1 1 3 1 1 1 1 1 1 1 4 1 3 1 1 1 1 1 1 4 3 1 2 1 1 1 1 1 1 1 4 1 1 1 1 1 4 3 4 3 1 1 2 3 3 4 1 1 3 3 3 4 3 4 3 4 1 3 3 3 3 1 3 1 4 3 1 2 3 4 4 4 3 3 4 1 4 4 3 1 3 3 4 4 4 1 3 3 4 4 4 3 2 3 4 3 3 3 3 3 3 3 3 3 3 3 4 2 3 3 4 1 3 4 3 4 1 4 3 3 3 2 3 2 2 3 3 1 2 3 3 3 4 4 4 1 4 1 3 4 3 1 3 3 1 3 3 1 1 5 5 1 1 1 5 4 3 3 4 3 5 1 3 0 4 1 3 1 5 1 4 5 1 3 4 5 5 5 5"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 5 5 5 3 3 5 5 2 1 1 1 1 1 5 3 1 4 2 1 3 5 3 5 1 4 5 1 5 5 4 1 2 4 3 3 5 4 5 4 2 0 2 1 4 4 4 3 4 4 4 4 4 4 5 3 5 3 5 4 3 3 3 5 3 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 3 5 5 5 5 5 5 5 5 5 1 1 5 4 1 4 4 3 3 1 3 1 4 4 4 2 4 4 3 3 4 5 4 0 3 5 2 1 2 1 3 3 2 3 1 1 5 2 5 3 2 2 4 5 4 4 2 4 2 2 2 2 2 4 2 2 4 3 4 2 4 3 3 4 2 2 4 2 4 4 2 2 2 2 2 2 2 2 2 2 3 2 3 1 1 1 1 1 4 2 3 5 4 1 4 5 4 5 3 1 4 4 4 1 4 1 4 3 1 5 1 4 1 4 4 1 5 5 1 1 4 1 1 1 4 4 5 4 4 4 1 5 4 4 5 1 4 2 5 0 3 3 3 3 3 4 2 4 2 4 3 3 3 3 3 3 5 3 4 1 3 1 1 5 3 5 1 5 3 3 3 3 1 3 1 1 1 1 3 1 5 3 5 1 1 1 2 1 4 1 1 3 2 1 1 1 4 5 3 5 3 5 3 0 2 2 1 0 1 2 1 1 1 0 0 1 1 0 2 0 2 0 0 0 1 0 0 2 1 0 0 1 0 2 0 0 0 2 1 5 3 3 3 4 3 3 3 3 4 3 3 3 3 3 3 1 4 3 4 3 1 3 5 2 5 5 5 5 5 5 4 5 1 4 3 3 3 3 5 3 3 5 1 4 3 5 5 5 5 1 3 0 1 5 5 2 4 1 0 0 1 1 3 3 4 4 4 1 5 5 3 4 1 1 1 1 1 1 1 1 1 1 1 1 1 5 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 5 3 1 1 1 1 5 5 1 1 1 1 1 5 1 4 3 3 2 3 3 5 4 3 3 4 4 4 4 4 3 3 3 2 4 1 1 1 1 4 2 4 2 2 2 4 2 1 1 5 1 4 5 3 3 0 0 4 3 4 1 1 4 2 4 1 4 3 2 2 4 4 1 4 3 2 1 3 1 4 3 1 1 4 1 1 4 1 1 4 4 4 3 1 4 3 1 5 4 1 1 4 3 1 4 1 2 1 1 3 5 4 1 2 3 4 3 3 1 4 4 3 1 4 4 1 3 3 4 3 4 3 1 2 1 4 3 3 1 4 1 4 2 1 3 4 1 3 1 1 4 4 4 5 4 1 4 1 1 4 3 4 2 1 4 3 4 4 3 1 1 3 1 4 4 3 1 4 3 1 4 1 3 4 1 4 4 1 4 4 4 4 4 1 3 1 1 3 4 1 1 4 4 4 4 4 1 4 4 5 3 3 3 3 3 3 3 3 3 3 1 3 1 1 1 1 1 5 3 1 5 1 5 1 1 5 5 3 3 5 2 2 1 4 3 3 3 3 3 1 1 3 3 3 3 3 1 2 2 5 5 1 1 2 0 3 3 3 3 4 4 3 2 3 2 2 2 3 4 1 0 2 2 2 2 4 4 4 4 4 4 4 5 5 5 5 1 4 4 5 4 5 4 5 5 5 5 5 5 5 5 1 1 1 1 1 3 3 2 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 4 3 2 2 0 3 5 1 3 3 1 3 3 3 2 2 2 3 3 3 5 5 1 1 5 0 0 3 4 3 1 5 0 2 3 4 4 4 4 4 0 0 3 3 3 5 0 0 4 0 0 0 0 0 2 1 2 1 2 1 0 0 1 2 2 2 5 4 5 3 3 3 4 4 4 4 3 3 4 4 5 1 5 5 3 5 5 4 4 5 5 1 2 2 2 2 4 3 1 1 4 1 3 3 4 3 5 1 3 3 4 4 3 4 1 1 0 4 3 4 3 2 5 5 5 5 3 3 4 4 1 1 3 3 5 0 1 3 3 2 3 3 3 4 1 5 5 3 5 4 4 1 3 3 3 3 3 0 4 4 4 5 1 4 4 5 5 4 5 3 3 4 4 3 3 1 5 1 1 2 1 3 1 1 3 1 1 1 1 1 1 1 3 2 1 4 1 4 2 1 1 5 1 1 3 1 4 5 3 4 1 1 1 1 1 1 5 4 4 4 1 1 2 4 1 3 3 1 3 3 1 3 3 1 3 5 3 4 5 5 3 4 1 1 5 2 1 2 1 4 2 3 3 3 3 4 2 2 1 1 1 4 1 4 2 2 1 1 2 1 1 3 2 2 4 2 1 1 2 2 2 2 2 4 1 2 1 1 4 4 2 1 3 2 2 4 4 2 4 3 5 1 2 1 1 1 1 1 2 4 1 2 4 2 2 1 3 2 1 4 1 2 2 4 2 2 1 2 3 4 2 2 1 1 2 2 1 2 2 4 2 2 2 2 4 2 2 2 4 5 3 2 3 3 0 0 5 1 1 1 3 4 4 4 3 3 3 3 3 3 3 3 3 3 3 1 1 1 2 5 2 1 4 5 1 1 3 1 3 5 5 5 1 2 2 2 2 5 2 2 2 2 2 2 2 2 2 2 5 2 2 2 2 2 2 2 2 2 2 5 2 1 5 2 2 4 4 4 1 4 4 4 2 3 4 1 4 5 5 3 1 1 3 1 5 2 1 2 1 1 4 2 2 2 5 2 3 1 1 1 4 0 2 2 2 3 4 4 4 4 2 4 4 4 5 5 5 1 3 3 3 4 3 3 4 3 4 3 4 4 4 4 3 4 4 3 3 4 3 3 3 3 4 3 3 3 4 3 3 3 3 3 3 5 3 4 3 4 4 3 3 3 3 4 2 5 5 4 4 4 4 4 1 4 4 3 1 1 4 1 4 4 4 4 4 4 4 4 4 5 4 2 5 2 4 3 4 5 5 3 3 4 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 4 3 4 3 4 1 1 3 1 4 4 3 3 3 5 5 5 1 2 4 2 2 1 1 1 4 2 1 1 1 5 2 4 0 3 2 2 5 5 3 5 3 5 5 3 4 4 4 1 1 3 5 4 1 0 1 1 1 1 3 1 1 2 1 1 4 1 1 1 1 1 2 1 1 1 1 1 2 1 4 1 4 3 3 5 1 1 1 5 3 5 3 3 1 1 3 4 3 3 4 2 1 4 2 1 4 1 1 1 5 1 4 2 3 3 1 0 1 1 3 1 1 4 2 2 2 3 1 3 5 5 5 1 2 3 0 1 1 1 0 1 4 1 0 5 3 1 1 3 2 2 2 2 1 4 2 4 3 3 2 2 0 4 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 4 2 1 1 2 1 5 4 4 4 4 2 4 4 5 5 3 5 1 3 5 3 4 3 4 2 5 2 0 4 1 3 1 4 4 4 1 1 4 4 5 3 3 3 4 3 5 2 0 0 0 0 4 0 0 0 0 0 0 0 0 0 0 0 0 0 0 5 3 5 4 4 4 4 5 1 3 1 3 3 3 3 3 1 3 3 0 0 3 1 1 1 5 3 5 5 3 3 1 2 3 1 0 0 4 0 2 2 2 3 3 3 1 4 3 4 4 4 4 4 4 4 4 4 3 4 4 4 4 4 3 4 0 3 3 1 1 5 2 2 4 0 5 5 5 0 1 4 3 1 3 3 3 3 4 4 3 4 4 4 3 4 4 4 2 4 1 1 4 3 3 3 3 3 3 2 3 1 1 3 1 5 4 5 0 2 3 2 3 4 2 1 4 2 2 1 1 5 5 0 1 1 1 1 1 1 5 5 4 2 5 5 3 1 3 3 3 4 1 5 5 5 0 4 4 4 3 4 Correct: 5454 out of: 10099\n",
      "Accuracy of the network :  54.00534706406575\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "countCorrect0=0\n",
    "countCorrect1=0\n",
    "count0=0\n",
    "count1=0\n",
    "labels=pd.read_excel('train-clean-Reputation.xlsx' )\n",
    "\n",
    "Y=[]  #target\n",
    "Pred=[]  #predicted\n",
    "\n",
    "with torch.no_grad():\n",
    "    for row in range(len(input)):\n",
    "        outputs = net(input[row,:].float())\n",
    "        result=0\n",
    "        total+=1\n",
    "        if outputs[0]<outputs[1]:result=1\n",
    "        if outputs[result]<outputs[2]:result=2\n",
    "        if outputs[result]<outputs[3]:result=3\n",
    "        if outputs[result]<outputs[4]:result=4\n",
    "        if outputs[result]<outputs[5]:result=5\n",
    "        \n",
    "        if TrainLables.iloc[row,result]==1: correct+=1\n",
    "        \n",
    "        Y.append(labels.iloc[row])\n",
    "        Pred.append(result)\n",
    "        \n",
    "        print(result, end=' ')\n",
    "        \n",
    "    \n",
    "print('Correct:', correct, 'out of:', total )\n",
    "print('Accuracy of the network : ',( 100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.4324, -0.1462, -0.5625],\n",
       "        [ 0.0050,  0.0000,  0.0100,  ...,  0.2032, -0.3833, -0.3286],\n",
       "        [ 0.0000,  0.0000,  0.0050,  ...,  0.2717, -0.2191, -0.4355],\n",
       "        ...,\n",
       "        [ 0.0000,  0.0000,  0.0150,  ...,  0.3020,  1.0312,  0.9219],\n",
       "        [ 0.0000,  0.0000,  0.0000,  ...,  0.3862,  0.9517,  1.0928],\n",
       "        [ 0.0000,  0.0000,  0.0000,  ...,  0.6538,  0.9268,  0.3442]],\n",
       "       dtype=torch.float64)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the validation data\n",
    "\n",
    "ValidData=pd.read_excel('valid-clean-Reputation.xlsx' )\n",
    "ValidData=ValidData.iloc[:,:-1].astype(float)\n",
    "ValidData=ValidData/200\n",
    "\n",
    "SavesDirectory='./TunedModels/'+model_class+'/'+model_version+\"/Saves/\"\n",
    "TF_Output=pd.read_csv( SavesDirectory+'evalOut.tsv', sep='\\t')\n",
    "\n",
    "ValidData=pd.concat([ValidData,TF_Output], axis=1)\n",
    "\n",
    "\n",
    "ValidData=torch.tensor(ValidData.values)\n",
    "ValidData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1267</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1268</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1269</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1270</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1271</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1272 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0  1  2  3  4  5\n",
       "0     0  0  0  1  0  0\n",
       "1     0  0  1  0  0  0\n",
       "2     0  0  0  1  0  0\n",
       "3     0  0  0  0  1  0\n",
       "4     0  0  0  0  0  1\n",
       "...  .. .. .. .. .. ..\n",
       "1267  0  0  0  0  0  1\n",
       "1268  0  0  0  1  0  0\n",
       "1269  0  0  1  0  0  0\n",
       "1270  0  0  0  0  1  0\n",
       "1271  0  0  0  1  0  0\n",
       "\n",
       "[1272 rows x 6 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels=pd.read_excel('valid-clean-Reputation.xlsx' )\n",
    "\n",
    "labels=labels.iloc[:,-1] \n",
    "labelsOneHot=pd.get_dummies(labels)\n",
    "labelsOneHot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0, 0, 1, 0, 0],\n",
       "        [0, 0, 1, 0, 0, 0],\n",
       "        [0, 0, 0, 1, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 1, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 1, 0],\n",
       "        [0, 0, 0, 1, 0, 0]], dtype=torch.uint8)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ValidLables =torch.tensor(labelsOneHot.values)\n",
    "ValidLables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 2 3 2 5 4 4 4 5 2 3 3 1 1 1 4 2 2 2 1 2 0 1 2 4 2 3 1 2 5 4 3 3 0 1 3 3 3 2 3 4 4 3 1 3 3 2 5 3 3 4 3 3 3 5 3 3 4 5 1 3 3 3 4 3 3 5 3 3 4 3 3 5 4 4 4 4 3 2 1 4 3 4 3 3 3 3 4 3 1 3 5 3 4 3 5 4 3 5 3 2 5 5 3 3 3 4 3 1 3 1 1 2 4 4 4 4 3 4 2 2 4 3 1 1 5 4 1 1 4 5 4 5 4 3 4 3 2 3 4 3 1 1 1 3 3 2 4 4 0 0 0 0 0 0 0 0 0 0 0 0 4 4 5 1 5 2 5 3 1 5 1 4 4 5 5 1 4 4 5 5 5 3 1 0 1 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 2 2 5 3 1 1 4 5 2 4 5 2 2 1 3 3 3 2 3 5 0 1 1 2 3 3 3 5 3 5 3 5 3 5 5 3 3 3 3 5 5 3 3 3 1 4 4 4 1 4 3 4 4 3 3 1 1 4 5 3 1 1 3 4 2 1 2 2 2 3 2 2 4 5 4 1 2 0 4 2 4 1 3 0 4 2 2 1 4 5 2 0 3 3 3 3 2 2 1 3 2 1 2 4 2 4 4 1 4 3 1 2 4 4 1 1 4 4 5 1 2 0 2 2 5 3 2 3 4 5 3 3 3 2 4 4 2 5 2 1 1 1 1 3 1 1 1 3 1 0 3 0 3 0 4 4 1 1 1 1 1 1 4 4 1 1 1 1 1 4 1 1 1 4 3 1 0 4 4 4 2 0 4 5 4 1 5 4 4 5 3 2 2 2 2 3 2 5 5 1 2 2 1 2 3 0 4 2 5 3 3 4 4 0 0 4 0 0 3 0 5 3 4 2 4 2 1 2 2 2 5 3 5 1 1 5 3 3 1 4 3 2 3 2 5 1 5 3 3 4 5 5 1 1 1 3 3 2 2 2 1 5 1 4 3 1 1 5 1 4 3 1 0 2 5 2 3 1 1 4 4 3 1 4 3 3 0 4 4 4 3 5 1 1 1 3 3 5 5 5 5 5 3 3 5 4 5 4 5 5 5 5 5 5 3 3 5 5 5 5 3 5 2 1 1 0 1 5 3 3 3 2 3 1 3 4 1 5 3 4 2 4 4 5 3 1 2 4 0 4 5 2 4 5 2 4 4 5 1 1 2 4 2 1 1 5 0 1 3 4 3 1 5 4 3 2 5 4 4 1 4 4 2 4 3 3 4 1 4 4 0 1 3 5 3 5 2 5 4 2 2 3 1 1 3 3 1 1 1 1 1 1 5 1 5 5 5 5 5 3 2 4 4 4 1 4 4 4 5 4 4 5 4 1 5 0 4 4 3 3 4 4 5 3 1 1 1 5 5 2 1 1 1 4 1 4 1 4 3 4 3 1 4 1 1 4 3 0 2 2 4 3 4 2 1 4 3 1 4 4 0 3 1 1 1 1 2 4 4 4 4 4 4 3 5 4 4 4 0 2 3 4 4 3 4 1 1 1 2 1 3 5 2 4 5 4 5 4 3 1 1 1 1 1 4 1 4 1 1 1 1 2 3 5 5 1 1 4 1 3 3 3 0 3 4 3 5 1 4 4 3 1 3 1 5 5 3 5 4 3 1 5 4 1 3 3 1 4 3 3 3 1 4 3 1 3 3 2 1 1 2 5 3 4 3 1 4 4 1 3 3 1 2 3 5 2 1 3 3 3 1 3 3 4 5 4 5 0 1 3 5 3 5 5 2 3 4 5 4 1 1 1 4 4 2 3 2 5 5 3 1 1 1 1 1 1 1 1 2 3 5 3 5 3 2 5 1 1 1 1 3 1 3 3 1 3 3 3 2 3 1 4 2 4 3 3 1 1 5 1 1 3 3 1 3 3 3 3 2 3 1 3 0 3 3 3 1 3 5 3 5 3 4 5 2 2 2 2 2 2 2 3 1 1 2 0 2 3 1 1 1 1 2 3 4 3 4 1 4 1 4 2 3 1 3 5 5 1 3 3 2 4 4 3 3 2 2 2 2 1 1 4 2 5 2 4 0 3 5 5 2 2 3 2 4 5 5 5 0 5 4 3 3 1 5 4 2 4 0 1 1 1 2 5 1 5 4 1 4 1 2 3 5 3 3 5 4 1 4 3 1 3 3 3 3 3 2 2 2 2 2 2 2 3 4 3 1 3 5 1 0 3 3 5 3 3 1 3 4 0 3 3 4 4 5 4 4 4 1 1 3 4 3 3 5 4 3 3 3 5 4 3 1 1 5 4 3 1 3 5 5 5 5 5 5 5 5 5 1 3 5 1 2 5 0 2 2 3 2 2 2 2 1 5 1 4 3 4 4 2 1 1 1 1 1 3 3 1 1 3 3 1 3 1 3 5 5 1 0 4 1 1 1 1 1 1 4 1 5 4 3 4 1 1 3 1 1 4 3 4 4 4 1 1 1 4 1 3 3 5 5 1 2 4 5 5 1 5 5 5 3 5 5 3 1 4 4 1 4 4 3 3 3 1 3 4 1 1 1 1 1 3 1 2 3 3 4 2 2 2 3 2 3 2 1 1 2 2 1 4 1 0 5 4 3 2 2 2 5 2 5 2 5 1 5 2 4 4 3 3 3 5 4 1 1 1 3 4 3 3 1 1 2 3 5 3 3 3 0 1 1 1 1 2 1 3 4 1 0 1 3 4 2 2 3 4 5 5 3 4 5 1 1 0 0 0 4 3 3 1 2 3 2 1 0 4 4 4 4 4 5 3 4 4 3 Correct: 606 out of: 1272\n",
      "Accuracy of the network :  47.64150943396226\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "countCorrect0=0\n",
    "countCorrect1=0\n",
    "count0=0\n",
    "count1=0\n",
    "\n",
    "Y=[]  #target\n",
    "Pred=[]  #predicted\n",
    "\n",
    "with torch.no_grad():\n",
    "    for row in range(len(ValidData)):\n",
    "        outputs = net(ValidData[row,:].float())\n",
    "        result=0\n",
    "        total+=1\n",
    "        if outputs[0]<outputs[1]:result=1\n",
    "        if outputs[result]<outputs[2]:result=2\n",
    "        if outputs[result]<outputs[3]:result=3\n",
    "        if outputs[result]<outputs[4]:result=4\n",
    "        if outputs[result]<outputs[5]:result=5\n",
    "        \n",
    "        if labelsOneHot.iloc[row,result]==1: correct+=1\n",
    "        \n",
    "        Y.append(labels.iloc[row])\n",
    "        Pred.append(result)\n",
    "        \n",
    "        print(result, end=' ')\n",
    "        \n",
    "    \n",
    "print('Correct:', correct, 'out of:', total )\n",
    "print('Accuracy of the network : ',( 100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0000,  0.0050,  0.0100,  ..., -0.1688, -0.3889, -0.0365],\n",
       "        [ 0.0000,  0.0050,  0.0100,  ...,  0.4417,  0.5527,  0.3252],\n",
       "        [ 0.0000,  0.0050,  0.0100,  ...,  0.1344,  0.0543, -0.1962],\n",
       "        ...,\n",
       "        [ 0.0000,  0.0000,  0.0050,  ...,  0.5479,  0.1997, -0.2791],\n",
       "        [ 0.0050,  0.0000,  0.0000,  ...,  0.2302,  0.9248,  0.8755],\n",
       "        [ 0.0000,  0.0000,  0.0000,  ...,  0.4470,  0.0788, -0.3301]],\n",
       "       dtype=torch.float64)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the test data\n",
    "\n",
    "TestData=pd.read_excel('test-clean-Reputation.xlsx' )\n",
    "TestData=TestData.iloc[:,:-1].astype(float)\n",
    "TestData=TestData/200\n",
    "\n",
    "SavesDirectory='./TunedModels/'+model_class+'/'+model_version+\"/Saves/\"\n",
    "TF_Output=pd.read_csv( SavesDirectory+'testOut.tsv', sep='\\t')\n",
    "\n",
    "TestData=pd.concat([TestData,TF_Output], axis=1)\n",
    "\n",
    "\n",
    "TestData=torch.tensor(TestData.values)\n",
    "TestData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0, 0, 0, 1, 0],\n",
       "        [0, 0, 0, 0, 1, 0],\n",
       "        [0, 0, 1, 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 1, 0, 0, 0],\n",
       "        [1, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 1, 0, 0]], dtype=torch.uint8)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels=pd.read_excel('test-clean-Reputation.xlsx' )\n",
    "\n",
    "labels=labels.iloc[:,-1] \n",
    "labelsOneHot=pd.get_dummies(labels)\n",
    "labelsOneHot\n",
    "\n",
    "TestLables =torch.tensor(labelsOneHot.values)\n",
    "TestLables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 4 4 2 2 5 2 4 2 3 5 5 5 3 3 4 1 1 1 2 1 1 4 2 0 5 2 3 0 2 3 2 2 2 1 2 2 3 3 2 3 0 1 2 4 2 1 1 3 1 2 4 1 5 0 5 3 3 3 5 3 3 3 3 4 4 4 3 1 3 4 1 3 3 1 4 1 5 3 3 4 3 5 4 5 3 3 3 4 3 4 3 3 4 3 3 3 4 4 1 3 3 5 5 4 4 3 5 4 3 3 4 4 1 4 5 4 2 3 4 3 3 1 5 1 4 4 4 4 4 3 4 4 3 1 3 3 2 2 3 0 2 4 3 1 1 3 4 4 4 4 4 4 4 4 4 2 1 0 0 0 0 0 1 1 0 0 3 3 3 3 5 3 5 5 1 5 2 4 3 5 0 0 3 4 0 5 5 1 5 1 1 0 4 4 3 3 5 4 0 0 1 0 1 0 0 0 0 0 0 0 0 1 2 3 4 0 3 3 5 5 5 5 3 2 3 5 4 4 1 3 3 5 5 5 4 3 3 5 3 5 3 1 3 3 5 4 3 2 3 1 4 5 0 0 4 3 3 5 5 1 5 1 3 4 3 4 2 0 4 4 2 2 2 1 1 1 4 4 2 3 4 3 4 4 1 1 4 2 5 5 3 3 3 3 1 5 4 2 4 0 5 5 5 1 5 4 1 4 3 3 0 2 2 2 0 2 2 3 4 3 3 3 3 2 2 2 3 5 3 5 4 4 4 2 3 1 4 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 4 4 1 0 1 3 2 1 1 3 1 1 4 1 1 4 4 1 1 4 4 4 1 3 3 2 1 2 1 5 2 0 3 3 1 1 3 5 3 2 2 2 2 5 2 2 2 3 2 3 3 3 1 2 4 1 3 4 0 3 3 4 0 3 0 3 0 3 3 5 3 4 1 2 3 1 2 5 1 1 2 3 2 4 2 4 4 4 5 1 1 5 4 3 3 5 5 4 5 5 3 1 2 2 5 4 4 4 2 0 4 3 3 1 0 1 1 4 5 3 1 1 5 5 2 2 2 5 3 2 5 5 2 3 3 5 3 3 2 4 1 5 1 1 1 4 3 4 4 5 4 3 5 5 4 3 3 3 3 3 4 4 3 4 3 4 4 3 5 3 4 3 3 5 5 4 3 2 3 2 4 4 4 4 5 5 1 5 3 1 2 5 3 4 5 5 1 2 4 4 5 3 3 3 3 3 4 3 4 4 4 2 2 4 3 5 4 4 1 1 3 4 1 0 1 5 4 3 4 2 3 5 1 5 1 4 4 5 5 2 4 1 3 1 3 5 4 4 3 4 3 3 1 3 5 1 1 1 1 1 1 1 1 1 1 1 1 5 4 1 5 4 4 4 2 5 4 5 1 4 4 1 2 3 3 4 4 3 4 3 3 3 3 3 2 2 3 1 4 3 1 4 3 3 3 2 3 4 2 4 3 2 4 2 3 5 3 5 4 3 5 5 0 2 2 4 2 0 3 0 4 4 0 3 5 5 3 3 4 3 3 5 4 4 0 2 5 1 4 5 2 5 1 4 5 4 1 4 1 1 1 4 4 5 4 3 4 4 4 4 3 3 1 1 5 4 1 2 4 5 1 1 3 5 3 5 3 3 1 5 4 4 5 4 5 4 4 4 4 0 2 4 1 5 0 4 4 1 5 4 3 4 2 5 1 1 2 3 2 4 3 5 4 4 2 3 2 0 3 4 5 3 1 1 4 4 4 1 4 4 1 2 3 3 1 3 3 3 3 3 3 4 1 1 5 2 2 4 3 2 1 3 5 4 5 1 0 5 1 4 2 1 1 1 1 1 1 1 1 2 5 1 1 0 2 0 2 1 2 1 1 1 1 5 4 4 4 1 4 2 3 3 3 5 3 3 4 2 3 3 5 1 1 3 3 4 4 2 2 4 3 4 2 5 5 5 1 2 2 2 2 2 2 2 4 1 1 2 3 3 4 3 3 3 1 1 3 3 4 4 5 4 3 3 1 2 4 2 5 1 3 2 3 4 4 4 5 4 1 3 5 4 5 1 4 3 3 2 2 2 2 2 2 5 3 2 4 4 3 0 5 3 1 3 1 1 0 3 3 3 5 2 1 4 4 2 1 5 4 4 3 3 5 3 1 1 1 1 1 1 1 1 1 2 4 3 3 3 3 3 2 2 2 2 2 3 5 4 3 3 1 1 1 4 1 5 3 5 5 4 4 3 1 3 3 3 5 4 3 1 1 4 1 1 3 4 2 1 3 3 2 4 3 4 3 4 4 4 3 3 3 3 3 3 3 1 1 3 4 3 4 1 3 1 1 4 4 5 5 5 3 5 3 1 4 2 2 3 3 5 1 4 1 2 5 1 1 5 3 1 3 1 0 0 3 3 3 1 1 4 3 5 1 3 5 3 1 1 1 1 1 1 2 1 5 0 4 1 3 2 1 1 1 5 4 4 3 5 4 1 3 4 1 3 3 3 3 1 1 5 5 1 2 1 4 5 5 0 5 5 5 5 5 5 3 2 3 2 1 5 0 0 4 2 1 4 3 1 2 3 1 0 3 4 4 4 4 3 2 5 5 5 3 3 4 4 4 2 1 2 2 2 2 1 2 2 1 1 2 1 2 3 1 1 5 2 4 2 4 2 5 1 2 4 4 3 3 3 4 4 4 4 3 3 1 1 1 1 5 3 1 1 1 1 5 3 3 1 2 0 4 3 4 2 3 0 1 0 0 0 0 0 0 0 1 1 5 2 1 1 4 4 4 4 1 1 1 1 5 2 0 3 Correct: 600 out of: 1255\n",
      "Accuracy of the network :  47.808764940239044\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "\n",
    "Y=[]  #target\n",
    "Pred=[]  #predicted\n",
    "\n",
    "with torch.no_grad():\n",
    "    for row in range(len(TestData)):\n",
    "        outputs = net(TestData[row,:].float())\n",
    "        result=0\n",
    "        total+=1\n",
    "        if outputs[0]<outputs[1]:result=1\n",
    "        if outputs[result]<outputs[2]:result=2\n",
    "        if outputs[result]<outputs[3]:result=3\n",
    "        if outputs[result]<outputs[4]:result=4\n",
    "        if outputs[result]<outputs[5]:result=5\n",
    "        \n",
    "        if labelsOneHot.iloc[row,result]==1: correct+=1\n",
    "        \n",
    "        Y.append(labels.iloc[row])\n",
    "        Pred.append(result)\n",
    "        \n",
    "        print(result, end=' ')\n",
    "        \n",
    "       \n",
    "print('Correct:', correct, 'out of:', total )\n",
    "print('Accuracy of the network : ',( 100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 49  17   4  14   5   2]\n",
      " [  6 130  29  29  26  13]\n",
      " [ 13  36  76  45  28  23]\n",
      " [  2  35  24 126  45  23]\n",
      " [  1  21  21  58 126  22]\n",
      " [  2  23  13  34  41  93]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics \n",
    "print(metrics.confusion_matrix(Y,Pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Pants       0.67      0.54      0.60        91\n",
      "       False       0.50      0.56      0.53       233\n",
      " Barely-True       0.46      0.34      0.39       221\n",
      "   Half-True       0.41      0.49      0.45       255\n",
      " Mostly-True       0.46      0.51      0.48       249\n",
      "        True       0.53      0.45      0.49       206\n",
      "\n",
      "    accuracy                           0.48      1255\n",
      "   macro avg       0.50      0.48      0.49      1255\n",
      "weighted avg       0.48      0.48      0.48      1255\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "target_names = ['Pants', 'False', 'Barely-True','Half-True','Mostly-True','True']\n",
    "\n",
    "print(metrics.classification_report(Y, Pred,target_names =target_names))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the FCNN model\n",
    "\n",
    "stage='NNetwork6WayClassification/'\n",
    "SavesDirectory='./TunedModels/'+model_class+'/'+model_version+\"/\"+stage\n",
    "#PATH = SavesDirectory+'Tanh_MSE_adam4781.pth'\n",
    "\n",
    "torch.save(net.state_dict(), PATH)\n",
    "\n",
    "# more on saving pytorch networks: https://pytorch.org/docs/stable/notes/serialization.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
