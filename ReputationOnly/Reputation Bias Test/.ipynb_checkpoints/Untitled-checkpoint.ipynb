{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary libraries\n",
    "import pandas as pd \n",
    "import sklearn\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reputation based detection\n",
    "\n",
    "This notebook is used to test if the inclusion of reputation vector biases the classification of the statement.\n",
    "\n",
    "The basic assumtion being:  If a frequent liar says something true, it will be marked as a lie.  Similarly a lie frequent truth-speaker will tend to be marked as truth.\n",
    "\n",
    "We first load the trained model and test it on a collection of statments that are not on the usual level of truth of their speakers (truths from liars, and lies from \"honest\"), and then check the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model variables were set up: \n"
     ]
    }
   ],
   "source": [
    "# loading BERT\n",
    "\n",
    "\n",
    "model_class='bert'  # bert or roberta or albert\n",
    "model_version='bert-base-cased' #bert-base-cased, roberta-base, roberta-large, albert-base-v2 OR albert-large-v2\n",
    "output_folder='../TunedModels/'+model_class+'/'+model_version+\"/\"\n",
    "\n",
    "# Load pre-trained model (weights)\n",
    "CheckPoint='checkpoint-322-epoch-2'  #epoch 2\n",
    "preSavedCheckpoint=output_folder+CheckPoint\n",
    " \n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained(preSavedCheckpoint)\n",
    "model = BertForSequenceClassification.from_pretrained(preSavedCheckpoint)\n",
    "\n",
    "print('model variables were set up: ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.3281,  0.5524,  0.0417, -0.4856, -0.8885, -0.0527]],\n",
       "       grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()\n",
    "input_ids = torch.tensor(tokenizer.encode(\" This is a sample statement.\", add_special_tokens=True)).unsqueeze(0)  # Batch size 1\n",
    "labels = torch.tensor([1]).unsqueeze(0)  # Batch size 1\n",
    "outputs = model(input_ids, labels=labels)\n",
    "\n",
    "loss, logits = outputs[:2]\n",
    "logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we load the rows whose label does not reflect the reputation of the speaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>All private healthcare plans must conform to g...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Obama has \"visited more countries and met with...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Iraq has the second-largest oilfields in the w...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Says American polling shows Russian President ...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The U.S. doesnt make television sets anymore.</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>Mitt Romney did not run his campaign on the ba...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>My opponent supported policies that increased ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>Fundamental changes made to the language descr...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223</th>\n",
       "      <td>Ed Gillespie supports a personhood amendment.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224</th>\n",
       "      <td>On whether state employees should contribute t...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>225 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text  labels\n",
       "0    All private healthcare plans must conform to g...       5\n",
       "1    Obama has \"visited more countries and met with...       5\n",
       "2    Iraq has the second-largest oilfields in the w...       4\n",
       "3    Says American polling shows Russian President ...       5\n",
       "4        The U.S. doesnt make television sets anymore.       5\n",
       "..                                                 ...     ...\n",
       "220  Mitt Romney did not run his campaign on the ba...       0\n",
       "221  My opponent supported policies that increased ...       1\n",
       "222  Fundamental changes made to the language descr...       0\n",
       "223      Ed Gillespie supports a personhood amendment.       1\n",
       "224  On whether state employees should contribute t...       1\n",
       "\n",
       "[225 rows x 2 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ReadSet=pd.read_excel('test_reputationExceptions.xlsx' )\n",
    "  \n",
    "ReadSet['text']=ReadSet['Statement']\n",
    "ReadSet['labels']=ReadSet['Label']\n",
    "    \n",
    "ReadSet=ReadSet.drop(['ID','Label','Statement','Subject','Speaker','Job','From','Affiliation','PantsTotal','NotRealTotal','BarelyTotal','HalfTotal','MostlyTotal','Truths','Context','PositivityRatio'],axis=1)\n",
    "\n",
    "\n",
    "ReadSet\n",
    "\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PantsTotal</th>\n",
       "      <th>NotRealTotal</th>\n",
       "      <th>BarelyTotal</th>\n",
       "      <th>HalfTotal</th>\n",
       "      <th>MostlyTotal</th>\n",
       "      <th>Truths</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>105</td>\n",
       "      <td>43</td>\n",
       "      <td>11</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>105</td>\n",
       "      <td>43</td>\n",
       "      <td>11</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>61</td>\n",
       "      <td>114</td>\n",
       "      <td>63</td>\n",
       "      <td>51</td>\n",
       "      <td>37</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>61</td>\n",
       "      <td>114</td>\n",
       "      <td>63</td>\n",
       "      <td>51</td>\n",
       "      <td>37</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>61</td>\n",
       "      <td>114</td>\n",
       "      <td>63</td>\n",
       "      <td>51</td>\n",
       "      <td>37</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>11</td>\n",
       "      <td>41</td>\n",
       "      <td>26</td>\n",
       "      <td>32</td>\n",
       "      <td>40</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>11</td>\n",
       "      <td>41</td>\n",
       "      <td>26</td>\n",
       "      <td>32</td>\n",
       "      <td>40</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>11</td>\n",
       "      <td>41</td>\n",
       "      <td>26</td>\n",
       "      <td>32</td>\n",
       "      <td>40</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224</th>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>225 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PantsTotal  NotRealTotal  BarelyTotal  HalfTotal  MostlyTotal  Truths\n",
       "0           105            43           11          8            5       6\n",
       "1           105            43           11          8            5       6\n",
       "2            61           114           63         51           37      14\n",
       "3            61           114           63         51           37      14\n",
       "4            61           114           63         51           37      14\n",
       "..          ...           ...          ...        ...          ...     ...\n",
       "220          11            41           26         32           40      23\n",
       "221          11            41           26         32           40      23\n",
       "222          11            41           26         32           40      23\n",
       "223           0             1            3          6            3       8\n",
       "224           3             5            6          7            6       9\n",
       "\n",
       "[225 rows x 6 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Reputation=pd.read_excel('test_reputationExceptions.xlsx' )\n",
    "    \n",
    "Reputation=Reputation.drop(['ID','Label','Statement','Subject','Speaker','Job','From','Affiliation','Context','PositivityRatio'],axis=1)\n",
    "Reputation\n",
    "#now we normalise these values\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PantsTotal</th>\n",
       "      <th>NotRealTotal</th>\n",
       "      <th>BarelyTotal</th>\n",
       "      <th>HalfTotal</th>\n",
       "      <th>MostlyTotal</th>\n",
       "      <th>Truths</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.525</td>\n",
       "      <td>0.215</td>\n",
       "      <td>0.055</td>\n",
       "      <td>0.040</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.525</td>\n",
       "      <td>0.215</td>\n",
       "      <td>0.055</td>\n",
       "      <td>0.040</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.305</td>\n",
       "      <td>0.570</td>\n",
       "      <td>0.315</td>\n",
       "      <td>0.255</td>\n",
       "      <td>0.185</td>\n",
       "      <td>0.070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.305</td>\n",
       "      <td>0.570</td>\n",
       "      <td>0.315</td>\n",
       "      <td>0.255</td>\n",
       "      <td>0.185</td>\n",
       "      <td>0.070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.305</td>\n",
       "      <td>0.570</td>\n",
       "      <td>0.315</td>\n",
       "      <td>0.255</td>\n",
       "      <td>0.185</td>\n",
       "      <td>0.070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>0.055</td>\n",
       "      <td>0.205</td>\n",
       "      <td>0.130</td>\n",
       "      <td>0.160</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>0.055</td>\n",
       "      <td>0.205</td>\n",
       "      <td>0.130</td>\n",
       "      <td>0.160</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>0.055</td>\n",
       "      <td>0.205</td>\n",
       "      <td>0.130</td>\n",
       "      <td>0.160</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.030</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224</th>\n",
       "      <td>0.015</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.030</td>\n",
       "      <td>0.035</td>\n",
       "      <td>0.030</td>\n",
       "      <td>0.045</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>225 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PantsTotal  NotRealTotal  BarelyTotal  HalfTotal  MostlyTotal  Truths\n",
       "0         0.525         0.215        0.055      0.040        0.025   0.030\n",
       "1         0.525         0.215        0.055      0.040        0.025   0.030\n",
       "2         0.305         0.570        0.315      0.255        0.185   0.070\n",
       "3         0.305         0.570        0.315      0.255        0.185   0.070\n",
       "4         0.305         0.570        0.315      0.255        0.185   0.070\n",
       "..          ...           ...          ...        ...          ...     ...\n",
       "220       0.055         0.205        0.130      0.160        0.200   0.115\n",
       "221       0.055         0.205        0.130      0.160        0.200   0.115\n",
       "222       0.055         0.205        0.130      0.160        0.200   0.115\n",
       "223       0.000         0.005        0.015      0.030        0.015   0.040\n",
       "224       0.015         0.025        0.030      0.035        0.030   0.045\n",
       "\n",
       "[225 rows x 6 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#here we normalise these values to reflect those used by the trained network\n",
    "for row in range(len(Reputation)):    \n",
    "    for value in range(6):\n",
    "        Reputation.iloc[row,value]=Reputation.iloc[row,value]/200\n",
    "Reputation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Now we take the vectors from BERT to be added to the reputation vector and all will be fed to the FC neural net.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(28996, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=6, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching Vectors...Saving...Saved!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.944851</td>\n",
       "      <td>0.210424</td>\n",
       "      <td>-0.110360</td>\n",
       "      <td>0.353483</td>\n",
       "      <td>0.160371</td>\n",
       "      <td>0.096508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.031268</td>\n",
       "      <td>-0.027468</td>\n",
       "      <td>-0.076674</td>\n",
       "      <td>0.551089</td>\n",
       "      <td>0.415860</td>\n",
       "      <td>0.132593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.232078</td>\n",
       "      <td>-0.163362</td>\n",
       "      <td>-0.443130</td>\n",
       "      <td>0.630184</td>\n",
       "      <td>1.293313</td>\n",
       "      <td>0.801998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.602480</td>\n",
       "      <td>0.115499</td>\n",
       "      <td>-0.068574</td>\n",
       "      <td>0.430667</td>\n",
       "      <td>0.156590</td>\n",
       "      <td>-0.145021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.641113</td>\n",
       "      <td>0.330818</td>\n",
       "      <td>-0.113212</td>\n",
       "      <td>-0.063934</td>\n",
       "      <td>0.049839</td>\n",
       "      <td>0.044381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>-0.812189</td>\n",
       "      <td>0.046724</td>\n",
       "      <td>-0.023658</td>\n",
       "      <td>0.465596</td>\n",
       "      <td>0.271030</td>\n",
       "      <td>-0.084956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>-1.217539</td>\n",
       "      <td>0.212214</td>\n",
       "      <td>-0.024047</td>\n",
       "      <td>0.318464</td>\n",
       "      <td>0.280139</td>\n",
       "      <td>0.080603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>-0.367165</td>\n",
       "      <td>0.433367</td>\n",
       "      <td>0.090700</td>\n",
       "      <td>-0.151363</td>\n",
       "      <td>-0.546449</td>\n",
       "      <td>-0.272010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223</th>\n",
       "      <td>-0.493372</td>\n",
       "      <td>0.445718</td>\n",
       "      <td>0.193865</td>\n",
       "      <td>-0.175051</td>\n",
       "      <td>-0.612319</td>\n",
       "      <td>-0.300215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224</th>\n",
       "      <td>-0.754633</td>\n",
       "      <td>1.044860</td>\n",
       "      <td>-0.131322</td>\n",
       "      <td>0.124473</td>\n",
       "      <td>-0.700626</td>\n",
       "      <td>-0.021628</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>225 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2         3         4         5\n",
       "0   -0.944851  0.210424 -0.110360  0.353483  0.160371  0.096508\n",
       "1   -1.031268 -0.027468 -0.076674  0.551089  0.415860  0.132593\n",
       "2   -1.232078 -0.163362 -0.443130  0.630184  1.293313  0.801998\n",
       "3   -0.602480  0.115499 -0.068574  0.430667  0.156590 -0.145021\n",
       "4   -0.641113  0.330818 -0.113212 -0.063934  0.049839  0.044381\n",
       "..        ...       ...       ...       ...       ...       ...\n",
       "220 -0.812189  0.046724 -0.023658  0.465596  0.271030 -0.084956\n",
       "221 -1.217539  0.212214 -0.024047  0.318464  0.280139  0.080603\n",
       "222 -0.367165  0.433367  0.090700 -0.151363 -0.546449 -0.272010\n",
       "223 -0.493372  0.445718  0.193865 -0.175051 -0.612319 -0.300215\n",
       "224 -0.754633  1.044860 -0.131322  0.124473 -0.700626 -0.021628\n",
       "\n",
       "[225 rows x 6 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "statementVectors=[] # we collect the sentence vectors in this array\n",
    "print (\"Fetching Vectors...\", end='')\n",
    "\n",
    "for row in range(len(ReadSet)):\n",
    "    with torch.no_grad():\n",
    "        text=ReadSet.iloc[row,0]\n",
    "        input_ids = torch.tensor(tokenizer.encode(text, add_special_tokens=True)).unsqueeze(0)  # Batch size 1\n",
    "        labels = torch.tensor([1]).unsqueeze(0)  # Batch size 1\n",
    "        outputs = model(input_ids, labels=labels)\n",
    "        loss, logits = outputs[:2]\n",
    "        #logits[0].detach().numpy()\n",
    "        statementVectors.append(logits[0].detach().numpy())\n",
    "\n",
    "print('Saving...',end='')\n",
    "fileOut = pd.DataFrame(data= statementVectors)\n",
    "fileOut.to_csv('BERT_Vectors.tsv', sep='\\t',  index=False)\n",
    "print('Saved!')\n",
    "fileOut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PantsTotal</th>\n",
       "      <th>NotRealTotal</th>\n",
       "      <th>BarelyTotal</th>\n",
       "      <th>HalfTotal</th>\n",
       "      <th>MostlyTotal</th>\n",
       "      <th>Truths</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.525</td>\n",
       "      <td>0.215</td>\n",
       "      <td>0.055</td>\n",
       "      <td>0.040</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.030</td>\n",
       "      <td>-0.944851</td>\n",
       "      <td>0.210424</td>\n",
       "      <td>-0.110360</td>\n",
       "      <td>0.353483</td>\n",
       "      <td>0.160371</td>\n",
       "      <td>0.096508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.525</td>\n",
       "      <td>0.215</td>\n",
       "      <td>0.055</td>\n",
       "      <td>0.040</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.030</td>\n",
       "      <td>-1.031268</td>\n",
       "      <td>-0.027468</td>\n",
       "      <td>-0.076674</td>\n",
       "      <td>0.551089</td>\n",
       "      <td>0.415860</td>\n",
       "      <td>0.132593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.305</td>\n",
       "      <td>0.570</td>\n",
       "      <td>0.315</td>\n",
       "      <td>0.255</td>\n",
       "      <td>0.185</td>\n",
       "      <td>0.070</td>\n",
       "      <td>-1.232078</td>\n",
       "      <td>-0.163362</td>\n",
       "      <td>-0.443130</td>\n",
       "      <td>0.630184</td>\n",
       "      <td>1.293313</td>\n",
       "      <td>0.801998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.305</td>\n",
       "      <td>0.570</td>\n",
       "      <td>0.315</td>\n",
       "      <td>0.255</td>\n",
       "      <td>0.185</td>\n",
       "      <td>0.070</td>\n",
       "      <td>-0.602480</td>\n",
       "      <td>0.115499</td>\n",
       "      <td>-0.068574</td>\n",
       "      <td>0.430667</td>\n",
       "      <td>0.156590</td>\n",
       "      <td>-0.145021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.305</td>\n",
       "      <td>0.570</td>\n",
       "      <td>0.315</td>\n",
       "      <td>0.255</td>\n",
       "      <td>0.185</td>\n",
       "      <td>0.070</td>\n",
       "      <td>-0.641113</td>\n",
       "      <td>0.330818</td>\n",
       "      <td>-0.113212</td>\n",
       "      <td>-0.063934</td>\n",
       "      <td>0.049839</td>\n",
       "      <td>0.044381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>0.055</td>\n",
       "      <td>0.205</td>\n",
       "      <td>0.130</td>\n",
       "      <td>0.160</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.115</td>\n",
       "      <td>-0.812189</td>\n",
       "      <td>0.046724</td>\n",
       "      <td>-0.023658</td>\n",
       "      <td>0.465596</td>\n",
       "      <td>0.271030</td>\n",
       "      <td>-0.084956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>0.055</td>\n",
       "      <td>0.205</td>\n",
       "      <td>0.130</td>\n",
       "      <td>0.160</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.115</td>\n",
       "      <td>-1.217539</td>\n",
       "      <td>0.212214</td>\n",
       "      <td>-0.024047</td>\n",
       "      <td>0.318464</td>\n",
       "      <td>0.280139</td>\n",
       "      <td>0.080603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>0.055</td>\n",
       "      <td>0.205</td>\n",
       "      <td>0.130</td>\n",
       "      <td>0.160</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.115</td>\n",
       "      <td>-0.367165</td>\n",
       "      <td>0.433367</td>\n",
       "      <td>0.090700</td>\n",
       "      <td>-0.151363</td>\n",
       "      <td>-0.546449</td>\n",
       "      <td>-0.272010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.030</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.040</td>\n",
       "      <td>-0.493372</td>\n",
       "      <td>0.445718</td>\n",
       "      <td>0.193865</td>\n",
       "      <td>-0.175051</td>\n",
       "      <td>-0.612319</td>\n",
       "      <td>-0.300215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224</th>\n",
       "      <td>0.015</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.030</td>\n",
       "      <td>0.035</td>\n",
       "      <td>0.030</td>\n",
       "      <td>0.045</td>\n",
       "      <td>-0.754633</td>\n",
       "      <td>1.044860</td>\n",
       "      <td>-0.131322</td>\n",
       "      <td>0.124473</td>\n",
       "      <td>-0.700626</td>\n",
       "      <td>-0.021628</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>225 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PantsTotal  NotRealTotal  BarelyTotal  HalfTotal  MostlyTotal  Truths  \\\n",
       "0         0.525         0.215        0.055      0.040        0.025   0.030   \n",
       "1         0.525         0.215        0.055      0.040        0.025   0.030   \n",
       "2         0.305         0.570        0.315      0.255        0.185   0.070   \n",
       "3         0.305         0.570        0.315      0.255        0.185   0.070   \n",
       "4         0.305         0.570        0.315      0.255        0.185   0.070   \n",
       "..          ...           ...          ...        ...          ...     ...   \n",
       "220       0.055         0.205        0.130      0.160        0.200   0.115   \n",
       "221       0.055         0.205        0.130      0.160        0.200   0.115   \n",
       "222       0.055         0.205        0.130      0.160        0.200   0.115   \n",
       "223       0.000         0.005        0.015      0.030        0.015   0.040   \n",
       "224       0.015         0.025        0.030      0.035        0.030   0.045   \n",
       "\n",
       "            0         1         2         3         4         5  \n",
       "0   -0.944851  0.210424 -0.110360  0.353483  0.160371  0.096508  \n",
       "1   -1.031268 -0.027468 -0.076674  0.551089  0.415860  0.132593  \n",
       "2   -1.232078 -0.163362 -0.443130  0.630184  1.293313  0.801998  \n",
       "3   -0.602480  0.115499 -0.068574  0.430667  0.156590 -0.145021  \n",
       "4   -0.641113  0.330818 -0.113212 -0.063934  0.049839  0.044381  \n",
       "..        ...       ...       ...       ...       ...       ...  \n",
       "220 -0.812189  0.046724 -0.023658  0.465596  0.271030 -0.084956  \n",
       "221 -1.217539  0.212214 -0.024047  0.318464  0.280139  0.080603  \n",
       "222 -0.367165  0.433367  0.090700 -0.151363 -0.546449 -0.272010  \n",
       "223 -0.493372  0.445718  0.193865 -0.175051 -0.612319 -0.300215  \n",
       "224 -0.754633  1.044860 -0.131322  0.124473 -0.700626 -0.021628  \n",
       "\n",
       "[225 rows x 12 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test=pd.concat([Reputation,fileOut], axis=1)\n",
    "test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  adding the Fully Connected Neural Network to include the reputation vector\n",
    "InputSize=12\n",
    "OutputSize=6\n",
    "\n",
    "class Net(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "         \n",
    "        # an affine operation: y = Wx + b\n",
    "        self.fc1 = nn.Linear(InputSize, 120)  # input size 32\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, OutputSize)  #classifies 'outputsize' different classes\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.tanh(self.fc1(x))\n",
    "        x = torch.tanh(self.fc2(x)) \n",
    "        x = torch.tanh(self.fc3(x)).double()\n",
    "        return x\n",
    "\n",
    "    \n",
    "\n",
    "#\n",
    "#And we load previously saved FCNN model (which was trained)\n",
    "\n",
    "stage='NNetwork/'\n",
    "SavesDirectory='../TunedModels/'+model_class+'/'+model_version+\"/\"+stage\n",
    "PATH = SavesDirectory+'Tanh_MSE_adam4887.pth'\n",
    "\n",
    "net = Net()\n",
    "net.load_state_dict(torch.load(PATH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.5250,  0.2150,  0.0550,  ...,  0.3535,  0.1604,  0.0965],\n",
       "        [ 0.5250,  0.2150,  0.0550,  ...,  0.5511,  0.4159,  0.1326],\n",
       "        [ 0.3050,  0.5700,  0.3150,  ...,  0.6302,  1.2933,  0.8020],\n",
       "        ...,\n",
       "        [ 0.0550,  0.2050,  0.1300,  ..., -0.1514, -0.5464, -0.2720],\n",
       "        [ 0.0000,  0.0050,  0.0150,  ..., -0.1751, -0.6123, -0.3002],\n",
       "        [ 0.0150,  0.0250,  0.0300,  ...,  0.1245, -0.7006, -0.0216]],\n",
       "       dtype=torch.float64)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TestData=torch.tensor(test.values)\n",
    "TestData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>225 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0  1  2  3  4  5\n",
       "0    0  0  0  0  0  1\n",
       "1    0  0  0  0  0  1\n",
       "2    0  0  0  0  1  0\n",
       "3    0  0  0  0  0  1\n",
       "4    0  0  0  0  0  1\n",
       "..  .. .. .. .. .. ..\n",
       "220  1  0  0  0  0  0\n",
       "221  0  1  0  0  0  0\n",
       "222  1  0  0  0  0  0\n",
       "223  0  1  0  0  0  0\n",
       "224  0  1  0  0  0  0\n",
       "\n",
       "[225 rows x 6 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " \n",
    "labels=ReadSet['labels']\n",
    "labelsOneHot=pd.get_dummies(labels)\n",
    "labelsOneHot\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 4 1 1 1 1 1 1 1 1 0 1 0 2 1 2 1 2 5 5 2 1 4 1 3 1 3 5 1 4 5 3 5 5 2 3 4 5 5 2 4 2 4 1 1 4 2 3 4 2 4 3 4 1 4 4 1 5 4 3 1 4 1 5 3 1 5 3 4 3 3 1 3 3 1 3 3 5 3 2 3 3 2 3 1 4 3 2 3 2 1 5 4 3 5 3 4 1 1 1 1 3 1 1 1 3 3 1 4 4 4 5 4 2 3 4 1 5 4 4 4 1 1 1 1 5 2 5 2 3 5 3 3 3 1 2 0 3 1 3 2 4 5 4 3 1 4 4 4 1 1 4 4 3 0 2 5 1 1 1 3 2 3 5 4 4 4 2 5 3 5 3 4 4 2 1 5 1 2 1 1 2 3 1 2 3 3 2 2 1 3 2 1 1 5 5 3 3 4 1 3 4 1 1 3 0 3 1 1 5 3 3 4 4 3 1 1 5 4 3 4 1 2 1 Correct: 49 out of: 225\n",
      "Accuracy of the network :  21.77777777777778\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "countCorrect0=0\n",
    "countCorrect1=0\n",
    "count0=0\n",
    "count1=0\n",
    "\n",
    "Y=[]  #target\n",
    "Pred=[]  #predicted\n",
    "\n",
    "with torch.no_grad():\n",
    "    for row in range(len(TestData)):\n",
    "        outputs = net(TestData[row,:].float())\n",
    "        result=0\n",
    "        total+=1\n",
    "        if outputs[0]<outputs[1]:result=1\n",
    "        if outputs[result]<outputs[2]:result=2\n",
    "        if outputs[result]<outputs[3]:result=3\n",
    "        if outputs[result]<outputs[4]:result=4\n",
    "        if outputs[result]<outputs[5]:result=5\n",
    "        \n",
    "        if labelsOneHot.iloc[row,result]==1: correct+=1\n",
    "        \n",
    "        Y.append(result)\n",
    "        Pred.append(labels.iloc[row])\n",
    "        \n",
    "        print(result, end=' ')\n",
    "        \n",
    "       \n",
    "print('Correct:', correct, 'out of:', total )\n",
    "print('Accuracy of the network : ',( 100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 2  0  0  0  2  3]\n",
      " [ 8 29 10  0 10  7]\n",
      " [ 3  8 13  0  4  1]\n",
      " [ 8 22 19  1  1  1]\n",
      " [ 2 21 15  0  4  2]\n",
      " [ 2 16 10  0  1  0]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    " \n",
    "print(metrics.confusion_matrix(Y,Pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can see that truths tend to be labelled as lies very frequently\n",
    "# while lies tend to still be labelled as lies, but can be seen as truth occasionally.\n",
    "\n",
    "# the problem with the statement classification on its own, of being biased towards\n",
    "#marking statements as false, is not diluted by adding the reputation vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Pants       0.08      0.29      0.12         7\n",
      "       False       0.30      0.45      0.36        64\n",
      " Barely-True       0.19      0.45      0.27        29\n",
      "   Half-True       1.00      0.02      0.04        52\n",
      " Mostly-True       0.18      0.09      0.12        44\n",
      "        True       0.00      0.00      0.00        29\n",
      "\n",
      "    accuracy                           0.22       225\n",
      "   macro avg       0.29      0.22      0.15       225\n",
      "weighted avg       0.38      0.22      0.17       225\n",
      "\n"
     ]
    }
   ],
   "source": [
    "target_names = ['Pants', 'False', 'Barely-True','Half-True','Mostly-True','True']\n",
    "\n",
    "print(metrics.classification_report(Y, Pred,target_names =target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
