{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PantsTotal</th>\n",
       "      <th>NotRealTotal</th>\n",
       "      <th>BarelyTotal</th>\n",
       "      <th>HalfTotal</th>\n",
       "      <th>MostlyTotal</th>\n",
       "      <th>Truths</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6529</th>\n",
       "      <td>9.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>163.0</td>\n",
       "      <td>125.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6530</th>\n",
       "      <td>9.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>163.0</td>\n",
       "      <td>125.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6531</th>\n",
       "      <td>9.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>163.0</td>\n",
       "      <td>125.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6532</th>\n",
       "      <td>9.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>163.0</td>\n",
       "      <td>125.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6533</th>\n",
       "      <td>9.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>163.0</td>\n",
       "      <td>125.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6534 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      PantsTotal  NotRealTotal  BarelyTotal  HalfTotal  MostlyTotal  Truths\n",
       "0            1.0           0.0          1.0        1.0          0.0     3.0\n",
       "1            0.0           2.0          1.0        1.0          0.0     2.0\n",
       "2            1.0           0.0          1.0        1.0          0.0     3.0\n",
       "3            0.0           1.0          1.0        1.0          2.0     1.0\n",
       "4            1.0           1.0          2.0        0.0          1.0     1.0\n",
       "...          ...           ...          ...        ...          ...     ...\n",
       "6529         9.0          71.0         70.0      160.0        163.0   125.0\n",
       "6530         9.0          71.0         70.0      160.0        163.0   125.0\n",
       "6531         9.0          71.0         70.0      160.0        163.0   125.0\n",
       "6532         9.0          71.0         70.0      160.0        163.0   125.0\n",
       "6533         9.0          71.0         70.0      160.0        163.0   125.0\n",
       "\n",
       "[6534 rows x 6 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we import the training set \n",
    "train=pd.read_excel('trainReputationLowNoise.xlsx' )\n",
    "train=train.iloc[:,:-2].astype(float)\n",
    "\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6529</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6530</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6531</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6532</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6533</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6534 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0  1  2  3  4  5\n",
       "0     1  0  0  0  0  0\n",
       "1     0  0  0  0  0  1\n",
       "2     0  0  0  0  0  1\n",
       "3     0  0  0  0  1  0\n",
       "4     1  0  0  0  0  0\n",
       "...  .. .. .. .. .. ..\n",
       "6529  0  0  0  0  1  0\n",
       "6530  0  0  0  0  1  0\n",
       "6531  0  0  0  1  0  0\n",
       "6532  0  0  0  0  0  1\n",
       "6533  0  0  0  1  0  0\n",
       "\n",
       "[6534 rows x 6 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#we import the one hot encoded labels\n",
    "TrainLables=pd.read_excel('trainReputationLowNoise.xlsx' )\n",
    "TrainLables=TrainLables.iloc[:,-1] \n",
    "\n",
    "TrainLables=pd.get_dummies(TrainLables)\n",
    "TrainLables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  1.,   0.,   1.,   1.,   0.,   3.],\n",
       "        [  0.,   2.,   1.,   1.,   0.,   2.],\n",
       "        [  1.,   0.,   1.,   1.,   0.,   3.],\n",
       "        ...,\n",
       "        [  9.,  71.,  70., 160., 163., 125.],\n",
       "        [  9.,  71.,  70., 160., 163., 125.],\n",
       "        [  9.,  71.,  70., 160., 163., 125.]], dtype=torch.float64)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get input vector from dataset in this cell\n",
    " \n",
    "input=torch.tensor(train.values)\n",
    "input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 1.],\n",
       "        [0., 0., 0., 0., 0., 1.],\n",
       "        ...,\n",
       "        [0., 0., 0., 1., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1., 0., 0.]], dtype=torch.float64)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#we get the size of the output of our neural network from classification\n",
    "\n",
    " \n",
    "targets=torch.tensor(TrainLables.astype(float).values)\n",
    "\n",
    "targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input size: 6\n",
      "output size: 6\n"
     ]
    }
   ],
   "source": [
    " \n",
    "size= torch.tensor(input[0].size())\n",
    "InputSize=size.item()\n",
    "\n",
    "OutputSize=torch.tensor(targets[0].size()).item()\n",
    "\n",
    "print('input size:', InputSize)\n",
    "print('output size:', OutputSize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Net(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "         \n",
    "        # an affine operation: y = Wx + b\n",
    "        self.fc1 = nn.Linear(InputSize, 120)  # input size 32\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, OutputSize)  #classifies 'outputsize' different classes\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.sigmoid(self.fc1(x))\n",
    "        x = torch.sigmoid(self.fc2(x)) \n",
    "        x = torch.sigmoid(self.fc3(x)).double()\n",
    "        return x\n",
    "\n",
    "    \n",
    "\n",
    "#now we use it\n",
    "\n",
    "net = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here we  setup the neural network parameters\n",
    "# pick an optimizer (Simple Gradient Descent)\n",
    "\n",
    "learning_rate = 9e-4\n",
    "criterion = nn.MSELoss()  #computes the loss Function\n",
    "\n",
    "import torch.optim as optim\n",
    "\n",
    "# creating optimizer\n",
    "#optimizer = optim.SGD(net.parameters(), lr=learning_rate)\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor(0.2388, dtype=torch.float64, grad_fn=<MseLossBackward>) "
     ]
    }
   ],
   "source": [
    " # this is how to compute the loss, backporpagate and update the weights\n",
    "\n",
    "# in the training loop:\n",
    "optimizer.zero_grad()   # zero the gradient buffers\n",
    "output = net(input.float())\n",
    "\n",
    "loss = criterion(output, targets)\n",
    "print('Loss:', loss, end=' ')\n",
    "\n",
    "loss.backward()  #backprop\n",
    "optimizer.step()    # Does the update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor(0.1261, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 0\n",
      "Loss: tensor(0.1261, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1\n",
      "Loss: tensor(0.1261, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2\n",
      "Loss: tensor(0.1261, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3\n",
      "Loss: tensor(0.1261, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4\n",
      "Loss: tensor(0.1261, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5\n",
      "Loss: tensor(0.1261, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6\n",
      "Loss: tensor(0.1261, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7\n",
      "Loss: tensor(0.1261, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8\n",
      "Loss: tensor(0.1261, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 9\n",
      "Loss: tensor(0.1261, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 10\n",
      "Loss: tensor(0.1261, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 11\n",
      "Loss: tensor(0.1260, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 12\n",
      "Loss: tensor(0.1260, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 13\n",
      "Loss: tensor(0.1260, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 14\n",
      "Loss: tensor(0.1260, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 15\n",
      "Loss: tensor(0.1260, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 16\n",
      "Loss: tensor(0.1260, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 17\n",
      "Loss: tensor(0.1260, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 18\n",
      "Loss: tensor(0.1260, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 19\n",
      "Loss: tensor(0.1260, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 20\n",
      "Loss: tensor(0.1260, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 21\n",
      "Loss: tensor(0.1260, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 22\n",
      "Loss: tensor(0.1260, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 23\n",
      "Loss: tensor(0.1260, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 24\n",
      "Loss: tensor(0.1260, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 25\n",
      "Loss: tensor(0.1260, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 26\n",
      "Loss: tensor(0.1260, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 27\n",
      "Loss: tensor(0.1260, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 28\n",
      "Loss: tensor(0.1260, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 29\n",
      "Loss: tensor(0.1260, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 30\n",
      "Loss: tensor(0.1260, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 31\n",
      "Loss: tensor(0.1260, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 32\n",
      "Loss: tensor(0.1260, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 33\n",
      "Loss: tensor(0.1260, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 34\n",
      "Loss: tensor(0.1260, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 35\n",
      "Loss: tensor(0.1260, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 36\n",
      "Loss: tensor(0.1260, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 37\n",
      "Loss: tensor(0.1260, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 38\n",
      "Loss: tensor(0.1260, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 39\n",
      "Loss: tensor(0.1260, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 40\n",
      "Loss: tensor(0.1260, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 41\n",
      "Loss: tensor(0.1260, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 42\n",
      "Loss: tensor(0.1260, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 43\n",
      "Loss: tensor(0.1260, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 44\n",
      "Loss: tensor(0.1260, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 45\n",
      "Loss: tensor(0.1260, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 46\n",
      "Loss: tensor(0.1260, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 47\n",
      "Loss: tensor(0.1260, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 48\n",
      "Loss: tensor(0.1260, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 49\n",
      "Loss: tensor(0.1260, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 50\n",
      "Loss: tensor(0.1260, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 51\n",
      "Loss: tensor(0.1260, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 52\n",
      "Loss: tensor(0.1260, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 53\n",
      "Loss: tensor(0.1260, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 54\n",
      "Loss: tensor(0.1260, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 55\n",
      "Loss: tensor(0.1260, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 56\n",
      "Loss: tensor(0.1260, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 57\n",
      "Loss: tensor(0.1260, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 58\n",
      "Loss: tensor(0.1260, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 59\n",
      "Loss: tensor(0.1260, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 60\n",
      "Loss: tensor(0.1260, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 61\n",
      "Loss: tensor(0.1260, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 62\n",
      "Loss: tensor(0.1260, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 63\n",
      "Loss: tensor(0.1260, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 64\n",
      "Loss: tensor(0.1260, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 65\n",
      "Loss: tensor(0.1260, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 66\n",
      "Loss: tensor(0.1260, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 67\n",
      "Loss: tensor(0.1260, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 68\n",
      "Loss: tensor(0.1260, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 69\n",
      "Loss: tensor(0.1260, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 70\n",
      "Loss: tensor(0.1260, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 71\n",
      "Loss: tensor(0.1260, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 72\n",
      "Loss: tensor(0.1260, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 73\n",
      "Loss: tensor(0.1260, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 74\n",
      "Loss: tensor(0.1260, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 75\n",
      "Loss: tensor(0.1260, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 76\n",
      "Loss: tensor(0.1260, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 77\n",
      "Loss: tensor(0.1260, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 78\n",
      "Loss: tensor(0.1260, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 79\n",
      "Loss: tensor(0.1260, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 80\n",
      "Loss: tensor(0.1260, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 81\n",
      "Loss: tensor(0.1260, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 82\n",
      "Loss: tensor(0.1260, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 83\n",
      "Loss: tensor(0.1260, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 84\n",
      "Loss: tensor(0.1260, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 85\n",
      "Loss: tensor(0.1260, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 86\n",
      "Loss: tensor(0.1260, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 87\n",
      "Loss: tensor(0.1260, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 88\n",
      "Loss: tensor(0.1260, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 89\n",
      "Loss: tensor(0.1260, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 90\n",
      "Loss: tensor(0.1260, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 91\n",
      "Loss: tensor(0.1260, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 92\n",
      "Loss: tensor(0.1260, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 93\n",
      "Loss: tensor(0.1260, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 94\n",
      "Loss: tensor(0.1260, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 95\n",
      "Loss: tensor(0.1260, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 96\n",
      "Loss: tensor(0.1260, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 97\n",
      "Loss: tensor(0.1260, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 98\n",
      "Loss: tensor(0.1260, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 99\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor(0.1260, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 100\n",
      "Loss: tensor(0.1260, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 101\n",
      "Loss: tensor(0.1260, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 102\n",
      "Loss: tensor(0.1260, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 103\n",
      "Loss: tensor(0.1260, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 104\n",
      "Loss: tensor(0.1260, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 105\n",
      "Loss: tensor(0.1260, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 106\n",
      "Loss: tensor(0.1260, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 107\n",
      "Loss: tensor(0.1260, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 108\n",
      "Loss: tensor(0.1260, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 109\n",
      "Loss: tensor(0.1260, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 110\n",
      "Loss: tensor(0.1260, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 111\n",
      "Loss: tensor(0.1260, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 112\n",
      "Loss: tensor(0.1260, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 113\n",
      "Loss: tensor(0.1260, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 114\n",
      "Loss: tensor(0.1260, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 115\n",
      "Loss: tensor(0.1260, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 116\n",
      "Loss: tensor(0.1260, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 117\n",
      "Loss: tensor(0.1260, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 118\n",
      "Loss: tensor(0.1260, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 119\n",
      "Loss: tensor(0.1260, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 120\n",
      "Loss: tensor(0.1260, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 121\n",
      "Loss: tensor(0.1260, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 122\n",
      "Loss: tensor(0.1260, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 123\n",
      "Loss: tensor(0.1260, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 124\n",
      "Loss: tensor(0.1260, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 125\n",
      "Loss: tensor(0.1260, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 126\n",
      "Loss: tensor(0.1260, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 127\n",
      "Loss: tensor(0.1260, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 128\n",
      "Loss: tensor(0.1260, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 129\n",
      "Loss: tensor(0.1260, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 130\n",
      "Loss: tensor(0.1260, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 131\n",
      "Loss: tensor(0.1260, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 132\n",
      "Loss: tensor(0.1260, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 133\n",
      "Loss: tensor(0.1260, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 134\n",
      "Loss: tensor(0.1260, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 135\n",
      "Loss: tensor(0.1260, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 136\n",
      "Loss: tensor(0.1260, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 137\n",
      "Loss: tensor(0.1260, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 138\n",
      "Loss: tensor(0.1260, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 139\n",
      "Loss: tensor(0.1260, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 140\n",
      "Loss: tensor(0.1260, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 141\n",
      "Loss: tensor(0.1260, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 142\n",
      "Loss: tensor(0.1260, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 143\n",
      "Loss: tensor(0.1260, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 144\n",
      "Loss: tensor(0.1260, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 145\n",
      "Loss: tensor(0.1260, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 146\n",
      "Loss: tensor(0.1260, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 147\n",
      "Loss: tensor(0.1260, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 148\n",
      "Loss: tensor(0.1260, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 149\n",
      "Loss: tensor(0.1260, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 150\n",
      "Loss: tensor(0.1260, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 151\n",
      "Loss: tensor(0.1260, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 152\n",
      "Loss: tensor(0.1260, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 153\n",
      "Loss: tensor(0.1260, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 154\n",
      "Loss: tensor(0.1260, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 155\n",
      "Loss: tensor(0.1260, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 156\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 157\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 158\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 159\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 160\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 161\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 162\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 163\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 164\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 165\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 166\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 167\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 168\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 169\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 170\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 171\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 172\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 173\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 174\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 175\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 176\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 177\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 178\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 179\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 180\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 181\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 182\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 183\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 184\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 185\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 186\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 187\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 188\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 189\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 190\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 191\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 192\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 193\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 194\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 195\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 196\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 197\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 198\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 199\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 200\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 201\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 202\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 203\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 204\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 205\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 206\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 207\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 208\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 209\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 210\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 211\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 212\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 213\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 214\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 215\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 216\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 217\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 218\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 219\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 220\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 221\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 222\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 223\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 224\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 225\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 226\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 227\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 228\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 229\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 230\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 231\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 232\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 233\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 234\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 235\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 236\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 237\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 238\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 239\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 240\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 241\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 242\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 243\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 244\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 245\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 246\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 247\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 248\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 249\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 250\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 251\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 252\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 253\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 254\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 255\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 256\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 257\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 258\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 259\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 260\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 261\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 262\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 263\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 264\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 265\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 266\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 267\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 268\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 269\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 270\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 271\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 272\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 273\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 274\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 275\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 276\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 277\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 278\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 279\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 280\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 281\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 282\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 283\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 284\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 285\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 286\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 287\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 288\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 289\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 290\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 291\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 292\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 293\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 294\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 295\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 296\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 297\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 298\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 299\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 300\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 301\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 302\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 303\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 304\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 305\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 306\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 307\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 308\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 309\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 310\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 311\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 312\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 313\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 314\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 315\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 316\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 317\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 318\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 319\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 320\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 321\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 322\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 323\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 324\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 325\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 326\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 327\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 328\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 329\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 330\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 331\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 332\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 333\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 334\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 335\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 336\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 337\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 338\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 339\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 340\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 341\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 342\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 343\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 344\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 345\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 346\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 347\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 348\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 349\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 350\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 351\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 352\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 353\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 354\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 355\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 356\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 357\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 358\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 359\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 360\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 361\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 362\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 363\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 364\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 365\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 366\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 367\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 368\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 369\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 370\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 371\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 372\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 373\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 374\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 375\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 376\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 377\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 378\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 379\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 380\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 381\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 382\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 383\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 384\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 385\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 386\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 387\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 388\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 389\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 390\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 391\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 392\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 393\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 394\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 395\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 396\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 397\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 398\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 399\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 400\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 401\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 402\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 403\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 404\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 405\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 406\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 407\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 408\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 409\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 410\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 411\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 412\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 413\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 414\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 415\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 416\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 417\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 418\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 419\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 420\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 421\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 422\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 423\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 424\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 425\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 426\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 427\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 428\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 429\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 430\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 431\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 432\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 433\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 434\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 435\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 436\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 437\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 438\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 439\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 440\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 441\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 442\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 443\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 444\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 445\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 446\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 447\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 448\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 449\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 450\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 451\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 452\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 453\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 454\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 455\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 456\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 457\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 458\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 459\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 460\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 461\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 462\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 463\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 464\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 465\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 466\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 467\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 468\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 469\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 470\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 471\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 472\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 473\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 474\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 475\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 476\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 477\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 478\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 479\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 480\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 481\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 482\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 483\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 484\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 485\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 486\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 487\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 488\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 489\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 490\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 491\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 492\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 493\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 494\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 495\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 496\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 497\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 498\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 499\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 501\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 502\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 503\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 504\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 505\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 506\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 507\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 508\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 509\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 510\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 511\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 512\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 513\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 514\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 515\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 516\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 517\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 518\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 519\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 520\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 521\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 522\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 523\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 524\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 525\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 526\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 527\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 528\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 529\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 530\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 531\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 532\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 533\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 534\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 535\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 536\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 537\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 538\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 539\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 540\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 541\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 542\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 543\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 544\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 545\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 546\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 547\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 548\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 549\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 550\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 551\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 552\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 553\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 554\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 555\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 556\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 557\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 558\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 559\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 560\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 561\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 562\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 563\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 564\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 565\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 566\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 567\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 568\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 569\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 570\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 571\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 572\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 573\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 574\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 575\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 576\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 577\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 578\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 579\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 580\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 581\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 582\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 583\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 584\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 585\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 586\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 587\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 588\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 589\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 590\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 591\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 592\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 593\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 594\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 595\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 596\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 597\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 598\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 599\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 601\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 602\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 603\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 604\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 605\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 606\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 607\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 608\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 609\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 610\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 611\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 612\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 613\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 614\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 615\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 616\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 617\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 618\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 619\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 620\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 621\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 622\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 623\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 624\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 625\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 626\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 627\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 628\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 629\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 630\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 631\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 632\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 633\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 634\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 635\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 636\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 637\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 638\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 639\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 640\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 641\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 642\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 643\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 644\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 645\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 646\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 647\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 648\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 649\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 650\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 651\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 652\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 653\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 654\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 655\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 656\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 657\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 658\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 659\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 660\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 661\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 662\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 663\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 664\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 665\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 666\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 667\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 668\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 669\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 670\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 671\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 672\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 673\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 674\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 675\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 676\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 677\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 678\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 679\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 680\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 681\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 682\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 683\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 684\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 685\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 686\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 687\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 688\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 689\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 690\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 691\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 692\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 693\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 694\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 695\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 696\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 697\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 698\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 699\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 701\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 702\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 703\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 704\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 705\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 706\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 707\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 708\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 709\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 710\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 711\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 712\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 713\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 714\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 715\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 716\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 717\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 718\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 719\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 720\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 721\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 722\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 723\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 724\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 725\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 726\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 727\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 728\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 729\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 730\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 731\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 732\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 733\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 734\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 735\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 736\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 737\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 738\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 739\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 740\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 741\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 742\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 743\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 744\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 745\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 746\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 747\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 748\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 749\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 750\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 751\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 752\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 753\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 754\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 755\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 756\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 757\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 758\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 759\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 760\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 761\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 762\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 763\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 764\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 765\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 766\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 767\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 768\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 769\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 770\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 771\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 772\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 773\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 774\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 775\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 776\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 777\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 778\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 779\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 780\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 781\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 782\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 783\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 784\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 785\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 786\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 787\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 788\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 789\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 790\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 791\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 792\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 793\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 794\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 795\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 796\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 797\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 798\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 799\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 800\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 801\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 802\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 803\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 804\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 805\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 806\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 807\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 808\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 809\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 810\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 811\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 812\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 813\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 814\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 815\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 816\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 817\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 818\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 819\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 820\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 821\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 822\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 823\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 824\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 825\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 826\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 827\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 828\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 829\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 830\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 831\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 832\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 833\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 834\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 835\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 836\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 837\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 838\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 839\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 840\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 841\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 842\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 843\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 844\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 845\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 846\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 847\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 848\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 849\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 850\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 851\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 852\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 853\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 854\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 855\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 856\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 857\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 858\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 859\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 860\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 861\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 862\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 863\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 864\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 865\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 866\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 867\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 868\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 869\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 870\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 871\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 872\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 873\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 874\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 875\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 876\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 877\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 878\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 879\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 880\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 881\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 882\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 883\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 884\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 885\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 886\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 887\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 888\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 889\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 890\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 891\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 892\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 893\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 894\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 895\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 896\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 897\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 898\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 899\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 900\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 901\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 902\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 903\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 904\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 905\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 906\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 907\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 908\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 909\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 910\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 911\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 912\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 913\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 914\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 915\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 916\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 917\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 918\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 919\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 920\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 921\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 922\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 923\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 924\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 925\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 926\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 927\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 928\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 929\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 930\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 931\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 932\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 933\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 934\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 935\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 936\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 937\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 938\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 939\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 940\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 941\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 942\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 943\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 944\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 945\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 946\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 947\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 948\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 949\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 950\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 951\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 952\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 953\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 954\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 955\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 956\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 957\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 958\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 959\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 960\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 961\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 962\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 963\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 964\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 965\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 966\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 967\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 968\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 969\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 970\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 971\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 972\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 973\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 974\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 975\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 976\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 977\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 978\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 979\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 980\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 981\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 982\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 983\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 984\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 985\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 986\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 987\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 988\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 989\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 990\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 991\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 992\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 993\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 994\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 995\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 996\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 997\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 998\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 999\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1000\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1001\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1002\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1003\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1004\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1005\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1006\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1007\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1008\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1009\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1010\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1011\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1012\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1013\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1014\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1015\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1016\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1017\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1018\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1019\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1020\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1021\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1022\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1023\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1024\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1025\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1026\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1027\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1028\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1029\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1030\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1031\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1032\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1033\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1034\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1035\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1036\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1037\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1038\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1039\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1040\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1041\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1042\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1043\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1044\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1045\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1046\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1047\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1048\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1049\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1050\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1051\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1052\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1053\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1054\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1055\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1056\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1057\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1058\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1059\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1060\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1061\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1062\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1063\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1064\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1065\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1066\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1067\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1068\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1069\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1070\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1071\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1072\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1073\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1074\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1075\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1076\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1077\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1078\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1079\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1080\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1081\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1082\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1083\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1084\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1085\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1086\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1087\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1088\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1089\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1090\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1091\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1092\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1093\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1094\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1095\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1096\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1097\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1098\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1099\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1100\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1101\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1102\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1103\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1104\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1105\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1106\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1107\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1108\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1109\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1110\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1111\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1112\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1113\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1114\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1115\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1116\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1117\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1118\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1119\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1120\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1121\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1122\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1123\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1124\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1125\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1126\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1127\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1128\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1129\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1130\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1131\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1132\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1133\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1134\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1135\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1136\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1137\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1138\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1139\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1140\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1141\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1142\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1143\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1144\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1145\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1146\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1147\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1148\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1149\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1150\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1151\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1152\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1153\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1154\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1155\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1156\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1157\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1158\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1159\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1160\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1161\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1162\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1163\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1164\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1165\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1166\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1167\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1168\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1169\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1170\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1171\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1172\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1173\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1174\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1175\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1176\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1177\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1178\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1179\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1180\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1181\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1182\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1183\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1184\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1185\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1186\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1187\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1188\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1189\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1190\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1191\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1192\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1193\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1194\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1195\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1196\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1197\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1198\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1199\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1200\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1201\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1202\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1203\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1204\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1205\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1206\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1207\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1208\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1209\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1210\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1211\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1212\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1213\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1214\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1215\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1216\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1217\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1218\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1219\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1220\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1221\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1222\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1223\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1224\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1225\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1226\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1227\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1228\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1229\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1230\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1231\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1232\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1233\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1234\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1235\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1236\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1237\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1238\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1239\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1240\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1241\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1242\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1243\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1244\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1245\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1246\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1247\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1248\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1249\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1250\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1251\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1252\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1253\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1254\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1255\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1256\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1257\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1258\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1259\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1260\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1261\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1262\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1263\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1264\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1265\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1266\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1267\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1268\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1269\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1270\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1271\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1272\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1273\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1274\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1275\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1276\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1277\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1278\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1279\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1280\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1281\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1282\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1283\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1284\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1285\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1286\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1287\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1288\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1289\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1290\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1291\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1292\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1293\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1294\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1295\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1296\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1297\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1298\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1299\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1300\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1301\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1302\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1303\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1304\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1305\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1306\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1307\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1308\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1309\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1310\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1311\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1312\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1313\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1314\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1315\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1316\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1317\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1318\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1319\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1320\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1321\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1322\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1323\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1324\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1325\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1326\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1327\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1328\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1329\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1330\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1331\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1332\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1333\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1334\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1335\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1336\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1337\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1338\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1339\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1340\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1341\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1342\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1343\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1344\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1345\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1346\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1347\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1348\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1349\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1350\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1351\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1352\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1353\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1354\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1355\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1356\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1357\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1358\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1359\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1360\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1361\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1362\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1363\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1364\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1365\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1366\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1367\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1368\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1369\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1370\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1371\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1372\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1373\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1374\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1375\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1376\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1377\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1378\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1379\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1380\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1381\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1382\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1383\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1384\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1385\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1386\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1387\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1388\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1389\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1390\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1391\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1392\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1393\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1394\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1395\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1396\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1397\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1398\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1399\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1400\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1401\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1402\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1403\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1404\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1405\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1406\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1407\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1408\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1409\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1410\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1411\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1412\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1413\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1414\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1415\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1416\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1417\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1418\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1419\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1420\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1421\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1422\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1423\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1424\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1425\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1426\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1427\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1428\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1429\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1430\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1431\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1432\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1433\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1434\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1435\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1436\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1437\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1438\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1439\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1440\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1441\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1442\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1443\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1444\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1445\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1446\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1447\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1448\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1449\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1450\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1451\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1452\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1453\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1454\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1455\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1456\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1457\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1458\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1459\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1460\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1461\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1462\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1463\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1464\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1465\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1466\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1467\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1468\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1469\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1470\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1471\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1472\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1473\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1474\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1475\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1476\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1477\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1478\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1479\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1480\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1481\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1482\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1483\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1484\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1485\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1486\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1487\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1488\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1489\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1490\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1491\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1492\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1493\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1494\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1495\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1496\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1497\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1498\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1499\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1500\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1501\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1502\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1503\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1504\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1505\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1506\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1507\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1508\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1509\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1510\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1511\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1512\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1513\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1514\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1515\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1516\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1517\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1518\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1519\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1520\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1521\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1522\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1523\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1524\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1525\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1526\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1527\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1528\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1529\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1530\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1531\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1532\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1533\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1534\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1535\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1536\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1537\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1538\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1539\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1540\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1541\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1542\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1543\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1544\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1545\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1546\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1547\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1548\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1549\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1550\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1551\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1552\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1553\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1554\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1555\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1556\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1557\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1558\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1559\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1560\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1561\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1562\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1563\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1564\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1565\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1566\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1567\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1568\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1569\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1570\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1571\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1572\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1573\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1574\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1575\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1576\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1577\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1578\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1579\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1580\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1581\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1582\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1583\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1584\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1585\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1586\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1587\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1588\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1589\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1590\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1591\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1592\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1593\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1594\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1595\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1596\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1597\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1598\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1599\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1600\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1601\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1602\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1603\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1604\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1605\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1606\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1607\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1608\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1609\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1610\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1611\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1612\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1613\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1614\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1615\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1616\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1617\n",
      "Loss: tensor(0.1259, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1618\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1619\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1620\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1621\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1622\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1623\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1624\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1625\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1626\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1627\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1628\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1629\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1630\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1631\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1632\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1633\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1634\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1635\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1636\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1637\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1638\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1639\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1640\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1641\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1642\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1643\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1644\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1645\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1646\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1647\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1648\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1649\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1650\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1651\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1652\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1653\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1654\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1655\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1656\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1657\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1658\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1659\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1660\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1661\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1662\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1663\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1664\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1665\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1666\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1667\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1668\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1669\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1670\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1671\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1672\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1673\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1674\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1675\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1676\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1677\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1678\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1679\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1680\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1681\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1682\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1683\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1684\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1685\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1686\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1687\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1688\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1689\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1690\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1691\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1692\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1693\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1694\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1695\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1696\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1697\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1698\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1699\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1700\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1701\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1702\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1703\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1704\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1705\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1706\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1707\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1708\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1709\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1710\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1711\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1712\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1713\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1714\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1715\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1716\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1717\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1718\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1719\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1720\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1721\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1722\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1723\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1724\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1725\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1726\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1727\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1728\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1729\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1730\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1731\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1732\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1733\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1734\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1735\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1736\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1737\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1738\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1739\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1740\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1741\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1742\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1743\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1744\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1745\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1746\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1747\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1748\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1749\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1750\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1751\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1752\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1753\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1754\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1755\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1756\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1757\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1758\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1759\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1760\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1761\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1762\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1763\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1764\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1765\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1766\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1767\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1768\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1769\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1770\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1771\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1772\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1773\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1774\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1775\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1776\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1777\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1778\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1779\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1780\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1781\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1782\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1783\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1784\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1785\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1786\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1787\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1788\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1789\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1790\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1791\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1792\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1793\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1794\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1795\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1796\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1797\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1798\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1799\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1800\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1801\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1802\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1803\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1804\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1805\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1806\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1807\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1808\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1809\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1810\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1811\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1812\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1813\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1814\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1815\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1816\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1817\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1818\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1819\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1820\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1821\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1822\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1823\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1824\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1825\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1826\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1827\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1828\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1829\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1830\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1831\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1832\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1833\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1834\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1835\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1836\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1837\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1838\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1839\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1840\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1841\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1842\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1843\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1844\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1845\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1846\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1847\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1848\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1849\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1850\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1851\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1852\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1853\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1854\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1855\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1856\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1857\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1858\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1859\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1860\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1861\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1862\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1863\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1864\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1865\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1866\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1867\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1868\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1869\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1870\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1871\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1872\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1873\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1874\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1875\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1876\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1877\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1878\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1879\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1880\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1881\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1882\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1883\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1884\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1885\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1886\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1887\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1888\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1889\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1890\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1891\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1892\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1893\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1894\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1895\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1896\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1897\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1898\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1899\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1900\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1901\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1902\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1903\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1904\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1905\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1906\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1907\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1908\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1909\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1910\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1911\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1912\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1913\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1914\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1915\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1916\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1917\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1918\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1919\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1920\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1921\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1922\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1923\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1924\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1925\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1926\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1927\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1928\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1929\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1930\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1931\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1932\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1933\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1934\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1935\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1936\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1937\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1938\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1939\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1940\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1941\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1942\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1943\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1944\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1945\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1946\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1947\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1948\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1949\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1950\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1951\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1952\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1953\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1954\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1955\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1956\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1957\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1958\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1959\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1960\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1961\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1962\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1963\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1964\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1965\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1966\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1967\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1968\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1969\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1970\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1971\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1972\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1973\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1974\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1975\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1976\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1977\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1978\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1979\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1980\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1981\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1982\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1983\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1984\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1985\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1986\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1987\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1988\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1989\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1990\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1991\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1992\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1993\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1994\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1995\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1996\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1997\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1998\n",
      "Loss: tensor(0.1258, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1999\n"
     ]
    }
   ],
   "source": [
    "# next step is to apply this in epochs \n",
    "for epoch in range(2000):  \n",
    "\n",
    "        \n",
    "    optimizer.zero_grad()   # zero the gradient buffers\n",
    "    output = net(input.float())\n",
    "\n",
    "    loss = criterion(output, targets)\n",
    "    print('Loss:', loss, ' at epoch:', epoch)\n",
    "\n",
    "    loss.backward()  #backprop\n",
    "    optimizer.step()    # Does the update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  1.,   0.,   0.,   0.,   0.,   0.],\n",
       "        [ 19.,  32.,  34.,  58.,  33.,  33.],\n",
       "        [  1.,   2.,   1.,   3.,   8.,   2.],\n",
       "        ...,\n",
       "        [  7.,  23.,  28.,  38.,  34.,  15.],\n",
       "        [ 61., 114.,  63.,  51.,  37.,  14.],\n",
       "        [  0.,   1.,   0.,   0.,   0.,   0.]], dtype=torch.float64)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we import the training set \n",
    "train2=pd.read_excel('trainReputation.xlsx' )\n",
    "train2=train2.iloc[:,:-2].astype(float)\n",
    "train2\n",
    "input2=torch.tensor(train2.values)\n",
    "input2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 1., 0., 0.],\n",
       "        [0., 0., 0., 0., 1., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0., 0., 0.],\n",
       "        [0., 1., 0., 0., 0., 0.]], dtype=torch.float64)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#we import the one hot encoded labels\n",
    "TrainLables2=pd.read_excel('trainReputation.xlsx' )\n",
    "TrainLables2=TrainLables2.iloc[:,-1] \n",
    " \n",
    "\n",
    "TrainLables2=pd.get_dummies(TrainLables2)\n",
    "\n",
    "targets2=torch.tensor(TrainLables2.astype(float).values)\n",
    "targets2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10269, 6])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input2.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10269, 6])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets2.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor(0.0989, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 0\n",
      "Loss: tensor(0.0988, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 1\n",
      "Loss: tensor(0.0987, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 2\n",
      "Loss: tensor(0.0986, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 3\n",
      "Loss: tensor(0.0986, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 4\n",
      "Loss: tensor(0.0985, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 5\n",
      "Loss: tensor(0.0985, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 6\n",
      "Loss: tensor(0.0984, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 7\n",
      "Loss: tensor(0.0984, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 8\n",
      "Loss: tensor(0.0984, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 9\n",
      "Loss: tensor(0.0983, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 10\n",
      "Loss: tensor(0.0983, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 11\n",
      "Loss: tensor(0.0983, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 12\n",
      "Loss: tensor(0.0983, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 13\n",
      "Loss: tensor(0.0982, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 14\n",
      "Loss: tensor(0.0982, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 15\n",
      "Loss: tensor(0.0982, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 16\n",
      "Loss: tensor(0.0982, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 17\n",
      "Loss: tensor(0.0982, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 18\n",
      "Loss: tensor(0.0982, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 19\n",
      "Loss: tensor(0.0981, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 20\n",
      "Loss: tensor(0.0981, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 21\n",
      "Loss: tensor(0.0981, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 22\n",
      "Loss: tensor(0.0981, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 23\n",
      "Loss: tensor(0.0981, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 24\n",
      "Loss: tensor(0.0981, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 25\n",
      "Loss: tensor(0.0981, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 26\n",
      "Loss: tensor(0.0981, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 27\n",
      "Loss: tensor(0.0981, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 28\n",
      "Loss: tensor(0.0981, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 29\n",
      "Loss: tensor(0.0980, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 30\n",
      "Loss: tensor(0.0980, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 31\n",
      "Loss: tensor(0.0980, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 32\n",
      "Loss: tensor(0.0980, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 33\n",
      "Loss: tensor(0.0980, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 34\n",
      "Loss: tensor(0.0980, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 35\n",
      "Loss: tensor(0.0980, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 36\n",
      "Loss: tensor(0.0980, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 37\n",
      "Loss: tensor(0.0980, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 38\n",
      "Loss: tensor(0.0980, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 39\n",
      "Loss: tensor(0.0980, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 40\n",
      "Loss: tensor(0.0980, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 41\n",
      "Loss: tensor(0.0980, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 42\n",
      "Loss: tensor(0.0980, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 43\n",
      "Loss: tensor(0.0980, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 44\n",
      "Loss: tensor(0.0980, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 45\n",
      "Loss: tensor(0.0980, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 46\n",
      "Loss: tensor(0.0979, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 47\n",
      "Loss: tensor(0.0979, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 48\n",
      "Loss: tensor(0.0979, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 49\n",
      "Loss: tensor(0.0979, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 50\n",
      "Loss: tensor(0.0979, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 51\n",
      "Loss: tensor(0.0979, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 52\n",
      "Loss: tensor(0.0979, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 53\n",
      "Loss: tensor(0.0979, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 54\n",
      "Loss: tensor(0.0979, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 55\n",
      "Loss: tensor(0.0979, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 56\n",
      "Loss: tensor(0.0979, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 57\n",
      "Loss: tensor(0.0979, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 58\n",
      "Loss: tensor(0.0979, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 59\n",
      "Loss: tensor(0.0979, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 60\n",
      "Loss: tensor(0.0979, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 61\n",
      "Loss: tensor(0.0979, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 62\n",
      "Loss: tensor(0.0979, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 63\n",
      "Loss: tensor(0.0979, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 64\n",
      "Loss: tensor(0.0979, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 65\n",
      "Loss: tensor(0.0979, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 66\n",
      "Loss: tensor(0.0979, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 67\n",
      "Loss: tensor(0.0979, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 68\n",
      "Loss: tensor(0.0979, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 69\n",
      "Loss: tensor(0.0979, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 70\n",
      "Loss: tensor(0.0979, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 71\n",
      "Loss: tensor(0.0979, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 72\n",
      "Loss: tensor(0.0979, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 73\n",
      "Loss: tensor(0.0979, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 74\n",
      "Loss: tensor(0.0978, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 75\n",
      "Loss: tensor(0.0978, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 76\n",
      "Loss: tensor(0.0978, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 77\n",
      "Loss: tensor(0.0978, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 78\n",
      "Loss: tensor(0.0978, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 79\n",
      "Loss: tensor(0.0978, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 80\n",
      "Loss: tensor(0.0978, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 81\n",
      "Loss: tensor(0.0978, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 82\n",
      "Loss: tensor(0.0978, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 83\n",
      "Loss: tensor(0.0978, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 84\n",
      "Loss: tensor(0.0978, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 85\n",
      "Loss: tensor(0.0978, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 86\n",
      "Loss: tensor(0.0978, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 87\n",
      "Loss: tensor(0.0978, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 88\n",
      "Loss: tensor(0.0978, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 89\n",
      "Loss: tensor(0.0978, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 90\n",
      "Loss: tensor(0.0978, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 91\n",
      "Loss: tensor(0.0978, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 92\n",
      "Loss: tensor(0.0978, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 93\n",
      "Loss: tensor(0.0978, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 94\n",
      "Loss: tensor(0.0978, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 95\n",
      "Loss: tensor(0.0978, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 96\n",
      "Loss: tensor(0.0978, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 97\n",
      "Loss: tensor(0.0978, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 98\n",
      "Loss: tensor(0.0978, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 99\n",
      "Loss: tensor(0.0978, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 100\n",
      "Loss: tensor(0.0978, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 101\n",
      "Loss: tensor(0.0978, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 102\n",
      "Loss: tensor(0.0978, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 103\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor(0.0978, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 104\n",
      "Loss: tensor(0.0978, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 105\n",
      "Loss: tensor(0.0978, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 106\n",
      "Loss: tensor(0.0978, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 107\n",
      "Loss: tensor(0.0978, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 108\n",
      "Loss: tensor(0.0978, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 109\n",
      "Loss: tensor(0.0978, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 110\n",
      "Loss: tensor(0.0978, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 111\n",
      "Loss: tensor(0.0978, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 112\n",
      "Loss: tensor(0.0978, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 113\n",
      "Loss: tensor(0.0978, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 114\n",
      "Loss: tensor(0.0978, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 115\n",
      "Loss: tensor(0.0978, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 116\n",
      "Loss: tensor(0.0978, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 117\n",
      "Loss: tensor(0.0978, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 118\n",
      "Loss: tensor(0.0978, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 119\n",
      "Loss: tensor(0.0978, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 120\n",
      "Loss: tensor(0.0978, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 121\n",
      "Loss: tensor(0.0978, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 122\n",
      "Loss: tensor(0.0977, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 123\n",
      "Loss: tensor(0.0977, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 124\n",
      "Loss: tensor(0.0977, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 125\n",
      "Loss: tensor(0.0977, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 126\n",
      "Loss: tensor(0.0977, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 127\n",
      "Loss: tensor(0.0977, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 128\n",
      "Loss: tensor(0.0977, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 129\n",
      "Loss: tensor(0.0977, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 130\n",
      "Loss: tensor(0.0977, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 131\n",
      "Loss: tensor(0.0977, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 132\n",
      "Loss: tensor(0.0977, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 133\n",
      "Loss: tensor(0.0977, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 134\n",
      "Loss: tensor(0.0977, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 135\n",
      "Loss: tensor(0.0977, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 136\n",
      "Loss: tensor(0.0977, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 137\n",
      "Loss: tensor(0.0977, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 138\n",
      "Loss: tensor(0.0977, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 139\n",
      "Loss: tensor(0.0977, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 140\n",
      "Loss: tensor(0.0977, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 141\n",
      "Loss: tensor(0.0977, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 142\n",
      "Loss: tensor(0.0977, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 143\n",
      "Loss: tensor(0.0977, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 144\n",
      "Loss: tensor(0.0977, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 145\n",
      "Loss: tensor(0.0977, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 146\n",
      "Loss: tensor(0.0977, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 147\n",
      "Loss: tensor(0.0977, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 148\n",
      "Loss: tensor(0.0977, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 149\n",
      "Loss: tensor(0.0977, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 150\n",
      "Loss: tensor(0.0977, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 151\n",
      "Loss: tensor(0.0977, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 152\n",
      "Loss: tensor(0.0977, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 153\n",
      "Loss: tensor(0.0977, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 154\n",
      "Loss: tensor(0.0977, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 155\n",
      "Loss: tensor(0.0977, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 156\n",
      "Loss: tensor(0.0977, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 157\n",
      "Loss: tensor(0.0977, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 158\n",
      "Loss: tensor(0.0977, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 159\n",
      "Loss: tensor(0.0977, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 160\n",
      "Loss: tensor(0.0977, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 161\n",
      "Loss: tensor(0.0977, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 162\n",
      "Loss: tensor(0.0977, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 163\n",
      "Loss: tensor(0.0977, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 164\n",
      "Loss: tensor(0.0977, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 165\n",
      "Loss: tensor(0.0977, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 166\n",
      "Loss: tensor(0.0977, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 167\n",
      "Loss: tensor(0.0977, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 168\n",
      "Loss: tensor(0.0977, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 169\n",
      "Loss: tensor(0.0977, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 170\n",
      "Loss: tensor(0.0977, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 171\n",
      "Loss: tensor(0.0977, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 172\n",
      "Loss: tensor(0.0977, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 173\n",
      "Loss: tensor(0.0977, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 174\n",
      "Loss: tensor(0.0977, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 175\n",
      "Loss: tensor(0.0977, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 176\n",
      "Loss: tensor(0.0977, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 177\n",
      "Loss: tensor(0.0977, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 178\n",
      "Loss: tensor(0.0977, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 179\n",
      "Loss: tensor(0.0977, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 180\n",
      "Loss: tensor(0.0977, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 181\n",
      "Loss: tensor(0.0977, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 182\n",
      "Loss: tensor(0.0977, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 183\n",
      "Loss: tensor(0.0977, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 184\n",
      "Loss: tensor(0.0977, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 185\n",
      "Loss: tensor(0.0977, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 186\n",
      "Loss: tensor(0.0977, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 187\n",
      "Loss: tensor(0.0977, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 188\n",
      "Loss: tensor(0.0977, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 189\n",
      "Loss: tensor(0.0977, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 190\n",
      "Loss: tensor(0.0977, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 191\n",
      "Loss: tensor(0.0977, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 192\n",
      "Loss: tensor(0.0977, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 193\n",
      "Loss: tensor(0.0977, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 194\n",
      "Loss: tensor(0.0977, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 195\n",
      "Loss: tensor(0.0977, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 196\n",
      "Loss: tensor(0.0977, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 197\n",
      "Loss: tensor(0.0977, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 198\n",
      "Loss: tensor(0.0977, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 199\n",
      "Loss: tensor(0.0977, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 200\n",
      "Loss: tensor(0.0977, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 201\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor(0.0977, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 202\n",
      "Loss: tensor(0.0977, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 203\n",
      "Loss: tensor(0.0977, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 204\n",
      "Loss: tensor(0.0977, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 205\n",
      "Loss: tensor(0.0976, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 206\n",
      "Loss: tensor(0.0976, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 207\n",
      "Loss: tensor(0.0976, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 208\n",
      "Loss: tensor(0.0976, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 209\n",
      "Loss: tensor(0.0976, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 210\n",
      "Loss: tensor(0.0976, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 211\n",
      "Loss: tensor(0.0976, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 212\n",
      "Loss: tensor(0.0976, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 213\n",
      "Loss: tensor(0.0976, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 214\n",
      "Loss: tensor(0.0976, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 215\n",
      "Loss: tensor(0.0976, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 216\n",
      "Loss: tensor(0.0976, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 217\n",
      "Loss: tensor(0.0976, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 218\n",
      "Loss: tensor(0.0976, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 219\n",
      "Loss: tensor(0.0976, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 220\n",
      "Loss: tensor(0.0976, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 221\n",
      "Loss: tensor(0.0976, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 222\n",
      "Loss: tensor(0.0976, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 223\n",
      "Loss: tensor(0.0976, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 224\n",
      "Loss: tensor(0.0976, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 225\n",
      "Loss: tensor(0.0976, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 226\n",
      "Loss: tensor(0.0976, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 227\n",
      "Loss: tensor(0.0976, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 228\n",
      "Loss: tensor(0.0976, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 229\n",
      "Loss: tensor(0.0976, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 230\n",
      "Loss: tensor(0.0976, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 231\n",
      "Loss: tensor(0.0976, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 232\n",
      "Loss: tensor(0.0976, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 233\n",
      "Loss: tensor(0.0976, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 234\n",
      "Loss: tensor(0.0976, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 235\n",
      "Loss: tensor(0.0976, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 236\n",
      "Loss: tensor(0.0976, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 237\n",
      "Loss: tensor(0.0976, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 238\n",
      "Loss: tensor(0.0976, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 239\n",
      "Loss: tensor(0.0976, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 240\n",
      "Loss: tensor(0.0976, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 241\n",
      "Loss: tensor(0.0976, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 242\n",
      "Loss: tensor(0.0976, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 243\n",
      "Loss: tensor(0.0976, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 244\n",
      "Loss: tensor(0.0976, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 245\n",
      "Loss: tensor(0.0976, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 246\n",
      "Loss: tensor(0.0976, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 247\n",
      "Loss: tensor(0.0976, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 248\n",
      "Loss: tensor(0.0976, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 249\n",
      "Loss: tensor(0.0976, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 250\n",
      "Loss: tensor(0.0976, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 251\n",
      "Loss: tensor(0.0976, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 252\n",
      "Loss: tensor(0.0976, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 253\n",
      "Loss: tensor(0.0976, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 254\n",
      "Loss: tensor(0.0976, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 255\n",
      "Loss: tensor(0.0976, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 256\n",
      "Loss: tensor(0.0976, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 257\n",
      "Loss: tensor(0.0976, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 258\n",
      "Loss: tensor(0.0976, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 259\n",
      "Loss: tensor(0.0976, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 260\n",
      "Loss: tensor(0.0976, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 261\n",
      "Loss: tensor(0.0976, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 262\n",
      "Loss: tensor(0.0976, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 263\n",
      "Loss: tensor(0.0976, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 264\n",
      "Loss: tensor(0.0976, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 265\n",
      "Loss: tensor(0.0976, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 266\n",
      "Loss: tensor(0.0976, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 267\n",
      "Loss: tensor(0.0976, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 268\n",
      "Loss: tensor(0.0976, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 269\n",
      "Loss: tensor(0.0976, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 270\n",
      "Loss: tensor(0.0976, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 271\n",
      "Loss: tensor(0.0976, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 272\n",
      "Loss: tensor(0.0976, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 273\n",
      "Loss: tensor(0.0976, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 274\n",
      "Loss: tensor(0.0976, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 275\n",
      "Loss: tensor(0.0976, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 276\n",
      "Loss: tensor(0.0976, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 277\n",
      "Loss: tensor(0.0976, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 278\n",
      "Loss: tensor(0.0976, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 279\n",
      "Loss: tensor(0.0976, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 280\n",
      "Loss: tensor(0.0976, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 281\n",
      "Loss: tensor(0.0976, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 282\n",
      "Loss: tensor(0.0976, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 283\n",
      "Loss: tensor(0.0976, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 284\n",
      "Loss: tensor(0.0976, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 285\n",
      "Loss: tensor(0.0976, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 286\n",
      "Loss: tensor(0.0976, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 287\n",
      "Loss: tensor(0.0976, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 288\n",
      "Loss: tensor(0.0976, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 289\n",
      "Loss: tensor(0.0976, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 290\n",
      "Loss: tensor(0.0976, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 291\n",
      "Loss: tensor(0.0976, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 292\n",
      "Loss: tensor(0.0976, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 293\n",
      "Loss: tensor(0.0976, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 294\n",
      "Loss: tensor(0.0976, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 295\n",
      "Loss: tensor(0.0976, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 296\n",
      "Loss: tensor(0.0976, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 297\n",
      "Loss: tensor(0.0976, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 298\n",
      "Loss: tensor(0.0976, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 299\n",
      "Loss: tensor(0.0976, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 300\n",
      "Loss: tensor(0.0976, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 301\n",
      "Loss: tensor(0.0976, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 302\n",
      "Loss: tensor(0.0976, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 303\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor(0.0976, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 304\n",
      "Loss: tensor(0.0976, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 305\n",
      "Loss: tensor(0.0976, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 306\n",
      "Loss: tensor(0.0976, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 307\n",
      "Loss: tensor(0.0976, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 308\n",
      "Loss: tensor(0.0976, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 309\n",
      "Loss: tensor(0.0976, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 310\n",
      "Loss: tensor(0.0976, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 311\n",
      "Loss: tensor(0.0976, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 312\n",
      "Loss: tensor(0.0976, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 313\n",
      "Loss: tensor(0.0976, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 314\n",
      "Loss: tensor(0.0976, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 315\n",
      "Loss: tensor(0.0976, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 316\n",
      "Loss: tensor(0.0976, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 317\n",
      "Loss: tensor(0.0976, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 318\n",
      "Loss: tensor(0.0976, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 319\n",
      "Loss: tensor(0.0976, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 320\n",
      "Loss: tensor(0.0976, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 321\n",
      "Loss: tensor(0.0976, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 322\n",
      "Loss: tensor(0.0976, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 323\n",
      "Loss: tensor(0.0976, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 324\n",
      "Loss: tensor(0.0976, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 325\n",
      "Loss: tensor(0.0976, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 326\n",
      "Loss: tensor(0.0976, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 327\n",
      "Loss: tensor(0.0976, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 328\n",
      "Loss: tensor(0.0976, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 329\n",
      "Loss: tensor(0.0976, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 330\n",
      "Loss: tensor(0.0976, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 331\n",
      "Loss: tensor(0.0976, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 332\n",
      "Loss: tensor(0.0976, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 333\n",
      "Loss: tensor(0.0976, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 334\n",
      "Loss: tensor(0.0976, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 335\n",
      "Loss: tensor(0.0976, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 336\n",
      "Loss: tensor(0.0976, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 337\n",
      "Loss: tensor(0.0976, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 338\n",
      "Loss: tensor(0.0976, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 339\n",
      "Loss: tensor(0.0976, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 340\n",
      "Loss: tensor(0.0976, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 341\n",
      "Loss: tensor(0.0976, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 342\n",
      "Loss: tensor(0.0976, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 343\n",
      "Loss: tensor(0.0976, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 344\n",
      "Loss: tensor(0.0976, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 345\n",
      "Loss: tensor(0.0976, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 346\n",
      "Loss: tensor(0.0976, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 347\n",
      "Loss: tensor(0.0976, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 348\n",
      "Loss: tensor(0.0976, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 349\n",
      "Loss: tensor(0.0976, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 350\n",
      "Loss: tensor(0.0975, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 351\n",
      "Loss: tensor(0.0975, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 352\n",
      "Loss: tensor(0.0975, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 353\n",
      "Loss: tensor(0.0975, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 354\n",
      "Loss: tensor(0.0975, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 355\n",
      "Loss: tensor(0.0975, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 356\n",
      "Loss: tensor(0.0975, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 357\n",
      "Loss: tensor(0.0975, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 358\n",
      "Loss: tensor(0.0975, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 359\n",
      "Loss: tensor(0.0975, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 360\n",
      "Loss: tensor(0.0975, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 361\n",
      "Loss: tensor(0.0975, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 362\n",
      "Loss: tensor(0.0975, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 363\n",
      "Loss: tensor(0.0975, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 364\n",
      "Loss: tensor(0.0975, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 365\n",
      "Loss: tensor(0.0975, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 366\n",
      "Loss: tensor(0.0975, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 367\n",
      "Loss: tensor(0.0975, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 368\n",
      "Loss: tensor(0.0975, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 369\n",
      "Loss: tensor(0.0975, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 370\n",
      "Loss: tensor(0.0975, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 371\n",
      "Loss: tensor(0.0975, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 372\n",
      "Loss: tensor(0.0975, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 373\n",
      "Loss: tensor(0.0975, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 374\n",
      "Loss: tensor(0.0975, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 375\n",
      "Loss: tensor(0.0975, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 376\n",
      "Loss: tensor(0.0975, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 377\n",
      "Loss: tensor(0.0975, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 378\n",
      "Loss: tensor(0.0975, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 379\n",
      "Loss: tensor(0.0975, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 380\n",
      "Loss: tensor(0.0975, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 381\n",
      "Loss: tensor(0.0975, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 382\n",
      "Loss: tensor(0.0975, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 383\n",
      "Loss: tensor(0.0975, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 384\n",
      "Loss: tensor(0.0975, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 385\n",
      "Loss: tensor(0.0975, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 386\n",
      "Loss: tensor(0.0975, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 387\n",
      "Loss: tensor(0.0975, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 388\n",
      "Loss: tensor(0.0975, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 389\n",
      "Loss: tensor(0.0975, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 390\n",
      "Loss: tensor(0.0975, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 391\n",
      "Loss: tensor(0.0975, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 392\n",
      "Loss: tensor(0.0975, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 393\n",
      "Loss: tensor(0.0975, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 394\n",
      "Loss: tensor(0.0975, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 395\n",
      "Loss: tensor(0.0975, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 396\n",
      "Loss: tensor(0.0975, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 397\n",
      "Loss: tensor(0.0975, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 398\n",
      "Loss: tensor(0.0975, dtype=torch.float64, grad_fn=<MseLossBackward>)  at epoch: 399\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for epoch in range(400):  \n",
    "\n",
    "        \n",
    "    optimizer.zero_grad()   # zero the gradient buffers\n",
    "    output = net(input2.float())\n",
    "\n",
    "    loss = criterion(output, targets2)\n",
    "    print('Loss:', loss, ' at epoch:', epoch)\n",
    "\n",
    "    loss.backward()  #backprop\n",
    "    optimizer.step()    # Does the update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 1 5 4 2 4 1 4 5 3 3 3 4 3 1 4 4 4 2 2 2 1 4 4 4 2 4 4 2 4 2 2 2 1 2 5 4 1 1 1 1 4 4 1 1 1 1 3 4 3 4 4 1 3 2 1 4 1 4 4 4 4 4 4 1 4 1 4 3 1 4 1 1 4 1 1 1 5 1 2 4 4 1 3 3 5 2 1 2 1 1 4 1 1 1 4 4 4 1 5 2 1 4 3 4 2 4 1 1 4 4 5 1 1 3 4 1 4 4 4 4 4 2 1 0 0 0 0 0 0 1 1 3 5 5 1 3 2 5 1 5 5 5 1 5 5 5 1 4 4 4 4 3 5 5 2 4 1 3 3 2 3 4 4 4 4 4 3 5 4 4 5 4 4 1 4 3 1 1 3 1 4 4 1 4 4 4 3 3 5 5 5 1 4 2 1 3 4 2 5 3 5 3 3 5 5 5 1 4 5 4 3 3 3 3 4 4 4 3 3 3 1 3 3 5 2 3 5 3 1 1 4 3 2 4 3 3 4 3 4 1 4 2 4 2 4 3 4 3 4 3 4 1 4 2 2 5 5 4 5 3 3 3 1 5 3 4 3 1 1 1 1 1 1 1 3 5 5 1 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 5 5 3 3 3 1 1 2 2 2 3 4 1 5 4 2 4 5 5 1 5 3 4 3 4 3 4 5 1 2 2 1 5 4 4 2 4 1 1 5 5 5 1 5 5 4 5 5 5 5 5 4 4 3 5 4 1 2 1 5 5 5 5 4 1 3 4 1 3 4 5 1 4 5 2 4 4 3 3 2 2 4 3 5 1 1 3 1 3 5 3 5 4 1 5 4 4 4 5 5 4 1 1 4 1 4 4 5 3 5 5 4 3 3 1 1 4 4 4 4 2 2 5 2 4 4 4 3 4 5 4 5 5 3 3 3 3 1 4 1 1 1 4 4 4 2 3 3 4 1 3 1 5 4 1 4 1 4 4 3 3 3 3 3 4 3 3 5 1 3 4 4 4 1 1 1 3 3 1 5 5 5 1 1 1 3 3 1 3 1 1 1 3 5 3 3 4 3 5 3 4 3 4 5 1 3 4 3 3 3 3 4 1 1 4 4 5 4 0 4 3 1 2 5 4 4 2 5 3 0 4 5 5 2 4 5 4 4 0 0 5 5 5 3 0 4 4 4 5 4 1 0 5 5 4 4 0 4 4 5 1 4 5 4 1 1 5 4 5 5 1 4 5 3 5 3 3 3 3 3 3 3 3 3 3 4 3 2 3 4 5 3 4 3 4 1 3 5 4 3 1 4 5 5 5 1 4 4 4 5 5 5 4 1 4 4 4 4 1 1 4 4 4 4 1 5 4 3 1 4 4 1 5 5 1 3 5 3 5 3 5 5 2 5 2 5 0 4 3 5 5 1 5 3 4 3 4 5 4 3 3 4 2 3 1 4 1 4 3 1 4 5 1 1 4 4 3 1 0 4 3 1 2 2 2 2 0 1 2 0 3 1 4 1 1 3 4 3 3 5 2 2 2 2 3 1 4 5 3 4 4 2 4 3 4 4 4 0 1 3 3 4 2 4 2 1 2 2 3 2 0 2 2 2 1 3 3 2 1 1 1 1 4 4 5 4 4 5 5 5 5 4 5 5 5 5 5 4 4 4 4 2 3 4 1 1 5 3 3 4 3 4 4 4 4 3 4 3 3 1 4 4 5 4 1 3 4 3 4 3 3 5 3 3 4 3 3 3 4 3 3 4 3 4 3 4 4 4 4 3 5 4 3 3 3 3 4 2 3 1 4 3 1 3 3 4 4 2 1 2 3 2 4 1 4 3 4 4 3 4 1 4 4 2 1 3 1 1 1 1 4 4 1 3 4 3 1 3 1 5 3 1 3 4 1 4 1 1 1 4 1 1 4 1 4 4 4 3 4 4 3 1 4 3 3 4 3 4 1 1 4 2 3 2 2 3 3 4 4 1 3 4 2 4 4 4 2 4 2 4 4 4 4 4 1 3 3 3 1 4 1 4 4 4 4 1 4 3 4 1 4 2 2 2 3 2 2 4 2 3 4 3 3 3 3 3 3 2 3 3 4 4 2 2 2 4 1 4 2 2 2 2 1 3 4 4 1 4 2 2 1 4 4 3 1 1 4 1 2 4 4 4 4 4 1 4 4 4 4 4 1 4 3 1 4 4 4 4 4 4 4 4 4 1 4 1 4 2 4 4 2 1 4 1 4 4 1 2 1 4 4 4 3 5 1 5 3 3 4 1 3 4 4 3 5 3 3 3 3 3 1 3 3 3 3 1 1 1 1 3 4 5 3 1 1 1 1 3 4 3 2 1 1 4 1 1 4 2 1 3 2 1 4 3 4 2 1 1 1 2 1 4 4 1 1 1 2 4 3 4 4 1 2 1 2 2 2 1 4 3 3 4 4 1 4 4 5 1 4 4 5 4 4 3 3 4 3 4 3 1 3 3 4 1 4 3 1 1 3 1 5 3 3 3 3 1 3 1 3 3 4 1 1 1 3 1 1 3 1 3 3 4 3 3 4 4 1 4 1 3 5 1 4 4 3 1 3 1 3 3 5 3 3 3 4 1 4 4 4 3 3 3 1 5 3 4 4 5 5 4 4 3 3 3 4 3 3 3 1 4 1 4 3 1 4 5 5 1 1 3 3 3 3 5 5 4 3 5 5 4 5 1 3 3 3 5 3 5 5 5 5 1 1 3 5 5 3 5 3 3 3 5 4 5 4 3 5 3 1 3 3 3 1 3 3 4 4 5 3 3 3 4 3 4 5 3 3 4 5 3 5 4 1 1 3 4 2 4 4 1 3 1 1 3 1 1 3 1 3 3 3 1 3 5 3 3 1 5 3 3 3 3 1 3 1 3 3 3 3 3 1 3 1 4 4 5 4 1 1 1 3 1 4 3 3 5 1 3 5 3 4 3 5 4 3 5 3 3 1 1 1 2 2 2 5 2 4 3 3 2 3 3 2 1 3 1 1 4 0 0 4 0 4 4 4 1 4 2 2 2 2 4 4 2 1 0 3 3 3 3 2 4 3 4 2 3 2 2 2 1 2 4 0 0 2 2 1 1 3 2 1 4 1 1 0 4 4 1 0 1 1 4 1 1 4 1 1 4 1 1 1 2 2 1 1 1 1 1 2 1 1 2 3 0 0 4 3 1 4 1 1 1 1 1 2 3 3 1 2 4 0 5 5 5 5 5 5 5 5 5 5 3 3 4 3 4 4 4 4 4 4 4 5 4 4 4 4 4 3 4 4 4 1 4 3 3 4 1 4 4 4 4 4 4 3 1 1 1 4 4 1 5 3 5 1 1 1 1 1 1 1 4 3 3 4 4 4 4 3 4 3 4 4 4 3 4 3 4 3 3 4 3 3 4 4 4 4 4 4 4 4 4 4 4 4 5 4 5 2 5 5 3 3 2 3 3 4 5 5 4 5 3 3 3 5 5 3 5 4 5 3 3 5 4 5 3 5 3 2 4 3 3 2 3 3 3 3 5 3 2 2 2 2 4 5 3 3 4 3 5 5 5 4 5 4 5 5 2 2 5 5 4 4 4 4 4 5 4 4 4 4 4 4 5 5 5 5 5 5 5 5 5 5 5 5 5 5 2 4 4 4 4 4 4 3 2 3 4 3 4 2 4 2 2 2 2 4 4 2 2 2 2 2 4 4 4 4 4 4 4 4 3 3 4 3 2 2 2 2 2 2 2 2 2 2 3 3 3 2 3 3 2 4 3 4 4 4 4 4 4 4 4 4 4 4 4 4 1 1 4 5 5 4 4 1 5 4 4 1 3 3 4 3 3 3 3 3 1 3 3 3 4 3 3 3 4 5 5 3 4 5 5 4 5 4 4 4 4 4 3 4 3 4 5 4 5 4 4 3 3 4 5 3 4 4 5 3 3 3 3 3 3 3 3 3 3 5 3 3 3 1 4 4 4 4 4 1 4 1 4 4 4 4 1 1 4 4 1 1 4 4 4 5 4 1 1 3 3 3 3 3 3 3 4 3 1 1 4 4 4 4 2 1 4 1 1 4 4 2 4 2 2 4 4 1 1 4 1 4 1 1 4 4 4 1 2 1 2 2 2 1 1 4 2 3 4 2 4 1 1 2 2 2 1 4 2 1 2 4 2 2 1 1 1 4 2 2 2 1 1 1 4 3 4 1 1 1 1 1 1 1 3 1 2 2 1 1 1 4 2 2 1 1 1 1 4 4 4 4 1 2 1 2 1 2 4 1 2 1 2 1 1 1 3 3 1 3 3 1 1 1 3 1 1 1 1 3 4 3 3 4 3 3 3 4 1 4 1 1 1 1 1 5 5 5 5 5 1 5 1 5 5 1 5 5 1 5 5 1 1 5 1 1 1 5 5 1 1 1 1 1 5 5 2 5 2 1 1 5 5 2 5 1 1 2 1 1 2 5 1 2 2 5 1 2 2 2 2 2 1 1 2 1 2 5 1 1 1 1 1 1 5 1 1 5 1 1 2 5 5 5 5 5 5 5 5 4 1 1 5 1 4 4 4 4 4 4 5 4 1 4 4 4 4 4 4 4 4 5 4 4 4 4 5 4 4 4 1 4 1 1 1 1 4 4 1 1 4 1 1 5 1 1 1 1 4 4 5 4 5 5 5 4 4 4 5 5 5 1 4 5 5 5 1 1 3 1 3 3 3 3 3 3 3 5 3 5 1 1 1 5 5 5 1 3 5 3 3 3 5 1 5 1 5 5 1 5 5 5 1 1 5 1 5 5 3 3 1 3 1 3 3 3 1 3 3 3 3 3 5 5 3 3 5 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 5 1 1 1 5 1 1 1 1 1 1 1 5 1 1 1 5 1 1 1 1 5 5 5 1 5 5 5 1 5 5 5 5 1 1 5 1 1 5 1 1 1 1 5 5 5 1 1 1 1 5 1 1 1 1 1 5 5 5 5 5 5 1 1 1 1 1 1 5 1 1 1 5 5 5 5 5 5 5 5 5 3 5 5 3 3 3 3 3 3 3 3 3 3 1 5 3 1 1 1 1 1 1 3 3 3 3 1 3 1 3 3 3 3 3 4 4 5 4 5 4 4 4 5 4 4 4 1 1 4 5 1 4 5 4 4 4 4 5 4 4 5 4 4 5 1 3 5 3 3 3 4 3 4 3 3 4 3 5 1 5 3 5 5 3 4 5 5 1 5 1 1 4 1 1 1 1 5 1 5 1 1 5 5 1 1 5 5 1 1 1 1 1 1 1 1 1 4 3 1 1 1 5 5 5 5 5 4 3 3 1 3 3 3 3 5 5 5 5 5 4 5 1 4 4 4 4 4 4 1 4 5 1 3 5 4 3 4 4 1 5 3 4 1 1 5 3 4 4 1 1 5 1 1 5 5 1 1 5 3 3 5 4 4 1 1 1 1 1 1 4 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 4 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 4 1 4 1 1 4 4 1 4 4 1 4 1 1 4 1 4 4 4 1 4 4 4 4 1 1 1 1 1 1 1 4 4 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 1 1 1 1 0 1 0 1 0 1 0 1 0 1 1 1 1 1 1 1 1 0 0 1 1 1 0 1 0 0 0 1 1 0 0 1 1 0 0 0 3 3 3 3 3 3 3 3 5 3 1 3 5 5 3 1 5 3 5 5 3 5 1 1 5 3 1 1 1 3 1 1 1 5 1 1 1 1 1 5 3 1 1 5 5 5 5 1 1 5 5 1 5 1 1 5 3 5 3 5 5 3 5 3 3 5 3 5 5 5 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 2 2 2 3 3 3 2 2 2 2 2 2 3 2 2 3 2 2 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 1 3 1 3 2 3 4 4 2 4 5 4 4 5 3 4 4 2 4 2 4 4 4 4 2 1 4 5 2 1 1 5 2 5 2 5 4 3 5 1 2 5 1 5 1 1 2 5 2 3 1 1 2 5 1 2 4 1 4 5 4 1 5 1 2 2 2 2 3 2 5 5 2 2 3 5 4 1 5 5 1 2 2 4 1 1 5 1 2 4 5 4 3 3 3 4 2 2 3 3 3 2 3 3 2 2 2 2 3 3 3 3 2 2 3 2 3 1 3 1 1 2 2 3 3 2 2 2 3 2 3 3 2 2 3 3 3 2 2 3 2 3 2 3 3 3 3 3 3 4 4 4 2 4 2 4 4 4 4 5 3 5 5 2 2 2 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 1 1 1 1 1 1 1 1 3 3 3 3 3 1 3 1 1 1 3 1 3 1 1 1 1 1 1 1 1 1 1 1 1 1 1 3 3 3 3 1 3 3 1 3 3 3 3 3 3 3 3 3 3 1 3 3 3 3 3 1 2 2 2 2 2 2 2 2 2 2 2 2 2 4 2 2 2 2 2 2 2 4 4 4 4 2 4 4 4 2 2 4 2 4 2 4 4 4 4 2 4 2 4 2 4 2 2 4 4 4 2 2 4 2 2 2 2 2 4 4 4 4 4 4 4 4 4 4 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 4 4 4 4 5 5 4 4 5 5 5 5 5 4 5 5 5 4 4 4 4 5 5 5 4 4 4 5 5 4 5 5 4 5 5 5 4 5 4 4 5 4 5 5 5 4 5 5 5 4 4 4 5 5 4 4 4 4 5 4 4 4 4 4 4 4 5 4 5 4 5 4 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 2 2 2 2 2 2 2 2 5 5 5 5 5 5 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 5 5 2 5 2 2 5 5 5 5 5 2 5 2 2 5 2 2 2 2 5 5 5 5 5 5 2 2 5 2 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 4 4 4 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 4 4 3 4 3 3 3 4 3 4 4 3 4 4 4 4 4 4 4 4 4 4 4 4 3 4 4 4 4 4 4 4 4 4 4 4 4 4 4 3 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 3 3 3 3 3 3 3 0 0 0 0 3 0 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 0 3 3 0 3 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 3 3 0 0 0 0 3 0 0 0 3 0 3 3 3 3 0 0 3 3 3 3 3 0 3 3 3 3 0 3 0 3 0 0 3 3 3 3 0 0 0 3 0 3 3 0 0 3 0 3 3 3 3 3 3 3 3 0 0 0 0 0 0 0 0 3 0 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 Correct: 2150 out of: 6534\n",
      "Accuracy of the network : 32 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "predicted=0  #how many wer predicted correctly\n",
    " \n",
    "\n",
    "with torch.no_grad():\n",
    "    for row in range(len(train)):\n",
    "        outputs = net(input[row,:].float())\n",
    "        result=0\n",
    "        total+=1\n",
    "        if outputs[0]<outputs[1]:result=1\n",
    "        if outputs[result]<outputs[2]:result=2\n",
    "        if outputs[result]<outputs[3]:result=3\n",
    "        if outputs[result]<outputs[4]:result=4\n",
    "        if outputs[result]<outputs[5]:result=5\n",
    "        \n",
    "        if TrainLables.iloc[row,result]==1: correct+=1\n",
    "        \n",
    "        print(result, end=' ')\n",
    "    \n",
    " \n",
    "print('Correct:', correct, 'out of:', total )\n",
    "print('Accuracy of the network : %d %%' % (\n",
    "    100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the model\n",
    "\n",
    "\n",
    "\n",
    "PATH = './Sigmoid_linearMSE_adam_###.pth'\n",
    "torch.save(net.state_dict(), PATH)\n",
    "\n",
    "# more on saving pytorch networks: https://pytorch.org/docs/stable/notes/serialization.html\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load previously saved model \n",
    "\n",
    "PATH = './Sigmoid_linearMSE_adam_43.pth'\n",
    "net = Net()\n",
    "net.load_state_dict(torch.load(PATH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  4.,  10.,  11.,  21.,  16.,  13.],\n",
       "        [  2.,   6.,   6.,  11.,   5.,   4.],\n",
       "        [  9.,  71.,  70., 160., 163., 125.],\n",
       "        ...,\n",
       "        [  0.,   0.,   0.,   0.,   1.,   0.],\n",
       "        [  0.,  10.,   8.,  12.,   5.,   4.],\n",
       "        [  0.,   0.,   0.,   1.,   1.,   0.]], dtype=torch.float64)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EvalData=pd.read_excel('validReputation.xlsx' )\n",
    "EvalData=EvalData.iloc[:,:-2].astype(float)\n",
    "\n",
    "EvalData=torch.tensor(EvalData.values)\n",
    "EvalData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 1., 0., 0.],\n",
       "        [0., 0., 0., 1., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 1., 0., 0.]], dtype=torch.float64)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "EvalLabels=pd.read_excel('validReputation.xlsx' )\n",
    "EvalLables=EvalLabels.iloc[:,-1]\n",
    "EvalLables=pd.get_dummies(EvalLables)\n",
    "EvalLables=EvalLables.astype(float)\n",
    "EvalLables=torch.tensor(EvalLables.values) \n",
    "\n",
    "EvalLables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Tensor' object has no attribute 'iloc'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-78-8c192c34659c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     21\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m<\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m         \u001b[1;32mif\u001b[0m \u001b[0mEvalLables\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mrow\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mcorrect\u001b[0m\u001b[1;33m+=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m         \u001b[0mY\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Tensor' object has no attribute 'iloc'"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "countCorrect0=0\n",
    "countCorrect1=0\n",
    "count0=0\n",
    "count1=0\n",
    "\n",
    "Y=[]  #target\n",
    "Pred=[]  #predicted\n",
    "\n",
    "with torch.no_grad():\n",
    "    for row in range(len(EvalData)):\n",
    "        outputs = net(EvalData[row,:].float())\n",
    "        result=0\n",
    "        total+=1\n",
    "        if outputs[0]<outputs[1]:result=1\n",
    "        if outputs[result]<outputs[2]:result=2\n",
    "        if outputs[result]<outputs[3]:result=3\n",
    "        if outputs[result]<outputs[4]:result=4\n",
    "        if outputs[result]<outputs[5]:result=5\n",
    "        \n",
    "        if EvalLables.iloc[row,result]==1: correct+=1\n",
    "        \n",
    "        Y.append(result)\n",
    "        Pred.append(labels.iloc[row])\n",
    "        \n",
    "        print(result, end=' ')\n",
    "        \n",
    "       \n",
    "print('Correct:', correct, 'out of:', total )\n",
    "print('Accuracy of the network : %d %%' % ( 100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.,  2.,  1.,  3.,  8.,  2.],\n",
       "        [ 0.,  0.,  0.,  3.,  3.,  2.],\n",
       "        [ 4.,  5., 12.,  9.,  3.,  8.],\n",
       "        ...,\n",
       "        [ 2.,  1.,  5.,  6.,  1.,  1.],\n",
       "        [44., 19.,  7.,  3.,  5.,  3.],\n",
       "        [ 1., 12.,  2.,  8.,  3.,  1.]], dtype=torch.float64)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the test data\n",
    "\n",
    "TestData=pd.read_excel('testReputation.xlsx' )\n",
    "TestData=TestData.iloc[:,:-2].astype(float)\n",
    "TestData=torch.tensor(TestData.values)\n",
    "TestData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1278</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1279</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1280</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1281</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1282</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1283 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0  1  2  3  4  5\n",
       "0     0  0  0  0  1  0\n",
       "1     0  0  0  1  0  0\n",
       "2     0  1  0  0  0  0\n",
       "3     0  0  0  0  0  1\n",
       "4     0  0  0  0  0  1\n",
       "...  .. .. .. .. .. ..\n",
       "1278  0  1  0  0  0  0\n",
       "1279  0  0  0  0  1  0\n",
       "1280  0  0  1  0  0  0\n",
       "1281  1  0  0  0  0  0\n",
       "1282  0  1  0  0  0  0\n",
       "\n",
       "[1283 rows x 6 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels=pd.read_excel('testReputation.xlsx' )\n",
    "\n",
    "labels=labels.iloc[:,-1] \n",
    "labelsOneHot=pd.get_dummies(labels)\n",
    "labelsOneHot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0, 0, 0, 1, 0],\n",
       "        [0, 0, 0, 1, 0, 0],\n",
       "        [0, 1, 0, 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 1, 0, 0, 0],\n",
       "        [1, 0, 0, 0, 0, 0],\n",
       "        [0, 1, 0, 0, 0, 0]], dtype=torch.uint8)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TestLables =torch.tensor(labelsOneHot.values)\n",
    "TestLables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 3 2 1 1 1 3 4 1 4 4 3 4 5 3 3 1 3 1 4 4 4 3 1 1 4 1 3 3 4 4 1 0 4 4 1 4 4 4 4 1 1 4 1 4 4 4 4 4 4 4 1 1 3 1 4 2 2 4 1 1 1 4 4 1 4 3 3 5 4 1 5 1 1 1 1 1 1 4 4 1 1 1 4 1 1 4 4 1 4 4 4 3 1 1 4 4 1 3 1 4 0 4 3 3 1 1 3 1 3 1 4 3 3 1 3 0 4 1 2 3 4 4 3 1 4 1 4 3 3 3 3 0 1 1 0 0 1 2 1 4 3 3 3 4 4 4 3 4 3 0 3 1 3 5 1 4 5 1 3 3 1 4 4 1 5 4 3 3 1 3 3 5 5 3 3 3 4 0 2 1 4 4 1 1 3 1 1 1 3 5 5 5 0 1 3 2 3 3 1 1 4 5 3 5 3 3 5 1 3 3 4 3 3 4 1 3 3 3 1 1 1 4 1 1 5 2 2 2 0 5 1 0 1 1 4 4 0 4 2 2 1 2 4 4 1 2 3 3 3 0 4 3 5 3 3 5 0 4 1 3 1 1 2 0 3 1 3 4 0 3 4 1 2 3 2 5 1 1 5 2 1 5 5 5 5 3 3 5 0 4 5 1 4 3 1 4 5 1 3 1 5 3 3 5 3 2 5 3 1 1 4 1 4 3 5 5 3 3 3 3 1 5 4 3 0 5 1 5 4 1 4 3 3 0 1 1 3 3 2 4 1 3 1 3 5 2 5 5 2 2 0 4 1 4 1 1 3 1 2 1 1 1 1 1 0 3 5 3 1 0 1 5 5 4 3 4 5 3 1 3 1 3 4 5 3 3 3 3 5 4 3 5 1 2 1 3 5 3 4 4 3 0 1 4 5 2 4 1 3 4 2 4 3 2 1 1 5 3 2 5 4 4 1 2 3 4 5 4 3 5 1 1 5 2 5 1 1 4 1 5 5 1 1 3 1 3 1 2 3 1 3 1 1 4 3 4 3 1 1 5 1 1 4 4 4 1 3 1 3 3 4 1 0 3 4 3 1 4 3 2 3 3 3 1 1 2 0 3 1 1 5 5 3 2 3 3 4 3 4 3 4 3 3 5 3 1 0 1 3 1 5 2 3 1 5 1 3 1 0 1 3 3 1 1 4 5 3 1 5 1 0 0 3 3 4 3 1 3 5 2 5 4 4 1 3 0 5 3 1 1 3 1 2 3 3 5 2 2 1 3 5 4 1 0 1 3 4 1 1 4 3 3 0 3 3 3 4 3 4 1 5 1 1 1 1 3 5 5 1 5 2 3 1 2 1 1 4 5 5 2 5 2 4 1 3 4 1 4 4 1 5 4 1 4 2 4 5 1 4 2 3 3 1 2 4 4 5 0 0 1 1 3 4 3 1 4 4 2 3 1 5 3 3 3 4 1 2 3 3 4 2 3 2 1 4 1 5 4 3 5 2 5 5 3 1 4 3 4 0 3 3 5 1 3 3 1 4 5 3 1 1 3 3 4 2 3 3 2 4 3 5 3 4 3 4 4 4 1 0 4 2 4 4 5 3 3 5 1 2 4 4 3 4 3 5 4 1 1 4 1 4 4 1 5 5 3 5 3 1 5 2 3 4 4 3 3 4 1 1 3 4 4 5 4 2 5 0 5 0 3 4 4 3 1 5 3 1 1 3 0 5 1 1 4 4 1 1 1 2 2 5 4 4 1 2 1 5 4 4 4 3 5 2 0 2 2 1 2 4 4 4 5 4 5 3 1 2 2 3 4 4 1 1 2 1 0 2 3 1 4 1 1 4 3 1 4 4 0 4 1 5 3 4 3 5 3 4 4 4 4 2 5 5 4 1 4 5 1 2 4 4 3 5 5 3 4 0 3 5 0 3 3 0 4 4 3 3 0 3 4 4 2 1 1 1 3 3 0 0 4 5 1 1 0 1 3 0 3 1 5 5 1 0 4 3 1 4 3 4 4 2 1 4 4 1 3 1 3 2 1 4 1 2 2 1 4 2 4 1 2 0 3 2 1 4 4 0 0 2 3 3 1 3 3 5 3 2 3 2 2 1 4 2 3 3 3 1 2 2 4 4 3 4 4 3 5 3 0 5 3 3 1 1 3 3 2 4 1 5 0 3 3 1 5 5 1 2 3 1 1 1 0 4 0 4 4 4 4 4 5 2 5 4 4 4 5 1 4 3 2 2 1 4 5 4 1 1 5 5 1 4 5 1 3 3 0 1 3 2 3 4 2 3 3 4 1 3 5 1 4 0 5 4 5 1 4 3 2 0 4 4 1 3 5 4 4 1 4 4 4 3 1 1 4 4 4 3 0 2 2 0 4 3 4 1 4 4 0 1 2 0 4 4 0 0 2 1 3 3 3 3 3 4 4 0 4 5 1 1 0 3 3 4 3 5 1 4 1 2 4 5 4 3 0 2 4 5 2 1 1 4 4 2 1 4 3 1 1 4 5 3 0 3 1 2 2 5 2 1 3 1 4 4 1 2 3 3 3 1 4 5 2 2 3 1 1 4 0 4 5 3 2 3 1 4 3 1 0 3 5 3 1 4 2 4 4 4 4 4 2 4 3 2 2 4 1 1 5 4 3 1 4 1 4 2 0 2 4 1 4 4 1 1 3 0 3 4 4 4 1 1 4 4 1 0 4 5 3 3 1 1 4 4 1 2 1 3 1 1 5 1 4 2 0 1 3 4 5 1 2 1 1 5 1 2 4 1 3 5 1 3 3 2 1 0 2 2 4 3 4 1 4 1 4 3 4 3 4 3 2 4 3 4 1 4 4 1 3 1 1 1 1 1 3 4 4 1 3 3 1 4 1 4 0 0 1 2 4 4 3 0 1 Correct: 556 out of: 1283\n",
      "Accuracy of the network : 43 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "countCorrect0=0\n",
    "countCorrect1=0\n",
    "count0=0\n",
    "count1=0\n",
    "\n",
    "Y=[]  #target\n",
    "Pred=[]  #predicted\n",
    "\n",
    "with torch.no_grad():\n",
    "    for row in range(len(TestData)):\n",
    "        outputs = net(TestData[row,:].float())\n",
    "        result=0\n",
    "        total+=1\n",
    "        if outputs[0]<outputs[1]:result=1\n",
    "        if outputs[result]<outputs[2]:result=2\n",
    "        if outputs[result]<outputs[3]:result=3\n",
    "        if outputs[result]<outputs[4]:result=4\n",
    "        if outputs[result]<outputs[5]:result=5\n",
    "        \n",
    "        if labelsOneHot.iloc[row,result]==1: correct+=1\n",
    "        \n",
    "        Y.append(result)\n",
    "        Pred.append(labels.iloc[row])\n",
    "        \n",
    "        print(result, end=' ')\n",
    "        \n",
    "       \n",
    "print('Correct:', correct, 'out of:', total )\n",
    "print('Accuracy of the network : %d %%' % ( 100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 50  13   9   2   3   4]\n",
      " [ 20 137  49  46  36  37]\n",
      " [  3  20  60  18  11  12]\n",
      " [ 13  38  54 110  55  29]\n",
      " [  1  26  32  63 128  58]\n",
      " [  5  16  10  28  16  71]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    " \n",
    "print(metrics.confusion_matrix(Y,Pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Pants       0.54      0.62      0.58        81\n",
      "       False       0.55      0.42      0.48       325\n",
      " Barely-True       0.28      0.48      0.36       124\n",
      "   Hlaf-True       0.41      0.37      0.39       299\n",
      " Mostly-True       0.51      0.42      0.46       308\n",
      "        True       0.34      0.49      0.40       146\n",
      "\n",
      "    accuracy                           0.43      1283\n",
      "   macro avg       0.44      0.47      0.44      1283\n",
      "weighted avg       0.46      0.43      0.44      1283\n",
      "\n"
     ]
    }
   ],
   "source": [
    "target_names = ['Pants', 'False', 'Barely-True','Hlaf-True','Mostly-True','True']\n",
    "\n",
    "print(metrics.classification_report(Y, Pred,target_names =target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
